.packageName <- "spatstat"
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Fest.R"
#
#	Fest.R
#
#	Computes estimates of the empty space function
#
#	$Revision: 4.39 $	$Date: 2014/11/10 07:40:28 $
#

Fhazard <- function(X, ...) {
  Z <- Fest(X, ...)
  if(!any(names(Z) == "km"))
    stop("Kaplan-Meier estimator 'km' is required for hazard rate")
  ## strip off Poisson F
  Z <- Z[, (colnames(Z) != "theo")]
  ## relabel the fv object
  Z <- rebadge.fv(Z,
                  new.ylab=quote(h(r)),
                  new.fname="h",
                  tags=c("hazard", "theohaz"),
                  new.tags=c("hazard", "theo"),
                  new.labl=c("hat(%s)[km](r)", "%s[pois](r)"),
                  new.desc=c(
                      "Kaplan-Meier estimate of %s",
                      "theoretical Poisson %s"),
                  new.dotnames=c("hazard", "theo"),
                  new.preferred="hazard")
  ## strip off unwanted bits
  Z <- Z[, c("r", "hazard", "theo")]
  return(Z)
}

Fest <- function(X, ..., eps = NULL, r=NULL, breaks=NULL,
                 correction=c("rs", "km", "cs"),
                 domain=NULL) {
  verifyclass(X, "ppp")
  if(!is.null(domain))
      stopifnot(is.subset.owin(domain, Window(X)))
  
  ## Intensity estimate
  W <- X$window
  npts <- npoints(X)
  lambda <- npts/area(W)
  
  ## First discretise
  dwin <- as.mask(W, eps=eps)
  dX <- ppp(X$x, X$y, window=dwin, check=FALSE)

  ## histogram breakpoints 
  rmaxdefault <- rmax.rule("F", dwin, lambda)
  breaks <- handle.r.b.args(r, breaks, dwin, eps, 
                                  rmaxdefault=rmaxdefault)
  rvals <- breaks$r
  rmax  <- breaks$max
  
  ## choose correction(s)
#  correction.given <- !missing(correction) && !is.null(correction)
  if(is.null(correction)) {
    correction <- c("rs", "km", "cs")
  } else correction <- pickoption("correction", correction,
                           c(none="none",
                             border="rs",
                             rs="rs",
                             KM="km",
                             km="km",
                             Kaplan="km",
                             cs="cs",
                             ChiuStoyan="cs",
                             Hanisch="cs",
                             han="cs",
                             best="km"),
                           multi=TRUE)
  
  ## initialise fv object
  df <- data.frame(r=rvals, theo=1-exp(-lambda * pi * rvals^2))
  Z <- fv(df, "r", substitute(F(r), NULL), "theo", . ~ r,
          c(0,rmax),
          c("r", "%s[pois](r)"), 
          c("distance argument r", "theoretical Poisson %s"),
          fname="F")
  nr <- length(rvals)
  zeroes <- numeric(nr)

  ##  compute distances and censoring distances
  if(X$window$type == "rectangle") {
    ## original data were in a rectangle
    ## output of exactdt() is sufficient
    e <- exactdt(dX)
    dist <- e$d
    bdry <- e$b
    if(!is.null(domain)) {
      ok <- inside.owin(raster.xy(e$w), , domain)
      dist <- dist[ok]
      bdry <- bdry[ok]
    }
  } else {
    ## window is irregular..
    # Distance transform & boundary distance for all pixels
    e <- exactdt(dX)
    b <- bdist.pixels(dX$window, style="matrix")
    ## select only those pixels inside mask
    mm <- dwin$m
    if(!is.null(domain)) {
      ok <- inside.owin(raster.xy(e$w), , domain)
      mm <- as.vector(mm) & ok
    }
    dist <- e$d[mm]
    bdry <- b[mm]
  }
  
  ## censoring indicators
  d <- (dist <= bdry)
  ##  observed distances
  o <- pmin.int(dist, bdry)

  ## start calculating estimates of F
  
  if("none" %in% correction) {
    ##  UNCORRECTED e.d.f. of empty space distances
    if(npts == 0)
      edf <- zeroes
    else {
      hh <- hist(dist[dist <= rmax],breaks=breaks$val,plot=FALSE)$counts
      edf <- cumsum(hh)/length(dist)
    }
    Z <- bind.fv(Z, data.frame(raw=edf), "hat(%s)[raw](r)",
                 "uncorrected estimate of %s", "raw")
  }
  
  if("cs" %in% correction) {
    ## Chiu-Stoyan correction
    if(npts == 0)
      cs <- zeroes
    else {
      ##  uncensored distances
      x <- dist[d]
      ##  weights
      a <- eroded.areas(W, rvals)
      ## calculate Hanisch estimator
      h <- hist(x[x <= rmax], breaks=breaks$val, plot=FALSE)$counts
      H <- cumsum(h/a)
      cs <- H/max(H[is.finite(H)])
    }
    ## add to fv object
    Z <- bind.fv(Z, data.frame(cs=cs),
                 "hat(%s)[cs](r)", 
                 "Chiu-Stoyan estimate of %s",
                 "cs")
  }

  if(any(correction %in% c("rs", "km"))) {
    ## calculate Kaplan-Meier and/or border corrected (Reduced Sample) estimators
    want.rs <- "rs" %in% correction
    want.km <- "km" %in% correction
    selection <- c(want.rs, want.km, want.km, want.km)
    tags <- c("rs", "km", "hazard", "theohaz")[selection]
    labels <- c("hat(%s)[bord](r)", "hat(%s)[km](r)",
                "hat(h)[km](r)", "h[pois](r)")[selection]
    descr <- c("border corrected estimate of %s",
               "Kaplan-Meier estimate of %s",
               "Kaplan-Meier estimate of hazard function h(r)",
               "theoretical Poisson hazard h(r)")[selection]
    if(npts == 0) {
      result <- as.data.frame(matrix(0, nr, length(tags)))
      names(result) <- tags
    } else {
      result <- km.rs.opt(o, bdry, d, breaks, KM=want.km, RS=want.rs)
      result$theohaz <- 2 * pi * lambda * rvals
      result <- as.data.frame(result[tags])
    }
    ## add to fv object
    Z <- bind.fv(Z, result,
                 labels, descr, if(want.km) "km" else "rs")
  }
  
  ## wrap up
  unitname(Z) <- unitname(X)
  
  ## remove 'hazard' from the dotnames
  nama <- names(Z)
  fvnames(Z, ".") <- rev(setdiff(nama, c("r", "hazard", "theohaz")))
  
  ## determine recommended plot range
  attr(Z, "alim") <- with(Z, range(.x[is.finite(.y) & .y <= 0.9]))
  return(Z)
}

	
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/First.R"
#  First.R
#
#  $Revision: 1.41 $ $Date: 2014/10/24 00:22:30 $
#

.onLoad <- function(...) reset.spatstat.options()

.onAttach <- function(libname, pkgname) {
  store.versionstring.spatstat()
  ver <- versionstring.spatstat()
  descfile <- system.file("DESCRIPTION", package="spatstat")
  ni <- as.character(read.dcf(file=descfile, fields="Nickname"))
  msg <- paste("\nspatstat", ver,
               "     ",
               paren(paste("nickname:", sQuote(ni))),
               "\nFor an introduction to spatstat, type",
               sQuote("beginner"))
  packageStartupMessage(msg)
  ## check versions
  rv <- R.Version()
  rdate <- with(rv, ISOdate(year, month, day))
  if(Sys.Date() - as.Date(rdate) > 270) {
    ## R version is really old; just warn about this
    packageStartupMessage(paste("\nNote:",
                                rv$version.string,
                                "is more than 9 months old;",
            "we strongly recommend upgrading to the latest version"))
  } else {
    ## warn if spatstat version is old
    packdate <- as.Date(read.dcf(file=descfile, fields="Date"))
    elapsed <- Sys.Date() - packdate
    if(elapsed > 70) {
      if(elapsed > 365) {
        n <- floor(elapsed/365)
        unit <- "year"
        sowhat <- "we strongly recommend upgrading to the latest version."
      } else if(elapsed > 84) {
        n <- floor(elapsed/30)
        unit <- "month"
        sowhat <- "we recommend upgrading to the latest version."
      } else {
        n <- floor(elapsed/7)
        unit <- "week"
        sowhat <- "a newer version should be available."
      }
      expired <- if(n == 1) paste("a", unit) else paste(n, paste0(unit, "s"))
      packageStartupMessage(paste("\nNote: spatstat version", ver,
                                  "is out of date by more than",
                                  paste0(expired, ";"), 
                                  sowhat))
    }
  }
  invisible(NULL)
}

  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/GJfox.R"
#
#  GJfox.R
#
#  Foxall G-function and J-function
#
#  $Revision: 1.7 $   $Date: 2014/10/14 04:00:43 $
#
Gfox <- function(X, Y, r=NULL, breaks=NULL,
                 correction=c("km", "rs", "han"), ...) {
  stopifnot(is.ppp(X))
  if(!(is.ppp(Y) || is.psp(Y) || is.owin(Y)))
    stop("Y should be an object of class ppp, psp or owin")
  if(!identical(unitname(X), unitname(Y)))
    warning("X and Y are not in the same units")
  # 
  if(is.null(correction))
    correction <- c("rs", "km", "cs")
  correction <- pickoption("correction", correction,
                           c(none="none",
                             raw="none",
                             border="rs",
                             rs="rs",
                             KM="km",
                             km="km",
                             Kaplan="km",
                             han="han",
                             Hanisch="han",
                             best="km"),
                           multi=TRUE)
  corxtable <- c("km", "rs", "han", "none") 
  corx <- as.list(corxtable %in% correction)
  names(corx) <- corxtable
# ensure compatible windows
  WX <- as.owin(X)
  WY <- as.owin(Y)
  if(!is.subset.owin(WX, WY)) {
    warning("Trimming the window of X to be a subset of the window of Y")
    WX <- intersect.owin(WX, WY)
    X <- X[WX]
  }
# compute distances and censoring distances
  D <- distfun(Y)
  dist <- D(X)
  bdry <- bdist.points(X[WY])
# histogram breakpoints 
  dmax <- max(dist)
  breaks <- handle.r.b.args(r, breaks, WX, NULL, rmaxdefault=dmax)
  rval <- breaks$r
# censoring indicators
  d <- (dist <= bdry)
#  observed distances
  o <- pmin.int(dist, bdry)
# calculate estimates
  Z <- censtimeCDFest(o, bdry, d, breaks,
                      KM=corx$km,
                      RS=corx$rs,
                      HAN=corx$han,
                      RAW=corx$none,
                      han.denom=if(corx$han) eroded.areas(WX, rval) else NULL,
                      tt=dist)
# relabel
  Z <- rebadge.fv(Z, quote(G[fox](r)), c("G", "fox"))
  unitname(Z) <- unitname(Y)
  return(Z)
}

Jfox <- function(X, Y, r=NULL, breaks=NULL,
                 correction=c("km", "rs", "han"), ...) {
  H <- Hest(Y, r=r, breaks=breaks, correction=correction, ...)
  G <- Gfox(X, Y, r=H$r, correction=correction, ...)
  # derive J-function
  J <- eval.fv((1-G)/(1-H), dotonly=FALSE)
  # correct calculation of hazard is different
  if("hazard" %in% names(J))
    J$hazard <- G$hazard - H$hazard
  # base labels on 'J' rather than full expression
  attr(J, "labl") <- attr(H, "labl")
  # add column of 1's
  J <- bind.fv(J, data.frame(theo=rep.int(1, nrow(J))), "%s[theo](r)",
               "theoretical value of %s for independence")
  # rename 
  J <- rebadge.fv(J, quote(J[fox](r)), c("J", "fox"))
  funs <- c("km", "han", "rs", "raw", "theo")
  fvnames(J, ".") <- funs[funs %in% names(J)]
  unitname(J) <- unitname(Y)
  return(J)
}


	

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Gcom.R"
#
#	Gcom.R
#
#	Model compensator of G 
#
#	$Revision: 1.8 $	$Date: 2014/11/10 13:20:25 $
#
################################################################################
#


Gcom <- function(object, r=NULL, breaks=NULL, ...,
                 correction=c("border", "Hanisch"),
                 conditional=!is.poisson(object),
                 restrict=FALSE,
                 model=NULL,
                 trend=~1, interaction=Poisson(),
                 rbord=reach(interaction),
                 ppmcorrection="border",
                 truecoef=NULL, hi.res=NULL) {
  if(inherits(object, "ppm")) {
    fit <- object
  } else if(is.ppp(object) || inherits(object, "quad")) {
    if(is.ppp(object)) object <- quadscheme(object, ...)
    if(!is.null(model)) {
      fit <- update(model, Q=object, forcefit=TRUE)
    } else {
      fit <- ppm(object, trend=trend, interaction=interaction, rbord=rbord,
                 forcefit=TRUE)
    }
  } else 
    stop("object should be a fitted point process model or a point pattern")

  if(missing(conditional) || is.null(conditional))
    conditional <- !is.poisson(fit)
  
#  rfixed <- !is.null(r) || !is.null(breaks)
  
  # selection of edge corrections
#  correction.given <- !missing(correction) && !is.null(correction)
  correction <- pickoption("correction", correction,
                           c(none="none",
                             border="border",
                             Hanisch="Hanisch",
                             hanisch="Hanisch",
                             best="Hanisch"),
                           multi=TRUE)

  # Extract data and quadrature points
  Q <- quad.ppm(fit, drop=FALSE)
  X <- data.ppm(fit)
  Win <- X$window

  # edge correction algorithm 
  algo <- if(!conditional) "classical" else
          if(restrict) "restricted" else "reweighted"

  # conditioning on border region?
  if(!conditional) {
    Wfree <- Win
  } else {
    rbord <- fit$rbord
    Wfree <- erosion(Win, rbord)
    if(restrict) {
      retain <- inside.owin(union.quad(Q), , Wfree)
      Q <- Q[Wfree]
      X <- X[Wfree]
      Win <- Wfree
    } 
  }

  # Extract quadrature info
  U <- union.quad(Q)
  Z <- is.data(Q) # indicator data/dummy
#  E <- equalsfun.quad(Q)
  WQ <- w.quad(Q)  # quadrature weights

  # basic statistics
  npts <- npoints(X)
  areaW <- area(Win)
  lambda <- npts/areaW
  
  # quadrature points used
  USED <- if(algo == "reweighted") (bdist.points(U) > rbord) else rep.int(TRUE, U$n)
  
  # adjustments to account for restricted domain 
  if(conditional && spatstat.options("eroded.intensity")) {
    npts.used <- sum(Z & USED)
    area.used <- sum(WQ[USED])
    lambda.used <- npts.used/area.used
  } else {
    npts.used <- npts
    area.used <- areaW
    lambda.used <- lambda
  }
  
  #  determine breakpoints for r values
  rmaxdefault <- rmax.rule("G", if(restrict) Wfree else Win, lambda)
  breaks <- handle.r.b.args(r, breaks, Wfree, rmaxdefault=rmaxdefault)
  rvals <- breaks$r
  rmax  <- breaks$max
  
  # residuals
  resid <- residuals(fit, type="raw",drop=FALSE,
                    new.coef=truecoef, quad=hi.res)
  rescts  <- with(resid, "continuous")
  if(restrict) {
    # keep only data inside Wfree
    rescts  <- rescts[retain]
  }
  # absolute weight for continuous integrals
#  wc   <- -rescts

  # nearest neighbours (quadrature point to data point)
  nn <- nncross(U, X, seq(U$n), seq(X$n))
  dIJ <- nn$dist
  I <- seq(U$n)
#  J <- nn$which
  DD <- Z <- (I <= X$n)  # TRUE for data points
  wcIJ <- -rescts

  # determine whether a quadrature point will be used in integral
  okI <- USED[I]

   # initialise fv object
  r <- breaks$r
  df <- data.frame(r=r, pois=1 - exp(-pi * lambda.used * r^2))
  G <- fv(df, "r", substitute(G(r), NULL), "pois", . ~ r,
          alim=c(0, rmax),
          labl=c("r","%s[pois](r)"),
          desc=c("distance argument r", "theoretical Poisson %s"),
          fname="G")

  #  distance to boundary
  b <- bI <- bdist.points(U)

  dotnames <- character(0)

  # Border method
  if("border" %in% correction) {
    # reduced sample for G(r) of data only
    ZUSED <- Z & USED
    RSX <- Kount(dIJ[DD & okI], bI[DD & okI], b[ZUSED], breaks)
    Gb <- RSX$numerator/RSX$denom.count
    G <- bind.fv(G, data.frame(border=Gb), "hat(%s)[bord](r)",
                 "border-corrected nonparametric estimate of %s",
                 "border")
    # reduced sample for adjustment integral
    RSD <- Kwtsum(dIJ[okI], bI[okI], wcIJ[okI], b[ZUSED],
                  rep.int(1, sum(ZUSED)), breaks)
    Gbcom <- RSD$numerator/(1 + RSD$denominator)
    
    G <- bind.fv(G, data.frame(bcom=Gbcom), "bold(C)~hat(%s)[bord](r)",
                 "model compensator of border-corrected %s",
                 "bcom")

    dotnames <- c("border", "bcom", "pois")
  }

  # Hanisch correction for data
  if("Hanisch" %in% correction) {
    nnd <- dIJ[DD & okI]
    bdry <- bI[DD & okI]
    # weights
    ea <- eroded.areas(Win, rvals)
    if(algo == "reweighted") {
      # replace weight(r) by weight(max(rbord,r))
      ea[rvals < rbord] <- eroded.areas(Win, rbord)
    }
    # compute
    x <- nnd[nnd <= bdry]
    h <- whist(x[x <= rmax], breaks=breaks$val)
    H <- (1/lambda.used) * cumsum(h/ea)
    # glue on 
    G <- bind.fv(G, data.frame(han=H), "hat(%s)[han](r)",
                 "Hanisch correction estimate of %s",
                 "han")
    # Hanisch correction for adjustment integral
    nnd <- dIJ[okI]
    bdry <- bI[okI]
    wt   <- wcIJ[okI]
    x <- nnd[nnd <= bdry]
    wt <- wt[nnd <= bdry]
    h <- whist(x[x <= rmax], breaks=breaks$val, weights=wt[x <= rmax])
    lambdaplus <- (npts.used + 1)/area.used
    Hint <- (1/lambdaplus) * cumsum(h/ea)
    # glue on 
    G <- bind.fv(G, data.frame(hcom=Hint), "bold(C)~hat(%s)[han](r)",
                 "model compensator of Hanisch-corrected %s",
                 "hcom")
    # pseudovariance for Hanisch residual
    Hvar <- (1/lambdaplus^2) * cumsum(h/ea^2)
    G <- bind.fv(G, data.frame(hvar=Hvar), "bold(C)^2~hat(%s)[han](r)",
                 "Poincare variance for Hanisch corrected %s",
                 "hcom")
    # default plot does not show all components
    dotnames <- c("han", "hcom", dotnames)
  }
  # compute sensible 'alim'
  endpoint <- function(y, r, f) { min(r[y >= f * max(y)]) }
  amax <- endpoint(G$pois, G$r, 0.99)
  if(length(dotnames) > 0) 
    amax <- max(amax,
                unlist(lapply(as.data.frame(G)[,dotnames,drop=FALSE],
                              endpoint,
                              r=r, f=0.9)))
  attr(G, "alim") <- c(0, amax)
  #  
  fvnames(G, ".") <- dotnames
  unitname(G) <- unitname(X)
  # secret tag used by 'Gres'
  attr(G, "maker") <- "Gcom"
  return(G)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Gest.R"
#
#	Gest.S
#
#	Compute estimates of nearest neighbour distance distribution function G
#
#	$Revision: 4.30 $	$Date: 2014/10/24 00:22:30 $
#
################################################################################
#
"Gest" <-
"nearest.neighbour" <-
function(X, r=NULL, breaks=NULL, ..., correction=c("rs", "km", "han"),
         domain=NULL) {
  verifyclass(X, "ppp")
  if(!is.null(domain))
      stopifnot(is.subset.owin(domain, Window(X)))
  
  ##
  W <- X$window
  npts <- npoints(X)
  lambda <- npts/area(W)
  
  ## determine r values 
  rmaxdefault <- rmax.rule("G", W, lambda)
  breaks <- handle.r.b.args(r, breaks, W, rmaxdefault=rmaxdefault)
  rvals <- breaks$r
  rmax  <- breaks$max
  zeroes <- numeric(length(rvals))

  ## choose correction(s)
#  correction.given <- !missing(correction) && !is.null(correction)
  if(is.null(correction)) {
    correction <- c("rs", "km", "han")
  } else correction <- pickoption("correction", correction,
                           c(none="none",
                             border="rs",
                             rs="rs",
                             KM="km",
                             km="km",
                             Kaplan="km",
                             han="han",
                             Hanisch="han",
                             cs="han",
                             ChiuStoyan="han",
                             best="km"),
                           multi=TRUE)

  ##  compute nearest neighbour distances
  nnd <- nndist(X$x, X$y)
  ##  distance to boundary
  bdry <- bdist.points(X)
  ## restrict to subset ?
  if(!is.null(domain)) {
    ok <- inside.owin(X, w=domain)
    nnd <- nnd[ok]
    bdry <- bdry[ok]
  }
  ##  observations
  o <- pmin.int(nnd,bdry)
  ##  censoring indicators
  d <- (nnd <= bdry)

  ## initialise fv object
  df <- data.frame(r=rvals, theo=1-exp(-lambda * pi * rvals^2))
  Z <- fv(df, "r", substitute(G(r), NULL), "theo", . ~ r,
          c(0,rmax),
          c("r", "%s[pois](r)"), 
          c("distance argument r", "theoretical Poisson %s"),
          fname="G")

  if("none" %in% correction) {
    ##  UNCORRECTED e.d.f. of nearest neighbour distances: use with care
    if(npts <= 1)
      edf <- zeroes
    else {
      hh <- hist(nnd[nnd <= rmax],breaks=breaks$val,plot=FALSE)$counts
      edf <- cumsum(hh)/length(nnd)
    }
    Z <- bind.fv(Z, data.frame(raw=edf), "hat(%s)[raw](r)",
                 "uncorrected estimate of %s", "raw")
  }
  if("han" %in% correction) {
    if(npts <= 1)
      G <- zeroes
    else {
      ##  uncensored distances
      x <- nnd[d]
      ##  weights
      a <- eroded.areas(W, rvals, subset=domain)
      ## calculate Hanisch estimator
      h <- hist(x[x <= rmax], breaks=breaks$val, plot=FALSE)$counts
      G <- cumsum(h/a)
      G <- G/max(G[is.finite(G)])
    }
    ## add to fv object
    Z <- bind.fv(Z, data.frame(han=G),
                 "hat(%s)[han](r)", 
                 "Hanisch estimate of %s",
                 "han")
    ## modify recommended plot range
    attr(Z, "alim") <- range(rvals[G <= 0.9])
  }

  if(any(correction %in% c("rs", "km"))) {
    ## calculate Kaplan-Meier and border correction (Reduced Sample) estimators
    if(npts == 0)
      result <- data.frame(rs=zeroes, km=zeroes, hazard=zeroes, theohaz=zeroes)
    else {
      result <- km.rs(o, bdry, d, breaks)
      result$theohaz <- 2 * pi * lambda * rvals
      result <- as.data.frame(result[c("rs", "km", "hazard", "theohaz")])
    }
    ## add to fv object
    Z <- bind.fv(Z, result,
                 c("hat(%s)[bord](r)", "hat(%s)[km](r)",
                   "hat(h)[km](r)", "h[pois](r)"),
                 c("border corrected estimate of %s",
                   "Kaplan-Meier estimate of %s",
                   "Kaplan-Meier estimate of hazard function h(r)",
                   "theoretical Poisson hazard function h(r)"),
                 "km")
    
    ## modify recommended plot range
    attr(Z, "alim") <- range(rvals[result$km <= 0.9])
  }
  nama <- names(Z)
  fvnames(Z, ".") <- rev(setdiff(nama, c("r", "hazard", "theohaz")))
  unitname(Z) <- unitname(X)
  return(Z)
}	

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Gmulti.R"
#	Gmulti.S
#
#	Compute estimates of nearest neighbour distance distribution functions
#	for multitype point patterns
#
#	S functions:	
#		Gcross                G_{ij}
#		Gdot		      G_{i\bullet}
#		Gmulti	              (generic)
#
#	$Revision: 4.42 $	$Date: 2014/10/24 00:22:30 $
#
################################################################################

"Gcross" <-		
function(X, i, j, r=NULL, breaks=NULL, ..., correction=c("rs", "km", "han"))
{
#	computes G_{ij} estimates
#
#	X		marked point pattern (of class 'ppp')
#	i,j		the two mark values to be compared
#  
#       r:              (optional) values of argument r  
#	breaks:		(optional) breakpoints for argument r
#
  X <- as.ppp(X)
  if(!is.marked(X, dfok=FALSE))
    stop(paste("point pattern has no", sQuote("marks")))
  stopifnot(is.multitype(X))
#
  marx <- marks(X, dfok=FALSE)
  if(missing(i)) i <- levels(marx)[1]
  if(missing(j)) j <- levels(marx)[2]
#  
  I <- (marx == i)
  if(sum(I) == 0) stop("No points are of type i")
        
  if(i == j)
    result <- Gest(X[I], r=r, breaks=breaks, ...)
  else {
    J <- (marx == j)
    if(sum(J) == 0) stop("No points are of type j")
    result <- Gmulti(X, I, J, r=r, breaks=breaks, disjoint=FALSE, ...,
                     correction=correction)
  }
  iname <- make.parseable(paste(i))
  jname <- make.parseable(paste(j))
  result <-
    rebadge.fv(result,
               substitute(G[i,j](r), list(i=iname, j=jname)),
               c("G", paste0("list(", iname, ",", jname, ")")),
               new.yexp=substitute(G[list(i,j)](r),
                                   list(i=iname,j=jname)))
  return(result)
}	

"Gdot" <- 	
function(X, i, r=NULL, breaks=NULL, ..., correction=c("km","rs","han")) {
#  Computes estimate of 
#      G_{i\bullet}(t) = 
#  P( a further point of pattern in B(0,t)| a type i point at 0 )
#	
#	X		marked point pattern (of class ppp)
#  
#       r:              (optional) values of argument r  
#	breaks:		(optional) breakpoints for argument r
#
  X <- as.ppp(X)
  if(!is.marked(X))
    stop(paste("point pattern has no", sQuote("marks")))
  stopifnot(is.multitype(X))
#
  marx <- marks(X, dfok=FALSE)
  if(missing(i)) i <- levels(marx)[1]
  I <- (marx == i)
  if(sum(I) == 0) stop("No points are of type i")
  J <- rep.int(TRUE, X$n)	# i.e. all points
# 
  result <- Gmulti(X, I, J, r, breaks, disjoint=FALSE, ...,
                   correction=correction)
  iname <- make.parseable(paste(i))
  result <- rebadge.fv(result,
                  substitute(G[i ~ dot](r), list(i=iname)),
                  c("G", paste(iname, "~ symbol(\"\\267\")")),
                  new.yexp=substitute(G[i ~ symbol("\267")](r), list(i=iname)))
  return(result)
}	

	
##########

"Gmulti" <- 	
function(X, I, J, r=NULL, breaks=NULL, ..., disjoint=NULL,
         correction=c("rs", "km", "han")) {
#
#  engine for computing the estimate of G_{ij} or G_{i\bullet}
#  depending on selection of I, J
#  
#	X		marked point pattern (of class ppp)
#	
#	I,J		logical vectors of length equal to the number of points
#			and identifying the two subsets of points to be
#			compared.
#  
#       r:              (optional) values of argument r  
#	breaks:		(optional) breakpoints for argument r
#
  verifyclass(X, "ppp")
  W <- X$window
  npts <- npoints(X)
  areaW <- area(W)
# check I and J
  I <- ppsubset(X, I)
  J <- ppsubset(X, J)
  if(is.null(I) || is.null(J))
    stop("I and J must be valid subset indices")
  nI <- sum(I)
  nJ <- sum(J)
  if(nI == 0) stop("No points satisfy condition I")
  if(nJ == 0) stop("No points satisfy condition J")

  if(is.null(disjoint))
    disjoint <- !any(I & J)
# choose correction(s)
#  correction.given <- !missing(correction) && !is.null(correction)
  if(is.null(correction))
    correction <- c("rs", "km", "han")
  correction <- pickoption("correction", correction,
                           c(none="none",
                             border="rs",
                             rs="rs",
                             KM="km",
                             km="km",
                             Kaplan="km",
                             han="han",
                             Hanisch="han",
                             best="km"),
                           multi=TRUE)
#  determine breakpoints for r values
  lamJ <- nJ/areaW
  rmaxdefault <- rmax.rule("G", W, lamJ)
  breaks <- handle.r.b.args(r, breaks, W, rmaxdefault=rmaxdefault)
#  brks <- breaks$val
  rmax <- breaks$max
  rvals <- breaks$r
  zeroes <- numeric(length(rvals))
# initialise fv object
  df <- data.frame(r=rvals, theo=1-exp(-lamJ * pi * rvals^2))
  fname <- c("G", "list(I,J)")
  Z <- fv(df, "r", quote(G[I,J](r)), "theo", . ~ r,
          c(0,rmax),
          c("r", makefvlabel(NULL, NULL, fname, "pois")),
          c("distance argument r", "theoretical Poisson %s"),
          fname=fname,
          yexp=quote(G[list(I,J)](r)))
#  "type I to type J" nearest neighbour distances
  XI <- X[I]
  XJ <- X[J]
  if(disjoint) 
    nnd <- nncross(XI, XJ, what="dist")
  else {
    seqnp <- seq_len(npts)
    iX <- seqnp[I]
    iY <- seqnp[J]
    nnd <- nncross(XI, XJ, iX, iY, what="dist")
  }
#  distance to boundary from each type i point
  bdry <- bdist.points(XI)
#  observations
  o <- pmin.int(nnd,bdry)
#  censoring indicators
  d <- (nnd <= bdry)
#
# calculate estimates
  
  if("none" %in% correction) {
    #  UNCORRECTED e.d.f. of nearest neighbour distances: use with care
    if(npts == 0)
      edf <- zeroes
    else {
      hh <- hist(nnd[nnd <= rmax],breaks=breaks$val,plot=FALSE)$counts
      edf <- cumsum(hh)/length(nnd)
    }
    Z <- bind.fv(Z, data.frame(raw=edf),
                 makefvlabel(NULL, "hat", fname, "raw"),
                 "uncorrected estimate of %s", "raw")
  }

  if("han" %in% correction) {
    # Hanisch style estimator
    if(npts == 0)
      G <- zeroes
    else {
      #  uncensored distances
      x <- nnd[d]
      #  weights
      a <- eroded.areas(W, rvals)
      # calculate Hanisch estimator
      h <- hist(x[x <= rmax], breaks=breaks$val, plot=FALSE)$counts
      G <- cumsum(h/a)
      G <- G/max(G[is.finite(G)])
    }
    # add to fv object
    Z <- bind.fv(Z, data.frame(han=G),
                 makefvlabel(NULL, "hat", fname, "han"),
                 "Hanisch estimate of %s",
                 "han")
    # modify recommended plot range
    attr(Z, "alim") <- range(rvals[G <= 0.9])
  }
  
  if(any(correction %in% c("rs", "km"))) {
    # calculate Kaplan-Meier and border correction (Reduced Sample) estimators
    if(npts == 0)
      result <- data.frame(rs=zeroes, km=zeroes, hazard=zeroes)
    else {
      result <- km.rs(o, bdry, d, breaks)
      result <- as.data.frame(result[c("rs", "km", "hazard")])
    }
    # add to fv object
    Z <- bind.fv(Z, result,
                 c(makefvlabel(NULL, "hat", fname, "bord"),
                   makefvlabel(NULL, "hat", fname, "km"),
                   "hazard(r)"),
                 c("border corrected estimate of %s",
                   "Kaplan-Meier estimate of %s",
                   "Kaplan-Meier estimate of hazard function lambda(r)"),
                 "km")
    # modify recommended plot range
    attr(Z, "alim") <- range(rvals[result$km <= 0.9])
  }
  nama <- names(Z)
  fvnames(Z, ".") <- rev(nama[!(nama %in% c("r", "hazard"))])
  unitname(Z) <- unitname(X)
  return(Z)
}	


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Gres.R"
#
#	Gres.R
#
#	Residual G 
#
#	$Revision: 1.3 $	$Date: 2013/04/25 06:37:43 $
#
#############################################################################
#

Gres <- function(object, ...) {
  if(!is.fv(object)) {
    # usual case where 'object' is a ppm, ppp or quad
    G <- Gcom(object, ...)
  } else {
    # case where 'object' is the output of 'Gcom'
    a <- attr(object, "maker")
    if(is.null(a) || a != "Gcom")
      stop("fv object was not created by Gcom")
    G <- object
    if(length(list(...)) > 0)
      warning("Extra arguments ignored")
  }
  # initialise fv object
  df <- data.frame(r=G$r, theo=numeric(length(G$r)))
  desc <- c("distance argument r", "value 0 corresponding to perfect fit")
  ans <- fv(df, "r", substitute(bold(R)~hat(G)(r), NULL),
            "theo", . ~ r,
            attr(G, "alim"), c("r","bold(R)~%s[theo](r)"), desc, fname="G")
  # add residual estimates
  nam <- names(G)
  if(all(c("border","bcom") %in% nam))
    ans <- bind.fv(ans,
                    data.frame(bres=with(G, border-bcom)),
                    "bold(R)~hat(%s)[bord](r)",
                    "border corrected residual of %s",
                    "bres")
  if(all(c("han","hcom") %in% nam))
    ans <- bind.fv(ans,
                    data.frame(hres=with(G, han-hcom)),
                    "bold(R)~hat(%s)[han](r)",
                    "Hanisch corrected residual of %s",
                    "hres")
  if("hvar" %in% nam) {
    savedotnames <- fvnames(ans, ".")
    hsd <- with(G, sqrt(hvar))
    ans <- bind.fv(ans,
                    data.frame(hvar=with(G, hvar),
                               hsd = hsd,
                               hi =  2*hsd,
                               lo = -2*hsd),
                    c("bold(C)^2~hat(%s)[han](r)",
                      "sqrt(bold(C)^2~hat(%s)[han](r))",
                      "bold(R)~hat(%s)[Hi](r)",
                      "bold(R)~hat(%s)[Lo](r)"),
                    c("pseudovariance of Hanisch corrected residual %s",
                      "pseudo-SD of Hanisch corrected residual %s",
                      "upper critical band for Hanisch corrected residual %s",
                      "lower critical band for Hanisch corrected residual %s"),
                    "hres")
    ans <- bind.fv(ans,
                   data.frame(hstdres=with(ans, hres/hsd)),
                   "bold(T)~hat(%s)[han](r)",
                   "standardised Hanisch-corrected residual %s",
                   "hres")
    fvnames(ans, ".") <- c(savedotnames, c("hi", "lo"))
  }
  unitname(ans) <- unitname(G)
  return(ans)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Hest.R"
#
#    Hest.R
#
#  Contact distribution for a random set
#
#
Hest <- function(X, r=NULL, breaks=NULL,
                 ...,
                 correction=c("km", "rs", "han"),
                 conditional=TRUE) {
  if(!(is.ppp(X) || is.psp(X) || is.owin(X)))
    stop("X should be an object of class ppp, psp or owin")
  # handle corrections
  if(is.null(correction))
    correction <- c("rs", "km", "cs")
  correction <- pickoption("correction", correction,
                           c(none="none",
                             raw="none",
                             border="rs",
                             rs="rs",
                             KM="km",
                             km="km",
                             Kaplan="km",
                             han="han",
                             Hanisch="han",
                             best="km"),
                           multi=TRUE)
  corxtable <- c("km", "rs", "han", "none") 
  corx <- as.list(corxtable %in% correction)
  names(corx) <- corxtable
# compute distance map
  D <- distmap(X, ...)
  B <- attr(D, "bdry")
  W <- as.owin(D)
# histogram breakpoints 
  dmax <- summary(D)$max
  breaks <- handle.r.b.args(r, breaks, W, NULL, rmaxdefault=dmax)
  rval <- breaks$r
#  extract distances and censoring distances
  dist <- as.vector(as.matrix(D))
  bdry <- as.vector(as.matrix(B))
  ok <- !is.na(dist) && !is.na(bdry)
  dist <- dist[ok]
  bdry <- bdry[ok]
# delete zero distances
  if(conditional && is.owin(X)) {
    pos <- (dist > 0)
    dist <- dist[pos]
    bdry <- bdry[pos]
  }
# censoring indicators
  d <- (dist <= bdry)
#  observed distances
  o <- pmin.int(dist, bdry)
# calculate estimates
  Z <- censtimeCDFest(o, bdry, d, breaks,
                      KM=corx$km,
                      RS=corx$rs,
                      HAN=corx$han,
                      RAW=corx$none,
                      han.denom=if(corx$han) eroded.areas(W, rval) else NULL,
                      tt=dist)
# conditional on d > 0 ?  
  if(conditional && is.owin(X)) {
    zeroadj <- function(x) { (x - x[1])/(1-x[1]) }
    if(corx$km) Z$km <- zeroadj(Z$km)
    if(corx$rs) Z$rs <- zeroadj(Z$rs)
    if(corx$han) Z$han <- zeroadj(Z$han)
    if(corx$none) Z$raw <- zeroadj(Z$raw)
  }
# relabel
  Z <- rebadge.fv(Z, substitute(H(r), NULL), "H")
  unitname(Z) <- unitname(X)
  return(Z)
}

	

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Iest.R"
#	Iest.R
#
#	I function
#
#	$Revision: 1.12 $	$Date: 2011/04/19 02:31:39 $
#
#
#
Iest <- function(X, ..., eps=NULL, r = NULL, breaks = NULL, correction=NULL) {

  X <- as.ppp(X)
  if(!is.multitype(X))
    stop("Only applicable to multitype point patterns")
  marx <- marks(X, dfok=FALSE)
  ntypes <- length(levels(marx))

  Y <- unmark(split(X))
  
  # relative proportions 
  ni <- unlist(lapply(Y, function(Z) { Z$n }))
  fi <- ni/sum(ni)

  # J function of pattern regardless of type
  Jdotdot <- Jest(unmark(X), correction=correction)
  rvals <- Jdotdot$r
  
  # J function of subpattern of each type i
  Jii <- lapply(Y, Jest, r=rvals, correction=correction)
  nrvals <- unlist(lapply(Jii, function(x) { length(x$r) }))
  if(length(unique(nrvals)) != 1 || nrvals[1] != length(rvals))
    stop("Internal error: J function objects have different lengths")

  # initialise fv object
  alim <- attr(Jdotdot, "alim")
  Z <- fv(data.frame(r=rvals, theo=0),
          "r", substitute(I(r), NULL), "theo",
          . ~ r, alim,
          c("r", "%s[pois](r)"),
          c("distance argument r", "theoretical Poisson %s"),
          fname="I")
  
  # Estimates of each type
  extractit <- function(Z, what) { Z[[what]] }
  extract <- function(Zlist, what) { unlist(lapply(Zlist, extractit, what=what)) }
  namii <- unlist(lapply(Jii, names))
  namdd <- names(Jdotdot)
  bothnames <- namii[namii %in% namdd]
  
  if("un" %in% bothnames) {
    Jun <- matrix(extract(Jii, "un"), nrow=ntypes, byrow=TRUE)
    Iun <- apply(fi * Jun, 2, sum) - Jdotdot$un
    Z <- bind.fv(Z, data.frame(un=Iun), "hat(%s)[un](r)",
                 "uncorrected estimate of %s", "un")
  }
  if("rs" %in% bothnames) {
    Jrs <- matrix(extract(Jii, "rs"), nrow=ntypes, byrow=TRUE)
    Irs <- apply(fi * Jrs, 2, sum) - Jdotdot$rs    
    Z <- bind.fv(Z, data.frame(rs=Irs), "hat(%s)[rs](r)",
                 "border corrected estimate of %s", "rs")
  }
  if("han" %in% bothnames) {
    Jhan <- matrix(extract(Jii, "han"), nrow=ntypes, byrow=TRUE)
    Ihan <- apply(fi * Jhan, 2, sum) - Jdotdot$han
    Z <- bind.fv(Z, data.frame(han=Ihan), "hat(%s)[han](r)",
                 "Hanisch-style estimate of %s", "han")
  }
  if("km" %in% bothnames) {
    Jkm <- matrix(extract(Jii, "km"), nrow=ntypes, byrow=TRUE)
    Ikm <- apply(fi * Jkm, 2, sum) - Jdotdot$km
    Z <- bind.fv(Z, data.frame(km=Ikm), "hat(%s)[km](r)",
                 "Kaplan-Meier estimate of %s", "km")
  }
  unitname(Z) <- unitname(X)
  return(Z)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Jest.R"
#	Jest.S
#
#	Usual invocation to compute J function
#	if F and G are not required 
#
#	$Revision: 4.19 $	$Date: 2014/11/10 08:23:33 $
#
#
#
"Jest" <-
function(X, ..., eps=NULL, r=NULL, breaks=NULL, correction=NULL) {
  X <- as.ppp(X)
  W<- X$window
  rmaxdefault <- rmax.rule("J", W)
  brks <- handle.r.b.args(r, breaks, W, rmaxdefault=rmaxdefault)$val
  # compute F and G 
  FF <- Fest(X, eps, breaks=brks, correction=correction)
  G <- Gest(X, breaks=brks, correction=correction)
  # initialise fv object
  rvals <- FF$r
  rmax  <- max(rvals)
#  Fvals <- FF[[attr(FF, "valu")]]
  Z <- fv(data.frame(r=rvals, theo=1),
          "r", substitute(J(r), NULL),
          "theo",
          . ~ r,
          c(0,rmax),
          c("r", "%s[pois](r)"),
          c("distance argument r", "theoretical Poisson %s"),
          fname="J")
  # compute J function estimates
  # this has to be done manually because of the mismatch between names
  ratio <- function(a, b) {
    result <- a/b
    result[ b == 0 ] <- NA
    result
  }
  Fnames <- names(FF)
  Gnames <- names(G)
  if("raw" %in% Gnames && "raw" %in% Fnames) {
    Jun <- ratio(1-G$raw, 1-FF$raw)
    Z <- bind.fv(Z, data.frame(un=Jun), "hat(%s)[un](r)",
                 "uncorrected estimate of %s", "un")
    attr(Z, "alim") <- range(rvals[FF$raw <= 0.9])
  }
  if("rs" %in% Gnames && "rs" %in% Fnames) {
    Jrs <- ratio(1-G$rs, 1-FF$rs)
    Z <- bind.fv(Z, data.frame(rs=Jrs), "hat(%s)[rs](r)",
                 "border corrected estimate of %s", "rs")
    attr(Z, "alim") <- range(rvals[FF$rs <= 0.9])
  }
  if("han" %in% Gnames && "cs" %in% Fnames) {
    Jhan <- ratio(1-G$han, 1-FF$cs)
    Z <- bind.fv(Z, data.frame(han=Jhan), "hat(%s)[han](r)",
                 "Hanisch-style estimate of %s", "han")
    attr(Z, "alim") <- range(rvals[FF$cs <= 0.9])
  }
  if("km" %in% Gnames && "km" %in% Fnames) {
    Jkm <- ratio(1-G$km, 1-FF$km)
    Z <- bind.fv(Z, data.frame(km=Jkm), "hat(%s)[km](r)",
                 "Kaplan-Meier estimate of %s", "km")
    attr(Z, "alim") <- range(rvals[FF$km <= 0.9])
  }
  if("hazard" %in% Gnames && "hazard" %in% Fnames) {
    Jhaz <- G$hazard - FF$hazard
    Z <- bind.fv(Z, data.frame(hazard=Jhaz), "hazard(r)",
                 "Kaplan-Meier estimate of derivative of log(%s)")
  }
# set default plotting values and order
  nama <- names(Z)
  fvnames(Z, ".") <- rev(nama[!(nama %in% c("r", "hazard"))])
  
# add more info        
  attr(Z, "F") <- FF
  attr(Z, "G") <- G

  unitname(Z) <- unitname(X)
  return(Z)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Jinhom.R"
#
# Jinhom.R
#
#  $Revision: 1.9 $ $Date: 2014/10/24 00:22:30 $
#

Ginhom <- function(X, lambda=NULL, lmin=NULL,
                   ...,
                   sigma=NULL, varcov=NULL,
                   r=NULL, breaks=NULL,
                   ratio=FALSE, update = TRUE) {
  
  stopifnot(is.ppp(X))

  npts <- npoints(X)
  W <- as.owin(X)
  areaW <- area(W)
  miss.update <- missing(update)

  # determine 'r' values
  rmaxdefault <- rmax.rule("G", W, npts/areaW)
  breaks <- handle.r.b.args(r, breaks, W, rmaxdefault=rmaxdefault)
  if(!breaks$even)
    stop("r values must be evenly spaced")
  r <- breaks$r
  rmax <- breaks$max
  nr <- length(r)

  dangerous <- "lambda"
  danger <- TRUE
  
  # Intensity values at data points
  if(is.null(lambda)) {
    # No intensity data provided
    danger <- FALSE
    # Estimate density at points by leave-one-out kernel smoothing
    lamX <- density(X, ..., sigma=sigma, varcov=varcov,
                      at="points", leaveoneout=TRUE)
    lambdaX <- as.numeric(lamX)
    # negative or zero values are due to numerical error
    lambdaX <- pmax.int(lambdaX, .Machine$double.eps)
  } else {
    # lambda values provided
    if(is.im(lambda)) 
      lambdaX <- safelookup(lambda, X)
    else if(is.ppm(lambda) || is.kppm(lambda) || is.dppm(lambda)) {
          model <- lambda
          if(!update) {
            ## just use intensity of fitted model
            lambdaX <- predict(lambda, locations=X, type="trend")
          } else {
            ## re-fit model to data X
            model <-
              if(is.ppm(model)) update(model, Q=X) else update(model, X=X)
            lambdaX <- fitted(model, dataonly=TRUE)
            danger <- FALSE
            if(miss.update) 
              warn.once(key="Ginhom.update",
                        "The behaviour of Ginhom when lambda is a ppm object",
                        "has changed (in spatstat 1.37-0 and later).",
                        "See help(Ginhom)")
          }
        } else if(is.function(lambda)) 
      lambdaX <- lambda(X$x, X$y)
    else if(is.numeric(lambda) && is.vector(as.numeric(lambda))) {
      lambdaX <- lambda
      check.nvector(lambdaX, npts)
    } else stop(paste(sQuote("lambda"),
                      "should be a vector, a pixel image, or a function"))
    # negative values are illegal
    minX <- min(lambdaX)
    if(minX < 0)
      stop("Negative values of lambda were encountered at data points")
    if(minX == 0)
      stop("Zero values of lambda were encountered at data points")
  }
  # Minimum intensity
  if(!is.null(lmin)) {
    check.1.real(lmin)
    stopifnot(lmin >= 0)
  } else {
    # Compute minimum value over window
    if(is.null(lambda)) {
      # extract previously selected smoothing bandwidth
      sigma <- attr(lamX, "sigma")
      varcov <- attr(lamX, "varcov")
      # estimate density on a pixel grid and minimise
      lam <- density(X, ..., sigma=sigma, varcov=varcov, at="pixels")
      lmin <- min(lam)
      # negative or zero values may occur due to numerical error
      lmin <- max(lmin, .Machine$double.eps)
    } else {
      if(is.im(lambda)) 
        lmin <- min(lambda)
      else if(is.ppm(lambda) || is.kppm(lambda) || is.dppm(lambda)) 
        lmin <- min(predict(lambda))
      else if(is.function(lambda)) 
        lmin <- min(as.im(lambda, W))
      else if(is.numeric(lambda) && is.vector(as.numeric(lambda))) 
        lmin <- min(lambdaX)
    }
    if(lmin < 0)
      stop("Negative values of intensity encountered")
    # ensure lmin < lambdaX
    lmin <- min(lmin, lambdaX)
  }
  # Compute intensity factor
  lratio <- lmin/lambdaX
  vv <- 1 - lratio
  bad <- (lratio > 1)
  if((nbad <- sum(bad)) > 0)
    stop(paste("Value of", sQuote("lmin"), "exceeds",
               nbad, gettext(nbad, "value", "values"),
               "of", sQuote("lambda")))
   # sort data points in order of increasing x coordinate
  xx <- X$x
  yy <- X$y
  oX <- fave.order(xx)
  xord <- xx[oX]
  yord <- yy[oX]
  vord <- vv[oX]
  # compute local cumulative products
  z <- .C("locprod",
          n = as.integer(npts),
          x = as.double(xord),
          y = as.double(yord),
          v = as.double(vord),
          nr = as.integer(nr),
          rmax = as.double(rmax),
          ans = as.double(numeric(npts * nr)))
  ans <- matrix(z$ans, nrow=nr, ncol=npts)
  # revert to original ordering
  loccumprod <- matrix(,  nrow=nr, ncol=npts)
  loccumprod[, oX] <- ans
  # border correction
  bX <- bdist.points(X)
  ok <- outer(r, bX, "<=")
  denom <- .rowSums(ok, nr, npts)
  loccumprod[!ok] <- 0
  numer <- .rowSums(loccumprod, nr, npts)
  # pack up
  Gdf <- data.frame(r=r, theo = 1 - exp(- lmin * pi * r^2))
  desc <- c("distance argument r", "theoretical Poisson %s")
  theo.denom <- rep.int(npts, nr)
  G <- ratfv(Gdf, NULL, theo.denom,
             "r", quote(G[inhom](r)),
             "theo", NULL, c(0,rmax),
             c("r", "{%s[%s]^{pois}}(r)"),
             desc,
             fname=c("G", "inhom"),
             ratio=ratio)
  G <- bind.ratfv(G,
                  data.frame(bord=denom-numer), denom,
                   "{hat(%s)[%s]^{bord}}(r)",
                  "border estimate of %s",
                  "bord",
                  ratio=ratio)
  # 
  formula(G) <- . ~ r
  fvnames(G, ".") <- c("bord", "theo")
  unitname(G) <- unitname(X)
  if(ratio)
    G <- conform.ratfv(G)
  if(danger)
    attr(G, "dangerous") <- dangerous
  return(G)
}


   

Finhom <- function(X, lambda=NULL, lmin=NULL,
                   ...,
                   sigma=NULL, varcov=NULL,
                   r=NULL, breaks=NULL,
                   ratio=FALSE, update = TRUE) {
  
  stopifnot(is.ppp(X))

  npts <- npoints(X)
  W <- as.owin(X)
  areaW <- area(W)
  miss.update <- missing(update)

  # determine 'r' values
  rmaxdefault <- rmax.rule("F", W, npts/areaW)
  breaks <- handle.r.b.args(r, breaks, W, rmaxdefault=rmaxdefault)
  if(!breaks$even)
    stop("r values must be evenly spaced")
  r <- breaks$r
  rmax <- breaks$max
  nr <- length(r)

  dangerous <- "lambda"
  danger <- TRUE
  
  # Intensity values at data points
  if(is.null(lambda)) {
    # No intensity data provided
    danger <- FALSE
    # Estimate density at points by leave-one-out kernel smoothing
    lamX <- density(X, ..., sigma=sigma, varcov=varcov,
                      at="points", leaveoneout=TRUE)
    lambdaX <- as.numeric(lamX)
    # negative or zero values are due to numerical error
    lambdaX <- pmax.int(lambdaX, .Machine$double.eps)
  } else {
    # lambda values provided
    if(is.im(lambda)) 
      lambdaX <- safelookup(lambda, X)
    else if(is.ppm(lambda) || is.kppm(lambda) || is.dppm(lambda)) {
          model <- lambda
          if(!update) {
            ## just use intensity of fitted model
            lambdaX <- predict(lambda, locations=X, type="trend")
          } else {
            ## re-fit model to data X
            model <-
              if(is.ppm(model)) update(model, Q=X) else update(model, X=X)
            lambdaX <- fitted(model, dataonly=TRUE)
            danger <- FALSE
            if(miss.update) 
              warn.once(key="Finhom.update",
                        "The behaviour of Finhom when lambda is a ppm object",
                        "has changed (in spatstat 1.37-0 and later).",
                        "See help(Finhom)")
          }
        } else if(is.function(lambda)) 
      lambdaX <- lambda(X$x, X$y)
    else if(is.numeric(lambda) && is.vector(as.numeric(lambda))) {
      lambdaX <- lambda
      check.nvector(lambdaX, npts)
    } else stop(paste(sQuote("lambda"),
                      "should be a vector, a pixel image, or a function"))
    # negative values are illegal
    minX <- min(lambdaX)
    if(minX < 0)
      stop("Negative values of lambda were encountered at data points")
    if(minX == 0)
      stop("Zero values of lambda were encountered at data points")
  }
  # Minimum intensity
  if(!is.null(lmin)) {
    check.1.real(lmin)
    stopifnot(lmin >= 0)
  } else {
    # Compute minimum value over window
    if(is.null(lambda)) {
      # extract previously selected smoothing bandwidth
      sigma <- attr(lamX, "sigma")
      varcov <- attr(lamX, "varcov")
      # estimate density on a pixel grid and minimise
      lam <- density(X, ..., sigma=sigma, varcov=varcov, at="pixels")
      lmin <- min(lam)
      # negative or zero values may occur due to numerical error
      lmin <- max(lmin, .Machine$double.eps)
    } else {
      if(is.im(lambda)) 
        lmin <- min(lambda)
      else if(is.ppm(lambda) || is.kppm(lambda) || is.dppm(lambda)) 
        lmin <- min(predict(lambda))
      else if(is.function(lambda)) 
        lmin <- min(as.im(lambda, W))
      else if(is.numeric(lambda) && is.vector(as.numeric(lambda))) 
        lmin <- min(lambdaX)
    }
    if(lmin < 0)
      stop("Negative values of intensity encountered")
    # ensure lmin < lambdaX
    lmin <- min(lmin, lambdaX)
  }
  # Compute intensity factor
  lratio <- lmin/lambdaX
  vv <- 1 - lratio
  bad <- (lratio > 1)
  if((nbad <- sum(bad)) > 0)
    stop(paste("Value of", sQuote("lmin"), "exceeds",
               nbad, gettext(nbad, "value", "values"),
               "of", sQuote("lambda")))
  # sort data points in order of increasing x coordinate
  xx <- X$x
  yy <- X$y
  oX <- fave.order(xx)
  xord <- xx[oX]
  yord <- yy[oX]
  vord <- vv[oX]
  # determine pixel grid and compute distance to boundary
  M <- do.call.matched("as.mask", append(list(w=W), list(...)))
  bM <- bdist.pixels(M, style="matrix")
  bM <- as.vector(bM)
  # x, y coordinates of pixels are already sorted by increasing x
  xM <- as.vector(rasterx.mask(M))
  yM <- as.vector(rastery.mask(M))
  nM <- length(xM)
  # compute local cumulative products
  z <- .C("locxprod",
         ntest = as.integer(nM),
         xtest = as.double(xM),
         ytest = as.double(yM),
         ndata = as.integer(npts),
         xdata = as.double(xord),
         ydata = as.double(yord),
         vdata = as.double(vord),
         nr = as.integer(nr),
         rmax = as.double(rmax),
         ans = as.double(numeric(nM * nr)))
  loccumprod <- matrix(z$ans, nrow=nr, ncol=nM)
  # border correction
  ok <- outer(r, bM, "<=")
  denom <- .rowSums(ok, nr, nM)
  loccumprod[!ok] <- 0
  numer <- .rowSums(loccumprod, nr, nM)
  # pack up
  Fdf <- data.frame(r=r, theo = 1 - exp(- lmin * pi * r^2))
  desc <- c("distance argument r", "theoretical Poisson %s")
  theo.denom <- rep.int(npts, nr)
  FX <- ratfv(Fdf, NULL, theo.denom,
              "r",
              quote(F[inhom](r)),
              "theo", NULL, c(0,rmax),
              c("r","{%s[%s]^{pois}}(r)"),
              desc,
              fname=c("F", "inhom"),
              ratio=ratio)
  FX <- bind.ratfv(FX,
                  data.frame(bord=denom-numer), denom,
                  "{hat(%s)[%s]^{bord}}(r)",
                  "border estimate of %s",
                  "bord",
                  ratio=ratio)
  # 
  formula(FX) <- . ~ r
  fvnames(FX, ".") <- c("bord", "theo")
  unitname(FX) <- unitname(X)
  if(ratio)
    FX <- conform.ratfv(FX)
  if(danger)
    attr(FX, "dangerous") <- dangerous
  return(FX)
}

Jinhom <- function(X, lambda=NULL, lmin=NULL,
                   ...,
                   sigma=NULL, varcov=NULL,
                   r=NULL, breaks=NULL, update = TRUE) {
  if(missing(update) & (is.ppm(lambda) || is.kppm(lambda) || is.dppm(lambda)))
    warn.once(key="Jinhom.update",
              "The behaviour of Jinhom when lambda is a ppm object",
              "has changed (in spatstat 1.37-0 and later).",
              "See help(Jinhom)")
        
  GX <- Ginhom(X, lambda=lambda, lmin=lmin, ...,
               sigma=sigma, varcov=varcov, r=r, breaks=breaks, ratio=FALSE, update=update)
  r <- GX$r
  FX <- Finhom(X, lambda=lambda, lmin=lmin, ...,
               sigma=sigma, varcov=varcov, r=r, ratio=FALSE, update=update)
  JX <- eval.fv((1-GX)/(1-FX))
  # relabel the fv object
  JX <- rebadge.fv(JX, quote(J[inhom](r)), c("J","inhom"),
                  names(JX), new.labl=attr(GX, "labl"))
  # tack on extra info
  attr(JX, "G") <- GX
  attr(JX, "F") <- FX
  attr(JX, "dangerous") <- attr(GX, "dangerous")
  return(JX)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Jmulti.R"
#	Jmulti.S
#
#	Usual invocations to compute multitype J function(s)
#	if F and G are not required 
#
#	$Revision: 4.39 $	$Date: 2014/10/24 00:22:30 $
#
#
#
"Jcross" <-
function(X, i, j, eps=NULL, r=NULL, breaks=NULL, ..., correction=NULL) {
#
#       multitype J function J_{ij}(r)
#  
#	X:		point pattern (an object of class 'ppp')
#       i, j:           types for which J_{i,j}(r) is calculated  
#	eps:		raster grid mesh size for distance transform
#				(unless specified by X$window)
#       r:              (optional) values of argument r  
#	breaks:		(optional) breakpoints for argument r
#
  X <- as.ppp(X)
  if(!is.marked(X))
    stop(paste("point pattern has no", sQuote("marks")))
  stopifnot(is.multitype(X))
#
  marx <- marks(X, dfok=FALSE)
  if(missing(i)) i <- levels(marx)[1]
  if(missing(j)) j <- levels(marx)[2]
#
  I <- (marx == i)
  if(sum(I) == 0)
    stop(paste("No points have mark = ", i))
#        
  if(i == j)
    result <- Jest(X[I], eps=eps, r=r, breaks=breaks, correction=correction)
  else {
    J <- (marx == j)
    result <- Jmulti(X, I, J,
                     eps=eps, r=r, breaks=breaks, disjoint=TRUE,
                     correction=correction)
  }
  iname <- make.parseable(paste(i))
  jname <- make.parseable(paste(j))
  result <-
    rebadge.fv(result,
               substitute(J[i,j](r),
                          list(i=iname,j=jname)),
               c("J", paste0("list(", iname, ",", jname, ")")),
               new.yexp=substitute(J[list(i,j)](r),
                                      list(i=iname,j=jname)))
  return(result)
}

"Jdot" <-
function(X, i, eps=NULL, r=NULL, breaks=NULL, ..., correction=NULL) {
#  
#    multitype J function J_{i\dot}(r)
#  
#	X:		point pattern (an object of class 'ppp')
#       i:              mark i for which we calculate J_{i\cdot}(r)  
#	eps:		raster grid mesh size for distance transform
#				(unless specified by X$window)
#       r:              (optional) values of argument r  
#	breaks:		(optional) breakpoints for argument r
#
  X <- as.ppp(X)
  if(!is.marked(X))
    stop(paste("point pattern has no", sQuote("marks")))
  stopifnot(is.multitype(X))
#
  marx <- marks(X, dfok=FALSE)
  if(missing(i)) i <- levels(marx)[1]
#  
  I <- (marx == i)
  if(sum(I) == 0)
    stop(paste("No points have mark = ", i))          
  J <- rep.int(TRUE, X$n)
#  
  result <- Jmulti(X, I, J,
                   eps=eps, r=r, breaks=breaks, disjoint=FALSE,
                   correction=correction)
  iname <- make.parseable(paste(i))
  result <-
    rebadge.fv(result,
               substitute(J[i ~ dot](r), list(i=iname)),
               c("J", paste(iname, "~ symbol(\"\\267\")")),
               new.yexp=substitute(J[i ~ symbol("\267")](r), list(i=iname)))
  return(result)
}

"Jmulti" <- 	
function(X, I, J, eps=NULL, r=NULL, breaks=NULL, ..., disjoint=NULL,
         correction=NULL) {
#  
#    multitype J function (generic engine)
#  
#	X		marked point pattern (of class ppp)
#	
#	I,J		logical vectors of length equal to the number of points
#			and identifying the two subsets of points to be
#			compared.
#  
#	eps:		raster grid mesh size for distance transform
#				(unless specified by X$window)
#  
#       r:              (optional) values of argument r  
#	breaks:		(optional) breakpoints for argument r
#  
#
  X <- as.ppp(X)
  W<- X$window
  rmaxdefault <- rmax.rule("J", W)
  brks <- handle.r.b.args(r, breaks, W, rmaxdefault=rmaxdefault)$val
  I <- ppsubset(X, I)
  J <- ppsubset(X, J)
  if(is.null(I) || is.null(J))
    stop("I and J must be valid subset indices")
  FJ <- Fest(X[J], eps, breaks=brks, correction=correction)
  GIJ <- Gmulti(X, I, J, breaks=brks, disjoint=disjoint, correction=correction)
  rvals <- FJ$r
  Fnames <- names(FJ)
  Gnames <- names(GIJ)
  bothnames <- Fnames[Fnames %in% Gnames]
  # initialise fv object
  alim <- attr(FJ, "alim")
  fname <- c("J", "list(I,J)")
  Z <- fv(data.frame(r=rvals, theo=1),
          "r", quote(J[I,J](r)), "theo",
          . ~ r, alim,
          c("r", makefvlabel(NULL, NULL, fname, "pois")),
          c("distance argument r", "theoretical Poisson %s"),
          fname=fname,
          yexp=quote(J[list(I,J)](r)))
  # add pieces manually
  ratio <- function(a, b) {
    result <- a/b
    result[ b == 0 ] <- NA
    result
  }
  if("raw" %in% bothnames) {
    Jun <- ratio(1-GIJ$raw, 1-FJ$raw)
    Z <- bind.fv(Z, data.frame(un=Jun),
                 makefvlabel(NULL, "hat", fname, "un"),
                 "uncorrected estimate of %s", "un")
  }
  if("rs" %in% bothnames) {
    Jrs <- ratio(1-GIJ$rs, 1-FJ$rs)
    Z <- bind.fv(Z, data.frame(rs=Jrs),
                 makefvlabel(NULL, "hat", fname, "rs"),
                 "border corrected estimate of %s", "rs")
  }
  if("han" %in% Gnames && "cs" %in% Fnames) {
    Jhan <- ratio(1-GIJ$han, 1-FJ$cs)
    Z <- bind.fv(Z, data.frame(han=Jhan),
                 makefvlabel(NULL, "hat", fname, "han"),
                 "Hanisch-style estimate of %s", "han")
  }
  if("km" %in% bothnames) {
    Jkm <- ratio(1-GIJ$km, 1-FJ$km)
    Z <- bind.fv(Z, data.frame(km=Jkm),
                 makefvlabel(NULL, "hat", fname, "km"),
                 "Kaplan-Meier estimate of %s", "km")
    if("hazard" %in% names(GIJ) && "hazard" %in% names(FJ)) {
      Jhaz <- GIJ$hazard - FJ$hazard
      Z <- bind.fv(Z, data.frame(hazard=Jhaz), "hazard(r)",
                   "Kaplan-Meier estimate of derivative of log(%s)")
    } 
  }
# set default plotting values and order
  nama <- names(Z)
  fvnames(Z, ".") <- rev(nama[!(nama %in% c("r", "hazard"))])
# add other info
  attr(Z, "G") <- GIJ
  attr(Z, "F") <- FJ
  unitname(Z) <- unitname(X)
  return(Z)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Kcom.R"
#
#  Kcom.R
#
#   model compensated K-function
#
# $Revision: 1.12 $ $Date: 2014/11/10 08:27:27 $
#

Kcom <- local({

  Kcom <- function(object, r=NULL, breaks=NULL, ..., 
                   correction=c("border", "isotropic", "translate"),
                   conditional=!is.poisson(object),
                   restrict=FALSE,
                   model=NULL, 
                   trend=~1, interaction=Poisson(), rbord=reach(interaction),
                   compute.var=TRUE,
                   truecoef=NULL, hi.res=NULL) {
  if(inherits(object, "ppm")) {
    fit <- object
  } else if(is.ppp(object) || inherits(object, "quad")) {
    if(is.ppp(object)) object <- quadscheme(object, ...)
    if(!is.null(model)) {
      fit <- update(model, Q=object, forcefit=TRUE)
    } else {
      fit <- ppm(object, trend=trend, interaction=interaction, rbord=rbord,
                 forcefit=TRUE)
    }
  } else 
    stop("object should be a fitted point process model or a point pattern")
  
  if(missing(conditional) || is.null(conditional))
    conditional <- !is.poisson(fit)

#  rfixed <- !is.null(r) || !is.null(breaks)
  
  # Extract data and window
  Q <- quad.ppm(fit, drop=FALSE)
  X <- data.ppm(fit)
  Win <- X$window

  # selection of edge corrections
  correction.given <- !missing(correction) && !is.null(correction)
  correction <- pickoption("correction", correction,
                           c(none="none",
                             border="border",
                             isotropic="isotropic",
                             Ripley="isotropic",
                             ripley="isotropic",
                             trans="translation",
                             translate="translation",
                             translation="translation",
                             best="best"),
                           multi=TRUE)
  correction <- implemented.for.K(correction, Win$type, correction.given)

  opt <- list(bord = any(correction == "border"),
              tran = any(correction == "translation"),
              ripl = any(correction == "isotropic"))
  if(sum(unlist(opt)) == 0)
    stop("No corrections selected")
  
  # edge correction algorithm
  algo <- if(!conditional) "classical" else
          if(restrict) "restricted" else "reweighted"

  # conditioning on border region?
  if(!conditional) {
    Wfree <- Win
  } else {
    rbord <- fit$rbord
    Wfree <- erosion(Win, rbord)
    if(restrict) {
      retain <- inside.owin(union.quad(Q), , Wfree)
      # Throw away boundary data
      Q <- Q[Wfree]
      X <- X[Wfree]
      Win <- Wfree
    }
  }
  
  # Extract quadrature info
  U <- union.quad(Q)
  Z <- is.data(Q) # indicator data/dummy
  E <- equalsfun.quad(Q)
  WQ <- w.quad(Q)  # quadrature weights

  # quadrature points used 
  USED <- if(algo == "reweighted") (bdist.points(U) > rbord) else rep.int(TRUE, U$n)

  # basic statistics
  npts <- npoints(X)
  areaW <- area(Win)
  lambda <- npts/areaW
  lambda2 <- npts * (npts - 1)/(areaW^2)

  # adjustments to account for restricted domain of pseudolikelihood
  if(algo == "reweighted") {
    npts.used <- sum(Z & USED)
    area.used <- sum(WQ[USED])
    lambda.used <- npts.used/area.used
    lambda2.used <- npts.used * (npts.used - 1)/(area.used^2)
  } else {
    npts.used <- npts
    area.used <- areaW
    lambda.used <- lambda
    lambda2.used <- lambda2
  }
  
  # 'r' values
  rmaxdefault <- rmax.rule("K", if(restrict) Wfree else Win, npts/areaW)
  breaks <- handle.r.b.args(r, breaks, Wfree, rmaxdefault=rmaxdefault)
  r <- breaks$r
#  nr <- length(r)
  rmax <- breaks$max

  
  # recommended range of r values
  alim <- c(0, min(rmax, rmaxdefault))
        
  # this will be the output data frame
  K <- data.frame(r=r, pois=pi * r^2)
  desc <- c("distance argument r", "expected %s for CSR")
  K <- fv(K, "r", substitute(K(r), NULL),
            "pois", , alim, c("r","%s[pois](r)"), desc, fname="K")

  ############### start computing ##################

  # residuals
  resid <- residuals(fit, type="raw",drop=FALSE,
                    new.coef=truecoef, quad=hi.res)
  resval  <- with(resid, "increment")
  rescts  <- with(resid, "continuous")
  if(restrict) {
    # keep only data inside Wfree
    resval <- resval[retain]
    rescts <- rescts[retain]
  }
  
  # close pairs of points
  # (quadrature point to data point)
  clos <- crosspairs(U, X, rmax)
  dIJ <- clos$d
  I   <- clos$i
  J   <- clos$j
  UI <- U[I]
  XJ <- X[J]
  EIJ <- E(I, J) # TRUE if points are identical, U[I[k]] == X[J[k]] 
  ZI <- Z[I]     # TRUE if U[I[k]] is a data point
  DD <- ZI & !EIJ  # TRUE for pairs of distinct data points only
#  nDD <- sum(DD)

  # determine whether a quadrature point will be used in integral
  okI <- USED[I]
  
  if(spatstat.options("Kcom.remove.zeroes"))
    okI <- okI & !EIJ
  
  # residual weights
#  wIJ <- ifelseXY(EIJ, rescts[I], resval[I])
  # absolute weight for continuous integrals
  wc   <- -rescts
  wcIJ <- -rescts[I]

  ####################################################
  
  if(opt$bord) {
    # border method
    # Compute distances to boundary
    # (in restricted case, the window of U has been adjusted)
    b <- bdist.points(U)
    bI <- b[I]
    # reduced sample for K(r) of data only
    RSX <- Kount(dIJ[DD & okI], bI[DD & okI], b[Z & USED], breaks)
#    Kb <- RSX$numerator/(lambda.used * RSX$denom.count)
    Kb <- RSX$numerator/(lambda * RSX$denom.count)
    K <- bind.fv(K, data.frame(border=Kb), "hat(%s)[bord](r)",
                 nzpaste(algo,
                         "border-corrected nonparametric estimate of %s"),
                 "border")
    # reduced sample for adjustment integral
    RSD <- Kwtsum(dIJ[okI], bI[okI], wcIJ[okI],
                  b[Z & USED], rep.int(1, npts.used), breaks)
#    lambdaU <- (npts.used + 1)/area.used
    lambdaU <- (npts + 1)/areaW
    Kb <- RSD$numerator/((RSD$denominator + 1) * lambdaU)

    K <- bind.fv(K, data.frame(bcom=Kb), "bold(C)~hat(%s)[bord](r)",
                 nzpaste("model compensator of",
                         algo, "border-corrected %s"),
                 "border")
  }
  if(opt$tran) {
    # translation correction
    edgewt <- switch(algo,
                     classical  = edge.Trans(UI, XJ, paired=TRUE),
                     restricted = edge.Trans(UI, XJ, paired=TRUE),
                     reweighted = edge.Trans.modif(UI, XJ, Win, Wfree,
                       paired=TRUE))
    wh   <- whist(dIJ[okI], breaks$val, (edgewt * wcIJ)[okI])
    whDD <- whist(dIJ[DD & okI], breaks$val, edgewt[DD & okI])    
    Ktrans <- cumsum(whDD)/(lambda2 * area.used)
    Ktrans[r >= rmax] <- NA
    K <- bind.fv(K, data.frame(trans=Ktrans), "hat(%s)[trans](r)",
                 nzpaste(algo,
                         "translation-corrected nonparametric estimate of %s"),
                 "trans")
#    lambda2U <- (npts.used + 1) * npts.used/(area.used^2)
    lambda2U <- (npts + 1) * npts/(areaW^2)
    Ktrans <- cumsum(wh)/(lambda2U * area.used)
    Ktrans[r >= rmax] <- NA
    K <- bind.fv(K, data.frame(tcom=Ktrans), "bold(C)~hat(%s)[trans](r)",
                 nzpaste("model compensator of",
                         algo,
                         "translation-corrected %s"),
                 "trans")
  }
  if(opt$ripl) {
    # Ripley isotropic correction
    edgewt <- edge.Ripley(UI, matrix(dIJ, ncol=1))
    wh   <- whist(dIJ[okI],     breaks$val, (edgewt * wcIJ)[okI])
    whDD <- whist(dIJ[DD & okI], breaks$val, edgewt[DD & okI])    
#    Kiso <- cumsum(whDD)/(lambda2.used * area.used)
    Kiso <- cumsum(whDD)/(lambda2 * area.used)
    Kiso[r >= rmax] <- NA
    K <- bind.fv(K, data.frame(iso=Kiso), "hat(%s)[iso](r)",
                 nzpaste(algo,
                         "isotropic-corrected nonparametric estimate of %s"),
                 "iso")
#    lambda2U <- (npts.used + 1) * npts.used/(area.used^2)
    lambda2U <- (npts + 1) * npts/(areaW^2)    
    Kiso <- cumsum(wh)/(lambda2U * area.used)
    Kiso[r >= rmax] <- NA
    K <- bind.fv(K, data.frame(icom=Kiso), "bold(C)~hat(%s)[iso](r)",
                 nzpaste("model compensator of",
                         algo, "isotropic-corrected %s"),
                 "iso")
    #
    if(compute.var) {
      savedotnames <- fvnames(K, ".")
      # compute contribution to compensator from each quadrature point
      dOK <- dIJ[okI]
      eOK <- edgewt[okI]
      iOK <- I[okI]
      denom <- lambda2U * area.used
      variso <- varsumiso <- 0 * Kiso
      for(i in sort(unique(iOK))) {
        relevant <- (iOK == i)
        tincrem <- whist(dOK[relevant], breaks$val, eOK[relevant])
        localterm <- cumsum(tincrem)/denom
        variso <- variso + wc[i] * localterm^2
        if(Z[i])
          varsumiso <- varsumiso + localterm^2
      }
      sdiso <- sqrt(variso)
      K <- bind.fv(K, data.frame(ivar=variso,
                                 isd =sdiso,
                                 ihi = 2*sdiso,
                                 ilo = -2*sdiso,
                                 ivarsum=varsumiso),
                   c("bold(C)^2~hat(%s)[iso](r)",
                     "sqrt(bold(C)^2~hat(%s)[iso](r))",
                     "bold(R)~hat(%s)[hi](r)",
                     "bold(R)~hat(%s)[lo](r)",
                     "hat(C)^2~hat(%s)[iso](r)"),
                   c("Poincare variance of isotropic-corrected %s",
                     "sqrt(Poincare variance)  of isotropic-corrected %s",
                     "upper critical band for isotropic-corrected %s",
                     "lower critical band for isotropic-corrected %s",
                     "data estimate of Poincare variance of %s"),
                   "iso")
      # fvnames(K, ".") <- c(savedotnames, "isd")
      fvnames(K, ".") <- savedotnames
    }
  }

  # default is to display all corrections
  formula(K) <- . ~ r
  unitname(K) <- unitname(X)
  # secret tag used by 'Kres'
  attr(K, "maker") <- "Kcom"
  return(K)
}

# `reweighted' translation edge correction
edge.Trans.modif <- function(X, Y=X, WX=X$window, WY=Y$window,
                             exact=FALSE, paired=FALSE,
                             trim=spatstat.options("maxedgewt")) {

  # computes edge correction factor
  #  f = area(WY)/area(intersect.owin(WY, shift(WX, X[i] - Y[j])))
  
  X <- as.ppp(X, WX)

  W <- X$window
  x <- X$x
  y <- X$y

  Y <- as.ppp(Y, WY)
  xx <- Y$x
  yy <- Y$y

  nX <- npoints(X)
  nY <- npoints(Y)
  if(paired && (nX != nY))
    stop("X and Y should have equal length when paired=TRUE")
  
  # For irregular polygons, exact evaluation is very slow;
  # so use pixel approximation, unless exact=TRUE
  if(!exact) {
    if(WX$type == "polygonal")
      WX <- as.mask(WX)
    if(WY$type == "polygonal")
      WY <- as.mask(WX)
  }

  typeX <- WX$type
  typeY <- WY$type

  if(typeX == "rectangle" && typeY == "rectangle") {
    # Fast code for this case
    if(!paired) {
      DX <- abs(outer(x,xx,"-"))
      DY <- abs(outer(y,yy,"-"))
    } else {
      DX <- abs(xx - x)
      DY <- abs(yy - y)
    }
    A <- WX$xrange
    B <- WX$yrange
    a <- WY$xrange 
    b <- WY$yrange
    # compute width and height of intersection
    wide  <- pmin.int(a[2], A[2]+DX) - pmax(a[1], A[1]+DX)
    high  <- pmin.int(b[2], B[2]+DY) - pmax(b[1], B[1]+DY)
    # edge correction weight
    weight <- diff(a) * diff(b) / (wide * high)
    if(!paired)
      weight <- matrix(weight, nrow=X$n, ncol=Y$n)
  } else if(typeX %in% c("rectangle", "polygonal")
            && typeY %in% c("rectangle", "polygonal")) {
    # This code is SLOW
    WX <- as.polygonal(WX)
    WY <- as.polygonal(WY)
    a <- area(W)
    if(!paired) {
      weight <- matrix(, nrow=nX, ncol=nY)
      if(nX > 0 && nY > 0) {
        for(i in seq_len(nX)) {
          X.i <- c(x[i], y[i])
          for(j in seq_len(nY)) {
            shiftvector <- X.i - c(xx[j],yy[j])
            WXshift <- shift(WX, shiftvector)
            b <- overlap.owin(WY, WXshift)
            weight[i,j] <- a/b
          }
        }
      }
    } else {
      nX <- npoints(X)
      weight <- numeric(nX)
      if(nX > 0) {
        for(i in seq_len(nX)) {
          shiftvector <- c(x[i],y[i]) - c(xx[i],yy[i])
          WXshift <- shift(WX, shiftvector)
          b <- overlap.owin(WY, WXshift)
          weight[i] <- a/b
        }
      }
    }
  } else {
    WX <- as.mask(WX)
    WY <- as.mask(WY)
    # make difference vectors
    if(!paired) {
      DX <- outer(x,xx,"-")
      DY <- outer(y,yy,"-")
    } else {
      DX <- x - xx
      DY <- y - yy
    }
    # compute set cross-covariance
    g <- setcov(WY,WX)
    # evaluate set cross-covariance at these vectors
    gvalues <- lookup.im(g, as.vector(DX), as.vector(DY),
                         naok=TRUE, strict=FALSE)
    weight <- area(WY)/gvalues
  }

  # clip high values
  if(length(weight) > 0)
    weight <- pmin.int(weight, trim)
  if(!paired) 
    weight <- matrix(weight, nrow=X$n, ncol=Y$n)
  return(weight)
}

Kcom
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Kest.R"
#
#	Kest.R		Estimation of K function
#
#	$Revision: 5.106 $	$Date: 2014/11/10 10:35:35 $
#
#
# -------- functions ----------------------------------------
#	Kest()		compute estimate of K
#                       using various edge corrections
#
#
# -------- standard arguments ------------------------------	
#	X		point pattern (of class 'ppp')
#
#	r		distance values at which to compute K	
#
# -------- standard output ------------------------------
#      A data frame (class "fv") with columns named
#
#	r:		same as input
#
#	trans:		K function estimated by translation correction
#
#	iso:		K function estimated by Ripley isotropic correction
#
#	theo:		K function for Poisson ( = pi * r ^2 )
#
#	border:		K function estimated by border method
#			using standard formula (denominator = count of points)
#
#       bord.modif:	K function estimated by border method
#			using modified formula 
#			(denominator = area of eroded window
#
# ------------------------------------------------------------------------

"Lest" <- function(X, ...) {
  K <- Kest(X, ...)
  L <- eval.fv(sqrt(K/pi))
  # handle variance estimates
  if(any(varcols <- colnames(K) %in% c("rip", "ls"))) {
    r <- with(L, .x)
    L[,varcols] <- as.data.frame(K)[,varcols]/(2 * pi * r)^2
    # fix 0/0
    n <- npoints(X)
    A <- area(Window(X))
    if(any(colnames(K) == "rip"))
      L[r == 0, "rip"] <- (2 * A/(n-1)^2)/(4 * pi)
    if(any(colnames(K) == "ls"))
      L[r == 0, "ls"]  <- (2 * A/(n * (n-1)))/(4 * pi)
  }
  # relabel the fv object
  L <- rebadge.fv(L, quote(L(r)), "L", names(K), new.labl=attr(K, "labl"))
  #
  return(L)  
}

"Kest"<-
function(X, ..., r=NULL, breaks=NULL, 
         correction=c("border", "isotropic", "Ripley", "translate"),
         nlarge=3000, domain=NULL, var.approx=FALSE,
         ratio=FALSE)
{
  verifyclass(X, "ppp")
  nlarge.given <- !missing(nlarge) && !is.null(nlarge)
  rfixed <- !is.null(r) || !is.null(breaks)
  npts <- npoints(X)
  W <- X$window
  areaW <- area(W)
  lambda <- npts/areaW
  lambda2 <- (npts * (npts - 1))/(areaW^2)

  if(!is.null(domain)) {
    # estimate based on contributions from a subdomain
    domain <- as.owin(domain)
    if(!is.subset.owin(domain, W))
      stop(paste(dQuote("domain"),
                 "is not a subset of the window of X"))
    # trick Kdot() into doing it
    indom <- factor(inside.owin(X$x, X$y, domain), levels=c(FALSE,TRUE))
    Kd <- Kdot(X %mark% indom, i="TRUE",
               r=r, breaks=breaks, correction=correction,
               ratio=ratio)
    # relabel and exit
    Kd <- rebadge.fv(Kd, quote(K(r)), "K")
    return(Kd)
  }

  rmaxdefault <- rmax.rule("K", W, lambda)        
  breaks <- handle.r.b.args(r, breaks, W, rmaxdefault=rmaxdefault)
  r <- breaks$r
  rmax <- breaks$max

  # choose correction(s)
  correction.given <- !missing(correction) && !is.null(correction)
  if(is.null(correction))
    correction <- c("border", "isotropic", "Ripley", "translate")
  correction <- pickoption("correction", correction,
                           c(none="none",
                             border="border",
                             "bord.modif"="bord.modif",
                             isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             rigid="rigid",
                             good="good",
                             best="best"),
                           multi=TRUE)
  best.wanted <- ("best" %in% correction)
  # replace 'good' by the optimal choice for this size of dataset
  if("good" %in% correction)
    correction[correction == "good"] <- good.correction.K(X)
  # retain only corrections that are implemented for the window
  correction <- implemented.for.K(correction, W$type, correction.given)
  
  # recommended range of r values
  alim <- c(0, min(rmax, rmaxdefault))

  ###########################################
  # Efficient code for border correction and no correction
  # Usable only if r values are evenly spaced from 0 to rmax
  # Invoked automatically if number of points is large

  can.do.fast <- breaks$even
  large.n    <- (npts >= nlarge)
#  demand.best <- correction.given && best.wanted
  large.n.trigger <- large.n && !correction.given
  fastcorrections <- c("border", "bord.modif", "none")
  fastdefault     <- "border"
  correction.fast   <- all(correction %in% fastcorrections)
  will.do.fast <- can.do.fast && (correction.fast || large.n.trigger)
  asked <- correction.fast || (nlarge.given && large.n.trigger)
  if(asked && !can.do.fast)
    warning("r values not evenly spaced - cannot use efficient code")
  if(will.do.fast) {
    # determine correction(s)
    ok <- correction %in% fastcorrections
    correction <- if(any(ok)) correction[ok] else fastdefault
    bord <- any(correction %in% c("border", "bord.modif"))
    none <- any(correction =="none")
    if(!all(ok)) {
      # some corrections were overridden; notify user
      corx <- c(if(bord) "border correction estimate" else NULL,
                if(none) "uncorrected estimate" else NULL)
      corx <- paste(corx, collapse=" and ")
      message(paste("number of data points exceeds",
                    nlarge, "- computing", corx , "only"))
    }
    # restrict r values to recommended range, unless specifically requested
    if(!rfixed) 
      r <- seq(from=0, to=alim[2], length.out=length(r))
    if(bord)
      Kb <- Kborder.engine(X, max(r), length(r), correction, ratio=ratio)
    if(none)
      Kn <- Knone.engine(X, max(r), length(r), ratio=ratio)
    if(bord && none) 
      return(cbind.fv(Kb, Kn[, names(Kn) != "theo"]))
    if(bord) return(Kb)
    if(none) return(Kn) 
  }

  do.fast.rectangle <-
    can.do.fast && is.rectangle(W) &&
      spatstat.options("use.Krect") && !any(correction == "rigid")
  
  if(do.fast.rectangle) {
    ###########################################
    ## Fast code for rectangular window
    ###########################################
    K <-  Krect.engine(X, rmax, length(r), correction, ratio=ratio)
    attr(K, "alim") <- alim
  } else {
    ###########################################
    ## Slower code
    ###########################################

    ## this will be the output data frame
    Kdf <- data.frame(r=r, theo = pi * r^2)
    desc <- c("distance argument r", "theoretical Poisson %s")
    denom <- lambda2 * areaW
    K <- ratfv(Kdf, NULL, denom,
               "r", quote(K(r)),
               "theo", NULL, alim, c("r","%s[pois](r)"), desc, fname="K",
               ratio=ratio)
  
    ## identify all close pairs
    rmax <- max(r)
    close <- closepairs(X, rmax)
    DIJ <- close$d

    if(any(correction == "none")) {
      ## uncorrected! For demonstration purposes only!
      wh <- whist(DIJ, breaks$val)  # no weights
      numKun <- cumsum(wh)
      denKun <- lambda2 * areaW
      ## uncorrected estimate of K
      K <- bind.ratfv(K,
                      data.frame(un=numKun), denKun,
                      "hat(%s)[un](r)",
                      "uncorrected estimate of %s",
                      "un",
                      ratio=ratio)
    }
  
    if(any(correction == "border" | correction == "bord.modif")) {
      ## border method
      ## Compute distances to boundary
      b <- bdist.points(X)
      I <- close$i
      bI <- b[I]
      ## apply reduced sample algorithm
      RS <- Kount(DIJ, bI, b, breaks)
      if(any(correction == "bord.modif")) {
        ## modified border correction
        denom.area <- eroded.areas(W, r)
        numKbm <- RS$numerator
        denKbm <- lambda2 * denom.area
        K <- bind.ratfv(K,
                        data.frame(bord.modif=numKbm),
                        data.frame(bord.modif=denKbm),
                        "hat(%s)[bordm](r)",
                        "modified border-corrected estimate of %s",
                        "bord.modif",
                        ratio=ratio)
      }
      if(any(correction == "border")) {
        numKb <- RS$numerator
        denKb <- lambda * RS$denom.count
        K <- bind.ratfv(K,
                        data.frame(border=numKb), 
                        data.frame(border=denKb), 
                        "hat(%s)[bord](r)",
                        "border-corrected estimate of %s",
                        "border",
                        ratio=ratio)
      }
    }

    if(any(correction == "translate")) {
      ## Ohser-Stoyan translation correction
      edgewt <- edge.Trans(dx=close$dx, dy=close$dy, W=W, paired=TRUE)
      wh <- whist(DIJ, breaks$val, edgewt)
      numKtrans <- cumsum(wh)
      denKtrans <- lambda2 * areaW
      h <- diameter(as.rectangle(W))/2
      numKtrans[r >= h] <- NA
      K <- bind.ratfv(K,
                      data.frame(trans=numKtrans),
                      denKtrans,
                      "hat(%s)[trans](r)",
                      "translation-corrected estimate of %s",
                      "trans",
                      ratio=ratio)
    }
    if(any(correction == "rigid")) {
      ## Ohser-Stoyan rigid motion correction
      CW <- rotmean(setcov(W))
      edgewt <- areaW/as.function(CW)(DIJ)
      wh <- whist(DIJ, breaks$val, edgewt)
      numKrigid <- cumsum(wh)
      denKrigid <- lambda2 * areaW
      h <- diameter(as.rectangle(W))
      numKrigid[r >= h] <- NA
      K <- bind.ratfv(K,
                      data.frame(rigid=numKrigid),
                      denKrigid,
                      "hat(%s)[rigid](r)",
                      "rigid motion-corrected estimate of %s",
                      "rigid",
                      ratio=ratio)
    }
    if(any(correction == "isotropic")) {
      ## Ripley isotropic correction
      XI <- ppp(close$xi, close$yi, window=W, check=FALSE)
      edgewt <- edge.Ripley(XI, matrix(DIJ, ncol=1))
      wh <- whist(DIJ, breaks$val, edgewt)
      numKiso <- cumsum(wh)
      denKiso <- lambda2 * areaW
      h <- diameter(W)/2
      numKiso[r >= h] <- NA
      K <- bind.ratfv(K,
                      data.frame(iso=numKiso),
                      denKiso,
                      "hat(%s)[iso](r)",
                      "Ripley isotropic correction estimate of %s",
                      "iso",
                      ratio=ratio)
    }
  }

  #############################
  ##  VARIANCE APPROXIMATION
  #############################

  if(var.approx) {
    ## Compute variance approximations
    A <- areaW
    P <- perimeter(W)
    n <- npts
    ## Ripley asymptotic approximation
    rip <- 2 * ((A/(n-1))^2) * (pi * r^2/A + 0.96 * P * r^3/A^2
                                + 0.13 * (n/A) * P * r^5/A^2)
    if(!ratio) {
      K <- bind.fv(K, data.frame(rip=rip),
                 "vR(r)", 
                 "Ripley approximation to var(%s) under CSR",
                 "iso")
    } else {
      den <- (n-1)^2
      ripnum <- den * rip
      ripden <- rep.int(den, length(rip))
      K <- bind.ratfv(K,
                      data.frame(rip=ripnum),
                      data.frame(rip=ripden),
                      "vR(r)", 
                      "Ripley approximation to var(%s) under CSR",
                      "iso")
    }
    if(W$type == "rectangle") {
      # Lotwick-Silverman
      a1r <- (0.21 * P * r^3 + 1.3 * r^4)/A^2
      a2r <- (0.24 * P * r^5 + 2.62 * r^6)/A^3
      # contains correction to typo on p52 of Diggle 2003
      # cf Lotwick & Silverman 1982 eq (5)
      br <- (pi * r^2/A) * (1 - pi * r^2/A) +
        (1.0716 * P * r^3 + 2.2375 * r^4)/A^2
      ls <- (A^2) * (2 * br - a1r + (n-2) * a2r)/(n*(n-1))
      # add column 
      if(!ratio) {
        K <- bind.fv(K, data.frame(ls=ls), "vLS(r)",
                     "Lotwick-Silverman approx to var(%s) under CSR",
                     "iso")
      } else {
        den <- n*(n-1)
        lsnum <- ls * den
        lsden <- rep.int(den, length(ls))
        K <- bind.ratfv(K,
                        data.frame(ls=lsnum),
                        data.frame(ls=lsden),
                        "vLS(r)",
                        "Lotwick-Silverman approx to var(%s) under CSR",
                        "iso")
      }
    }
  }

  ### FINISH OFF #####
  ## default plot will display all edge corrections
  formula(K) <- . ~ r
  nama <- rev(colnames(K))
  nama <- nama[!(nama %in% c("r", "rip", "ls"))]
  fvnames(K, ".") <- nama
  unitname(K) <- unitname(X)
  # copy to other components
  if(ratio)
    K <- conform.ratfv(K)

  return(K)
}

################################################################  
#############  SUPPORTING ALGORITHMS ###########################
################################################################  

Kount <- function(dIJ, bI, b, breaks) {
  #
  # "internal" routine to compute border-correction estimate of K or Kij
  #
  # dIJ:  vector containing pairwise distances for selected I,J pairs
  # bI:   corresponding vector of boundary distances for I
  # b:    vector of ALL distances to window boundary
  #
  # breaks : breakpts object
  #

  stopifnot(length(dIJ) == length(bI))
  
  # determine which distances d_{ij} were observed without censoring
  uncen <- (dIJ <= bI)
  # histogram of noncensored distances
  nco <- whist(dIJ[uncen], breaks$val)
  # histogram of censoring times for noncensored distances
  ncc <- whist(bI[uncen], breaks$val)
  # histogram of censoring times (yes, this is a different total size)
  cen <- whist(b, breaks$val)
  # count censoring times beyond rightmost breakpoint
  uppercen <- sum(b > max(breaks$val))
  # go
  RS <- reduced.sample(nco, cen, ncc, show=TRUE, uppercen=uppercen)
  # extract results
  numerator <- RS$numerator
  denom.count <- RS$denominator
  # check
  if(length(numerator) != breaks$ncells)
    stop("internal error: length(numerator) != breaks$ncells")
  if(length(denom.count) != breaks$ncells)
    stop("internal error: length(denom.count) != breaks$ncells")
  
  return(list(numerator=numerator, denom.count=denom.count))
}

#### interface to C code for border method

Kborder.engine <- function(X, rmax, nr=100,
                           correction=c("border", "bord.modif"),
                           weights=NULL, ratio=FALSE) 
{
  verifyclass(X, "ppp")
  npts <- npoints(X)
  W <- as.owin(X)

  areaW <- area(W)
  lambda <- npts/areaW
  lambda2 <- (npts * (npts - 1))/(areaW^2)

  if(missing(rmax))
    rmax <- diameter(W)/4
  r <- seq(from=0, to=rmax, length.out=nr)

  # this will be the output data frame
  Kdf <- data.frame(r=r, theo= pi * r^2)
  desc <- c("distance argument r", "theoretical Poisson %s")
  Kfv <- fv(Kdf, "r", quote(K(r)),
          "theo", , c(0,rmax), c("r","%s[pois](r)"), desc, fname="K")

  if(ratio) {
    # save numerator and denominator
    denom <- lambda2 * areaW
    numK <- eval.fv(denom * Kfv)
    denK <- eval.fv(denom + Kfv * 0)
    attributes(numK) <- attributes(denK) <- attributes(Kfv)
    numK <- rebadge.fv(numK, tags="theo",
                       new.desc="numerator for theoretical Poisson %s")
    denK <- rebadge.fv(denK, tags="theo",
                       new.desc="denominator for theoretical Poisson %s")
  }
  
  ####### start computing ############
  # sort in ascending order of x coordinate
  orderX <- fave.order(X$x)
  Xsort <- X[orderX]
  x <- Xsort$x
  y <- Xsort$y
  
  # boundary distances
  b <- bdist.points(Xsort)

  # call the C code
  if(is.null(weights)) {
    # determine whether the numerator can be stored as an integer
    bigint <- .Machine$integer.max
    if(npts < sqrt(bigint)) {
      # yes - use faster integer arithmetic
      res <- .C("KborderI",
                nxy=as.integer(npts),
                x=as.double(x),
                y=as.double(y),
                b=as.double(b),
                nr=as.integer(nr),
                rmax=as.double(rmax),
                numer=as.integer(integer(nr)),
                denom=as.integer(integer(nr)))
    } else {
      # no - need double precision storage
      res <- .C("KborderD",
                nxy=as.integer(npts),
                x=as.double(x),
                y=as.double(y),
                b=as.double(b),
                nr=as.integer(nr),
                rmax=as.double(rmax),
                numer=as.double(numeric(nr)),
                denom=as.double(numeric(nr)))
    }
    if("bord.modif" %in% correction) {
      denom.area <- eroded.areas(W, r)
      numKbm <- res$numer
      denKbm <- lambda2 * denom.area
      bm <- numKbm/denKbm
      Kfv <- bind.fv(Kfv, data.frame(bord.modif=bm), "hat(%s)[bordm](r)",
                   "modified border-corrected estimate of %s",
                   "bord.modif")
      if(ratio) {
        # save numerator and denominator
        numK <- bind.fv(numK, data.frame(bord.modif=numKbm),
                        "hat(%s)[bordm](r)",
                        "numerator of modified border-corrected estimate of %s",
                        "bord.modif")
        denK <- bind.fv(denK, data.frame(bord.modif=denKbm),
                        "hat(%s)[bordm](r)",
                        "denominator of modified border-corrected estimate of %s",
                        "bord.modif")
      }
    }
    if("border" %in% correction) {
      numKb <- res$numer
      denKb <- lambda * res$denom
      bord <- numKb/denKb
      Kfv <- bind.fv(Kfv, data.frame(border=bord), "hat(%s)[bord](r)",
                   "border-corrected estimate of %s",
                   "border")
      if(ratio) {
        numK <- bind.fv(numK, data.frame(border=numKb),
                        "hat(%s)[bord](r)",
                        "numerator of border-corrected estimate of %s",
                        "border")
        denK <- bind.fv(denK, data.frame(border=denKb),
                        "hat(%s)[bord](r)",
                        "denominator of border-corrected estimate of %s",
                        "border")
      }
    }
  } else {
    # weighted version
    if(is.numeric(weights)) {
      if(length(weights) != X$n)
        stop("length of weights argument does not match number of points in X")
    } else {
      wim <- as.im(weights, W)
      weights <- wim[X, drop=FALSE]
      if(any(is.na(weights)))
        stop("domain of weights image does not contain all points of X")
    }
    weights.Xsort <- weights[orderX]
    res <- .C("Kwborder",
              nxy=as.integer(npts),
              x=as.double(x),
              y=as.double(y),
              w=as.double(weights.Xsort),
              b=as.double(b),
              nr=as.integer(nr),
              rmax=as.double(rmax),
              numer=as.double(numeric(nr)),
              denom=as.double(numeric(nr)))
    if("border" %in% correction) {
      bord <- res$numer/res$denom
      Kfv <- bind.fv(Kfv, data.frame(border=bord), "hat(%s)[bord](r)",
                     "border-corrected estimate of %s",
                     "border")
      if(ratio) {
        numK <- bind.fv(numK, data.frame(border=res$numer),
                        "hat(%s)[bord](r)",
                        "numerator of border-corrected estimate of %s",
                        "border")
        denK <- bind.fv(denK, data.frame(border=res$denom),
                        "hat(%s)[bord](r)",
                        "denominator of border-corrected estimate of %s",
                        "border")
      }
    }
    if("bord.modif" %in% correction) {
      numKbm <- res$numer
      denKbm <- eroded.areas(W, r)
      bm <- numKbm/denKbm
      Kfv <- bind.fv(Kfv, data.frame(bord.modif=bm), "hat(%s)[bordm](r)",
                     "modified border-corrected estimate of %s",
                     "bord.modif")
      if(ratio) {
        # save numerator and denominator
        numK <- bind.fv(numK, data.frame(bord.modif=numKbm),
                        "hat(%s)[bordm](r)",
                        "numerator of modified border-corrected estimate of %s",
                        "bord.modif")
        denK <- bind.fv(denK, data.frame(bord.modif=denKbm),
                        "hat(%s)[bordm](r)",
                        "denominator of modified border-corrected estimate of %s",
                        "bord.modif")
      }
    }
  }
  ##
  # default is to display them all
  formula(Kfv) <- . ~ r
  unitname(Kfv) <- unitname(X)
  if(ratio) {
    # finish off numerator and denominator
    formula(numK) <- formula(denK) <- . ~ r
    unitname(denK) <- unitname(numK) <- unitname(X)
    # tack on to result
    Kfv <- rat(Kfv, numK, denK, check=FALSE)
  }
  return(Kfv)
}

Knone.engine <- function(X, rmax, nr=100,
                         weights=NULL, ratio=FALSE) 
{
  verifyclass(X, "ppp")
  npts <- npoints(X)
  W <- as.owin(X)

  areaW <- area(W)
#  lambda <- npts/areaW
  lambda2 <- (npts * (npts - 1))/(areaW^2)
  denom <- lambda2 * areaW

  if(missing(rmax))
    rmax <- diameter(W)/4
  r <- seq(from=0, to=rmax, length.out=nr)

  # this will be the output data frame
  Kdf <- data.frame(r=r, theo= pi * r^2)
  desc <- c("distance argument r", "theoretical Poisson %s")
  Kfv <- fv(Kdf, "r", quote(K(r)),
          "theo", , c(0,rmax), c("r","%s[pois](r)"), desc, fname="K")

  if(ratio) {
    # save numerator and denominator
    numK <- eval.fv(denom * Kfv)
    denK <- eval.fv(denom + Kfv * 0)
    attributes(numK) <- attributes(denK) <- attributes(Kfv)
    numK <- rebadge.fv(numK, tags="theo",
                       new.desc="numerator for theoretical Poisson %s")
    denK <- rebadge.fv(denK, tags="theo",
                       new.desc="denominator for theoretical Poisson %s")
  }
  
  ####### start computing ############
  # sort in ascending order of x coordinate
  orderX <- fave.order(X$x)
  Xsort <- X[orderX]
  x <- Xsort$x
  y <- Xsort$y
  
  # call the C code
  if(is.null(weights)) {
    # determine whether the numerator can be stored as an integer
    bigint <- .Machine$integer.max
    if(npts < sqrt(bigint)) {
      # yes - use faster integer arithmetic
      res <- .C("KnoneI",
                nxy=as.integer(npts),
                x=as.double(x),
                y=as.double(y),
                nr=as.integer(nr),
                rmax=as.double(rmax),
                numer=as.integer(integer(nr)))
    } else {
      # no - need double precision storage
      res <- .C("KnoneD",
                nxy=as.integer(npts),
                x=as.double(x),
                y=as.double(y),
                nr=as.integer(nr),
                rmax=as.double(rmax),
                numer=as.double(numeric(nr)))
    }

    numKun <- res$numer
    denKun <- denom # = lambda2 * areaW
    Kun <- numKun/denKun
  } else {
    # weighted version
    if(is.numeric(weights)) {
      if(length(weights) != X$n)
        stop("length of weights argument does not match number of points in X")
    } else {
      wim <- as.im(weights, W)
      weights <- wim[X, drop=FALSE]
      if(any(is.na(weights)))
        stop("domain of weights image does not contain all points of X")
    }
    weights.Xsort <- weights[orderX]
    res <- .C("Kwnone",
              nxy=as.integer(npts),
              x=as.double(x),
              y=as.double(y),
              w=as.double(weights.Xsort),
              nr=as.integer(nr),
              rmax=as.double(rmax),
              numer=as.double(numeric(nr)))
    numKun <- res$numer
    denKun <- sum(weights)
    Kun <- numKun/denKun
  }

  # tack on to fv object
  Kfv <- bind.fv(Kfv, data.frame(un=Kun), "hat(%s)[un](r)",
                 "uncorrected estimate of %s",
                 "un")
  if(ratio) {
    numK <- bind.fv(numK, data.frame(un=numKun),
                    "hat(%s)[un](r)",
                    "numerator of uncorrected estimate of %s",
                    "un")
    denK <- bind.fv(denK, data.frame(un=denKun),
                    "hat(%s)[un](r)",
                    "denominator of uncorrected estimate of %s",
                    "un")
  }
  ##
  # default is to display them all
  formula(Kfv) <- . ~ r
  unitname(Kfv) <- unitname(X)
  if(ratio) {
    # finish off numerator and denominator
    formula(numK) <- formula(denK) <- . ~ r
    unitname(denK) <- unitname(numK) <- unitname(X)
    # tack on to result
    Kfv <- rat(Kfv, numK, denK, check=FALSE)
  }
  return(Kfv)
}

     

rmax.rule <- function(fun="K", W, lambda) {
  verifyclass(W, "owin")
  switch(fun,
         K = {
           # Ripley's Rule
           ripley <- min(diff(W$xrange), diff(W$yrange))/4
           # Count at most 1000 neighbours per point
           rlarge <- if(!missing(lambda)) sqrt(1000 /(pi * lambda)) else Inf
           rmax <- min(rlarge, ripley)
         },
         F = ,
         G = ,
         J = {
           # rule of thumb
           rdiam  <- diameter(as.rectangle(W))/2
           # Poisson process has F(rlarge) = 1 - 10^(-5)
           rlarge <-
             if(!missing(lambda)) sqrt(log(1e5)/(pi * lambda)) else Inf
           rmax <- min(rlarge, rdiam)
         },
         stop(paste("Unrecognised function type", sQuote(fun)))
         )
  return(rmax)
}
           
    
implemented.for.K <- function(correction, windowtype, explicit) {
  pixels <- (windowtype == "mask")
  if(any(correction == "best")) {
    # select best available correction
    correction <- if(!pixels) "isotropic" else "translate"
  } else {
    # available selection of edge corrections depends on window
    if(pixels) {
      iso <- (correction == "isotropic") 
      if(any(iso)) {
        whinge <- "Isotropic correction not implemented for binary masks"
        if(explicit) {
          if(all(iso)) stop(whinge) else warning(whinge)
        }
        correction <- correction[!iso]
      }
    }
  }
  return(correction)
}

good.correction.K <- function(X) {
  nX <- npoints(X)
  W <- as.owin(X)
  avail <- c("none",
             if(nX < 1e5) "border" else NULL,
             if(nX < 3000)"translate" else NULL,
             if(nX < 1000 && !is.mask(W)) "isotropic" else NULL)
  chosen <- rev(avail)[1]
  return(chosen)
}

Krect.engine <- function(X, rmax, nr=100,
                           correction,
                           weights=NULL, ratio=FALSE, fname="K") {
  verifyclass(X, "ppp")
  npts <- npoints(X)
  W <- as.owin(X)

  areaW <- area(W)
  width <- sidelengths(W)[1]
  height <- sidelengths(W)[2]
  lambda <- npts/areaW
  lambda2 <- (npts * (npts - 1))/(areaW^2)

  if(missing(rmax))
    rmax <- diameter(W)/4
  r <- seq(from=0, to=rmax, length.out=nr)

  if(weighted <- !is.null(weights)) {
    ## coerce weights to a vector
    if(is.numeric(weights)) {
      check.nvector(weights, npts)
    } else {
      wim <- as.im(weights, W)
      weights <- wim[X, drop=FALSE]
      if(any(is.na(weights)))
        stop("domain of weights image does not contain all points of X")
    }
  }

  # this will be the output data frame
  Kdf <- data.frame(r=r, theo= pi * r^2)
  desc <- c("distance argument r", "theoretical Poisson %s")
  denom <- if(weighted) areaW else (lambda2 * areaW)
  Kfv <- ratfv(Kdf, NULL, denom,
               "r", quote(K(r)),
               "theo", NULL, c(0,rmax),
               c("r", makefvlabel(NULL, NULL, fname, "pois")),
               desc, fname=fname,
               ratio=ratio)

  ####### prepare data ############

  if(!all(correction == "translate")) {
    ## Ensure rectangle has its bottom left corner at the origin
    if(W$xrange[1] != 0 || W$yrange[1] != 0) {
      X <- shift(X, origin="bottomleft")
      W <- as.owin(X)
    }
  }

  ## sort in ascending order of x coordinate
  orderX <- fave.order(X$x)
  x <- X$x[orderX]
  y <- X$y[orderX]
  if(weighted)
    wt <- weights[orderX]

  ## establish algorithm parameters
  doIso <- "isotropic" %in% correction 
  doTrans <- "translate" %in% correction
  doBord <- any(c("border", "bord.modif") %in% correction)
  doUnco <- "none" %in% correction
  trimedge <- spatstat.options("maxedgewt")

  ## allocate space for results
  ziso   <- numeric(if(doIso) nr else 1L)
  ztrans <- numeric(if(doTrans) nr else 1L)
  
  ## call the C code
  if(weighted) {
    ## weighted version
    zbnumer <- numeric(if(doBord) nr else 1L)
    zbdenom <- numeric(if(doBord) nr else 1L)
    zunco   <- numeric(if(doUnco) nr else 1L)
    res <- .C("KrectWtd",
              width=as.double(width),
              height=as.double(height),
              nxy=as.integer(npts),
              x=as.double(x),
              y=as.double(y),
              w=as.double(wt),
              nr=as.integer(nr),
              rmax=as.double(rmax),
              trimedge=as.double(trimedge),
              doIso=as.integer(doIso),
              doTrans=as.integer(doTrans),
              doBord=as.integer(doBord),
              doUnco=as.integer(doUnco),
              iso=as.double(ziso),
              trans=as.double(ztrans),
              bnumer=as.double(zbnumer),
              bdenom=as.double(zbdenom),
              unco=as.double(zunco))
  } else if(npts < sqrt(.Machine$integer.max)) {
    ## unweighted
    ## numerator of border correction can be stored as an integer
    ## use faster integer arithmetic
    zbnumer <- integer(if(doBord) nr else 1L)
    zbdenom <- integer(if(doBord) nr else 1L)
    zunco   <- integer(if(doUnco) nr else 1L)
    res <- .C("KrectInt",
              width=as.double(width),
              height=as.double(height),
              nxy=as.integer(npts),
              x=as.double(x),
              y=as.double(y),
              nr=as.integer(nr),
              rmax=as.double(rmax),
              trimedge=as.double(trimedge),
              doIso=as.integer(doIso),
              doTrans=as.integer(doTrans),
              doBord=as.integer(doBord),
              doUnco=as.integer(doUnco),
              iso=as.double(ziso),
              trans=as.double(ztrans),
              bnumer=as.integer(zbnumer),
              bdenom=as.integer(zbdenom),
              unco=as.integer(zunco))
  } else {
    ## unweighted
    ## need double precision storage
    zbnumer <- numeric(if(doBord) nr else 1L)
    zbdenom <- numeric(if(doBord) nr else 1L)
    zunco   <- numeric(if(doUnco) nr else 1L)
    res <- .C("KrectDbl",
              width=as.double(width),
              height=as.double(height),
              nxy=as.integer(npts),
              x=as.double(x),
              y=as.double(y),
              nr=as.integer(nr),
              rmax=as.double(rmax),
              trimedge=as.double(trimedge),
              doIso=as.integer(doIso),
              doTrans=as.integer(doTrans),
              doBord=as.integer(doBord),
              doUnco=as.integer(doUnco),
              iso=as.double(ziso),
              trans=as.double(ztrans),
              bnumer=as.double(zbnumer),
              bdenom=as.double(zbdenom),
              unco=as.double(zunco))
  }

  ## Process corrections in reverse order of priority

  ## Uncorrected estimate
  if("none" %in% correction) {
    numKun <- res$unco
    denKun <- if(weighted) areaW else (lambda2 * areaW)
    Kfv <- bind.ratfv(Kfv,
                      data.frame(un=numKun),
                      denKun,
                      makefvlabel(NULL, "hat", fname, "un"),
                      "uncorrected estimate of %s",
                      "un",
                      ratio=ratio)
  }
  
  ## Modified border correction
  if("bord.modif" %in% correction) {
    denom.area <- eroded.areas(W, r)
    numKbm <- res$bnumer
    denKbm <- if(weighted) denom.area else (lambda2 * denom.area)
    Kfv <- bind.ratfv(Kfv,
                      data.frame(bord.modif=numKbm),
                      denKbm,
                      makefvlabel(NULL, "hat", fname, "bordm"),
                      "modified border-corrected estimate of %s",
                      "bord.modif",
                      ratio=ratio)
  }
  ## Border correction
  if("border" %in% correction) {
    numKb <- res$bnumer
    denKb <- if(weighted) res$bdenom else lambda * res$bdenom
    Kfv <- bind.ratfv(Kfv,
                      data.frame(border=numKb),
                      denKb,
                      makefvlabel(NULL, "hat", fname, "bord"),
                      "border-corrected estimate of %s",
                      "border",
                      ratio=ratio)
  }
  
  ## translation correction
  if("translate" %in% correction) {
    numKtrans <- res$trans
    denKtrans <- if(weighted) areaW else (lambda2 * areaW)
    h <- diameter(as.rectangle(W))/2
    numKtrans[r >= h] <- NA
    Kfv <- bind.ratfv(Kfv,
                      data.frame(trans=numKtrans),
                      denKtrans,
                      makefvlabel(NULL, "hat", fname, "trans"),
                      "translation-corrected estimate of %s",
                      "trans",
                      ratio=ratio)
  }
  ## isotropic correction
  if("isotropic" %in% correction) {
    numKiso <- res$iso
    denKiso <- if(weighted) areaW else (lambda2 * areaW)
    h <- diameter(as.rectangle(W))/2
    numKiso[r >= h] <- NA
    Kfv <- bind.ratfv(Kfv,
                      data.frame(iso=numKiso),
                      denKiso,
                      makefvlabel(NULL, "hat", fname, "iso"),
                      "isotropic-corrected estimate of %s",
                      "iso",
                      ratio=ratio)
  }
  ##
  # default is to display them all
  formula(Kfv) <- . ~ r
  unitname(Kfv) <- unitname(X)
  if(ratio) 
    Kfv <- conform.ratfv(Kfv)
  return(Kfv)
}



#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Kinhom.R"
#
#	Kinhom.S	Estimation of K function for inhomogeneous patterns
#
#	$Revision: 1.84 $	$Date: 2014/11/10 08:29:05 $
#
#	Kinhom()	compute estimate of K_inhom
#
#
#       Reference:
#            Non- and semiparametric estimation of interaction
#	     in inhomogeneous point patterns
#            A.Baddeley, J.Moller, R.Waagepetersen
#            Statistica Neerlandica 54 (2000) 329--350.
#
# -------- functions ----------------------------------------
#	Kinhom()	compute estimate of K
#                       using various edge corrections
#
#       Kwtsum()         internal routine for border correction
#
# -------- standard arguments ------------------------------	
#	X		point pattern (of class 'ppp')
#
#	r		distance values at which to compute K	
#
#       lambda          vector of intensity values for points of X
#
# -------- standard output ------------------------------
#      A data frame (class "fv") with columns named
#
#	r:		same as input
#
#	trans:		K function estimated by translation correction
#
#	iso:		K function estimated by Ripley isotropic correction
#
#	theo:		K function for Poisson ( = pi * r ^2 )
#
#	border:		K function estimated by border method
#			(denominator = sum of weights of points)
#
#       bord.modif:	K function estimated by border method
#			(denominator = area of eroded window)
#
# ------------------------------------------------------------------------

"Linhom" <- function(...) {
  K <- Kinhom(...)
  L <- eval.fv(sqrt(pmax.int(K,0)/pi))
  # relabel the fv object
  L <- rebadge.fv(L, quote(L[inhom](r)), c("L", "inhom"),
                  names(K), new.labl=attr(K, "labl"))
  attr(L, "labl") <- attr(K, "labl")
  attr(L, "dangerous") <- attr(K, "dangerous")
  #
  return(L)  
}

"Kinhom"<-
  function (X, lambda=NULL, ..., r = NULL, breaks = NULL, 
            correction=c("border", "bord.modif", "isotropic", "translate"),
            renormalise=TRUE,
            normpower=1,
            update = TRUE,
            leaveoneout = TRUE,
            nlarge = 1000, 
            lambda2=NULL,
            reciplambda=NULL, reciplambda2=NULL,
            sigma=NULL, varcov=NULL)
{
    verifyclass(X, "ppp")
    nlarge.given <- !missing(nlarge)
    rfixed <- !missing(r) || !missing(breaks)
    miss.update <- missing(update)
    
    # determine basic parameters
    W <- X$window
    npts <- npoints(X)
    areaW <- area(W)
    diamW <- diameter(W)
    
    rmaxdefault <- rmax.rule("K", W, npts/areaW)
    breaks <- handle.r.b.args(r, breaks, W, rmaxdefault=rmaxdefault)
    r <- breaks$r
    rmax <- breaks$max

    # match corrections
    correction.given <- !missing(correction) && !is.null(correction)
    correction <- pickoption("correction", correction,
                             c(none="none",
                               border="border",
                               "bord.modif"="bord.modif",
                               isotropic="isotropic",
                               Ripley="isotropic",
                               trans="translate",
                               translate="translate",
                               translation="translate",
                               good="good",
                               best="best"),
                             multi=TRUE)

    best.wanted <- ("best" %in% correction)
    ## replace 'good' by the optimal choice for this size of dataset
    if("good" %in% correction)
      correction[correction == "good"] <- good.correction.K(X)
    ## retain only corrections that are implemented for the window
    correction <- implemented.for.K(correction, W$type, correction.given)

    ###########################################################
    # DETERMINE WEIGHTS AND VALIDATE
    #
    # The matrix 'lambda2' or 'reciplambda2' is sufficient information
    # unless we want the border correction.
    lambda2.given    <- !is.null(lambda2) || !is.null(reciplambda2)
    lambda2.suffices <- !any(correction %in% c("bord", "bord.modif"))
    
    ## Arguments that are 'dangerous' for envelope, if fixed
    dangerous <- c("lambda", "reciplambda", "lambda2", "reciplambda2")
    danger <- TRUE
    
    # Use matrix of weights if it was provided and if it is sufficient
    if(lambda2.suffices && lambda2.given) {
      if(!is.null(reciplambda2)) 
        check.nmatrix(reciplambda2, npts)
      else {
        check.nmatrix(lambda2, npts)
        reciplambda2 <- 1/lambda2
      }
      # renormalise
      if(renormalise) {
        check.1.real(normpower)
        stopifnot(normpower %in% 1:2)
        renorm.factor <- (areaW^2/sum(reciplambda2))^(normpower/2)
      } 
    } else {
      # Vector lambda or reciplambda is required
      if(missing(lambda) && is.null(reciplambda)) {
        # No intensity data provided
        danger <- FALSE
        # Estimate density by leave-one-out kernel smoothing
        lambda <- density(X, ..., sigma=sigma, varcov=varcov,
                            at="points", leaveoneout=leaveoneout)
        lambda <- as.numeric(lambda)
        reciplambda <- 1/lambda
      } else if(!is.null(reciplambda)) {
        # 1/lambda values provided
        if(is.im(reciplambda)) 
          reciplambda <- safelookup(reciplambda, X)
        else if(is.function(reciplambda))
          reciplambda <- reciplambda(X$x, X$y)
        else if(is.numeric(reciplambda) && is.vector(as.numeric(reciplambda)))
          check.nvector(reciplambda, npts)
        else stop(paste(sQuote("reciplambda"),
                        "should be a vector, a pixel image, or a function"))
      } else {
        # lambda values provided
        if(is.im(lambda)) 
          lambda <- safelookup(lambda, X)
        else if(is.ppm(lambda) || is.kppm(lambda) || is.dppm(lambda)) {
          model <- lambda
          if(!update) {
            ## just use intensity of fitted model
            lambda <- predict(lambda, locations=X, type="trend")
          } else {
            ## re-fit model to data X
            if(is.ppm(model)) {
              model <- update(model, Q=X)
              lambda <- fitted(model, dataonly=TRUE, leaveoneout=leaveoneout)
            } else if(is.kppm(model)) {
              model <- update(model, X=X)
              lambda <- fitted(model, dataonly=TRUE, leaveoneout=leaveoneout)
            } else {
              model <- update(model, X=X)
              lambda <- fitted(model, dataonly=TRUE)
            }
            danger <- FALSE
            if(miss.update) 
              warn.once(key="Kinhom.update",
                        "The behaviour of Kinhom when lambda is a ppm object",
                        "has changed (in spatstat 1.37-0 and later).",
                        "See help(Kinhom)")
          }
        } else if(is.function(lambda)) 
          lambda <- lambda(X$x, X$y)
        else if(is.numeric(lambda) && is.vector(as.numeric(lambda)))
          check.nvector(lambda, npts)
        else stop(paste(sQuote("lambda"),
                          "should be a vector, a pixel image, or a function"))
        # evaluate reciprocal
        reciplambda <- 1/lambda
      }
      # renormalise
      if(renormalise) {
        check.1.real(normpower)
        stopifnot(normpower %in% 1:2)
        renorm.factor <- (areaW/sum(reciplambda))^normpower
      } 
    }

    
    # recommended range of r values
    alim <- c(0, min(rmax, rmaxdefault))
        
  ###########################################
  # Efficient code for border correction and no correction
  # Usable only if r values are evenly spaced from 0 to rmax
  # Invoked automatically if number of points is large

    can.do.fast <- breaks$even && !lambda2.given
    large.n    <- (npts >= nlarge)
#    demand.best <- correction.given && best.wanted
    large.n.trigger <- large.n && !correction.given
    fastcorrections <- c("border", "bord.modif", "none")
    fastdefault <- "border"
    correction.fast  <- all(correction %in% fastcorrections)
    will.do.fast <- can.do.fast && (correction.fast || large.n.trigger)
    asked.fast <- (correction.given && correction.fast) ||
                  (nlarge.given && large.n.trigger)
    if(!can.do.fast && asked.fast) {
      whynot <-
        if(!(breaks$even)) "r values not evenly spaced" else
        if(!missing(lambda)) "matrix lambda2 was given" else NULL
      warning(paste("cannot use efficient code", whynot, sep="; "))
    }
    if(will.do.fast) {
      ## Compute Kinhom using fast algorithm(s)
      ## determine correction(s)
      ok <- correction %in% fastcorrections
      correction <- if(any(ok)) correction[ok] else fastdefault
      bord <- any(correction %in% c("border", "bord.modif"))
      none <- any(correction =="none")
      if(!all(ok)) {
        ## some corrections were overridden; notify user
        corx <- c(if(bord) "border correction estimate" else NULL,
                  if(none) "uncorrected estimate" else NULL)
        corx <- paste(corx, collapse=" and ")
        message(paste("number of data points exceeds",
                      nlarge, "- computing", corx , "only"))
      }
      ## restrict r values to recommended range, unless specifically requested
      if(!rfixed) 
        r <- seq(from=0, to=alim[2], length.out=length(r))
      ## border method
      if(bord) {
        Kb <- Kborder.engine(X, max(r), length(r), correction,
                             weights=reciplambda)
        if(renormalise) {
          ynames <- fvnames(Kb, "*")
          Kb[,ynames] <- renorm.factor * as.data.frame(Kb)[,ynames]
        }
        Kb <- tweak.fv.entry(Kb, "border", new.labl="{hat(%s)[%s]^{bord}} (r)")
        Kb <- tweak.fv.entry(Kb, "bord.modif", new.labl="{hat(%s)[%s]^{bordm}} (r)")
      }
      ## uncorrected
      if(none) {
        Kn <- Knone.engine(X, max(r), length(r), weights=reciplambda)
        if(renormalise) 
          Kn$un <- Kn$un * renorm.factor
        Kn <- tweak.fv.entry(Kn, "un", new.labl="{hat(%s)[%s]^{un}} (r)")
      }
      K <-
        if(bord && !none) Kb else
        if(!bord && none) Kn else 
      cbind.fv(Kb, Kn[, names(Kn) != "theo"])
      ## tweak labels
      K <- rebadge.fv(K, quote(K[inhom](r)), c("K", "inhom"))
      if(danger)
        attr(K, "dangerous") <- dangerous
      return(K)
    }

  ###########################################
  # Fast code for rectangular window
  ###########################################

  if(can.do.fast && is.rectangle(W) && spatstat.options("use.Krect")) {
    K <-  Krect.engine(X, rmax, length(r), correction,
                        weights=reciplambda, fname=c("K", "inhom"))
    if(renormalise) {
      allfun <- fvnames(K, "*")
      K[, allfun] <- renorm.factor * as.data.frame(K)[, allfun]
    }
    K <- rebadge.fv(K, quote(K[inhom](r)), c("K", "inhom"))
    attr(K, "alim") <- alim
    if(danger)
      attr(K, "dangerous") <- dangerous
    return(K)
  }
  
  ###########################################
  # Slower code
  ###########################################
        
        
    # this will be the output data frame
    K <- data.frame(r=r, theo= pi * r^2)
    desc <- c("distance argument r", "theoretical Poisson %s")
    K <- fv(K, "r", quote(K[inhom](r)),
            "theo", , alim, c("r","{%s[%s]^{pois}}(r)"), desc,
            fname=c("K", "inhom"))

    # identify all close pairs
    rmax <- max(r)
    close <- closepairs(X, rmax)
    dIJ <- close$d
    # compute weights for these pairs
    I <- close$i
    J <- close$j
    wI <- reciplambda[I]
    wIJ <- 
      if(!lambda2.given)
        reciplambda[I] * reciplambda[J]
      else 
        reciplambda2[cbind(I,J)]
    # 

    # compute edge corrected estimates
    if(any(correction == "border" | correction == "bord.modif")) {
      # border method
      # Compute distances to boundary
      b <- bdist.points(X)
      I <- close$i
      bI <- b[I]
      # apply reduced sample algorithm
      RS <- Kwtsum(dIJ, bI, wIJ, b, w=reciplambda, breaks)
      if(any(correction == "border")) {
        Kb <- RS$ratio
        if(renormalise) Kb <- Kb * renorm.factor
        K <- bind.fv(K, data.frame(border=Kb), "{hat(%s)[%s]^{bord}}(r)",
                     "border-corrected estimate of %s",
                     "border")
      }
      if(any(correction == "bord.modif")) {
        Kbm <- RS$numerator/eroded.areas(W, r)
        if(renormalise) Kbm <- Kbm * renorm.factor
        K <- bind.fv(K, data.frame(bord.modif=Kbm), "{hat(%s)[%s]^{bordm}}(r)",
                     "modified border-corrected estimate of %s",
                     "bord.modif")
      }
    }
    if(any(correction == "translate")) {
      # translation correction
      edgewt <- edge.Trans(dx=close$dx, dy=close$dy, W=W, paired=TRUE)
      allweight <- edgewt * wIJ
      wh <- whist(dIJ, breaks$val, allweight)
      Ktrans <- cumsum(wh)/areaW
      if(renormalise) Ktrans <- Ktrans * renorm.factor
      rmax <- diamW/2
      Ktrans[r >= rmax] <- NA
      K <- bind.fv(K, data.frame(trans=Ktrans), "{hat(%s)[%s]^{trans}}(r)",
                   "translation-correction estimate of %s",
                   "trans")
    }
    if(any(correction == "isotropic" | correction == "Ripley")) {
      # Ripley isotropic correction
      edgewt <- edge.Ripley(X[I], matrix(dIJ, ncol=1))
      allweight <- edgewt * wIJ
      wh <- whist(dIJ, breaks$val, allweight)
      Kiso <- cumsum(wh)/areaW
      if(renormalise) Kiso <- Kiso * renorm.factor
      rmax <- diamW/2
      Kiso[r >= rmax] <- NA
      K <- bind.fv(K, data.frame(iso=Kiso), "{hat(%s)[%s]^{iso}}(r)",
                   "Ripley isotropic correction estimate of %s",
                   "iso")
    }

    # default is to display them all
    formula(K) <- . ~ r
    unitname(K) <- unitname(X)
    if(danger)
      attr(K, "dangerous") <- dangerous
    return(K)
}


Kwtsum <- function(dIJ, bI, wIJ, b, w, breaks) {
  #
  # "internal" routine to compute border-correction estimates of Kinhom
  #
  # dIJ:  vector containing pairwise distances for selected I,J pairs
  # bI:   corresponding vector of boundary distances for I
  # wIJ:  product weight for selected I, J pairs
  #
  # b:    vector of ALL distances to window boundary
  # w:   weights for ALL points
  #
  # breaks : breakpts object
  #

  stopifnot(length(dIJ) == length(bI))
  stopifnot(length(bI) == length(wIJ))
  stopifnot(length(w) == length(b))

  if(!is.finite(sum(w, wIJ)))
    stop("Weights in K-function were infinite or NA")

  bkval <- breaks$val
  
  # determine which distances d_{ij} were observed without censoring
  uncen <- (dIJ <= bI)
  #
  # histogram of noncensored distances
  nco <- whist(dIJ[uncen], bkval, wIJ[uncen])
  # histogram of censoring times for noncensored distances
  ncc <- whist(bI[uncen], bkval, wIJ[uncen])
  # histogram of censoring times (yes, this is a different total size)
  cen <- whist(b, bkval, w)
  # total weight of censoring times beyond rightmost breakpoint
  uppercen <- sum(w[b > breaks$max])
  # go
  RS <- reduced.sample(nco, cen, ncc, show=TRUE, uppercen=uppercen)
  # extract results
  numerator   <- RS$numerator
  denominator <- RS$denominator
  ratio        <- RS$numerator/RS$denominator
  # check
  if(length(numerator) != breaks$ncells)
    stop("internal error: length(numerator) != breaks$ncells")
  if(length(denominator) != breaks$ncells)
    stop("internal error: length(denom.count) != breaks$ncells")
  return(list(numerator=numerator, denominator=denominator, ratio=ratio))
}
	
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Kmeasure.R"
#
#           Kmeasure.R
#
#           $Revision: 1.48 $    $Date: 2014/10/24 00:22:30 $
#
#     Kmeasure()         compute an estimate of the second order moment measure
#
#     Kest.fft()        use Kmeasure() to form an estimate of the K-function
#
#     second.moment.calc()    underlying algorithm
#

Kmeasure <- function(X, sigma, edge=TRUE, ..., varcov=NULL) {
  stopifnot(is.ppp(X))
  
  sigma.given <- !missing(sigma) && !is.null(sigma)
  varcov.given <- !is.null(varcov)
  ngiven <- sigma.given + varcov.given
  if(ngiven == 2)
    stop(paste("Give only one of the arguments",
               sQuote("sigma"), "and", sQuote("varcov")))
  if(ngiven == 0)
    stop(paste("Please specify smoothing bandwidth", sQuote("sigma"),
               "or", sQuote("varcov")))
  if(varcov.given) {
    stopifnot(is.matrix(varcov) && nrow(varcov) == 2 && ncol(varcov)==2 )
    sigma <- NULL
  } else {
    stopifnot(is.numeric(sigma))
    stopifnot(length(sigma) %in% c(1,2))
    stopifnot(all(sigma > 0))
    if(length(sigma) == 2) {
      varcov <- diag(sigma^2)
      sigma <- NULL
    }
  }  

  second.moment.calc(x=X, sigma=sigma, edge=edge,
                     what="Kmeasure", varcov=varcov, ...)
}

second.moment.calc <- function(x, sigma=NULL, edge=TRUE,
                               what="Kmeasure", debug=FALSE, ...,
                               varcov=NULL, expand=FALSE) {
  if(is.null(sigma) && is.null(varcov))
    stop("must specify sigma or varcov")
  choices <- c("kernel", "smooth", "Kmeasure", "Bartlett", "edge", "all", "smoothedge")
  if(!(what %in% choices))
    stop(paste("Unknown choice: what = ", sQuote(what),
               "; available options are:",
               paste(sQuote(choices), collapse=", ")))
  sig <- if(!is.null(sigma)) sigma else max(c(diag(varcov), sqrt(det(varcov))))

  xtype <- if(is.ppp(x)) "ppp" else
           if(is.im(x)) "im" else 
           if(all(unlist(lapply(x, is.im)))) "imlist" else
           stop("x should be a point pattern or a pixel image")

  nimages <- switch(xtype,
                    ppp = 1,
                    im = 1,
                    imlist = length(x))

  win <- if(nimages == 1) as.owin(x) else as.owin(x[[1]])
  win <- rescue.rectangle(win)
  rec <- as.rectangle(win)
  across <- min(diff(rec$xrange), diff(rec$yrange))
  # determine whether to expand window
  if(!expand || (6 * sig < across)) {
    result <- second.moment.engine(x, sigma=sigma, edge=edge,
                                   what=what, debug=debug, ..., varcov=varcov)
    return(result)
  }
  # need to expand window
  bigger <- grow.rectangle(rec, (7 * sig - across)/2)
  switch(xtype,
         ppp = {
           # pixellate first (to preserve pixel resolution)
           X <- pixellate(x, ..., padzero=TRUE)
           np <- npoints(x)
         },
         im = {
           X <- x
           np <- NULL
         },
         imlist = {
           Xlist <- x
           np <- NULL
         })

  # Now expand
  if(nimages == 1) {
    X <- rebound.im(X, bigger)
    X <- na.handle.im(X, 0)
  } else {
    X <- lapply(X, rebound.im, rect=bigger)
    X <- lapply(X, na.handle.im, na.replace=0)
  }
  # Compute!
  out <- second.moment.engine(X, sigma=sigma, edge=edge,
                              what=what, debug=debug, ...,
                              obswin=win, varcov=varcov, npts=np)
  # Now clip it
  fbox <- shift(rec, origin="midpoint")
  if(nimages == 1) {
    result <- switch(what,
                     kernel   = out[fbox],
                     smooth   = out[win],
                     Kmeasure = out[fbox],
                     Bartlett = out[fbox],
                     edge     = out[win],
                     smoothedge = list(smooth=out$smooth[win],
                       edge  =out$edge[win]),
                     all      =
                     list(kernel=out$kernel[fbox],
                          smooth=out$smooth[win],
                          Kmeasure=out$Kmeasure[fbox],
                          Bartlett=out$Bartlett[fbox],
                          edge=out$edge[win]))
  } else {
    result <-
      switch(what,
             kernel     = out[fbox], 
             smooth     = lapply(out, "[", i=win),
             Kmeasure   = lapply(out, "[", i=fbox),
             Bartlett   = lapply(out, "[", i=fbox),
             edge       = out[win],
             smoothedge = list(
               smooth = lapply(out$smooth, "[", i=win),
               edge   = out$edge[win]),
             all        = list(
               kernel=out$kernel[fbox],
               smooth=lapply(out$smooth, "[", i=win),
               Kmeasure=lapply(out$Kmeasure, "[", i=fbox),
               Bartlett=lapply(out$Bartlett, "[", i=fbox),
               edge=out$edge[win]))
  }
  return(result)
}

second.moment.engine <-
  function(x, sigma=NULL, edge=TRUE,
           what=c("Kmeasure", "kernel", "smooth", 
             "Bartlett", "edge", "smoothedge", "all"),
           ...,
           obswin = as.owin(x), varcov=NULL,
           npts=NULL, debug=FALSE)
{
  what <- match.arg(what)
  if(is.ppp(x)) {
    # convert list of points to mass distribution
    X <- pixellate(x, ..., padzero=TRUE)
    if(is.null(npts))
      npts <- npoints(x)
  } else X <- x
  if(is.im(X)) {
    Xlist <- list(X)
    nimages <- 1
  } else if(all(unlist(lapply(X, is.im)))) {
    Xlist <- X
    X <- Xlist[[1]]
    nimages <- length(Xlist)
    blanklist <- vector(mode="list", length=nimages)
    names(blanklist) <- names(Xlist)
  } else stop("internal error: unrecognised format for x")
  unitsX <- unitname(X)
  # ensure obswin has same bounding frame as X
  if(!missing(obswin))
    obswin <- rebound.owin(obswin, as.rectangle(X))
  # go to work
  Y <- X$v
  Ylist <- lapply(Xlist, getElement, name="v")
  #
  xw <- X$xrange
  yw <- X$yrange
  # pad with zeroes
  nr <- nrow(Y)
  nc <- ncol(Y)
  Ypad <- matrix(0, ncol=2*nc, nrow=2*nr)
  Ypadlist <- rep(list(Ypad), nimages)
  for(i in 1:nimages)
    Ypadlist[[i]][1:nr, 1:nc] <- Ylist[[i]]
  Ypad <- Ypadlist[[1]]
  lengthYpad <- 4 * nc * nr
  # corresponding coordinates
#  xw.pad <- xw[1] + 2 * c(0, diff(xw))
#  yw.pad <- yw[1] + 2 * c(0, diff(yw))
  xcol.pad <- X$xcol[1] + X$xstep * (0:(2*nc-1))
  yrow.pad <- X$yrow[1] + X$ystep * (0:(2*nr-1))
  # set up Gauss kernel
  xcol.G <- X$xstep * c(0:(nc-1),-(nc:1))
  yrow.G <- X$ystep * c(0:(nr-1),-(nr:1))
  Gpixarea <- X$xstep * X$ystep
  if(!is.null(sigma)) {
    densX.G <- dnorm(xcol.G, sd=sigma)
    densY.G <- dnorm(yrow.G, sd=sigma)
    Kern <- outer(densY.G, densX.G, "*") * Gpixarea
  } else if(!is.null(varcov)) {
    # anisotropic kernel
    detSigma <- det(varcov)
    Sinv <- solve(varcov)
    halfSinv <- Sinv/2
    constG <- Gpixarea/(2 * pi * sqrt(detSigma))
    xsq <- matrix((xcol.G^2)[col(Ypad)], ncol=2*nc, nrow=2*nr)
    ysq <- matrix((yrow.G^2)[row(Ypad)], ncol=2*nc, nrow=2*nr)
    xy <- outer(yrow.G, xcol.G, "*")
    Kern <- constG * exp(-(xsq * halfSinv[1,1]
                           + xy * (halfSinv[1,2]+halfSinv[2,1])
                           + ysq * halfSinv[2,2]))
#    xx <- matrix(xcol.G[col(Ypad)], ncol=2*nc, nrow=2*nr)
#    yy <- matrix(yrow.G[row(Ypad)], ncol=2*nc, nrow=2*nr)
#    Kern <- const * exp(-(xx * (xx * Sinv[1,1] + yy * Sinv[1,2])
#                          + yy * (xx * Sinv[2,1] + yy * Sinv[2,2]))/2)
  } else 
    stop("Must specify either sigma or varcov")

  # these options call for several image outputs
  if(what %in% c("all", "smoothedge"))
    result <- list()
  
  if(what %in% c("kernel", "all")) {
    # return the kernel
    # first rearrange it into spatially sensible order (monotone x and y)
    rtwist <- ((-nr):(nr-1)) %% (2 * nr) + 1
    ctwist <- (-nc):(nc-1) %% (2*nc) + 1
    if(debug) {
      if(any(fave.order(xcol.G) != rtwist))
        cat("something round the twist\n")
    }
    Kermit <- Kern[ rtwist, ctwist]
    ker <- im(Kermit, xcol.G[ctwist], yrow.G[ rtwist], unitname=unitsX)
    if(what == "kernel")
      return(ker)
    else 
      result$kernel <- ker
  }
  # convolve using fft
  fK <- fft(Kern)
  if(what != "edge") {
    if(nimages == 1) {
      fY <- fft(Ypad)
      sm <- fft(fY * fK, inverse=TRUE)/lengthYpad
      if(debug) {
        cat(paste("smooth: maximum imaginary part=",
                  signif(max(Im(sm)),3), "\n"))
        if(!is.null(npts))
          cat(paste("smooth: mass error=",
                    signif(sum(Mod(sm))-npts,3), "\n"))
      }
    } else {
      fYlist <- smlist <- blanklist
      for(i in 1:nimages) {
        fYlist[[i]] <- fY.i <- fft(Ypadlist[[i]])
        smlist[[i]] <- sm.i <- fft(fY.i * fK, inverse=TRUE)/lengthYpad
        if(debug) {
          cat(paste("smooth component", i, ": maximum imaginary part=",
                    signif(max(Im(sm.i)),3), "\n"))
          if(!is.null(npts))
            cat(paste("smooth component", i, ": mass error=",
                      signif(sum(Mod(sm.i))-npts,3), "\n"))
        }
      }
    }
  }
  if(what %in% c("smooth", "all", "smoothedge")) {
    # return the smoothed point pattern without edge correction
    if(nimages == 1) {
      smo <- im(Re(sm)[1:nr, 1:nc],
                xcol.pad[1:nc], yrow.pad[1:nr],
                unitname=unitsX)
      if(what == "smooth") {
        return(smo)
      } else {
        result$smooth <- smo
      }
    } else {
      smolist <- blanklist
      for(i in 1:nimages) 
        smolist[[i]] <- im(Re(smlist[[i]])[1:nr, 1:nc],
                           xcol.pad[1:nc], yrow.pad[1:nr],
                           unitname=unitsX)
      smolist <- as.listof(smolist)
      if(what == "smooth") {
        return(smolist)
      } else {
        result$smooth <- smolist
      }
    }
  }

  if(what != "edge") {
    # compute Bartlett spectrum
    if(nimages == 1) {
      bart <- Mod(fY)^2 * fK
    } else {
      bartlist <- lapply(fYlist, function(z, fK) { Mod(z)^2 * fK}, fK=fK)
    }
  }
  
  if(what %in% c("Bartlett", "all")) {
     # return Bartlett spectrum
     # rearrange into spatially sensible order (monotone x and y)
    rtwist <- ((-nr):(nr-1)) %% (2 * nr) + 1
    ctwist <- (-nc):(nc-1) %% (2*nc) + 1
    if(nimages == 1) {
      Bart <- bart[ rtwist, ctwist]
      Bartlett <- im(Mod(Bart),(-nc):(nc-1), (-nr):(nr-1))
      if(what == "Bartlett")
        return(Bartlett)
      else
        result$Bartlett <- Bartlett
    } else {
      Bartlist <- blanklist
      for(i in 1:nimages) {
        Bart <- (bartlist[[i]])[ rtwist, ctwist]
        Bartlist[[i]] <- im(Mod(Bart),(-nc):(nc-1), (-nr):(nr-1))
      }
      Bartlist <- as.listof(Bartlist)
      if(what == "Bartlett")
        return(Bartlist)
      else
        result$Bartlett <- Bartlist
    }
  }
  
  #### ------- Second moment measure --------------
  #
  if(what != "edge") {
    if(nimages == 1) {
      mom <- fft(bart, inverse=TRUE)/lengthYpad
      if(debug) {
        cat(paste("2nd moment measure: maximum imaginary part=",
                  signif(max(Im(mom)),3), "\n"))
        if(!is.null(npts))
          cat(paste("2nd moment measure: mass error=",
                    signif(sum(Mod(mom))-npts^2, 3), "\n"))
      }
      mom <- Mod(mom)
      # subtract (delta_0 * kernel) * npts
      if(is.null(npts))
        stop("Internal error: second moment measure requires npts")
      mom <- mom - npts* Kern
    } else {
      momlist <- blanklist
      for(i in 1:nimages) {
        mom.i <- fft(bartlist[[i]], inverse=TRUE)/lengthYpad
        if(debug) {
          cat(paste("2nd moment measure: maximum imaginary part=",
                    signif(max(Im(mom.i)),3), "\n"))
          if(!is.null(npts))
            cat(paste("2nd moment measure: mass error=",
                      signif(sum(Mod(mom.i))-npts^2, 3), "\n"))
        }
        mom.i <- Mod(mom.i)
        # subtract (delta_0 * kernel) * npts
        if(is.null(npts))
          stop("Internal error: second moment measure requires npts")
        mom.i <- mom.i - npts* Kern
        momlist[[i]] <- mom.i
      }
    }
  }
  # edge correction
  if(edge || what %in% c("edge", "all", "smoothedge")) {
    # compute kernel-smoothed set covariance
    M <- as.mask(obswin, dimyx=c(nr, nc))$m
    # previous line ensures M has same dimensions and scale as Y 
    Mpad <- matrix(0, ncol=2*nc, nrow=2*nr)
    Mpad[1:nr, 1:nc] <- M
    lengthMpad <- 4 * nc * nr
    fM <- fft(Mpad)
    if(edge && what != "edge") {
      # apply edge correction      
      co <- fft(Mod(fM)^2 * fK, inverse=TRUE)/lengthMpad
      co <- Mod(co) 
      a <- sum(M)
      wt <- a/co
      me <- spatstat.options("maxedgewt")
      weight <- matrix(pmin.int(me, wt), ncol=2*nc, nrow=2*nr)
      # apply edge correction to second moment measure
      if(nimages == 1) {
        mom <- mom * weight
        # set to NA outside 'reasonable' region
        mom[wt > 10] <- NA
      } else {
        wgt10 <- (wt > 10)
        for(i in 1:nimages) {
          mom.i <- momlist[[i]]
          mom.i <- mom.i * weight
          # set to NA outside 'reasonable' region
          mom.i[wgt10] <- NA
          momlist[[i]] <- mom.i
        }
      }
    }
  }
  if(what != "edge") {
    # rearrange into spatially sensible order (monotone x and y)
    rtwist <- ((-nr):(nr-1)) %% (2 * nr) + 1
    ctwist <- (-nc):(nc-1) %% (2*nc) + 1
    if(nimages == 1) {
      mom <- mom[ rtwist, ctwist]
    } else {
      momlist <- lapply(momlist, "[", i=rtwist, j=ctwist)
    }
    if(debug) {
      if(any(fave.order(xcol.G) != rtwist))
        cat("internal error: something round the twist\n")
    }
  }
  if(what %in% c("edge", "all", "smoothedge")) {
    # return convolution of window with kernel
    # (evaluated inside window only)
    con <- fft(fM * fK, inverse=TRUE)/lengthMpad
    edg <- Mod(con[1:nr, 1:nc])
    edg <- im(edg, xcol.pad[1:nc], yrow.pad[1:nr], unitname=unitsX)
    if(what == "edge") 
      return(edg)
    else
      result$edge <- edg
  }
  if(what == "smoothedge")
    return(result)
  # Second moment measure, density estimate
  # Divide by number of points * lambda and convert mass to density
  pixarea <- with(X, xstep * ystep)
  if(nimages == 1) {
    mom <- mom * area(obswin) / (pixarea * npts^2)
    # this is the second moment measure
    mm <- im(mom, xcol.G[ctwist], yrow.G[rtwist], unitname=unitsX)
    if(what == "Kmeasure")
      return(mm)
    else 
      result$Kmeasure <- mm
  } else {
    ccc <- area(obswin) / (pixarea * npts^2)
    mmlist <- blanklist
    for(i in 1:nimages) {
      mom.i <- momlist[[i]]
      mom.i <- mom.i * ccc
      # this is the second moment measure
      mmlist[[i]] <-
        im(mom.i, xcol.G[ctwist], yrow.G[rtwist], unitname=unitsX)
    }
    mmlist <- as.listof(mmlist)
    if(what == "Kmeasure")
      return(mmlist)
    else 
      result$Kmeasure <- mmlist
  }
  # what = "all", so return all computed objects
  return(result)
}

Kest.fft <- function(X, sigma, r=NULL, breaks=NULL) {
  verifyclass(X, "ppp")
  W <- X$window
  lambda <- X$n/area(W)
  rmaxdefault <- rmax.rule("K", W, lambda)        
  bk <- handle.r.b.args(r, breaks, W, rmaxdefault=rmaxdefault)
  breaks <- bk$val
  rvalues <- bk$r
  u <- Kmeasure(X, sigma)
  xx <- rasterx.im(u)
  yy <- rastery.im(u)
  rr <- sqrt(xx^2 + yy^2)
  tr <- whist(rr, breaks, u$v)
  K  <- cumsum(tr)
  rmax <- min(rr[is.na(u$v)])
  K[rvalues >= rmax] <- NA
  result <- data.frame(r=rvalues, theo=pi * rvalues^2, border=K)
  w <- X$window
  alim <- c(0, min(diff(w$xrange), diff(w$yrange))/4)
  out <- fv(result,
            "r", quote(K(r)),
            "border",
             . ~ r, alim,
            c("r", "%s[pois](r)", "hat(%s)[fb](r)"),
            c("distance argument r",
              "theoretical Poisson %s",
              "border-corrected FFT estimate of %s"),
            fname="K",
            unitname=unitname(X)
            )
  return(out)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Kmodel.R"
#
#  Kmodel.R
#
# Kmodel and pcfmodel
#
#  $Revision: 1.1 $  $Date: 2011/05/30 14:02:21 $
#

Kmodel <- function(model, ...) {
  UseMethod("Kmodel")
}

pcfmodel <- function(model, ...) {
  UseMethod("pcfmodel")
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Kmulti.R"
#
#	Kmulti.S		
#
#	Compute estimates of cross-type K functions
#	for multitype point patterns
#
#	$Revision: 5.46 $	$Date: 2014/11/10 10:34:24 $
#
#
# -------- functions ----------------------------------------
#	Kcross()	cross-type K function K_{ij}
#                       between types i and j
#
#	Kdot()          K_{i\bullet}
#                       between type i and all points regardless of type
#
#       Kmulti()        (generic)
#
#
# -------- standard arguments ------------------------------	
#	X		point pattern (of class 'ppp')
#				including 'marks' vector
#	r		distance values at which to compute K	
#
# -------- standard output ------------------------------
#      A data frame with columns named
#
#	r:		same as input
#
#	trans:		K function estimated by translation correction
#
#	iso:		K function estimated by Ripley isotropic correction
#
#	theo:		K function for Poisson ( = pi * r ^2 )
#
#	border:		K function estimated by border method
#			using standard formula (denominator = count of points)
#
#       bord.modif:	K function estimated by border method
#			using modified formula 
#			(denominator = area of eroded window
#
# ------------------------------------------------------------------------

"Lcross" <- function(X, i, j, ...) {
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  if(missing(i)) i <- levels(marks(X))[1]
  if(missing(j)) j <- levels(marks(X))[2]
  K <- Kcross(X, i, j, ...)
  L <- eval.fv(sqrt(K/pi))
  # relabel the fv object
  iname <- make.parseable(paste(i))
  jname <- make.parseable(paste(j))
  L <- rebadge.fv(L,
                  substitute(L[i,j](r),
                             list(i=iname,j=jname)),
                  c("L", paste0("list(", iname, ",", jname, ")")),
                  new.yexp=substitute(L[list(i,j)](r),
                                      list(i=iname,j=jname)))
  attr(L, "labl") <- attr(K, "labl")
  return(L)  
}

"Ldot" <- function(X, i, ...) {
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  if(missing(i)) i <- levels(marks(X))[1]
  K <- Kdot(X, i, ...)
  L <- eval.fv(sqrt(K/pi))
  # relabel the fv object
  iname <- make.parseable(paste(i))
  L <- rebadge.fv(L,
                  substitute(L[i ~ dot](r), list(i=iname)),
                  c("L", paste(iname, "~ symbol(\"\\267\")")), 
                  new.yexp=substitute(L[i ~ symbol("\267")](r), list(i=iname)))
  attr(L, "labl") <- attr(K, "labl")
  return(L)  
}

"Kcross" <- 
function(X, i, j, r=NULL, breaks=NULL,
         correction =c("border", "isotropic", "Ripley", "translate") , ...,
         ratio=FALSE)
{
  verifyclass(X, "ppp")
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  if(missing(correction))
    correction <- NULL
  marx <- marks(X)
  if(missing(i))
    i <- levels(marx)[1]
  if(missing(j))
    j <- levels(marx)[2]
  I <- (marx == i)
  if(!any(I))
    stop(paste("No points have mark i =", i))

  if(i == j) {
    result <- Kest(X[I],
                   r=r, breaks=breaks, correction=correction, ...,
                   ratio=ratio)
  } else {
    J <- (marx == j)
    if(!any(J))
      stop(paste("No points have mark j =", j))
    result <- Kmulti(X, I, J,
                     r=r, breaks=breaks, correction=correction, ...,
                     ratio=ratio)
  }
  iname <- make.parseable(paste(i))
  jname <- make.parseable(paste(j))
  result <-
    rebadge.fv(result, 
               substitute(Kcross[i,j](r), list(i=iname,j=jname)),
               c("K", paste0("list(", iname, ",", jname, ")")), 
               new.yexp=substitute(K[list(i,j)](r),
                                   list(i=iname,j=jname)))
  return(result)
}

"Kdot" <- 
function(X, i, r=NULL, breaks=NULL,
         correction = c("border", "isotropic", "Ripley", "translate") , ...,
         ratio=FALSE)
{
  verifyclass(X, "ppp")
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  if(missing(correction))
    correction <- NULL

  marx <- marks(X)
  if(missing(i))
    i <- levels(marx)[1]
        
  I <- (marx == i)
  J <- rep.int(TRUE, X$n)  # i.e. all points
	
  if(!any(I)) stop(paste("No points have mark i =", i))
	
  result <- Kmulti(X, I, J,
                   r=r, breaks=breaks, correction=correction, ..., ratio=ratio)
  iname <- make.parseable(paste(i))
  result <-
    rebadge.fv(result,
               substitute(K[i ~ dot](r), list(i=iname)),
               c("K", paste0(iname, "~ symbol(\"\\267\")")),
               new.yexp=substitute(K[i ~ symbol("\267")](r), list(i=iname)))
  return(result)
}


"Kmulti"<-
function(X, I, J, r=NULL, breaks=NULL,
         correction = c("border", "isotropic", "Ripley", "translate") , ...,
         ratio=FALSE)
{
  verifyclass(X, "ppp")

  npts <- npoints(X)
  W <- X$window
  areaW <- area(W)

  correction.given <- !missing(correction) && !is.null(correction)
  if(is.null(correction))
    correction <- c("border", "isotropic", "Ripley", "translate")
  
  correction <- pickoption("correction", correction,
                           c(none="none",
                             border="border",
                             "bord.modif"="bord.modif",
                             isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             best="best"),
                           multi=TRUE)

  correction <- implemented.for.K(correction, W$type, correction.given)

  I <- ppsubset(X, I)
  J <- ppsubset(X, J)
  if(is.null(I) || is.null(J))
    stop("I and J must be valid subset indices")
	
  if(!any(I)) stop("no points belong to subset I")
  if(!any(J)) stop("no points belong to subset J")
		
  nI <- sum(I)
  nJ <- sum(J)
  lambdaI <- nI/areaW
  lambdaJ <- nJ/areaW

  # r values 
  rmaxdefault <- rmax.rule("K", W, lambdaJ)
  breaks <- handle.r.b.args(r, breaks, W, rmaxdefault=rmaxdefault)
  r <- breaks$r
  rmax <- breaks$max
        
  # recommended range of r values
  alim <- c(0, min(rmax, rmaxdefault))
        
  # this will be the output data frame
  # It will be given more columns later
  K <- data.frame(r=r, theo= pi * r^2)
  desc <- c("distance argument r", "theoretical Poisson %s")
  K <- fv(K, "r", quote(K[IJ](r)), 
          "theo", , alim, c("r","{%s[%s]^{pois}}(r)"),
          desc, fname=c("K", "list(I,J)"),
          yexp=quote(K[list(I,J)](r)))
  
  # save numerator and denominator?
  if(ratio) {
    denom <- lambdaI * lambdaJ * areaW
    numK <- eval.fv(denom * K)
    denK <- eval.fv(denom + K * 0)
    attributes(numK) <- attributes(denK) <- attributes(K)
    attr(numK, "desc")[2] <- "numerator for theoretical Poisson %s"
    attr(denK, "desc")[2] <- "denominator for theoretical Poisson %s"
  }

  # find close pairs of points
  XI <- X[I]
  XJ <- X[J]
  close <- crosspairs(XI, XJ, max(r))
# close$i and close$j are serial numbers in XI and XJ respectively;        
# map them to original serial numbers in X
  orig <- seq_len(npts)
  imap <- orig[I]
  jmap <- orig[J]
  iX <- imap[close$i]
  jX <- jmap[close$j]
# eliminate any identical pairs
  if(any(I & J)) {
    ok <- (iX != jX)
    if(!all(ok)) {
      close$i  <- close$i[ok]
      close$j  <- close$j[ok]
      close$xi <- close$xi[ok]
      close$yi <- close$yi[ok]
      close$xj <- close$xj[ok]
      close$yj <- close$yj[ok]
      close$dx <- close$dx[ok]
      close$dy <- close$dy[ok]
      close$d  <- close$d[ok]
    }
  }
# extract information for these pairs (relative to orderings of XI, XJ)
  dcloseIJ <- close$d
  icloseI  <- close$i
  jcloseJ  <- close$j
        
# Compute estimates by each of the selected edge corrections.
        
  if(any(correction == "none")) {
    # uncorrected! 
    wh <- whist(dcloseIJ, breaks$val)  # no weights
    numKun <- cumsum(wh)
    denKun <- lambdaI * lambdaJ * areaW
    Kun <- numKun/denKun
    K <- bind.fv(K, data.frame(un=Kun), "{hat(%s)[%s]^{un}}(r)",
                 "uncorrected estimate of %s",
                 "un")
    if(ratio) {
      # save numerator and denominator
      numK <- bind.fv(numK, data.frame(un=numKun), "{hat(%s)[%s]^{un}}(r)",
                 "numerator of uncorrected estimate of %s",
                 "un")
      denK <- bind.fv(denK, data.frame(un=denKun), "{hat(%s)[%s]^{un}}(r)",
                 "denominator of uncorrected estimate of %s",
                 "un")
    }

  }
  if(any(correction == "border" | correction == "bord.modif")) {
    # border method
    # distance to boundary from each point of type I
    bI <- bdist.points(XI)
    # distance to boundary from first element of each (i, j) pair
    bcloseI <- bI[icloseI]
    # apply reduced sample algorithm
    RS <- Kount(dcloseIJ, bcloseI, bI, breaks)
    if(any(correction == "bord.modif")) {
      denom.area <- eroded.areas(W, r)
      numKbm <- RS$numerator
      denKbm <- denom.area * nI * nJ
      Kbm <- numKbm/denKbm
      K <- bind.fv(K, data.frame(bord.modif=Kbm), "{hat(%s)[%s]^{bordm}}(r)",
                   "modified border-corrected estimate of %s",
                   "bord.modif")
      if(ratio) {
        # save numerator and denominator
        numK <- bind.fv(numK, data.frame(bord.modif=numKbm),
                        "{hat(%s)[%s]^{bordm}}(r)",
                        "numerator of modified border-corrected estimate of %s",
                        "bord.modif")
        denK <- bind.fv(denK, data.frame(bord.modif=denKbm),
                        "{hat(%s)[%s]^{bordm}}(r)",
                        "denominator of modified border-corrected estimate of %s",
                        "bord.modif")
      }
    }
    if(any(correction == "border")) {
      numKb <- RS$numerator
      denKb <- lambdaJ * RS$denom.count
      Kb <- numKb/denKb
      K <- bind.fv(K, data.frame(border=Kb), "{hat(%s)[%s]^{bord}}(r)",
                   "border-corrected estimate of %s",
                   "border")
      if(ratio) {
        numK <- bind.fv(numK, data.frame(border=numKb),
                        "{hat(%s)[%s]^{bord}}(r)",
                        "numerator of border-corrected estimate of %s",
                        "border")
        denK <- bind.fv(denK, data.frame(border=denKb),
                        "{hat(%s)[%s]^{bord}}(r)",
                        "denominator of border-corrected estimate of %s",
                        "border")
      }
    }
  }
  if(any(correction == "translate")) {
    # translation correction
    edgewt <- edge.Trans(XI[icloseI], XJ[jcloseJ], paired=TRUE)
    wh <- whist(dcloseIJ, breaks$val, edgewt)
    numKtrans <- cumsum(wh)
    denKtrans <- lambdaI * lambdaJ * areaW
    Ktrans <- numKtrans/denKtrans
    rmax <- diameter(W)/2
    Ktrans[r >= rmax] <- NA
    K <- bind.fv(K, data.frame(trans=Ktrans), "{hat(%s)[%s]^{trans}}(r)", 
                 "translation-corrected estimate of %s",
                 "trans")
    if(ratio) {
      numK <- bind.fv(numK, data.frame(trans=numKtrans),
                      "{hat(%s)[%s]^{trans}}(r)",
                      "numerator of translation-corrected estimate of %s",
                      "trans")
      denK <- bind.fv(denK, data.frame(trans=denKtrans),
                      "{hat(%s)[%s]^{trans}}(r)",
                      "denominator of translation-corrected estimate of %s",
                      "trans")
    }
  }
  if(any(correction == "isotropic")) {
    # Ripley isotropic correction
    edgewt <- edge.Ripley(XI[icloseI], matrix(dcloseIJ, ncol=1))
    wh <- whist(dcloseIJ, breaks$val, edgewt)
    numKiso <- cumsum(wh)
    denKiso <- lambdaI * lambdaJ * areaW
    Kiso <- numKiso/denKiso
    rmax <- diameter(W)/2
    Kiso[r >= rmax] <- NA
    K <- bind.fv(K, data.frame(iso=Kiso), "{hat(%s)[%s]^{iso}}(r)",
                 "Ripley isotropic correction estimate of %s",
                 "iso")
   if(ratio) {
      numK <- bind.fv(numK, data.frame(iso=numKiso), "{hat(%s)[%s]^{iso}}(r)",
                      "numerator of Ripley isotropic correction estimate of %s",
                      "iso")
      denK <- bind.fv(denK, data.frame(iso=denKiso), "{hat(%s)[%s]^{iso}}(r)",
                      "denominator of Ripley isotropic correction estimate of %s",
                      "iso")
    }
  }
  # default is to display them all
  formula(K) <- . ~ r
  unitname(K) <- unitname(X)
  
  if(ratio) {
    # finish up numerator & denominator
    formula(numK) <- formula(denK) <- . ~ r
    unitname(numK) <- unitname(denK) <- unitname(K)
    # tack on to result
    K <- rat(K, numK, denK, check=FALSE)
  }
  return(K)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Kmulti.inhom.R"
#
#	Kmulti.inhom.S		
#
#	$Revision: 1.44 $	$Date: 2014/11/10 10:34:57 $
#
#
# ------------------------------------------------------------------------

Lcross.inhom <- function(X, i, j, ...) {
  if(!is.multitype(X, dfok=FALSE))
	stop("Point pattern must be multitype")
  if(missing(i)) i <- levels(marks(X))[1]
  if(missing(j)) j <- levels(marks(X))[2]
  K <- Kcross.inhom(X, i, j, ...)
  L <- eval.fv(sqrt(pmax.int(K,0)/pi))
  iname <- make.parseable(paste(i))
  jname <- make.parseable(paste(j))
  # relabel the fv object
  L <- rebadge.fv(L,
                  substitute(L[inhom,i,j](r),
                             list(i=iname,j=jname)),
                  c("L", paste0("list", paren(paste("inhom", i, j, sep=",")))),
                  new.yexp=substitute(L[list(inhom,i,j)](r),
                                      list(i=iname,j=jname)))
  attr(L, "labl") <- attr(K, "labl")
  attr(L, "dangerous") <- attr(K, "dangerous")
  return(L)  
}

Ldot.inhom <- function(X, i, ...) {
  if(!is.multitype(X, dfok=FALSE))
	stop("Point pattern must be multitype")
  if(missing(i)) i <- levels(marks(X))[1]
  K <- Kdot.inhom(X, i, ...)
  L <- eval.fv(sqrt(pmax.int(K,0)/pi))
  # relabel the fv object
  iname <- make.parseable(paste(i))
  L <- rebadge.fv(L,
                  substitute(L[inhom, i ~ dot](r), list(i=iname)),
                  c("L", paste0("list(inhom,", iname, "~symbol(\"\\267\"))")),
                  new.yexp=substitute(L[list(inhom, i ~ symbol("\267"))](r),
                    list(i=iname)))
  attr(L, "labl") <- attr(K, "labl")
  attr(L, "dangerous") <- attr(K, "dangerous")
  return(L)  
}

"Kcross.inhom" <- 
function(X, i, j, lambdaI=NULL, lambdaJ=NULL, ...,
         r=NULL, breaks=NULL,
         correction = c("border", "isotropic", "Ripley", "translate"),
         sigma=NULL, varcov=NULL,
         lambdaIJ=NULL)
{
  verifyclass(X, "ppp")
  if(!is.multitype(X, dfok=FALSE))
	stop("Point pattern must be multitype")
  if(missing(correction))
    correction <- NULL
  marx <- marks(X)
  if(missing(i))
    i <- levels(marx)[1]
  if(missing(j))
    j <- levels(marx)[2]
  I <- (marx == i)
  J <- (marx == j)
  Iname <- paste("points with mark i =", i)
  Jname <- paste("points with mark j =", j)
  K <- Kmulti.inhom(X, I, J, lambdaI, lambdaJ, ...,
                    r=r,breaks=breaks,correction=correction,
                    sigma=sigma, varcov=varcov,
                    lambdaIJ=lambdaIJ, Iname=Iname, Jname=Jname)
  iname <- make.parseable(paste(i))
  jname <- make.parseable(paste(j))
  result <-
    rebadge.fv(K,
               substitute(K[inhom,i,j](r),
                          list(i=iname,j=jname)),
               c("K", paste0("list", paren(paste("inhom", i, j, sep=",")))),
               new.yexp=substitute(K[list(inhom,i,j)](r),
                                   list(i=iname,j=jname)))
  attr(result, "dangerous") <- attr(K, "dangerous")
  return(result)
}

"Kdot.inhom" <- 
function(X, i, lambdaI=NULL, lambdadot=NULL, ...,
         r=NULL, breaks=NULL,
         correction = c("border", "isotropic", "Ripley", "translate"),
         sigma=NULL, varcov=NULL, 
         lambdaIdot=NULL)
{
  verifyclass(X, "ppp")
  if(!is.multitype(X, dfok=FALSE))
	stop("Point pattern must be multitype")
  if(missing(correction))
    correction <- NULL

  marx <- marks(X)
  if(missing(i))
    i <- levels(marx)[1]

  I <- (marx == i)
  J <- rep.int(TRUE, X$n)  # i.e. all points
  Iname <- paste("points with mark i =", i)
  Jname <- paste("points")
	
  K <- Kmulti.inhom(X, I, J, lambdaI, lambdadot, ...,
                    r=r,breaks=breaks,correction=correction,
                    sigma=sigma, varcov=varcov,
                    lambdaIJ=lambdaIdot,
                    Iname=Iname, Jname=Jname)
  iname <- make.parseable(paste(i))
  result <-
    rebadge.fv(K,
               substitute(K[inhom, i ~ dot](r), list(i=iname)),
               c("K", paste0("list(inhom,", iname, "~symbol(\"\\267\"))")),
               new.yexp=substitute(K[list(inhom, i ~ symbol("\267"))](r),
                                   list(i=iname)))
  if(!is.null(dang <- attr(K, "dangerous"))) {
    dang[dang == "lambdaJ"] <- "lambdadot"
    dang[dang == "lambdaIJ"] <- "lambdaIdot"
    attr(result, "dangerous") <- dang
  }
  return(result)
}


"Kmulti.inhom"<-
function(X, I, J, lambdaI=NULL, lambdaJ=NULL, 
         ...,
         r=NULL, breaks=NULL,
         correction = c("border", "isotropic", "Ripley", "translate"),
         lambdaIJ=NULL,
         sigma=NULL, varcov=NULL)
{
  verifyclass(X, "ppp")

  extrargs <- resolve.defaults(list(...),
                               list(Iname="points satisfying condition I",
                                    Jname="points satisfying condition J"))
  if(length(extrargs) > 2)
    warning("Additional arguments unrecognised")
  Iname <- extrargs$Iname
  Jname <- extrargs$Jname
  
        
  npts <- npoints(X)
  W <- as.owin(X)
  areaW <- area(W)

  # validate edge correction
  correction.given <- !missing(correction) && !is.null(correction)
  if(is.null(correction))
    correction <- c("border", "isotropic", "Ripley", "translate")

  correction <- pickoption("correction", correction,
                           c(none="none",
                             border="border",
                             "bord.modif"="bord.modif",
                             isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             best="best"),
                           multi=TRUE)

  correction <- implemented.for.K(correction, W$type, correction.given)

  # validate I, J
  I <- ppsubset(X, I)
  J <- ppsubset(X, J)
  if(is.null(I) || is.null(J))
    stop("I and J must be valid subset indices")
	
  nI <- sum(I)
  nJ <- sum(J)
  if(nI == 0) stop(paste("There are no", Iname))
  if(nJ == 0) stop(paste("There are no", Jname))

  # r values 
  rmaxdefault <- rmax.rule("K", W, nJ/areaW)
  breaks <- handle.r.b.args(r, breaks, W, rmaxdefault=rmaxdefault)
  r <- breaks$r
  rmax <- breaks$max

  dangerous <- c("lambdaI", "lambdaJ", "lambdaIJ")
  dangerI <- dangerJ <- TRUE

  ## intensity data
  if(is.null(lambdaI)) {
    # estimate intensity
    dangerI <- FALSE
    lambdaI <- density(X[I], ..., sigma=sigma, varcov=varcov,
                       at="points", leaveoneout=TRUE)
  } else if(is.im(lambdaI)) {
    # look up intensity values
    lambdaI <- safelookup(lambdaI, X[I])
  } else if(is.function(lambdaI)) {
    # evaluate function at locations
    XI <- X[I]
    lambdaI <- lambdaI(XI$x, XI$y)
  } else if(is.numeric(lambdaI) && is.vector(as.numeric(lambdaI))) {
    # validate intensity vector
    if(length(lambdaI) != nI)
      stop(paste("The length of", sQuote("lambdaI"),
                 "should equal the number of", Iname))
  } else 
  stop(paste(sQuote("lambdaI"), "should be a vector or an image"))

  if(is.null(lambdaJ)) {
    # estimate intensity
    dangerJ <- FALSE
    lambdaJ <- density(X[J], ..., sigma=sigma, varcov=varcov,
                       at="points", leaveoneout=TRUE)
  } else if(is.im(lambdaJ)) {
    # look up intensity values
    lambdaJ <- safelookup(lambdaJ, X[J])
  } else if(is.function(lambdaJ)) {
    # evaluate function at locations
    XJ <- X[J]
    lambdaJ <- lambdaJ(XJ$x, XJ$y)
  } else if(is.numeric(lambdaJ) && is.vector(as.numeric(lambdaJ))) {
    # validate intensity vector
    if(length(lambdaJ) != nJ)
      stop(paste("The length of", sQuote("lambdaJ"),
                 "should equal the number of", Jname))
  } else 
  stop(paste(sQuote("lambdaJ"), "should be a vector or an image"))

  # Weight for each pair
  if(!is.null(lambdaIJ)) {
    dangerIJ <- TRUE
    if(!is.matrix(lambdaIJ))
      stop("lambdaIJ should be a matrix")
    if(nrow(lambdaIJ) != nI)
      stop(paste("nrow(lambdaIJ) should equal the number of", Iname))
    if(ncol(lambdaIJ) != nJ)
      stop(paste("ncol(lambdaIJ) should equal the number of", Jname))
  } else dangerIJ <- FALSE

  danger <- dangerI || dangerJ || dangerIJ

  # Recommended range of r values
  alim <- c(0, min(rmax, rmaxdefault))
        
  # this will be the output data frame
  # It will be given more columns later
  K <- data.frame(r=r, theo= pi * r^2)
  desc <- c("distance argument r", "theoretical Poisson %s")
  fname <- c("K", "list(inhom,I,J)")
  K <- fv(K, "r", quote(K[inhom, I, J](r)),
          "theo", , alim,
          c("r", makefvlabel(NULL, NULL, fname, "pois")),
          desc,
          fname=fname,
          yexp=quote(K[list(inhom,I,J)](r)))

# identify close pairs of points
  XI <- X[I]
  XJ <- X[J]
  close <- crosspairs(XI, XJ, max(r))
# map (i,j) to original serial numbers in X
  orig <- seq_len(npts)
  imap <- orig[I]
  jmap <- orig[J]
  iX <- imap[close$i]
  jX <- jmap[close$j]
# eliminate any identical pairs
  if(any(I & J)) {
    ok <- (iX != jX)
    if(!all(ok)) {
      close$i  <- close$i[ok]
      close$j  <- close$j[ok]
      close$xi <- close$xi[ok]
      close$yi <- close$yi[ok]
      close$xj <- close$xj[ok]
      close$yj <- close$yj[ok]
      close$dx <- close$dx[ok]
      close$dy <- close$dy[ok]
      close$d  <- close$d[ok]
    }
  }
# extract information for these pairs (relative to orderings of XI, XJ)
  dclose <- close$d
  icloseI  <- close$i
  jcloseJ  <- close$j
        
# Form weight for each pair
  if(is.null(lambdaIJ))
    weight <- 1/(lambdaI[icloseI] * lambdaJ[jcloseJ])
  else 
    weight <- 1/lambdaIJ[cbind(icloseI, jcloseJ)]

# Compute estimates by each of the selected edge corrections.

  if(any(correction == "border" | correction == "bord.modif")) {
    # border method
    # Compute distances to boundary
    b <- bdist.points(XI)
    bI <- b[icloseI]
    # apply reduced sample algorithm
    RS <- Kwtsum(dclose, bI, weight, b, 1/lambdaI, breaks)
    if(any(correction == "border")) {
      Kb <- RS$ratio
      K <- bind.fv(K, data.frame(border=Kb),
                   makefvlabel(NULL, "hat", fname, "bord"),
                   "border-corrected estimate of %s",
                   "border")
    }
    if(any(correction == "bord.modif")) {
      Kbm <- RS$numerator/eroded.areas(W, r)
      K <- bind.fv(K, data.frame(bord.modif=Kbm),
                   makefvlabel(NULL, "hat", fname, "bordm"),
                   "modified border-corrected estimate of %s",
                   "bord.modif")
    }
  }
  if(any(correction == "translate")) {
    ## translation correction
    edgewt <- edge.Trans(XI[icloseI], XJ[jcloseJ], paired=TRUE)
    allweight <- edgewt * weight
    wh <- whist(dclose, breaks$val, allweight)
    Ktrans <- cumsum(wh)/areaW
    rmax <- diameter(W)/2
    Ktrans[r >= rmax] <- NA
    K <- bind.fv(K, data.frame(trans=Ktrans),
                 makefvlabel(NULL, "hat", fname, "trans"),
                 "translation-corrected estimate of %s",
                 "trans")
  }
  if(any(correction == "isotropic")) {
    ## Ripley isotropic correction
    edgewt <- edge.Ripley(XI[icloseI], matrix(dclose, ncol=1))
    allweight <- edgewt * weight
    wh <- whist(dclose, breaks$val, allweight)
    Kiso <- cumsum(wh)/areaW
    rmax <- diameter(W)/2
    Kiso[r >= rmax] <- NA
    K <- bind.fv(K, data.frame(iso=Kiso), 
                 makefvlabel(NULL, "hat", fname, "iso"),
                 "Ripley isotropic correction estimate of %s",
                 "iso")
  }
  ## default is to display them all
  formula(K) <- . ~ r
  unitname(K) <- unitname(X)
  if(danger)
    attr(K, "dangerous") <- dangerous
  return(K)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Kres.R"
#
#	Kres.R
#
#	Residual K
#
#	$Revision: 1.3 $	$Date: 2013/04/25 06:37:43 $
#
#############################################################################
#

Kres <- function(object, ...) {
  if(!is.fv(object)) {
    # usual case where 'object' is a ppm, ppp or quad
    K <- Kcom(object, ...)
  } else {
    # case where 'object' is the output of 'Kcom'
    a <- attr(object, "maker")
    if(is.null(a) || a != "Kcom")
      stop("fv object was not created by Kcom")
    K <- object
    if(length(list(...)) > 0)
      warning("Extra arguments ignored")
  }
  # initialise fv object
  df <- data.frame(r=K$r, theo=numeric(length(K$r)))
  desc <- c("distance argument r", "value 0 corresponding to perfect fit")
  ans <- fv(df, "r", substitute(bold(R)~hat(K)(r), NULL),
            "theo", . ~ r ,
            attr(K, "alim"), c("r","bold(R)~%s[theo](r)"), desc, fname="K")
  # add residual functions
  nam <- names(K)
  if("border" %in% nam)
    ans <- bind.fv(ans,
                    data.frame(bres=with(K, border-bcom)),
                    "bold(R)~hat(%s)[bord](r)",
                    "residual function %s based on border correction",
                    "bres")
  if(all(c("trans","tcom") %in% nam))
    ans <- bind.fv(ans,
                    data.frame(tres=with(K, trans-tcom)),
                    "bold(R)~hat(%s)[trans](r)",
                    "residual function %s based on translation correction",
                    "tres")
  if(all(c("iso","icom") %in% nam))
    ans <- bind.fv(ans,
                    data.frame(ires=with(K, iso-icom)),
                    "bold(R)~hat(%s)[iso](r)",
                    "residual function %s based on isotropic correction",
                    "ires")
  if("ivar" %in% nam) {
    savedotnames <- fvnames(ans, ".")
    ans <- bind.fv(ans,
                   as.data.frame(K)[, c("ivar", "isd", "ihi", "ilo")],
                    c("bold(C)^2~hat(%s)[iso](r)",
                      "sqrt(bold(C)^2~hat(%s)[iso](r))",
                      "bold(R)~hat(%s)[Hi](r)",
                      "bold(R)~hat(%s)[Lo](r)"),
                    c("pseudovariance of isotropic-corrected residual %s",
                      "pseudo-SD of isotropic-corrected residual %s",
                      "upper critical band for isotropic-corrected residual %s",
                      "lower critical band for isotropic-corrected residual %s"),
                    "ires")
    ans <- bind.fv(ans,
                   data.frame(istdres=with(ans, ires/isd)),
                   "bold(T)~hat(%s)[iso](r)",
                   "standardised isotropic-corrected residual %s",
                   "ires")
    fvnames(ans, ".") <- c(savedotnames, c("ihi", "ilo"))
  }
  unitname(ans) <- unitname(K)
  return(ans)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Kscaled.R"
#
#	Kscaled.R	Estimation of K function for locally-scaled process
#
#	$Revision: 1.15 $	$Date: 2014/11/10 10:41:18 $
#

"Lscaled" <- function(...) {
  K <- Kscaled(...)
  L <- eval.fv(sqrt(pmax.int(K,0)/pi))
  # relabel the fv object
  L <- rebadge.fv(L, quote(L[scaled](r)), c("L","scaled"))
  attr(L, "labl") <- attr(K, "labl")
  return(L)  
}

"Kscaled"<-
  function (X, lambda=NULL, ..., r = NULL, breaks = NULL,
            rmax = 2.5,
            correction=c("border", "isotropic", "translate"),
            renormalise=FALSE, normpower=1,
            sigma=NULL, varcov=NULL)
{
  verifyclass(X, "ppp")
#  rfixed <- !missing(r) || !missing(breaks)

  ## determine basic parameters
  W <- X$window
  npts <- X$n
  areaW <- area(W)
  halfdiameter <- diameter(W)/2
  
  ## match corrections
  correction.given <- !missing(correction) && !is.null(correction)
  correction <- pickoption("correction", correction,
                           c(none="none",
                             border="border",
                             isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             best="best"),
                           multi=TRUE)

#  best.wanted <- ("best" %in% correction)
  correction <- implemented.for.K(correction, W$type, correction.given)

  ###########################################################
  ## DETERMINE WEIGHTS AND VALIDATE
  ##

  if(missing(lambda)) {
    ## No intensity data provided
    ## Estimate density by leave-one-out kernel smoothing
    lambda <- density(X, ..., sigma=sigma, varcov=varcov,
                      at="points", leaveoneout=TRUE)
    lambda <- as.numeric(lambda)
  } else {
    ## lambda values provided
    if(is.im(lambda)) 
      lambda <- safelookup(lambda, X)
    else if(is.function(lambda)) 
      lambda <- lambda(X$x, X$y)
    else if(is.ppm(lambda)) 
      lambda <- safelookup(predict(lambda, type="trend"), X)
    else if(!is.numeric(lambda) || !is.null(dim(lambda)))
      stop(paste(sQuote("lambda"),
                 "should be a vector, a pixel image, a function or a ppm"))
    check.nvector(lambda, npts)
  }

  if(renormalise) {
    ## renormalise. Here we only need half the power ;-)
    check.1.real(normpower)
    stopifnot(normpower %in% 1:2) 
    renorm.factor <- (areaW/sum(1/lambda))^(normpower/2)
    lambda <- lambda/renorm.factor
  }     
  ## Calculate range of r values using max lambda
  sra <- sqrt(range(lambda))
  minrescale <- sra[1]
  maxrescale <- sra[2]

  ## convert arguments to absolute distances 
  absr <- if(!is.null(r)) r/maxrescale else NULL
  absrmaxdefault <- min(rmax.rule("K", W), rmax/maxrescale)
  absbreaks <-
    if(!is.null(breaks)) scalardilate(breaks, 1/maxrescale) else NULL
  ## determine absolute distances
  absbreaks <- handle.r.b.args(absr, absbreaks, W, rmaxdefault=absrmaxdefault)
  absr <- absbreaks$r
  ## convert to rescaled distances
  breaks <- scalardilate(absbreaks, maxrescale)
  r <- breaks$r
  rmax <- breaks$max
  ## recommended range of scaled r values
  alim <- c(0, min(rmax, maxrescale * absrmaxdefault))
  rthresh <- minrescale * halfdiameter
  ## maximum absolute distance ever needed
  maxabsdist <- min(rmax/minrescale, halfdiameter)
  
  ## this will be the output data frame
  K <- data.frame(r=r, theo= pi * r^2)
  desc <- c("distance argument r", "theoretical Poisson %s")
  K <- fv(K, "r", quote(K[scaled](r)),
          "theo", , alim,
          c("r","{%s[%s]^{pois}}(r)"),
          desc,
          fname=c("K", "scaled"))
        
  ## identify all relevant close pairs
  close <- closepairs(X, maxabsdist)
  I <- close$i
  J <- close$j
  ## locally-scaled distances
  sqrtLambda <- sqrt(lambda)
  lamIJ <- (sqrtLambda[I] + sqrtLambda[J])/2
  absDIJ <- close$d
  DIJ <- absDIJ * lamIJ

  XI <- ppp(close$xi, close$yi, window=W, check=FALSE)
  
  if(any(correction == "none")) {
    ## uncorrected! For demonstration purposes only!
    wh <- whist(DIJ, breaks$val)  # no weights
    Kun <- cumsum(wh)/npts
    K <- bind.fv(K, data.frame(un=Kun), "{hat(%s)[%s]^{un}}(r)",
                 "uncorrected estimate of %s",
                 "un")
  }
  
  if(any(correction == "border")) {
    ## border method
    ## Compute SCALED distances to boundary
    b <- bdist.points(X) * sqrtLambda
    bI <- b[I]
    ## apply reduced sample algorithm to scaled distances
    RS <- Kount(DIJ, bI, b, breaks)
    Kb <- RS$numerator/RS$denom.count
    Kb[r > rthresh] <- NA
    K <- bind.fv(K, data.frame(border=Kb), "{hat(%s)[%s]^{bord}}(r)",
                 "border-corrected estimate of %s",
                 "border")
  }

  if(any(correction == "translate")) {
    ## translation correction
    XJ <- ppp(close$xj, close$yj, window=W, check=FALSE)
    edgewt <- edge.Trans(XI, XJ, paired=TRUE)
    wh <- whist(DIJ, breaks$val, edgewt)
    Ktrans <- cumsum(wh)/npts
    Ktrans[r >= rthresh] <- NA
    K <- bind.fv(K, data.frame(trans=Ktrans), "{hat(%s)[%s]^{trans}}(r)",
                 "translation-corrected estimate of %s",
                 "trans")
  }
  if(any(correction == "isotropic")) {
    ## Ripley isotropic correction (using UN-SCALED distances)
    edgewt <- edge.Ripley(XI, matrix(absDIJ, ncol=1))
    wh <- whist(DIJ, breaks$val, edgewt)
    Kiso <- cumsum(wh)/npts
    Kiso[r >= rthresh] <- NA
    K <- bind.fv(K, data.frame(iso=Kiso), "{hat(%s)[%s]^{iso}}(r)",
                 "Ripley isotropic correction estimate of %s",
                 "iso")
  }
  ## default plot will display all edge corrections
  formula(K) <- . ~ r
  nama <- rev(colnames(K))
  fvnames(K, ".") <- nama[!(nama %in% c("r", "rip", "ls"))]
  ##
  unitname(K) <- c("normalised unit", "normalised units")
  return(K)
}
	
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Ksector.R"
#
#	Ksector.R	Estimation of 'sector K function'
#
#	$Revision: 1.5 $	$Date: 2014/11/10 10:41:14 $
#

Ksector <- function(X, begin=0, end=360, ...,
                    units=c("degrees", "radians"),
                    r=NULL, breaks=NULL, 
                    correction=c("border", "isotropic", "Ripley", "translate"),
                    domain = NULL,
                    ratio=FALSE, verbose=TRUE)
{
  verifyclass(X, "ppp")
#  rfixed <- !is.null(r) || !is.null(breaks)
  npts <- npoints(X)
  W <- Window(X)
  areaW <- area(W)
  lambda <- npts/areaW
  lambda2 <- (npts * (npts - 1))/(areaW^2)
  rmaxdefault <- rmax.rule("K", W, lambda)        
  breaks <- handle.r.b.args(r, breaks, W, rmaxdefault=rmaxdefault)
  r <- breaks$r
  rmax <- breaks$max
  
  if(!is.null(domain)) {
    domain <- as.owin(domain)
    stopifnot(is.subset.owin(domain, Window(X)))
    areaW <- area(domain)
  }

  units <- match.arg(units)
  switch(units,
         radians = {
           if(missing(end)) end <- 2 * pi
           check.1.real(begin)
           check.1.real(end)
           check.in.range(begin, c(-pi, 2*pi))
           check.in.range(end, c(0, 2*pi))
           stopifnot(begin < end)
           stopifnot((end - begin) <= 2 * pi)
           BEGIN <- begin
           END   <- end
           Bname <- simplenumber(begin/pi, "pi") %orifnull% signif(begin, 3)
           Ename <- simplenumber(end/pi, "pi") %orifnull% signif(end, 3)
         },
         degrees = {
           check.1.real(begin)
           check.1.real(end)
           check.in.range(begin, c(-90, 360))
           check.in.range(end, c(0, 360))
           stopifnot(begin < end)
           stopifnot((end - begin) <= 360)
           if(verbose && (end - begin) <= 2 * pi)
             warning("Very small interval in degrees: did you mean radians?")
           BEGIN <- pi* (begin/180)
           END   <- pi * (end/180)
           Bname <- signif(begin, 3)
           Ename <- signif(end, 3)
         })
  ## choose correction(s)
  correction.given <- !missing(correction) && !is.null(correction)
  if(is.null(correction))
    correction <- c("border", "isotropic", "Ripley", "translate")
  correction <- pickoption("correction", correction,
                           c(none="none",
                             border="border",
                             "bord.modif"="bord.modif",
                             isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             good="good",
                             best="best"),
                           multi=TRUE)
#  best.wanted <- ("best" %in% correction)
  ## replace 'good' by the optimal choice for this size of dataset
  if("good" %in% correction)
    correction[correction == "good"] <- good.correction.K(X)
  ## retain only corrections that are implemented for the window
  correction <- implemented.for.K(correction, W$type, correction.given)
  
  ## recommended range of r values
  alim <- c(0, min(rmax, rmaxdefault))

  ## labels
  subscripts <- paste("sector", Bname, Ename, sep=",")
  ylabel <- paste("K[", subscripts, "]")
  ylab <-  eval(parse(text=paste("quote(", ylabel, ")")))
#  ylab <-  parse(text=paste("K[sector,", Bname, ",", Ename, "]"))
#  yexp <- substitute(K[list(sector,B,E)](r),
#                     list(B=Bname, E=Ename))
  yexp <-  parse(text=paste("K[list(", subscripts, ")]"))
  fname <- c("K", paste("list", paren(subscripts)))
  
  ## this will be the output data frame
  Kdf <- data.frame(r=r, theo = ((END-BEGIN)/2) * r^2)
  desc <- c("distance argument r", "theoretical Poisson %s")
  denom <- lambda2 * areaW
  K <- ratfv(Kdf, NULL, denom,
             "r",
             ylab = ylab,
             valu = "theo",
             fmla = NULL,
             alim =alim,
             labl = c("r","{%s[%s]^{pois}}(r)"),
             desc = desc,
             fname=fname, yexp=yexp, 
             ratio=ratio)
  
  ## identify all close pairs
  rmax <- max(r)
  close <- as.data.frame(closepairs(X, rmax))

  if(!is.null(domain)) {
    ## restrict to pairs with first point in 'domain'
    indom <- with(close, inside.owin(xi, yi, domain))
    close <- close[indom, , drop=FALSE]
  }

  ## select pairs in angular range
  ang <- with(close, atan2(dy, dx)) %% (2*pi)
  if(BEGIN >= 0) {
    ## 0 <= begin < end
    ok <- (BEGIN <= ang) & (ang <= END)
  } else {
    ## begin < 0 <= end
    ok <- (ang >= 2 * pi + BEGIN) | (ang <= END)
  }
  close <- close[ok, , drop=FALSE]

  ## pairwise distances
  DIJ <- close$d

  if(any(correction == "none")) {
    # uncorrected! For demonstration purposes only!
    wh <- whist(DIJ, breaks$val)  # no weights
    numKun <- cumsum(wh)
    denKun <- lambda2 * areaW
    # uncorrected estimate of K
    K <- bind.ratfv(K,
                    data.frame(un=numKun), denKun,
                    "{hat(%s)[%s]^{un}}(r)",
                    "uncorrected estimate of %s",
                    "un",
                    ratio=ratio)
  }
  
  if(any(correction == "border" | correction == "bord.modif")) {
  # border method
  # Compute distances to boundary
    b <- bdist.points(X)
    I <- close$i
    bI <- b[I]
    if(!is.null(domain))
      b <- b[inside.owin(X, , w=domain)]
  # apply reduced sample algorithm
    RS <- Kount(DIJ, bI, b, breaks)
    if(any(correction == "bord.modif")) {
      # modified border correction
      denom.area <- eroded.areas(W, r, subset=domain)
      numKbm <- RS$numerator
      denKbm <- lambda2 * denom.area
      K <- bind.ratfv(K,
                      data.frame(bord.modif=numKbm),
                      data.frame(bord.modif=denKbm),
                      "{hat(%s)[%s]^{bordm}}(r)",
                      "modified border-corrected estimate of %s",
                      "bord.modif",
                      ratio=ratio)
    }
    if(any(correction == "border")) {
      numKb <- RS$numerator
      denKb <- lambda * RS$denom.count
      K <- bind.ratfv(K,
                      data.frame(border=numKb), 
                      data.frame(border=denKb), 
                      "{hat(%s)[%s]^{bord}}(r)",
                      "border-corrected estimate of %s",
                      "border",
                      ratio=ratio)
    }
  }

  if(any(correction == "translate")) {
    ## Ohser-Stoyan translation correction
    edgewt <- edge.Trans(dx=close$dx, dy=close$dy, W=W, paired=TRUE)
    wh <- whist(DIJ, breaks$val, edgewt)
    numKtrans <- cumsum(wh)
    denKtrans <- lambda2 * areaW
    h <- diameter(as.rectangle(W))/2
    numKtrans[r >= h] <- NA
    K <- bind.ratfv(K,
                    data.frame(trans=numKtrans),
                    denKtrans,
                    "{hat(%s)[%s]^{trans}}(r)",
                    "translation-corrected estimate of %s",
                    "trans",
                    ratio=ratio)
  }
  if(any(correction == "isotropic")) {
    ## Ripley isotropic correction
    XI <- ppp(close$xi, close$yi, window=W, check=FALSE)
    edgewt <- edge.Ripley(XI, matrix(DIJ, ncol=1))
    wh <- whist(DIJ, breaks$val, edgewt)
    numKiso <- cumsum(wh)
    denKiso <- lambda2 * areaW
    h <- diameter(W)/2
    numKiso[r >= h] <- NA
    K <- bind.ratfv(K,
                 data.frame(iso=numKiso),
                 denKiso,
                 "{hat(%s)[%s]^{iso}}(r)",
                 "Ripley isotropic correction estimate of %s",
                 "iso",
                 ratio=ratio)
  }
  #
  # default plot will display all edge corrections
  formula(K) <- . ~ r
  nama <- rev(colnames(K))
  nama <- nama[!(nama %in% c("r", "rip", "ls"))]
  fvnames(K, ".") <- nama
  unitname(K) <- unitname(X)
  # copy to other components
  if(ratio)
    K <- conform.ratfv(K)

  return(K)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Math.im.R"
##
##   Math.im.R
##
##   $Revision: 1.2 $ $Date: 2014/11/10 03:46:52 $
##

Ops.im <- function(e1,e2=NULL){
    unary <- nargs() == 1L
    if(unary){
        if(!is.element(.Generic, c("!", "-", "+")))
            stop("Unary usage is undefined for this operation for images.")
        callstring <- paste(.Generic, "e1")
    } else{
        callstring <- paste("e1", .Generic, "e2")
        expr <- parse(text = callstring)
    }
    return(do.call(eval.im, list(expr = expr)))
}

Math.im <- function(x, ...){
    m <- do.call(.Generic, list(x[,,drop=FALSE], ...))
    rslt <- im(m, xcol = x$xcol, yrow = x$yrow, xrange = x$xrange,
               yrange = x$yrange, unitname = unitname(x))
    return(rslt)
}

Summary.im <- function(..., na.rm){
    args <- list(...)
    args <- lapply(args, as.matrix)
    do.call(.Generic, c(args, na.rm = na.rm))
}

Complex.im <- function(z){
    m <- do.call(.Generic, list(z=z[drop=TRUE]))
    rslt <- im(m, xcol = z$xcol, yrow = z$yrow, xrange = z$xrange,
               yrange = z$yrange, unitname = unitname(z))
    return(rslt)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/Tstat.R"
#
#	tstat.R		Estimation of T function
#
#	$Revision: 1.8 $	$Date: 2014/10/24 00:22:30 $
#

Tstat <- local({
  
  # helper functions
  edgetri.Trans <- function(X, triid, trim=spatstat.options("maxedgewt")) {
    triid <- as.matrix(triid)
    ntri <- nrow(triid)
    if(ntri == 0) return(numeric(0))
    W <- rescue.rectangle(as.owin(X))
    if(W$type != "rectangle")
      stop("Translation correction is only implemented for rectangular windows")
    x <- matrix(X$x[triid], nrow=ntri)
    y <- matrix(X$y[triid], nrow=ntri)
    dx <- apply(x, 1, function(z) diff(range(z)))
    dy <- apply(y, 1, function(z) diff(range(z)))
    wide <- diff(W$xrange)
    high <- diff(W$yrange)
    weight <- wide * high/((wide - dx) * (high - dy))
    weight <- pmin.int(trim, weight)
    return(weight)
  }
  # helper function
  implemented.for.T <- function(correction, windowtype, explicit) {
    rect <- (windowtype == "rectangle")
    if(any(correction == "best")) {
      # select best available correction
      correction <- if(rect) "translate" else "border"
    } else {
      # available selection of edge corrections depends on window
      if(!rect) {
        tra <- (correction == "translate") 
        if(any(tra)) {
          whinge <- "Translation correction is only implemented for rectangular windows"
          if(explicit) {
            if(all(tra)) stop(whinge) else warning(whinge)
          }
          correction <- correction[!tra]
        }
      }
    }
    return(correction)
  }
  # .......... main function ....................
  Tstat <- function(X, ..., r=NULL, rmax=NULL,
                    correction=c("border", "translate"),
                    ratio=FALSE,
                    verbose=TRUE)
    {
      verifyclass(X, "ppp")
#      rfixed <- !is.null(r) 
      npts <- npoints(X)
      W <- Window(X)
      areaW <- area(W)
      lambda <- npts/areaW
      lambda2 <- (npts * (npts - 1))/(areaW^2)
      lambda3 <- (npts * (npts - 1) * (npts - 2))/(areaW^3)

      rmaxdefault <- if(!is.null(rmax)) rmax else rmax.rule("K", W, lambda)
      breaks <- handle.r.b.args(r, NULL, W, rmaxdefault=rmaxdefault)
      r <- breaks$r
      rmax <- breaks$max

      # choose correction(s)
      correction.given <- !missing(correction) && !is.null(correction)
      if(!correction.given)
        correction <- c("border", "bord.modif", "translate")
      correction <- pickoption("correction", correction,
                               c(none="none",
                                 border="border",
                                 "bord.modif"="bord.modif",
                                 trans="translate",
                                 translate="translate",
                                 translation="translate",
                                 best="best"),
                               multi=TRUE)
      correction <- implemented.for.T(correction, W$type, correction.given)
  
      # recommended range of r values
      alim <- c(0, min(rmax, rmaxdefault))

      # this will be the output data frame
      TT <- data.frame(r=r, theo= (pi/2) * (pi - 3 * sqrt(3)/4) * r^4)
      desc <- c("distance argument r", "theoretical Poisson %s")
      TT <- fv(TT, "r", quote(T(r)),
               "theo", , alim, c("r","%s[pois](r)"), desc, fname="T")

      # save numerator and denominator?
      if(ratio) {
        denom <- lambda2 * areaW
        numT <- eval.fv(denom * TT)
        denT <- eval.fv(denom + TT * 0)
        attributes(numT) <- attributes(denT) <- attributes(T)
        attr(numT, "desc")[2] <- "numerator for theoretical Poisson %s"
        attr(denT, "desc")[2] <- "denominator for theoretical Poisson %s"
      }
  
      # identify all close pairs
      rmax <- max(r)
      close <- closepairs(X, rmax, ordered=FALSE)
      I <- close$i
      J <- close$j
      DIJ <- close$d

      nI <- length(I)
  
      # estimate computation time
      if(verbose) {
        nTmax <- nI * (nI-1) /2
        esttime <- exp(1.25 * log(nTmax) - 21.5)
        message(paste("Searching", nTmax, "potential triangles;",
                      "estimated time", codetime(esttime)))
      }

      # find triangles with their diameters
      tri <- trianglediameters(I, J, DIJ, nvert=npts)
      stopifnot(identical(colnames(tri), c("i", "j", "k", "diam")))
      # reassemble so each triangle appears 3 times, once for each vertex
      II <- with(tri, c(i, j, k))
      DD <- with(tri, rep.int(diam, 3))
  
      if(any(correction == "none")) {
        # uncorrected! For demonstration purposes only!
        wh <- whist(DD, breaks$val)  # no weights
        numTun <- cumsum(wh)
        denTun <- lambda3 * areaW
        # uncorrected estimate of T
        Tun <- numTun/denTun
        TT <- bind.fv(TT, data.frame(un=Tun), "hat(%s)[un](r)",
                      "uncorrected estimate of %s",
                      "un")
        if(ratio) {
          # save numerator and denominator
          numT <- bind.fv(numT, data.frame(un=numTun), "hat(%s)[un](r)",
                          "numerator of uncorrected estimate of %s",
                          "un")
          denT <- bind.fv(denT, data.frame(un=denTun), "hat(%s)[un](r)",
                          "denominator of uncorrected estimate of %s",
                          "un")
        }
      }
  
      if(any(correction == "border" | correction == "bord.modif")) {
      # border method
      # Compute distances to boundary
        b <- bdist.points(X)
        bI <- b[II]
      # apply reduced sample algorithm
        RS <- Kount(DD, bI, b, breaks)
        if(any(correction == "bord.modif")) {
          # modified border correction
          denom.area <- eroded.areas(W, r)
          numTbm <- RS$numerator
          denTbm <- lambda3 * denom.area
          Tbm <- numTbm/denTbm
          TT <- bind.fv(TT, data.frame(bord.modif=Tbm), "hat(%s)[bordm](r)",
                        "modified border-corrected estimate of %s",
                        "bord.modif")
          if(ratio) {
            # save numerator and denominator
            numT <- bind.fv(numT, data.frame(bord.modif=numTbm),
                            "hat(%s)[bordm](r)",
                      "numerator of modified border-corrected estimate of %s",
                            "bord.modif")
            denT <- bind.fv(denT, data.frame(bord.modif=denTbm),
                            "hat(%s)[bordm](r)",
                      "denominator of modified border-corrected estimate of %s",
                            "bord.modif")
          }
        }
        if(any(correction == "border")) {
          numTb <- RS$numerator
          denTb <- lambda2 * RS$denom.count
          Tb <- numTb/denTb
          TT <- bind.fv(TT, data.frame(border=Tb), "hat(%s)[bord](r)",
                        "border-corrected estimate of %s",
                        "border")
          if(ratio) {
            numT <- bind.fv(numT, data.frame(border=numTb), "hat(%s)[bord](r)",
                            "numerator of border-corrected estimate of %s",
                            "border")
            denT <- bind.fv(denT, data.frame(border=denTb), "hat(%s)[bord](r)",
                            "denominator of border-corrected estimate of %s",
                            "border")
          }
        }
      }

      if(any(correction == "translate")) {
        # translation correction
        # apply to triangle list
        edgewt <- edgetri.Trans(X, tri[, 1:3])
        wh <- whist(tri$diam, breaks$val, edgewt)
        numTtrans <- 3 * cumsum(wh)
        denTtrans <- lambda3 * areaW
        Ttrans <- numTtrans/denTtrans
        h <- diameter(W)/2
        Ttrans[r >= h] <- NA
        TT <- bind.fv(TT, data.frame(trans=Ttrans), "hat(%s)[trans](r)",
                      "translation-corrected estimate of %s",
                      "trans")
        if(ratio) {
          numT <- bind.fv(numT, data.frame(trans=numTtrans),
                          "hat(%s)[trans](r)",
                          "numerator of translation-corrected estimate of %s",
                          "trans")
          denT <- bind.fv(denT, data.frame(trans=denTtrans),
                          "hat(%s)[trans](r)",
                          "denominator of translation-corrected estimate of %s",
                          "trans")
        }
      }
      # default plot will display all edge corrections
      formula(TT) <- . ~ r
      unitname(TT) <- unitname(X)
      #
      if(ratio) {
        # finish up numerator & denominator
        formula(numT) <- formula(denT) <- . ~ r
        unitname(numT) <- unitname(denT) <- unitname(TT)
        # tack on to result
        TT <- rat(TT, numT, denT, check=FALSE)
      }
      return(TT)
    }
  
  Tstat
})



#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/aaaa.R"
#'
#'    aaaa.R
#'
#'   Code that must be read before the rest of the R code in spatstat
#' 
#'    $Revision: 1.4 $  $Date: 2014/12/10 10:34:53 $

#' ...................................................................
#'   intermaker:
#'   Class structure for functions like 'Strauss'
#'   so they print a nice description.
#'

intermaker <- function(f, blank) {
  # f is the creator function like 'Strauss'
  class(f) <- c("intermaker", class(f))
  # blank is the prototype interaction object: extract some fields
  desired <- c("creator", "name", "par", "parnames", "pardesc")
  avail <- desired[desired %in% names(blank)]
  attr(f, "b") <- blank[avail]
  return(f)
}

print.intermaker <- function(x, ...) {
  b <- attr(x, "b")
  argh <- names(formals(x))
  explain <- NULL
  if(length(argh) > 0) {
    desc <- b$pardesc %orifnull% b$parnames
    namep <- names(b$par)
    if(length(desc) == length(namep) && all(argh %in% namep)) {
      names(desc) <- namep
      explain <- paste(", where",
                       commasep(paste(sQuote(argh), "is the", desc[argh])))
    }
  }
  blah <- paste0("Function ",
                 b$creator,
                 paren(paste(argh, collapse=", ")), 
                 ": creates the interpoint interaction of the ",
                 b$name,
                 explain)
  splat(blah)
  return(invisible(NULL))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/adaptive.density.R"
#
#  adaptive.density.R
#
#  $Revision: 1.5 $   $Date: 2014/10/24 00:22:30 $
#
#

adaptive.density <- function(X, f=0.1, ..., nrep=1, verbose=TRUE) {
  stopifnot(is.ppp(X))
  npts <- npoints(X)
  stopifnot(is.numeric(f) && length(f) == 1 && f > 0 & f < 1)
  ntess <- floor(f * npts)
  if(ntess == 0) {
    # naive estimate of intensity
    if(verbose) cat("Tiny threshold: returning uniform intensity estimate")
    W <- X$window
    lam <- npts/area(W)
    return(as.im(lam, W, ...))
  }
  if(nrep > 1) {
    # estimate is the average of nrep randomised estimates
    total <- 0
    if(verbose) cat(paste("Computing", nrep, "intensity estimates..."))
    for(i in seq_len(nrep)) {
      estimate <- adaptive.density(X, f, ..., nrep=1)
      total <- eval.im(total + estimate)
      if(verbose) progressreport(i, nrep)
    }
    if(verbose) cat("Done.\n")
    average <- eval.im(total/nrep)
    return(average)
  }
  ncount <- npts - ntess
  fcount <- ncount/npts
  itess <- sample(seq_len(npts), ntess, replace=FALSE)
  Xtess <- X[itess]
  Xcount <- X[-itess]
  tes <- dirichlet(Xtess)
  meanintensity <- function(x) { x$n/area(x$window) }
  lam <- unlist(lapply(split(Xcount, tes), meanintensity))
  tesim <- as.im(tes, ...)
  out <- eval.im(lam[as.integer(tesim)]/fcount)
  return(out)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/addvar.R"
#
# addvar.R
#
# added variable plot
#
#   $Revision: 1.6 $  $Date: 2014/11/10 05:26:39 $
#


addvar <- function(model, covariate, ...,
                   subregion=NULL,
                   bw="nrd0", adjust=1,
                   from=NULL, to=NULL, n=512,
                   bw.input = c("points", "quad"),
                   bw.restrict = FALSE,
                   covname, crosscheck=FALSE) {  

  if(missing(covname))
    covname <- sensiblevarname(deparse(substitute(covariate)), "X")
  callstring <- paste(deparse(sys.call()), collapse = "")
  
  if(is.null(adjust)) adjust <- 1
  
  bw.input <- match.arg(bw.input)
  
  # validate model
  stopifnot(is.ppm(model))
  if(is.null(getglmfit(model)))
    model <- update(model, forcefit=TRUE)
  modelcall <- model$callstring
  if(is.null(modelcall))
    modelcall <- model$call
  
  # extract spatial locations
  Q <- quad.ppm(model)
#  datapoints <- Q$data
  quadpoints <- union.quad(Q)
  Z <- is.data(Q)
  wts <- w.quad(Q)
  nQ <- n.quad(Q)
  # fitted intensity
  lam <- fitted(model, type="trend")
  # subset of quadrature points used to fit model
  subQset <- getglmsubset(model)
  if(is.null(subQset)) subQset <- rep.int(TRUE, nQ)
  # restriction to subregion
  insubregion <- if(!is.null(subregion)) {
    inside.owin(quadpoints, w=subregion)
  } else rep.int(TRUE, nQ)

  ################################################################
  # Pearson residuals from point process model

  yr <- residuals(model, type="Pearson")
  yresid <- with(yr, "increment")
  # averaged (then sum with weight 'wts')
  yresid <- yresid/wts

  #################################################################
  # Covariates
  #
  # covariate data frame
  df <- getglmdata(model)
  if(!all(c("x", "y") %in% names(df))) {
    xy <- as.data.frame(quadpoints)
    notxy <- !(colnames(df) %in% c("x", "y"))
    other <- df[, notxy]
    df <- cbind(xy, other)
  }
  #
  avail.covars <- names(df)
  # covariates used in model 
  used.covars   <- model.covariates(model)
  fitted.covars <- model.covariates(model, offset=FALSE)
  #
  #################################################################
  # identify the covariate
  #
  if(!is.character(covariate)) {
    # Covariate is some kind of data, treated as external covariate
    if(covname %in% fitted.covars)
      stop(paste("covariate named", dQuote(covname),
                 "is already used in model"))
    covvalues <- evalCovariate(covariate, quadpoints)
    # validate covvalues
    if(is.null(covvalues))
      stop("Unable to extract covariate values")
    else if(length(covvalues) != npoints(quadpoints))
      stop(paste("Internal error: number of covariate values =",
                 length(covvalues), "!=", npoints(quadpoints),
                 "= number of quadrature points"))
    # tack onto data frame
    covdf <- data.frame(covvalues)
    names(covdf) <- covname
    df <- cbind(df, covdf)
  } else {
    # Argument is name of covariate
    covname <- covariate
    if(length(covname) > 1)
      stop("Must specify only one covariate")
    #
    if(covname %in% fitted.covars)
      stop(paste("covariate", dQuote(covname), "already used in model"))
    #
    if(!(covname %in% avail.covars))
      stop(paste("covariate", dQuote(covname), "not available"))
    # 
    covvalues <- df[, covname]
  }
  
  ################################################################
  # Pearson residuals from weighted linear regression of new covariate on others

  rhs <- formula(model)
  fo <- as.formula(paste(covname, paste(rhs, collapse=" ")))

  fit <- lm(fo, data=df, weights=lam * wts)
  xresid <- residuals(fit, type="pearson")/sqrt(wts)

  if(crosscheck) {
    message("Cross-checking...")
    X <- model.matrix(fo, data=df)
    V <- diag(lam * wts)
    sqrtV <- diag(sqrt(lam * wts))
    Info <- t(X) %*% V %*% X
    H <- sqrtV %*% X  %*% solve(Info) %*% t(X) %*% sqrtV
    nQ <- length(lam)
    Id <- diag(1, nQ, nQ)
    xresid.pearson <- (Id - H) %*% sqrtV %*% covvalues
    xresid.correct <- xresid.pearson/sqrt(wts)
    abserr <- max(abs(xresid - xresid.correct), na.rm=TRUE)
    relerr <- abserr/diff(range(xresid.correct, finite=TRUE))
    if(is.finite(relerr) && relerr > 0.01) {
      warning("Large relative error in residual computation")
    }
    message("Done.")
  }
  # experiment suggests residuals(fit, "pearson") == xresid.correct
  # and residuals(fit) equivalent to
  # covvalues - X  %*% solve(t(X) %*% V %*% X) %*% t(X) %*% V %*% covvalues

  #################################################################
  # check for NA's etc

  # locations that must have finite values 
  operative <- if(bw.restrict) insubregion & subQset else subQset
 
  nbg <- !is.finite(xresid) |  !is.finite(yresid)
  if(any(offending <- nbg & operative)) {
    warning(paste(sum(offending), "out of", length(offending),
                  "covariate values discarded because",
                  ngettext(sum(offending), "it is", "they are"),
                  "NA or infinite"))
  }
  #################################################################
  # Restrict data to 'operative' points
  #                            with finite values

  ok <- !nbg & operative
  Q           <- Q[ok]
  xresid      <- xresid[ok]
  yresid      <- yresid[ok]
  covvalues   <- covvalues[ok]
  df          <- df[ok, ]
  lam         <- lam[ok]
  wts         <- wts[ok]
  Z           <- Z[ok]
  insubregion <- insubregion[ok]

  ####################################################
  # assemble data for smoothing 
  xx <- xresid
  yy <- yresid
  ww <- wts
  if(makefrom <- is.null(from))
    from <- min(xresid)
  if(maketo <- is.null(to))
    to   <- max(xresid)
  
  ####################################################
  # determine smoothing bandwidth
  #     from 'operative' data

  switch(bw.input,
          quad = {
           # bandwidth selection from covariate values at all quadrature points
           numer <- unnormdensity(xx, weights=yy * ww,
                                  bw=bw, adjust=adjust,
                                  n=n,from=from,to=to, ...)
           sigma <- numer$bw
         },
         points= {
           # bandwidth selection from covariate values at data points
           fake <- unnormdensity(xx[Z], weights=1/lam[Z],
                                 bw=bw, adjust=adjust,
                                 n=n,from=from,to=to, ...)
           sigma <- fake$bw
           numer <- unnormdensity(xx, weights=yy * ww,
                                  bw=sigma, adjust=1,
                                  n=n,from=from,to=to, ...)
         })

 ####################################################
  # Restrict data and recompute numerator if required

  if(!is.null(subregion) && !bw.restrict) {
    # Bandwidth was computed on all data
    # Restrict to subregion and recompute numerator
    xx   <- xx[insubregion]
    yy   <- yy[insubregion]
    ww   <- ww[insubregion]
    lam  <- lam[insubregion]
    Z    <- Z[insubregion]
    if(makefrom) from <- min(xx)
    if(maketo)     to <- max(xx)
    numer <- unnormdensity(xx, weights=yy * ww,
                           bw=sigma, adjust=1,
                           n=n,from=from,to=to, ...)
  }

 ####################################################
  # Compute denominator
  denom <- unnormdensity(xx,weights=ww,
                           bw=sigma, adjust=1,
                           n=n,from=from,to=to, ...)

  ####################################################
  # Determine recommended plot range

  xr <- range(xresid[Z], finite=TRUE)
  alim <- xr + 0.1 * diff(xr) * c(-1,1)
  alim <- intersect.ranges(alim, c(from, to))
  
  ####################################################
  # Compute terms 

  interpolate <- function(x,y) {
    if(inherits(x, "density") && missing(y))
      approxfun(x$x, x$y, rule=2)
    else 
      approxfun(x, y, rule=2)
  }
  numfun <- interpolate(numer)
  denfun <- interpolate(denom)
  xxx <- numer$x
  ratio <- function(y, x) { ifelseXB(x != 0, y/x, NA) }
  yyy <- ratio(numfun(xxx), denfun(xxx))
  # Null variance estimation
  # smooth with weight 1 and smaller bandwidth
  tau <- sigma/sqrt(2)
  varnumer <- unnormdensity(xx,weights=ww,
                            bw=tau,adjust=1,
                            n=n,from=from,to=to, ...)
  varnumfun <- interpolate(varnumer)
  vvv <- ratio(varnumfun(xxx), 2 * sigma * sqrt(pi) * denfun(xxx)^2)
  safesqrt <- function(x) {
    ok <- is.finite(x) & (x >= 0)
    y <- rep.int(NA_real_, length(x))
    y[ok] <- sqrt(x[ok])
    return(y)
  }
  twosd <- 2 * safesqrt(vvv)
  # pack into fv object
  rslt <- data.frame(rcov=xxx, rpts=yyy, theo=0, var=vvv, hi=twosd, lo=-twosd)
  nuc <- length(used.covars)
  if(nuc == 0) {
    given <- givenlab <- 1
  } else if(nuc == 1) {
    given <- givenlab <- used.covars
  } else {
    given <- commasep(used.covars, ", ")
    givenlab <- paste("list", paren(given))
  }
  given <- paste("|", given)
  xlab <- sprintf("r(paste(%s, '|', %s))", covname, givenlab)
  ylab <- sprintf("r(paste(points, '|', %s))", givenlab)
  yexpr <- parse(text=ylab)[[1]]
  desc <- c(paste("Pearson residual of covariate", covname, given),
            paste("Smoothed Pearson residual of point process", given),
            "Null expected value of point process residual",
            "Null variance of point process residual",
            "Upper limit of pointwise 5%% significance band",
            "Lower limit of pointwise 5%% significance band")
  rslt <- fv(rslt,
             argu="rcov",
             ylab=yexpr,
             valu="rpts",
             fmla= (. ~ rcov),
             alim=alim,
             labl=c(xlab,
                    "%s",
                    "0",
                    "bold(var) ~ %s",
                    "%s[hi]",
                    "%s[lo]"),
             desc=desc,
             fname=ylab)
  attr(rslt, "dotnames") <- c("rpts", "theo", "hi", "lo")
  # data associated with quadrature points
  reserved <- (substr(colnames(df), 1, 4) == ".mpl")
  isxy <- colnames(df) %in% c("x", "y")
  dfpublic <- cbind(df[, !(reserved | isxy)], data.frame(xresid, yresid))
  attr(rslt, "spatial") <- union.quad(Q) %mark% dfpublic
  # auxiliary data
  attr(rslt, "stuff") <- list(covname     = covname,
                              xresid      = xresid,
                              yresid      = yresid,
                              covvalues   = covvalues,
                              wts         = wts,
                              bw          = bw,
                              adjust      = adjust,
                              sigma       = sigma,
                              used.covars = used.covars,
                              modelcall   = modelcall,
                              callstring  = callstring,
                              xlim        = c(from, to),
                              xlab        = xlab,
                              ylab        = ylab,
                              lmcoef      = coef(fit),
                              bw.input    = bw.input,
                              bw.restrict = bw.restrict,
                              restricted  = !is.null(subregion))
  # finish
  class(rslt) <- c("addvar", class(rslt))
  return(rslt)
}

print.addvar <- function(x, ...) {
  cat("Added variable plot diagnostic (class addvar)\n")
  s <- attr(x, "stuff")
  mc <- paste(s$modelcall, collapse="")
  cat(paste("for the covariate", dQuote(s$covname),
            "for the fitted model:",
            if(nchar(mc) <= 30) "" else "\n\t",
            mc, "\n\n"))
  if(identical(s$restricted, TRUE))
    cat("\t--Diagnostic computed for a subregion--\n")
   cat(paste("Call:", s$callstring, "\n"))
  cat(paste("Actual smoothing bandwidth sigma =", signif(s$sigma,5),
                    "\n\n"))
  NextMethod("print")
}

plot.addvar <- function(x, ..., do.points=FALSE) {
  xname <- deparse(substitute(x))
  s <- attr(x, "stuff")
#  covname <- s$covname
  xresid <- s$xresid
  yresid <- s$yresid
  # adjust y limits if intending to plot points as well
  ylimcover <- if(do.points) range(yresid, finite=TRUE) else NULL
  #
  do.call("plot.fv", resolve.defaults(list(x), list(...),
                                      list(main=xname,
                                           shade=c("hi", "lo"),
                                           legend=FALSE,
                                           ylim.covers=ylimcover)))
  # plot points
  if(do.points)
    do.call(points,
            resolve.defaults(list(x=xresid, y=yresid),
                             list(...),
                             list(pch=3, cex=0.5)))
  return(invisible(x))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/affine.R"
#
#	affine.R
#
#	$Revision: 1.47 $	$Date: 2014/10/24 00:22:30 $
#

affinexy <- function(X, mat=diag(c(1,1)), vec=c(0,0), invert=FALSE) {
  if(length(X$x) == 0 && length(X$y) == 0)
    return(list(x=numeric(0),y=numeric(0)))
  if(invert) {
    mat <- invmat <- solve(mat)
    vec <- - as.numeric(invmat %*% vec)
  }
  # Y = M X + V
  ans <- mat %*% rbind(X$x, X$y) + matrix(vec, nrow=2, ncol=length(X$x))
  return(list(x = ans[1,],
              y = ans[2,]))
}

affinexypolygon <- function(p, mat=diag(c(1,1)), vec=c(0,0),
                             detmat=det(mat)) {
  # transform (x,y)
  p[c("x","y")] <- affinexy(p, mat=mat, vec=vec)
  # transform area
  if(!is.null(p$area))
    p$area <- p$area * detmat
  # if map has negative sign, cyclic order was reversed; correct it
  if(detmat < 0)
    p <- reverse.xypolygon(p, adjust=TRUE)
  return(p)
}
       
"affine" <- function(X, ...) {
  UseMethod("affine")
}

"affine.owin" <- function(X,  mat=diag(c(1,1)), vec=c(0,0), ...,
                          rescue=TRUE) {
  verifyclass(X, "owin")
  vec <- as2vector(vec)
  if(!is.matrix(mat) || any(dim(mat) != c(2,2)))
    stop(paste(sQuote("mat"), "should be a 2 x 2 matrix"))
  # Inspect the determinant
  detmat <- det(mat)
  if(abs(detmat) < .Machine$double.eps)
    stop("Matrix of linear transformation is singular")
  #
  diagonalmatrix <- all(mat == diag(diag(mat)))
  scaletransform <- diagonalmatrix && (length(unique(diag(mat))) == 1)
  newunits <- if(scaletransform) unitname(X) else as.units(NULL)
  #
  switch(X$type,
         rectangle={
           if(diagonalmatrix) {
             # result is a rectangle
             Y <- owin(range(mat[1,1] * X$xrange + vec[1]),
                       range(mat[2,2] * X$yrange + vec[2]))
             unitname(Y) <- newunits
             return(Y)
           } else {
             # convert rectangle to polygon
             P <- as.polygonal(X)
             # call polygonal case
             return(affine.owin(P, mat, vec, rescue=rescue))
           }
         },
         polygonal={
           # Transform the polygonal boundaries
           bdry <- lapply(X$bdry, affinexypolygon, mat=mat, vec=vec,
                          detmat=detmat)
           # Compile result
           W <- owin(poly=bdry, check=FALSE, unitname=newunits)
           # Result might be a rectangle: if so, convert to rectangle type
           if(rescue)
             W <- rescue.rectangle(W)
           return(W)
         },
         mask={
           # binary mask
           newframe <- boundingbox(affinexy(corners(X), mat, vec))
           W <- if(length(list(...)) > 0) as.mask(newframe, ...) else 
                   as.mask(newframe, eps=with(X, min(xstep, ystep)))
           pixelxy <- rasterxy.mask(W)
           xybefore <- affinexy(pixelxy, mat, vec, invert=TRUE)
           W$m[] <- with(xybefore, inside.owin(x, y, X))
           W <- intersect.owin(W, boundingbox(W))
           if(rescue)
             W <- rescue.rectangle(W)
           return(W)
         },
         stop("Unrecognised window type")
         )
}

"affine.ppp" <- function(X, mat=diag(c(1,1)), vec=c(0,0), ...) {
  verifyclass(X, "ppp")
  vec <- as2vector(vec)
  r <- affinexy(X, mat, vec)
  w <- affine.owin(X$window, mat, vec, ...)
  return(ppp(r$x, r$y, window=w, marks=marks(X, dfok=TRUE), check=FALSE))
}

"affine.im" <- function(X,  mat=diag(c(1,1)), vec=c(0,0), ...) {
  verifyclass(X, "im")
  vec <- as2vector(vec)
  if(!is.matrix(mat) || any(dim(mat) != c(2,2)))
    stop(paste(sQuote("mat"), "should be a 2 x 2 matrix"))
  # Inspect the determinant
  detmat <- det(mat)
  if(abs(detmat) < .Machine$double.eps)
    stop("Matrix of linear transformation is singular")
  #
  diagonalmatrix <- all(mat == diag(diag(mat)))
  scaletransform <- diagonalmatrix && (length(unique(diag(mat))) == 1)
  newunits <- if(scaletransform) unitname(X) else as.units(NULL)
  newpixels <- (length(list(...)) > 0)
  #
  if(diagonalmatrix && !newpixels) {
    # diagonal matrix: apply map to row and column locations
    v      <- X$v
    d      <- X$dim
    newbox <- affine(as.rectangle(X), mat=mat, vec=vec)
    xscale <- diag(mat)[1]
    yscale <- diag(mat)[2]
    xcol <- xscale * X$xcol + vec[1]
    yrow <- yscale * X$yrow + vec[2]
    if(xscale < 0) {
      # x scale is negative
      xcol <- rev(xcol)
      v <- v[, (d[2]:1)]
    }
    if(yscale < 0) {
      # y scale is negative
      yrow <- rev(yrow)
      v <- v[(d[1]:1), ]
    }
    Y <- im(v, xcol=xcol, yrow=yrow,
            xrange=newbox$xrange, yrange=newbox$yrange,
            unitname=newunits)
  } else {
    # general case
    # create box containing transformed image
    newframe <- boundingbox(affinexy(corners(X), mat, vec))
    W <- if(length(list(...)) > 0) as.mask(newframe, ...) else 
    as.mask(newframe, eps=with(X, min(xstep, ystep)))
    unitname(W) <- newunits
    # raster for transformed image
    naval <- switch(X$type,
                    factor= , 
                    integer = NA_integer_,
                    logical = as.logical(NA_integer_),
                    real = NA_real_,
                    complex = NA_complex_, 
                    character = NA_character_,
                    NA)
    Y <- as.im(W, value=naval)
    # preimages of pixels of transformed image
    xx <- as.vector(rasterx.im(Y))
    yy <- as.vector(rastery.im(Y))
    pre <- affinexy(list(x=xx, y=yy), mat, vec, invert=TRUE)
    # sample original image
    if(X$type != "factor") {
      Y$v[] <- lookup.im(X, pre$x, pre$y, naok=TRUE)
    } else {
      lab <- levels(X)
      lev <- seq_along(lab)
      Y$v[] <- lookup.im(eval.im(as.integer(X)), pre$x, pre$y, naok=TRUE)
      Y <- eval.im(factor(Y, levels=lev, labels=lab))
    }
  }
  return(Y)
}


### ---------------------- reflect ----------------------------------

reflect <- function(X) {
  UseMethod("reflect")
}

reflect.default <- function(X) { affine(X, mat=diag(c(-1,-1))) }

reflect.im <- function(X) {
  stopifnot(is.im(X))
  out <- with(X,
              list(v      = v[dim[1]:1, dim[2]:1],
                   dim    = dim,
                   xrange = rev(-xrange),
                   yrange = rev(-yrange),
                   xstep  = xstep,
                   ystep  = ystep,
                   xcol   = rev(-xcol),
                   yrow   = rev(-yrow),
                   type   = type,
                   units  = units))
  class(out) <- "im"
  return(out)
}

### ---------------------- shift ----------------------------------

"shift" <- function(X, ...) {
  UseMethod("shift")
}

shiftxy <- function(X, vec=c(0,0)) {
  if(is.null(vec)) {
    warning("Null displacement vector; treated as zero")
    return(X)
  }
  list(x = X$x + vec[1],
       y = X$y + vec[2])
}

shiftxypolygon <- function(p, vec=c(0,0)) {
  # transform (x,y), retaining other data
  p[c("x","y")] <- shiftxy(p, vec=vec)
  return(p)
}

"shift.owin" <- function(X,  vec=c(0,0), ..., origin=NULL) {
  verifyclass(X, "owin")
  if(!is.null(origin)) {
    if(!missing(vec))
      warning("argument vec ignored; overruled by argument origin")
    if(is.numeric(origin)) {
      locn <- origin
    } else if(is.character(origin)) {
      origin <- pickoption("origin", origin, c(centroid="centroid",
                                               midpoint="midpoint",
                                               bottomleft="bottomleft"))
      locn <- switch(origin,
                     centroid={ unlist(centroid.owin(X)) },
                     midpoint={ c(mean(X$xrange), mean(X$yrange)) },
                     bottomleft={ c(X$xrange[1], X$yrange[1]) })
    } else stop("origin must be a character string or a numeric vector")
    return(shift(X, -locn))
  }
  vec <- as2vector(vec)
  # Shift the bounding box
  X$xrange <- X$xrange + vec[1]
  X$yrange <- X$yrange + vec[2]
  switch(X$type,
         rectangle={
         },
         polygonal={
           # Shift the polygonal boundaries
           X$bdry <- lapply(X$bdry, shiftxypolygon, vec=vec)
         },
         mask={
           # Shift the pixel coordinates
           X$xcol <- X$xcol + vec[1]
           X$yrow <- X$yrow + vec[2]
           # That's all --- the mask entries are unchanged
         },
         stop("Unrecognised window type")
         )
  # tack on shift vector
  attr(X, "lastshift") <- vec
  # units are unchanged
  return(X)
}

"shift.ppp" <- function(X, vec=c(0,0), ..., origin=NULL) {
  verifyclass(X, "ppp")
  if(!is.null(origin)) {
    if(!missing(vec))
      warning("argument vec ignored; overruled by argument origin")
    if(is.numeric(origin)) {
      locn <- origin
    } else if(is.character(origin)) {
      origin <- pickoption("origin", origin, c(centroid="centroid",
                                               midpoint="midpoint",
                                               bottomleft="bottomleft"))
      W <- X$window
      locn <- switch(origin,
                     centroid={ unlist(centroid.owin(W)) },
                     midpoint={ c(mean(W$xrange), mean(W$yrange)) },
                     bottomleft={ c(W$xrange[1], W$yrange[1]) })
    } else stop("origin must be a character string or a numeric vector")
    vec <- -locn
  }
  vec <- as2vector(vec)
  # perform shift
  r <- shiftxy(X, vec)
  w <- shift.owin(X$window, vec)
  Y <- ppp(r$x, r$y, window=w, marks=marks(X, dfok=TRUE), check=FALSE)
  # tack on shift vector
  attr(Y, "lastshift") <- vec
  return(Y)
}

getlastshift <- function(X) {
  v <- attr(X, "lastshift")
  if(is.null(v))
    stop(paste("Internal error: shifted object of class",
               sQuote(as.character(class(X))[1]),
               "does not have \"lastshift\" attribute"),
         call.=FALSE)
  if(!(is.numeric(v) && length(v) == 2))
    stop("Internal error: \"lastshift\" attribute is not a vector",
         call.=FALSE)
  return(v)
}

putlastshift <- function(X, vec) {
  attr(X, "lastshift") <- vec
  return(X)
}


### ---------------------- scalar dilation ---------------------------------

scalardilate <- function(X, f, ...) {
  UseMethod("scalardilate")
}

scalardilate.default <- function(X, f, ...) {
  trap.extra.arguments(..., .Context="In scalardilate(X,f)")
  check.1.real(f, "In scalardilate(X,f)")
  stopifnot(is.finite(f) && f > 0)
  Y <- affine(X, mat=diag(c(f,f)))
  return(Y)
}

scalardilate.im <- scalardilate.owin <- scalardilate.psp <- scalardilate.ppp <-
  function(X, f, ..., origin=NULL) {
  trap.extra.arguments(..., .Context="In scalardilate(X,f)")
  check.1.real(f, "In scalardilate(X,f)")
  stopifnot(is.finite(f) && f > 0)
  if(!is.null(origin)) {
    X <- shift(X, origin=origin)
    negorig <- getlastshift(X)
  } else negorig <- c(0,0)
  Y <- affine(X, mat=diag(c(f, f)), vec = -negorig)
  return(Y)
}
  


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/allstats.R"
#
#
#   allstats.R
#
#   $Revision: 1.16 $   $Date: 2013/04/25 06:37:43 $
#
#
allstats <- function(pp, ..., dataname=NULL,verb=FALSE) {
#
# Function allstats --- to calculate the F, G, K, and J functions
# for an unmarked point pattern.
#
  verifyclass(pp,"ppp")
  if(is.marked(pp))
    stop("This function is applicable only to unmarked patterns.\n")

# estimate F, G and J 
  if(verb) cat("Calculating F, G, J ...")
  Jout <- do.call.matched("Jest",list(X=pp, ...))
  if(verb) cat("ok.\n")

# extract F, G and J
  Fout <- attr(Jout, "F")
  Gout <- attr(Jout, "G")
  attr(Jout, "F") <- NULL
  attr(Jout, "G") <- NULL
  fns <- list("F function"=Fout,
              "G function"=Gout,
              "J function"=Jout)

# compute second moment function K
  if(verb) cat("Calculating K function...")
  Kout <- do.call.matched("Kest", list(X=pp, ...))
  fns <- append(fns, list("K function"=Kout))
  if(verb) cat("done.\n")

# add title
  if(is.null(dataname))
    dataname <- short.deparse(substitute(pp))
  title <- paste("Four summary functions for ",
              	dataname,".",sep="")
  attr(fns, "title") <- title

#
  fns <- as.listof(fns)
  return(fns)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/alltypes.R"
#
#      alltypes.R
#
#   $Revision: 1.30 $   $Date: 2014/11/10 05:27:18 $
#
#
                                  
alltypes <- function(X, fun="K", ...,
                     dataname=NULL,verb=FALSE,envelope=FALSE) {
#
# Function 'alltypes' --- calculates a summary function for
# each type, or each pair of types, in a multitype point pattern
#
  if(is.ppp(X)) classname <- "ppp" else
  if(is.lpp(X)) classname <- "lpp" else
  stop("X should be a ppp or lpp object")
  
  if(is.null(dataname))
    dataname <- short.deparse(substitute(X))

# --------------------------------------------------------------------  
# First inspect marks

  if(!is.marked(X)) {
    nmarks <- 0
    marklabels <- ""
  } else {
    if(!is.multitype(X))
      stop("the marks must be a factor")
    # ensure type names are parseable (for mathematical labels)
    levels(marks(X)) <- make.parseable(levels(marks(X)))
    mks <- marks(X)
    ma <- levels(mks)
    nmarks <- length(ma)
    marklabels <- paste(ma)
  }

# ---------------------------------------------------------------------
# determine function name

  f.is.name <- is.name(substitute(fun))
  fname <-
    if(f.is.name)
      paste(as.name(substitute(fun)))
    else if(is.character(fun))
      fun
    else sQuote("fun") 

# ---------------------------------------------------------------------
# determine function to be called
  
  if(is.function(fun)) {
    estimator <- fun
  } else if(is.character(fun)) {
    # First try matching one of the standard abbreviations K, G etc
    estimator <- getSumFun(fun, classname, (nmarks > 0), fatal=FALSE)
    if(is.null(estimator))
      estimator <- get(fun, mode="function")
  } else 
      stop(paste(sQuote("fun"), "should be a function or a character string"))
  
# ------------------------------------------------------------------  
# determine how the function shall be called.
#
  indices.expected <- sum(c("i", "j") %in% names(formals(estimator)))

  apply.to.split   <- (indices.expected == 0 && nmarks > 1)
  if(apply.to.split)
    ppsplit <- split(X)
  
# --------------------------------------------------------------------  
# determine array dimensions and margin labels
  witch <-
    if(nmarks == 0)
      matrix(1, nrow=1, ncol=1, dimnames=list("",""))
    else if (nmarks == 1) 
      matrix(1, nrow=1, ncol=1, dimnames=list(marklabels, marklabels))
    else if(indices.expected != 2)
      matrix(1:nmarks, nrow=nmarks, ncol=1,
             dimnames=list(marklabels, ""))
    else 
      matrix(1:(nmarks^2),ncol=nmarks,nrow=nmarks, byrow=TRUE,
             dimnames=list(marklabels, marklabels))

  # ------------ start computing -------------------------------  
  # if computing envelopes, first generate simulated patterns
  # using undocumented feature of envelope()
  if(envelope) {
    L <- do.call("envelope",
                 resolve.defaults(
                                  list(X, fun=estimator),
                                  list(internal=list(eject="patterns")),
                                  list(...),
                                  list(verbose=verb)))
    intern <- attr(L, "internal")
  }

  # compute function array and build up 'fasp' object
  fns  <- list()
  k   <- 0

  for(i in 1:nrow(witch)) {
    Y <- if(apply.to.split) ppsplit[[i]] else X
    for(j in 1:ncol(witch)) {
      if(verb) cat("i =",i,"j =",j,"\n")
      currentfv <- 
        if(!envelope) 
          switch(1+indices.expected,
                 estimator(Y, ...),
                 estimator(Y, i=ma[i], ...),
                 estimator(Y, i=ma[i], j=ma[j], ...))
        else
          do.call("envelope",
                  resolve.defaults(
                                   list(Y, estimator),
                                   list(simulate=L, internal=intern),
                                   list(verbose=FALSE),
                                   list(...),
                                   list(Yname=dataname),
                                   switch(1+indices.expected,
                                          NULL,
                                          list(i=ma[i]),
                                          list(i=ma[i], j=ma[j]),
                                          NULL)))
      k <- k+1
      fns[[k]] <- as.fv(currentfv)
    }
  }

  # wrap up into 'fasp' object
  title <- paste(if(nmarks > 1) "array of " else NULL,
                 if(envelope) "envelopes of " else NULL,
                 fname,
                 if(nmarks <= 1) " function " else " functions ",
                 "for ", dataname, ".", sep="")
  
  rslt <- fasp(fns, which=witch,
               formulae=NULL,
               dataname=dataname,
               title=title,
               checkfv=FALSE)
  return(rslt)
}

# Lookup table for standard abbreviations of functions

getSumFun <- local({

  ftable <-
  rbind(
        data.frame(class="ppp", marked=FALSE,
                   abbrev=c("F", "G", "J", "K", "L", "pcf"),
                   full=c("Fest", "Gest", "Jest", "Kest", "Lest", "pcf"),
                   stringsAsFactors=FALSE),
        data.frame(class="ppp", marked=TRUE,
                   abbrev=c("F", "G", "J", "K", "L", "pcf"),
                   full=  c("Fest",
                     "Gcross", "Jcross", "Kcross", "Lcross",
                     "pcfcross"),
                   stringsAsFactors=FALSE),
        data.frame(class="lpp", marked=FALSE,
                   abbrev=c("K", "pcf"),
                   full=c("linearK", "linearpcf"),
                   stringsAsFactors=FALSE),
        data.frame(class="lpp", marked=TRUE,
                   abbrev=c("K", "pcf"),
                   full=c("linearKcross", "linearpcfcross"),
                   stringsAsFactors=FALSE)
        )

  getfun <- function(abbreviation, classname, ismarked, fatal=TRUE) {
    matches <- with(ftable,
                    which(abbrev == abbreviation &
                          class == classname &
                          marked == ismarked))
    if(length(matches) == 0) {
      if(!fatal)
        return(NULL)
      stop(paste("No match to function abbreviation",
                 sQuote(abbreviation),
                 "for class",
                 sQuote(classname)))
    }
    if(length(matches) > 1)
      stop("Ambiguous function name")
    fullname <- ftable$full[matches]
    get(fullname, mode="function")
  }

  getfun
})


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/anova.mppm.R"
#
# anova.mppm.R
#
# $Revision: 1.3 $ $Date: 2007/02/28 10:16:07 $
#

anova.mppm <- function(object, ..., test=NULL, override=FALSE) {

  # list of models
  objex <- append(list(object), list(...))

  # Check each model is an mppm object
  if(!all(unlist(lapply(objex, function(x) {inherits(x, "mppm")}))))
    stop(paste("Arguments must all be", sQuote("mppm"), "objects"))

  # Any non-Poisson models?
  if(!all(unlist(lapply(objex, is.poisson.mppm)))) {
    whinge <- paste("Some of the fitted models are not Poisson processes:",
                    "p-values are not supported by any theory")
    if(override)
      warning(whinge)
    else
      stop(whinge)
  }

  # All models fitted using same method?
  fitter <- unique(unlist(lapply(objex, function(x) { x$Fit$fitter })))
  if(length(fitter) > 1)
    stop(paste("Models are incompatible;",
               "they were fitted by different methods (",
               paste(fitter, collapse=", "), ")" ))

  
  # Extract fit objects 
  fitz <- lapply(objex, function(x) { x$Fit$FIT })

  # Finally do the appropriate ANOVA
  result <- do.call("anova", append(fitz, list(test=test, dispersion=1)))
  
  return(result)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/anova.ppm.R"
#
#   anova.ppm.R
#
#  $Revision: 1.17 $   $Date: 2014/12/09 02:39:39 $
#

anova.ppm <- function(object, ..., test=NULL, adjust=TRUE, warn=TRUE) {

  gripe <-
    if(warn) function(...) warning(paste(...), call.=FALSE) else
    function(...) NULL
  
  if(!is.null(test)) {
    test <- match.arg(test, c("Chisq", "LRT", "Rao", "F", "Cp"))
    if(!(test %in% c("Chisq", "LRT")))
      stop("test=", dQuote(test), "is not yet implemented")
  }

  ## trap outmoded usage
  argh <- list(...)
  if("override" %in% names(argh)) {
    gripe("Argument 'override' is superseded and was ignored")
    argh <- argh[-which(names(argh) == "override")]
  }
  
  ## list of models
  objex <- append(list(object), argh)
  if(!all(unlist(lapply(objex, is.ppm))))
    stop(paste("Arguments must all be", sQuote("ppm"), "objects"))

  ## non-Poisson models?
  pois <- all(unlist(lapply(objex, is.poisson.ppm)))

  ## handle anova for a single 'ippm' object  
  expandedfrom1 <- FALSE
  if(length(objex) == 1 && inherits(object, "ippm")) {
    ## we can't rely on anova.glm to get the df right in this case
    ## so we have to re-fit explicitly
    Terms <- drop.scope(object)
    if((nT <- length(Terms)) > 0) {
      ## generate models by adding terms sequentially
      objex <- vector(mode="list", length=nT+1)
      for(n in 1:nT) {
        ## model containing terms 1, ..., n-1
        fmla <- paste(". ~ . - ", paste(Terms[n:nT], collapse=" - "))
        fmla <- as.formula(fmla)
        objex[[n]] <- update(object, fmla)
      }
      ## full model
      objex[[nT+1]] <- object
      expandedfrom1 <- TRUE
    }
  }

  ## all models fitted by same method?
  fitmethod <- unique(unlist(lapply(objex, getElement, name="method")))
  if(length(fitmethod) > 1)
    stop(paste("Models were fitted by different methods",
               commasep(sQuote(fitmethod)), 
               "- comparison is not possible"))
  ## fitted by MPL or logistic?
  if(!(fitmethod %in% c("mpl", "logi")))
    stop(paste("Not implemented for models fitted by method=",
               sQuote(fitmethod)))
  logi <- (fitmethod == "logi")

  refitargs <- list()
  ## fitted to same quadscheme using same edge correction?
  if(length(objex) > 1) {
    ## same data? 
    datas <- lapply(objex, data.ppm)
    samedata <- all(sapply(datas[-1], identical, y=datas[[1]]))
    if(!samedata) stop("Models were fitted to different datasets")
    ## same dummy points?
    quads <- lapply(objex, quad.ppm)
    samequad <- all(sapply(quads[-1], identical, y=quads[[1]]))
    if(!samequad) {
      gripe("Models were re-fitted using a common quadrature scheme")
      sizes <- sapply(quads,
                      function(x) if(inherits(x, "quad")) n.quad(x) else 0)
      imax <- which.max(sizes)
      bigQ <- quads[[imax]]
      refitargs$Q <- bigQ
    }
    ## same edge correction?
    corrxn <- unique(sapply(objex, getElement, name="correction"))
    if(length(corrxn) > 1)
      stop(paste("Models were fitting using different edge corrections",
                 commasep(sQuote(corrxn))))
    if(corrxn == "border") {
      rbord <- unique(sapply(objex, getElement, name="rbord"))
      if(length(rbord) > 1) {
        gripe("Models were re-fitted using a common value of 'rbord'")
        refitargs$rbord <- max(rbord)
      }
    } 
    
    ## Extract glmfit objects 
    fitz <- lapply(objex, getglmfit)

    ## Any trivial models? (uniform Poisson)
    trivial <- unlist(lapply(fitz, is.null))
    if(any(trivial))
      refitargs$forcefit <- TRUE
    
    ## force all non-trivial models to be fitted using same method
    ## (all using GLM or all using GAM)
    isgam <- unlist(lapply(fitz, inherits, what="gam"))
    isglm <- unlist(lapply(fitz, inherits, what="glm"))
    usegam <- any(isgam)
    if(usegam && any(isglm)) {
      gripe("Models were re-fitted with use.gam=TRUE")
      refitargs$use.gam <- TRUE
      refitargs$forcefit <- TRUE
    }

    ## finally refit models
    if(length(refitargs) > 0)
      objex <- do.call(lapply, append(list(X=objex, FUN=update),
                                      refitargs))
  }
  
  ## If any models were fitted by ippm we need to correct the df
  if(any(unlist(lapply(objex, inherits, what="ippm")))) {
    nfree <- unlist(lapply(lapply(objex, logLik), attr, which="df"))
    ncanonical <- unlist(lapply(lapply(objex, coef), length))
    nextra <- nfree - ncanonical
    for(i in seq_along(fitz))
      if(nextra[i] != 0)
        fitz[[i]]$df.residual <- fitz[[i]]$df.residual - nextra[i]
  }
  
  ## Finally do the appropriate ANOVA
  fitz <- lapply(objex, getglmfit)
  result <- do.call("anova", append(fitz, list(test=test, dispersion=1)))

  ## Remove approximation-dependent columns 
  result[, "Resid. Df"] <- NULL
  result[, "Resid. Dev"] <- NULL

  ## edit header 
  if(!is.null(h <- attr(result, "heading"))) {
    ## remove .mpl.Y and .logi.Y from formulae if present
    h <- gsub(".mpl.Y", "", h)
    h <- gsub(".logi.Y", "", h)
    ## delete GLM information if present
    h <- gsub("Model: quasi, link: log", "", h)
    h <- gsub("Model: binomial, link: logit", "", h)
    h <- gsub("Response: ", "", h)
    ## remove blank lines (up to 4 consecutive blanks can occur)
    for(i in 1:5)
      h <- gsub("\n\n", "\n", h)
    if(length(objex) > 1 && length(h) > 1) {
      ## anova(mod1, mod2, ...)
      ## change names of models
      fmlae <- unlist(lapply(objex,
                             function(z) paste(as.expression(formula(z)))))
      intrx <- unlist(lapply(objex, function(z) as.interact(z)$creator))
      h[2] <- paste("Model",
                    paste0(1:length(objex), ":"),
                    fmlae,
                    "\t",
                    intrx,
                    collapse="\n")
    }
    ## Add explanation if we did the stepwise thing ourselves
    if(expandedfrom1)
      h <- c(h[1], "Terms added sequentially (first to last)\n", h[-1])
    ## Contract spaces in output if spatstat.options('terse') >= 2
    if(!waxlyrical('space'))
      h <- gsub("\n$", "", h)
    ## Put back
    attr(result, "heading") <- h
  }
  
  if(adjust && !pois) {
    ## issue warning, if not already given
    if(warn) warn.once("anovaAdjust",
                          "anova.ppm now computes the *adjusted* deviances",
                          "when the models are not Poisson processes.")
    ## Corrected pseudolikelihood ratio 
    nmodels <- length(objex)
    if(nmodels > 1) {
      cfac <- rep(1, nmodels)
      for(i in 2:nmodels) {
        a <- objex[[i-1]]
        b <- objex[[i]]
        df <- length(coef(a)) - length(coef(b))
        if(df > 0) {
          ibig <- i-1
          ismal <- i
        } else {
          ibig <- i
          ismal <- i-1
          df <- -df
        }
        bigger <- objex[[ibig]]
        smaller <- objex[[ismal]]
        if(df == 0) {
          gripe("Models", i-1, "and", i, "have the same dimension")
        } else {
          bignames <- names(coef(bigger))
          smallnames <- names(coef(smaller))
          injection <- match(smallnames, bignames)
          if(any(uhoh <- is.na(injection))) {
            gripe("Unable to match",
                  ngettext(sum(uhoh), "coefficient", "coefficients"),
                  commasep(sQuote(smallnames[uhoh])),
                  "of model", ismal, 
                  "to coefficients in model", ibig)
          } else {
            thetaDot <- 0 * coef(bigger)
            thetaDot[injection] <- coef(smaller)
            JH <- vcov(bigger, what="internals", new.coef=thetaDot)
            J   <- if(!logi) JH$Sigma else (JH$Sigma1log+JH$Sigma2log)
            H   <- if(!logi) JH$A1 else JH$Slog
            G   <- H%*%solve(J)%*%H
            if(df == 1) {
              cfac[i] <- H[-injection,-injection]/G[-injection,-injection]
            } else {
              Res <- residuals(bigger, type="score",
                               new.coef=thetaDot, drop=TRUE)
              U <- integral.msr(Res)
              Uo <- U[-injection]
              Uo <- matrix(Uo, ncol=1)
              Hinv <- solve(H)
              Ginv <- solve(G)
              Hoo <- Hinv[-injection,-injection, drop=FALSE]
              Goo <- Ginv[-injection,-injection, drop=FALSE]
              ScoreStat <- t(Uo) %*% Hoo %*% solve(Goo) %*% Hoo %*% Uo
              cfac[i] <- ScoreStat/(t(Uo) %*% Hoo %*% Uo)
            }
          }
        }
      }
      ## apply Pace et al (2011) adjustment to pseudo-deviances
      ## (save attributes of 'result' for later reinstatement)
      oldresult <- result
      result$Deviance <- AdjDev <- result$Deviance * cfac
      cn <- colnames(result)
      colnames(result)[cn == "Deviance"] <- "AdjDeviance"
      if("Pr(>Chi)" %in% colnames(result)) 
        result[["Pr(>Chi)"]] <- c(NA, pchisq(abs(AdjDev[-1]),
                                       df=abs(result$Df[-1]),
                                       lower.tail=FALSE))
      class(result) <- class(oldresult)
      attr(result, "heading") <- attr(oldresult, "heading")
    }
    if(any(unlist(lapply(objex, inherits, what="ippm")))) {
      ## calculation does not include 'covfunargs'
      cfa <- lapply(lapply(objects, getElement, name="confunargs"), names)
      cfa <- unique(unlist(cfa))
      gripe("Adjustment to composite likelihood does not account for",
            "irregular trend parameters (covfunargs)",
            commasep(sQuote(cfa)))
    }
  }
  return(result)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/applynbd.R"
# 	applynbd.R
#
#     $Revision: 1.16 $     $Date: 2014/10/24 00:22:30 $
#
#  applynbd()
# For each point, identify either
#	 - all points within distance R
#        - the closest N points  
#        - those points satisfying some constraint
# and apply the function FUN to them
#
#  markstat()
#      simple application of applynbd
#################################################################


applynbd <- function(X, FUN, N=NULL, R=NULL, criterion=NULL, exclude=FALSE, ...) {

  if(is.null(N) && is.null(R) && is.null(criterion)) 
    stop(paste("must specify at least one of the arguments",
               commasep(sQuote(c("N","R","criterion")))))
     
  X <- as.ppp(X)
  npts <- npoints(X)

  # compute matrix of pairwise distances
  dist <- pairdist(X)

  # compute row ranks (avoid ties)
  rankit <- function(x) {  u <- numeric(length(x)); u[fave.order(x)] <- seq_along(x); return(u) }
  drank <- t(apply(dist, 1, rankit)) - 1

  included <- matrix(TRUE, npts, npts)
  if(!is.null(R)) {
    # select points closer than R
    included <- included & (dist <= R)
  }
  if(!is.null(N)) {
    # select N closest points
    if(N < 1)
      stop("Value of N must be at least 1")
    if(exclude)
      included <- included & (drank <= N) 
    else
      included <- included & (drank <= N-1)
  }
  if(!is.null(criterion)) {
    # some funny criterion
    for(i in 1:npts) 
      included[i,] <- included[i,] & criterion(dist[i,], drank[i,])
  }
     
  if(exclude) 
    diag(included) <- FALSE

  # bind into an array
  a <- array(c(included, dist, drank, row(included)), dim=c(npts,npts,4))

  # what to do with a[i, , ]
  if(!is.marked(X)) 
    go <- function(ai, Z, fun, ...) { 
      which <- as.logical(ai[,1])
      distances <- ai[,2]
      dranks <- ai[,3]
      here <- ai[1,4]
      fun(Y=Z[which],
          current=c(x=Z$x[here], y=Z$y[here]),
          dists=distances[which], dranks=dranks[which],
          ...) 
    }
  else
    go <- function(ai, Z, fun, ...) { 
      which <- as.logical(ai[,1])
      distances <- ai[,2]
      dranks <- ai[,3]
      here <- ai[1,4]
      fun(Y=Z[which],
          current=Z[here],
          dists=distances[which], dranks=dranks[which],
          ...) 
    }
  
  # do it
  result <- apply(a, 1, go, Z=X, fun=FUN, ...)
  
  return(result)
}

markstat <- function(X, fun, N=NULL, R=NULL, ...) {
  verifyclass(X, "ppp")
  stopifnot(is.function(fun))
  statfun <- function(Y, current, dists, dranks, func, ...)
    { func(marks(Y, dfok=TRUE), ...) }
  applynbd(X, statfun, R=R, N=N, func=fun, ...)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/areadiff.R"
#
# areadiff.R
#
#  $Revision: 1.29 $  $Date: 2014/10/24 00:22:30 $
#
# Computes sufficient statistic for area-interaction process
#
# Invokes areadiff.c
#
# areaLoss = area lost by removing X[i] from X

areaLoss <- function(X, r, ..., W=as.owin(X),
                     subset=NULL, exact=FALSE,
                     ngrid=spatstat.options("ngrid.disc")) {
  if(exact)
    areaLoss.diri(X, r, ..., W=W, subset=subset)
  else
    areaLoss.grid(X, r, ..., W=W, subset=subset, ngrid=ngrid)
}

# areaGain = area gained by adding u[i] to X

areaGain <- function(u, X, r, ..., W=as.owin(X), exact=FALSE,
                     ngrid=spatstat.options("ngrid.disc")) {
  if(exact)
    areaGain.diri(u, X, r, ..., W=W)
  else
    areaGain.grid(u, X, r, W=W, ngrid=ngrid)
}


#////////////////////////////////////////////////////////////
#    algorithms using Dirichlet tessellation
#///////////////////////////////////////////////////////////

areaLoss.diri <- function(X, r, ..., W=as.owin(X), subset=NULL) {
  stopifnot(is.ppp(X))
  npts <- npoints(X)
  if(is.matrix(r)) {
    if(sum(dim(r) > 1) > 1)
      stop("r should be a vector or single value")
    r <- as.vector(r)
  }
  nr <- length(r)
  if(npts == 0)
    return(matrix(, nrow=0, ncol=nr))
  else if(npts == 1) 
    return(matrix(discpartarea(X, r, W), nrow=1))
  # set up output array
  indices <- 1:npts
  if(!is.null(subset))
    indices <- indices[subset]
  out <- matrix(, nrow=length(indices), ncol=nr)
  #
  w <- X$window
  pir2 <- pi * r^2
  # dirichlet neighbour relation in entire pattern 
  dd <- deldir(X$x, X$y, rw=c(w$xrange, w$yrange))
  a <- dd$delsgs[,5]
  b <- dd$delsgs[,6]
  for(k in seq_along(indices)) {
    i <- indices[k]
    # find all Delaunay neighbours of i 
    jj <- c(b[a==i], a[b==i])
    jj <- sort(unique(jj))
    # extract only these points
    Yminus <- X[jj]
    Yplus  <- X[c(jj, i)]
    # dilate
    aplus <- dilated.areas(Yplus, r, W, exact=TRUE)
    aminus <- dilated.areas(Yminus, r, W, exact=TRUE)
    areas <- aplus - aminus
    # area/(pi * r^2) must be positive and nonincreasing
    y <- ifelseAX(r == 0, 1, areas/pir2)
    y <- pmin.int(1, y)
    ok <- is.finite(y)
    y[ok] <- rev(cummax(rev(y[ok])))
    areas <- pmax.int(0, y * pir2)
    # save
    out[k, ] <- areas
  }
  return(out)
}

areaGain.diri <- function(u, X, r, ..., W=as.owin(X)) {
  stopifnot(is.ppp(X))
  Y <- as.ppp(u, W=W)
  nX <- X$n
  nY <- Y$n
  if(is.matrix(r)) {
    if(sum(dim(r) > 1) > 1)
      stop("r should be a vector or single value")
    r <- as.vector(r)
  }
  nr <- length(r)
  if(nY == 0)
    return(matrix(, nrow=0, ncol=nr))
  if(nX == 0)
    return(matrix(pi * r^2, nrow=nY, ncol=nr, byrow=TRUE))
  cat(paste("areaGain,", nY, "points,", nr, "r values\n"))
  out <- matrix(0, nrow=nY, ncol=nr)
  pir2 <- pi * r^2
  wbox <- as.rectangle(as.owin(X))
  #
  for(i in 1:nY) {
    progressreport(i, nY)
    V <- superimpose(Y[i], X, W=wbox, check=FALSE)
    # Dirichlet neighbour relation for V
    dd <- deldir(V$x, V$y, rw=c(wbox$xrange, wbox$yrange))
    aa <- dd$delsgs[,5]
    bb <- dd$delsgs[,6]
    # find all Delaunay neighbours of Y[1] in V
    jj <- c(bb[aa==1], aa[bb==1])
    jj <- sort(unique(jj))
    # extract only these points
    Zminus <- V[jj]
    Zplus  <- V[c(1, jj)]
    # dilate
    aplus <- dilated.areas(Zplus, r, W, exact=TRUE)
    aminus <- dilated.areas(Zminus, r, W, exact=TRUE)
    areas <- aplus - aminus
    # area/(pi * r^2) must be in [0,1] and nonincreasing
    y <- ifelseAX(r == 0, 1, areas/pir2)
    y <- pmin.int(1, y)
    ok <- is.finite(y)
    y[ok] <- rev(cummax(rev(y[ok])))
    areas <- pmax.int(0, y * pir2)
    # save
    out[i,] <- areas
  }
  return(out)
}

#////////////////////////////////////////////////////////////////////////
#    alternative implementations using grid counting in C
#////////////////////////////////////////////////////////////////////////

areaGain.grid <- function(u, X, r, ..., W=NULL, ngrid=spatstat.options("ngrid.disc")) {
  verifyclass(X, "ppp")
  u <- as.ppp(u, W=as.owin(X))
  stopifnot(is.numeric(r) && all(is.finite(r)) && all(r >= 0))
  #
  nu <- u$n
  nr <- length(r)
  if(nr == 0)
    return(numeric(0))
  rmax <- max(r)
  #
  constrain <- !is.null(W)
  if(constrain && (W$type != "rectangle")) {
    # Constrained to an irregular window
    # initialise to value for small-r
    result <- matrix(pi * r^2, nrow=nu, ncol=nr, byrow=TRUE)    
    # vector of radii below which b(u,r) is disjoint from U(X,r)
    rcrit.u <- nncross(u, X, what="dist")/2
    rcrit.min <- min(rcrit.u)
    # Use distance transform and set covariance
    D <- distmap(X, ...)
    DW <- D[W, drop=FALSE]
    # distance from (0,0) - thresholded to make digital discs
    discWin <- owin(c(-rmax,rmax),c(-rmax,rmax))
    discWin <- as.mask(discWin, eps=min(D$xstep, rmax/4))
    rad <- as.im(function(x,y){sqrt(x^2+y^2)}, W=discWin)
    # 
    for(j in which(r > rcrit.min)) {
      # rj is above the critical radius rcrit.u[i] for at least one point u[i]
      rj <- r[j]
      if(any(above <- (rj > rcrit.u))) {
        Uncovered  <- levelset(DW, rj, ">")
        DiscRj     <- levelset(rad, rj, "<=")
        AreaGainIm <- setcov(Uncovered, DiscRj)
        result[above, j] <- safelookup(AreaGainIm, u[above])
      }
    }
    return(result)
  }
  #
  #
  xx <- X$x
  yy <- X$y
  result <- matrix(, nrow=nu, ncol=nr)
  #
  for(i in 1:nu) {
    # shift u[i] to origin
    xu <- u$x[i]
    yu <- u$y[i]
    xshift <- xx - xu
    yshift <- yy - yu
    # find points within distance 2 rmax of origin
    close <- (xshift^2 + yshift^2 < 4 * rmax^2)
    nclose <- sum(close)
    # invoke C routine
    if(!constrain) {
      z <- .C("areadifs",
              rad = as.double(r),
              nrads = as.integer(nr),
              x   = as.double(xshift[close]),
              y   = as.double(yshift[close]),
              nn  = as.integer(nclose),
              ngrid = as.integer(ngrid),
              answer = as.double(numeric(nr)))
      result[i,] <- z$answer
    } else {
      z <- .C("areaBdif",
              rad = as.double(r),
              nrads = as.integer(nr),
              x   = as.double(xshift[close]),
              y   = as.double(yshift[close]),
              nn  = as.integer(nclose),
              ngrid = as.integer(ngrid),
              x0 = as.double(W$xrange[1] - xu),
              y0 = as.double(W$yrange[1] - yu),
              x1 = as.double(W$xrange[2] - xu),
              y1 = as.double(W$yrange[2] - yu),
              answer = as.double(numeric(nr)))
      result[i,] <- z$answer
    }
  }
  return(result)
}

areaLoss.grid <- function(X, r, ...,
                          W=as.owin(X), subset=NULL,
                          method = c("count", "distmap"),
                          ngrid = spatstat.options("ngrid.disc"),
                          exact = FALSE) {
  verifyclass(X, "ppp")
  n <- npoints(X)
  nr <- length(r)
  indices <- if(is.null(subset)) 1:n else (1:n)[subset]
  answer <- matrix(, nrow=length(indices), ncol=nr)
  if(missing(method)) {
    method <- if(nr <= 20 || exact) "count" else "distmap"
  } else method <- match.arg(method)
  switch(method,
         count = {
           # one value of r: use grid-counting
           for(k in seq_along(indices)) {
             i <- indices[k]
             answer[k,] <- areaGain(X[i], X[-i], r, W=W,
                                    ngrid=ngrid, exact=exact)
           }
         },
         distmap = {
           # Many values of r: use distance transform
           D <- distmap(X, ...)
           DW <- D[W, drop=FALSE]
           a <- area(Window(DW))
           # empirical cdf of distance values
           FW <- ecdf(DW[drop=TRUE])
           # radii below which there are no overlaps
           rcrit <- nndist(X)/2
           for(k in seq_along(indices)) {
             i <- indices[k]
             Di <- distmap(X[-i], ...)
             FiW <- ecdf(Di[W, drop=TRUE])
             answer[k, ] <-
               ifelseXY(r > rcrit[i], a * (FW(r) - FiW(r)), pi * r^2)
           }
         })
  return(answer)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/areainter.R"
#
#
#    areainter.R
#
#    $Revision: 1.35 $	$Date: 2014/12/22 04:37:56 $
#
#    The area interaction
#
#    AreaInter()    create an instance of the area-interaction process
#                 [an object of class 'interact']
#	
#
# -------------------------------------------------------------------
#

AreaInter <- local({

  # area-interaction conditional intensity potential
  #     corresponds to potential -C(x) = n(x) - A(x)/\pi r^2
  areapot <- 
    function(X,U,EqualPairs,pars,correction, ..., W=as.owin(X)) {
      uhoh <- !(correction %in% c("border", "none"))
      if(any(uhoh)) {
        nuh <- sum(uhoh)
        warning(paste(ngettext(nuh, "Correction", "Corrections"),
                      commasep(sQuote(correction[uhoh])),
                      ngettext(nuh,
                               "is not supported and was ignored",
                               "are not supported and were ignored")))
      }
      r <- pars$r
      if(is.null(r)) stop("internal error: r parameter not found")
      n <- U$n
      areas <- numeric(n)
      dummies <- !(seq_len(n) %in% EqualPairs[,2])
      if(sum(dummies) > 0)
        areas[dummies] <- areaGain(U[dummies], X, r, W=W)
      ii <- EqualPairs[,1]
      jj <- EqualPairs[,2]
      areas[jj] <- areaLoss(X, r, subset=ii, W=W)
      return(1 - areas/(pi * r^2))
    }

  #' fractional area of overlap of two unit discs at distance 2 * z
  discOverlap <- function(z) {
    z <- pmax(pmin(z, 1), -1)
    (2/pi) * (acos(z) - z * sqrt(1 - z^2))
  }
  
  # template object without family, par, version
  BlankAI <- 
  list(
         name     = "Area-interaction process",
         creator  = "AreaInter",
         family   = "inforder.family", # evaluated later
         pot      = areapot,
         par      = list(r = NULL), # to be filled in
         parnames = "disc radius",
         init     = function(self) {
                      r <- self$par$r
                      if(!is.numeric(r) || length(r) != 1 || r <= 0)
                       stop("disc radius r must be a positive number")
                    },
         update = NULL,  # default OK
         print = NULL,    # default OK
         plot = function(fint, ..., d=NULL, plotit=TRUE) {
           verifyclass(fint, "fii")
           inter <- fint$interaction
           unitz <- unitname(fint)
           if(!identical(inter$name, "Area-interaction process"))
             stop("Tried to plot the wrong kind of interaction")
           #' fitted interaction coefficient
           theta <- fint$coefs[fint$Vnames]
           #' interaction radius
           r <- inter$par$r
           xlim <- resolve.1.default(list(xlim=c(0, 1.25 * 2*r)), list(...)) 
           rmax <- max(xlim, d)
           if(is.null(d)) {
             d <- seq(from=0, to=rmax, length.out=1024)
           } else {
             stopifnot(is.numeric(d) &&
                       all(is.finite(d)) &&
                       all(diff(d) > 0))
           }
           #' compute interaction between two points at distance d
           y <- exp(theta * discOverlap(d/(2 * r)))
           #' compute `fv' object
           fun <- fv(data.frame(r=d, h=y, one=1),
                     "r", substitute(h(r), NULL), "h", cbind(h,one) ~ r,
                     xlim, c("r", "h(r)", "1"),
                     c("distance argument r",
                       "maximal interaction h(r)",
                       "reference value 1"),
                     unitname=unitz)
           if(plotit)
             do.call("plot.fv",
                     resolve.defaults(list(fun),
                                      list(...),
                                      list(ylim=range(0,1,y))))
           return(invisible(fun))
         },
         #' end of function 'plot'
         interpret =  function(coeffs, self) {
           logeta <- as.numeric(coeffs[1])
           eta <- exp(logeta)
           return(list(param=list(eta=eta),
                       inames="interaction parameter eta",
                       printable=signif(eta)))
         },
         valid = function(coeffs, self) {
           eta <- ((self$interpret)(coeffs, self))$param$eta
           return(is.finite(eta))
         },
         project = function(coeffs, self) {
           if((self$valid)(coeffs, self))
             return(NULL)
           return(Poisson())
         },
         irange = function(self, coeffs=NA, epsilon=0, ...) {
           r <- self$par$r
           if(any(is.na(coeffs)))
             return(2 * r)
           logeta <- coeffs[1]
           if(abs(logeta) <= epsilon)
             return(0)
           else
             return(2 * r)
         },
         delta2 = function(X, inte, correction) {
           # Sufficient statistic for second order conditional intensity
           # Area-interaction model 
           if(!(correction %in% c("border", "none")))
             return(NULL)
           r <- inte$par$r
           areadelta2(X, r)
         },
       version=NULL # to be added
  )
  class(BlankAI) <- "interact"

  AreaInter <- function(r) {
    instantiate.interact(BlankAI, list(r=r))
  }

  AreaInter <- intermaker(AreaInter, BlankAI)
  
  AreaInter
})


areadelta2 <- local({

  areadelta2 <- function(X, r, ...) {
    # Sufficient statistic for second order conditional intensity
    # Area-interaction model 
    if(is.ppp(X)) return(areadelppp(X, r, ...)) else
    if(inherits(X, "quad")) return(areadelquad(X, r)) else
    stop("internal error: X should be a ppp or quad object")
  }

  areadelppp <- function(X, r, algorithm=c("C", "nncross", "nnmap")) {
    # Evaluate \Delta_{x_i} \Delta_{x_j} S(x) for data points x_i, x_j
    # i.e.  h(X[i]|X) - h(X[i]|X[-j])
    #       where h is first order cif statistic
    algorithm <- match.arg(algorithm)
    nX <- npoints(X)
    result <- matrix(0, nX, nX)
    if(nX < 2)
      return(result)
    if(algorithm == "C") {
      # use special purpose C routine
      # called once for each interacting pair of points
      xx <- X$x
      yy <- X$y
      cl <- closepairs(X, 2 * r, what="indices", ordered=FALSE)
      I <- cl$i
      J <- cl$j
      eps <- r/spatstat.options("ngrid.disc")
      for(k in seq_along(I)) {
        i <- I[k]
        j <- J[k]
        # all neighbours of i
        Ki <- union(J[I==i], I[J==i])
        # all neighbours of j
        Kj <- union(J[I==j], I[J==j])
        # relevant neighbours
        K <- setdiff(union(Ki, Kj), c(i,j))
        # call C code
        z <- .C("delta2area",
                xa = as.double(xx[i]),
                ya = as.double(yy[i]),
                xb = as.double(xx[j]),
                yb = as.double(yy[j]),
                nother = as.integer(length(K)),
                xother = as.double(xx[K]),
                yother = as.double(yy[K]),
                radius = as.double(r),
                epsilon = as.double(eps),
                pixcount = as.integer(integer(1)))
        result[i,j] <- result[j,i] <- z$pixcount
      }
      # normalise
      result <- result * (eps^2)/(pi * r^2)
      return(result)
    }
    # remove any non-interacting points
    relevant <- (nndist(X) <= 2 * r)
    if(!all(relevant)) {
      answer <- matrix(0, nX, nX)
      if(any(relevant)) {
        # call self on subset
        Dok <- areadelppp(X[relevant], r, algorithm)
        answer[relevant,relevant] <- Dok
      }
      return(answer)
    }

    # .............. algorithm using interpreted code ...........
    
    # sort pattern in increasing order of x
    sortX <- (algorithm == "nnmap")
    if(sortX) {
      oX <- fave.order(X$x)
      X <- X[oX]
    }

    # area calculation may be restricted to window W for efficiency
    W <- as.owin(X)
    U <- as.rectangle(W)

    # decide pixel resolution
    eps <- r/spatstat.options("ngrid.disc")
    npix <- prod(ceiling(sidelengths(U)/eps))
    if(npix <= 2^20) {
      # do it all in one go
      tile <- list(NULL)
    } else {
      # divide into rectangular tiles
      B <- as.rectangle(W)
      ntile0 <- ceiling(npix/(2^20))
      tile0area <- area(B)/ntile0
      tile0side <- sqrt(tile0area)
      nx <- ceiling(sidelengths(B)[1]/tile0side)
      ny <- ceiling(sidelengths(B)[2]/tile0side)
      tile <- tiles(quadrats(B, nx, ny))
    }
           
    result <- matrix(0, nX, nX)
    for(i in seq_len(length(tile))) {
      # form pixel grid
      Ti <- tile[[i]]
      Wi <- if(is.null(Ti)) W else intersect.owin(W, Ti)
      if(algorithm == "nncross") {
        # Trusted, slow algorithm using nncross
        Z <- as.mask(Wi, eps=eps)
        G <- as.ppp(rasterxy.mask(Z), U, check=FALSE)
        # compute 3 nearest neighbours in X of each grid point
        v <- nncross(G, X, k=1:3)
        # select pixels which have exactly 2 neighbours within distance r
        ok <- with(v, dist.3 > r & dist.2 <= r)
        if(any(ok)) {
          v <- v[ok, , drop=FALSE]
          # accumulate pixel counts -> areas
          counts <- with(v, table(i=factor(which.1, levels=1:nX),
                                  j=factor(which.2, levels=1:nX)))
          pixarea <- with(Z, xstep * ystep)
          result <- result + pixarea * (counts + t(counts))
        }
      } else {
        # Faster algorithm using nnmap
        # compute 3 nearest neighbours in X of each grid point
        stuff <- nnmap(X, k=1:3, W=Wi, eps=eps,
                       is.sorted.X=TRUE, sortby="x",
                       outputarray=TRUE)
        dist.2 <- stuff$dist[2,,]
        dist.3 <- stuff$dist[3,,]
        which.1 <- stuff$which[1,,]
        which.2 <- stuff$which[2,,]
        ok <- (dist.3 > r & dist.2 <= r)
        if(any(ok)) {
          which.1 <- as.vector(which.1[ok])
          which.2 <- as.vector(which.2[ok])
          counts <- table(i=factor(which.1, levels=1:nX),
                          j=factor(which.2, levels=1:nX))
          pixarea <- attr(stuff, "pixarea")
          result <- result + pixarea * (counts + t(counts))
        }
      }
    }
    if(sortX) {
      # map back to original ordering
      result[oX, oX] <- result
    }
    # normalise
    result <- result/(pi * r^2)
    return(result)
  }

  areadelquad <- function(Q, D, r) {
    # Sufficient statistic for second order conditional intensity
    # Area-interaction model 
    # Evaluate \Delta_{u_j} \Delta_{u_i} S(x) for quadrature points 
    # answer is area(b(u[i],r) \cap b(u[j],r)\setminus \bigcup_k b(x[k],r))
    # where k ranges over all indices that are not equivalent to u[i,j]
    U <- union.quad(Q)
    Z <- is.data(Q)
    nU <- npoints(U)
    xx <- U$x
    yy <- U$y
    # identify all close pairs of quadrature points
    cl <- closepairs(U, 2 * r, what="indices")
    I <- b$i
    J <- b$j
    # find neighbours in X of each quadrature point
    zJ <- Z[J]
    neigh <- split(J[zJ], factor(I[zJ], levels=1:nU))
    # 
    result <- matrix(0, nU, nU)
    eps <- r/spatstat.options("ngrid.disc")
    #
    for(k in seq_along(I)) {
      i <- I[k]
      j <- J[k]
      # all points of X close to U[i]
      Ki <- neigh[[i]]
      # all points of X close to U[j]
      Kj <- neigh[[j]]
      # relevant neighbours
      K <- setdiff(union(Ki, Kj), c(i,j))
      # call C code
      z <- .C("delta2area",
            xa = as.double(xx[i]),
            ya = as.double(yy[i]),
            xb = as.double(xx[j]),
            yb = as.double(yy[j]),
            nother = as.integer(length(K)),
            xother = as.double(xx[K]),
            yother = as.double(yy[K]),
            radius = as.double(r),
            epsilon = as.double(eps),
            pixcount = as.integer(integer(1)))
      result[i,j] <- z$pixcount
    }
    # normalise
    result <- result * (eps^2)/(pi * r^2)
    return(result)
  }

  areadelta2
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/as.im.R"
#
#    as.im.R
#
#    conversion to class "im"
#
#    $Revision: 1.41 $   $Date: 2014/08/30 10:30:05 $
#
#    as.im()
#

as.im <- function(X, ...) {
  UseMethod("as.im")
}

as.im.im <- function(X, W=NULL, ...,
                     eps=NULL, dimyx=NULL, xy=NULL,
                     na.replace=NULL) {
  X <- repair.old.factor.image(X)
  if(is.null(W)) {
    if(is.null(eps) && is.null(dimyx) && is.null(xy)) {
      X <- repair.image.xycoords(X)
      X <- na.handle.im(X, na.replace)
      return(X)
    }
    # pixel raster determined by dimyx etc
    W <- as.mask(as.rectangle(X), eps=eps, dimyx=dimyx, xy=xy)
    # invoke as.im.owin
    Y <- as.im(W)
  } else {
    # apply dimyx (etc) if present,
    # otherwise use W to determine pixel raster
    Y <- as.im(W, eps=eps, dimyx=dimyx, xy=xy)
  }
  # resample X onto raster of Y
  Y <- rastersample(X, Y)

  return(na.handle.im(Y, na.replace))
}

as.im.owin <- function(X, W=NULL, ...,
                       eps=NULL, dimyx=NULL, xy=NULL,
                       na.replace=NULL, value=1) {
  if(!(is.null(eps) && is.null(dimyx) && is.null(xy))) {
    # raster dimensions determined by dimyx etc
    # convert X to a mask 
    M <- as.mask(X, eps=eps, dimyx=dimyx, xy=xy)
    # convert mask to image
    d <- M$dim
    v <- matrix(value, d[1], d[2])
    m <- M$m
    v[!m] <- if(is.null(na.replace)) NA else na.replace
    out <- im(v, M$xcol, M$yrow,
              xrange=M$xrange, yrange=M$yrange,
              unitname=unitname(X))
    return(out)
  }
  if(!is.null(W) && is.owin(W) && W$type == "mask") {
    # raster dimensions determined by W
    # convert W to zero image
    d <- W$dim
    Z <- im(matrix(0, d[1], d[2]), W$xcol, W$yrow, unitname=unitname(X))    
    # adjust values to indicator of X
    Z[X] <- 1
    if(missing(value) && is.null(na.replace)) {
      # done
      out <- Z
    } else {
      # map {0, 1} to {na.replace, value}
      v <- matrix(ifelseAB(Z$v == 0, na.replace, value), d[1], d[2])
      out <- im(v, W$xcol, W$yrow, unitname=unitname(X))
    }
    return(out)
  }
  if(X$type == "mask") {
    # raster dimensions determined by X
    # convert X to image
    d <- X$dim
    v <- matrix(value, d[1], d[2])
    m <- X$m
    v[!m] <- if(is.null(na.replace)) NA else na.replace
    out <- im(v, xcol=X$xcol, yrow=X$yrow,
              xrange=X$xrange, yrange=X$yrange, unitname=unitname(X))
    return(out)
  }
  # X is not a mask.
  # W is either missing, or is not a mask.
  # Convert X to a image using default settings
  M <- as.mask(X)
  # convert mask to image
  d <- M$dim
  v <- matrix(value, d[1], d[2])
  m <- M$m
  v[!m] <- if(is.null(na.replace)) NA else na.replace
  out <- im(v, M$xcol, M$yrow, unitname=unitname(X))
  return(out)
}

as.im.function <- function(X, W=NULL, ...,
                           eps=NULL, dimyx=NULL, xy=NULL,
                           na.replace=NULL) {
  f <- X
  if(is.null(W))
    stop("A window W is required")
  W <- as.owin(W)
  W <- as.mask(W, eps=eps, dimyx=dimyx, xy=xy)
  m <- W$m
  funnywindow <- !all(m)

  xx <- as.vector(rasterx.mask(W))
  yy <- as.vector(rastery.mask(W))

  # evaluate function value at each pixel 
  if(!funnywindow) 
    values <- f(xx, yy, ...)
  else {
    # evaluate only inside window
    inside <- as.vector(m)
    val <- f(xx[inside], yy[inside], ...)
    # create space for full matrix
    msize <- length(m)
    values <-
      if(!is.factor(val))
        vector(mode=typeof(val), length=msize)
      else {
        lev <- levels(val)
        factor(rep.int(lev[1], msize), levels=lev)
      }
    # copy values, assigning NA outside window
    values[inside] <- val
    values[!inside] <- NA
  }

  nc <- length(W$xcol)
  nr <- length(W$yrow)
  if(nr == 1 || nc == 1) {
    # exception: can't determine pixel width/height from centres
    out <- im(matrix(values, nr, nc),
              xrange=W$xrange, yrange=W$yrange, unitname=unitname(W))
  } else {
    out <- im(values, W$xcol, W$yrow, unitname=unitname(W))
  }
  return(na.handle.im(out, na.replace))
}

as.im.matrix <- function(X, W=NULL, ...) {
  nr <- nrow(X)
  nc <- ncol(X)
  if(is.null(W))
    return(im(X, ...))
  W <- as.owin(W)
  if(W$type == "mask") {
    xcol <- W$xcol
    yrow <- W$yrow
    # pixel coordinate information
    if(length(xcol) == nc && length(yrow) == nr)
      return(im(X, xcol, yrow, unitname=unitname(W)))
  }
  # range information
  R <- as.rectangle(W)
  xrange <- R$xrange
  yrange <- R$yrange
  return(im(X, xrange=xrange, yrange=yrange, unitname=unitname(W)))
}

as.im.default <- function(X, W=NULL, ...,
                          eps=NULL, dimyx=NULL, xy=NULL,
                          na.replace=NULL) {

  if((is.vector(X) || is.factor(X)) && length(X) == 1) {
    # numerical value: interpret as constant function
    xvalue <- X
    X <- function(xx, yy, ...) { rep.int(xvalue, length(xx)) }
    return(as.im(X, W, ..., dimyx=dimyx, na.replace=na.replace))
  }
  
  if(is.list(X) && checkfields(X, c("x","y","z"))) {
    stopifnot(is.matrix(X$z))
    z <- X$z
    y <- X$y
    x <- X$x
    # Usual S convention as in contour.default() and image.default()
    # Rows of z correspond to x values.
    nr <- nrow(z)
    nc <- ncol(z)
    lx <- length(x)
    ly <- length(y)
    if(lx == nr + 1)
      x <- (x[-1] + x[-lx])/2
    else if(lx != nr)
      stop("length of x coordinate vector does not match number of rows of z")
    if(ly == nc + 1)
      y <- (y[-1] + y[-ly])/2
    else if(ly != nc)
      stop("length of y coordinate vector does not match number of columns of z")
    # convert to class "im"
    out <- im(t(z), x, y)
    # now apply W and dimyx if present
    if(is.null(W) && !(is.null(eps) && is.null(dimyx) && is.null(xy)))
      out <- as.im(out, eps=eps, dimyx=dimyx, xy=xy)
    else if(!is.null(W))
      out <- as.im(out, W=W, eps=eps, dimyx=dimyx, xy=xy)
    return(na.handle.im(out, na.replace))
  }
  stop("Can't convert X to a pixel image")
}

as.im.ppp <- function(X, ...) {
  pixellate(X, ..., weights=NULL, zeropad=FALSE)
}

# convert to image from some other format, then do something

do.as.im <- function(x, action, ...,
                     W = NULL, eps = NULL, dimyx = NULL, xy = NULL, 
                     na.replace = NULL) {
  Z <- as.im(x, W=W, eps=eps, dimyx=dimyx, xy=xy, na.replace=na.replace)
  Y <- do.call(action, list(Z, ...))
  return(Y)
}

na.handle.im <- function(X, na.replace) {
if(is.null(na.replace))
  return(X)
if(length(na.replace) != 1)
  stop("na.replace should be a single value")
X$v[is.na(X$v)] <- na.replace
return(X)
}

repair.old.factor.image <- function(x) {
  # convert from old to new representation of factor images
  if(x$type != "factor")
    return(x)
  v <- x$v
  isold <- !is.null(lev <- attr(x, "levels"))
  isnew <- is.factor(v) && is.matrix(v)
  if(isnew)
    return(x)
  if(!isold)
    stop("Internal error: unrecognised format for factor-valued image")
  v <- factor(v, levels=lev)
  dim(v) <- x$dim
  x$v <- v
  return(x)
}

repair.image.xycoords <- function(x) {
  im(x$v, xrange=x$xrange, yrange=x$yrange, unitname=unitname(x))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/badgey.R"
#
#
#    badgey.S
#
#    $Revision: 1.13 $	$Date: 2014/02/07 04:44:47 $
#
#    Hybrid Geyer process
#
#    BadGey()   create an instance of the process
#                 [an object of class 'interact']
#	
#
# -------------------------------------------------------------------
#	

BadGey <- local({

  # ........... auxiliary functions ..............
  delBG <- function(i, r, sat) {
    r   <- r[-i]
    if(length(r) == length(sat)) {
      r   <- r[-i]
      sat <- sat[-i]
    } else if(length(sat) == 1) {
      r <- r[-i]
    } else stop("Mismatch in dimensions of arguments r and sat")
    nr <- length(r)
    if(nr == 0) return(Poisson())
    if(nr == 1) return(Geyer(r, sat))
    return(BadGey(r, sat))
  }

  # .............. template ....................
  
  BlankBG <- 
  list(
         name     = "hybrid Geyer process",
         creator  = "BadGey",
         family   = "pairsat.family",  # will be evaluated later
         pot      = function(d, par) {
                       r <- par$r
                       nr <- length(r)
                       out <- array(FALSE, dim=c(dim(d), nr))
                       for(i in 1:nr) 
                         out[,,i] <- (d <= r[i])
                       out
                    },
         par      = list(r = NULL, sat=NULL), # to fill in later
         parnames = c("interaction radii", "saturation parameters"),
         init     = function(self) {
                      r <- self$par$r
                      sat <- self$par$sat
                      if(!is.numeric(r) || !all(r > 0))
                        stop("interaction radii r must be positive numbers")
                      if(length(r) > 1 && !all(diff(r) > 0))
                        stop("interaction radii r must be strictly increasing")
                      if(!is.numeric(sat) || any(sat < 0))
                        stop("saturation parameters must be nonnegative numbers")
                      if(length(sat) != length(r) && length(sat) != 1)
                        stop("vectors r and sat must have equal length")
                    },
         update = NULL,  # default OK
         print = NULL,    # default OK
         interpret =  function(coeffs, self) {
           r <- self$par$r
           npiece <- length(r)
           # extract coefficients
           gammas <- exp(as.numeric(coeffs))
           # name them
           gn <- gammas
           names(gn) <- paste("[0,", r, ")", sep="")
           #
           return(list(param=list(gammas=gammas),
                       inames="interaction parameters gamma_i",
                       printable=dround(gn)))
         },
        valid = function(coeffs, self) {
           # interaction parameters gamma must be
           #   non-NA 
           #   finite, if sat > 0
           #   less than 1, if sat = Inf
           gamma <- (self$interpret)(coeffs, self)$param$gammas
           sat <- self$par$sat
           if(any(is.na(gamma)))
             return(FALSE)
           return(all((is.finite(gamma) | sat == 0)
                      & (gamma <= 1 | sat != Inf)))
        },
        project = function(coeffs, self){
          loggammas <- as.numeric(coeffs)
          sat <- self$par$sat
          r   <- self$par$r
          good <- is.finite(loggammas) & (is.finite(sat) | loggammas <= 0)
          if(all(good))
            return(NULL)
          if(!any(good))
            return(Poisson())
          bad <- !good
          if(spatstat.options("project.fast") || sum(bad) == 1) {
            # remove smallest threshold with an unidentifiable parameter
            firstbad <- min(which(bad))
            return(delBG(firstbad, r, sat))
          } else {
            # consider all candidate submodels
            subs <- lapply(which(bad), delBG, r=r, sat=sat)
            return(subs)
          }
        },
        irange = function(self, coeffs=NA, epsilon=0, ...) {
          r <- self$par$r
          sat <- self$par$sat
          if(all(is.na(coeffs)))
            return(2 * max(r))
          gamma <- (self$interpret)(coeffs, self)$param$gammas
          gamma[is.na(gamma)] <- 1
          active <- (abs(log(gamma)) > epsilon) & (sat > 0)
          if(!any(active))
            return(0)
          else return(2 * max(r[active]))
        },
       version=NULL, # to be added later
       # fast evaluation is available for the border correction only
       can.do.fast=function(X,correction,par) {
         return(all(correction %in% c("border", "none")))
       },
       fasteval=function(X,U,EqualPairs,pairpot,potpars,correction,
                         ..., halfway=FALSE) {
         # fast evaluator for BadGey interaction
         if(!all(correction %in% c("border", "none")))
           return(NULL)
         if(spatstat.options("fasteval") == "test")
           message("Using fast eval for BadGey")
         r   <- potpars$r
         sat <- potpars$sat
         # ensure r and sat have equal length
         if(length(r) != length(sat)) {
           if(length(r) == 1)
             r <- rep.int(r, length(sat))
           else if(length(sat) == 1)
             sat <- rep.int(sat, length(r))
           else stop("lengths or r and sat do not match")
         }
         # first ensure all data points are in U
         nX <- npoints(X)
         nU <- npoints(U)
         Xseq  <- seq_len(nX)
         if(length(EqualPairs) == 0) {
           # no data points currently included 
           missingdata <- rep.int(TRUE, nX)
         } else {
           Xused <- EqualPairs[,1]
           missingdata <- !(Xseq %in% Xused)
         }
         somemissing <- any(missingdata)
         if(somemissing) {
           # add the missing data points
           nmiss <- sum(missingdata)
           U <- superimpose(U, X[missingdata], W=X$window)
           # correspondingly augment the list of equal pairs
           originalrows <- seq_len(nU)
           newXindex <- Xseq[missingdata]
           newUindex <- nU + seq_len(nmiss)
           EqualPairs <- rbind(EqualPairs, cbind(newXindex, newUindex))
           nU <- nU + nmiss
         }
         nterms <- length(r)
         answer <- matrix(, nrow=nU, ncol=nterms)
         for(k in 1:nterms) {
           # first determine saturated pair counts
           counts <- strausscounts(U, X, r[k], EqualPairs) 
           satcounts <- pmin.int(sat[k], counts)
           # trapdoor used by suffstat() 
           if(halfway) 
             answer[,k] <- satcounts
           else if(sat[k] == Inf)
             answer[,k] <- 2 * satcounts
           else {
             # extract counts for data points
             Uindex <- EqualPairs[,2]
             Xindex <- EqualPairs[,1]
             Xcounts <- integer(npoints(X))
             Xcounts[Xindex] <- counts[Uindex]
             # evaluate change in saturated counts of other data points
             change <- geyercounts(U, X, r[k], sat[k], Xcounts, EqualPairs)
             answer[,k] <- satcounts + change
           }
         }
         if(somemissing)
           answer <- answer[originalrows, , drop=FALSE]
         return(answer)
       }
  )
  class(BlankBG) <- "interact"

  BadGey <- function(r, sat) {
    instantiate.interact(BlankBG, list(r=r, sat=sat))
  }

  BadGey <- intermaker(BadGey, BlankBG)
  
  BadGey

})


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/beginner.R"
#
#  beginner.R
#
# Helpful information for beginners
#
#  $Revision: 1.2 $  $Date: 2014/10/24 00:22:30 $
#

print.autoexec <- function(x, ...) { x() }

beginner <- function(package="spatstat") {
  package <- as.character(substitute(package))
  RShowDoc("BEGINNER.txt", type="txt", package=package)
  return(invisible(NULL))
}

class(beginner) <- "autoexec"

foo <- local({
  fooText <- paste0("Error: object 'foo' not found.\n\n",
                    "'foo' is not a defined variable or function.\n",
                    "It is a placeholder name, which serves only to ",
                    "demonstrate a concept. It represents the name of ",
                    "any desired object or function. ", 
                    "Other placeholder names popular with computer scientists ",
                    "are 'bar', 'foobar', 'qux' and 'mork'.")

  foo <- function() {
    splat(fooText) 
    return(invisible(NULL))
  }
  class(foo) <- "autoexec"
  foo
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/bermantest.R"
#
# bermantest.R
#
# Test statistics from Berman (1986)
#
#  $Revision: 1.16 $  $Date: 2014/06/22 03:07:20 $
#
#

# --------- outdated --------

bermantest <- function(...) {
  message("bermantest is out of date; use berman.test")
#  .Deprecated("berman.test", package="spatstat")
  berman.test(...)
}

bermantest.ppp <- function(...) {
    message("bermantest.ppp is out of date; use berman.test.ppp")
#  .Deprecated("berman.test.ppp", package="spatstat")
  berman.test.ppp(...)
}

bermantest.ppm <- function(...) {
    message("bermantest.ppm is out of date; use berman.test.ppm")
#  .Deprecated("berman.test.ppm", package="spatstat")
  berman.test.ppm(...)
}

bermantest.lpp <- function(...) {
    message("bermantest.lpp is out of date; use berman.test.lpp")
#  .Deprecated("berman.test.lpp", package="spatstat")
  berman.test.lpp(...)
}

bermantest.lppm <- function(...) {
    message("bermantest.lppm is out of date; use berman.test.lppm")
#  .Deprecated("berman.test.lppm", package="spatstat")
  berman.test.lppm(...)
}

# ---------------------------

berman.test <- function(...) {
  UseMethod("berman.test")
}

berman.test.ppp <-
  function(X, covariate,
           which=c("Z1", "Z2"),
           alternative=c("two.sided", "less", "greater"),
           ...) {
    Xname <- short.deparse(substitute(X))
    covname <- short.deparse(substitute(covariate))
    if(is.character(covariate)) covname <- covariate
    which <- match.arg(which)
    alternative <- match.arg(alternative)

    do.call("bermantestEngine",
            resolve.defaults(list(ppm(X), covariate, which, alternative),
                             list(...),
                             list(modelname="CSR",
                                  covname=covname, dataname=Xname)))
}

berman.test.ppm <- function(model, covariate,
                           which=c("Z1", "Z2"),
                           alternative=c("two.sided", "less", "greater"),
                           ...) {
  modelname <- short.deparse(substitute(model))
  covname <- short.deparse(substitute(covariate))
  if(is.character(covariate)) covname <- covariate
  verifyclass(model, "ppm")
  which <- match.arg(which)
  alternative <- match.arg(alternative)
  if(is.poisson(model) && is.stationary(model))
    modelname <- "CSR"
  do.call("bermantestEngine",
          resolve.defaults(list(model, covariate, which, alternative),
                           list(...),
                           list(modelname=modelname,
                                covname=covname,
                                dataname=model$Qname)))
}

berman.test.lpp <-
  function(X, covariate,
           which=c("Z1", "Z2"),
           alternative=c("two.sided", "less", "greater"),
           ...) {
    Xname <- short.deparse(substitute(X))
    covname <- short.deparse(substitute(covariate))
    if(is.character(covariate)) covname <- covariate
    which <- match.arg(which)
    alternative <- match.arg(alternative)

    do.call("bermantestEngine",
            resolve.defaults(list(lppm(X), covariate, which, alternative),
                             list(...),
                             list(modelname="CSR",
                                  covname=covname, dataname=Xname)))
}

berman.test.lppm <- function(model, covariate,
                           which=c("Z1", "Z2"),
                           alternative=c("two.sided", "less", "greater"),
                           ...) {
  modelname <- short.deparse(substitute(model))
  covname <- short.deparse(substitute(covariate))
  if(is.character(covariate)) covname <- covariate
  verifyclass(model, "lppm")
  which <- match.arg(which)
  alternative <- match.arg(alternative)
  if(is.poisson(model) && is.stationary(model))
    modelname <- "CSR"
  do.call("bermantestEngine",
          resolve.defaults(list(model, covariate, which, alternative),
                           list(...),
                           list(modelname=modelname,
                                covname=covname,
                                dataname=model$Xname)))
}

bermantestEngine <- function(model, covariate,
                             which=c("Z1", "Z2"),
                             alternative=c("two.sided", "less", "greater"),
                             ...,
                             modelname, covname, dataname="") {

  csr <- is.poisson(model) && is.stationary(model)
  if(missing(modelname))
    modelname <- if(csr) "CSR" else short.deparse(substitute(model))
  if(missing(covname)) {
    covname <- short.deparse(substitute(covariate))
    if(is.character(covariate)) covname <- covariate
  }

  which <- match.arg(which)
  alternative <- match.arg(alternative)

  if(!is.poisson(model))
    stop("Only implemented for Poisson point process models")

  # ........... first assemble data ...............
  fram <- spatialCDFframe(model, covariate, ...,
                        modelname=modelname,
                        covname=covname,
                        dataname=dataname)
  fvalues <- fram$values
  info    <- fram$info
  # values of covariate at data points
  ZX <- fvalues$ZX
  # transformed to Unif[0,1] under H0
  U  <- fvalues$U
  # values of covariate at pixels
  Zvalues <- fvalues$Zvalues
  # corresponding pixel areas/weights
  weights <- fvalues$weights
  # intensity of model
  lambda  <- fvalues$lambda

  switch(which,
         Z1={
           #......... Berman Z1 statistic .....................
           method <-
             paste("Berman Z1 test of",
                   if(info$csr) "CSR" else "inhomogeneous Poisson process",
                   "in", info$spacename)
           # sum of covariate values at data points
           Sn <- sum(ZX)
           # predicted mean and variance
           lamwt <- lambda * weights
           En    <- sum(lamwt)
           ESn   <- sum(lamwt * Zvalues)
           varSn <- sum(lamwt * Zvalues^2)
           # working, for plot method
           working <- list(meanZX=mean(ZX),
                           meanZ=ESn/En)
           # standardise
           statistic <- (Sn - ESn)/sqrt(varSn)
           names(statistic) <- "Z1"
           p.value <- switch(alternative,
                            two.sided=2 * pnorm(-abs(statistic)),
                            less=pnorm(statistic),
                            greater=pnorm(statistic, lower.tail=FALSE))
           altblurb <- switch(alternative,
                              two.sided="two-sided",
                              less="mean value of covariate at random points is less than predicted under model",
                              greater="mean value of covariate at random points is greater than predicted under model")
           valuename <- paste("covariate",
                              sQuote(paste(covname, collapse="")),
                              "evaluated at points of",
                              sQuote(dataname))
         },
         Z2={
           #......... Berman Z2 statistic .....................
           method <-
             paste("Berman Z2 test of",
                   if(info$csr) "CSR" else "inhomogeneous Poisson process",
                   "in", info$spacename)
           npts <- length(ZX)
           statistic <- sqrt(12/npts) * (sum(U) - npts/2)
           working <- list(meanU=mean(U))
           names(statistic) <- "Z2"
           p.value <- switch(alternative,
                            two.sided=2 * pnorm(-abs(statistic)),
                            less=pnorm(statistic),
                            greater=pnorm(statistic, lower.tail=FALSE))
           altblurb <- switch(alternative,
                              two.sided="two-sided",
                              less="covariate values at random points have lower quantiles than predicted under model",
                              greater="covariate values at random points have higher quantiles than predicted under model")
           valuename <- paste("covariate",
                              sQuote(paste(covname, collapse="")),
                              "evaluated at points of",
                              sQuote(dataname), "\n\t",
                              "and transformed to uniform distribution under",
                              if(info$csr) modelname else sQuote(modelname))
         })
           
  out <- list(statistic=statistic,
              p.value=p.value,
              alternative=altblurb,
              method=method,
              which=which,
              working=working,
              data.name=valuename,
              fram=fram)
  class(out) <- c("htest", "bermantest")
  return(out)
}

plot.bermantest <-
  function(x, ...,
           lwd=par("lwd"), col=par("col"), lty=par("lty"),
           lwd0=lwd, col0=2, lty0=2)
{
  fram <- x$fram
  if(!is.null(fram)) {
    values <- fram$values
    info <- fram$info
  } else {
    # old style
    ks <- x$ks
    values <- attr(ks, "prep")
    info <- attr(ks, "info")
  }
  work <- x$working
  op <- options(useFancyQuotes=FALSE)
  switch(x$which,
         Z1={
           # plot cdf's of Z
           FZ <- values$FZ
           xxx <- get("x", environment(FZ))
           yyy <- get("y", environment(FZ))
           main <- c(x$method,
                     paste("based on distribution of covariate",
                           sQuote(info$covname)),
                     paste("Z1 statistic =", signif(x$statistic, 4)),
                     paste("p-value=", signif(x$p.value, 4)))
           do.call("plot.default",
                   resolve.defaults(
                                    list(x=xxx, y=yyy, type="l"),
                                    list(...),
                                    list(lwd=lwd0, col=col0, lty=lty0),
                                    list(xlab=info$covname,
                                         ylab="probability",
                                         main=main)))
           FZX <- values$FZX
           if(is.null(FZX))
             FZX <- ecdf(values$ZX)
           plot(FZX, add=TRUE, do.points=FALSE, lwd=lwd, col=col, lty=lty)
           abline(v=work$meanZ, lwd=lwd0,col=col0, lty=lty0, xpd=FALSE)
           abline(v=work$meanZX, lwd=lwd,col=col, lty=lty, xpd=FALSE)
         },
         Z2={
           # plot cdf of U
           U <- values$U
           cdfU <- ecdf(U)
           main <- c(x$method,
                     paste("based on distribution of covariate",
                           sQuote(info$covname)),
                     paste("Z2 statistic =", signif(x$statistic, 4)),
                     paste("p-value=", signif(x$p.value, 4)))
           do.call("plot.ecdf",
                   resolve.defaults(
                                    list(cdfU),
                                    list(...),
                                    list(do.points=FALSE, asp=1),
                                    list(lwd=lwd, col=col, lty=lty),
                                    list(xlab="U", ylab="relative frequency"),
                                    list(main=main)))
           abline(0,1,lwd=lwd0,col=col0,lty=lty0, xpd=FALSE)
           abline(v=0.5, lwd=lwd0,col=col0,lty=lty0, xpd=FALSE)
           abline(v=work$meanU, lwd=lwd,col=col,lty=lty, xpd=FALSE)
         })
  options(op)
  return(invisible(NULL))
}



#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/blur.R"
#
# blur.R
#
# apply Gaussian blur to an image
#
#    $Revision: 1.14 $   $Date: 2014/10/24 00:22:30 $
#
fillNA <- function(x, value=0) {
  stopifnot(is.im(x))
  v <- x$v
  v[is.na(v)] <- value
  x$v <- v
  return(x)
}

Smooth.im <- function(X, sigma=NULL, ...,
                      normalise=FALSE, bleed=TRUE, varcov=NULL) {
  blur(X, sigma=sigma, ..., normalise=normalise, bleed=bleed, varcov=varcov)
}

blur <- function(x, sigma=NULL, ..., normalise=FALSE, bleed=TRUE, varcov=NULL) {
  stopifnot(is.im(x))
  # determine smoothing kernel 
  sigma.given <- !is.null(sigma)
  varcov.given <- !is.null(varcov)
  if (sigma.given) {
    stopifnot(is.numeric(sigma))
    stopifnot(length(sigma) %in% c(1, 2))
    stopifnot(all(sigma > 0))
  }
  if (varcov.given)
    stopifnot(is.matrix(varcov) && nrow(varcov) == 2 && ncol(varcov) ==
              2)
  ngiven <- varcov.given + sigma.given
  switch(ngiven + 1,
         {
           sigma <- (1/8) * min(diff(x$xrange), diff(x$yrange))
         }, {
           if (sigma.given && length(sigma) == 2)
             varcov <- diag(sigma^2)
           if (!is.null(varcov))
             sigma <- NULL
         }, {
           stop(paste("Give only one of the arguments", sQuote("sigma"),
                      "and", sQuote("varcov")))
         })
  # replace NA's in image raster by zeroes 
  X <- fillNA(x, 0)
  # convolve with Gaussian
  Y <- second.moment.calc(X, sigma=sigma, varcov=varcov, what="smooth")
  # if no bleeding, we restrict data to the original boundary
  if(!bleed)
    Y$v[is.na(x$v)] <- NA
  # 
  if(!normalise)
    return(Y)
  # normalisation:
  # convert original image to window (0/1 image)
  Xone <- x
  isna <- is.na(x$v)
  Xone$v[isna] <- 0
  Xone$v[!isna] <- 1
  # convolve with Gaussian
  Ydenom <- second.moment.calc(Xone, sigma=sigma, ..., varcov=varcov, what="smooth")
  # normalise
  Z <- eval.im(Y/Ydenom)
  return(Z)
}
  
safelookup <- function(Z, X, factor=2, warn=TRUE) {
  # X is a ppp
  # evaluates Z[X], replacing any NA's by blur(Z)[X]
  Zvals <- Z[X, drop=FALSE]
  if(any(isna <- is.na(Zvals))) {
    # First pass - look up values at neighbouring pixels if valid
    XX <- X[isna]
    rc <- nearest.valid.pixel(XX$x, XX$y, Z)
    Zvals[isna] <- Z$v[cbind(rc$row, rc$col)]
  }
  if(any(isna <- is.na(Zvals))) {
    # Second pass - extrapolate
    XX <- X[isna]
    pixdiam <- sqrt(Z$xstep^2 + Z$ystep^2)
    # expand domain of Z 
    RX <- as.rectangle(X)
    RZ <- as.rectangle(Z)
    bb <- boundingbox(RX, RZ)
    big <- grow.rectangle(bb, 2 * pixdiam)
    Z <- rebound.im(Z, big)
    # now blur
    Zblur <- blur(Z, factor * pixdiam, bleed=TRUE, normalise=TRUE)
    Bvals <- Zblur[XX, drop=FALSE]
    if(any(is.na(Bvals))) 
      stop("Internal error: pixel values were NA, even after blurring")
    Zvals[isna] <- Bvals
    if(warn)
      warning(paste(sum(isna), "out of", X$n, "pixel values",
                    "were outside the pixel image domain",
                    "and were estimated by convolution"))
  }
  return(Zvals)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/boundingbox.R"
##
## boundingbox.R
##
## $Revision: 1.5 $ $Date: 2014/08/06 01:12:38 $

bounding.box <- function(...) {
  .Deprecated("boundingbox", "spatstat")
  boundingbox(...)
}

boundingbox <- function(...) {
  ## remove any NULL arguments
  arglist <- list(...)
  if(any(isnull <- sapply(arglist, is.null))) {
    if(length(arglist[!isnull]))
       return(do.call("boundingbox", arglist[!isnull]))
    stop("No non-null arguments given.\n")
  }
  UseMethod("boundingbox")
}

boundingbox.ppp  <-
boundingbox.psp  <-
boundingbox.owin <-
boundingbox.list <-
boundingbox.im   <- function(...) {
   bbEngine(...)
}

recognise.spatstat.type <- local({

  knowntypes <- c("ppp","psp","owin","im")

  function(x) {
    for(kt in knowntypes)
      if(inherits(x, kt)) return(kt)
    aso <- try(as.owin(x), silent=TRUE)
    if(!inherits(aso, "try-error")) return("as.owin")
    if(is.list(x) && checkfields(x, c("x", "y"))
       && is.numeric(x$x) && is.numeric(x$y) &&
       is.vector(x$x) && is.vector(x$y) && length(x$x) == length(x$y))
        return("listxy")
    return("unknown")
  }
})

bbEngine <- local({

  bb.listxy <- function(X) owin(range(X$x), range(X$y))

  bbEngine <- function(...) {
    wins <- list(...)
    ## first detect any numeric vector arguments
    if(any(isnumvec <- unlist(lapply(wins, is.vector)) &
           unlist(lapply(wins, is.numeric)))) {
      ## invoke default method on these arguments
      bb <- do.call("boundingbox", wins[isnumvec])
      ## repack
      wins <- append(wins[!isnumvec], list(bb))
    }
    if(length(wins) > 1) {
      ## multiple arguments -- compute bounding box for each argument.
      objtype <- unlist(lapply(wins, recognise.spatstat.type))
      nbad <- sum(objtype == "unknown")
      if(nbad > 0) {
        whinge <- paste("Function boundingbox called with",
                        nbad,"unrecognised",
                        ngettext(nbad,"argument","arguments"))
        stop(whinge, call.=FALSE)
      }
      if(any(isppp <- (objtype == "ppp"))) 
        wins[isppp] <- lapply(wins[isppp], boundingbox)
      if(any(islistxy <- (objtype == "listxy")))
        wins[islistxy] <- lapply(wins[islistxy], bb.listxy)
      ## then convert all windows to owin
      wins <- lapply(wins, as.owin)
      ## then take bounding box of each window
      boxes <- lapply(wins, boundingbox)
      ## discard NULL values
      isnull <- unlist(lapply(boxes, is.null))
      boxes <- boxes[!isnull]
      ## take bounding box of these boxes
      xrange <- range(unlist(lapply(boxes, getElement, name="xrange")))
      yrange <- range(unlist(lapply(boxes, getElement, name="yrange")))
      W <- owin(xrange, yrange)
      ## If all of the windows have a common unit name, give
      ## that unit name to the bounding box.
      youse <- unique(t(sapply(boxes,unitname)))
      if(nrow(youse)==1) {
        ute <- unlist(youse[1,])
        unitname(W) <- ute
      }
      return(W)
    }

    ## single argument
    w <- wins[[1]]
    if(is.null(w))
      return(NULL)
    
    wtype <- recognise.spatstat.type(w)
    ## point pattern?
    if(wtype == "ppp")
      return(boundingbox(coords(w)))
    
    ## list(x,y)
    if(wtype == "listxy")
      return(bb.listxy(w))
          
    ## convert to window
    w <- as.owin(w)

    ## determine a tight bounding box for the window w
    switch(w$type,
           rectangle = {
             return(w)
           },
           polygonal = {
             bdry <- w$bdry
             if(length(bdry) == 0)
               return(NULL)
             xr <- range(unlist(lapply(bdry, function(a) range(a$x))))
             yr <- range(unlist(lapply(bdry, function(a) range(a$y))))
             return(owin(xr, yr, unitname=unitname(w)))
           },
           mask = {
             m <- w$m
             x <- rasterx.mask(w)
             y <- rastery.mask(w)
             xr <- range(x[m]) + c(-1,1) * w$xstep/2
             yr <- range(y[m]) + c(-1,1) * w$ystep/2
             return(owin(xr, yr, unitname=unitname(w)))
           },
           stop("unrecognised window type", w$type)
           )
  }

  bbEngine
})


boundingbox.default <- local({

  bb.listxy <- function(X) owin(range(X$x), range(X$y))

  boundingbox.default <- function(...) {
    arglist <- list(...)
    bb <- NULL
    if(length(arglist) == 0)
      return(bb)
    ## handle numeric vector arguments
    if(any(isnumvec <- unlist(lapply(arglist, is.vector)) &
           unlist(lapply(arglist, is.numeric)))) {
      nvec <- sum(isnumvec)
      if(nvec != 2)
        stop(paste("boundingbox.default expects 2 numeric vectors:",
                   nvec, "were supplied"),
             call.=FALSE)
      vecs <- arglist[isnumvec]
      x <- vecs[[1]]
      y <- vecs[[2]]
      bb <- if(length(x) == length(y)) owin(range(x), range(y)) else NULL
      arglist <- arglist[!isnumvec]
    }
    if(length(arglist) == 0)
      return(bb)
    ## other objects are present
    objtype <- unlist(lapply(arglist, recognise.spatstat.type))
    ## Unrecognised?
    nbad <- sum(objtype == "unknown")
    if(nbad > 0) {
      whinge <- paste("Function boundingbox called with",
                      nbad,"unrecognised",
                      ngettext(nbad,"argument","arguments"))
      stop(whinge, call.=FALSE)
    }
    if(any(aso <- (objtype == "as.owin"))) {
      ## promote objects to owin (to avoid infinite recursion!)
      arglist[aso] <- lapply(arglist[aso], as.owin)
    }
    if(any(lxy <- (objtype == "listxy"))) {
      ## handle list(x,y) objects 
      arglist[lxy] <- lapply(arglist[lxy], bb.listxy)
    }
    result <- do.call("boundingbox",
                      if(is.null(bb)) arglist else append(list(bb), arglist))
    return(result)
  }

  boundingbox.default
})


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/breakpts.R"
#
#	breakpts.S
#
#	A simple class definition for the specification
#       of histogram breakpoints in the special form we need them.
#
#	even.breaks()
#
#	$Revision: 1.14 $	$Date: 2014/09/24 05:23:36 $
#
#
#       Other functions in this directory use the standard Splus function
#	hist() to compute histograms of distance values.
#       One argument of hist() is the vector 'breaks'
#	of breakpoints for the histogram cells. 
#
#       The breakpoints must
#            (a) span the range of the data
#            (b) be given in increasing order
#            (c) satisfy breaks[2] = 0,
#
#	The function make.even.breaks() will create suitable breakpoints.
#
#       Condition (c) means that the first histogram cell has
#       *right* endpoint equal to 0.
#
#       Since all our distance values are nonnegative, the effect of (c) is
#       that the first histogram cell counts the distance values which are
#       exactly equal to 0. Hence F(0), the probability P{X = 0},
#       is estimated without a discretisation bias.
#
#	We assume the histograms have followed the default counting rule
#	in hist(), which is such that the k-th entry of the histogram
#	counts the number of data values in 
#		I_k = ( breaks[k],breaks[k+1] ]	for k > 1
#		I_1 = [ breaks[1],breaks[2]   ]
#
#	The implementations of estimators of c.d.f's in this directory
#       produce vectors of length = length(breaks)-1
#       with value[k] = estimate of F(breaks[k+1]),
#       i.e. value[k] is an estimate of the c.d.f. at the RIGHT endpoint
#       of the kth histogram cell.
#
#       An object of class 'breakpts' contains:
#
#              $val     the actual breakpoints
#              $max     the maximum value (= last breakpoint)
#              $ncells  total number of histogram cells
#              $r       right endpoints, r = val[-1]
#              $even    logical = TRUE if cells known to be evenly spaced
#              $npos    number of histogram cells on the positive halfline
#                        = length(val) - 2,
#                       or NULL if cells not evenly spaced
#              $step    histogram cell width
#                       or NULL if cells not evenly spaced
#       
# --------------------------------------------------------------------
breakpts <- function(val, maxi, even=FALSE, npos=NULL, step=NULL) {
  out <- list(val=val, max=maxi, ncells=length(val)-1, r = val[-1],
              even=even, npos=npos, step=step)
  class(out) <- "breakpts"
  out
}

scalardilate.breakpts <- function(X, f, ...) {
  out <- with(X,
              list(val    = f*val,
                   max    = f*max,
                   ncells = ncells,
                   r      = f*r,
                   even   = even,
                   npos   = npos,
                   step   = f*step))
  class(out) <- "breakpts"
  out
}  
                            
"make.even.breaks" <- 
function(bmax, npos, bstep) {
  if(bmax <= 0)
    stop("bmax must be positive")
  if(missing(bstep) && missing(npos))
    stop(paste("Must specify either", sQuote("bstep"),
               "or", sQuote("npos")))
  if(!missing(npos)) {
    bstep <- bmax/npos
    val <- seq(from=0, to=bmax, length.out=npos+1)
    val <- c(-bstep,val)
    right <- bmax
  } else {
    npos <- ceiling(bmax/bstep)
    right <- bstep * npos
    val <- seq(from=0, to=right, length.out=npos+1)
    val <- c(-bstep,val)
  }
  breakpts(val, right, TRUE, npos, bstep)
}

"as.breakpts" <- function(...) {

  XL <- list(...)

  if(length(XL) == 1) {
    # single argument
    X <- XL[[1]]

    if(!is.null(class(X)) && class(X) == "breakpts")
    # X already in correct form
      return(X)
  
    if(is.vector(X) && length(X) > 2) {
    # it's a vector
      if(X[2] != 0)
        stop("breakpoints do not satisfy breaks[2] = 0")
      # The following test for equal spacing is used in hist.default
      steps <- diff(X)
      if(diff(range(steps)) < 1e-07 * mean(steps))
        # equally spaced
        return(breakpts(X, max(X), TRUE, length(X)-2, steps[1]))
      else
        # unknown spacing
        return(breakpts(X, max(X), FALSE))
    }
  } else {

    # There are multiple arguments.
  
    # exactly two arguments - interpret as even.breaks()
    if(length(XL) == 2)
      return(make.even.breaks(XL[[1]], XL[[2]]))

    # two arguments 'max' and 'npos'
  
    if(!is.null(XL$max) && !is.null(XL$npos))
      return(make.even.breaks(XL$max, XL$npos))

    # otherwise
    stop("Don't know how to convert these data to breakpoints")
  }
  # never reached
}


check.hist.lengths <- function(hist, breaks) {
  verifyclass(breaks, "breakpts")
  nh <- length(hist)
  nb <- breaks$ncells
  if(nh != nb)
    stop(paste("Length of histogram =", nh,
               "not equal to number of histogram cells =", nb))
}

breakpts.from.r <- function(r) {
  if(!is.numeric(r) && !is.vector(r))
    stop("r must be a numeric vector")
  if(length(r) < 2)
    stop(paste("r has length", length(r), "- must be at least 2"))
  if(r[1] != 0)
    stop("First r value must be 0")
  if(any(diff(r) <= 0))
    stop("successive values of r must be increasing")
  dr <- r[2] - r[1]
  b <- c(-dr, r)
  return(as.breakpts(b))
}

handle.r.b.args <- function(r=NULL, breaks=NULL, window, pixeps=NULL,
                            rmaxdefault=NULL) {

        if(!is.null(r) && !is.null(breaks))
          stop(paste("Do not specify both",
                     sQuote("r"), "and", sQuote("breaks")))
  
        if(!is.null(breaks)) {
          breaks <- as.breakpts(breaks)
        } else if(!is.null(r)) {
          breaks <- breakpts.from.r(r)
	} else {
          rmax <- rmaxdefault %orifnull% diameter(Frame(window))
          if(is.null(pixeps)) {
            pixeps <- if(is.mask(window))
                      min(window$xstep, window$ystep) else rmax/128
          }
          rstep <- pixeps/4
          breaks <- make.even.breaks(rmax, bstep=rstep)
        }

        return(breaks)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/bw.diggle.R"
##
## bw.diggle.R
##
## bandwidth selection rules bw.diggle and bw.scott (for density.ppp)
##
## $Revision: 1.2 $ $Date: 2014/10/24 00:22:30 $
##

bw.scott <- function(X) {
  stopifnot(is.ppp(X))
  n <- npoints(X)
  sdx <- sqrt(var(X$x))
  sdy <- sqrt(var(X$y))
  return(c(sdx, sdy) * n^(-1/6))
}

bw.diggle <- function(X, ..., correction="good", hmax=NULL) {
  stopifnot(is.ppp(X))
  # secret option for debugging
  mf <- function(..., method=c("C", "interpreted")) match.arg(method)
  method <- mf(...)
  #
  lambda <- npoints(X)/area(Window(X))
  r <- if(is.null(hmax)) NULL else seq(0, 4*hmax, length=512)
  K <- Kest(X, r=r, correction=correction)
  yname <- fvnames(K, ".y")
  K <- K[, c("r", yname)]
  ## check that K values can be passed to C code
  if(any(bad <- !is.finite(K[[yname]]))) {
    ## throw out bad values
    lastgood <- min(which(bad)) - 1
    if(lastgood < 2)
      stop("K function yields too many NA/NaN values")
    K <- K[1:lastgood, ]
  }
  rvals <- K$r
  # evaluation of M(r) requires K(2r)
  rmax2 <- max(rvals)/2
  if(!is.null(alim <- attr(K, "alim"))) rmax2 <- min(alim[2], rmax2)
  ok <- (rvals <= rmax2)
  switch(method,
         interpreted = {
           rvals <- rvals[ok]
           nr <- length(rvals)
           J <- numeric(nr)
           phi <- function(x,h) { 
             if(h <= 0) return(numeric(length(x)))
             y <- pmax.int(0, pmin.int(1, x/(2 * h)))
             4 * pi * h^2 * (acos(y) - y * sqrt(1 - y^2))
           }
           for(i in 1:nr) 
             J[i] <- stieltjes(phi, K, h=rvals[i])[[yname]]/(2 * pi)
         },
         C = {
           nr <- length(rvals)
           nrmax <- sum(ok)
           dK <- diff(K[[yname]])
           ndK <- length(dK)
           z <- .C("digberJ",
                   r=as.double(rvals),
                   dK=as.double(dK),
                   nr=as.integer(nr),
                   nrmax=as.integer(nrmax),
                   ndK=as.integer(ndK),
                   J=as.double(numeric(nrmax)))
           J <- z$J
           rvals <- rvals[ok]
         })
  pir2 <- pi * rvals^2
  M <- (1/lambda - 2 * K[[yname]][ok])/pir2 + J/pir2^2
  # This calculation was for the uniform kernel on B(0,h)
  # Convert to standard deviation of (one-dimensional marginal) kernel
  sigma <- rvals/2
  result <- bw.optim(M, sigma,
                     creator="bw.diggle",
                     criterion="Berman-Diggle Cross-Validation",
                     J=J,
                     lambda=lambda)
  return(result)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/bw.optim.R"
#
# bw.optim.R
#
#  Class of optimised bandwidths
#  Plotting the object displays the optimisation criterion
#
#  $Revision: 1.21 $  $Date: 2013/07/08 04:54:41 $
#

bw.optim <- function(cv, h, iopt=which.min(cv), ...,
                     cvname, hname,
                     criterion="cross-validation") {
  if(missing(cvname) || is.null(cvname)) cvname <- deparse(substitute(cv))
  if(missing(hname) || is.null(hname)) hname <- deparse(substitute(h))
  stopifnot(is.numeric(cv))
  stopifnot(is.numeric(h))
  stopifnot(length(h) == length(cv))
  result <- h[iopt]
  attr(result, "cv") <- cv
  attr(result, "h") <- h
  attr(result, "iopt") <- iopt
  attr(result, "labels") <- list(hname=hname, cvname=cvname)
  attr(result, "info") <- list(...)
  attr(result, "criterion") <- criterion
  class(result) <- "bw.optim"
  return(result)
}

print.bw.optim <- function(x, ...) {
  y <- as.numeric(x)
  names(y) <- attr(x, "labels")$hname
  print(y, ...)
  return(invisible(NULL))
}

as.data.frame.bw.optim <- function(x, ...) {
  h <- attr(x, "h")
  cv <- attr(x, "cv")
  df <- data.frame(h, cv)
  labels <- attr(x, "labels")
  colnames(df) <- labels[c("hname", "cvname")]
  info <- attr(x, "info")
  if(length(info) > 0) {
    lengths <- unlist(lapply(info, length))
    if(any(ok <- (lengths == nrow(df)))) {
      df <- cbind(df, as.data.frame(info[ok]))
    }
  }
  return(df)
}

as.fv.bw.optim <- function(x) {
  # convert to fv object
  df <- as.data.frame(x)
  dfnames <- colnames(df)
  hname <- dfnames[1]
  cvname <- dfnames[2]
  descrip <- c("smoothing parameter",
               paste(attr(x, "criterion"), "criterion"))
  if(ncol(df) > 2)
    descrip <- c(descrip, paste("Additional variable", sQuote(dfnames[-(1:2)])))
  labl <- c(hname, paste0(dfnames[-1], paren(hname)))
  yexp <- substitute(CV(h), list(CV=as.name(cvname), h=as.name(hname)))
  xfv <- fv(df,
            argu=hname,
            ylab=yexp,
            valu=cvname,
            labl=labl,
            desc=descrip,
            fname=cvname,
            yexp=yexp)
  fvnames(xfv, ".") <- cvname
  return(xfv)
}

plot.bw.optim <- function(x, ...,
                          showopt=TRUE, optargs=list(lty=3, col="blue")) {
  xname <- short.deparse(substitute(x))
  # convert to fv object
  xfv <- as.fv(x)
  # plot cross-validation criterion
  out <- do.call("plot.fv",
                 resolve.defaults(list(x=xfv),
                                  list(...),
                                  list(main=xname)))
  # Turn off 'showopt' if the x-variable is not the bandwidth
  if(missing(showopt)) {
    argh <- list(...)
    isfmla <- unlist(lapply(argh, inherits, what="formula"))
    if(any(isfmla)) {
      fmla <- argh[[min(which(isfmla))]]
      xvar <- deparse(rhs.of.formula(fmla, tilde=FALSE))
      if(!(identical(xvar, fvnames(xfv, ".x")) || identical(xvar, ".x")))
        showopt <- FALSE
    }
  }
  # show optimal value?
  if(showopt) {
    hopt <- as.numeric(x)
    do.call("abline", append(list(v=hopt), optargs))
  }
  if(is.null(out)) return(invisible(NULL))
  return(out)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/bw.ppl.R"
#
#   bw.ppl.R
#
#   Likelihood cross-validation for kernel smoother of point pattern
#
#   $Revision: 1.3 $ $Date: 2014/01/09 03:51:59 $
#

bw.ppl <- function(X, ..., srange=NULL, ns=16) {
  stopifnot(is.ppp(X))
  if(!is.null(srange)) check.range(srange) else {
    nnd <- nndist(X)
    srange <- c(min(nnd[nnd > 0]), diameter(as.owin(X))/2)
  }
  sigma <- exp(seq(log(srange[1]), log(srange[2]), length=ns))
  cv <- numeric(ns)
  for(i in 1:ns) {
    si <- sigma[i]
    lamx <- density(X, sigma=si, at="points", leaveoneout=TRUE)
    lam <- density(X, sigma=si)
    cv[i] <- sum(log(lamx)) - integral.im(lam)
  }
  result <- bw.optim(cv, sigma, iopt=which.max(cv), 
                     creator="bw.ppl",
                     criterion="Likelihood Cross-Validation")
  return(result)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/by.ppp.R"
#
#   by.ppp.R
#
#  $Revision: 1.5 $  $Date: 2011/05/18 01:29:48 $
#

by.ppp <- function(data, INDICES=marks(data), FUN, ...) {
  if(missing(INDICES))
    INDICES <- marks(data, dfok=FALSE)
  if(missing(FUN))
    stop("FUN is missing")
  y <- split(data, INDICES)
  z <- list()
  for(i in seq_along(y))
    z[[i]] <- FUN(y[[i]], ...)
  names(z) <- names(y)
  z <- as.listof(z)
  return(z)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/cdf.test.mppm.R"
#
# cdf.test.mppm.R
#
# $Revision: 1.12 $  $Date: 2014/06/10 02:47:08 $
#
cdf.test.mppm <- function(model, covariate,
                          test=c("ks", "cvm", "ad"), ..., verbose=TRUE,
                         interpolate=FALSE, fast=TRUE, jitter=TRUE) {
  modelname <- short.deparse(substitute(model))
  covname <- short.deparse(substitute(covariate))
  test <- match.arg(test)
  stopifnot(is.mppm(model))
  if(!is.poisson.mppm(model))
    stop("Only implemented for Poisson models")
  pixelvalues <- function(z) { as.vector(as.matrix(z)) }
  # extract things from model
  data  <- model$data
  npat  <- model$npat
  Y     <- data.mppm(model)
  if(fast) {
    # extract original quadrature schemes and convert to point patterns
    QQ  <- quad.mppm(model)
    PP  <- lapply(QQ, union.quad)
    Zweights <- lapply(QQ, w.quad)
  } else
    Zweights <- list()
  # `evaluate' covariate
  if(verbose)
    cat("Extracting covariate...")
  if(is.character(covariate)) {
    # extract covariate with this name from data used to fit model
    if(!(covariate %in% names(data)))
      stop(paste("Model does not contain a covariate called",
                 dQuote(covariate)))
    covname <- covariate
    covariate <- data[, covname, drop=TRUE]
  } else if(inherits(covariate, "listof")) {
    if(length(covariate) != npat)
      stop(paste("Length of list of covariate values does not match",
                 "number of point patterns in data of original model"))
  } else if(is.hyperframe(covariate)) {
    # extract first column
    covariate <- covariate[,1, drop=TRUE]
    if(length(covariate) != npat)
      stop(paste("Number of rows of covariate hyperframe does not match",
                 "number of point patterns in data of original model"))
  } else if(is.function(covariate) || is.im(covariate)) {
    # replicate to make a list
    covariate <- rep(list(covariate), npat)
    class(covariate) <- c("listof", class(covariate))
  } else     
  stop(paste("Format of argument", sQuote("covariates"), "not understood"))
  if(verbose)
    cat("done.\nComputing statistics for each pattern...")

  # compile information for test from each row
  Zvalues <- ZX <- Win <- list()
  for(i in 1:npat) {
    if(verbose) progressreport(i, npat)
    XI <- Y[[i]]
    if(fast)
      PI <- PP[[i]]
    else
      WI <- XI$window
    covariateI <- covariate[[i]]
    if(is.im(covariateI)) {
      type <- "im"
      # evaluate at data points
      ZXI <-
        if(interpolate) interp.im(covariateI, XI$x, XI$y)
        else covariateI[XI]
      if(fast) {
        # covariate values for quadrature points
        ZI <- covariateI[PI]
      } else {
        # covariate image inside window
        ZI <- covariateI[WI, drop=FALSE]
        # corresponding mask
        WI <- as.owin(ZI)
        # pixel areas 
        Zweights[[i]] <- rep(WI$xstep * WI$ystep, prod(WI$dim))
      }
    } else if(is.function(covariateI)) {
      type <- "function"
      # evaluate exactly at data points
      ZXI <- covariateI(XI$x, XI$y)
      if(fast) {
        # covariate values for quadrature points
        ZI <- covariateI(PI$x, PI$y)
      } else {
        # window
        WI <- as.mask(WI)
        # covariate image inside window
        ZI <- as.im(covariateI, W=WI)
        # pixel areas 
        Zweights[[i]] <- rep(WI$xstep * WI$ystep, prod(WI$dim))
      }
    } else
    stop("covariate should be an image or a function(x,y)")
    ZX[[i]] <- ZXI
    if(fast)
      Zvalues[[i]] <- ZI      
    else {
      Win[[i]] <- WI
      # values of covariate in window
      Zvalues[[i]] <- pixelvalues(ZI)
    }
  }

  if(verbose)
    cat("done.\nComputing predicted intensity...")

  # compute predicted intensities
  trend <-
    if(fast)
      fitted(model, type="trend")
    else
      predict(model, type="trend", locations=Win, verbose=verbose)$trend
  
  if(verbose)
    cat("done.\nExtracting...")
  # extract relevant values
  lambda <- if(fast) trend else lapply(trend, pixelvalues)
  if(verbose)
    cat("done.\nPerforming test...")
  
  # flatten to vectors
  lambda <- unlist(lambda)
  Zweights <- unlist(Zweights)
  Zvalues <- unlist(Zvalues)
  ZX      <- unlist(ZX)
  if(length(lambda) != length(Zvalues))
    stop("Internal error: mismatch between predicted values and Z values")
  if(length(Zvalues) != length(Zweights))
    stop("Internal error: mismatch between Z values and Z weights")
  lambda <- lambda * Zweights
  
  # form weighted cdf of Z values in window
  FZ <- ewcdf(Zvalues, lambda/sum(lambda))
  # Ensure support of cdf includes the range of the data
  xxx <- knots(FZ)
  yyy <- FZ(xxx)
  if(min(xxx) > min(ZX)) {
    xxx <- c(min(ZX), xxx)
    yyy <- c(0, yyy)
  }
  if(max(xxx) < max(ZX)) {
    xxx <- c(xxx, max(ZX))
    yyy <- c(yyy, 1)
  }
  # make piecewise linear approximation of cdf
  FZ <- approxfun(xxx, yyy, rule=2)
  # evaluate at data points
  if(!jitter)
    U <- FZ(ZX)
  else {
    # jitter observed values to avoid ties
    grain <- min(diff(sort(unique(ZX))))/8
    jit <- runif(length(ZX), min=0, max=grain)
    sgn <- sample(c(-1,1), length(ZX), replace=TRUE)
    sgn[ZX==min(xxx)] <- 1
    sgn[ZX==max(xxx)] <- -1
    U <- FZ(ZX + sgn*jit)
  }

  # Test uniformity
  result <- switch(test,
                   ks  = ks.test(U, "punif", ...),
                   cvm = cvm.test(U, "punif", ...),
                   ad = ad.test(U, "punif", ...))
  testname <- switch(test,
                     ks="Kolmogorov-Smirnov",
                     cvm="Cramer-Von Mises",
                     ad="Anderson-Darling")
  result$method <- paste("Spatial", testname, "test")
  result$data.name <-
    paste("predicted cdf of covariate", sQuote(paste(covname, collapse="")),
          "evaluated at data points of", sQuote(modelname))
  if(verbose)
    cat("done.\n")
  class(result) <- c("cdftest", class(result))
  attr(result, "prep") <- list(Zvalues = Zvalues, lambda = lambda,
                               ZX = ZX, FZ = FZ, U = U, type = type)
  attr(result, "info") <- list(modelname = modelname, covname = covname)
  return(result)        
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/cdftest.R"
#
#  cdftest.R
#
#  $Revision: 2.11 $  $Date: 2014/12/19 11:25:15 $
#
#

# --------- old -------------

ks.test.ppm <- function(...) {
  .Deprecated("cdf.test.ppm", package="spatstat")
  cdf.test.ppm(...)
}

kstest <- kstest.ppp <- kstest.ppm <- kstest.lpp <- kstest.lppm <-
  kstest.slrm <-
  function(...) {
    message("kstest is out of date; use cdf.test")
#  .Deprecated("cdf.test", package="spatstat")
  cdf.test(..., test="ks")
}

# ---------------------------

cdf.test <- function(...) {
  UseMethod("cdf.test")
}

cdf.test.ppp <-
  function(X, covariate, test=c("ks", "cvm", "ad"), ..., jitter=TRUE) {
    Xname <- short.deparse(substitute(X))
    covname <- singlestring(short.deparse(substitute(covariate)))
    test <- match.arg(test)
    if(is.character(covariate)) covname <- covariate
    if(!is.marked(X, dfok=TRUE)) {
      # unmarked
      model <- ppm(X)
      modelname <- "CSR"
    } else if(is.multitype(X)) {
      # multitype
      mf <- summary(X)$marks$frequency
      if(all(mf > 0)) {
        model <- ppm(X ~marks)
        modelname <- "CSRI"
      } else {
        warning("Ignoring marks, because some mark values have zero frequency")
        X <- unmark(X)
        model <- ppm(X)
        modelname <- "CSR"
      } 
    } else {
      # marked - general case
      X <- unmark(X)
      warning("marks ignored")
      model <- ppm(X)
      modelname <- "CSR"
    }
    do.call("spatialCDFtest",
            resolve.defaults(list(model, covariate, test=test),
                             list(jitter=jitter),
                             list(...),
                             list(modelname=modelname,
                                  covname=covname, dataname=Xname)))
}

cdf.test.ppm <- 
  function(model, covariate, test=c("ks", "cvm", "ad"), ...,
           jitter=TRUE, nsim=99, verbose=TRUE) {
  modelname <- short.deparse(substitute(model))
  covname <- singlestring(short.deparse(substitute(covariate)))
  test <- match.arg(test)
  verifyclass(model, "ppm")
  if(is.character(covariate)) covname <- covariate
  if(is.poisson(model) && is.stationary(model))
    modelname <- "CSR"
  do.call("spatialCDFtest",
          resolve.defaults(list(model, covariate, test=test),
                           list(jitter=jitter, nsim=nsim, verbose=verbose),
                           list(...),
                           list(modelname=modelname,
                                covname=covname)))
}

cdf.test.lpp <-
  function(X, covariate, test=c("ks", "cvm", "ad"), ..., jitter=TRUE) {
    Xname <- short.deparse(substitute(X))
    covname <- singlestring(short.deparse(substitute(covariate)))
    test <- match.arg(test)
    if(is.character(covariate)) covname <- covariate
    if(!is.marked(X, dfok=TRUE)) {
      # unmarked
      model <- lppm(X)
      modelname <- "CSR"
    } else if(is.multitype(X)) {
      # multitype
      mf <- table(marks(X))
      if(all(mf > 0)) {
        model <- lppm(X ~ marks)
        modelname <- "CSRI"
      } else {
        warning("Ignoring marks, because some mark values have zero frequency")
        X <- unmark(X)
        model <- ppm(X)
        modelname <- "CSR"
      } 
    } else {
      # marked - general case
      X <- unmark(X)
      warning("marks ignored")
      model <- ppm(X)
      modelname <- "CSR"
    }
    do.call("spatialCDFtest",
            resolve.defaults(list(model, covariate, test=test),
                             list(jitter=jitter),
                             list(...),
                             list(modelname=modelname,
                                  covname=covname, dataname=Xname)))
}

cdf.test.lppm <- function(model, covariate,
                          test=c("ks", "cvm", "ad"),
                          ..., jitter=TRUE,
                          nsim=99, verbose=TRUE) {
  modelname <- short.deparse(substitute(model))
  covname <- singlestring(short.deparse(substitute(covariate)))
  test <- match.arg(test)
  verifyclass(model, "lppm")
  if(is.character(covariate)) covname <- covariate
  if(is.poisson(model) && is.stationary(model))
    modelname <- "CSR"
  do.call("spatialCDFtest",
          resolve.defaults(list(model, covariate, test=test),
                           list(jitter=jitter, nsim=nsim, verbose=verbose),
                           list(...),
                           list(modelname=modelname,
                                covname=covname)))
}


cdf.test.slrm <- function(model, covariate,
                          test=c("ks", "cvm", "ad"), ...,
                          modelname=NULL, covname=NULL) {
  # get names
  if(is.null(modelname))
    modelname <- short.deparse(substitute(model))
  if(is.null(covname))
    covname <- short.deparse(substitute(covariate))
  dataname <- model$CallInfo$responsename
  test <- match.arg(test)
  #
  stopifnot(is.slrm(model))
  stopifnot(is.im(covariate))
  # extract data
  prob <- fitted(model)
  covim <- as.im(covariate, W=as.owin(prob))
  probvalu <- as.matrix(prob)
  covvalu  <- as.matrix(covim)
  ok <- !is.na(probvalu) & !is.na(covvalu)
  probvalu <- as.vector(probvalu[ok])
  covvalu <- as.vector(covvalu[ok])
  # compile weighted cdf's
  FZ <- ewcdf(covvalu, probvalu/sum(probvalu))
  X <- model$Data$response
  ZX <- safelookup(covim, X)
  # Ensure support of cdf includes the range of the data
  xxx <- knots(FZ)
  yyy <- FZ(xxx)
  if(min(xxx) > min(ZX)) {
    xxx <- c(min(ZX), xxx)
    yyy <- c(0, yyy)
  }
  if(max(xxx) < max(ZX)) {
    xxx <- c(xxx, max(ZX))
    yyy <- c(yyy, 1)
  }
  # make piecewise linear approximation of cdf
  FZ <- approxfun(xxx, yyy, rule=2)
  # now apply cdf
  U <- FZ(ZX)
  # Test uniformity of transformed values
  result <- switch(test,
                   ks  = ks.test(U, "punif", ...),
                   cvm = cvm.test(U, "punif", ...),
                   ad = ad.test(U, "punif", ...))
  testname <- switch(test,
                     ks="Kolmogorov-Smirnov",
                     cvm="Cramer-Von Mises",
                     ad="Anderson-Darling")

  # modify the 'htest' entries
  result$method <- paste("Spatial", testname, "test of",
                         "inhomogeneous Poisson process",
                         "in two dimensions")
  result$data.name <-
    paste("covariate", sQuote(paste(covname, collapse="")),
          "evaluated at points of", sQuote(dataname),
          "\n     and transformed to uniform distribution under",
          sQuote(modelname))
  # additional class 'cdftest'
  class(result) <- c("cdftest", class(result))
  attr(result, "prep") <-
    list(Zvalues=covvalu, ZX=ZX, FZ=FZ, FZX=ecdf(ZX), U=U)
  attr(result, "info") <- list(modelname=modelname, covname=covname,
                               dataname=dataname, csr=FALSE)
  return(result)        
}

#.............  helper functions ........................#

spatialCDFtest <- function(model, covariate, test=c("ks", "cvm", "ad"),
                           ...,
                           dimyx=NULL, eps=NULL,
                           jitter=TRUE, nsim=99, verbose=TRUE,
                           modelname=NULL, covname=NULL, dataname=NULL) {
  # conduct test based on comparison of CDF's of covariate values
  test <- match.arg(test)
  ispois <- is.poisson(model)
  # compute the essential data
  fra <- spatialCDFframe(model, covariate,
                         dimyx=dimyx, eps=eps,
                         jitter=jitter, modelname=modelname,
                         covname=covname, dataname=dataname)
  values <- fra$values
  info   <- fra$info
  ## Test uniformity of transformed values
  U <- values$U
  result <- switch(test,
                   ks  = ks.test(U, "punif", ...),
                   cvm = cvm.test(U, "punif", ...),
                   ad = ad.test(U, "punif", ...))
  testname <- switch(test,
                     ks="Kolmogorov-Smirnov",
                     cvm="Cramer-Von Mises",
                     ad="Anderson-Darling")
  ## 
  if(!ispois) {
    ## Gibbs model: perform Monte Carlo test
    result$poisson.p.value <- result$p.value
    pobs <- result$p.value
    Xsim <- simulate(model, nsim=nsim, progress=verbose)
    pvals <- numeric(nsim)
    if(verbose) cat("Processing.. ")
    for(i in seq_len(nsim)) {
      model.i <- update(model, Xsim[[i]])
      fra.i <- spatialCDFframe(model.i, covariate,
                               dimyx=dimyx, eps=eps,
                               jitter=jitter, modelname=modelname,
                               covname=covname, dataname=dataname)
      U.i <- fra.i$values$U
      res.i <- switch(test,
                      ks  = ks.test(U.i, "punif", ...),
                      cvm = cvm.test(U.i, "punif", ...),
                      ad = ad.test(U.i, "punif", ...))     
      pvals[i] <- res.i$p.value
      if(verbose) progressreport(i, nsim)
    }
    if(verbose) cat("Done.\n")
    ## insert Monte Carlo p-value
    result$p.value <- mean(pobs <= c(pobs, pvals))
  }
  ## 
  # modify the 'htest' entries
  csr <- info$csr
  modelname <- if(csr) "CSR" else
               if(ispois) "inhomogeneous Poisson process" else "Gibbs process"
  result$method <-
    paste(if(ispois) "Spatial" else "Monte Carlo spatial",
          testname, "test of", modelname, "in", info$spacename)
  result$data.name <-
    paste("covariate", sQuote(singlestring(info$covname)),
          "evaluated at points of", sQuote(info$dataname), 
          "\n     and transformed to uniform distribution under",
          if(csr) info$modelname else sQuote(info$modelname))
  
  # additional class 'cdftest'
  class(result) <- c("cdftest", class(result))
  attr(result, "frame") <- fra
  return(result)        
}

spatialCDFframe <- function(model, covariate, ...) {
  # evaluate CDF of covariate values at data points and at pixels
  stuff <- evalCovar(model, covariate, ...)
  # extract 
  values <- stuff$values
#  info   <- stuff$info
  Zvalues <- values$Zvalues
  lambda  <- values$lambda
  weights <- values$weights
  ZX      <- values$ZX
  # compute empirical cdf of Z values at points of X
  FZX <- ecdf(ZX)
  # form weighted cdf of Z values in window
  wts <- lambda * weights
  sumwts <- sum(wts)
  FZ <- ewcdf(Zvalues, wts/sumwts)
  # Ensure support of cdf includes the range of the data
  xxx <- knots(FZ)
  yyy <- FZ(xxx)
  minZX <- min(ZX, na.rm=TRUE)
  minxxx <- min(xxx, na.rm=TRUE)
  if(minxxx > minZX) {
    xxx <- c(minZX, xxx)
    yyy <- c(0, yyy)
  }
  maxZX <- max(ZX, na.rm=TRUE)
  maxxxx <- max(xxx, na.rm=TRUE)
  if(maxxxx < maxZX) {
    xxx <- c(xxx, maxZX)
    yyy <- c(yyy, 1)
  }
  # make piecewise linear approximation of cdf
  FZ <- approxfun(xxx, yyy, rule=2)
  # now apply cdf
  U <- FZ(ZX)

  # pack up
  stuff$values$FZ  <- FZ
  stuff$values$FZX <- FZX
  stuff$values$U   <- U
  stuff$values$EN <- sumwts  ## integral of intensity = expected number of pts
  class(stuff) <- "spatialCDFframe"
  return(stuff)
}

plot.kstest <- function(x, ...) {
  message("kstest is out of date; use cdf.test")
#  .Deprecated("plot.cdftest", package="spatstat")
  plot.cdftest(x, ...)
}

plot.cdftest <- function(x, ..., style=c("cdf", "PP", "QQ"),
                        lwd=par("lwd"), col=par("col"), lty=par("lty"),
                        lwd0=lwd, col0=2, lty0=2,
                        do.legend=TRUE) {
  style <- match.arg(style)
  fram <- attr(x, "frame")
  if(!is.null(fram)) {
    values <- fram$values
    info <- fram$info
  } else {
    # old style
    values <- attr(x, "prep")
    info <- attr(x, "info")
  }
  # cdf of covariate Z over window 
  FZ <- values$FZ
  # cdf of covariate values at data points
  FZX <- values$FZX
  # blurb
  covname <- info$covname
  covdescrip <- switch(covname,
                       x="x coordinate",
                       y="y coordinate",
                       paste("covariate", dQuote(covname)))
  # plot it
  switch(style,
         cdf={
           # plot both cdf's superimposed
           qZ <- get("x", environment(FZ))
           pZ <- get("y", environment(FZ))
           main <- c(x$method,
                     paste("based on distribution of", covdescrip),
                     paste("p-value=", signif(x$p.value, 4)))
           do.call("plot.default",
                   resolve.defaults(
                                    list(x=qZ, y=pZ, type="l"),
                                    list(...),
                                    list(lwd=lwd0, col=col0, lty=lty0),
                                    list(xlab=info$covname, ylab="probability",
                                         main=main)))
           plot(FZX, add=TRUE, do.points=FALSE, lwd=lwd, col=col, lty=lty)
           if(do.legend) 
             legend("topleft", c("observed", "expected"),
                    lwd=c(lwd,lwd0),
                    col=c(col2hex(col), col2hex(col0)),
                    lty=c(lty2char(lty),lty2char(lty0)))
         },
         PP={
           # plot FZX o (FZ)^{-1}
           pX <- get("y", environment(FZX))
           qX <- get("x", environment(FZX))
           p0 <- FZ(qX)
           do.call("plot.default",
                   resolve.defaults(
                                    list(x=p0, y=pX),
                                    list(...),
                                    list(col=col),
                                    list(xlim=c(0,1),
                                         ylim=c(0,1),
                                         xlab="Theoretical probability",
                                         ylab="Observed probability",
                                         main="")))
           abline(0,1, lwd=lwd0, col=col0, lty=lty0)           
         },
         QQ={
           # plot (FZX)^{-1} o FZ
           pZ <- get("y", environment(FZ))
           qZ <- get("x", environment(FZ))
           FZinverse <- approxfun(pZ, qZ, rule=2)
           pX <- get("y", environment(FZX))
           qX <- get("x", environment(FZX))
           qZX <- FZinverse(pX)
           Zrange <- range(qZ, qX, qZX)
           xlab <- paste("Theoretical quantile of", covname)
           ylab <- paste("Observed quantile of", covname)
           do.call("plot.default",
                   resolve.defaults(
                                    list(x=qZX, y=qX),
                                    list(...),
                                    list(col=col),
                                    list(xlim=Zrange, ylim=Zrange,
                                         xlab=xlab, ylab=ylab,
                                         main="")))
           abline(0,1, lwd=lwd0, col=col0, lty=lty0)           
         })
  return(invisible(NULL))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/centroid.R"
#
#	centroid.S	Centroid of a window
#			and related operations
#
#	$Revision: 1.6 $	$Date: 2014/11/10 08:20:59 $
#
# Function names (followed by "xypolygon" or "owin")
#	
#	intX            integral of x dx dy
#	intY            integral of y dx dy
#	meanX           mean of x dx dy
#	meanY           mean of y dx dy
#       centroid        (meanX, meanY)
#		
#-------------------------------------

intX.xypolygon <- function(polly) {
  #
  # polly: list(x,y) vertices of a single polygon (n joins to 1)
  #
  verify.xypolygon(polly)
  
  x <- polly$x
  y <- polly$y
  
#  nedges <- length(x)   # sic
  
  # place x axis below polygon
  y <- y - min(y) 

  # join vertex n to vertex 1
  xr <- c(x, x[1])
  yr <- c(y, y[1])

  # slope
  dx <- diff(xr)
  dy <- diff(yr)
  slope <- ifelseAX(dx == 0, 0, dy/dx)

  # integrate
  integrals <- x * y * dx + (y + slope * x) * (dx^2)/2 + slope * (dx^3)/3

  -sum(integrals)
}
		
intX.owin <- function(w) {
	verifyclass(w, "owin")
        switch(w$type,
               rectangle = {
		width  <- abs(diff(w$xrange))
		height <- abs(diff(w$yrange))
		answer <- width * height * mean(w$xrange)
               },
               polygonal = {
                 answer <- sum(unlist(lapply(w$bdry, intX.xypolygon)))
               },
               mask = {
                 pixelarea <- abs(w$xstep * w$ystep)
		 x <- rasterx.mask(w, drop=TRUE)
                 answer <- (pixelarea * length(x)) * mean(x)
               },
               stop("Unrecognised window type")
        )
        return(answer)
}

meanX.owin <- function(w) {
	verifyclass(w, "owin")
        switch(w$type,
               rectangle = {
		answer <- mean(w$xrange)
               },
               polygonal = {
	         area <- sum(unlist(lapply(w$bdry, Area.xypolygon)))
                 integrated <- sum(unlist(lapply(w$bdry, intX.xypolygon)))
		 answer <- integrated/area
               },
               mask = {
		 x <- rasterx.mask(w, drop=TRUE)
                 answer <- mean(x)
               },
               stop("Unrecognised window type")
        )
        return(answer)
}

intY.xypolygon <- function(polly) {
  #
  # polly: list(x,y) vertices of a single polygon (n joins to 1)
  #
  verify.xypolygon(polly)
  
  x <- polly$x
  y <- polly$y
  
#  nedges <- length(x)   # sic
  
  # place x axis below polygon
  yadjust <- min(y)
  y <- y - yadjust 

  # join vertex n to vertex 1
  xr <- c(x, x[1])
  yr <- c(y, y[1])

  # slope
  dx <- diff(xr)
  dy <- diff(yr)
  slope <- ifelseAX(dx == 0, 0, dy/dx)

  # integrate
  integrals <- (1/2) * (dx * y^2 + slope * y * dx^2 + slope^2 * dx^3/3)
  total <- sum(integrals) - yadjust * Area.xypolygon(polly)

  # change sign to adhere to anticlockwise convention
  -total
}
		
intY.owin <- function(w) {
	verifyclass(w, "owin")
        switch(w$type,
               rectangle = {
		width  <- abs(diff(w$xrange))
		height <- abs(diff(w$yrange))
		answer <- width * height * mean(w$yrange)
               },
               polygonal = {
                 answer <- sum(unlist(lapply(w$bdry, intY.xypolygon)))
               },
               mask = {
                 pixelarea <- abs(w$xstep * w$ystep)
		 y <- rastery.mask(w, drop=TRUE)
                 answer <- (pixelarea * length(y)) * mean(y)
               },
               stop("Unrecognised window type")
        )
        return(answer)
}

meanY.owin <- function(w) {
	verifyclass(w, "owin")
        switch(w$type,
               rectangle = {
		answer <- mean(w$yrange)
               },
               polygonal = {
	         area <- sum(unlist(lapply(w$bdry, Area.xypolygon)))
                 integrated <- sum(unlist(lapply(w$bdry, intY.xypolygon)))
		 answer <- integrated/area
               },
               mask = {
		 y <- rastery.mask(w, drop=TRUE)
                 answer <- mean(y)
               },
               stop("Unrecognised window type")
        )
        return(answer)
}

centroid.owin <- function(w, as.ppp = FALSE) {
	w <- as.owin(w)
        out <- list(x=meanX.owin(w), y=meanY.owin(w))
        if(as.ppp){
            if(!inside.owin(out$x, out$y, w))
                w <- as.rectangle(w)
            out <- as.ppp(out, W=w)
        }
	return(out)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/circdensity.R"
#'
#'   circdensity.R
#'
#' Kernel smoothing for circular data
#'
#'   $Revision: 1.3 $ $Date: 2014/12/04 06:49:20 $

circdensity <- function(x, sigma="nrd0", ..., bw=NULL,
                        weights=NULL,
                        unit=c("degree", "radian")) {
  xname <- short.deparse(substitute(x))
  missu <- missing(unit)
  if(missing(sigma) && !is.null(bw))
    sigma <- bw
  unit <- match.arg(unit)
  unit <- validate.angles(x, unit, missu)
  FullCircle <- switch(unit, degree = 360, radian = 2*pi)
  if(is.character(sigma)) {
    sigma <- switch(sigma,
                     bcv  = bw.bcv,
                     nrd  = bw.nrd,
                     nrd0 = bw.nrd0,
                     SJ   = bw.SJ,
                     ucv  = bw.ucv,
                     get(paste0("bw.", sigma), mode="function"))
  }
  if(is.function(sigma)) {
    sigma <- sigma(x)
    if(!(is.numeric(sigma) && length(sigma) == 1 && sigma > 0))
      stop("Bandwidth selector should return a single positive number")
  }
  check.1.real(sigma)
  #' replicate data
  x <- x %% FullCircle
  xx <- c(x - FullCircle, x, x + FullCircle)
  #' replicate weights
  if(!is.null(weights)) {
    stopifnot(length(weights) == length(x))
    weights <- rep(weights, 3)/3
  }
  #' smooth
  z <- do.call(density.default,
               resolve.defaults(list(x=xx, bw=sigma, weights=weights),
                                list(...),
                                list(from=0, to=FullCircle)))
  z$y <- 3 * z$y
  z$data.name <- xname
  return(z)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/clarkevans.R"
## clarkevans.R
## Clark-Evans statistic and test
## $Revision: 1.16 $ $Date: 2014/11/10 05:34:18 $

clarkevans <- function(X, correction=c("none", "Donnelly", "cdf"),
                       clipregion=NULL)
{
  verifyclass(X, "ppp")
  W <- X$window

  # validate correction argument
  gavecorrection <- !missing(correction)
  correction <- pickoption("correction", correction,
                           c(none="none",
                             Donnelly="Donnelly",
                             donnelly="Donnelly",
                             guard="guard",
                             cdf="cdf"),
                           multi=TRUE)

  if(("Donnelly" %in% correction) && (W$type != "rectangle")) {
    if(gavecorrection)
      warning("Donnelly correction only available for rectangular windows")
    correction <- correction[correction != "Donnelly"]
  }

  # guard correction applied iff `clipregion' is present
  isguard <- "guard" %in% correction
  askguard <- any(isguard)
  gaveguard <- !is.null(clipregion)
  if(gaveguard)
    clipregion <- as.owin(clipregion)
  if(askguard && !gaveguard) {
    warning("guard correction not performed; clipregion not specified")
    correction <- correction[!isguard]
  } else if(gaveguard && !askguard) 
    correction <- c(correction, "guard")

  result <- clarkevansCalc(X, correction, clipregion)
  if(length(result) == 1) result <- unname(result)
  return(result)
}

clarkevans.test <- function(X, ..., 
                            correction="none",
                            clipregion=NULL,
                            alternative=c("two.sided", "less", "greater",
                                          "clustered", "regular"),
                            nsim=999
                            ) {
  Xname <- short.deparse(substitute(X))
  miss.nsim <- missing(nsim)

  verifyclass(X, "ppp")
  W <- Window(X)
  nX <- npoints(X)
  
  # validate SINGLE correction
  correction <- pickoption("correction", correction,
                           c(none="none",
                             Donnelly="Donnelly",
                             donnelly="Donnelly",
                             guard="guard",
                             cdf="cdf"))
  switch(correction,
         none={
           corrblurb <- "No edge correction"
         },
         Donnelly={
           if(W$type != "rectangle")
             stop("Donnelly correction only available for rectangular windows")
           corrblurb <- "Donnelly correction"
         },
         guard={
           if(is.null(clipregion))
             stop("clipregion not specified")
           clipregion <- as.owin(clipregion)
           corrblurb <- "Guard correction"
         },
         cdf={
           corrblurb <- "CDF correction"
         })

  # alternative hypothesis
  if(missing(alternative) || is.null(alternative))
    alternative <- "two.sided"
  alternative <- pickoption("alternative", alternative,
                           c(two.sided="two.sided",
                             less="less",
                             clustered="less",
                             greater="greater",
                             regular="greater"))

  altblurb <-
    switch(alternative,
           two.sided="two-sided",
           less="clustered (R < 1)",
           greater="regular (R > 1)")

  # compute observed value
  statistic <- clarkevansCalc(X, correction=correction, clipregion=clipregion,
                              working=TRUE)
  working <- attr(statistic, "working")
  #
  if(correction == "none" && miss.nsim) {
    # standard Normal p-value
    SE <- with(working, sqrt(((4-pi)*areaW)/(4 * pi))/npts)
    Z <- with(working, (Dobs - Dpois)/SE)
    p.value <- switch(alternative,
                      less=pnorm(Z),
                      greater=1 - pnorm(Z),
                      two.sided= 2*(1-pnorm(abs(Z))))
    pvblurb <- "Z-test"
  } else {
    # Monte Carlo p-value
    sims <- numeric(nsim)
    for(i in 1:nsim) {
      Xsim <- runifpoint(nX, win=W)
      sims[i] <- clarkevansCalc(Xsim, correction=correction,
                                clipregion=clipregion)
    }
    p.upper <- (1 + sum(sims >= statistic))/(1 + nsim)
    p.lower <- (1 + sum(sims <= statistic))/(1 + nsim)
    p.value <- switch(alternative,
                      less=p.lower,
                      greater=p.upper,
                      two.sided=2*min(p.lower, p.upper))
    
    pvblurb <- paste("Monte Carlo test based on",
                     nsim, "simulations of CSR with fixed n")
  }

  statistic <- as.numeric(statistic)
  names(statistic) <- "R"
  
  out <- list(statistic=statistic,
              p.value=p.value,
              alternative=altblurb,
              method=c("Clark-Evans test", corrblurb, pvblurb),
              data.name=Xname)
  class(out) <- "htest"
  return(out)
}

clarkevansCalc <- function(X, correction="none", clipregion=NULL,
                           working=FALSE) {
  # calculations for Clark-Evans index or test
  W <- Window(X)
  areaW <- area(W)
  npts <- npoints(X)
  intensity <- npts/areaW
  # R undefined for empty point pattern
  if(npts == 0)
    return(NA)
  # Dobs = observed mean nearest neighbour distance
  nndistX <- nndist(X)
  Dobs <- mean(nndistX)
  # Dpois = Expected mean nearest neighbour distance for Poisson process
  Dpois <- 1/(2*sqrt(intensity))

  statistic <- NULL
  if(working) 
    work <- list(areaW=areaW, npts=npts, intensity=intensity,
                 Dobs=Dobs, Dpois=Dpois)
  
  # Naive uncorrected value
  if("none" %in% correction) {
    Rnaive <- Dobs/Dpois
    statistic <- c(statistic, naive=Rnaive)
  }
  # Donnelly edge correction
  if("Donnelly" %in% correction) {
     # Dedge = Edge corrected mean nearest neighbour distance, Donnelly 1978
    if(W$type == "rectangle") {
      perim <- perimeter(W)
      Dkevin  <- Dpois + (0.0514+0.0412/sqrt(npts))*perim/npts
      Rkevin <- Dobs/Dkevin
      if(working) work <- append(work, list(perim=perim, Dkevin=Dkevin))
    } else 
      Rkevin <- NA
    statistic <- c(statistic, Donnelly=Rkevin)
  }
  # guard area method
  if("guard" %in% correction && !is.null(clipregion)) {
    # use nn distances from points inside `clipregion'
    ok <- inside.owin(X, , clipregion)
    Dguard <- mean(nndistX[ok])
    Rguard <- Dguard/Dpois
    if(working) work <- append(work, list(Dguard=Dguard))
    statistic <- c(statistic, guard=Rguard)
  }
  if("cdf" %in% correction) {
    # compute mean of estimated nearest-neighbour distance distribution G
    G <- Gest(X)
    numer <- stieltjes(function(x){x}, G)$km
    denom <- stieltjes(function(x){rep.int(1, length(x))}, G)$km
    Dcdf <- numer/denom
    Rcdf <- Dcdf/Dpois
    if(working) work <- append(work, list(Dcdf=Dcdf))
    statistic <- c(statistic, cdf=Rcdf)
  }
  if(working) attr(statistic, "working") <- work

  return(statistic)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/classes.R"
#
#
#	classes.S
#
#	$Revision: 1.7 $	$Date: 2006/10/09 03:38:14 $
#
#	Generic utilities for classes
#
#
#--------------------------------------------------------------------------

verifyclass <- function(X, C, N=deparse(substitute(X)), fatal=TRUE) {
  if(!inherits(X, C)) {
    if(fatal) {
        gripe <- paste("argument", sQuote(N),
                       "is not of class", sQuote(C))
	stop(gripe)
    } else 
	return(FALSE)
  }
  return(TRUE)
}

#--------------------------------------------------------------------------

checkfields <- function(X, L) {
	  # X is a list, L is a vector of strings
	  # Checks for presence of field named L[i] for all i
	return(all(!is.na(match(L,names(X)))))
}

getfields <- function(X, L, fatal=TRUE) {
	  # X is a list, L is a vector of strings
	  # Extracts all fields with names L[i] from list X
	  # Checks for presence of all desired fields
	  # Returns the sublist of X with fields named L[i]
	absent <- is.na(match(L, names(X)))
	if(any(absent)) {
		gripe <- paste("Needed the following components:",
				paste(L, collapse=", "),
				"\nThese ones were missing: ",
				paste(L[absent], collapse=", "))
		if(fatal)
			stop(gripe)
		else 
			warning(gripe)
	} 
	return(X[L[!absent]])
}



#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/clickjoin.R"
#
#  clickjoin.R
#
# interactive addition/deletion of segments between vertices
#

clickjoin <- function(X, ..., add=TRUE, m=NULL, join=TRUE) {
  verifyclass(X, "ppp")
  if(!(is.logical(join) && length(join) == 1))
    stop("join should be a single logical value")
  plot(X, add=add, pch=16)
  if(is.null(m)) {
    m <- matrix(FALSE, npoints(X), npoints(X))
  } else {
    stopifnot(is.matrix(m) && is.logical(m))
    stopifnot(all(dim(m) == npoints(X)))
    from <- as.vector(row(m)[m])
    to   <- as.vector(col(m)[m])
    with(X, segments(x[from], y[from], x[to], y[to]))
  }
  while(TRUE) {
    twoid <- identify(X, plot=FALSE, n=2)
    n <- length(twoid)
    if(n == 0) break
    if(n == 2) {
      m[twoid[1],twoid[2]] <- m[twoid[2],twoid[1]] <- join
      lines(X$x[twoid], X$y[twoid], ...)
    }
  }
  return(m)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/clickpoly.R"
#
# clickpoly.R
#
#
# $Revision: 1.5 $  $Date: 2014/09/27 09:45:44 $
#
#
clickpoly <- function(add=FALSE, nv=NULL, np=1, ...) {
  if((!add) | dev.cur() == 1) {
    plot(0,0,type="n", xlab="", ylab="", xlim=c(0,1), ylim=c(0,1), asp=1.0,
         axes=FALSE)
    rect(0,0,1,1)
  }
  gon <- list()
  stopifnot(np >= 1)
  for(i in 1:np) {
    if(np > 1)
      cat(paste(".... Polygon number", i, ".....\n"))
    if(!is.null(nv)) 
      cat(paste("click", nv, "times in window\n"))
    else
      cat(paste("to add points: click left mouse button in window\n",
                "      to exit: click middle mouse button\n",
                "[The last point should NOT repeat the first point]\n"))
    xy <- do.call("locator",
                  resolve.defaults(if(!is.null(nv)) list(n=nv) else list(),
                                   list(...),
                                   list(type="o")))
    if(Area.xypolygon(xy) < 0)
      xy <- lapply(xy, rev)
    gon[[i]] <- xy
    plot(owin(poly=xy), add=TRUE)
  }
  result <- owin(poly=gon)
  plot(result, add=TRUE)
  return(result)
}
  
clickbox <- function(add=TRUE) {
  cat("Click two corners of a box\n")
  if(!add) plot(owin(), main="Click two corners of a box") 
  a <- try(locator(1), silent=TRUE)
  if(inherits(a, "try-error")) {
    ## add=TRUE but there is no current plot
    plot.new()
    a <- locator(1)
  }
  abline(v=a$x)
  abline(h=a$y)
  b <- locator(1)
  abline(v=b$x)
  abline(h=b$y)
  ab <- concatxy(a, b)
  return(owin(range(ab$x), range(ab$y)))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/clickppp.R"
#' Dominic Schuhmacher's idea

clickppp <- function(n=NULL, win=square(1), types=NULL, ...,
                     add=FALSE, main=NULL, hook=NULL) {

  win <- as.owin(win)

  instructions <-
    if(!is.null(n)) paste("click", n, "times in window") else
    paste("add points: click left mouse button in window\n",
          "exit: click middle mouse button")
  if(is.null(main))
    main <- instructions
  
  ####  single type #########################
  if(is.null(types)) {
    plot(win, add=add, main=main, invert=TRUE)
    if(!is.null(hook))
      plot(hook, add=TRUE)
    if(!is.null(n))
      xy <- do.call("locator",
                    resolve.defaults(list(...),
                                     list(n=n, type="p")))
    else
      xy <- do.call("locator",
                    resolve.defaults(list(...),
                                     list(type="p")))
    # check whether all points lie inside window
    if((nout <- sum(!inside.owin(xy$x, xy$y, win))) > 0) {
      warning(paste(nout,
                    ngettext(nout, "point", "points"),
                    "lying outside specified window; window was expanded"))
      win <- boundingbox(win, xy)
    }
    X <- ppp(xy$x, xy$y, window=win)
    return(X)
  }
  
  ##### multitype #######################
  
  ftypes <- factor(types, levels=types)
  getem <- function(i, instr, ...) {
    main <- paste("Points of type", sQuote(i), "\n", instr)
    do.call("clickppp", resolve.defaults(list(...), list(main=main)))
  }
  # input points of type 1 
  X <- getem(ftypes[1], instructions, n=n, win=win, add=add, ..., pch=1)
  X <- X %mark% ftypes[1]
  # input points of types 2, 3, ... in turn
  naughty <- FALSE
  for(i in 2:length(types)) {
    Xi <- getem(ftypes[i], instructions, n=n, win=win, add=add, ..., hook=X, pch=i)
    Xi <- Xi %mark% ftypes[i]
    if(!naughty && identical(Xi$window, win)) {
      # normal case
      X <- superimpose(X, Xi, W=win)
    } else {
      # User has clicked outside original window.
      naughty <- TRUE
      # Use bounding box for simplicity
      bb <- boundingbox(Xi$window, X$window)
      X <- superimpose(X, Xi, W=bb)
    } 
  }
  if(!add) {
    if(!naughty)
      plot(X, main="Final pattern")
    else {
      plot(X$window, main="Final pattern (in expanded window)", invert=TRUE)
      plot(win, add=TRUE, invert=TRUE)
      plot(X, add=TRUE)
    }
  }
  return(X)

}


  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/clip.psp.R"
#
# clip.psp.R
#
#    $Revision: 1.18 $   $Date: 2014/11/10 05:36:38 $
#
#
 
########################################################
# clipping operation (for subset)
########################################################

clip.psp <- function(x, window, check=TRUE) {
  verifyclass(x, "psp")
  verifyclass(window, "owin")
  if(check && !is.subset.owin(window, x$window))
    warning("The clipping window is not a subset of the window containing the line segment pattern x")
  if(x$n == 0) {
    emptypattern <- psp(numeric(0), numeric(0), numeric(0), numeric(0),
                      window=window, marks=x$marks)
    return(emptypattern)
  }
  switch(window$type,
         rectangle={
           result <- cliprect.psp(x, window)
         },
         polygonal={
           result <- clippoly.psp(x, window)
         },
         mask={
           result <- clippoly.psp(x, as.polygonal(window))
           result$window <- window
         })
  return(result)
}


#####
#
#  clipping to a rectangle
#
cliprect.psp <- function(x, window) {
  verifyclass(x, "psp")
  verifyclass(window, "owin")
  ends <- x$ends
  marx <- marks(x, dfok=TRUE)
  # find segments which are entirely inside the window
  # (by convexity)
  in0 <- inside.owin(ends$x0, ends$y0, window)
  in1 <- inside.owin(ends$x1, ends$y1, window)
  ok <- in0 & in1
  # if all segments are inside, return them
  if(all(ok))
    return(as.psp(ends, window=window, marks=marx, check=FALSE))
  # otherwise, store those segments which are inside the window
  ends.inside <- ends[ok, , drop=FALSE]
  marks.inside <- marx %msub% ok
  x.inside <- as.psp(ends.inside, window=window, marks=marks.inside, check=FALSE)
  # now consider the rest
  ends <- ends[!ok, , drop=FALSE]
  in0 <- in0[!ok] 
  in1 <- in1[!ok]
  marx <- marx %msub% (!ok)
  # first clip segments to the range x \in [xmin, xmax]
  # use parametric coordinates
  small <- function(x) { abs(x) <= .Machine$double.eps }
  tvalue <- function(z0, z1, zt) {
    y1 <- z1 - z0
    yt <- zt - z0
    tval <- ifelseAX(small(y1), 0.5, yt/y1)
    betwee <- (yt * (zt - z1)) <= 0
    result <- ifelseXB(betwee, tval, NA)
    return(result)
  }
  between <- function(x, r) { ((x-r[1]) * (x-r[2])) <= 0 }
  tx <- cbind(ifelse0NA(between(ends$x0, window$xrange)),
              ifelse1NA(between(ends$x1, window$xrange)),
              tvalue(ends$x0, ends$x1, window$xrange[1]),
              tvalue(ends$x0, ends$x1, window$xrange[2]))
  # discard segments which do not lie in the x range 
  nx <- apply(!is.na(tx), 1, sum)
  ok <- (nx >= 2)
  if(!any(ok))
    return(x.inside)
  ends <- ends[ok, , drop=FALSE]
  tx   <- tx[ok, , drop=FALSE]
  in0  <- in0[ok]
  in1  <- in1[ok]
  marx <- marx %msub% ok
  # Clip the segments to the x range
  tmin <- apply(tx, 1, min, na.rm=TRUE)
  tmax <- apply(tx, 1, max, na.rm=TRUE)
  dx <- ends$x1 - ends$x0
  dy <- ends$y1 - ends$y0
  ends.xclipped <- data.frame(x0=ends$x0 + tmin * dx,
                             y0=ends$y0 + tmin * dy,
                             x1=ends$x0 + tmax * dx,
                             y1=ends$y0 + tmax * dy)
  # Now clip the segments to the range y \in [ymin, ymax]
  ends <- ends.xclipped
  in0 <- inside.owin(ends$x0, ends$y0, window)
  in1 <- inside.owin(ends$x1, ends$y1, window)
  ty <- cbind(ifelse0NA(in0),
              ifelse1NA(in1),
              tvalue(ends$y0, ends$y1, window$yrange[1]),
              tvalue(ends$y0, ends$y1, window$yrange[2]))
  # discard segments which do not lie in the y range 
  ny <- apply(!is.na(ty), 1, sum)
  ok <- (ny >= 2)
  if(!any(ok))
    return(x.inside)
  ends <- ends[ok, , drop=FALSE]
  ty   <- ty[ok, , drop=FALSE]
  in0  <- in0[ok]
  in1  <- in1[ok]
  marx <- marx %msub% ok
  # Clip the segments to the y range
  tmin <- apply(ty, 1, min, na.rm=TRUE)
  tmax <- apply(ty, 1, max, na.rm=TRUE)
  dx <- ends$x1 - ends$x0
  dy <- ends$y1 - ends$y0
  ends.clipped <- data.frame(x0=ends$x0 + tmin * dx,
                             y0=ends$y0 + tmin * dy,
                             x1=ends$x0 + tmax * dx,
                             y1=ends$y0 + tmax * dy)
  marks.clipped <- marx
  # OK - segments clipped
  # Put them together with the unclipped ones
  ends.all <- rbind(ends.inside, ends.clipped)
  marks.all <- marks.inside %mapp% marks.clipped
  as.psp(ends.all, window=window, marks=marks.all, check=FALSE)
}


############################
#
#   clipping to a polygonal window
#

clippoly.psp <- function(s, window) {
  verifyclass(s, "psp")
  verifyclass(window, "owin")
  stopifnot(window$type == "polygonal")
  marx <- marks(s)
  has.marks <- !is.null(marx)
  
  eps <- .Machine$double.eps

  # find the intersection points between segments and window edges
  
  ns <- s$n
  es <- s$ends
  x0s <- es$x0
  y0s <- es$y0
  dxs <- es$x1 - es$x0
  dys <- es$y1 - es$y0

  bdry <- edges(window)
  nw <- bdry$n
  ew <- bdry$ends
  x0w <- ew$x0
  y0w <- ew$y0
  dxw <- ew$x1 - ew$x0
  dyw <- ew$y1 - ew$y0

  out <- .C("xysegint",
            na=as.integer(ns),
            x0a=as.double(x0s),
            y0a=as.double(y0s),
            dxa=as.double(dxs),
            dya=as.double(dys), 
            nb=as.integer(nw),
            x0b=as.double(x0w),
            y0b=as.double(y0w),
            dxb=as.double(dxw),
            dyb=as.double(dyw), 
            eps=as.double(eps),
            xx=as.double(numeric(ns * nw)),
            yy=as.double(numeric(ns * nw)),
            ta=as.double(numeric(ns * nw)),
            tb=as.double(numeric(ns * nw)),
            ok=as.integer(integer(ns * nw)))

  ok <- (matrix(out$ok, ns, nw) != 0)
  ts <- matrix(out$ta, ns, nw)

  # form all the chopped segments (whether in or out)

  chopped <- s[numeric(0)]
  chopped$window <- boundingbox(s$window, window)
    
  for(seg in seq_len(ns)) {
    segment <- s$ends[seg, , drop=FALSE]
    hit <- ok[seg, ]
    if(!any(hit)) {
      # no intersection with boundary - add single segment
      chopped$ends <- rbind(chopped$ends, segment)
    if(has.marks) chopped$marks <- (chopped$marks) %mapp% (marx %msub% seg)
    } else {
      # crosses boundary - add several pieces
      tvals <- ts[seg,]
      tvals <- sort(tvals[hit])
      x0 <- segment$x0
      dx <- segment$x1 - x0
      y0 <- segment$y0
      dy <- segment$y1 - y0
      newones <- data.frame(x0 = x0 + c(0,tvals) * dx,
                            y0 = y0 + c(0,tvals) * dy,
                            x1 = x0 + c(tvals,1) * dx,
                            y1 = y0 + c(tvals,1) * dy)
      chopped$ends <- rbind(chopped$ends, newones)
      if(has.marks) {
        hitmarks <- marx %msub% seg
        newmarks <- hitmarks %mrep% nrow(newones)
        chopped$marks <-  (chopped$marks) %mapp% newmarks
      }
    }
  }
  chopped$n <- nrow(chopped$ends)
  
  # select those chopped segments which are inside the window
  mid <- midpoints.psp(chopped)
  ins <- inside.owin(mid$x, mid$y, window)
  retained <- chopped[ins]
  retained$window <- window
  return(retained)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/close3Dpairs.R"
#
# close3Dpairs.R
#
#   $Revision: 1.5 $   $Date: 2014/06/20 09:11:03 $
#
#  extract the r-close pairs from a 3D dataset
# 
#
closepairs.pp3 <- function(X, rmax, ordered=TRUE,
                           what=c("all", "indices"), ...) {
  verifyclass(X, "pp3")
  what <- match.arg(what)
  stopifnot(is.numeric(rmax) && length(rmax) == 1)
  stopifnot(is.finite(rmax))
  stopifnot(rmax >= 0)
  npts <- npoints(X)
  nama <- switch(what,
                 all = c("i", "j",
                         "xi", "yi", "zi",
                         "xj", "yj", "zj",
                         "dx", "dy", "dz",
                         "d"),
                 indices = c("i", "j"))
  names(nama) <- nama
  if(npts == 0) {
    null.answer <- lapply(nama, function(e) numeric(0))
    return(null.answer)
  }
  # sort points by increasing x coordinate
  oo <- fave.order(coords(X)$x)
  Xsort <- X[oo]
  # First make an OVERESTIMATE of the number of pairs
  nsize <- ceiling(5 * pi * (npts^2) * (rmax^3)/volume(as.box3(X)))
  nsize <- max(1024, nsize)
  # Now extract pairs
  XsortC <- coords(Xsort)
  x <- XsortC$x
  y <- XsortC$y
  z <- XsortC$z
  r <- rmax
  ng <- nsize
  storage.mode(x) <- "double"
  storage.mode(y) <- "double"
  storage.mode(z) <- "double"
  storage.mode(r) <- "double"
  storage.mode(ng) <- "integer"
  ## go
  a <- switch(what,
              all = {
                .Call("close3pairs",
                      xx=x, yy=y, zz=z, rr=r, nguess=ng)
              },
              indices = {
                .Call("close3IJpairs",
                      xx=x, yy=y, zz=z, rr=r, nguess=ng)
              })
  names(a) <- nama
  # convert i,j indices to original sequence
  a$i <- oo[a$i]
  a$j <- oo[a$j]
  # are (i, j) and (j, i) equivalent?
  if(!ordered) {
    a <- as.data.frame(a)
    a <- a[with(a, i < j), , drop=FALSE]
    a <- as.list(a)
  }
  return(a)
}

#######################

crosspairs.pp3 <- function(X, Y, rmax, what=c("all", "indices"), ...) {
  verifyclass(X, "pp3")
  verifyclass(Y, "pp3")
  what <- match.arg(what)
  stopifnot(is.numeric(rmax) && length(rmax) == 1 && rmax >= 0)
  nama <- switch(what,
                 all = c("i", "j",
                         "xi", "yi", "zi",
                         "xj", "yj", "zj",
                         "dx", "dy", "dz",
                         "d"),
                 indices = c("i", "j"))
  names(nama) <- nama
  nX <- npoints(X)
  nY <- npoints(Y)
  if(nX == 0 || nY == 0) {
    null.answer <- lapply(nama, function(e) numeric(0))
    return(null.answer)
  }
  # order patterns by increasing x coordinate
  ooX <- fave.order(coords(X)$x)
  Xsort <- X[ooX]
  ooY <- fave.order(coords(Y)$x)
  Ysort <- Y[ooY]
  ## First (over)estimate the number of pairs
  nsize <- ceiling(3 * pi * (rmax^3) * nX * nY/volume(as.box3(Y)))
  nsize <- max(1024, nsize)
  ## .Call
  XsortC <- coords(Xsort)
  YsortC <- coords(Ysort)
  Xx <- XsortC$x
  Xy <- XsortC$y
  Xz <- XsortC$z
  Yx <- YsortC$x
  Yy <- YsortC$y
  Yz <- YsortC$z
  r <- rmax
  ng <- nsize
  storage.mode(Xx) <- storage.mode(Xy) <- storage.mode(Xz) <- "double"
  storage.mode(Yx) <- storage.mode(Yy) <- storage.mode(Yz) <- "double"
  storage.mode(r) <- "double"
  storage.mode(ng) <- "integer"
  ## go
  a <- switch(what,
              all = {
                .Call("cross3pairs",
                      xx1=Xx, yy1=Xy, zz1=Xz,
                      xx2=Yx, yy2=Yy, zz2=Yz,
                      rr=r, nguess=ng)
              },
              indices = {
                .Call("cross3IJpairs",
                      xx1=Xx, yy1=Xy, zz1=Xz,
                      xx2=Yx, yy2=Yy, zz2=Yz,
                      rr=r, nguess=ng)
           })
  names(a) <- nama
  # convert i,j indices to original sequence
  a$i <- ooX[a$i]
  a$j <- ooY[a$j]
  return(a)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/closepairs.R"
#
# closepairs.R
#
#   $Revision: 1.30 $   $Date: 2014/10/24 00:22:30 $
#
#  simply extract the r-close pairs from a dataset
# 
#  Less memory-hungry for large patterns
#

closepairs <- function(X, rmax, ...) {
  UseMethod("closepairs")
}
  
closepairs.ppp <- function(X, rmax, ordered=TRUE,
                           what=c("all", "indices"), ...) {
  verifyclass(X, "ppp")
  what <- match.arg(what)
  stopifnot(is.numeric(rmax) && length(rmax) == 1)
  stopifnot(is.finite(rmax))
  stopifnot(rmax >= 0)
  npts <- npoints(X)
  null.answer <- switch(what,
                        all = {
                          list(i=integer(0),
                               j=integer(0),
                               xi=numeric(0),
                               yi=numeric(0),
                               xj=numeric(0),
                               yj=numeric(0),
                               dx=numeric(0),
                               dy=numeric(0),
                               d=numeric(0))
                        },
                        indices = {
                          list(i=integer(0),
                               j=integer(0))
                        })
   if(npts == 0)
     return(null.answer)
  # sort points by increasing x coordinate
  oo <- fave.order(X$x)
  Xsort <- X[oo]
  # First make an OVERESTIMATE of the number of pairs
  nsize <- ceiling(4 * pi * (npts^2) * (rmax^2)/area(Window(X)))
  nsize <- max(1024, nsize)
  # Now extract pairs
  if(spatstat.options("closepairs.newcode")) {
    # ------------------- use new faster code ---------------------
    x <- Xsort$x
    y <- Xsort$y
    r <- rmax
    ng <- nsize
    storage.mode(x) <- "double"
    storage.mode(y) <- "double"
    storage.mode(r) <- "double"
    storage.mode(ng) <- "integer"
    switch(what,
           all = {
             z <- .Call("Vclosepairs",
                        xx=x, yy=y, rr=r, nguess=ng)
             if(length(z) != 9)
               stop("Internal error: incorrect format returned from Vclosepairs")
             i  <- z[[1]]  # NB no increment required
             j  <- z[[2]]
             xi <- z[[3]]
             yi <- z[[4]]
             xj <- z[[5]]
             yj <- z[[6]]
             dx <- z[[7]]
             dy <- z[[8]]
             d  <- z[[9]]
           },
           indices = {
             z <- .Call("VcloseIJpairs",
                        xx=x, yy=y, rr=r, nguess=ng)
             if(length(z) != 2)
               stop("Internal error: incorrect format returned from VcloseIJpairs")
             i  <- z[[1]]  # NB no increment required
             j  <- z[[2]]
           })

  } else {
    # ------------------- use older code --------------------------
    z <-
      .C("Fclosepairs",
         nxy=as.integer(npts),
         x=as.double(Xsort$x),
         y=as.double(Xsort$y),
         r=as.double(rmax),
         noutmax=as.integer(nsize), 
         nout=as.integer(integer(1)),
         iout=as.integer(integer(nsize)),
         jout=as.integer(integer(nsize)), 
         xiout=as.double(numeric(nsize)),
         yiout=as.double(numeric(nsize)),
         xjout=as.double(numeric(nsize)),
         yjout=as.double(numeric(nsize)),
         dxout=as.double(numeric(nsize)),
         dyout=as.double(numeric(nsize)),
         dout=as.double(numeric(nsize)),
         status=as.integer(integer(1)))

    if(z$status != 0) {
      # Guess was insufficient
      # Obtain an OVERCOUNT of the number of pairs
      # (to work around gcc bug #323)
      rmaxplus <- 1.25 * rmax
      nsize <- .C("paircount",
                  nxy=as.integer(npts),
                  x=as.double(Xsort$x),
                  y=as.double(Xsort$y),
                  rmaxi=as.double(rmaxplus),
                  count=as.integer(integer(1)))$count
      if(nsize <= 0)
        return(null.answer)
      # add a bit more for safety
      nsize <- ceiling(1.1 * nsize) + 2 * npts
      # now extract points
      z <-
        .C("Fclosepairs",
           nxy=as.integer(npts),
           x=as.double(Xsort$x),
           y=as.double(Xsort$y),
           r=as.double(rmax),
           noutmax=as.integer(nsize), 
           nout=as.integer(integer(1)),
           iout=as.integer(integer(nsize)),
           jout=as.integer(integer(nsize)), 
           xiout=as.double(numeric(nsize)),
           yiout=as.double(numeric(nsize)),
           xjout=as.double(numeric(nsize)),
           yjout=as.double(numeric(nsize)),
           dxout=as.double(numeric(nsize)),
           dyout=as.double(numeric(nsize)),
           dout=as.double(numeric(nsize)),
           status=as.integer(integer(1)))
      if(z$status != 0)
        stop(paste("Internal error: C routine complains that insufficient space was allocated:", nsize))
    }
  # trim vectors to the length indicated
    npairs <- z$nout
    if(npairs <= 0)
      return(null.answer)
    actual <- seq_len(npairs)
    i  <- z$iout[actual]  # sic
    j  <- z$jout[actual]
    if(what == "all") {
      xi <- z$xiout[actual]
      yi <- z$yiout[actual]
      xj <- z$xjout[actual]
      yj <- z$yjout[actual]
      dx <- z$dxout[actual]
      dy <- z$dyout[actual]
      d <-  z$dout[actual]
    }
    # ------------------- end code switch ------------------------
  }
  
  # convert i,j indices to original sequence
  i <- oo[i]
  j <- oo[j]
  # are (i, j) and (j, i) equivalent?
  if(!ordered) {
    ok <- (i < j)
    i  <-  i[ok]
    j  <-  j[ok]
    if(what == "all") {
      xi <- xi[ok]
      yi <- yi[ok]
      xj <- xj[ok]
      yj <- yj[ok]
      dx <- dx[ok]
      dy <- dy[ok]
      d  <-  d[ok]
    }
  }
  # done
  switch(what,
         all = {
           answer <- list(i=i,
                          j=j,
                          xi=xi, 
                          yi=yi,
                          xj=xj,
                          yj=yj,
                          dx=dx,
                          dy=dy,
                          d=d)
         },
         indices = {
           answer <- list(i = i, j = j)
         })
  return(answer)
}

#######################

crosspairs <- function(X, Y, rmax, ...) {
  UseMethod("crosspairs")
}

crosspairs.ppp <- function(X, Y, rmax, what=c("all", "indices"), ...) {
  verifyclass(X, "ppp")
  verifyclass(Y, "ppp")
  what <- match.arg(what)
  stopifnot(is.numeric(rmax) && length(rmax) == 1 && rmax >= 0)
  null.answer <- switch(what,
                        all = {
                          list(i=integer(0),
                               j=integer(0),
                               xi=numeric(0),
                               yi=numeric(0),
                               xj=numeric(0),
                               yj=numeric(0),
                               dx=numeric(0),
                               dy=numeric(0),
                               d=numeric(0))
                        },
                        indices = {
                          list(i=integer(0),
                               j=integer(0))
                        })
  nX <- npoints(X)
  nY <- npoints(Y)
  if(nX == 0 || nY == 0) return(null.answer)
  # order patterns by increasing x coordinate
  ooX <- fave.order(X$x)
  Xsort <- X[ooX]
  ooY <- fave.order(Y$x)
  Ysort <- Y[ooY]
  if(spatstat.options("crosspairs.newcode")) {
    # ------------------- use new faster code ---------------------
    # First (over)estimate the number of pairs
    nsize <- ceiling(2 * pi * (rmax^2) * nX * nY/area(Window(Y)))
    nsize <- max(1024, nsize)
    # .Call
    Xx <- Xsort$x
    Xy <- Xsort$y
    Yx <- Ysort$x
    Yy <- Ysort$y
    r <- rmax
    ng <- nsize
    storage.mode(Xx) <- storage.mode(Xy) <- "double"
    storage.mode(Yx) <- storage.mode(Yy) <- "double"
    storage.mode(r) <- "double"
    storage.mode(ng) <- "integer"
    switch(what,
           all = {
             z <- .Call("Vcrosspairs",
                        xx1=Xx, yy1=Xy,
                        xx2=Yx, yy2=Yy,
                        rr=r, nguess=ng)
             if(length(z) != 9)
               stop("Internal error: incorrect format returned from Vcrosspairs")
             i  <- z[[1]]  # NB no increment required
             j  <- z[[2]]
             xi <- z[[3]]
             yi <- z[[4]]
             xj <- z[[5]]
             yj <- z[[6]]
             dx <- z[[7]]
             dy <- z[[8]]
             d  <- z[[9]]
           },
           indices = {
             z <- .Call("VcrossIJpairs",
                        xx1=Xx, yy1=Xy,
                        xx2=Yx, yy2=Yy,
                        rr=r, nguess=ng)
             if(length(z) != 2)
               stop("Internal error: incorrect format returned from VcrossIJpairs")
             i  <- z[[1]]  # NB no increment required
             j  <- z[[2]]
           })
           
  } else {
    # Older code 
    # obtain upper estimate of number of pairs
    # (to work around gcc bug 323)
    rmaxplus <- 1.25 * rmax
    nsize <- .C("crosscount",
                nn1=as.integer(X$n),
                x1=as.double(Xsort$x),
                y1=as.double(Xsort$y),
                nn2=as.integer(Ysort$n),
                x2=as.double(Ysort$x),
                y2=as.double(Ysort$y),
                rmaxi=as.double(rmaxplus),
                count=as.integer(integer(1)))$count
    if(nsize <= 0)
      return(null.answer)

    # allow slightly more space to work around gcc bug #323
    nsize <- ceiling(1.1 * nsize) + X$n + Y$n
    
    # now extract pairs
    z <-
      .C("Fcrosspairs",
         nn1=as.integer(X$n),
         x1=as.double(Xsort$x),
         y1=as.double(Xsort$y),
         nn2=as.integer(Y$n),
         x2=as.double(Ysort$x),
         y2=as.double(Ysort$y),
         r=as.double(rmax),
         noutmax=as.integer(nsize), 
         nout=as.integer(integer(1)),
         iout=as.integer(integer(nsize)),
         jout=as.integer(integer(nsize)), 
         xiout=as.double(numeric(nsize)),
         yiout=as.double(numeric(nsize)),
         xjout=as.double(numeric(nsize)),
         yjout=as.double(numeric(nsize)),
         dxout=as.double(numeric(nsize)),
         dyout=as.double(numeric(nsize)),
         dout=as.double(numeric(nsize)),
         status=as.integer(integer(1)))
    if(z$status != 0)
      stop(paste("Internal error: C routine complains that insufficient space was allocated:", nsize))
    # trim vectors to the length indicated
    npairs <- z$nout
    if(npairs <= 0)
      return(null.answer)
    actual <- seq_len(npairs)
    i  <- z$iout[actual] # sic
    j  <- z$jout[actual] 
    xi <- z$xiout[actual]
    yi <- z$yiout[actual]
    xj <- z$xjout[actual]
    yj <- z$yjout[actual]
    dx <- z$dxout[actual]
    dy <- z$dyout[actual]
    d <-  z$dout[actual]
  }
  # convert i,j indices to original sequences
  i <- ooX[i]
  j <- ooY[j]
  # done
  switch(what,
         all = {
           answer <- list(i=i,
                          j=j,
                          xi=xi, 
                          yi=yi,
                          xj=xj,
                          yj=yj,
                          dx=dx,
                          dy=dy,
                          d=d)
         },
         indices = {
           answer <- list(i=i, j=j)
         })
  return(answer)
}

closethresh <- function(X, R, S, ordered=TRUE) {
  # list all R-close pairs
  # and indicate which of them are S-close (S < R)
  # so that results are consistent with closepairs(X,S)
  verifyclass(X, "ppp")
  stopifnot(is.numeric(R) && length(R) == 1 && R >= 0)
  stopifnot(is.numeric(S) && length(S) == 1 && S >= 0)
  stopifnot(S < R)
  npts <- npoints(X)
   if(npts == 0)
     return(list(i=integer(0), j=integer(0), t=logical(0)))
  # sort points by increasing x coordinate
  oo <- fave.order(X$x)
  Xsort <- X[oo]
  # First make an OVERESTIMATE of the number of pairs
  nsize <- ceiling(4 * pi * (npts^2) * (R^2)/area(Window(X)))
  nsize <- max(1024, nsize)
  # Now extract pairs
  x <- Xsort$x
  y <- Xsort$y
  r <- R
  s <- S
  ng <- nsize
  storage.mode(x) <- "double"
  storage.mode(y) <- "double"
  storage.mode(r) <- "double"
  storage.mode(s) <- "double"
  storage.mode(ng) <- "integer"
  z <- .Call("Vclosethresh",
             xx=x, yy=y, rr=r, ss=s, nguess=ng)
  if(length(z) != 3)
    stop("Internal error: incorrect format returned from Vclosethresh")
  i  <- z[[1]]  # NB no increment required
  j  <- z[[2]]
  th <- as.logical(z[[3]])
  
  # convert i,j indices to original sequence
  i <- oo[i]
  j <- oo[j]
  # are (i, j) and (j, i) equivalent?
  if(!ordered) {
    ok <- (i < j)
    i  <-  i[ok]
    j  <-  j[ok]
    th <- th[ok]
  }
  # done
  return(list(i=i, j=j, th=th))
}

crosspairquad <- function(Q, rmax, what=c("all", "indices")) {
  # find all close pairs X[i], U[j]
  stopifnot(inherits(Q, "quad"))
  what <- match.arg(what)
  X <- Q$data
  D <- Q$dummy
  clX <- closepairs(X=X, rmax=rmax, what=what)
  clXD <- crosspairs(X=X, Y=D, rmax=rmax, what=what)
  # convert all indices to serial numbers in union.quad(Q)
  # assumes data are listed first
  clXD$j <- npoints(X) + clXD$j
  result <- list(rbind(as.data.frame(clX), as.data.frame(clXD)))
  return(result)
}

  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/clusterset.R"
#
#   clusterset.R
#
#   Allard-Fraley estimator of cluster region
#
#   $Revision: 1.10 $  $Date: 2014/10/24 00:22:30 $
#

clusterset <- function(X, what=c("marks", "domain"),
                       ...,
                       verbose=TRUE,
                       fast=FALSE,
                       exact=!fast) {
  stopifnot(is.ppp(X))
  what <- match.arg(what, several.ok=TRUE)
  if(!missing(exact)) stopifnot(is.logical(exact))
  if(fast && exact)
    stop("fast=TRUE is incompatible with exact=TRUE")
  # compute duplication exactly as in deldir, or the universe will explode
  X <- unique(unmark(X), rule="deldir", warn=TRUE)
  n <- npoints(X)
  W <- as.owin(X)
  # discretised Dirichlet tessellation
  if(verbose) cat("Computing Dirichlet tessellation...")
  if(fast || !exact)
    cellid <- as.im(nnfun(X), ...)
  # compute tile areas
  if(fast) {
    a <- table(factor(as.vector(as.matrix(cellid)), levels=1:n))
    if(verbose) cat("done.\n")
    a <- a + 0.5
    A <- sum(a)
  } else {
    d <- dirichlet(X)
    if(verbose) cat("done.\n")
    D <- tiles(d)
    suppressWarnings(id <- as.integer(names(D)))
    if(any(is.na(id)) && ("marks" %in% what))
      stop("Unable to map Dirichlet tiles to data points")
    A <- area(W)
    a <- unlist(lapply(D, area))
  }
  # determine optimal selection of tiles
  ntile <- length(a)
  o <- order(a)
  b <- cumsum(a[o])
  m <- seq_len(ntile)
  logl <- -n * log(n) + m * log(m/b) + (n-m) * log((n-m)/(A-b))
  mopt <- which.max(logl)
  picked <- o[seq_len(mopt)]
  ## map tiles to points
  if(!fast) picked <- id[picked]
  ## logical vector
  is.picked <- rep.int(FALSE, n)
  is.picked[picked] <- TRUE
  # construct result
  out <- list(marks=NULL, domain=NULL)
  if("marks" %in% what) {
    ## label points
    yesno <- factor(ifelse(is.picked, "yes", "no"), levels=c("no", "yes"))
    out$marks <- X %mark% yesno
  }
  if("domain" %in% what) {
    if(verbose) cat("Computing cluster set...")
    if(exact) {
      domain <- do.call("union.owin", unname(D[is.picked]))
      domain <- rebound.owin(domain, as.rectangle(W))
    } else {
      domain <- eval.im(is.picked[cellid])
    }
    out$domain <- domain
    if(verbose) cat("done.\n")
  }
  out <- if(length(what) == 1) out[[what]] else out
  return(out)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/colourschemes.R"
#
#  colourschemes.R
#
#  $Revision: 1.3 $  $Date: 2013/07/17 04:53:48 $
#

beachcolourmap <- function(range, ...) {
  col <- beachcolours(range, ...)
  z <- colourmap(col, range=range)
  return(z)
}

beachcolours <- function(range, sealevel = 0, monochrome=FALSE,
                         ncolours=if(monochrome) 16 else 64,
                         nbeach=1) {
  if(monochrome)
    return(grey(seq(from=0,to=1,length.out=ncolours)))
  stopifnot(is.numeric(range) && length(range) == 2)
  stopifnot(all(is.finite(range)))
  depths <- range[1]
  peaks <- range[2]
  dv <- diff(range)/(ncolours - 1)
  epsilon <- nbeach * dv/2
  lowtide <- max(sealevel - epsilon, depths)
  hightide <-  min(sealevel + epsilon, peaks)
  countbetween <- function(a, b, delta) { max(0, round((b-a)/delta)) }
  nsea <- countbetween(depths, lowtide, dv)
  nbeach <- countbetween(lowtide,  hightide, dv)
  nland <- countbetween(hightide,  peaks, dv)
  colours <- character(0)
  if(nsea > 0)  colours <- rev(rainbow(nsea, start=3/6,end=4/6)) # cyan/blue
  if(nbeach > 0)  colours <- c(colours,
                             rev(rainbow(nbeach, start=3/12,end=5/12))) # green
  if(nland > 0)  colours <- c(colours,
                              rev(rainbow(nland, start=0, end=1/6)))  # red/yellow
  return(colours)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/colourtables.R"
#
# colourtables.R
#
# support for colour maps and other lookup tables
#
# $Revision: 1.34 $ $Date: 2014/11/12 01:21:02 $
#

colourmap <- function(col, ..., range=NULL, breaks=NULL, inputs=NULL) {
  if(nargs() == 0) {
    ## null colour map
    f <- lut()
  } else {
    ## validate colour data 
    col2hex(col)
    ## store without conversion
    f <- lut(col, ..., range=range, breaks=breaks, inputs=inputs)
  }
  class(f) <- c("colourmap", class(f))
  f
}

lut <- function(outputs, ..., range=NULL, breaks=NULL, inputs=NULL) {
  if(nargs() == 0) {
    ## null lookup table
    f <- function(x, what="value"){NULL}
    class(f) <- c("lut", class(f))
    attr(f, "stuff") <- list(n=0)
    return(f)
  }
  n <- length(outputs)
  given <- c(!is.null(range), !is.null(breaks), !is.null(inputs))
  names(given) <- c("range", "breaks", "inputs")
  ngiven <- sum(given)
  if(ngiven == 0)
    stop(paste("One of the arguments",
               sQuote("range"), ",", sQuote("breaks"), "or", sQuote("inputs"),
               "should be given"))
  if(ngiven > 1) {
    offending <- names(breaks)[given]
    stop(paste("The arguments",
               commasep(sQuote(offending)),
               "are incompatible"))
  }
  if(!is.null(inputs)) {
    # discrete set of input values mapped to output values
    stopifnot(length(inputs) == length(outputs))
    stuff <- list(n=n, discrete=TRUE, inputs=inputs, outputs=outputs)
    f <- function(x, what="value") {
      m <- match(x, stuff$inputs)
      if(what == "index")
        return(m)
      cout <- stuff$outputs[m]
      return(cout)
    }
  } else if(!is.null(range) && inherits(range, c("Date", "POSIXt"))) {
    # date/time interval mapped to colours
    timeclass <- if(inherits(range, "Date")) "Date" else "POSIXt"
    if(is.null(breaks)) {
      breaks <- seq(from=range[1], to=range[2], length.out=length(outputs)+1)
    } else {
      if(!inherits(breaks, timeclass))
        stop(paste("breaks should belong to class", dQuote(timeclass)),
             call.=FALSE)
      stopifnot(length(breaks) >= 2)
      stopifnot(length(breaks) == length(outputs) + 1)
      if(!all(diff(breaks) > 0))
        stop("breaks must be increasing")
    }
    stuff <- list(n=n, discrete=FALSE, breaks=breaks, outputs=outputs)
    f <- function(x, what="value") {
      x <- as.vector(as.numeric(x))
      z <- findInterval(x, stuff$breaks,
                        rightmost.closed=TRUE)
      if(what == "index")
        return(z)
      cout <- stuff$outputs[z]
      return(cout)
    }
  } else {
    # interval of real line mapped to colours
    if(is.null(breaks)) {
      breaks <- seq(from=range[1], to=range[2], length.out=length(outputs)+1)
    } else {
      stopifnot(is.numeric(breaks) && length(breaks) >= 2)
      stopifnot(length(breaks) == length(outputs) + 1)
      if(!all(diff(breaks) > 0))
        stop("breaks must be increasing")
    }
    stuff <- list(n=n, discrete=FALSE, breaks=breaks, outputs=outputs)
    f <- function(x, what="value") {
      stopifnot(is.numeric(x))
      x <- as.vector(x)
      z <- findInterval(x, stuff$breaks,
                        rightmost.closed=TRUE)
      if(what == "index")
        return(z)
      cout <- stuff$outputs[z]
      return(cout)
    }
  }
  attr(f, "stuff") <- stuff
  class(f) <- c("lut", class(f))
  f
}

print.lut <- function(x, ...) {
  if(inherits(x, "colourmap")) {
    tablename <- "Colour map"
    outputname <- "colour"
  } else {
    tablename  <- "Lookup table"
    outputname <- "output"
  }
  stuff <- attr(x, "stuff")
  n <- stuff$n
  if(n == 0) {
    ## Null map
    cat(paste("Null", tablename, "\n"))
    return(invisible(NULL))
  }
  if(stuff$discrete) {
    cat(paste(tablename, "for discrete set of input values\n"))
    out <- data.frame(input=stuff$inputs, output=stuff$outputs)
  } else {
    b <- stuff$breaks
    cat(paste(tablename, "for the range", prange(b[c(1,n+1)]), "\n"))
    leftend  <- rep("[", n)
    rightend <- c(rep(")", n-1), "]")
    inames <- paste(leftend, b[-(n+1)], ", ", b[-1], rightend, sep="")
    out <- data.frame(interval=inames, output=stuff$outputs)
  }
  colnames(out)[2] <- outputname
  print(out)
  invisible(NULL)
}

print.colourmap <- function(x, ...) {
  NextMethod("print")
}

summary.lut <- function(object, ...) {
  s <- attr(object, "stuff")
  if(inherits(object, "colourmap")) {
    s$tablename <- "Colour map"
    s$outputname <- "colour"
  } else {
    s$tablename  <- "Lookup table"
    s$outputname <- "output"
  }
  class(s) <- "summary.lut"
  return(s)
}

print.summary.lut <- function(x, ...) {
  n <- x$n
  if(n == 0) {
    cat(paste("Null", x$tablename, "\n"))
    return(invisible(NULL))
  }
  if(x$discrete) {
    cat(paste(x$tablename, "for discrete set of input values\n"))
    out <- data.frame(input=x$inputs, output=x$outputs)
  } else {
    b <- x$breaks
    cat(paste(x$tablename, "for the range", prange(b[c(1,n+1)]), "\n"))
    leftend  <- rep("[", n)
    rightend <- c(rep(")", n-1), "]")
    inames <- paste(leftend, b[-(n+1)], ", ", b[-1], rightend, sep="")
    out <- data.frame(interval=inames, output=x$outputs)
  }
  colnames(out)[2] <- x$outputname
  print(out)  
}

plot.colourmap <- local({

  # recognised additional arguments to image.default() and axis()
  
  imageparams <- c("main", "asp", "sub", "axes", "ann",
                   "cex", "font", 
                   "cex.axis", "cex.lab", "cex.main", "cex.sub",
                   "col.axis", "col.lab", "col.main", "col.sub",
                   "font.axis", "font.lab", "font.main", "font.sub")
  axisparams <- c("cex", 
                  "cex.axis", "cex.lab",
                  "col.axis", "col.lab",
                  "font.axis", "font.lab",
                  "las", "mgp", "xaxp", "yaxp",
                  "tck", "tcl", "xpd")

  linmap <- function(x, from, to) {
    to[1] + diff(to) * (x - from[1])/diff(from)
  }

  # rules to determine the ribbon dimensions when one dimension is given
  widthrule <- function(heightrange, separate, n, gap) {
    if(separate) 1 else diff(heightrange)/10
  }
  heightrule <- function(widthrange, separate, n, gap) {
    (if(separate) (n + (n-1)*gap) else 10) * diff(widthrange) 
  }

  plot.colourmap <- function(x, ..., main,
                             xlim=NULL, ylim=NULL, vertical=FALSE, axis=TRUE,
                             labelmap=NULL, gap=0.25, add=FALSE) {
    if(missing(main))
      main <- short.deparse(substitute(x))
    stuff <- attr(x, "stuff")
    col <- stuff$outputs
    n   <- stuff$n
    if(n == 0) {
      ## Null map
      return(invisible(NULL))
    }
    discrete <- stuff$discrete
    if(discrete) {
      check.1.real(gap, "In plot.colourmap")
      explain.ifnot(gap >= 0, "In plot.colourmap")
    }
    separate <- discrete && (gap > 0)
    if(is.null(labelmap)) {
      labelmap <- function(x) x
    } else if(is.numeric(labelmap) && length(labelmap) == 1 && !discrete) {
      labscal <- labelmap
      labelmap <- function(x) { x * labscal }
    } else stopifnot(is.function(labelmap))

    # determine pixel entries 'v' and colour map breakpoints 'bks'
    # to be passed to 'image.default'
    if(!discrete) {
      # real numbers: continuous ribbon
      bks <- stuff$breaks
      rr <- range(bks)
      v <- seq(from=rr[1], to=rr[2], length.out=max(n+1, 1024))
    } else if(!separate) {
      # discrete values: blocks of colour, run together
      v <- (1:n) - 0.5
      bks <- 0:n
      rr <- c(0,n)
    } else {
      # discrete values: separate blocks of colour
      vleft <- (1+gap) * (0:(n-1))
      vright <- vleft + 1
      v <- vleft + 0.5
      rr <- c(0, n + (n-1)*gap)
    }
    # determine position of ribbon or blocks of colour
    if(is.null(xlim) && is.null(ylim)) {
      u <- widthrule(rr, separate, n, gap)
      if(!vertical) {
        xlim <- rr
        ylim <- c(0,u)
      } else {
        xlim <- c(0,u)
        ylim <- rr
      }
    } else if(is.null(ylim)) {
      if(!vertical) 
        ylim <- c(0, widthrule(xlim, separate, n, gap))
      else 
        ylim <- c(0, heightrule(xlim, separate, n, gap))
    } else if(is.null(xlim)) {
      if(!vertical) 
        xlim <- c(0, heightrule(ylim, separate, n, gap))
      else 
        xlim <- c(0, widthrule(ylim, separate, n, gap))
    } 

    # .......... initialise plot ...............................
    if(!add)
      do.call.matched("plot.default",
                      resolve.defaults(list(x=xlim, y=ylim,
                                            type="n", main=main,
                                            axes=FALSE, xlab="", ylab="",
                                            asp=1.0),
                                       list(...)))
    
    if(separate) {
      # ................ plot separate blocks of colour .................
      if(!vertical) {
        # horizontal arrangement of blocks
        xleft <- linmap(vleft, rr, xlim)
        xright <- linmap(vright, rr, xlim)
        y <- ylim
        z <- matrix(1, 1, 1)
        for(i in 1:n) {
          x <- c(xleft[i], xright[i])
          do.call.matched("image.default",
                      resolve.defaults(list(x=x, y=y, z=z, add=TRUE),
                                       list(...),
                                       list(col=col[i])),
                      extrargs=imageparams)
                          
        }
      } else {
        # vertical arrangement of blocks
        x <- xlim 
        ylow <- linmap(vleft, rr, ylim)
        yupp <- linmap(vright, rr, ylim)
        z <- matrix(1, 1, 1)
        for(i in 1:n) {
          y <- c(ylow[i], yupp[i])
          do.call.matched("image.default",
                      resolve.defaults(list(x=x, y=y, z=z, add=TRUE),
                                       list(...),
                                       list(col=col[i])),
                      extrargs=imageparams)
                          
        }
      }
    } else {
      # ................... plot ribbon image .............................
      if(!vertical) {
        # horizontal colour ribbon
        x <- linmap(v, rr, xlim)
        y <- ylim
        z <- matrix(v, ncol=1)
      } else {
        # vertical colour ribbon
        y <- linmap(v, rr, ylim)
        z <- matrix(v, nrow=1)
        x <- xlim
      }
      do.call.matched("image.default",
                      resolve.defaults(list(x=x, y=y, z=z, add=TRUE),
                                       list(...),
                                       list(breaks=bks, col=col)),
                      extrargs=imageparams)
    }
    if(axis) {
      # ................. draw annotation ..................
      if(!vertical) {
          # add horizontal axis/annotation
        if(discrete) {
          la <- paste(labelmap(stuff$inputs))
          at <- linmap(v, rr, xlim)
        } else {
          la <- prettyinside(rr)
          at <- linmap(la, rr, xlim)
          la <- labelmap(la)
        }
        # default axis position is below the ribbon (side=1)
        sidecode <- resolve.1.default("side", list(...), list(side=1))
        if(!(sidecode %in% c(1,3)))
          warning(paste("side =", sidecode,
                        "is not consistent with horizontal orientation"))
        pos <- c(ylim[1], xlim[1], ylim[2], xlim[2])[sidecode]
        # don't draw axis lines if plotting separate blocks
        lwd0 <- if(separate) 0 else 1
        # draw axis
        do.call.matched("axis",
                        resolve.defaults(list(...),
                                         list(side = 1, pos = pos, at = at),
                                         list(labels=la, lwd=lwd0)),
                        extrargs=axisparams)
      } else {
        # add vertical axis
        if(discrete) {
          la <- paste(labelmap(stuff$inputs))
          at <- linmap(v, rr, ylim)
        } else {
          la <- prettyinside(rr)
          at <- linmap(la, rr, ylim)
          la <- labelmap(la)
        }
        # default axis position is to the right of ribbon (side=4)
        sidecode <- resolve.1.default("side", list(...), list(side=4))
        if(!(sidecode %in% c(2,4)))
          warning(paste("side =", sidecode,
                        "is not consistent with vertical orientation"))
        pos <- c(ylim[1], xlim[1], ylim[2], xlim[2])[sidecode]
        # don't draw axis lines if plotting separate blocks
        lwd0 <- if(separate) 0 else 1
        # draw labels horizontally if plotting separate blocks
        las0 <- if(separate) 1 else 0
        # draw axis
        do.call.matched("axis",
                        resolve.defaults(list(...),
                                         list(side=4, pos=pos, at=at),
                                         list(labels=la, lwd=lwd0, las=las0)),
                        extrargs=axisparams)
      }
    }
    invisible(NULL)
  }

  plot.colourmap
})


# Interpolate a colourmap or lookup table defined on real numbers

interp.colourmap <- function(m, n=512) {
  if(!inherits(m, "colourmap"))
    stop("m should be a colourmap")
  st <- attr(m, "stuff")
  if(st$discrete) {
    # discrete set of input values mapped to colours
    xknots <- st$inputs
    # Ensure the inputs are real numbers
    if(!is.numeric(xknots))
      stop("Cannot interpolate: inputs are not numerical values")
  } else {
    # interval of real line, chopped into intervals, mapped to colours
    # Find midpoints of intervals
    bks <- st$breaks
    nb <- length(bks)
    xknots <- (bks[-1] + bks[-nb])/2
  }
  # corresponding colours in hsv coordinates
  yknots.hsv <- rgb2hsv(col2rgb(st$outputs))
  # transform 'hue' from polar to cartesian coordinate
  # divide domain into n equal intervals
  xrange <- range(xknots)
  xbreaks <- seq(xrange[1], xrange[2], length=n+1)
  xx <- (xbreaks[-1] + xbreaks[-(n+1)])/2
  # interpolate saturation and value in hsv coordinates
  yy.sat <- approx(x=xknots, y=yknots.hsv["s", ], xout=xx)$y
  yy.val <- approx(x=xknots, y=yknots.hsv["v", ], xout=xx)$y
  # interpolate hue by first transforming polar to cartesian coordinate
  yknots.hue <- 2 * pi * yknots.hsv["h", ]
  yy.huex <- approx(x=xknots, y=cos(yknots.hue), xout=xx)$y
  yy.huey <- approx(x=xknots, y=sin(yknots.hue), xout=xx)$y
  yy.hue <- (atan2(yy.huey, yy.huex)/(2 * pi)) %% 1
  # form colours using hue, sat, val
  yy <- hsv(yy.hue, yy.sat, yy.val)
  # done
  f <- colourmap(yy, breaks=xbreaks)
  return(f)
}

interp.colours <- function(x, length.out=512) {
  y <- colourmap(x, range=c(0,1))
  z <- interp.colourmap(y, length.out)
  oo <- attr(z, "stuff")$outputs
  return(oo)
}

tweak.colourmap <- function(m, col, ..., inputs=NULL, range=NULL) {
  if(!inherits(m, "colourmap"))
    stop("m should be a colourmap")
  if(is.null(inputs) && is.null(range)) 
    stop("Specify either inputs or range")
  if(!is.null(inputs) && !is.null(range))
    stop("Do not specify both inputs and range")
  # determine indices of colours to be changed
  if(!is.null(inputs)) {
    ix <- m(inputs, what="index")
  } else {
    if(!(is.numeric(range) && length(range) == 2 && diff(range) > 0))
      stop("range should be a numeric vector of length 2 giving (min, max)")
    if(length(col2hex(col)) != 1)
      stop("When range is given, col should be a single colour value")
    ixr <- m(range, what="index")
    ix <- (ixr[1]):(ixr[2])
  }
  # reassign colours
  st <- attr(m, "stuff")
  outputs <- st$outputs
  is.hex <- function(z) identical(substr(z, 1, 7), substr(col2hex(z), 1, 7))
  result.hex <- FALSE
  if(is.hex(outputs)) {
    # convert replacement data to hex
    col <- col2hex(col)
    result.hex <- TRUE
  } else if(is.hex(col)) {
    # convert existing data to hex
    outputs <- col2hex(outputs)
    result.hex <- TRUE
  } else if(!(is.character(outputs) && is.character(col))) {
    # unrecognised format - convert both to hex
    outputs <- col2hex(outputs)
    col <- col2hex(col)
    result.hex <- TRUE
  }
  if(result.hex) {
    # hex codes may be 7 or 9 characters
    outlen <- nchar(outputs)
    collen <- nchar(col)
    if(length(unique(c(outlen, collen))) > 1) {
      # convert all to 9 characters
      if(any(bad <- (outlen == 7))) 
        outputs[bad] <- paste0(outputs[bad], "FF")
      if(any(bad <- (collen == 7))) 
        col[bad] <- paste0(col[bad], "FF")
    }
  }
  # Finally, replace
  outputs[ix] <- col
  st$outputs <- outputs
  attr(m, "stuff") <- st
  assign("stuff", st, envir=environment(m))
  return(m)
}

colouroutputs <- function(x) {
  stopifnot(inherits(x, "colourmap"))
  attr(x, "stuff")$outputs
}

"colouroutputs<-" <- function(x, value) {
  stopifnot(inherits(x, "colourmap"))
  st <- attr(x, "stuff")
  col2hex(value) # validates colours
  st$outputs[] <- value
  attr(x, "stuff") <- st
  assign("stuff", st, envir=environment(x))
  return(x)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/colourtools.R"
#
#  colourtools.R
#
#   $Revision: 1.9 $   $Date: 2014/10/14 12:35:54 $
#


rgb2hex <- function(v) {
  stopifnot(is.numeric(v))
  if(is.matrix(v)) {
    stopifnot(ncol(v) == 3)
  } else {
    if(length(v) != 3)
      stop("v should be a vector of length 3 or a matrix with 3 columns")
    v <- matrix(v, ncol=3)
  } 
  out <- rgb(v[,1], v[,2], v[,3], maxColorValue=255)
  return(out)
}

col2hex <- function(x) { apply(col2rgb(x), 2, rgb2hex) }

paletteindex <- function(x) {
  x <- col2hex(x)
  p <- col2hex(palette())
  m <- match(x, p)
  return(m)
}

samecolour <- function(x, y) { col2hex(x) == col2hex(y) }

complementarycolour <- function(x) {
  if(is.null(x)) return(NULL)
  if(inherits(x, "colourmap")) {
    colouroutputs(x) <- complementarycolour(colouroutputs(x))
    return(x)
  }
  y <- apply(255 - col2rgb(x), 2, rgb2hex)
  return(y)
}

is.grey <- function(x) {
  if(inherits(x, "colourmap")) x <- colouroutputs(x)
  if(is.function(x)) return(NA)
  sat <- rgb2hsv(col2rgb(x))["s", ]
  return(sat == 0)
}
  
to.grey <- function(x, weights=c(1,1,1)) {
  if(is.null(x)) return(NULL)
  if(inherits(x, "colourmap")) {
    colouroutputs(x) <- to.grey(colouroutputs(x), weights=weights)
    return(x)
  }
  if(is.function(x)) {
    f <- x
    g <- function(...) to.grey(f(...))
    return(g)
  }
  ## preserve palette indices, if only using black/grey
  if(all(!is.na(paletteindex(x))) && all(is.grey(x)))
    return(x)
  y <- col2rgb(x)
  z <- (weights %*% y)/(255 * sum(weights))
  return(grey(z))
}

# versions of rgb() and hsv() that work with NA values

rgbNA <- function(red, green, blue, ...) {
  with(data.frame(red=red, green=green, blue=blue), {
    ok <- !(is.na(red) | is.na(green) | is.na(blue))
    values <- rgb(red[ok], green[ok], blue[ok], ...)
    result <- character(length(red))
    result[ok] <- values
    result[!ok] <- NA
    return(result)
  })
}

hsvNA <- function(h, s, v, ...) {
  with(data.frame(h=h, s=s, v=v), {
    ok <- !(is.na(h) | is.na(s) | is.na(v))
    values <- hsv(h[ok], s[ok], v[ok], ...)
    result <- character(length(h))
    result[ok] <- values
    result[!ok] <- NA
    return(result)
  })
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/compareFit.R"
#
# compareFit.R
#
# $Revision: 1.2 $  $Date: 2014/10/24 00:22:30 $

compareFit <- function(object, Fun, r=NULL, breaks=NULL,
                     ..., trend=~1, interaction=Poisson(),
                     rbord=NULL, modelnames=NULL,
                     same=NULL, different=NULL) {
  dotargs <- list(...)
  h <- hyperframe(obj=object, tren=trend, inte=interaction)
  N <- nrow(h)
  if(N == 0)
    stop("No objects specified")
  # determine rbord for summary statistics
  if(is.null(rbord) && !is.null(interaction))
    rbord <- max(with(h, reach(inte)))
  h$rbord <- rbord
  # try to get nice model names
  if(is.null(modelnames)) {
    if(inherits(trend, "formula") && is.interact(interaction) &&
       inherits(object, "listof") && all(nzchar(names(object))) &&
       length(names(object)) == nrow(h))
      modelnames <- names(object)
    else if(inherits(trend, "listof") && all(nzchar(names(trend))) &&
            length(names(trend)) == nrow(h))
      modelnames <- names(trend) 
    else if(inherits(interaction, "listof") &&
            all(nzchar(names(interaction))) &&
            length(names(interaction)) == nrow(h))
      modelnames <- names(interaction)
    else 
      modelnames <- row.names(h)
  }
  row.names(h) <- make.names(modelnames)
  # fix a common vector of r values
  if(is.null(r)) {
    # compute first function 
    fun1 <- with(h[1,,drop=TRUE,strip=FALSE],
                 do.call(Fun,
                         append(list(object=obj,
                                     trend=tren,
                                     interaction=inte,
                                     rbord=rbord,
                                     r=NULL, breaks=breaks),
                                dotargs)))
    # extract r values
    r <- with(fun1, .x)
  }
  # compute the subsequent functions
  if(N == 1)
    funs2toN <- NULL
  else 
    funs2toN <- with(h[-1, , drop=TRUE, strip=FALSE],
                     do.call(Fun,
                             append(list(object=obj,
                                         trend=tren,
                                         interaction=inte,
                                         rbord=rbord,
                                         r=r),
                                    dotargs)))
  if(N == 2)
    funs2toN <- list(funs2toN)
  # collect all functions in a list
  funs <- as.listof(append(list(fun1), funs2toN))
  names(funs) <- row.names(h)
  # collapse together
  out <- collapse.fv(funs, same=same, different=different)
  return(out)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/compileK.R"
# compileK
#
# Function to take a matrix of pairwise distances
# and compile a 'K' function in the format required by spatstat.
#
#   $Revision: 1.7 $  $Date: 2014/10/24 00:22:30 $
# -------------------------------------------------------------------

compileK <- function(D, r, weights=NULL, denom=1, check=TRUE, ratio=FALSE,
                     fname="K") {
  # process r values
  breaks <- breakpts.from.r(r)
  rmax <- breaks$max
  r    <- breaks$r
  # check that D is a symmetric matrix with nonnegative entries
  if(check)
    stopifnot(is.matrix(D) && isSymmetric(D) && all(D >= 0))
  # ignore the diagonal; throw away any D values greater than rmax
  ok <- (D <= rmax & D > 0)
  Dvalues <- D[ok]
  #
  # weights?
  if(!is.null(weights)) {
    stopifnot(is.matrix(weights) && all(dim(weights)==dim(D)))
    wvalues <- weights[ok]
  } else wvalues <- NULL
  # count the number of D values in each interval (r[k], r[k+1]]
  counts <- whist(Dvalues, breaks=breaks$val, weights=wvalues)
  # cumulative counts: number of D values in [0, r[k])
  Kcount <- cumsum(counts)
  # divide by appropriate denominator
  Kratio <- Kcount/denom
  # wrap it up as an 'fv' object for use in spatstat
  df <- data.frame(r=r, est=Kratio)
  if(!ratio) {
    K <- fv(df, "r", quote(K(r)), "est", . ~ r , c(0,rmax),
            c("r", makefvlabel(NULL, "hat", fname)), 
            c("distance argument r", "estimated %s"),
            fname=fname)
  } else {
    num <- data.frame(r=r, est=Kcount)
    den <- data.frame(r=r, est=denom)
    K <- ratfv(num, den,
               "r", quote(K[compile](r)), "est", . ~ r , c(0,rmax),
               c("r", makefvlabel(NULL, "hat", fname)), 
               c("distance argument r", "estimated %s"),
               fname=fname)
  }
  return(K)
}


compilepcf <- function(D, r, weights=NULL, denom=1, check=TRUE,
                       endcorrect=TRUE, ..., fname="g") {
  # process r values
  breaks <- breakpts.from.r(r)
  if(!breaks$even)
    stop("compilepcf: r values must be evenly spaced", call.=FALSE)
  r    <- breaks$r
  rmax <- breaks$max
  # check that D is a symmetric matrix with nonnegative entries
  if(check)
    stopifnot(is.matrix(D) && isSymmetric(D) && all(D >= 0))
  # ignore the diagonal; throw away any D values greater than rmax
  ok <- (D <= rmax & D > 0)
  Dvalues <- D[ok]
  #
  # weights?
  if(!is.null(weights)) {
    stopifnot(is.matrix(weights) && all(dim(weights)==dim(D)))
    wvalues <- weights[ok]
    totwt <- sum(wvalues)
    normwvalues <- wvalues/totwt
  } else {
    nv <- length(Dvalues)
    normwvalues <- rep.int(1/nv, nv)
    totwt <- nv
  }
  # form kernel estimate
  rmin <- min(r)
  rmax <- max(r)
  nr   <- length(r)
  den <- density(Dvalues, weights=normwvalues,
                 from=rmin, to=rmax, n=nr, ...)
  gval <- den$y * totwt
  # normalise
  gval <- gval/denom
  # edge effect correction at r = 0
  if(endcorrect) {
    one <- do.call("density",
                   resolve.defaults(
                                    list(seq(rmin,rmax,length=512)),
                                    list(bw=den$bw, adjust=1),
                                    list(from=rmin, to=rmax, n=nr),
                                    list(...)))
    onefun <- approxfun(one$x, one$y, rule=2)
    gval <- gval /((rmax-rmin) * onefun(den$x))
  }
  # wrap it up as an 'fv' object for use in spatstat
  df <- data.frame(r=r,
                   est=gval)
  g <- fv(df, "r", quote(g(r)), "est", . ~ r , c(0,rmax),
          c("r", makefvlabel(NULL, "hat", fname)),
          c("distance argument r", "estimated %s"),
          fname=fname)
  attr(g, "bw") <- den$bw
  return(g)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/concom.R"
#
#
#    concom.R
#
#    $Revision: 1.1 $	$Date: 2013/02/25 05:19:36 $
#
#    The connected component interaction
#
#    Concom()    create an instance of the connected component interaction
#                 [an object of class 'interact']
#	
# -------------------------------------------------------------------
#

Concom <- local({

  connectedlabels <- function(X, R) {
    connected(X, R, internal=TRUE)
  }
  
  countcompo <- function(X, R) {
    length(unique(connectedlabels(X, R)))
  }

   # change in number of components when point i is deleted
  cocoDel <- function(X, R, subset=seq_len(npoints(X))) {
    n <- length(subset)
    ans <- integer(n)
    if(n > 0) {
      cX <- countcompo(X, R)
      for(i in 1:n) 
        ans[i] = countcompo(X[-subset[i]], R) - cX
    }
    return(ans)
  }

  # change in number of components when new point is added

  cocoAdd <- function(U, X, R) {
    U <- as.ppp(U, W=as.owin(X))
    nU <- npoints(U)
    cr <- crosspairs(U, X, R)
    lab <- connectedlabels(X, R)
    hitcomp <- tapply(X=lab[cr$j],
                      INDEX=factor(cr$i, levels=1:nU),
                      FUN=unique, 
                      simplify=FALSE)
    nhit <- unname(unlist(lapply(hitcomp, length)))
    change <- 1 - nhit
    return(change)
  }

  # connected component potential 
  cocopot <- 
    function(X,U,EqualPairs,pars,correction, ...) {
      bad <- !(correction %in% c("border", "none"))
      if((nbad <- sum(bad)) > 0) 
        warning(paste("The",
                      ngettext(nbad, "correction", "corrections"),
                      commasep(sQuote(correction[!ok])),
                      ngettext(nbad, "is", "are"),
                      "not implemented"))
      n <- U$n
      answer <- numeric(n)
      r <- pars$r
      if(is.null(r)) stop("internal error: r parameter not found")
      dummies <- !(seq_len(n) %in% EqualPairs[,2])
      if(sum(dummies) > 0)
        answer[dummies] <- -cocoAdd(U[dummies], X, r)
      ii <- EqualPairs[,1]
      jj <- EqualPairs[,2]
      answer[jj] <- cocoDel(X, r, subset=ii)
      return(answer + 1)
    }

  # template object without family, par, version
  BlankCoco <- 
  list(
         name     = "Connected component process",
         creator  = "Concom",
         family   = "inforder.family", # evaluated later
         pot      = cocopot,
         par      = list(r = NULL), # to be filled in
         parnames = "distance threshold",
         init     = function(self) {
                      r <- self$par$r
                      if(!is.numeric(r) || length(r) != 1 || r <= 0)
                       stop("distance threshold r must be a positive number")
                    },
         update = NULL,  # default OK
         print = NULL,    # default OK
         interpret =  function(coeffs, self) {
           logeta <- as.numeric(coeffs[1])
           eta <- exp(logeta)
           return(list(param=list(eta=eta),
                       inames="interaction parameter eta",
                       printable=signif(eta)))
         },
         valid = function(coeffs, self) {
           eta <- ((self$interpret)(coeffs, self))$param$eta
           return(is.finite(eta))
         },
         project = function(coeffs, self) {
           if((self$valid)(coeffs, self))
             return(NULL)
           return(Poisson())
         },
         irange = function(self, coeffs=NA, epsilon=0, ...) {
           if(any(is.na(coeffs)))
             return(Inf)
           logeta <- coeffs[1]
           if(abs(logeta) <= epsilon)
             return(0)
           else
             return(Inf)
         },
       version=NULL # to be added
  )
  class(BlankCoco) <- "interact"

  Concom <- function(r) {
    instantiate.interact(BlankCoco, list(r=r))
  }

  Concom <- intermaker(Concom, BlankCoco)
  
  Concom
})


             
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/connected.R"
#
# connected.R
#
# connected component transform
#
#    $Revision: 1.17 $  $Date: 2014/10/24 00:22:30 $
#
# Interpreted code for pixel images by Julian Burgos <jmburgos@u.washington.edu>
# Rewritten in C by Adrian Baddeley
#
# Code for point patterns by Adrian Baddeley

connected <- function(X, ...) {
  UseMethod("connected")
}

connected.im <- function(X, ..., background=NA, method="C") {
  method <- pickoption("algorithm choice", method,
                       c(C="C", interpreted="interpreted"))
  if(!is.na(background))
    X <- solutionset(X != background)
  else
    X <- as.mask(as.owin(X))
  connected.owin(X, method=method)
}

connected.owin <- function(X, ..., method="C") {
  method <- pickoption("algorithm choice", method,
                       c(C="C", interpreted="interpreted"))
  # convert X to binary mask
  X <- as.mask(X)
  #     
  Y <- X$m
  nr <- X$dim[1]
  nc <- X$dim[2]

  if(method == "C") {
################ COMPILED CODE #########################
# Pad border with FALSE
    M <- rbind(FALSE, Y, FALSE)
    M <- cbind(FALSE, M, FALSE)
    # assign unique label to each foreground pixel 
    L <- M
    L[M] <- seq_len(sum(M))
    L[!M] <- 0
    # resolve labels
    z <- .C("cocoImage",
            mat=as.integer(t(L)),
            nr=as.integer(nr),
            nc=as.integer(nc))
    # unpack
    Z <- matrix(z$mat, nr+2, nc+2, byrow=TRUE)
  } else {
################ INTERPRETED CODE #########################
# by Julian Burgos
#  
# Pad border with zeros
    padY <- rbind(0, Y, 0)
    padY <- cbind(0, padY, 0)
    # Initialise 
    Z <- matrix(0, nrow(padY), ncol(padY))
    currentlab <- 1
    todo <- as.vector(t(Y))
    equiv <- NULL
  
    # ........ main loop ..........................
    while(any(todo)){
      # pick first unresolved pixel
      one <- which(todo)[1]
      onerow <- ceiling(one/nc)
      onecol <- one -((onerow-1)*nc)
      parow=onerow+1 # Equivalent rows & column in padded matrix
      pacol=onecol+1
      #Examine four previously scanned neighbors
      # (use padded matrix to avoid edge issues)
      nbrs <- rbind(c(parow-1,pacol-1),
                    c(parow-1,pacol),
                    c(parow,  pacol-1),
                    c(parow-1,pacol+1))
      px <- sum(padY[nbrs])
      if (px==0){
        # no neighbours: new component
        Z[parow,pacol] <- currentlab
        currentlab <- currentlab+1
        todo[one] <- FALSE
      } else if(px==1) {
        # one neighbour: assign existing label
        labs <- unique(Z[nbrs], na.rm=TRUE)
        labs <- labs[labs != 0]
        Z[parow,pacol] <- labs[1]
        currentlab <- max(Z)+1
        todo[one] <- FALSE
      } else {
        # more than one neighbour: possible merger of labels
        labs <- unique(Z[nbrs], na.rm=TRUE)
        labs <- labs[labs != 0]
        labs <- sort(labs)
        equiv <- rbind(equiv,c(labs,rep.int(0,times=4-length(labs))))
        Z[parow,pacol] <- labs[1]
        currentlab <- max(Z)+1
        todo[one] <- FALSE
      }
    }
    # ........... end of loop ............
    # Resolve equivalences ................

    if(length(equiv)>1){
      merges <- (equiv[,2] > 1)
      nmerge <- sum(merges)
      if(nmerge==1)
        equiv <- equiv[which(merges), , drop=FALSE]
      else if(nmerge > 1) {
        relevant <- (equiv[,2] > 0)
        equiv <- equiv[relevant, , drop=FALSE]
        equiv <- equiv[fave.order(equiv[,1]),]
      }
      for (i in 1:nrow(equiv)){
        current <- equiv[i, 1]
        for (j in 2:4){
          twin <- equiv[i,j]
          if (twin>0){
            # Change labels matrix
            Z[which(Z==twin)] <- current
            # Update equivalence table
            equiv[which(equiv==twin)] <- current
          }
        }
      }
    }
  }

  ########### COMMON CODE ############################
    
  # Renumber labels sequentially
  mapped <- (Z != 0)
  usedlabs <- sort(unique(as.vector(Z[mapped])))
  nlabs <- length(usedlabs)
  labtable <- cumsum(seq_len(max(usedlabs)) %in% usedlabs)
  Z[mapped] <- labtable[Z[mapped]]

  # banish zeroes
  Z[!mapped] <- NA
  
  # strip borders
  Z <- Z[2:(nrow(Z)-1),2:(ncol(Z)-1)]
  # dress up 
  Z <- im(factor(Z, levels=1:nlabs),
          xcol=X$xcol, yrow=X$yrow, unitname=unitname(X))
  return(Z)
}

connected.ppp <- function(X, R, ...) {
  stopifnot(is.ppp(X))
  check.1.real(R, "In connected.ppp")
  stopifnot(R >= 0)
  internal <- resolve.1.default("internal", list(...), list(internal=FALSE))
  nv <- npoints(X)
  cl <- closepairs(X, R, what="indices")
  ie <- cl$i - 1L
  je <- cl$j - 1L
  ne <- length(ie)
  zz <- .C("cocoGraph",
           nv=as.integer(nv),
           ne=as.integer(ne),
           ie=as.integer(ie),
           je=as.integer(je),
           label=as.integer(integer(nv)),
           status=as.integer(integer(1)))
  if(zz$status != 0)
    stop("Internal error: connected.ppp did not converge")
  if(internal)
    return(zz$label)
  lab <- zz$label + 1L
  # Renumber labels sequentially 
  lab <- as.integer(factor(lab))
  # Convert labels to factor
  lab <- factor(lab)
  # Apply to points
  Y <- X %mark% lab
  return(Y)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/covariates.R"
#
# covariates.R
#
# evaluate covariates
#
#   $Revision: 1.2 $  $Date: 2013/04/25 06:37:43 $
#

evalCovariate <- function(covariate, locations) {
  # evaluate covariate of any kind at specified locations
  covvalues <-
    if(is.im(covariate)) 
      safelookup(covariate, locations)
    else if(is.function(covariate)) 
      covariate(locations$x, locations$y)
    else if(is.numeric(covariate) || is.factor(covariate)) {
      if(length(covariate) == 1)
        rep.int(covariate, length(locations$x))
      else if(length(covariate) == length(locations$x))
        covariate
      else stop("Inappropriate length for covariate vector")
    } else
  stop("Covariate should be an image, a function or a factor/numeric vector")
  return(covvalues)
}

ppmCovariates <- function(model) {
  # generate list of all covariates in ppm (excluding marks)
  stopifnot(is.ppm(model))
  co <- as.list(model$covariates)
  xy <- list(x=function(x,y){x}, y=function(x,y){y})
  coplus <- append(co, xy)
  return(as.listof(coplus))
}

findCovariate <- function(covname, scope, scopename=NULL) {
  # find the named covariate in the given ppm object or list
  if(is.ppm(scope)) {
    covlist <- ppmCovariates(scope)
    if(missing(scopename)) scopename <- "covariates in model"
  } else if(is.list(scope)) {
    covlist <- scope
  } else stop("scope should be a named list of covariates, or a ppm object")
  if(!(covname %in% names(covlist))) 
    stop(paste("covariate", dQuote(covname), "not found",
               if(!is.null(scopename)) paste("amongst", scopename) else NULL))
  covlist[[covname]]
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/crossdistlpp.R"
#
# crossdistlpp.R
#
#  $Revision: 1.4 $ $Date: 2014/10/24 00:22:30 $
#
#  crossdist.lpp
#        Calculates the shortest-path distance from each point of X
#        to each point of Y, where X and Y are point patterns
#        on the same linear network.
#

crossdist.lpp <- function(X, Y, ..., method="C") {
  stopifnot(inherits(X, "lpp"))
  stopifnot(method %in% c("C", "interpreted"))
  check <- resolve.defaults(list(...), list(check=TRUE))$check
  #
  nX <- npoints(X)
  nY <- npoints(Y)
  #
  L <- as.linnet(X)
  if(check) {
    LY <- as.linnet(Y)
    if(!identical(L, LY))
      stop("X and Y are on different linear networks")
  }
  
  P <- as.ppp(X)
  Q <- as.ppp(Y)
  #
#  Lseg  <- L$lines
  Lvert <- L$vertices
  from  <- L$from
  to    <- L$to
  dpath <- L$dpath
  
  # nearest segment for each point
  Xpro <- coords(X, local=TRUE, spatial=FALSE, temporal=FALSE)$seg
  Ypro <- coords(Y, local=TRUE, spatial=FALSE, temporal=FALSE)$seg

  crossdistmat <- matrix(0,nX,nY)

  if(method == "interpreted") {
    # loop through all pairs of data points
    for (i in 1:nX) {
      Xproi <- Xpro[i]
      Xi <- P[i]
      nbi1 <- from[Xproi]
      nbi2 <- to[Xproi]
      vi1 <- Lvert[nbi1]
      vi2 <- Lvert[nbi2]   
      dXi1 <- crossdist(Xi, vi1)
      dXi2 <- crossdist(Xi, vi2)
      for (j in 1:nY) {
        Yj <- Q[j]
        Yproj <- Ypro[j]
        if(Xproi == Yproj) {
          # points i and j lie on the same segment
          # use Euclidean distance
          d <- crossdist(Xi, Yj)
        } else {
          # shortest path from i to j passes through ends of segments
          nbj1 <- from[Yproj]
          nbj2 <- to[Yproj]
          vj1 <- Lvert[nbj1]
          vj2 <- Lvert[nbj2]
          # Calculate shortest of 4 possible paths from i to j
          d1Yj <- crossdist(vj1,Yj)
          d2Yj <- crossdist(vj2,Yj)
          d11 <- dXi1 + dpath[nbi1,nbj1] + d1Yj
          d12 <- dXi1 + dpath[nbi1,nbj2] + d2Yj
          d21 <- dXi2 + dpath[nbi2,nbj1] + d1Yj
          d22 <- dXi2 + dpath[nbi2,nbj2] + d2Yj
          d <- min(d11,d12,d21,d22)
        }
        # store result
        crossdistmat[i,j] <- d
      }
    }
  } else {
    # C code
    # convert indices to start at 0
    from0 <- from - 1L
    to0   <- to - 1L
    Xsegmap <- Xpro - 1L
    Ysegmap <- Ypro - 1L
    zz <- .C("lincrossdist",
             np = as.integer(nX),
             xp = as.double(P$x),
             yp = as.double(P$y),
             nq = as.integer(nY),
             xq = as.double(Q$x),
             yq = as.double(Q$y),
             nv = as.integer(Lvert$n),
             xv = as.double(Lvert$x),
             yv = as.double(Lvert$y),
             ns = as.double(L$n),
             from = as.integer(from0),
             to = as.integer(to0),
             dpath = as.double(dpath),
             psegmap = as.integer(Xsegmap),
             qsegmap = as.integer(Ysegmap),
             answer = as.double(crossdistmat))
    crossdistmat <- matrix(zz$answer, nX, nY)
  }
  return(crossdistmat)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/cut.ppp.R"
#
#  cut.ppp.R
#
#  cut method for ppp objects
#
#  $Revision: 1.14 $   $Date: 2014/10/24 00:22:30 $
#

cut.ppp <- function(x, z=marks(x), ...) {
  x <- as.ppp(x)
  if(missing(z) || is.null(z)) {
    z <- marks(x, dfok=TRUE)
    if(is.null(z))
      stop("x has no marks to cut")
  }
  if(is.character(z)) {
    if(length(z) == npoints(x)) {
      # interpret as a factor
      z <- factor(z)
    } else if((length(z) == 1) && (z %in% colnames(marks(x)))) {
      # interpret as the name of a column of marks
      zname <- z
      m <- marks(x)
      z <- m[, zname]
    } else stop("format of argument z not understood") 
  }
  if(is.factor(z) || is.vector(z)) {
    stopifnot(length(z) == npoints(x))
    g <- if(is.factor(z)) z else if(is.numeric(z)) cut(z, ...) else factor(z)
    marks(x) <- g
    return(x)
  }
  if(is.data.frame(z) || is.matrix(z)) {
    stopifnot(nrow(z) == npoints(x))
    # take first column 
    z <- z[,1]
    g <- if(is.numeric(z)) cut(z, ...) else factor(z)
    marks(x) <- g
    return(x)
  }
  if(is.im(z)) 
    return(cut(x, z[x, drop=FALSE], ...))

  if(is.owin(z)) {
    marks(x) <- factor(inside.owin(x$x, x$y, z), levels=c(FALSE, TRUE))
    return(x)
  }
  
  if(is.tess(z)) {
    marks(x) <- tileindex(x$x, x$y, z)
    return(x)
  }

  stop("Format of z not understood")
} 

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/datasetup.R"
#
#   When the package is installed, this tells us 
#   the directory where the .tab files are stored
#
#   Typically data/murgatroyd.R reads data-raw/murgatroyd.tab
#   and applies special processing
#
spatstat.rawdata.location <- function(...) {
    locn <- system.file("data-raw", package="spatstat")
    if(length(list(...)) != 0) 
      locn <- paste(c(locn, ...), collapse=.Platform$file.sep)
    return(locn)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/dclftest.R"
#
#  dclftest.R
#
#  $Revision: 1.24 $  $Date: 2014/08/20 10:39:43 $
#
#  Monte Carlo tests for CSR (etc)
#

clf.test <- function(...) {
 .Deprecated("dclf.test", package="spatstat")
 dclf.test(...)
}

dclf.test <- function(X, ...,
                      alternative=c("two.sided", "less", "greater"),
                      rinterval=NULL, use.theo=FALSE) {
  Xname <- short.deparse(substitute(X))
  envelopeTest(X, ..., power=2, alternative=alternative,
                       use.theo=use.theo, rinterval=rinterval, Xname=Xname)
}

mad.test <- function(X, ...,
                     alternative=c("two.sided", "less", "greater"),
                     rinterval=NULL, use.theo=FALSE) {
  Xname <- short.deparse(substitute(X))
  envelopeTest(X, ..., power=Inf, alternative=alternative,
               use.theo=use.theo, rinterval=rinterval, Xname=Xname)
}

envelopeTest <- local({

  plusvalue <- function(x) {
    d <- dim(x)
    y <- pmax(0, x)
    if(!is.null(d)) y <- matrix(y, d[1], d[2])
    return(y)
  }

  envelopeTest <-
    function(X, ...,
             power=1,
             alternative=c("two.sided", "less", "greater"),
             rinterval=NULL,
             use.theo=FALSE,
             tie.rule=c("randomise","mean"),
             save.envelope = savefuns || savepatterns,
             savefuns = FALSE, 
             savepatterns = FALSE, 
             Xname=NULL,
             verbose=TRUE,
             internal=NULL) {
      if(is.null(Xname)) Xname <- short.deparse(substitute(X))
      tie.rule <- match.arg(tie.rule)
      alternative <- match.arg(alternative)
      force(save.envelope)
      check.1.real(power)
      explain.ifnot(power >= 0)
      if(use.theo) {
        ## using theoretical function as reference.
        ## ensure resulting envelope object includes theoretical function.
        internal <- resolve.defaults(internal, list(csr=TRUE))
      }
      ## case where X is a previous result of dclf.test, etc
      if(inherits(X, "htest")) {
        if(is.null(envX <- attr(X, "envelope")))
          stop(paste(Xname, "does not contain simulation data"))
        X <- envX
      }
      ## compute or extract simulated functions
      X <- envelope(X, ...,
                    savefuns=TRUE, savepatterns=savepatterns,
                    Yname=Xname, internal=internal, verbose=verbose)
      Y <- attr(X, "simfuns")
      ## extract values
      r   <- with(X, .x)
      obs <- with(X, .y)
      sim <- as.matrix(as.data.frame(Y))[, -1]
      nsim <- ncol(sim)
      nr <- length(r)
      ## choose function as reference
      has.theo <- ("theo" %in% names(X))
      if(use.theo && !has.theo)
        warning("No theoretical function available; use.theo ignored")
      if(use.theo && has.theo) {
        reference <- with(X, theo)
        used.theo <- TRUE
      } else {
        ## compute sample mean of simulations *and* observed 
        reference <- apply(cbind(sim, obs), 1, mean, na.rm=TRUE)
        used.theo <- FALSE
      }
      ## determine interval of r values for computation
      if(!is.null(rinterval)) {
        check.range(rinterval)
        if(max(r) < rinterval[2]) {
          oldrinterval <- rinterval
          rinterval <- intersect.ranges(rinterval, range(r), fatal=FALSE)
          if(is.null(rinterval))
            stop(paste("The specified rinterval",
                       prange(oldrinterval),
                       "has empty intersection",
                       "with the range of r values",
                       prange(range(r)), 
                       "computed by the summary function"),
                 call.=FALSE)
          if(verbose)
            warning(paste("The interval", prange(oldrinterval),
                          "is too large for the available data;",
                          "it has been trimmed to", prange(rinterval)))
        }
        ok <- (rinterval[1] <= r & r <= rinterval[2])
        nr <- sum(ok)
        if(nr == 0) {
          ## rinterval is very short: pick nearest r value
          ok <- which.min(abs(r - mean(rinterval)))
          nr <- 1
        }
        obs <- obs[ok]
        sim <- sim[ok, , drop=FALSE]
        reference <- reference[ok]
      } else {
        rinterval <- range(r)
        bad <- !apply(is.finite(as.matrix(X)), 1, all)
        if(any(bad)) {
          if(bad[1] && !any(bad[-1])) {
            ## ditch r = 0
            rinterval <- c(r[2], max(r))
            if(verbose)
              warning(paste("Some function values were infinite or NaN",
                            "at distance r = 0;",
                            "interval of r values was reset to",
                            prange(rinterval)))
            ok <- (rinterval[1] <= r & r <= rinterval[2])
            obs <- obs[ok]
            sim <- sim[ok, ]
            reference <- reference[ok]
            nr <- sum(ok)
          } else {
            ## problem
            rbadmax <- paste(max(r[bad]), summary(unitname(X))$plural)
            stop(paste("Some function values were infinite or NaN",
                       "at distances r up to",
                       paste(rbadmax, ".", sep=""),
                       "Please specify a shorter", sQuote("rinterval")))
          }
        } 
      }

      deviant <- switch(alternative,
                        two.sided = function(x) abs(x),
                        less = function(x) plusvalue(-x),
                        greater = plusvalue)

      ## compute test statistic
      if(is.infinite(power)) {
        ## MAD
        devdata <- max(deviant(obs-reference))
        names(devdata) <- "mad"
        devsim <- apply(deviant(sim-reference), 2, max)
        testname <- "Maximum absolute deviation test"
      } else {
        L <- if(nr > 1) diff(rinterval) else 1
        a <- L * (if(used.theo) 1 else ((nsim+1)/nsim)^power)
        if(power == 2) {
          ## Cramer-von Mises
          devdata <- a * mean((deviant(obs - reference))^2)
          names(devdata) <- "u"
          devsim <- a * .colMeans((deviant(sim - reference))^2, nr, nsim)
          testname <- "Diggle-Cressie-Loosmore-Ford test"
        } else if(power == 1) {
          ## integral absolute deviation
          devdata <- a * mean(deviant(obs - reference))
          names(devdata) <- "L1"
          devsim <- a * .colMeans(deviant(sim - reference), nr, nsim)
          testname <- "Integral absolute deviation test"
        } else {
          ## general p
          devdata <- a * mean(((deviant(obs - reference))^power))
          names(devdata) <- "Lp"
          devsim <- a * .colMeans(((deviant(sim - reference))^power), nr, nsim)
          testname <- paste("Integrated",
                            ordinal(power), "Power Deviation test")
        }
      }
      ## compute rank and p-value
      datarank <- sum(devdata < devsim) + 1
      nties <- sum(devdata == devsim)
      if(nties > 0) {
        tierank <- switch(tie.rule,
                          mean = nties/2,
                          randomise = sample(1:nties, 1))
        datarank <- datarank + tierank
        if(verbose) message("Ties were encountered")
      }
      pvalue <- datarank/(nsim+1)
      ## bookkeeping
      statistic <- data.frame(devdata, rank=datarank)
      colnames(statistic)[1] <- names(devdata)
      e <- attr(X, "einfo")
      nullmodel <-
        if(identical(e$csr, TRUE)) "CSR" else 
      if(!is.null(e$simtype)) {
        switch(e$simtype,
               csr = "CSR",
               rmh = paste("fitted",
                 if(identical(e$pois, TRUE)) "Poisson" else "Gibbs",
                 "model"),
               kppm = "fitted cluster model",
               expr = "model simulated by evaluating expression",
               list = "model simulated by drawing patterns from a list",
               "unrecognised model")
      } else "unrecognised model"
      fname <- deparse(attr(X, "ylab"))
      uname <- with(summary(unitname(X)),
                    if(!vanilla) paste(plural, explain) else NULL)
      testname <- c(paste(testname, "of", nullmodel),
                    paste("Monte Carlo test based on", nsim,
                          "simulations", e$constraints), 
                    paste("Summary function:", fname),
                    paste("Reference function:",
                          if(used.theo) "theoretical" else "sample mean"),
                    paste("Alternative:", alternative),
                    paste("Interval of distance values:",
                          prange(rinterval), uname)
                    )
      result <- structure(list(statistic = statistic,
                               p.value = pvalue,
                               method = testname,
                               data.name = e$Yname),
                          class="htest")
      attr(result, "rinterval") <- rinterval
      if(save.envelope) {
        attr(result, "envelope") <- X
        attr(result, "statistics") <- list(data=devdata, sim=devsim)
        attr(result, "info") <- list(power=power,
                                     alternative=alternative,
                                     nties=nties,
                                     tie.rule=tie.rule,
                                     use.theo=use.theo)
      }
      return(result)
    }

  envelopeTest
})



    
   
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/defaultwin.R"
#
#
#  defaultwin.R
#
#   $Revision: 1.9 $   $Date: 2012/05/11 11:20:09 $
#

default.expand <- function(object, m=2, epsilon=1e-6) {
  stopifnot(is.ppm(object) || inherits(object, "rmhmodel"))
  # no expansion necessary if model is Poisson
  if(is.poisson(object))
    return(.no.expansion)
  # default is no expansion if model is nonstationary
  if(!is.stationary(object))
    return(.no.expansion)
  
# Redundant since a non-expandable model is non-stationary
#  if(!is.expandable(object))
#    return(.no.expansion)
  
  # rule is to expand data window by distance d = m * reach
  rr <- reach(object, epsilon=epsilon)
  if(!is.finite(rr))
    return(rmhexpand())
  if(!is.numeric(m) || length(m) != 1 || m < 1)
    stop("m should be a single number >= 1")
  mr <- m * rr
  rule <- rmhexpand(distance = mr)
  # 
  w <- as.owin(object)
  if(!is.null(w)) {
    # apply rule to window
    wplus <- expand.owin(w, rule)
    # save as new expansion rule
    rule <- rmhexpand(wplus)
  }
  return(rule)
}

default.clipwindow <- function(object, epsilon=1e-6) {
  stopifnot(is.ppm(object) || inherits(object, "rmhmodel"))
  # data window
  w <- as.owin(object)
  if(is.null(w)) return(NULL)
  # interaction range of model
  rr <- reach(object, epsilon=epsilon)
  if(!is.finite(rr))
    return(NULL)
  if(rr == 0)
    return(w)
  else
    return(erosion(w, rr))
}

  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/deldir.R"
#
# deldir.R
#
# Interface to deldir package
#
#  $Revision: 1.20 $ $Date: 2014/10/24 00:22:30 $
#

.spst.triEnv <- new.env()

assign("use.trigraf",  TRUE, envir=.spst.triEnv)
assign("use.trigrafS", TRUE, envir=.spst.triEnv)
assign("debug.delaunay", FALSE, envir=.spst.triEnv)

dirichlet <- function(X) {
  stopifnot(is.ppp(X))
  X <- unique(X, rule="deldir", warn=TRUE)
  w <- X$window
  dd <- safedeldir(X)
  if(is.null(dd)) return(NULL)
  pp <- lapply(tile.list(dd), function(z) { owin(poly=z[c("x","y")]) })
  if(length(pp) == npoints(X))
    names(pp) <- seq_len(npoints(X))
  dir <- tess(tiles=pp, window=as.rectangle(w))
  if(w$type != "rectangle")
    dir <- intersect.tess(dir, w)
  return(dir)
}

delaunay <- function(X) {
  stopifnot(is.ppp(X))
  X <- unique(X, rule="deldir", warn=TRUE)
  nX <- npoints(X)
  if(nX < 3) return(NULL)
  w <- X$window
  dd <- safedeldir(X)
  if(is.null(dd)) return(NULL)
  a <- dd$delsgs[,5]
  b <- dd$delsgs[,6]
  use.trigraf  <- get("use.trigraf", envir=.spst.triEnv)
  use.trigrafS <- get("use.trigrafS", envir=.spst.triEnv)
  debug.delaunay <- get("debug.delaunay", envir=.spst.triEnv)
  if(use.trigrafS) {
    # first ensure a[] < b[]
    swap <- (a > b)
    if(any(swap)) {
      oldb <- b
      b[swap] <- a[swap]
      a[swap] <- oldb[swap]
    }
    # next ensure a is sorted
    o <- order(a, b)
    a <- a[o]
    b <- b[o]
    # 
    nv <- nX
    ne <- length(a)
    ntmax <- ne
    z <- .C("trigrafS",
            nv = as.integer(nv),
            ne = as.integer(ne),
            ie = as.integer(a),
            je = as.integer(b),
            ntmax = as.integer(ntmax),
            nt = as.integer(integer(1)),
            it = as.integer(integer(ne)),
            jt = as.integer(integer(ne)),
            kt = as.integer(integer(ne)),
            status = as.integer(integer(1)))
    if(z$status != 0)
      stop("Internal error: overflow in trigrafS")
    tlist <- with(z, cbind(it, jt, kt)[1:nt, ])
  } else if(use.trigraf) {
    nv <- nX
    ne <- length(a)
    ntmax <- ne
    z <- .C("trigraf",
            nv = as.integer(nv),
            ne = as.integer(ne),
            ie = as.integer(a),
            je = as.integer(b),
            ntmax = as.integer(ntmax),
            nt = as.integer(integer(1)),
            it = as.integer(integer(ntmax)),
            jt = as.integer(integer(ntmax)),
            kt = as.integer(integer(ntmax)),
            status = as.integer(integer(1)))
    if(z$status != 0)
      stop("Internal error: overflow in trigraf")
    tlist <- with(z, cbind(it, jt, kt)[1:nt, ])
  } else {
    tlist <- matrix(integer(0), 0, 3)
    for(i in seq_len(nX)) {
      # find all Delaunay neighbours of i 
      jj <- c(b[a==i], a[b==i])
      jj <- sort(unique(jj))
      # select those with a higher index than i
      jj <- jj[jj > i]
      # find pairs of neighbours which are Delaunay neighbours
      # (thus, triangles where the first numbered vertex is i)
      if(length(jj) > 0) 
        for(j in jj) {
          kk <- c(b[a == j], a[b == j])
          kk <- kk[(kk %in% jj) & (kk > j)]
          if(length(kk) > 0)
            for(k in kk) 
              # add (i,j,k) to list of triangles (i < j < k)
              tlist <- rbind(tlist, c(i, j, k))
        }
    }
  }
  # At this point, `tlist' contains all triangles formed by the Delaunay edges,
  # with vertices given in ascending order i < j < k in the 3 columns of tlist.
  # Some of these triangles may not belong to the Delaunay triangulation.
  # They will be weeded out later.
  
  # Assemble coordinates of triangles
  x <- X$x
  y <- X$y
  xtri <- matrix(x[tlist], nrow(tlist), 3)
  ytri <- matrix(y[tlist], nrow(tlist), 3)
  # ensure triangle vertices are in anticlockwise order
  ztri <- ytri - min(y)
  dx <- cbind(xtri[,2]-xtri[,1], xtri[,3]-xtri[,2], xtri[,1]-xtri[,3])
  zm <- cbind(ztri[,1]+ztri[,2], ztri[,2]+ztri[,3], ztri[,3]+ztri[,1])
  negareas <- apply(dx * zm, 1, sum)
  clockwise <- (negareas > 0)
  #
  if(any(clockwise)) {
    xc <- xtri[clockwise, , drop=FALSE]
    yc <- ytri[clockwise, , drop=FALSE]
    tc <- tlist[clockwise, , drop=FALSE]
    xtri[clockwise,]  <- xc[,c(1,3,2)]
    ytri[clockwise,]  <- yc[,c(1,3,2)]
    tlist[clockwise,] <- tc[, c(1,3,2)]
  }
  # At this point, triangle vertices are listed in anticlockwise order.
  # The same directed edge (i, j) cannot appear twice.
  # To weed out invalid triangles, check for such duplication
  triedges <- rbind(tlist[, c(1,2)],
                    tlist[, c(2,3)],
                    tlist[, c(3,1)])
  if(any(bad <- duplicated(triedges))) {
    badedges <- unique(triedges[bad, , drop=FALSE])
    ntri <- nrow(tlist)
    triid <- rep.int(seq_len(ntri), 3)
    illegal <- rep.int(FALSE, ntri)
    for(j in seq_len(nrow(badedges))) {
      from <- badedges[j, 1]
      to   <- badedges[j, 2]
      if(debug.delaunay)
        cat(paste("Suspect edge from vertex", from, "to vertex", to, "\n"))
      # find all triangles sharing this edge in this orientation
      sustri <- triid[(triedges[,1] == from) & (triedges[,2] == to)]
      if(debug.delaunay)
        cat(paste("\tInvestigating triangles", commasep(sustri), "\n"))
      # list all vertices associated with the suspect triangles
      susvert <- sort(unique(as.vector(tlist[sustri, ])))
      if(debug.delaunay)
        cat(paste("\tInvestigating vertices", commasep(susvert), "\n"))
      xsusvert <- x[susvert]
      ysusvert <- y[susvert]
      # take each triangle in turn and check whether it contains a data point
      for(k in sustri) {
        if(!illegal[k] &&
           any(inside.triangle(xsusvert, ysusvert, xtri[k,], ytri[k,]))) {
          if(debug.delaunay)
            cat(paste("Triangle", k, "is illegal\n"))
          illegal[k] <- TRUE
        }
      }
    }
    if(!any(illegal)) {
      if(debug.delaunay)
        cat("No illegal triangles found\n")
    } else {
      if(debug.delaunay)
        cat(paste("Removing", sum(illegal), "triangles\n"))
      tlist <- tlist[!illegal, , drop=FALSE]
      xtri  <- xtri[!illegal, , drop=FALSE]
      ytri  <- ytri[!illegal, , drop=FALSE]
    }
  }
  # make tile list
  tiles <- list()
  for(m in seq_len(nrow(tlist))) {
    p <- list(x=xtri[m,], y=ytri[m,])
    tiles[[m]] <- owin(poly=p, check=FALSE)
  }

  wc <- convexhull.xy(x, y)
  del <- tess(tiles=tiles, window=wc)
  if(w$type != "rectangle")
    del <- intersect.tess(del, w)
  return(del)
}

delaunay.distance <- function(X) {
  stopifnot(is.ppp(X))
  nX <- npoints(X)
  w <- as.owin(X)
  ok <- !duplicated(X, rule="deldir")
  Y <- X[ok] 
  nY <- npoints(Y)
  if(nY < 3) 
    return(matrix(Inf, nX, nX))
  dd <- deldir(Y$x, Y$y, rw=c(w$xrange,w$yrange))
  if(is.null(dd)) return(NULL)
  joins <- as.matrix(dd$delsgs[,5:6])
  joins <- rbind(joins, joins[,2:1])
  d <- matrix(-1L, nY, nY)
  diag(d) <- 0
  d[joins] <- 1
  adj <- matrix(FALSE, nY, nY)
  diag(adj) <- TRUE
  adj[joins] <- TRUE
  z <- .C("Idist2dpath",
          nv = as.integer(nY),
          d = as.integer(d), 
          adj = as.integer(adj),
          dpath = as.integer(integer(nY * nY)),
          tol = as.integer(0),
          niter = as.integer(integer(1)), 
          status = as.integer(integer(1)))
  if (z$status == -1)
    warning(paste("graph connectivity algorithm did not converge after", 
                  z$niter, "iterations", "on", nY, "vertices and", 
                  sum(adj) - nY, "edges"))
  dpathY <- matrix(z$dpath, nY, nY)
  if(all(ok)) {
    dpathX <- dpathY
  } else {
    dpathX <- matrix(NA_integer_, nX, nX)
    dpathX[ok, ok] <- dpathY
  }
  return(dpathX)
}

safedeldir <- function(X) {
  rw <- with(X$window, c(xrange,yrange))
  dd <- try(deldir(X$x, X$y, rw=rw))
  if(!inherits(dd, "try-error") && inherits(dd, "deldir"))
    return(dd)
  warning("deldir failed; re-trying with slight perturbation of coordinates.",
          call.=FALSE)
  Y <- rjitter(X, mean(nndist(X))/100)
  dd <- try(deldir(Y$x, Y$y, rw=rw))
  if(!inherits(dd, "try-error") && inherits(dd, "deldir"))
    return(dd)
  warning("deldir failed even after perturbation of coordinates.", call.=FALSE)
  return(NULL)
}

dirichlet.vertices <- function(X) {
  DT <- tiles(dirichlet(X))
  xy <- do.call(concatxy, lapply(DT, vertices))
  Y <- unique(ppp(xy$x, xy$y, window=Window(X), check=FALSE))
  b <- bdist.points(Y)
  thresh <- diameter(Frame(X))/1000
  Y <- Y[b > thresh]
  return(Y)
}
    
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/deltametric.R"
#
#   deltametric.R
#
#   Delta metric
#
#   $Revision: 1.4 $  $Date: 2014/10/24 00:22:30 $
#

deltametric <- function(A, B, p=2, c=Inf, ...) {
  stopifnot(is.numeric(p) && length(p) == 1 && p > 0)
  # ensure frames are identical
  bb <- boundingbox(as.rectangle(A), as.rectangle(B))
  # enforce identical frames
  A <- rebound(A, bb)
  B <- rebound(B, bb)
  # compute distance functions
  dA <- distmap(A, ...)
  dB <- distmap(B, ...)
  if(!is.infinite(c)) {
    dA <- eval.im(pmin.int(dA, c))
    dB <- eval.im(pmin.int(dB, c))
  }
  if(is.infinite(p)) {
    # L^infinity
    Z <- eval.im(abs(dA-dB))
    delta <- summary(Z)$max
  } else {
    # L^p
    Z <- eval.im(abs(dA-dB)^p)
    iZ <- summary(Z)$mean
    delta <- iZ^(1/p)
  }
  return(delta)
}





#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/density.ppp.R"
#
#  density.ppp.R
#
#  Method for 'density' for point patterns
#
#  $Revision: 1.70 $    $Date: 2014/10/24 00:22:30 $
#

ksmooth.ppp <- function(x, sigma, ..., edge=TRUE) {
  .Deprecated("density.ppp", package="spatstat")
  density.ppp(x, sigma, ..., edge=edge)
}

density.ppp <- local({
  
density.ppp <- function(x, sigma=NULL, ...,
                        weights=NULL, edge=TRUE, varcov=NULL,
                        at="pixels", leaveoneout=TRUE,
                        adjust=1, diggle=FALSE) {
  verifyclass(x, "ppp")

  output <- pickoption("output location type", at,
                       c(pixels="pixels",
                         points="points"))
  
  ker <- resolve.2D.kernel(..., sigma=sigma, varcov=varcov, x=x, adjust=adjust)
  sigma <- ker$sigma
  varcov <- ker$varcov

  if(is.expression(weights)) 
    weights <- eval(weights, envir=as.data.frame(x), enclos=parent.frame())
  if(length(weights) == 0 || (!is.null(dim(weights)) && nrow(weights) == 0))
    weights <- NULL 

  if(output == "points") {
    # VALUES AT DATA POINTS ONLY
    result <- densitypointsEngine(x, sigma, varcov=varcov,
                                  weights=weights, edge=edge,
                                  leaveoneout=leaveoneout,
                                  diggle=diggle, ...)
    if(!is.null(uhoh <- attr(result, "warnings"))) {
      switch(uhoh,
             underflow=warning("underflow due to very small bandwidth"),
             warning(uhoh))
    }
    return(result)
  }
  
  # VALUES AT PIXELS
  if(!edge) {
    # no edge correction
    edg <- NULL
    raw <- second.moment.calc(x, sigma, what="smooth", ...,
                              weights=weights, varcov=varcov)
    raw <- divide.by.pixelarea(raw) 
    smo <- raw
  } else if(!diggle) {
    # edge correction e(u)
    both <- second.moment.calc(x, sigma, what="smoothedge", ...,
                              weights=weights, varcov=varcov)
    raw <- divide.by.pixelarea(both$smooth)
    edg <- both$edge
    smo <- if(is.im(raw)) eval.im(raw/edg) else
           lapply(raw, function(a,b) eval.im(a/b), b=edg)
  } else {
    # edge correction e(x_i)
    edg <- second.moment.calc(x, sigma, what="edge", ..., varcov=varcov)
    wi <- 1/safelookup(edg, x, warn=FALSE)
    wi[!is.finite(wi)] <- 0
    # edge correction becomes weight attached to points
    if(is.null(weights)) {
      newweights <- wi
    } else if(is.matrix(weights) || is.data.frame(weights)) {
      stopifnot(nrow(weights) == npoints(x))
      newweights <- weights * wi
    } else {
      stopifnot(length(weights) == npoints(x))
      newweights <- weights * wi
    }
    raw <- second.moment.calc(x, sigma, what="smooth", ...,
                              weights=newweights, varcov=varcov)
    raw <- divide.by.pixelarea(raw)
    smo <- raw
  }

  result <- if(is.im(smo)) smo[x$window, drop=FALSE]
            else as.listof(lapply(smo, "[", i=x$window, drop=FALSE))

  # internal use only
  spill <- resolve.1.default(list(spill=FALSE), list(...))
  if(spill)
    return(list(result=result, sigma=sigma, varcov=varcov, raw = raw, edg=edg))

  # normal return
  attr(result, "sigma") <- sigma
  attr(result, "varcov") <- varcov
  return(result)
}

divide.by.pixelarea <- function(x) {
  if(is.im(x)) {
    x$v <- x$v/(x$xstep * x$ystep)
  } else {
    for(i in seq_along(x))
      x[[i]]$v <- with(x[[i]], v/(xstep * ystep))
  }
  return(x)
}

density.ppp

})

densitypointsEngine <- function(x, sigma, ...,
                                weights=NULL, edge=TRUE, varcov=NULL,
                                leaveoneout=TRUE, diggle=FALSE,
                                sorted=FALSE, spill=FALSE) {
  if(is.null(varcov)) {
    const <- 1/(2 * pi * sigma^2)
  } else {
    detSigma <- det(varcov)
    Sinv <- solve(varcov)
    const <- 1/(2 * pi * sqrt(detSigma))
  }
  if(length(weights) == 0 || (!is.null(dim(weights)) && nrow(weights) == 0))
    weights <- NULL
  # Leave-one-out computation
  # cutoff: contributions from pairs of distinct points
  # closer than 8 standard deviations
  sd <- if(is.null(varcov)) sigma else sqrt(sum(diag(varcov)))
  cutoff <- 8 * sd
#  nnd <- nndist(x)
#  nnrange <- range(nnd)
#  if(nnrange[1] > cutoff) {
#    npts <- npoints(x)
#    result <- if(leaveoneout) numeric(npts) else rep.int(const, npts)
#    attr(result, "sigma") <- sigma
#    attr(result, "varcov") <- varcov
#    attr(result, "warnings") <- "underflow"
#    return(result)
#  }
  if(leaveoneout) {
    # ensure each point has its closest neighbours within the cutoff
    nndmax <- maxnndist(x)
    cutoff <- max(2 * nndmax, cutoff)
  }
  # validate weights
  if(is.null(weights)) {
    k <- 1
  } else if(is.matrix(weights) || is.data.frame(weights)) {
    k <- ncol(weights)
    stopifnot(nrow(weights) == npoints(x))
    weights <- as.data.frame(weights)
    weightnames <- colnames(weights)
  } else {
    k <- 1
    stopifnot(length(weights) == npoints(x) || length(weights) == 1)
  }
  # evaluate edge correction weights at points 
  if(edge) {
    win <- x$window
    if(is.null(varcov) && win$type == "rectangle") {
      # evaluate Gaussian probabilities directly
      xr <- win$xrange
      yr <- win$yrange
      xx <- x$x
      yy <- x$y
      xprob <-
        pnorm(xr[2], mean=xx, sd=sigma) - pnorm(xr[1], mean=xx, sd=sigma)
      yprob <-
        pnorm(yr[2], mean=yy, sd=sigma) - pnorm(yr[1], mean=yy, sd=sigma)
      edgeweight <- xprob * yprob
    } else {
      edg <- second.moment.calc(x, sigma=sigma, what="edge", varcov=varcov)
      edgeweight <- safelookup(edg, x, warn=FALSE)
    }
    if(diggle) {
      # Diggle edge correction
      # edgeweight is attached to each point
      if(is.null(weights)) {
        k <- 1
        weights <- 1/edgeweight
      } else {
        weights <- weights/edgeweight
      }
    }
  }
  
  if(spatstat.options("densityC") || k > 1) {
    # .................. new C code ...........................
    npts <- npoints(x)
    result <- if(k == 1) numeric(npts) else matrix(, npts, k)
    # sort into increasing order of x coordinate (required by C code)
    if(sorted) {
      xx <- x$x
      yy <- x$y
    } else {
      oo <- fave.order(x$x)
      xx <- x$x[oo]
      yy <- x$y[oo]
    }
    if(is.null(varcov)) {
      # isotropic kernel
      if(is.null(weights)) {
        zz <- .C("denspt",
                 nxy     = as.integer(npts),
                 x       = as.double(xx),
                 y       = as.double(yy),
                 rmaxi   = as.double(cutoff),
                 sig     = as.double(sd),
                 result  = as.double(double(npts)))
        if(sorted) result <- zz$result else result[oo] <- zz$result 
      } else if(k == 1) {
        wtsort <- if(sorted) weights else weights[oo]
        zz <- .C("wtdenspt",
                 nxy     = as.integer(npts),
                 x       = as.double(xx),
                 y       = as.double(yy),
                 rmaxi   = as.double(cutoff),
                 sig     = as.double(sd),
                 weight  = as.double(wtsort),
                 result  = as.double(double(npts)))
        if(sorted) result <- zz$result else result[oo] <- zz$result 
       } else {
        # matrix of weights
        wtsort <- if(sorted) weights else weights[oo, ]
        for(j in 1:k) {
          zz <- .C("wtdenspt",
                   nxy     = as.integer(npts),
                   x       = as.double(xx),
                   y       = as.double(yy),
                   rmaxi   = as.double(cutoff),
                   sig     = as.double(sd),
                   weight  = as.double(wtsort[,j]),
                   result  = as.double(double(npts)))
          if(sorted) result[,j] <- zz$result else result[oo,j] <- zz$result
        }
      }
    } else {
      # anisotropic kernel
      flatSinv <- as.vector(t(Sinv))
      if(is.null(weights)) {
        zz <- .C("adenspt",
                 nxy     = as.integer(npts),
                 x       = as.double(xx),
                 y       = as.double(yy),
                 rmaxi   = as.double(cutoff),
                 detsigma = as.double(detSigma),
                 sinv    = as.double(flatSinv),
                 result  = as.double(double(npts)))
        if(sorted) result <- zz$result else result[oo] <- zz$result 
      } else if(k == 1) {
        # vector of weights
        wtsort <- if(sorted) weights else weights[oo]
        zz <- .C("awtdenspt",
                 nxy     = as.integer(npts),
                 x       = as.double(xx),
                 y       = as.double(yy),
                 rmaxi   = as.double(cutoff),
                 detsigma = as.double(detSigma),
                 sinv    = as.double(flatSinv),
                 weight  = as.double(wtsort),
                 result   = as.double(double(npts)))
        if(sorted) result <- zz$result else result[oo] <- zz$result 
      } else {
        # matrix of weights
        wtsort <- if(sorted) weights else weights[oo, ]
        for(j in 1:k) {
          zz <- .C("awtdenspt",
                   nxy     = as.integer(npts),
                   x       = as.double(xx),
                   y       = as.double(yy),
                   rmaxi   = as.double(cutoff),
                   detsigma = as.double(detSigma),
                   sinv    = as.double(flatSinv),
                   weight  = as.double(wtsort[,j]),
                   result  = as.double(double(npts)))
          if(sorted) result[,j] <- zz$result else result[oo,j] <- zz$result 
        }
      }
    }
  } else {
      # ..... interpreted code .........................................
    close <- closepairs(x, cutoff)
    i <- close$i
    j <- close$j
    d <- close$d
    # evaluate contribution from each close pair (i,j)
    if(is.null(varcov)) {
      contrib <- const * exp(-d^2/(2 * sigma^2))
    } else {
      # anisotropic kernel
      dx <- close$dx
      dy <- close$dy
      contrib <- const * exp(-(dx * (dx * Sinv[1,1] + dy * Sinv[1,2])
                               + dy * (dx * Sinv[2,1] + dy * Sinv[2,2]))/2)
    }
    # multiply by weights
    if(!is.null(weights))
      contrib <- contrib * weights[j]
    # sum
    result <- tapply(contrib, factor(i, levels=1:(x$n)), sum)
    result[is.na(result)] <- 0
    #
  }
  # ----- contribution from point itself ----------------
  if(!leaveoneout) {
    # add contribution from point itself
    self <- const
    if(!is.null(weights))
      self <- self * weights
    result <- result + self
  }
  # ........  Edge correction ........................................
  if(edge && !diggle) 
    result <- result/edgeweight

  # ............. validate .................................
  npts <- npoints(x)
  if(k == 1) {
    result <- as.numeric(result)
    if(length(result) != npts) 
      stop(paste("Internal error: incorrect number of lambda values",
                 "in leave-one-out method:",
                 "length(lambda) = ", length(result),
                 "!=", npts, "= npoints"))
    if(any(is.na(result))) {
      nwrong <- sum(is.na(result))
      stop(paste("Internal error:", nwrong, "NA or NaN",
                 ngettext(nwrong, "value", "values"),
                 "generated in leave-one-out method"))
    }
  } else {
    if(ncol(result) != k)
      stop(paste("Internal error: incorrect number of columns returned:",
                 ncol(result), "!=", k))
    colnames(result) <- weightnames
    if(nrow(result) != npts) 
      stop(paste("Internal error: incorrect number of rows of lambda values",
                 "in leave-one-out method:",
                 "nrow(lambda) = ", nrow(result),
                 "!=", npts, "= npoints"))
    if(any(is.na(result))) {
      nwrong <- sum(!complete.cases(result))
      stop(paste("Internal error:", nwrong,
                 ngettext(nwrong, "row", "rows"),
                 "of NA values generated in leave-one-out method"))
    }
  }
  if(spill)
      return(list(result=result, sigma=sigma, varcov=varcov,
                  edg=edgeweight))
  # tack on bandwidth
  attr(result, "sigma") <- sigma
  attr(result, "varcov") <- varcov
  # 
  return(result)
}

resolve.2D.kernel <- function(..., sigma=NULL, varcov=NULL, x, mindist=NULL,
                              adjust=1, bwfun=NULL, allow.zero=FALSE) {
  if(is.function(sigma)) {
    bwfun <- sigma
    sigma <- NULL
  }
  if(is.null(sigma) && is.null(varcov) && !is.null(bwfun)) {
    # call bandwidth selection function
    bw <- do.call.matched(bwfun, resolve.defaults(list(X=x), list(...)))
    # interpret the result as either sigma or varcov
    if(!is.numeric(bw))
      stop("bandwidth selector returned a non-numeric result")
    if(length(bw) %in% c(1,2)) {
      sigma <- as.numeric(bw)
      if(!all(sigma > 0)) {
        gripe <- "bandwidth selector returned negative value(s)"
        if(allow.zero) warning(gripe) else stop(gripe)
      }
    } else if(is.matrix(bw) && nrow(bw) == 2 && ncol(bw) == 2) {
      varcov <- bw
      if(!all(eigen(varcov)$values > 0))
        stop("bandwidth selector returned matrix with negative eigenvalues")
    } else stop("bandwidth selector did not return a matrix or numeric value")
  }
  sigma.given <- !is.null(sigma)
  varcov.given <- !is.null(varcov)
  if(sigma.given) {
    stopifnot(is.numeric(sigma))
    stopifnot(length(sigma) %in% c(1,2))
    if(!allow.zero)
      stopifnot(all(sigma > 0))
  }
  if(varcov.given)
    stopifnot(is.matrix(varcov) && nrow(varcov) == 2 && ncol(varcov)==2 )
  # reconcile
  ngiven <- varcov.given + sigma.given
  switch(ngiven+1,
         {
           # default
           w <- x$window
           sigma <- (1/8) * shortside(as.rectangle(w))
         },
         {
           if(sigma.given && length(sigma) == 2) 
             varcov <- diag(sigma^2)
           if(!is.null(varcov))
             sigma <- NULL
         },
         {
           stop(paste("Give only one of the arguments",
                      sQuote("sigma"), "and", sQuote("varcov")))
         })
  # apply adjustments
  if(!is.null(sigma))  sigma <- adjust * sigma
  if(!is.null(varcov)) varcov <- (adjust^2) * varcov
  #
  sd <- if(is.null(varcov)) sigma else sqrt(sum(diag(varcov)))
  cutoff <- 8 * sd
  uhoh <- if(!is.null(mindist) && cutoff < mindist) "underflow" else NULL
  result <- list(sigma=sigma, varcov=varcov, cutoff=cutoff, warnings=uhoh)
  return(result)
}


densitycrossEngine <- function(Xdata, Xquery, sigma, ...,
                               weights=NULL, edge=TRUE, varcov=NULL,
                               diggle=FALSE,
                               sorted=FALSE) {
  if(is.null(varcov)) {
    const <- 1/(2 * pi * sigma^2)
  } else {
    detSigma <- det(varcov)
    Sinv <- solve(varcov)
    const <- 1/(2 * pi * sqrt(detSigma))
  }
  if(length(weights) == 0 || (!is.null(dim(weights)) && nrow(weights) == 0))
    weights <- NULL
  ## Leave-one-out computation
  ## cutoff: contributions from pairs of distinct points
  ## closer than 8 standard deviations
  sd <- if(is.null(varcov)) sigma else sqrt(sum(diag(varcov)))
  cutoff <- 8 * sd
  # validate weights
  if(is.null(weights)) {
    k <- 1
  } else if(is.matrix(weights) || is.data.frame(weights)) {
    k <- ncol(weights)
    stopifnot(nrow(weights) == npoints(Xdata))
    weights <- as.data.frame(weights)
    weightnames <- colnames(weights)
  } else {
    k <- 1
    stopifnot(length(weights) == npoints(Xdata) || length(weights) == 1)
  }
  # evaluate edge correction weights at points 
  if(edge) {
    win <- Xdata$window
    if(diggle) {
      ## edge correction weights are attached to data points
      xedge <- Xdata
    } else {
      ## edge correction weights are applied at query points
      xedge <- Xquery
      if(!all(inside.owin(Xquery, , win)))
        stop(paste("Edge correction is not possible:",
                   "some query points lie outside the data window"),
             call.=FALSE)
    }
    if(is.null(varcov) && win$type == "rectangle") {
        ## evaluate Gaussian probabilities directly
      xr <- win$xrange
      yr <- win$yrange
      xx <- xedge$x
      yy <- xedge$y
      xprob <-
        pnorm(xr[2], mean=xx, sd=sigma) - pnorm(xr[1], mean=xx, sd=sigma)
      yprob <-
        pnorm(yr[2], mean=yy, sd=sigma) - pnorm(yr[1], mean=yy, sd=sigma)
      edgeweight <- xprob * yprob
    } else {
      edg <- second.moment.calc(Xdata, sigma=sigma,
                                what="edge", varcov=varcov)
      edgeweight <- safelookup(edg, xedge, warn=FALSE)
    }
    if(diggle) {
      ## Diggle edge correction
      ## edgeweight is attached to each data point
      if(is.null(weights)) {
        k <- 1
        weights <- 1/edgeweight
      } else {
        weights <- weights/edgeweight
      }
    }
  }
  
  ndata <- npoints(Xdata)
  nquery <- npoints(Xquery)
  result <- if(k == 1) numeric(nquery) else matrix(, nquery, k)
  ## coordinates
  xq <- Xquery$x
  yq <- Xquery$y
  xd <- Xdata$x
  yd <- Xdata$y
  if(!sorted) {
    ## sort into increasing order of x coordinate (required by C code)
    ooq <- fave.order(Xquery$x)
    xq <- xq[ooq]
    yq <- yq[ooq]
    ood <- fave.order(Xdata$x)
    xd <- xd[ood]
    yd <- yd[ood]
  }
  if(is.null(varcov)) {
    ## isotropic kernel
    if(is.null(weights)) {
      zz <- .C("crdenspt",
               nquery  = as.integer(nquery),
               xq      = as.double(xq),
               yq      = as.double(yq),
               ndata   = as.integer(ndata),
               xd      = as.double(xd),
               yd      = as.double(yd),
               rmaxi   = as.double(cutoff),
               sig     = as.double(sd),
               result  = as.double(double(nquery)))
      if(sorted) result <- zz$result else result[ooq] <- zz$result 
    } else if(k == 1) {
      wtsort <- if(sorted) weights else weights[ood]
      zz <- .C("wtcrdenspt",
               nquery  = as.integer(nquery),
               xq      = as.double(xq),
               yq      = as.double(yq),
               ndata   = as.integer(ndata),
               xd      = as.double(xd),
               yd      = as.double(yd),
               wd      = as.double(wtsort),
               rmaxi   = as.double(cutoff),
               sig     = as.double(sd),
               result  = as.double(double(nquery)))
      if(sorted) result <- zz$result else result[ooq] <- zz$result 
    } else {
      ## matrix of weights
      wtsort <- if(sorted) weights else weights[ood, ]
      for(j in 1:k) {
        zz <- .C("wtcrdenspt",
                 nquery  = as.integer(nquery),
                 xq      = as.double(xq),
                 yq      = as.double(yq),
                 ndata   = as.integer(ndata),
                 xd      = as.double(xd),
                 yd      = as.double(yd),
                 wd      = as.double(wtsort[,j]),
                 rmaxi   = as.double(cutoff),
                 sig     = as.double(sd),
                 result  = as.double(double(nquery)))
        if(sorted) result[,j] <- zz$result else result[ooq,j] <- zz$result
      }
    }
  } else {
    ## anisotropic kernel
    flatSinv <- as.vector(t(Sinv))
    if(is.null(weights)) {
      zz <- .C("acrdenspt",
               nquery  = as.integer(nquery),
               xq      = as.double(xq),
               yq      = as.double(yq),
               ndata   = as.integer(ndata),
               xd      = as.double(xd),
               yd      = as.double(yd),
               rmaxi   = as.double(cutoff),
               detsigma = as.double(detSigma),
               sinv    = as.double(flatSinv),
               result  = as.double(double(nquery)))
      if(sorted) result <- zz$result else result[ooq] <- zz$result 
    } else if(k == 1) {
      ## vector of weights
      wtsort <- if(sorted) weights else weights[ood]
      zz <- .C("awtcrdenspt",
               nquery  = as.integer(nquery),
               xq      = as.double(xq),
               yq      = as.double(yq),
               ndata   = as.integer(ndata),
               xd      = as.double(xd),
               yd      = as.double(yd),
               wd      = as.double(wtsort),
               rmaxi   = as.double(cutoff),
               detsigma = as.double(detSigma),
               sinv    = as.double(flatSinv),
               result   = as.double(double(nquery)))
      if(sorted) result <- zz$result else result[ooq] <- zz$result 
    } else {
      ## matrix of weights
      wtsort <- if(sorted) weights else weights[ood, ]
      for(j in 1:k) {
        zz <- .C("awtcrdenspt",
                 nquery  = as.integer(nquery),
                 xq      = as.double(xq),
                 yq      = as.double(yq),
                 ndata   = as.integer(ndata),
                 xd      = as.double(xd),
                 yd      = as.double(yd),
                 wd      = as.double(wtsort[,j]),
                 rmaxi   = as.double(cutoff),
                 detsigma = as.double(detSigma),
                 sinv    = as.double(flatSinv),
                 result  = as.double(double(nquery)))
        if(sorted) result[,j] <- zz$result else result[ooq,j] <- zz$result 
      }
    }
  }
  # ........  Edge correction ........................................
  if(edge && !diggle) 
    result <- result/edgeweight

  # tack on bandwidth
  attr(result, "sigma") <- sigma
  attr(result, "varcov") <- varcov
  # 
  return(result)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/density.psp.R"
#
#
#  density.psp.R
#
#  $Revision: 1.6 $    $Date: 2014/08/04 09:49:22 $
#
#

density.psp <- function(x, sigma, ..., edge=TRUE) {
  verifyclass(x, "psp")
  w <- x$window
  n <- x$n
  if(missing(sigma))
    sigma <- 0.1 * diameter(w)
  w <- as.mask(w, ...)
  len <- lengths.psp(x)
  if(n == 0 || all(len == 0))
    return(as.im(0, w))
  #
  ang <- angles.psp(x, directed=TRUE)
  coz <- cos(ang)
  zin <- sin(ang)
  xy <- rasterxy.mask(w)
  xx <- xy$x
  yy <- xy$y
  # compute matrix contribution from each segment 
  for(i in seq_len(n)) {
    en <- x$ends[i,]
    dx <- xx - en$x0
    dy <- yy - en$y0
    u1 <- dx * coz[i] + dy * zin[i]
    u2 <- - dx * zin[i] + dy * coz[i]
    value <- dnorm(u2, sd=sigma) *
      (pnorm(u1, sd=sigma) - pnorm(u1-len[i], sd=sigma))
    totvalue <- if(i == 1) value else (value + totvalue)
  }
  dens <- im(totvalue, w$xcol, w$yrow)
  if(edge) {
    edg <- second.moment.calc(midpoints.psp(x), sigma, what="edge", ...)
    dens <- eval.im(dens/edg)
  }
  dens <- dens[x$window, drop=FALSE]
  return(dens)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/derivfv.R"
#
# derivfv.R
#
# differentiation for fv objects
#
#  $Revision: 1.6 $ $Date: 2014/10/24 00:22:30 $
#

deriv.fv <- local({

  derivative <- function(y, r, ...) {
    ss <- smooth.spline(r, y, ...)
    predict(ss, r, deriv=1)$y
  }
  
  deriv.fv <- function(expr, which="*", ...,
                       method=c("spline", "numeric"),
                       kinks=NULL,
                       periodic=FALSE,
                       Dperiodic=periodic) {
    f <- expr
    method <- match.arg(method)

    ## select columns
    ##  if(length(which) == 1 && which %in% .Spatstat.FvAbbrev) {
    if(length(which) == 1) {
      if(which == ".x")
        stop("Cannot smooth the function argument")
      which <- fvnames(f, which)
    }
    
    if(any(nbg <- !(which %in% names(f)))) 
      stop(paste("Unrecognised column",
                 ngettext(sum(nbg), "name", "names"),
                 commasep(sQuote(which[nbg])), 
                 "in argument", sQuote("which")))
    relevant <- names(f) %in% which
    ## get 
    rname <- fvnames(f, ".x")
    df <- as.data.frame(f)
    rpos <- which(colnames(df) == rname)
    rvals <- df[,rpos]
    yvals <- df[,relevant,drop=FALSE]
    nr <- length(rvals)
    ##
    if(Dperiodic) {
      ## Derivative should be periodic
      ## Recycle data to imitate periodicity
      DR <- diff(range(rvals))
      rvals <- c(rvals[-nr] - DR, rvals, rvals[-1] + DR)
      yleft <- yvals[-nr, , drop=FALSE]
      yright <-  yvals[-1, , drop=FALSE]
      if(!periodic) {
        ## original data are not periodic (e.g. cdf of angular variable)
        ## but derivative must be periodic
        jump <- matrix(as.numeric(yvals[nr,] - yvals[1, ]),
                       nr-1, ncol(yvals), byrow=TRUE)
        yleft <- yleft - jump
        yright <- yright + jump
      }
      yvals <- rbind(yleft, yvals, yright)
      actual <- nr:(2*nr - 1)
      NR <- length(rvals)
    } else {
      NR <- nr
      actual <- 1:nr
    }
    ## cut x axis into intervals?
    if(is.null(kinks)) {
      cutx <- factor(rep(1, NR))
    } else {
      rr <- range(rvals)
      if(periodic) 
        kinks <- c(kinks-DR, kinks, kinks+DR)
      breaks <- sort(unique(kinks))
      if(breaks[1] > rr[1]) breaks <- c(rr[1], breaks)
      if(max(breaks) < rr[2]) breaks <- c(breaks, rr[2])
      cutx <- cut(rvals, breaks=breaks, include.lowest=TRUE)
    }
    ## process
    for(segment in levels(cutx)) {
      ii <- (cutx == segment)
      yy <- yvals[ii, , drop=FALSE]
      switch(method,
             numeric = {
               dydx <- apply(yy, 2, diff)/diff(rvals[ii])
               nd <- nrow(dydx)
               dydx <- rbind(dydx, dydx[nd, ])
             },
             spline = {
               dydx <- apply(yy, 2, derivative, 
                             r=rvals[ii], ...)
         })
      df[ii[actual], relevant] <- dydx[ actual, ]
    }
    ## pack up
    result <- f
    result[,] <- df
    ## tweak name of function
    if(!is.null(yl <- attr(f, "ylab")))
      attr(result, "ylab") <- substitute(bold(D)~Fx, list(Fx=yl))
    if(!is.null(ye <- attr(f, "yexp")))
      attr(result, "yexp") <- substitute(bold(D)~Fx, list(Fx=ye))
    ## tweak mathematical labels
    attr(result, "labl")[relevant]  <-
      paste0("bold(D)~", attr(f, "labl")[relevant])
    return(result)
  }

  deriv.fv
})


increment.fv <- function(f, delta) {
  stopifnot(is.fv(f))
  check.1.real(delta)
  stopifnot(delta > 0)
  half <- delta/2
  xx <- with(f, .x)
  ynames <- fvnames(f, ".")
  yy <- as.data.frame(lapply(ynames,
                             function(a, xx, f, h) {
                               g <- as.function(f, value=a)
                               g(xx+h)-g(xx-h)
                             },
                             xx=xx, f=f, h=half))
  Y <- f
  Y[,ynames] <- yy
  ## tweak name of function
  if(!is.null(yl <- attr(f, "ylab")))
    attr(Y, "ylab") <- substitute(Delta~Fx, list(Fx=yl))
  if(!is.null(ye <- attr(f, "yexp")))
    attr(Y, "yexp") <- substitute(Delta~Fx, list(Fx=ye))
  ## tweak mathematical labels
  relevant <- colnames(Y) %in% ynames
  attr(Y, "labl")[relevant]  <-
      paste0("Delta~", attr(f, "labl")[relevant])
  ## tweak recommended range
  attr(Y, "alim") <- intersect.ranges(attr(f, "alim"),
                                      range(xx) + c(1,-1)*half)
  return(Y)
}

  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/dg.R"
#
#     dg.S
#
#    $Revision: 1.17 $	$Date: 2014/10/24 00:22:30 $
#
#     Diggle-Gratton pair potential
#
#
DiggleGratton <- local({

  # .... auxiliary functions ......

  diggraterms <- function(X, Y, idX, idY, delta, rho) {
    stopifnot(is.numeric(delta))
    stopifnot(is.numeric(rho))
    stopifnot(delta < rho)
    # sort in increasing order of x coordinate
    oX <- fave.order(X$x)
    oY <- fave.order(Y$x)
    Xsort <- X[oX]
    Ysort <- Y[oY]
    idXsort <- idX[oX]
    idYsort <- idY[oY]
    nX <- npoints(X)
    nY <- npoints(Y)
    # call C routine
    out <- .C("Ediggra",
              nnsource = as.integer(nX),
              xsource  = as.double(Xsort$x),
              ysource  = as.double(Xsort$y),
              idsource = as.integer(idXsort),
              nntarget = as.integer(nY),
              xtarget  = as.double(Ysort$x),
              ytarget  = as.double(Ysort$y),
              idtarget = as.integer(idYsort),
              ddelta   = as.double(delta),
              rrho     = as.double(rho),
              values   = as.double(double(nX)))
    answer <- integer(nX)
    answer[oX] <- out$values
    return(answer)
  }

  # .......... template object ..........
  
  BlankDG <- 
  list(
         name     = "Diggle-Gratton process",
         creator  = "DiggleGratton",
         family    = "pairwise.family",  #evaluated later
         pot      = function(d, par) {
                       delta <- par$delta
                       rho <- par$rho
                       above <- (d > rho)
                       inrange <- (!above) & (d > delta)
                       h <- above + inrange * (d - delta)/(rho - delta)
                       return(log(h))
                    },
         par      = list(delta=NULL, rho=NULL),  # to be filled in later
         parnames = list("lower limit delta", "upper limit rho"),
         selfstart = function(X, self) {
           # self starter for DiggleGratton
           nX <- npoints(X)
           if(nX < 2) {
             # not enough points to make any decisions
             return(self)
           }
           md <- minnndist(X)
           if(!is.na(delta <- self$par$delta)) {
             # value fixed by user or previous invocation
             # check it
             if(md < delta)
               warning(paste("Hard core distance delta is too large;",
                             "some data points will have zero probability"))
             return(self)
           }
           if(md == 0) 
             warning(paste("Pattern contains duplicated points:",
                           "hard core distance delta must be zero"))
           # take hard core = minimum interpoint distance * n/(n+1)
           deltaX <- md * nX/(nX+1)
           DiggleGratton(delta=deltaX, rho=self$par$rho)
         },
         init = function(self) {
           delta <- self$par$delta
           rho   <- self$par$rho
           if(!is.numeric(rho) || length(rho) != 1)
             stop("upper limit rho must be a single number")
           stopifnot(is.finite(rho))
           if(!is.na(delta)) {
             if(!is.numeric(delta) || length(delta) != 1)
               stop("lower limit delta must be a single number")
             stopifnot(delta >= 0)
             stopifnot(rho > delta)
           } else stopifnot(rho >= 0)
         },
         update = NULL, # default OK
         print = NULL,    # default OK
         interpret =  function(coeffs, self) {
           kappa <- as.numeric(coeffs[1])
           return(list(param=list(kappa=kappa),
                       inames="exponent kappa",
                       printable=dround(kappa)))
         },
         valid = function(coeffs, self) {
           kappa <- as.numeric(coeffs[1])
           return(is.finite(kappa) && (kappa >= 0))
         },
         project = function(coeffs, self) {
           kappa <- as.numeric(coeffs[1])
           if(is.finite(kappa) && (kappa >= 0))
             return(NULL)
           return(Poisson())
         },
         irange = function(self, coeffs=NA, epsilon=0, ...) {
           rho <- self$par$rho
           if(all(is.na(coeffs)))
             return(rho)
           kappa <- coeffs[1]
           delta <- self$par$delta
           if(abs(kappa) <= epsilon)
             return(delta)
           else return(rho)
         },
       version=NULL, # evaluated later
       # fast evaluation is available for the border correction only
       can.do.fast=function(X,correction,par) {
         return(all(correction %in% c("border", "none")))
       },
       fasteval=function(X,U,EqualPairs,pairpot,potpars,correction, ...) {
         # fast evaluator for DiggleGratton interaction
         if(!all(correction %in% c("border", "none")))
           return(NULL)
         if(spatstat.options("fasteval") == "test")
           message("Using fast eval for DiggleGratton")
         delta <- potpars$delta
         rho   <- potpars$rho
         idX <- seq_len(npoints(X))
         idU <- rep.int(-1, npoints(U))
         idU[EqualPairs[,2]] <- EqualPairs[,1]
         answer <- diggraterms(U, X, idU, idX, delta, rho)
         answer <- log(pmax.int(0, answer))
         return(matrix(answer, ncol=1))
       },
       Mayer=function(coeffs, self) {
         # second Mayer cluster integral
         rho   <- self$par$rho
         delta <- self$par$delta
         width <- rho - delta
         kappa <- coeffs[1]
         ans <- pi * (rho^2
                      - 2 * rho* width/(kappa + 1)
                      + 2 * width^2/((kappa + 1) * (kappa + 2)))
         return(ans)
       }
  )
  class(BlankDG) <- "interact"

  DiggleGratton <- function(delta=NA, rho) {
    instantiate.interact(BlankDG, list(delta=delta, rho=rho))
  }

  DiggleGratton <- intermaker(DiggleGratton, BlankDG)

  DiggleGratton
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/dgs.R"
#
#
#    dgs.R
#
#    $Revision: 1.7 $	$Date: 2014/10/24 00:22:30 $
#
#    Diggle-Gates-Stibbard process
#
#
# -------------------------------------------------------------------
#	

DiggleGatesStibbard <- local({

  # .......... auxiliary functions ................
  dgsTerms <- function(X, Y, idX, idY, rho) {
    stopifnot(is.numeric(rho))
    # sort in increasing order of x coordinate
    oX <- fave.order(X$x)
    oY <- fave.order(Y$x)
    Xsort <- X[oX]
    Ysort <- Y[oY]
    idXsort <- idX[oX]
    idYsort <- idY[oY]
    nX <- npoints(X)
    nY <- npoints(Y)
    # call C routine
    out <- .C("Ediggatsti",
            nnsource = as.integer(nX),
            xsource  = as.double(Xsort$x),
            ysource  = as.double(Xsort$y),
            idsource = as.integer(idXsort),
            nntarget = as.integer(nY),
            xtarget  = as.double(Ysort$x),
            ytarget  = as.double(Ysort$y),
            idtarget = as.integer(idYsort),
            rrho     = as.double(rho),
            values   = as.double(double(nX)))
    answer <- integer(nX)
    answer[oX] <- out$values
    return(answer)
  }

  # ...... template object ......................
  BlankDGS <- 
    list(
         name   = "Diggle-Gates-Stibbard process",
         creator = "DiggleGatesStibbard",
         family  = "pairwise.family",  # evaluated later
         pot    = function(d, par) {
           rho <- par$rho
           v <- log(sin((pi/2) * d/rho)^2)
           v[ d > par$rho ] <- 0
           attr(v, "IsOffset") <- TRUE
           v
         },
         par    = list(rho = NULL),  # to be filled in later
         parnames = "interaction range", 
         init   = function(self) {
           rho <- self$par$rho
           if(!is.numeric(rho) || length(rho) != 1 || rho <= 0)
             stop("interaction range rho must be a positive number")
         },
         update = NULL,       # default OK
         print = NULL,        # default OK
         interpret =  function(coeffs, self) {
           return(NULL)
         },
         valid = function(coeffs, self) {
           return(TRUE)
         },
         project = function(coeffs, self) {
           return(NULL)
         },
         irange = function(self, coeffs=NA, epsilon=0, ...) {
           rho <- self$par$rho
           return(rho)
         },
         version=NULL, # evaluated later
         # fast evaluation is available for the border correction only
         can.do.fast=function(X,correction,par) {
           return(all(correction %in% c("border", "none")))
         },
         fasteval=function(X,U,EqualPairs,pairpot,potpars,correction, ...) {
           # fast evaluator for DiggleGatesStibbard interaction
           if(!all(correction %in% c("border", "none")))
             return(NULL)
           if(spatstat.options("fasteval") == "test")
             message("Using fast eval for DiggleGatesStibbard")
           rho <- potpars$rho
           idX <- seq_len(npoints(X))
           idU <- rep.int(-1, npoints(U))
           idU[EqualPairs[,2]] <- EqualPairs[,1]
           v <- dgsTerms(U, X, idU, idX, rho)
           v <- matrix(v, ncol=1)
           attr(v, "IsOffset") <- TRUE
           return(v)
         },
         Mayer=function(coeffs, self) {
           # second Mayer cluster integral
           rho   <- self$par$rho
           return((pi/2 - 2/pi) * rho^2)
         }
         )
  class(BlankDGS) <- "interact"

  DiggleGatesStibbard <- function(rho) {
    instantiate.interact(BlankDGS, list(rho = rho))
  }

  DiggleGatesStibbard <- intermaker(DiggleGatesStibbard, BlankDGS)

  DiggleGatesStibbard
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/diagnoseppm.R"
#
#                            diagnoseppm.R
#
# Makes diagnostic plots based on residuals or energy weights
#
# $Revision: 1.35 $ $Date: 2014/10/24 00:22:30 $
#

diagnose.ppm.engine <- function(object, ..., type="eem", typename, opt,
                                sigma=NULL,
                                rbord = reach(object), compute.sd=TRUE,
                                compute.cts=TRUE,
                                envelope=FALSE, nsim=39, nrank=1,
                                rv=NULL, oldstyle=FALSE,
                                splineargs = list(spar=0.5),
                                verbose=TRUE)
{
  if(is.marked.ppm(object))
    stop("Sorry, this is not yet implemented for marked models")

  # quadrature points
  Q <- quad.ppm(object)
  U <- union.quad(Q)
  Qweights <- w.quad(Q)
  
  # -------------- Calculate residuals/weights -------------------

  # Discretised residuals

  if(type == "eem") {
    residval <- if(!is.null(rv)) rv else eem(object, check=FALSE)
    residval <- as.numeric(residval)
    X <- data.ppm(object)
    Y <- X %mark% residval
  } else {
    if(!is.null(rv) && !inherits(rv, "msr"))
      stop("rv should be a measure (object of class msr)")
    residobj <-
      if(!is.null(rv)) rv else residuals.ppm(object, type=type, check=FALSE)
    residval <- with(residobj, "increment")
    if(ncol(as.matrix(residval)) > 1)
      stop("Not implemented for vector-valued residuals; use [.msr to split into separate components")
    Y <- U %mark% residval
  }

  # Atoms and density of measure

  Ymass <- NULL
  Ycts  <- NULL
  Ydens <- NULL

  if(compute.cts) {
    if(type == "eem") {
      Ymass <- Y
      Ycts  <- U %mark% (-1)
      Ydens <- as.im(-1, Y$window)
    } else {
      atoms <- with(residobj, "is.atom")
      masses <- with(residobj, "discrete")
      cts    <- with(residobj, "density")
      if(!is.null(atoms) && !is.null(masses) && !is.null(cts)) {
        Ymass <- (U %mark% masses)[atoms]
        Ycts    <- U %mark% cts
        # remove NAs (as opposed to zero cif points)
        if(!all(ok <- is.finite(cts))) {
          U <- U[ok]
          Ycts <- Ycts[ok]
          cts  <- cts[ok]
          Qweights <- Qweights[ok]
        }
        # interpolate continuous part to yield an image for plotting
        if(type == "inverse" && all(cts > 0)) {
          Ydens <- as.im(-1, Y$window)
        } else if(is.stationary.ppm(object) && is.poisson.ppm(object)) {
          # all values of `cts' will be equal
          Ydens <- as.im(cts[1], Y$window)
        } else {
          smallsigma <- maxnndist(Ycts)
          Ujitter <- U
          Ujitter$x <- U$x + runif(U$n, -smallsigma, smallsigma)
          Ujitter$y <- U$y + runif(U$n, -smallsigma, smallsigma)
          Ydens <- Smooth(Ujitter %mark% marks(Ycts),
                          sigma=smallsigma,
                          weights=Qweights,
                          edge=TRUE, ...)
        }
      }
    }
  }
    

  #----------------  Erode window ---------------------------------
  #
  ## Compute windows 
  W <- Y$window

  # Erode window if required
  clip <- (rbord > 0)
  if(clip) {
    Wclip <- erosion.owin(W, rbord)
    Yclip <- Y[Wclip]
    Qweightsclip <- Qweights[inside.owin(U, , Wclip)]
    if(!is.null(Ycts))
      Ycts <- Ycts[Wclip]
    if(!is.null(Ydens))
      Ydens <- Ydens[Wclip, drop=FALSE]
  } else {
    Wclip <- W
    Yclip <- Y
  }
  
  # ------------ start collecting results -------------------------
  
  result <- list(type=type,
                 clip=clip,
                 Y=Y,
                 W=W,
                 Yclip=Yclip,
                 Ymass=Ymass,
                 Ycts=Ycts,
                 Ydens=Ydens)

  # ------------- smoothed field ------------------------------

  Z <- NULL
  if(opt$smooth | opt$xcumul | opt$ycumul | opt$xmargin | opt$ymargin) {
    if(is.null(sigma))
      sigma <- 0.1 * diameter(Wclip)  
    Z <- density.ppp(Yclip, sigma, weights=Yclip$marks, edge=TRUE, ...)
  }
  if(opt$smooth)
    result$smooth <- list(Z = Z, sigma=sigma)

  # -------------- marginals of smoothed field ------------------------
  
  if(opt$xmargin) {
    xZ <- apply(Z$v, 2, sum, na.rm=TRUE) * Z$xstep
    if(type == "eem") 
      ExZ <- apply(Z$v, 2, function(column) { sum(!is.na(column)) }) * Z$xstep
    else 
      ExZ <- numeric(length(xZ))
    result$xmargin <- list(x=Z$xcol, xZ=xZ, ExZ=ExZ)
  }
  
  if(opt$ymargin) {
    yZ <- apply(Z$v, 1, sum, na.rm=TRUE) * Z$ystep
    if(type == "eem")
      EyZ <- apply(Z$v, 1, function(roww) { sum(!is.na(roww)) }) * Z$ystep
    else
      EyZ <- numeric(length(yZ))
    result$ymargin <- list(y=Z$yrow, yZ=yZ, EyZ=EyZ)
  }
  
  # -------------- cumulative (lurking variable) plots --------------

  ## precompute simulated patterns for envelopes
  if(identical(envelope, TRUE))
    envelope <- simulate(object, nsim=nsim, progress=verbose)

  if(opt$xcumul)
    result$xcumul <- 
    lurking(object, covariate=expression(x),
            type=type,
            clipwindow= if(clip) Wclip else NULL,
            rv=residval,
            plot.sd=compute.sd,
            envelope=envelope, nsim=nsim, nrank=nrank,
            plot.it=FALSE,
            typename=typename,
            covname="x coordinate",
            oldstyle=oldstyle,
            check=FALSE,
            splineargs=splineargs,
            ...)

  if(opt$ycumul)
    result$ycumul <- 
    lurking(object, covariate=expression(y),
            type=type,
            clipwindow= if(clip) Wclip else NULL,
            rv=residval,
            plot.sd=compute.sd,
            envelope=envelope, nsim=nsim, nrank=nrank,
            plot.it=FALSE,
            typename=typename,
            covname="y coordinate",
            oldstyle=oldstyle,
            check=FALSE,
            splineargs=splineargs,
            ...)

  # -------------- summary numbers --------------
  
  if(opt$sum) 
    result$sum <- list(marksum=sum(Yclip$marks, na.rm=TRUE),
                       areaWclip=area(Wclip),
                       areaquad=if(clip) sum(Qweightsclip) else sum(Qweights),
                       range=if(!is.null(Z)) range(Z) else NULL)

  return(invisible(result))
}


########################################################################


diagnose.ppm <- function(object, ..., type="raw", which="all", 
                         sigma=NULL, 
                         rbord = reach(object), cumulative=TRUE,
                         plot.it = TRUE, rv = NULL, 
                         compute.sd=TRUE, compute.cts=TRUE,
                         envelope=FALSE, nsim=39, nrank=1,
                         typename, check=TRUE, repair=TRUE, oldstyle=FALSE,
                         splineargs=list(spar=0.5))
{
  if(is.marked.ppm(object))
    stop("Sorry, this is not yet implemented for marked models")

  if(check && damaged.ppm(object)) {
    if(!repair)
      stop("object format corrupted; try update(object, use.internal=TRUE)")
    message("object format corrupted; repairing it.")
    object <- update(object, use.internal=TRUE)
  } else if(compute.sd && is.null(getglmfit(object)))
    object <- update(object, forcefit=TRUE, use.internal=TRUE)

    
  # -------------  Interpret arguments --------------------------

  # edge effect avoidance
  if(!is.finite(rbord)) {
    if(missing(rbord))
      stop(paste(sQuote("rbord"),
                 "must be specified; the model has infinite range"))
    else
      stop(paste(sQuote("rbord"), "is infinite"))
  }
  
#  # whether window should be clipped
#  clip <- (rbord > 0)

  # match type argument
  type <- pickoption("type", type,
                     c(eem="eem",
                       raw="raw",
                       inverse="inverse",
                       pearson="pearson",
                       Pearson="pearson"))
  if(missing(typename))
    typename <- switch(type,
                       eem="exponential energy weights",
                       raw="raw residuals",
                       inverse="inverse-lambda residuals",
                       pearson="Pearson residuals")

  # 'which' is multiple choice with exact matching 
  optionlist <- c("all", "marks", "smooth", "x", "y", "sum")

  if(!all(m <- which %in% optionlist))
    stop(paste("Unrecognised choice(s) of",
               paste(sQuote("which"), ":", sep=""),
               paste(which[!m], collapse=", ")))

  opt <- list()
  opt$all <- "all" %in% which
  opt$marks <-  ("marks" %in% which)   | opt$all
  opt$smooth <- ("smooth" %in% which)  | opt$all
  opt$xmargin <- (("x" %in% which)       | opt$all) && !cumulative
  opt$ymargin <- (("y" %in% which)       | opt$all) && !cumulative
  opt$xcumul <-  (("x" %in% which)       | opt$all) && cumulative
  opt$ycumul <-  (("y" %in% which)       | opt$all) && cumulative
  opt$sum <-     ("sum" %in% which)      | opt$all

  # compute and plot estimated standard deviations?
  # yes for Poisson, no for other models, unless overridden
  if(!missing(compute.sd))
    plot.sd <- compute.sd
  else
    plot.sd <- list(...)$plot.sd
  if(is.null(plot.sd))
    plot.sd <- is.poisson.ppm(object)
  if(missing(compute.sd))
    compute.sd <- plot.sd

  # interpolate the density of the residual measure?
  if(missing(compute.cts)) {
    plot.neg <- resolve.defaults(list(...),
                                 formals(plot.diagppm)["plot.neg"])$plot.neg
    # only if it is needed for the mark plot
    compute.cts <- opt$marks && (plot.neg != "discrete")
  }

  # -------  DO THE CALCULATIONS -----------------------------------
  RES <-  diagnose.ppm.engine(object, type=type, typename=typename,
                              opt=opt, sigma=sigma, rbord=rbord,
                              compute.sd=compute.sd,
                              compute.cts=compute.cts,
                              envelope=envelope, nsim=nsim, nrank=nrank,
                              rv=rv, oldstyle=oldstyle,
                              splineargs=splineargs,
                              ...)

  RES$typename <- typename
  RES$opt <- opt
  RES$compute.sd <- compute.sd
  RES$compute.cts <- compute.cts
  
  class(RES) <- "diagppm"

  # -------  PLOT --------------------------------------------------
  if(plot.it) 
    plot(RES, ...)

  return(RES)
}

plot.diagppm <-
  function(x, ..., which,
           plot.neg=c("image", "discrete", "contour", "imagecontour"),
           plot.smooth=c("imagecontour", "image", "contour", "persp"),
           plot.sd=TRUE, spacing=0.1,
           srange=NULL, monochrome=FALSE, main=NULL)
{
  opt <- x$opt
  
  plot.neg <- match.arg(plot.neg)
  plot.smooth <- match.arg(plot.smooth)
  
  if(!missing(which)) {
    oldopt <- opt
    newopt <- list()
    newopt$all <- "all" %in% which
    newopt$marks <-  ("marks" %in% which)   | newopt$all
    newopt$smooth <- ("smooth" %in% which)  | newopt$all
    newopt$xmargin <- (("x" %in% which)       | newopt$all) && oldopt$xmargin
    newopt$ymargin <- (("y" %in% which)       | newopt$all) && oldopt$ymargin
    newopt$xcumul <-  (("x" %in% which)       | newopt$all) && oldopt$xcumul
    newopt$ycumul <-  (("y" %in% which)       | newopt$all)  && oldopt$ycumul
    newopt$sum <-     ("sum" %in% which)      | newopt$all

    illegal <- (unlist(newopt) > unlist(oldopt))
    if(any(illegal)) {
      offending <- paste(names(newopt)[illegal], collapse=", ")
      whinge <- paste("cannot display the following components;\n",
                      "they were not computed: - \n", offending, "\n")
      stop(whinge)
    }

    opt <- newopt
  }

  if(!(x$compute.sd) && plot.sd) {
    if(!missing(plot.sd))
      warning("can't plot standard deviations; they were not computed")
    plot.sd <- FALSE
  }

  if(!(x$compute.cts) && (plot.neg != "discrete") && (opt$marks || opt$all)) {
    if(!missing(plot.neg))
      warning("can't plot continuous component of residuals; it was not computed")
    plot.neg <- "discrete"
  }
  
  if(opt$all) 
    resid4plot(x, plot.neg, plot.smooth, spacing, srange,monochrome, main, ...)
  else
    resid1plot(x, opt, plot.neg, plot.smooth, srange, monochrome, main, ...)
}


print.diagppm <- function(x, ...) {
  
  opt <- x$opt
  typename <- x$typename
  
  cat(paste("Model diagnostics (", typename, ")\n", sep=""))

  cat("Diagnostics available:\n")
  optkey <- list(all="four-panel plot",
                 marks=paste("mark plot", if(!x$compute.cts)
                   "(discrete representation only)" else NULL),
                 smooth="smoothed residual field",
                 xmargin="x marginal density",
                 ymargin="y marginal density",
                 xcumul="x cumulative residuals",
                 ycumul="y cumulative residuals",
                 sum="sum of all residuals")
  avail <- unlist(optkey[names(opt)[unlist(opt)]])
  names(avail) <- NULL
  cat(paste("\t", paste(avail, collapse="\n\t"), "\n", sep=""))
  
  if(opt$sum) {
    xs <- x$sum
    windowname <- if(x$clip) "clipped window" else "entire window"
    cat(paste("sum of", typename, "in", windowname, "=",
              signif(sum(xs$marksum),4), "\n"))
    cat(paste("area of", windowname, "=",
              signif(xs$areaWclip, 4), "\n"))
    cat(paste("quadrature area =",
              signif(xs$areaquad, 4), "\n"))
  }
  if(opt$smooth) 
    cat(paste("range of smoothed field = [",
              paste(signif(range(x$smooth$Z$v, na.rm=TRUE),4), collapse=","),
              "]\n"))

  return(invisible(NULL))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/diagram.R"
##
##   diagram.R
##
##   Simple objects for the elements of a diagram (text, arrows etc)
##    that are compatible with plot.layered and plot.listof
##
##   $Revision: 1.8 $ $Date: 2014/12/02 09:31:45 $

# ......... internal class 'diagramobj' supports other classes  .........

diagramobj <- function(X, ...) {
  if(inherits(try(Frame(X), silent=TRUE), "try-error"))
    stop("X is not a spatial object")
  a <- list(...)
  if(sum(nzchar(names(a))) != length(a))
    stop("All extra arguments must be named")
  attributes(X) <- append(attributes(X), a)
  class(X) <- c("diagramobj", class(X))
  return(X)
}

"[.diagramobj" <- function(x, ...) {
  y <- NextMethod("[")
  attributes(y) <- attributes(x)
  return(y)
}

shift.diagramobj <- function(X, ...) {
  y <- NextMethod("shift")
  attributes(y) <- attributes(X)
  return(y)
}

# .............. user-accessible classes ................
# .........  (these only need a creator and a plot method) ......


## ...........  text .................

textstring <- function(x, y, txt=NULL, ...) {
  if(is.ppp(x) && missing(y)) {
    stopifnot(npoints(x) == 1)
    X <- x
    Window(x) <- boundingbox(x)
  } else {
    if(missing(y) && checkfields(x, c("x", "y"))) {
      y <- x$y
      x <- x$x
    }
    check.1.real(x)
    check.1.real(y)
    X <- ppp(x, y, window=owin(c(x,x),c(y,y)))
  }
  Y <- diagramobj(X, txt=txt, otherargs=list(...))
  class(Y) <- c("textstring", class(Y))
  return(Y)
}

plot.textstring <- function(x, ..., do.plot=TRUE) {
  txt <- attr(x, "txt")
  otha <- attr(x, "otherargs")
  if(do.plot) do.call.matched(text.default,
                              resolve.defaults(list(...),
                                               list(x=x$x, y=x$y, labels=txt),
                                               otha),
                              extrargs=c("srt", "family", "xpd"))
  return(invisible(Frame(x)))
}

print.textstring <- function(x, ...) {
  splat("Text string object")
  splat("Text:", dQuote(attr(x, "txt")))
  splat("Coordinates:", paren(paste(x$x, x$y, collapse=", ")))
  return(invisible(NULL))
}
  
## ...........  'yardstick' to display scale information  ................

yardstick <- function(x0, y0, x1, y1, txt=NULL, ...) {
  nomore <- missing(y0) && missing(x1) && missing(y1) 
  if(is.ppp(x0) && nomore) {
    if(npoints(x0) != 2) stop("x0 should consist of exactly 2 points")
    X <- x0
  } else if(is.psp(x0) && nomore) {
    if(nobjects(x0) != 1) stop("x0 should consist of exactly 1 segment")
    X <- endpoints.psp(x0)
  } else {
    xx <- c(x0, x1)
    yy <- c(y0, y1)
    B <- boundingbox(list(x=xx, y=yy))
    X <- ppp(xx, yy, window=B, check=FALSE)
  }
  Window(X) <- boundingbox(X)
  Y <- diagramobj(X, txt=txt, otherargs=list(...))
  class(Y) <- c("yardstick", class(Y))
  return(Y)
}

plot.yardstick <- local({

  mysegments <- function(x0, y0, x1, y1, ..., moreargs=list()) {
    ## ignore unrecognised arguments without whingeing
    do.call.matched(segments,
                    resolve.defaults(list(x0=x0, y0=y0, x1=x1, y1=y1),
                                     list(...),
                                     moreargs),
                    extrargs=c("col", "lty", "lwd", "xpd", "lend"))
  }
  
  myarrows <- function(x0, y0, x1, y1, ...,
                       left=TRUE, right=TRUE,
                       angle=20, frac=0.25,
                       main, show.all, add) {
    mysegments(x0, y0, x1, y1, ...)
    if(left || right) {
      ang <- angle * pi/180
      co <- cos(ang)
      si <- sin(ang)
      dx <- x1-x0
      dy <- y1-y0
      le <- sqrt(dx^2 + dy^2)
      rot <- matrix(c(dx, dy, -dy, dx)/le, 2, 2)
      arlen <- frac * le
      up <- arlen * (rot %*% c(co, si))
      lo <- arlen * (rot %*% c(co, -si))
      if(left) {
        mysegments(x0, y0, x0+up[1], y0+up[2], ...)
        mysegments(x0, y0, x0+lo[1], y0+lo[2], ...)
      }
      if(right) {
        mysegments(x1, y1, x1-up[1], y1-up[2], ...)
        mysegments(x1, y1, x1-lo[1], y1-lo[2], ...)
      }
    }
    return(invisible(NULL))
  }

  plot.yardstick <- function(x, ...,
                             angle=20,
                             frac=1/8,
                             cex=1,
                             pos=NULL,
                             split=FALSE,
                             shrink=1/4,
                             do.plot=TRUE) {
    if(do.plot) {
      txt <- attr(x, "txt")
      argh <- resolve.defaults(list(...), attr(x, "otherargs"))
      A <- as.numeric(coords(x)[1,])
      B <- as.numeric(coords(x)[2,])
      M <- (A+B)/2
      if(!split) {
        ## double-headed arrow
        myarrows(A[1], A[2], B[1], y1=B[2],
                 angle=angle, frac=frac, moreargs=argh)
        if(missing(pos))
          pos <- if(abs(A[1] - B[1]) < abs(A[2] - B[2])) 4 else 3
      } else {
        ## two single-headed arrows with text 
        dM <- (shrink/2) * (B - A)
        AM <- M - dM
        BM <- M + dM
        newfrac <- frac/((1-shrink)/2)
        myarrows(AM[1], AM[2], A[1], A[2],
                 angle=angle, frac=newfrac, left=FALSE, moreargs=argh)
        myarrows(BM[1], BM[2], B[1], B[2], 
                 angle=angle, frac=newfrac, left=FALSE, moreargs=argh)
      }
      text(M[1], M[2], txt, cex=cex, pos=pos)
    }
    return(invisible(Window(x)))
  }
  plot.yardstick
})


print.yardstick <- function(x, ...) {
  splat("Yardstick")
  if(!is.null(txt <- attr(x, "txt")))
    splat("Text:", txt)
  ui <- summary(unitname(x))
  splat("Length:", pairdist(x)[1,2], ui$plural, ui$explain)
  splat("Midpoint:",
        paren(paste(signif(c(mean(x$x), mean(x$y)), 3), collapse=", ")))
  dx <- diff(range(x$x))
  dy <- diff(range(x$y))
  orient <- if(dx == 0) "vertical" else
            if(dy == 0) "horizontal" else
            paste(atan2(dy, dx) * 180/pi, "degrees")
  splat("Orientation:", orient)
  return(invisible(NULL))
}


## code to draw a decent-looking arrow in spatstat diagrams
## (works in layered objects)

## The name 'onearrow' is used because R contains
## hidden functions [.arrow, length.arrow

onearrow <- function(x0, y0, x1, y1, txt=NULL, ...) {
  nomore <- missing(y0) && missing(x1) && missing(y1) 
  if(is.ppp(x0) && nomore) {
    if(npoints(x0) != 2) stop("x0 should consist of exactly 2 points")
    X <- x0
  } else if(is.psp(x0) && nomore) {
    if(nobjects(x0) != 1) stop("x0 should consist of exactly 1 segment")
    X <- endpoints.psp(x0)
  } else {
    xx <- c(x0, x1)
    yy <- c(y0, y1)
    B <- boundingbox(list(x=xx, y=yy))
    X <- ppp(xx, yy, window=B, check=FALSE)
  }
  Window(X) <- boundingbox(X)
  Y <- diagramobj(X, txt=txt, otherargs=list(...))
  class(Y) <- c("onearrow", class(Y))
  return(Y)
}

print.onearrow <- function(x, ...) {
  cat("Single arrow", fill=TRUE)
  if(!is.null(txt <- attr(x, "txt")))
    cat("Text:", txt, fill=TRUE)
  NextMethod("print")
}

plot.onearrow <- function(x, ...,
                          add=FALSE,
                          main="",
                          retract=0.05,   
                          headfraction=0.25,
                          headangle=12, # degrees
                          headnick=0.1, # fraction of head length
                          col.head=NA,
                          lwd.head=lwd,
                          lwd=1,
                          col=1,
                          zap=FALSE,
                          zapfraction=0.07,
                          pch=1, cex=1,
                          do.plot=TRUE,
                          do.points=FALSE,
                          show.all=!add) {
  result <- plot.ppp(x, main=main, add=add,
                     pch=pch, cex=cex,
                     do.plot=do.plot && do.points,
                     show.all=show.all)
  if(do.plot) {
    if(!do.points && !add)
      plot(Frame(x), main="", type="n")
    txt <- attr(x, "txt")
    argh <- resolve.defaults(list(...), attr(x, "otherargs"))
    A <- as.numeric(coords(x)[1,])
    B <- as.numeric(coords(x)[2,])
    V <- B - A
    AR <- A + retract * V
    BR <- B - retract * V
    H <- B - headfraction * V
    HN <- H + headnick * headfraction * V
    headlength <- headfraction * sqrt(sum(V^2))
    halfwidth <- headlength * tan((headangle/2) * pi/180)
    alpha <- atan2(V[2], V[1]) + pi/2
    U <- c(cos(alpha), sin(alpha))
    HL <- H + halfwidth * U
    HR <- H - halfwidth * U
    Head <- rbind(HN, HL, BR, HR, HN)
    if(!is.na(col.head))
      do.call.matched(polygon,
                      resolve.defaults(list(x=Head),
                                       argh,
                                       list(col=col.head, lwd=lwd.head)))
    if(!zap) {
      Tail <- AR
    } else {
      M <- (AR+HN)/2
      dM <- (zapfraction/2) * (1-headfraction) * V
      dM <- dM + c(-dM[2], dM[1])
      ML <- M + dM
      MR <- M - dM
      Tail <- rbind(AR, ML, MR)
    }
    do.call.matched(lines,
                    resolve.defaults(list(x=rbind(Tail, Head)),
                                     argh,
                                     list(col=col, lwd=lwd)),
                    extrargs=c("col", "lwd", "lty", "xpd", "lend"))
    if(!is.null(txt <- attr(x, "txt"))) {
      H <- (A+B)/2
      do.call.matched(text.default,
                      resolve.defaults(
                        list(x=H[1], y=H[2]),
                        argh,
                        list(labels=txt, pos=3 + (V[2] != 0))),
                      extrargs=c("srt", "family", "xpd"))
    }
  }
  return(invisible(result))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/disc.R"
##
## disc.R
##
##  discs and ellipses
##
## $Revision: 1.15 $ $Date: 2014/09/22 11:01:39 $
##

disc <- local({

  indic <- function(x,y,x0,y0,r) { as.integer((x-x0)^2 + (y-y0)^2 < r^2) }
  
  disc <- function(radius=1, centre=c(0,0), ...,
                   mask=FALSE, npoly=128, delta=NULL) {
    stopifnot(length(radius) == 1)
    stopifnot(radius > 0)
    centre <- as2vector(centre)
    if(!missing(npoly) && !is.null(delta))
      stop("Specify either npoly or delta")
    if(!missing(npoly)) {
      stopifnot(length(npoly) == 1)
      stopifnot(npoly >= 3)
    } else if(!is.null(delta)) {
      check.1.real(delta)
      stopifnot(delta > 0)
      npoly <- pmax(16, ceiling(2 * pi * radius/delta))
    }
    if(!mask) {
      theta <- seq(from=0, to=2*pi, length.out=npoly+1)[-(npoly+1)]
      x <- centre[1] + radius * cos(theta)
      y <- centre[2] + radius * sin(theta)
      W <- owin(poly=list(x=x, y=y), check=FALSE)
    } else {
      xr <- centre[1] + radius * c(-1,1)
      yr <- centre[2] + radius * c(-1,1)
      B <- owin(xr,yr)
      IW <- as.im(indic, B, x0=centre[1], y0=centre[2], r=radius, ...)
      W <- levelset(IW, 1, "==")
    }
    return(W)
  }

  disc
})

ellipse <- local({
  
  indic <- function(x,y,x0,y0,a,b,co,si){
    x <- x-x0
    y <- y-y0
    as.integer(((x*co + y*si)/a)^2 + ((-x*si + y*co)/b)^2 < 1)
  }

  ellipse <- function(a, b, centre=c(0,0), phi=0, ...,
                      mask=FALSE, npoly = 128) {
    ## Czechs:
    stopifnot(length(a) == 1)
    stopifnot(a > 0)
    stopifnot(length(b) == 1)
    stopifnot(b > 0)
    centre <- as2vector(centre)
    stopifnot(length(phi) == 1)
    stopifnot(length(npoly) == 1)
    stopifnot(npoly > 2)
    ## Rotator cuff:
    co <- cos(phi)
    si <- sin(phi)
    ## Mask:
    if(mask) {
      ## Thetas maximizing x and y.
      tx <- atan(-b*tan(phi)/a)
      ty <- atan(b/(a*tan(phi)))
      ## Maximal x and y (for centre = c(0,0)).
      xm <- a*co*cos(tx) - b*si*sin(tx)
      ym <- a*si*cos(ty) + b*co*sin(ty)
      ## Range of x and y.
      xr <- xm*c(-1,1)+centre[1]
      yr <- ym*c(-1,1)+centre[2]
      ## Wrecked-angle to contain the mask.
      B  <- as.mask(owin(xr,yr),...)
      ## Build the mask as a level set.
      IW <- as.im(indic, B, x0=centre[1], y0=centre[2], a=a, b=b, co=co, si=si)
      return(levelset(IW, 1, "=="))
    }
    ## Polygonal.
    ## Build "horizontal" ellipse centred at 0:
    theta <- seq(0, 2 * pi, length = npoly+1)[-(npoly+1)]
    xh <-  a * cos(theta)
    yh <-  b * sin(theta)

    ## Rotate through angle phi and shift centre:
    x  <- centre[1] + co*xh - si*yh
    y  <- centre[2] + si*xh + co*yh
    owin(poly=list(x = x, y = y))
  }

  ellipse
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/discarea.R"
#
#    discarea.R
#
#  $Revision: 1.17 $  $Date: 2014/10/24 00:22:30 $
#
#
#  Compute area of intersection between a disc and a window,
#
discpartarea <- function(X, r, W=as.owin(X)) {
  if(!missing(W)) {
    verifyclass(W, "owin")
    if(!inherits(X, "ppp"))
      X <- as.ppp(X, W)
  }
  verifyclass(X, "ppp")

  n <- X$n
  if(is.matrix(r) && nrow(r) != n)
    stop("the number of rows of r should match the number of points in X")
  if(!is.matrix(r)) {
    nr <- length(r)
    r <- matrix(r, nrow=n, ncol=nr, byrow=TRUE)
  } else {
    nr <- ncol(r)
  }
  
  W <- as.polygonal(W)
  
  # convert polygon to line segments
  Y <- edges(W)
  # remove vertical segments (contribution is zero)
  vert <- (Y$ends$x1 == Y$ends$x0)
  Y <- Y[!vert]
  # go
  z <- .C("discareapoly",
          nc=as.integer(n),
          xc=as.double(X$x),
          yc=as.double(X$y),
          nr=as.integer(nr),
          rmat=as.double(r),
          nseg=as.integer(Y$n),
          x0=as.double(Y$ends$x0),
          y0=as.double(Y$ends$y0),
          x1=as.double(Y$ends$x1),
          y1=as.double(Y$ends$y1),
          eps=as.double(.Machine$double.eps),
          out=as.double(numeric(length(r))))
  areas <- matrix(z$out, n, nr)
  return(areas)
}

# Compute area of dilation of point pattern
# using Dirichlet tessellation or distmap
#  (areas of other dilations using distmap)

dilated.areas <- function(X, r, W=as.owin(X), ...,
                          constrained=TRUE,
                          exact=FALSE) {
  if(is.matrix(r)) {
    if(sum(dim(r) > 1) > 1)
      stop("r should be a vector or single value")
    r <- as.vector(r)
  }
  if(exact && !is.ppp(X)) {
    exact <- FALSE
    warning("Option exact=TRUE is only available for ppp objects")
  }
  if(!constrained) {
    # unconstrained dilation
    bb <- as.rectangle(X)
    W <- grow.rectangle(bb, max(r))
    if(is.owin(X))
      X <- rebound.owin(X, W)
    else
      X$window <- W
  } else W <- as.owin(W)
  if(!exact) {
    D <- distmap(X)
    pixelarea <- D$xstep * D$ystep
    Dvals <- D[W, drop=TRUE]
    if(is.im(Dvals))
      Dvals <- as.vector(as.matrix(Dvals))
    Dvals <- Dvals[!is.na(Dvals)]
    rr <- c(-1, r)
    h <- cumsum(whist(Dvals, rr))
    return(h * pixelarea)
  }
  X <- unique(X)
  npts <- npoints(X)
  nr <- length(r)
  if(npts == 0)
    return(numeric(nr))
  else if(npts == 1) 
    return(discpartarea(X, r, W))
  samebox <- (W$type == "rectangle") &&
              identical(all.equal(W, as.owin(X)), "TRUE")
  needclip <- constrained && !samebox
  dd <- dirichlet(X)
  til <- tiles(dd)
  out <- matrix(0, npts, nr)
  for(i in 1:npts) {
    Ti <- til[[i]]
    if(needclip)
      Ti <- intersect.owin(Ti, W)
    out[i,] <- discpartarea(X[i], r, Ti)
  }
  return(apply(out, 2, sum))
}

  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/dist2dpath.R"
#
#  dist2dpath.R
#
#   $Revision: 1.8 $    $Date: 2014/10/24 00:22:30 $
#
#       dist2dpath    compute shortest path distances
#

dist2dpath <- function(dist, method="C") {
  ## given a matrix of distances between adjacent vertices
  ## (value = Inf if not adjacent)
  ## compute the matrix of shortest path distances
  stopifnot(is.matrix(dist) && isSymmetric(dist))
  stopifnot(all(diag(dist) == 0))
  stopifnot(all(dist[is.finite(dist)] >= 0))
  ##
  n <- nrow(dist)
  if(n <= 1) return(dist)
  cols <- col(dist)
  ##
  shortest <- min(dist[is.finite(dist) & dist > 0])
  tol <- shortest/max(n,1024)
  tol <- max(tol, .Machine$double.eps)
  ##
  switch(method,
         interpreted={
           dpathnew <- dpath <- dist
           changed <- TRUE
           while(changed) {
             for(j in 1:n) 
               dpathnew[,j] <- apply(dpath + dist[j,][cols], 1, min)
             changed <- any(abs(dpathnew - dpath) > tol)
             dpath <- dpathnew
           }
         },
         C={
           adj <- is.finite(dist)
           diag(adj) <- TRUE
           d <- dist
           d[!adj] <- -1
           z <- .C("Ddist2dpath",
                   nv=as.integer(n),
                   d=as.double(d),
                   adj=as.integer(adj),
                   dpath=as.double(numeric(n*n)),
                   tol=as.double(tol),
                   niter=as.integer(integer(1)),
                   status=as.integer(integer(1)))
           if(z$status == -1)
             warning(paste("C algorithm did not converge to tolerance", tol,
                           "after", z$niter, "iterations",
                           "on", n, "vertices and",
                           sum(adj) - n, "edges"))
           dpath <- matrix(z$dpath, n, n)
           ## value=-1 implies unreachable
           dpath[dpath < 0] <- Inf
         },
         stop(paste("Unrecognised method", sQuote(method))))
  return(dpath)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/distan3D.R"
#
#      distan3D.R
#
#      $Revision: 1.12 $     $Date: 2014/11/10 11:01:39 $
#
#      Interpoint distances for 3D points
#
#      Methods for pairdist, nndist, nnwhich, crossdist
#

pairdist.pp3 <- function(X, ..., periodic=FALSE, squared=FALSE) {
  verifyclass(X, "pp3")
  # extract point coordinates
  xyz <- coords(X)
  n <- nrow(xyz)
  x <- xyz$x
  y <- xyz$y
  z <- xyz$z
  #   
  # special cases
  if(n == 0)
    return(matrix(numeric(0), nrow=0, ncol=0))
  else if(n == 1)
    return(matrix(0,nrow=1,ncol=1))
  #
  if(!periodic) {
    Cout <- .C("D3pairdist",
               n = as.integer(n),
               x = as.double(x),
               y = as.double(y),
               z = as.double(z),
               squared = as.integer(squared),
               d = as.double(numeric(n*n)))
  } else {
    b <- as.box3(X)
    wide <- diff(b$xrange)
    high <- diff(b$yrange)
    deep <- diff(b$zrange)
    Cout <- .C("D3pairPdist",
               n = as.integer(n),
               x = as.double(x),
               y = as.double(y),
               z = as.double(z),
               xwidth=as.double(wide),
               yheight=as.double(high),
               zdepth=as.double(deep),
               squared = as.integer(squared),
               d= as.double(numeric(n*n)))
  }
  dout <- matrix(Cout$d, nrow=n, ncol=n)
  return(dout)
}

nndist.pp3 <- function(X, ..., k=1) {
  verifyclass(X, "pp3")

  if((narg <- length(list(...))) > 0) 
    warning(paste(narg, "unrecognised",
                  ngettext(narg, "argument was", "arguments were"),
                  "ignored"))

  # extract point coordinates
  xyz <- coords(X)
  n <- nrow(xyz)
  x <- xyz$x
  y <- xyz$y
  z <- xyz$z
  
  # k can be a single integer or an integer vector
  if(length(k) == 0)
    stop("k is an empty vector")
  else if(length(k) == 1) {
    if(k != round(k) || k <= 0)
      stop("k is not a positive integer")
  } else {
    if(any(k != round(k)) || any(k <= 0))
      stop(paste("some entries of the vector",
           sQuote("k"), "are not positive integers"))
  }
  k <- as.integer(k)
  kmax <- max(k)

  # trivial cases
  if(n <= 1) {
    # empty pattern => return numeric(0)
    # or pattern with only 1 point => return Inf
    nnd <- matrix(Inf, nrow=n, ncol=kmax)
    nnd <- nnd[,k, drop=TRUE]
    return(nnd)
  }
  
  # number of neighbours that are well-defined
  kmaxcalc <- min(n-1, kmax)

  # calculate k-nn distances for k <= kmaxcalc
  
  if(kmaxcalc == 1) {
    # calculate nearest neighbour distance only
    nnd<-numeric(n)
    o <- fave.order(z)
    big <- sqrt(.Machine$double.xmax)
    Cout <- .C("nnd3D",
               n= as.integer(n),
               x= as.double(x[o]),
               y= as.double(y[o]),
               z= as.double(z[o]),
               nnd= as.double(nnd),
               nnwhich = as.integer(integer(1)),
               huge=as.double(big))
    nnd[o] <- Cout$nnd
  } else {
    # case kmaxcalc > 1
    nnd<-numeric(n * kmaxcalc)
    o <- fave.order(z)
    big <- sqrt(.Machine$double.xmax)
    Cout <- .C("knnd3D",
               n    = as.integer(n),
               kmax = as.integer(kmaxcalc),
               x    = as.double(x[o]),
               y    = as.double(y[o]),
               z    = as.double(z[o]),
               nnd  = as.double(nnd),
               nnwhich = as.integer(integer(1)),
               huge = as.double(big))
    nnd <- matrix(nnd, nrow=n, ncol=kmaxcalc)
    nnd[o, ] <- matrix(Cout$nnd, nrow=n, ncol=kmaxcalc, byrow=TRUE)
  }

  # post-processing
  if(kmax > kmaxcalc) {
    # add columns of Inf's
    infs <- matrix(as.numeric(Inf), nrow=n, ncol=kmax-kmaxcalc)
    nnd <- cbind(nnd, infs)
  }

  if(length(k) < kmax) {
    # select only the specified columns
    nnd <- nnd[, k, drop=TRUE]
  }
  
  return(nnd)
}

nnwhich.pp3 <- function(X, ..., k=1) {
  verifyclass(X, "pp3")
  if((narg <- length(list(...))) > 0) 
    warning(paste(narg, "unrecognised",
                  ngettext(narg, "argument was", "arguments were"),
                  "ignored"))
  
  # k can be a single integer or an integer vector
  if(length(k) == 0)
    stop("k is an empty vector")
  else if(length(k) == 1) {
    if(k != round(k) || k <= 0)
      stop("k is not a positive integer")
  } else {
    if(any(k != round(k)) || any(k <= 0))
      stop(paste("some entries of the vector",
           sQuote("k"), "are not positive integers"))
  }
  k <- as.integer(k)
  kmax <- max(k)

  # extract point coordinates
  xyz <- coords(X)
  n <- nrow(xyz)
  x <- xyz$x
  y <- xyz$y
  z <- xyz$z
  
  # special cases
  if(n <= 1) {
    # empty pattern => return integer(0)
    # or pattern with only 1 point => return NA
    nnw <- matrix(as.integer(NA), nrow=n, ncol=kmax)
    nnw <- nnw[,k, drop=TRUE]
    return(nnw)
  }

  # number of neighbours that are well-defined
  kmaxcalc <- min(n-1, kmax)

  # identify k-nn for k <= kmaxcalc

  if(kmaxcalc == 1) {
    # identify nearest neighbour only
    nnw <- integer(n)
    o <- fave.order(z)
    big <- sqrt(.Machine$double.xmax)
    Cout <- .C("nnw3D",
               n = as.integer(n),
               x = as.double(x[o]),
               y = as.double(y[o]),
               z = as.double(z[o]),
               nnd = as.double(numeric(1)),
               nnwhich = as.integer(nnw),
               huge = as.double(big))
    # [sic] Conversion from C to R indexing is done in C code.
    witch <- Cout$nnwhich
    if(any(witch <= 0))
      stop("Internal error: illegal index returned from C code")
    if(any(witch > n))
      stop("Internal error: index returned from C code exceeds n")
    nnw[o] <- o[witch]
  } else {
    # case kmaxcalc > 1
    nnw <- matrix(integer(n * kmaxcalc), nrow=n, ncol=kmaxcalc)
    o <- fave.order(z)
    big <- sqrt(.Machine$double.xmax)
    Cout <- .C("knnw3D",
               n = as.integer(n),
               kmax = as.integer(kmaxcalc),
               x = as.double(x[o]),
               y = as.double(y[o]),
               z = as.double(z[o]),
               nnd = as.double(numeric(1)),
               nnwhich = as.integer(nnw),
               huge = as.double(big))
    # [sic] Conversion from C to R indexing is done in C code.
    witch <- Cout$nnwhich 
    witch <- matrix(witch, nrow=n, ncol=kmaxcalc, byrow=TRUE)
    if(any(witch <= 0))
      stop("Internal error: illegal index returned from C code")
    if(any(witch > n))
      stop("Internal error: index returned from C code exceeds n")
    # convert back to original ordering
    nnw[o,] <- matrix(o[witch], nrow=n, ncol=kmaxcalc)
  }
  
  # post-processing
  if(kmax > kmaxcalc) {
    # add columns of NA's
    nas <- matrix(as.integer(NA), nrow=n, ncol=kmax-kmaxcalc)
    nnw <- cbind(nnw, nas)
  }

  if(length(k) < kmax) {
    # select only the specified columns
    nnw <- nnw[, k, drop=TRUE]
  }
  return(nnw)
}

crossdist.pp3 <- function(X, Y, ..., periodic=FALSE, squared=FALSE) {
  verifyclass(X, "pp3")
  verifyclass(Y, "pp3")

  cX <- coords(X)
  cY <- coords(Y)
  nX <- nrow(cX)
  nY <- nrow(cY)

  if(nX == 0 || nY == 0)
    return(matrix(numeric(0), nrow=nX, ncol=nY))

  if(!periodic) {
    Cout <- .C("D3crossdist",
               nfrom = as.integer(nX),
               xfrom = as.double(cX$x),
               yfrom = as.double(cX$y),
               zfrom = as.double(cX$z),
               nto = as.integer(nY),
               xto = as.double(cY$x),
               yto = as.double(cY$y),
               zto = as.double(cY$z),
               squared = as.integer(squared),
               d = as.double(matrix(0, nrow=nX, ncol=nY)))
  } else {
    b <- as.box3(X)
    wide <- diff(b$xrange)
    high <- diff(b$yrange)
    deep <- diff(b$zrange)
    Cout <- .C("D3crossPdist",
               nfrom = as.integer(nX),
               xfrom = as.double(cX$x),
               yfrom = as.double(cX$y),
               zfrom = as.double(cX$z),
               nto = as.integer(nY),
               xto = as.double(cY$x),
               yto = as.double(cY$y),
               zto = as.double(cY$z),
               xwidth = as.double(wide),
               yheight = as.double(high),
               zheight = as.double(deep),
               squared = as.integer(squared),
               d = as.double(matrix(0, nrow=nX, ncol=nY)))
  }
  return(matrix(Cout$d, nrow=nX, ncol=nY))
}
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/distances.R"
#
#      distances.R
#
#      $Revision: 1.45 $     $Date: 2014/10/24 00:22:30 $
#
#
#      Interpoint distances between pairs 
#
#

pairdist <- function(X, ...) {
  UseMethod("pairdist")
}

pairdist.ppp <- function(X, ..., periodic=FALSE, method="C", squared=FALSE) {
  verifyclass(X, "ppp")
  if(!periodic)
    return(pairdist.default(X$x, X$y, method=method, squared=squared))
  # periodic case
  W <- X$window
  if(W$type != "rectangle")
    stop(paste("periodic edge correction can't be applied",
               "in a non-rectangular window"))
  wide <- diff(W$xrange)
  high <- diff(W$yrange)
  return(pairdist.default(X$x, X$y, period=c(wide,high),
                          method=method, squared=squared))
}


pairdist.default <-
  function(X, Y=NULL, ..., period=NULL, method="C", squared=FALSE)
{
  xy <- xy.coords(X,Y)[c("x","y")]
  x <- xy$x
  y <- xy$y

  n <- length(x)
  if(length(y) != n)
    stop("lengths of x and y do not match")

  # special cases
  if(n == 0)
    return(matrix(numeric(0), nrow=0, ncol=0))
  else if(n == 1)
    return(matrix(0,nrow=1,ncol=1))

  if((periodic<- !is.null(period))) {
    stopifnot(is.numeric(period))
    stopifnot(length(period) == 2 || length(period) == 1)
    stopifnot(all(period > 0))
    if(length(period) == 1) period <- rep.int(period, 2)
    wide <- period[1]
    high <- period[2]
  }

  switch(method,
         interpreted={
           xx <- matrix(rep.int(x, n), nrow = n)
           yy <- matrix(rep.int(y, n), nrow = n)
           if(!periodic) {
             d2 <- (xx - t(xx))^2 + (yy - t(yy))^2
           } else {
             dx <- xx - t(xx)
             dy <- yy - t(yy)
             dx2 <- pmin.int(dx^2, (dx + wide)^2, (dx - wide)^2)
             dy2 <- pmin.int(dy^2, (dy + high)^2, (dy - high)^2)
             d2 <- dx2 + dy2
           }
           if(squared)
             dout <- d2
           else
             dout <- sqrt(d2)
         },
         C={
           d <- numeric( n * n)
           if(!periodic) {
               z<- .C("Cpairdist",
                      n = as.integer(n),
                      x= as.double(x),
                      y= as.double(y),
                      squared=as.integer(squared),
                      d= as.double(d))
           } else {
             z <- .C("CpairPdist",
                     n = as.integer(n),
                     x= as.double(x),
                     y= as.double(y),
                     xwidth=as.double(wide),
                     yheight=as.double(high),
                     squared = as.integer(squared),
                     d= as.double(d))
           }
           dout <- matrix(z$d, nrow=n, ncol=n)
         },
         stop(paste("Unrecognised method", sQuote(method)))
       )
  return(dout)
}


crossdist <- function(X, Y, ...) {
  UseMethod("crossdist")
}

crossdist.ppp <- function(X, Y, ...,
                          periodic=FALSE, method="C", squared=FALSE) {
  verifyclass(X, "ppp")
  Y <- as.ppp(Y)
  if(!periodic)
    return(crossdist.default(X$x, X$y, Y$x, Y$y,
                             method=method, squared=squared))
  # periodic case
  WX <- X$window
  WY <- Y$window
  if(WX$type != "rectangle" || WY$type != "rectangle")
    stop(paste("periodic edge correction can't be applied",
               "in non-rectangular windows"))
  if(!is.subset.owin(WX,WY) || !is.subset.owin(WY, WX))
    stop(paste("periodic edge correction is not implemented",
               "for the case when X and Y lie in different rectangles"))
  wide <- diff(WX$xrange)
  high <- diff(WX$yrange)
  return(crossdist.default(X$x, X$y, Y$x, Y$y,
                           period=c(wide,high),
                           method=method, squared=squared))
}

crossdist.default <-
  function(X, Y, x2, y2, ..., period=NULL, method="C", squared=FALSE)
{
  x1 <- X
  y1 <- Y
  # returns matrix[i,j] = distance from (x1[i],y1[i]) to (x2[j],y2[j])
  if(length(x1) != length(y1))
    stop("lengths of x and y do not match")
  if(length(x2) != length(y2))
    stop("lengths of x2 and y2 do not match")
  n1 <- length(x1)
  n2 <- length(x2)
  if(n1 == 0 || n2 == 0)
    return(matrix(numeric(0), nrow=n1, ncol=n2))

  if((periodic<- !is.null(period))) {
    stopifnot(is.numeric(period))
    stopifnot(length(period) == 2 || length(period) == 1)
    stopifnot(all(period > 0))
    if(length(period) == 1) period <- rep.int(period, 2)
    wide <- period[1]
    high <- period[2]
  }

   switch(method,
         interpreted = {
                 X1 <- matrix(rep.int(x1, n2), ncol = n2)
                 Y1 <- matrix(rep.int(y1, n2), ncol = n2)
                 X2 <- matrix(rep.int(x2, n1), ncol = n1)
                 Y2 <- matrix(rep.int(y2, n1), ncol = n1)
                 if(!periodic) 
                   d2 <- (X1 - t(X2))^2 + (Y1 - t(Y2))^2
                 else {
                   dx <- X1 - t(X2)
                   dy <- Y1 - t(Y2)
                   dx2 <- pmin.int(dx^2, (dx + wide)^2, (dx - wide)^2)
                   dy2 <- pmin.int(dy^2, (dy + high)^2, (dy - high)^2)
                   d2 <- dx2 + dy2
                 }
                 return(if(squared) d2 else sqrt(d2))
               },
               C = {
                 if(!periodic) {
                   z<- .C("Ccrossdist",
                          nfrom = as.integer(n1),
                          xfrom = as.double(x1),
                          yfrom = as.double(y1),
                          nto = as.integer(n2),
                          xto = as.double(x2),
                          yto = as.double(y2),
                          squared = as.integer(squared),
                          d = as.double(matrix(0, nrow=n1, ncol=n2)))
                 } else {
                   z<- .C("CcrossPdist",
                          nfrom = as.integer(n1),
                          xfrom = as.double(x1),
                          yfrom = as.double(y1),
                          nto = as.integer(n2),
                          xto = as.double(x2),
                          yto = as.double(y2),
                          xwidth = as.double(wide),
                          yheight = as.double(high),
                          squared = as.integer(squared),
                          d = as.double(matrix(0, nrow=n1, ncol=n2)))
                 }
                 return(matrix(z$d, nrow=n1, ncol=n2))
               },
               stop(paste("Unrecognised method", method))
               )
      }

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/distances.psp.R"
#
#  distances.psp.R
#
#  Hausdorff distance and Euclidean separation for psp objects
#
#  $Revision: 1.10 $ $Date: 2014/10/24 00:22:30 $
#
#

pairdist.psp <- function(X, ..., method="Fortran", type="Hausdorff") {
  verifyclass(X, "psp")
  if(X$n == 0)
    return(matrix(, 0, 0))
  type <- pickoption("type", type,
                     c(Hausdorff="Hausdorff",
                       hausdorff="Hausdorff",
                       separation="separation"))

  D12 <- AsymmDistance.psp(X, X, metric=type, method=method)

  switch(type,
         Hausdorff={
           # maximum is Hausdorff metric
           D <- array(pmax.int(D12, t(D12)), dim=dim(D12))
         },
         separation={
           # Take minimum of endpoint-to-segment distances
           D <- array(pmin.int(D12, t(D12)), dim=dim(D12))
           # Identify any pairs of segments which cross
           cross <- test.selfcrossing.psp(X)
           # Assign separation = 0 to such pairs
           D[cross] <- 0
         })
  return(D)
}

crossdist.psp <- function(X, Y, ..., method="Fortran", type="Hausdorff") {
  verifyclass(X, "psp")
  Y <- as.psp(Y)
  if(X$n * Y$n == 0)
    return(matrix(, X$n, Y$n))

  type <- pickoption("type", type,
                     c(Hausdorff="Hausdorff",
                       hausdorff="Hausdorff",
                       separation="separation"))
  
  DXY <- AsymmDistance.psp(X, Y, metric=type, method=method)
  DYX <- AsymmDistance.psp(Y, X, metric=type, method=method)
  
  switch(type,
         Hausdorff={
           # maximum is Hausdorff metric
           D <- array(pmax.int(DXY, t(DYX)), dim=dim(DXY))
         },
         separation={
           # Take minimum of endpoint-to-segment distances
           D <- array(pmin.int(DXY, t(DYX)), dim=dim(DXY))
           # Identify pairs of segments which cross
           cross <- test.crossing.psp(X, Y)
           # Assign separation = 0 to such pairs
           D[cross] <- 0
         })
  return(D)
}

nndist.psp <- function(X, ..., k=1, method="Fortran") {
  verifyclass(X, "psp")
  if(!(is.vector(k) && all(k %% 1 == 0) && all(k >= 1)))
    stop("k should be a positive integer or integers")
  n <- nobjects(X)
  kmax <- max(k)
  lenk <- length(k)
  result <- if(lenk == 1) numeric(n) else matrix(, nrow=n, ncol=lenk)
  if(n == 0)
    return(result)
  if(kmax >= n) {
    # not enough objects 
    # fill with Infinite values
    result[] <- Inf
    if(any(ok <- (kmax < n))) {
      # compute the lower-order nnd's
      result[, ok] <- nndist.psp(X, ..., k=k[ok], method=method)
    }
    return(result)
  }
  # normal case:
  D <- pairdist.psp(X, ..., method=method)
  diag(D) <- Inf
  if(kmax == 1) 
    NND <- apply(D, 1, min)
  else 
    NND <- t(apply(D, 1, function(z,k) { sort(z)[k] }, k=k))[, , drop=TRUE]
  return(NND)
}

# .....  AsymmDistance.psp .....
#
# If metric="Hausdorff":
#     this function computes, for each pair of segments A = X[i] and B = Y[j],
#     the value max_{a in A} d(a,B) = max_{a in A} min_{b in B} ||a-b||
#     which appears in the definition of the Hausdorff metric.
#     Since the distance function d(a,B) of a segment B is a convex function,
#     the maximum is achieved at an endpoint of A. So the algorithm
#     actually computes h(A,B) = max (d(e_1,B), d(e_2,B)) where e_1, e_2
#     are the endpoints of A. And H(A,B) = max(h(A,B),h(B,A)).
#
# If metric="separation":
#     the function computes, for each pair of segments A = X[i] and B = Y[j],
#     the MINIMUM distance from an endpoint of A to any point of B.
#        t(A,B) = min (d(e_1,B), d(e_2,B))
#     where e_1, e_2 are the endpoints of A.
#     Define the separation distance
#        s(A,B) = min_{a in A} min_{b in B} ||a-b||.
#     The minimum (a*, b*) occurs either when a* is an endpoint of A,
#     or when b* is an endpoint of B, or when a* = b* (so A and B intersect).
#     (If A and B are parallel, the minimum is still achieved at an endpoint)
#     Thus s(A,B) = min(t(A,B), t(B,A)) unless A and B intersect.


AsymmDistance.psp <- function(X, Y, metric="Hausdorff",
                              method=c("Fortran", "C", "interpreted")) {
  method <- match.arg(method)
  # Extract endpoints of X
  EX <- endpoints.psp(X, "both")
  idX <- attr(EX, "id")
  # compute shortest dist from each endpoint of X to each segment of Y
  DPL <- distppll(cbind(EX$x,EX$y), Y$ends, mintype=0, method=method)
  # for each segment in X, maximise or minimise over the two endpoints
  Dist <- as.vector(DPL)
  Point <- as.vector(idX[row(DPL)])
  Segment <- as.vector(col(DPL))
  switch(metric,
         Hausdorff={
           DXY <- tapply(Dist, list(factor(Point), factor(Segment)), max)
         },
         separation={
           DXY <- tapply(Dist, list(factor(Point), factor(Segment)), min)
           })
  return(DXY)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/distanxD.R"
#
#      distanxD.R
#
#      $Revision: 1.6 $     $Date: 2014/10/24 00:22:30 $
#
#      Interpoint distances for multidimensional points
#
#      Methods for pairdist, nndist, nnwhich, crossdist
#

pairdist.ppx <- function(X, ...) {
  verifyclass(X, "ppx")
  # extract point coordinates
  coo <- as.matrix(coords(X, ...))
  n <- nrow(coo)
  if(n == 0)
    return(matrix(numeric(0), nrow=0, ncol=0))
  return(as.matrix(dist(coo)))
}

crossdist.ppx <- function(X, Y, ...) {
  verifyclass(X, "ppx")
  verifyclass(Y, "ppx")
  # extract point coordinates
  cooX <- as.matrix(coords(X, ...))
  cooY <- as.matrix(coords(Y, ...))
  nX <- nrow(cooX)
  nY <- nrow(cooY)
  if(ncol(cooX) != ncol(cooY))
    stop("X and Y have different dimensions (different numbers of coordinates)")
  if(nX == 0 || nY == 0)
    return(matrix(numeric(0), nrow=nX, ncol=nY))
  coo <- rbind(cooX, cooY)
  dis <- as.matrix(dist(coo))
  ans <- dis[1:nX, nX + (1:nY)]
  return(ans)
}

nndist.ppx <- function(X, ..., k=1) {
  verifyclass(X, "ppx")

  # extract point coordinates
  coo <- as.matrix(coords(X, ...))
  n <- nrow(coo)
  m <- ncol(coo)

  if(m == 0) {
    warning("nndist.ppx: Zero-dimensional coordinates: returning NA")
    if(length(k) == 1)
      return(rep.int(NA_real_, n))
    else
      return(matrix(NA_real_, n, length(k)))
  }
  
  # k can be a single integer or an integer vector
  if(length(k) == 0)
    stop("k is an empty vector")
  else if(length(k) == 1) {
    if(k != round(k) || k <= 0)
      stop("k is not a positive integer")
  } else {
    if(any(k != round(k)) || any(k <= 0))
      stop(paste("some entries of the vector",
           sQuote("k"), "are not positive integers"))
  }
  k <- as.integer(k)
  kmax <- max(k)

  # trivial cases
  if(n <= 1) {
    # empty pattern => return numeric(0)
    # or pattern with only 1 point => return Inf
    nnd <- matrix(Inf, nrow=n, ncol=kmax)
    nnd <- nnd[,k, drop=TRUE]
    return(nnd)
  }
  
  # number of neighbours that are well-defined
  kmaxcalc <- min(n-1, kmax)

  # calculate k-nn distances for k <= kmaxcalc
  
  if(kmaxcalc == 1) {
    # calculate nearest neighbour distance only
    nnd<-numeric(n)
    o <- fave.order(coo[,1])
    big <- sqrt(.Machine$double.xmax)
    Cout <- .C("nndMD",
               n= as.integer(n),
               m=as.integer(m),
               x= as.double(t(coo[o,])),
               nnd= as.double(nnd),
               as.double(big))
    nnd[o] <- Cout$nnd
  } else {
    # case kmaxcalc > 1
    nnd<-numeric(n * kmaxcalc)
    o <- fave.order(coo[,1])
    big <- sqrt(.Machine$double.xmax)
    Cout <- .C("knndMD",
               n    = as.integer(n),
               m    = as.integer(m),
               kmax = as.integer(kmaxcalc),
               x    = as.double(t(coo[o,])),
               nnd  = as.double(nnd),
               huge = as.double(big))
    nnd <- matrix(nnd, nrow=n, ncol=kmaxcalc)
    nnd[o, ] <- matrix(Cout$nnd, nrow=n, ncol=kmaxcalc, byrow=TRUE)
  }

  # post-processing
  if(kmax > kmaxcalc) {
    # add columns of Inf's
    infs <- matrix(as.numeric(Inf), nrow=n, ncol=kmax-kmaxcalc)
    nnd <- cbind(nnd, infs)
  }

  if(length(k) < kmax) {
    # select only the specified columns
    nnd <- nnd[, k, drop=TRUE]
  }
  
  return(nnd)
}

nnwhich.ppx <- function(X, ..., k=1) {
  verifyclass(X, "ppx")
  # k can be a single integer or an integer vector
  if(length(k) == 0)
    stop("k is an empty vector")
  else if(length(k) == 1) {
    if(k != round(k) || k <= 0)
      stop("k is not a positive integer")
  } else {
    if(any(k != round(k)) || any(k <= 0))
      stop(paste("some entries of the vector",
           sQuote("k"), "are not positive integers"))
  }
  k <- as.integer(k)
  kmax <- max(k)

  # extract point coordinates
  coo <- coords(X, ...)
  n <- nrow(coo)
  m <- ncol(coo)
  
  if(m == 0) {
    warning("nnwhich.ppx: Zero-dimensional coordinates: returning NA")
    if(length(k) == 1)
      return(rep.int(NA_real_, n))
    else
      return(matrix(NA_real_, n, length(k)))
  }
  
  # special cases
  if(n <= 1) {
    # empty pattern => return integer(0)
    # or pattern with only 1 point => return NA
    nnw <- matrix(NA_integer_, nrow=n, ncol=kmax)
    nnw <- nnw[,k, drop=TRUE]
    return(nnw)
  }

  # number of neighbours that are well-defined
  kmaxcalc <- min(n-1, kmax)

  # identify k-nn for k <= kmaxcalc

  if(kmaxcalc == 1) {
    # identify nearest neighbour only
    nnw <- integer(n)
    o <- fave.order(coo[,1])
    big <- sqrt(.Machine$double.xmax)
    Cout <- .C("nnwMD",
               n = as.integer(n),
               m = as.integer(m),
               x = as.double(t(coo[o,])),
               nnd = as.double(numeric(n)),
               nnwhich = as.integer(nnw),
               huge = as.double(big))
    witch <- Cout$nnwhich
    if(any(witch <= 0))
      stop("Internal error: non-positive index returned from C code")
    if(any(witch > n))
      stop("Internal error: index returned from C code exceeds n")
    nnw[o] <- o[witch]
  } else {
    # case kmaxcalc > 1
    nnw <- matrix(integer(n * kmaxcalc), nrow=n, ncol=kmaxcalc)
    o <- fave.order(coo[,1])
    big <- sqrt(.Machine$double.xmax)
    Cout <- .C("knnwMD",
               n = as.integer(n),
               m = as.integer(m),
               kmax = as.integer(kmaxcalc),
               x = as.double(t(coo[o,])),
               nnd = as.double(numeric(n * kmaxcalc)),
               nnwhich = as.integer(nnw),
               huge = as.double(big))
    witch <- Cout$nnwhich
    witch <- matrix(witch, nrow=n, ncol=kmaxcalc, byrow=TRUE)
    if(any(witch <= 0))
      stop("Internal error: non-positive index returned from C code")
    if(any(witch > n))
      stop("Internal error: index returned from C code exceeds n")
    # convert back to original ordering
    nnw[o,] <- matrix(o[witch], nrow=n, ncol=kmaxcalc)
  }
  
  # post-processing
  if(kmax > kmaxcalc) {
    # add columns of NA's
    nas <- matrix(NA_integer_, nrow=n, ncol=kmax-kmaxcalc)
    nnw <- cbind(nnw, nas)
  }

  if(length(k) < kmax) {
    # select only the specified columns
    nnw <- nnw[, k, drop=TRUE]
  }
  return(nnw)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/distbdry.R"
#
#	distbdry.S		Distance to boundary
#
#	$Revision: 4.38 $	$Date: 2014/08/04 09:55:14 $
#
# -------- functions ----------------------------------------
#
#	bdist.points()
#                       compute vector of distances 
#			from each point of point pattern
#                       to boundary of window
#
#       bdist.pixels()
#                       compute matrix of distances from each pixel
#                       to boundary of window
#
#       erodemask()    erode the window mask by a distance r
#                       [yields a new window]
#
#
# 
"bdist.points"<-
function(X)
{
	verifyclass(X, "ppp") 
        if(X$n == 0)
          return(numeric(0))
	x <- X$x
	y <- X$y
	window <- X$window
        switch(window$type,
               rectangle = {
		xmin <- min(window$xrange)
		xmax <- max(window$xrange)
		ymin <- min(window$yrange)
		ymax <- max(window$yrange)
		result <- pmin.int(x - xmin, xmax - x, y - ymin, ymax - y)
               },
               polygonal = {
                 xy <- cbind(x,y)
                 result <- rep.int(Inf, X$n)
                 bdry <- window$bdry
                 for(i in seq_along(bdry)) {
                   polly <- bdry[[i]]
                   px <- polly$x
                   py <- polly$y
                   nsegs <- length(px)
                   for(j in seq_len(nsegs)) {
                     j1 <- if(j < nsegs) j + 1 else 1
                     seg <- c(px[j],  py[j],
                              px[j1], py[j1])
                     result <- pmin.int(result, distppl(xy, seg))
                   }
                 }
               },
               mask = {
                 b <- bdist.pixels(window, style="matrix")
                 loc <- nearest.raster.point(x,y,window)
                 result <- b[cbind(loc$row, loc$col)]
               },
               stop("Unrecognised window type", window$type)
               )
        return(result)
}

"bdist.pixels" <- function(w, ..., style="image") {
	verifyclass(w, "owin")

        masque <- as.mask(w, ...)
        
        switch(w$type,
               mask = {
                 neg <- complement.owin(masque)
                 m <- exactPdt(neg)
                 b <- pmin.int(m$d,m$b)
               },
               rectangle = {
                 rxy <- rasterxy.mask(masque)
                 x <- rxy$x
                 y <- rxy$y
                 xmin <- w$xrange[1]
                 xmax <- w$xrange[2]
                 ymin <- w$yrange[1]
                 ymax <- w$yrange[2]
                 b <- pmin.int(x - xmin, xmax - x, y - ymin, ymax - y)
               },
               polygonal = {
                 # set up pixel raster
                 rxy <- rasterxy.mask(masque)
                 x <- rxy$x
                 y <- rxy$y
                 b <- numeric(length(x))
                 # test each pixel in/out, analytically
                 inside <- inside.owin(x, y, w)
                 # compute distances for these pixels
                 xy <- cbind(x[inside], y[inside])
                 dxy <- rep.int(Inf, sum(inside))
                 bdry <- w$bdry
                 for(i in seq_along(bdry)) {
                   polly <- bdry[[i]]
                   nsegs <- length(polly$x)
                   for(j in 1:nsegs) {
                     j1 <- if(j < nsegs) j + 1 else 1
                     seg <- c(polly$x[j],  polly$y[j],
                              polly$x[j1], polly$y[j1])
                     dxy <- pmin.int(dxy, distppl(xy, seg))
                   }
                 }
                 b[inside] <- dxy
               },
               stop("unrecognised window type", w$type)
               )

        # reshape it
        b <- matrix(b, nrow=masque$dim[1], ncol=masque$dim[2])

        switch(style,
               coords={
                 # format which can be plotted by image(), persp() etc
                 return(list(x=masque$xcol, y=masque$yrow, z=t(b)))
               },
               matrix={
                 # return matrix (for internal use by package)
                 return(b)
               },
               image={
                 bim <- im(b, xcol=masque$xcol, yrow=masque$yrow,
                           unitname=unitname(masque))
                 return(bim)
               },
               stop(paste("Unrecognised option for style:", style)))
} 

erodemask <- function(w, r, strict=FALSE) {
  # erode a binary image mask without changing any other entries
  verifyclass(w, "owin")
  if(w$type != "mask")
    stop(paste("window w is not of type", sQuote("mask")))
  if(!is.numeric(r) || length(r) != 1)
    stop("r must be a single number")
  if(r < 0)
    stop("r must be nonnegative")
        
  bb <- bdist.pixels(w, style="matrix")

  if(r > max(bb))
    warning("eroded mask is empty")

  if(identical(strict, TRUE))
    w$m <- (bb > r)
  else 
    w$m <- (bb >= r)
  return(w)
}

"Frame<-.owin" <- function(X, value) {
  stopifnot(is.rectangle(value))
  W <- Frame(X)
  if(!is.subset.owin(W, value))
    W <- intersect.owin(W, value)
  rebound.owin(X, value)
}

rebound.owin <- function(x, rect) {
  w <- x
  verifyclass(rect, "owin")
  if(is.empty(w))
    return(emptywindow(rect))
  verifyclass(w, "owin")
  if(!is.subset.owin(as.rectangle(w), rect)) {
    bb <- boundingbox(w)
    if(!is.subset.owin(bb, rect))
      stop(paste("The new rectangle",
                 sQuote("rect"),
                 "does not contain the window",
                 sQuote("win")))
  }
  xr <- rect$xrange
  yr <- rect$yrange
  switch(w$type,
         rectangle={
           return(owin(xr, yr,
                       poly=list(x=w$xrange[c(1,2,2,1)],
                                 y=w$yrange[c(1,1,2,2)])))
         },
         polygonal={
           return(owin(xr, yr, poly=w$bdry, check=FALSE))
         },
         mask={
           newseq <- function(oldseq, newrange, dstep) {
             oldends <- range(oldseq)
             nleft <- max(0, floor((oldends[1] - newrange[1])/dstep))
             nright <- max(0, floor((newrange[2] - oldends[2])/dstep))
             newstart <- max(oldends[1] - nleft * dstep, newrange[1])
             newend <- min(oldends[2] + nright * dstep, newrange[2])
             seq(from=newstart, by=dstep, to=newend)
           }
           xcol <- newseq(w$xcol, xr, mean(diff(w$xcol)))
           yrow <- newseq(w$yrow, yr, mean(diff(w$yrow)))
           newmask <- as.mask(xy=list(x=xcol, y=yrow))
           xx <- rasterx.mask(newmask)
           yy <- rastery.mask(newmask)
           newmask$m <- inside.owin(xx, yy, w)
           return(newmask)
         }
         )
}
  
    
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/distcdf.R"
#
#  distcdf.R
#
# cdf of |X1-X2| when X1,X2 are iid uniform in W, etc
#
#  $Revision: 1.7 $  $Date: 2014/10/24 00:22:30 $
#

distcdf <- function(W, V=W, ..., dW=1, dV=dW, nr=1024) {
  reflexive <- missing(V) && missing(dV)
  diffuse <- is.owin(W) && is.owin(V)
  uniformW <- identical(dW, 1)
  uniformV <- identical(dV, 1)
  uniform <- uniformW && uniformV
  
  if(is.owin(W)) {
    W <- as.mask(as.owin(W), ...)
    dW <- as.im(dW, W=W)
  } else if(is.ppp(W)) {
    if(uniformW) {
      # discrete uniform distribution on W
      dW <- pixellate(W, ...)
    } else {
      # dW should be a weight or vector of weights
      if(!is.vector(dW) || !is.numeric(dW))
        stop("If W is a point pattern, dW should be a vector of weights")
      if(length(dW) == 1) {
        dW <- rep(dW, npoints(W))
      } else stopifnot(length(dW) == npoints(W))
      dW <- pixellate(W, weights=dW, ...)
    }
  } else stop("W should be a point pattern or a window")
  
   if(is.owin(V)) {
    V <- as.mask(as.owin(V), ...)
    dV <- as.im(dV, W=V)
  } else if(is.ppp(V)) {
    if(uniformV) {
      # discrete uniform distribution on V
      dV <- pixellate(V, ...)
    } else {
      # dV should be a weight or vector of weights
      if(!is.vector(dV) || !is.numeric(dV))
        stop("If V is a point pattern, dV should be a vector of weights")
      if(length(dV) == 1) {
        dV <- rep(dV, npoints(V))
      } else stopifnot(length(dV) == npoints(V))
      dV <- pixellate(V, weights=dV, ...)
    }
  } else stop("V should be a point pattern or a window")

  # compute
  if(diffuse && uniform) {
    # uniform distributions on windows 
    g <- if(reflexive) setcov(W, ...) else setcov(W, V, ...)
  } else {
    g <- if(reflexive) imcov(dW) else imcov(dW, dV)
  }
  r <- as.im(function(x,y) { sqrt(x^2 + y^2) }, g)
  rvals <- as.vector(as.matrix(r))
  gvals <- as.vector(as.matrix(g))
  rgrid <- seq(0, max(rvals), length=nr)
  h <- whist(rvals, breaks=rgrid, weights=gvals/sum(gvals))
  ch <- c(0,cumsum(h))
  result <- fv(data.frame(r=rgrid, f=ch),
                "r", quote(CDF(r)),
               "f", , range(rvals), c("r","%s(r)"),
               c("Interpoint distance","Cumulative probability"),
               fname="CDF")
  return(result)
}

bw.frac <- function(X, ..., f=1/4) {
  X <- as.owin(X)
  g <- distcdf(X, ...)
  r <- with(g, .x)
  Fr <- with(g, .y)
  iopt <- min(which(Fr >= f))
  ropt <- r[iopt]
  attr(ropt, "f") <- f
  attr(ropt, "g") <- g
  class(ropt) <- c("bw.frac", class(ropt))
  return(ropt)
}

print.bw.frac <- function(x, ...) {
  print(as.numeric(x), ...)
}

plot.bw.frac <- function(x, ...) {
  xname <- short.deparse(substitute(x))
  g <- attr(x, "g")
  f <- attr(x, "f")
  ropt <- as.numeric(x)
  do.call("plot",
          resolve.defaults(list(g),
                             list(...),
                             list(main=xname)))
  abline(v=ropt, lty=3)
  abline(h=f, lty=3)
  invisible(NULL)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/distfun.R"
#
#   distfun.R
#
#   distance function (returns a function of x,y)
#
#   $Revision: 1.22 $   $Date: 2014/10/24 00:22:30 $
#

distfun <- function(X, ...) {
  UseMethod("distfun")
}

distfun.ppp <- function(X, ..., k=1) {
  # this line forces X to be bound
  stopifnot(is.ppp(X))
  stopifnot(length(k) == 1)
  g <- function(x,y=NULL) {
    Y <- xy.coords(x, y)[c("x", "y")]
    nncross(Y, X, what="dist", k=k)
  }
  attr(g, "Xclass") <- "ppp"
  g <- funxy(g, as.rectangle(as.owin(X)))
  attr(g, "k") <- k
  class(g) <- c("distfun", class(g))
  return(g)
}

distfun.psp <- function(X, ...) {
  # this line forces X to be bound
  stopifnot(is.psp(X))
  g <- function(x,y=NULL) {
    Y <-  xy.coords(x, y)[c("x", "y")]
    nncross(Y, X, what="dist")
  }
  attr(g, "Xclass") <- "psp"
  g <- funxy(g, as.rectangle(as.owin(X)))
  class(g) <- c("distfun", class(g))
  return(g)
}

distfun.owin <- function(X, ..., invert=FALSE) {
  # this line forces X to be bound
  stopifnot(is.owin(X))
  #
  P <- edges(X)
  #
  g <- function(x,y=NULL) {
    Y <-  xy.coords(x, y)
    inside <- inside.owin(Y$x, Y$y, X)
    D <- nncross(Y, P, what="dist")
    out <- if(!invert) ifelseAX(inside, 0, D) else ifelseXB(inside, D, 0)
    return(out)
  }
  attr(g, "Xclass") <- "owin"
  g <- funxy(g, as.rectangle(as.owin(X)))
  class(g) <- c("distfun", class(g))
  return(g)
}

as.owin.distfun <- function(W, ..., fatal=TRUE) {
  X <- get("X", envir=environment(W))
  result <- if(is.owin(X)) as.rectangle(X) else as.owin(X, ..., fatal=fatal)
  return(result)
}

domain.distfun <- Window.distfun <- function(X, ...) { as.owin(X) }

as.im.distfun <- function(X, W=NULL, ...,
                           eps=NULL, dimyx=NULL, xy=NULL,
                           na.replace=NULL) {
  k <- attr(X, "k")
  if(is.null(W) && (is.null(k) || (k == 1))) {
    # use 'distmap' for speed
    env <- environment(X)
    Xdata  <- get("X",      envir=env)
    args <- list(X=Xdata, eps=eps, dimyx=dimyx, xy=xy)
    if(is.owin(Xdata)) {
      args <- append(args, list(invert = get("invert", envir=env)))
    }
    D <- do.call(distmap, args = args)
    if(!is.null(na.replace))
      D$v[is.null(D$v)] <- na.replace
  } else if(identical(attr(X, "Xclass"), "ppp")) {
    # point pattern --- use nngrid/knngrid
    env <- environment(X)
    Xdata  <- get("X",      envir=env)
    D <- nnmap(Xdata, W=W, what="dist", k=k, 
               eps=eps, dimyx=dimyx, xy=xy, na.replace=na.replace,
               ...)
  } else {
    # evaluate function at pixel centres
    D <- as.im.function(X, W=W,
                        eps=eps, dimyx=dimyx, xy=xy, na.replace=na.replace)
  }
  return(D)
}

print.distfun <- function(x, ...) {
  xtype <- attr(x, "Xclass")
  typestring <- switch(xtype,
                       ppp="point pattern",
                       psp="line segment pattern",
                       owin="window",
                       "unrecognised object")
  objname <- switch(xtype,
                    ppp="point",
                    psp="line segment",
                    "object")
  cat(paste("Distance function for", typestring, "\n"))
  X <- get("X", envir=environment(x))
  print(X)
  if(!is.null(k <- attr(x, "k")) && k > 1)
    cat(paste("Distance to", ordinal(k), "nearest", objname,
              "will be computed\n"))
  return(invisible(NULL))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/distfunlpp.R"
#
# distfunlpp.R
#
#   method for 'distfun' for class 'lpp'
#
#   $Revision: 1.1 $ $Date: 2014/10/24 00:22:30 $
#

distfun.lpp <- local({
  
  distfun.lpp <- function(X, ...) {
    stopifnot(inherits(X, "lpp"))
    force(X)
    L <- as.linnet(X)
    f <- function(x, y=NULL, seg=NULL, tp=NULL, ...) {
      # L is part of the environment
      Y <- as.lpp(x=x, y=y, seg=seg, tp=tp, L=L)
      d <- nncross.lpp(Y, X, what="dist")
      return(d)
    }
    f <- linfun(f, L)
    attr(f, "explain") <- uitleggen
    return(f)
  }

  uitleggen <- function(x, ...) {
    cat("Distance function for lpp object\n")
    X <-  get("X", envir=environment(x))
    print(X)
  }

  distfun.lpp
})




#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/distmap.R"
#
#
#      distmap.R
#
#      $Revision: 1.20 $     $Date: 2014/10/24 00:22:30 $
#
#
#     Distance transforms
#
#
distmap <- function(X, ...) {
  UseMethod("distmap")
}

distmap.ppp <- function(X, ...) {
  verifyclass(X, "ppp")
  e <- exactdt(X, ...)
  W <- e$w
  uni <- unitname(W)
  dmat <- e$d
  imat <- e$i
  V <- im(dmat, W$xcol, W$yrow, unitname=uni)
  I <- im(imat, W$xcol, W$yrow, unitname=uni)
  if(X$window$type == "rectangle") {
    # distance to frame boundary
    bmat <- e$b
    B <- im(bmat, W$xcol, W$yrow, unitname=uni)
  } else {
    # distance to window boundary, not frame boundary
    bmat <- bdist.pixels(W, style="matrix")
    B <- im(bmat, W$xcol, W$yrow, unitname=uni)
    # clip all to window
    V <- V[W, drop=FALSE]
    I <- I[W, drop=FALSE]
    B <- B[W, drop=FALSE]
  }
  attr(V, "index") <- I
  attr(V, "bdry")  <- B
  return(V)
}

distmap.owin <- function(X, ..., discretise=FALSE, invert=FALSE) {
  verifyclass(X, "owin")
  uni <- unitname(X)
  if(X$type == "rectangle") {
    M <- as.mask(X, ...)
    Bdry <- im(bdist.pixels(M, style="matrix"),
               M$xcol, M$yrow, unitname=uni)
    if(!invert)
      Dist <- as.im(M, value=0)
    else 
      Dist <- Bdry
  } else if(X$type == "polygonal" && !discretise) {
    Edges <- edges(X)
    Dist <- distmap(Edges, ...)
    Bdry <- attr(Dist, "bdry")
    if(!invert) 
      Dist[X] <- 0
    else {
      bb <- as.rectangle(X)
      bigbox <- grow.rectangle(bb, diameter(bb)/4)
      Dist[complement.owin(X, bigbox)] <- 0
    }
  } else {
    X <- as.mask(X, ...)
    if(invert)
      X <- complement.owin(X)
    xc <- X$xcol
    yr <- X$yrow
    nr <- X$dim[1]
    nc <- X$dim[2]
# pad out the input image with a margin of width 1 on all sides
    mat <- X$m
    pad <- invert # boundary condition is opposite of value inside W
    mat <- cbind(pad, mat, pad)
    mat <- rbind(pad, mat, pad)
# call C routine
    res <- .C("distmapbin",
              as.double(X$xrange[1]),
              as.double(X$yrange[1]),
              as.double(X$xrange[2]),
              as.double(X$yrange[2]),
              nr = as.integer(nr),
              nc = as.integer(nc),
              as.logical(t(mat)),
              distances = as.double(matrix(0, ncol = nc + 2, nrow = nr + 2)),
              boundary = as.double(matrix(0, ncol = nc + 2, nrow = nr + 2)))
  # strip off margins again
    dist <- matrix(res$distances,
                   ncol = nc + 2, byrow = TRUE)[2:(nr + 1), 2:(nc +1)]
    bdist <- matrix(res$boundary,
                    ncol = nc + 2, byrow = TRUE)[2:(nr + 1), 2:(nc +1)]
  # cast as image objects
    Dist <- im(dist,  xc, yr, unitname=uni)
    Bdry <- im(bdist, xc, yr, unitname=uni)
  }
  attr(Dist, "bdry")  <- Bdry
  return(Dist)
}

distmap.psp <- function(X, ...) {
  verifyclass(X, "psp")
  W <- as.mask(X$window, ...)
  uni <- unitname(W)
  rxy <- rasterxy.mask(W)
  xp <- rxy$x
  yp <- rxy$y
  np <- length(xp)
  E <- X$ends
  big <- 2 * diameter(as.rectangle(W))^2
  dist2 <- rep.int(big, np)
  z <- .C("nndist2segs",
          xp=as.double(xp),
          yp=as.double(yp),
          npoints=as.integer(np),
          x0=as.double(E$x0),
          y0=as.double(E$y0),
          x1=as.double(E$x1),
          y1=as.double(E$y1),
          nsegments=as.integer(nrow(E)),
          epsilon=as.double(.Machine$double.eps),
          dist2=as.double(dist2),
          index=as.integer(integer(np)))
  xc <- W$xcol
  yr <- W$yrow
  Dist <- im(array(sqrt(z$dist2), dim=W$dim), xc, yr, unitname=uni)
  Indx <- im(array(z$index + 1, dim=W$dim), xc, yr, unitname=uni)
  Bdry <- im(bdist.pixels(W, style="matrix"), xc, yr, unitname=uni)
  attr(Dist, "index") <- Indx
  attr(Dist, "bdry")  <- Bdry
  return(Dist)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/dppmclass.R"
is.dppm <- function#Recognise Fitted Determinantal Point Process Models
### Check that an object inherits the class dppm
(x
 ### Any object.
 ){
    inherits(x, "dppm")
    ### A single logical value.

    ##keyword<< spatial
    ##keyword<< manip
    ##keyword<< models
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/dummify.R"
#
# dummify.R
#
# Convert a factor to a matrix of dummy variables, etc.
#
#  $Revision: 1.4 $  $Date: 2013/04/25 06:37:43 $
#

dummify <- function(x) {
  if(is.matrix(x) || is.data.frame(x)) {
    x <- as.data.frame(x)
    y <- do.call("data.frame", lapply(x, dummify))
    return(as.matrix(y))
  }
  # x is 1-dimensional
  if(is.complex(x)) 
    return(as.matrix(data.frame(Re=Re(x), Im=Im(x))))
  # convert factors etc
  if(is.character(x)) 
    x <- factor(x)
  if(is.logical(x)) 
    x <- factor(x, levels=c(FALSE,TRUE))
  if(is.factor(x)) {
    # convert to dummy variables
    nx <- length(x)
    lev <- levels(x)
    y <- matrix(0, nrow=nx, ncol=length(lev))
    colnames(y) <- lev
    y[cbind(seq_len(nx), as.integer(x))] <- 1
    return(y)
  }
  # convert to numeric
  y <- as.numeric(x)
  if(!is.matrix(y))
    y <- matrix(y, ncol=1)
  return(y)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/dummy.R"
#
#	dummy.S
#
#	Utilities for generating patterns of dummy points
#
#       $Revision: 5.29 $     $Date: 2014/11/10 05:33:43 $
#
#	corners()	corners of window
#	gridcenters()	points of a rectangular grid
#	stratrand()	random points in each tile of a rectangular grid
#	spokes()	Rolf's 'spokes' arrangement
#	
#	concatxy()	concatenate any lists of x, y coordinates
#
#	default.dummy()	Default action to create a dummy pattern
#		
	
corners <- function(window) {
	window <- as.owin(window)
	x <- window$xrange[c(1,2,1,2)]
	y <- window$yrange[c(1,1,2,2)]
	return(list(x=x, y=y))
}

gridcenters <-	
gridcentres <- function(window, nx, ny) {
	window <- as.owin(window)
	xr <- window$xrange
	yr <- window$yrange
	x <- seq(from=xr[1], to=xr[2], length.out = 2 * nx + 1)[2 * (1:nx)]
	y <- seq(from=yr[1], to=yr[2], length.out = 2 * ny + 1)[2 * (1:ny)]
	x <- rep.int(x, ny)
	y <- rep.int(y, rep.int(nx, ny))
	return(list(x=x, y=y))
}

stratrand <- function(window,nx,ny, k=1) {
	
	# divide window into an nx * ny grid of tiles
	# and place k points at random in each tile
	
	window <- as.owin(window)

	wide  <- diff(window$xrange)/nx
	high  <- diff(window$yrange)/ny
        cent <- gridcentres(window, nx, ny)
	cx <- rep.int(cent$x, k)
	cy <- rep.int(cent$y, k)
	n <- nx * ny * k
	x <- cx + runif(n, min = -wide/2, max = wide/2)
	y <- cy + runif(n, min = -high/2, max = high/2)
	return(list(x=x,y=y))
}

tilecentroids <- function (W, nx, ny)
{
  W <- as.owin(W)
  if(W$type == "rectangle")
    return(gridcentres(W, nx, ny))
  else {
    # approximate
    W   <- as.mask(W)
    rxy <- rasterxy.mask(W, drop=TRUE)
    xx  <- rxy$x
    yy  <- rxy$y
    pid <- gridindex(xx,yy,W$xrange,W$yrange,nx,nx)$index
    x   <- tapply(xx,pid,mean)
    y   <- tapply(yy,pid,mean)
    return(list(x=x,y=y))
  }
}

cellmiddles <- local({
  # auxiliary 
  middle <- function(v) { n <- length(v);
                          mid <- ceiling(n/2);
                          v[mid]}

  dcut <- function(x, nx, xrange) {
    dx <- diff(xrange)/nx
    fx <- ((x - xrange[1])/dx) %% 1
    bx <- dx * pmin(fx, 1-fx)
    bx
  }
  
  # main
  cellmiddles <- function (W, nx, ny, npix=NULL, distances=FALSE) {
    if(W$type == "rectangle")
      return(gridcentres(W, nx, ny))

    # pixel approximation to window
    # This matches the pixel approximation used to compute tile areas
    # and ensures that dummy points are generated only inside those tiles
    # that have nonzero digital area
    M   <- as.mask(W, dimyx=rev(npix))
    xx <- as.vector(rasterx.mask(M, drop=TRUE))
    yy <- as.vector(rastery.mask(M, drop=TRUE))
    pid <- gridindex(xx,yy,W$xrange,W$yrange,nx,ny)$index

    # compute tile centroids
    xmid <- tapply(xx, pid, mean)
    ymid <- tapply(yy, pid, mean)
    # check whether they are inside window
    ok <- inside.owin(xmid, ymid, W)
    if(all(ok))
      return(list(x=xmid, y=ymid))

    # some problem tiles
    bad <- rep.int(TRUE, nx * ny)
    bad[as.integer(names(xmid))] <- !ok
    badpid <- bad[pid]
    if(!distances) {
       midpix <- tapply(seq_along(pid)[badpid], pid[badpid], middle)
    } else {
      # find 'middle' points using boundary distances
      Dlines <- im(outer(dcut(M$yrow,ny,M$yrange),
                         dcut(M$xcol,nx,M$xrange),
                         "pmin"),
                   M$xcol, M$yrow, M$xrange, M$yrange)
      Dbdry <- bdist.pixels(M)
      Dtile <- eval.im(pmin(Dlines, Dbdry))
      dtile <- as.vector(Dtile[M])
      df <- data.frame(dtile=dtile, id=seq_along(dtile))[badpid, , drop=FALSE]
      midpix <- by(df, pid[badpid],
                   function(z) { z$id[which.max(z$dtile)] })
    }
    xmid[!ok] <- xx[midpix]
    ymid[!ok] <- yy[midpix]
    return(list(x=xmid,y=ymid))
  }
  cellmiddles
})

spokes <- function(x, y, nrad = 3, nper = 3, fctr = 1.5, Mdefault=1) {
	#
	# Rolf Turner's "spokes" arrangement
	#
	# Places dummy points on radii of circles 
	# emanating from each data point x[i], y[i]
	#
	#       nrad:    number of radii from each data point
	#       nper:	 number of dummy points per radius
	#       fctr:	 length of largest radius = fctr * M
	#                where M is mean nearest neighbour distance in data
	#
        pat <- inherits(x,"ppp")
        if(pat) w <- x$w
        if(checkfields(x,c("x","y"))) {
          y <- x$y
          x <- x$x
        }
        M <- if(length(x) > 1) mean(nndist(x,y)) else Mdefault
	lrad  <- fctr * M / nper
	theta <- 2 * pi * (1:nrad)/nrad
	cs    <- cos(theta)
	sn    <- sin(theta)
	xt    <- lrad * as.vector((1:nper) %o% cs)
	yt    <- lrad * as.vector((1:nper) %o% sn)
	xd    <- as.vector(outer(x, xt, "+"))
	yd    <- as.vector(outer(y, yt, "+"))
	
        tmp <- list(x = xd, y = yd)
        if(pat) return(as.ppp(tmp,W=w)[w]) else return(tmp)
}
	
# concatenate any number of list(x,y) into a list(x,y)
		
concatxy <- function(...) {
	x <- unlist(lapply(list(...), function(w) {w$x}))
	y <- unlist(lapply(list(...), function(w) {w$y}))
	if(length(x) != length(y))
		stop("Internal error: lengths of x and y unequal")
	return(list(x=x,y=y))
}

#------------------------------------------------------------

default.dummy <- function(X, nd=NULL, random=FALSE, ntile=NULL, npix = NULL,
                          quasi=FALSE, ..., eps=NULL, verbose=FALSE) {
  # default action to create dummy points.
  # regular grid of nd[1] * nd[2] points
  # plus corner points of window frame,
  # all clipped to window.
  X <- as.ppp(X)
  win <- X$window
  #
  # default dimensions
  a <- default.n.tiling(X, nd=nd, ntile=ntile, npix=npix,
                        eps=eps, random=random, quasi=quasi, verbose=verbose)
  nd    <- a$nd
  ntile <- a$ntile
  npix  <- a$npix
  periodsample <- !quasi && !random &&
                  is.mask(win) &&
                  all(nd %% win$dim == 0)
  # make dummy points
  dummy <- if(quasi) rQuasi(prod(nd), as.rectangle(win)) else
           if(random) stratrand(win, nd[1], nd[2], 1) else 
           cellmiddles(win, nd[1], nd[2], npix)
  dummy <- as.ppp(dummy, win, check=FALSE)
  # restrict to window
  if(!is.rectangle(win) && !periodsample)
    dummy <- dummy[win]
  # corner points
  corn <- as.ppp(corners(win), win, check=FALSE)
  corn <- corn[win]
  dummy <- superimpose(dummy, corn, W=win, check=FALSE)
  if(dummy$n == 0)
    stop("None of the dummy points lies inside the window")
  # pass parameters for computing weights
  attr(dummy, "dummy.parameters") <-
    list(nd=nd, random=random, quasi=quasi, verbose=verbose)
  attr(dummy, "weight.parameters") <-
    append(list(...), list(ntile=ntile, verbose=verbose, npix=npix))
  return(dummy)
}


# Criteria:
#   for rectangular windows,
#       R1.  nd >= ntile
#   for non-rectangular windows,
#       R2. nd should be a multiple of ntile
#       R3. each dummy point is also a pixel of the npix grid
#       R4. npix should ideally be a multiple of nd, for speed
#       R5. npix should be large, for accuracy
#       R6. npix should not be too large, for speed
#       R7. if the window is a mask, npix should ideally be
#           a multiple of the mask array dimensions, for speed.
#

default.n.tiling <- local({
  # auxiliary
  ensure2print <- function(x, verbose=TRUE, blah="user specified") {
    xname <- short.deparse(substitute(x))
    x <- ensure2vector(x)
    if(verbose)
      cat(paste(blah, xname, "=", x[1], "*", x[2], "\n"))
    x
  }
  minmultiple <- function(n, lo, hi) {
    if(lo > hi) {
      temp <- hi
      hi <- lo
      lo <- temp
    }
    if(n > hi) return(hi)
    m <- n * (floor(lo/n):ceiling(hi/n))
    m <- m[m >= n & m >= lo & m <= hi]
    if(length(m) > 0) min(m) else hi
  }
    
  mindivisor <- function(N, lo, Nbig) {
    d <- divisors(N)
    ok <- (d >= lo)
    if(any(ok)) return(min(d[ok]))
    m <- floor(Nbig/N)
    d <- unlist(lapply(as.list(seq_len(m) * N), divisors))
    d <- sort(unique(d))
    ok <- (d >= lo)
    if(any(ok)) return(min(d[ok]))
    return(Nbig)
  }

  min2mul <- function(n, lo, hi) 
    c(minmultiple(n[1], lo[1], hi[1]),
      minmultiple(n[2], lo[2], hi[2]))

  min2div <- function(N, lo, Nbig) 
    c(mindivisor(N[1], lo[1], Nbig[1]),
      mindivisor(N[2], lo[2], Nbig[2]))

  maxdiv <- function(n, k=1) {
    if(length(n) > 1)
      return(c(maxdiv(n[1], k),
               maxdiv(n[2], k)))
    ## k-th largest divisor other than n
    d <- divisors(n)
    m <- length(d)
    ans <- if(m == 2) n else if(m < 2+k) d[2] else d[m-k]
    return(ans)
  }

  # main
  default.n.tiling <- function(X,
                               nd=NULL, ntile=NULL, npix=NULL,
                               eps=NULL,
                               random=FALSE, quasi=FALSE, verbose=TRUE) {
  # computes dimensions of rectangular grids of 
  #     - dummy points  (nd) (eps)
  #     - tiles for grid weights (ntile)
  #     - pixels for approximating area (npix)
  # for data pattern X.
  #
  verifyclass(X, "ppp")
  win <- X$window
  pixels <- (win$type != "rectangle")
  
  if(nd.given <- !is.null(nd)) 
    nd <- ensure2print(nd, verbose)
  if(ntile.given <- !is.null(ntile)) 
    ntile <- ensure2print(ntile, verbose)
  if(npix.given <- !is.null(npix)) 
    npix <- ensure2print(npix, verbose)

  if(pixels) 
    sonpixel <- rev(ensure2print(spatstat.options("npixel"), verbose, ""))

  ndummy.min <- ensure2print(spatstat.options("ndummy.min"), verbose, "")
  ndminX <- pmax(ndummy.min, 10 * ceiling(2 * sqrt(X$n)/10))
  ndminX <- ensure2vector(ndminX)

  if(!is.null(eps)) {
    eps <- ensure2print(eps, verbose)
    Xbox <- as.rectangle(as.owin(X))
    sides <- with(Xbox, c(diff(xrange), diff(yrange)))
    ndminX <- pmax(ndminX, ceiling(sides/eps))
  }

  # range of acceptable values for npix
  if(npix.given)
    Nmin <- Nmax <- npix
  else 
    switch(win$type,
           rectangle = {
             Nmin <- ensure2vector(X$n)
             Nmax <- Inf
           },
           polygonal = {
             Nmin <- sonpixel
             Nmax <- 4 * sonpixel
           },
           mask={
             nmask <- rev(win$dim)
             Nmin <- nmask
             Nmax <- pmax(2 * nmask, 4 * sonpixel)
           })

  # determine values of nd and ntile

  if(nd.given && !ntile.given) {
    # ntile must be a divisor of nd
    if(any(nd > Nmax))
      warning("number of dummy points nd exceeds maximum pixel dimensions")
    ntile <- min2div(nd, ndminX, nd)
  } else if(!nd.given && ntile.given) {
    # nd must be a multiple of ntile
    nd <- min2mul(ntile, ndminX, Nmin)
    if(any(nd >= Nmin))
      nd <- ntile
  } else if(!nd.given && !ntile.given) {
     if(!pixels) {
       nd <- ntile <- ensure2vector(ndminX)
       if(verbose)
         cat(paste("nd and ntile default to", nd[1], "*", nd[2], "\n"))
     } else {
       # find suitable divisors of the number of pixels
       nd <- ntile <- min2div(Nmin, ndminX, Nmax)
       if(any(nd >= Nmin)) { # none suitable
         if(verbose)
           cat("No suitable divisor of pixel dimensions\n")
         nd <- ntile <- ndminX
       }
     }
  } else {
    # both nd, ntile were given
    if(any(ntile > nd))
      warning("the number of tiles (ntile) exceeds the number of dummy points (nd)")
  }

  if(!ntile.given && quasi) {
    if(verbose) cat("Adjusting ntile because quasi=TRUE\n")
    ntile <- maxdiv(ntile, if(pixels) 2 else 1)
  } 
 
  if(!npix.given && pixels) 
    npix <- min2mul(nd, Nmin, Nmax)

  if(verbose) {
    if(!quasi)
      cat(paste("dummy points:",
                paste0(if(random) "stratified random in" else NULL,
                       "grid"),
                nd[1], "x", nd[2], "\n"))
    else
      cat(paste("dummy points:",
                nd[1], "x", nd[2], "=", prod(nd),
                "quasirandom points\n"))
    cat(paste("weighting tiles", ntile[1], "x", ntile[2], "\n"))
    if(pixels) cat(paste("pixel grid", npix[1], "x", npix[2], "\n"))
  }

  if(pixels) 
    return(list(nd=nd, ntile=ntile, npix=npix))
  else
    return(list(nd=nd, ntile=ntile, npix=npix))
}

  default.n.tiling
})


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/edgeRipley.R"
#
#        edgeRipley.R
#
#    $Revision: 1.12 $    $Date: 2014/10/24 00:22:30 $
#
#    Ripley isotropic edge correction weights
#
#  edge.Ripley(X, r, W)      compute isotropic correction weights
#                            for centres X[i], radii r[i,j], window W
#
#  To estimate the K-function see the idiom in "Kest.S"
#
#######################################################################

edge.Ripley <- local({

  small <- function(x) { abs(x) < .Machine$double.eps }

  hang <- function(d, r) {
    nr <- nrow(r)
    nc <- ncol(r)
    answer <- matrix(0, nrow=nr, ncol=nc)
    # replicate d[i] over j index
    d <- matrix(d, nrow=nr, ncol=nc)
    hit <- (d < r)
    answer[hit] <- acos(d[hit]/r[hit])
    answer
  }

  edge.Ripley <- function(X, r, W=X$window, method="C", maxweight=100) {
    # X is a point pattern, or equivalent
    X <- as.ppp(X, W)
    W <- X$window

    switch(W$type,
           rectangle={},
           polygonal={
             if(method != "C")
               stop(paste("Ripley isotropic correction for polygonal windows",
                          "requires method = ", dQuote("C")))
           },
           mask={
             stop(paste("sorry, Ripley isotropic correction",
                        "is not implemented for binary masks"))
           }
           )

    n <- npoints(X)

    if(is.matrix(r) && nrow(r) != n)
      stop("the number of rows of r should match the number of points in X")
    if(!is.matrix(r)) {
      if(length(r) != n)
        stop("length of r is incompatible with the number of points in X")
      r <- matrix(r, nrow=n)
    }

    #
    Nr <- nrow(r)
    Nc <- ncol(r)
    if(Nr * Nc == 0) return(r)
    
    ##########
  
    x <- X$x
    y <- X$y

    stopifnot(method %in% c("interpreted", "C"))

    switch(method,
           interpreted = {
           ######## interpreted R code for rectangular case #########

             # perpendicular distance from point to each edge of rectangle
             # L = left, R = right, D = down, U = up
             dL  <- x - W$xrange[1]
             dR  <- W$xrange[2] - x
             dD  <- y - W$yrange[1]
             dU  <- W$yrange[2] - y

             # detect whether any points are corners of the rectangle
             corner <- (small(dL) + small(dR) + small(dD) + small(dU) >= 2)
  
             # angle between (a) perpendicular to edge of rectangle
             # and (b) line from point to corner of rectangle
             bLU <- atan2(dU, dL)
             bLD <- atan2(dD, dL)
             bRU <- atan2(dU, dR)
             bRD <- atan2(dD, dR)
             bUL <- atan2(dL, dU)
             bUR <- atan2(dR, dU)
             bDL <- atan2(dL, dD)
             bDR <- atan2(dR, dD)

             # The above are all vectors [i]
             # Now we compute matrices [i,j]

             # half the angle subtended by the intersection between
             # the circle of radius r[i,j] centred on point i
             # and each edge of the rectangle (prolonged to an infinite line)

             aL <- hang(dL, r)
             aR <- hang(dR, r)
             aD <- hang(dD, r) 
             aU <- hang(dU, r)

             # apply maxima
             # note: a* are matrices; b** are vectors;
             # b** are implicitly replicated over j index
             cL <- pmin.int(aL, bLU) + pmin.int(aL, bLD)
             cR <- pmin.int(aR, bRU) + pmin.int(aR, bRD)
             cU <- pmin.int(aU, bUL) + pmin.int(aU, bUR)
             cD <- pmin.int(aD, bDL) + pmin.int(aD, bDR)

             # total exterior angle
             ext <- cL + cR + cU + cD

             # add pi/2 for corners 
             if(any(corner))
               ext[corner,] <- ext[corner,] + pi/2

             # OK, now compute weight
             weight <- 1 / (1 - ext/(2 * pi))

           },
           C = {
             ############ C code #############################
             switch(W$type,
                    rectangle={
                      z <- .C("ripleybox",
                              nx=as.integer(n),
                              x=as.double(x),
                              y=as.double(y),
                              rmat=as.double(r),
                              nr=as.integer(Nc), #sic
                              xmin=as.double(W$xrange[1]),
                              ymin=as.double(W$yrange[1]),
                              xmax=as.double(W$xrange[2]),
                              ymax=as.double(W$yrange[2]),
                              epsilon=as.double(.Machine$double.eps),
                              out=as.double(numeric(Nr * Nc)))
                      weight <- matrix(z$out, nrow=Nr, ncol=Nc)
                    },
                    polygonal={
                      Y <- edges(W)
                      z <- .C("ripleypoly",
                              nc=as.integer(n),
                              xc=as.double(x),
                              yc=as.double(y),
                              nr=as.integer(Nc),
                              rmat=as.double(r),
                              nseg=as.integer(Y$n),
                              x0=as.double(Y$ends$x0),
                              y0=as.double(Y$ends$y0),
                              x1=as.double(Y$ends$x1),
                              y1=as.double(Y$ends$y1),
                              out=as.double(numeric(Nr * Nc)))
                      angles <- matrix(z$out, nrow = Nr, ncol = Nc)
                      weight <- 2 * pi/angles
                    }
                    )
           }
    )
    # eliminate wild values
    weight <- matrix(pmax.int(0, pmin.int(maxweight, weight)),
                     nrow=Nr, ncol=Nc)
    return(weight)
  }

  edge.Ripley
})

rmax.Ripley <- function(W) {
  W <- as.owin(W)
  if(is.rectangle(W))
    return(circumradius(W))
  if(is.polygonal(W) && length(W$bdry) == 1)
    return(circumradius(W))
  ## could have multiple connected components
  pieces <- tiles(tess(image=connected(W)))
  answer <- sapply(pieces, circumradius)
  return(as.numeric(answer))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/edgeTrans.R"
#
#        edgeTrans.R
#
#    $Revision: 1.13 $    $Date: 2014/10/24 00:22:30 $
#
#    Translation edge correction weights
#
#  edge.Trans(X)      compute translation correction weights
#                     for each pair of points from point pattern X 
#
#  edge.Trans(X, Y, W)   compute translation correction weights
#                        for all pairs of points X[i] and Y[j]
#                        (i.e. one point from X and one from Y)
#                        in window W
#
#  edge.Trans(X, Y, W, paired=TRUE)
#                        compute translation correction weights
#                        for each corresponding pair X[i], Y[i].
#
#  To estimate the K-function see the idiom in "Kest.R"
#
#######################################################################

edge.Trans <- function(X, Y=X, W=X$window, exact=FALSE, paired=FALSE,
                       ..., 
                       trim=spatstat.options("maxedgewt"),
                       dx=NULL, dy=NULL,
                       give.rmax=FALSE) {
  given.dxdy <- !is.null(dx) && !is.null(dy)
  if(!given.dxdy) {
    ## dx, dy will be computed from X, Y
    X <- as.ppp(X, W)
    W <- X$window
    Y <- if(!missing(Y)) as.ppp(Y, W) else X
    nX <- X$n
    nY <- Y$n
    if(paired) {
      if(nX != nY)
        stop("X and Y should have equal length when paired=TRUE")
      dx <- Y$x - X$x
      dy <- Y$y - X$y
    } else {
      dx <- outer(X$x, Y$x, "-")
      dy <- outer(X$y, Y$y, "-")
    }
  } else {
    ## dx, dy given
    if(paired) {
      ## dx, dy are vectors
      check.nvector(dx)
      check.nvector(dy)
      stopifnot(length(dx) == length(dy))
    } else {
      ## dx, dy are matrices
      check.nmatrix(dx)
      check.nmatrix(dy)
      stopifnot(all(dim(dx) == dim(dy)))
      nX <- nrow(dx)
      nY <- ncol(dx)
    }
    stopifnot(is.owin(W))
  }
    
  ## For irregular polygons, exact evaluation is very slow;
  ## so use pixel approximation, unless exact=TRUE
  if(W$type == "polygonal" && !exact)
    W <- as.mask(W)

  ## compute
  if(!paired) {
    dx <- as.vector(dx)
    dy <- as.vector(dy)
  }
  switch(W$type,
         rectangle={
           ## Fast code for this case
           wide <- diff(W$xrange)
           high <- diff(W$yrange)
           weight <- wide * high / ((wide - abs(dx)) * (high - abs(dy)))
           g <- NULL
         },
         polygonal={
           ## This code is SLOW
           n <- length(dx)
           weight <- numeric(n)
           if(n > 0) {
             for(i in seq_len(n)) {
               Wshift <- shift(W, c(dx[i], dy[i]))
               weight[i] <- overlap.owin(W, Wshift)
             }
             weight <- area(W)/weight
           }
           g <- NULL
         },
         mask={
           ## compute set covariance of window
           g <- setcov(W)
           ## evaluate set covariance at these vectors
           gvalues <- lookup.im(g, dx, dy, naok=TRUE, strict=FALSE)
           weight <- area(W)/gvalues
         }
         )
  
  ## clip high values
  if(length(weight) > 0)
    weight <- pmin.int(weight, trim)

  if(!paired) 
    weight <- matrix(weight, nrow=nX, ncol=nY)

  if(give.rmax) 
    attr(weight, "rmax") <- rmax.Trans(W, g)
  return(weight)
}

rmax.Trans <- function(W, g=setcov(W)) {
  W <- as.owin(W)
  ## calculate maximum permissible 'r' value
  ## for validity of translation correction
  if(is.rectangle(W)) 
    return(min(sidelengths(W)))
  ## find support of set covariance
  if(is.null(g)) g <- setcov(W)
  eps <- 2 * max(1, max(g)) * .Machine$double.eps
  gsupport <- solutionset(g > eps)
  gboundary <- bdry.mask(gsupport)
  xy <- rasterxy.mask(gboundary, drop=TRUE)
  rmax <- with(xy, sqrt(min(x^2 + y^2)))
  return(rmax)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/edges2triangles.R"
#
#   edges2triangles.R
#
#   $Revision: 1.11 $  $Date: 2014/10/24 00:22:30 $
#

edges2triangles <- function(iedge, jedge, nvert=max(iedge, jedge),
                            ..., check=TRUE, friendly=rep(TRUE, nvert)) {
  usefriends <- !missing(friendly)
  if(check) {
    stopifnot(length(iedge) == length(jedge))
    stopifnot(all(iedge > 0))
    stopifnot(all(jedge > 0))
    if(!missing(nvert)) {
      stopifnot(all(iedge <= nvert))
      stopifnot(all(jedge <= nvert))
    }
    if(usefriends) {
      stopifnot(is.logical(friendly))
      stopifnot(length(friendly) == nvert)
      usefriends <- !all(friendly)
    }
  }
  # zero length data, or not enough to make triangles
  if(length(iedge) < 3) return(matrix(, nrow=0, ncol=3))
  # sort in increasing order of 'iedge'
  oi <- fave.order(iedge)
  iedge <- iedge[oi]
  jedge <- jedge[oi]
  # call C
  storage.mode(nvert) <- storage.mode(iedge) <- storage.mode(jedge) <- "integer"
  if(!usefriends) {
    zz <- .Call("triograph",
                nv=nvert, iedge=iedge, jedge=jedge)
#                PACKAGE="spatstat")
  } else {
    fr <- as.logical(friendly)
    storage.mode(fr) <- "integer"
    zz <- .Call("trioxgraph",
                nv=nvert, iedge=iedge, jedge=jedge, friendly=fr)
#                PACKAGE="spatstat")
  }
  mat <- as.matrix(as.data.frame(zz))
  return(mat)
}

# compute triangle diameters as well

trianglediameters <- function(iedge, jedge, edgelength, ..., 
                              nvert=max(iedge, jedge), check=TRUE) {
  if(check) {
    stopifnot(length(iedge) == length(jedge))
    stopifnot(length(iedge) == length(edgelength))
    stopifnot(all(iedge > 0))
    stopifnot(all(jedge > 0))
    if(!missing(nvert)) {
      stopifnot(all(iedge <= nvert))
      stopifnot(all(jedge <= nvert))
    }
  }
  # zero length data
  if(length(iedge) == 0)
    return(data.frame(i=integer(0),
                      j=integer(0),
                      k=integer(0),
                      diam=numeric(0)))

  # call C
  storage.mode(nvert) <- storage.mode(iedge) <- storage.mode(jedge) <- "integer"
  storage.mode(edgelength) <- "double"
  zz <- .Call("triDgraph",
              nv=nvert, iedge=iedge, jedge=jedge, edgelength=edgelength)
#              PACKAGE="spatstat")
  df <- as.data.frame(zz)
  colnames(df) <- c("i", "j", "k", "diam")
  return(df)
}

# extract 'vees', i.e. triples (i, j, k) where i ~ j and i ~ k

edges2vees <- function(iedge, jedge, nvert=max(iedge, jedge),
                            ..., check=TRUE) {
  if(check) {
    stopifnot(length(iedge) == length(jedge))
    stopifnot(all(iedge > 0))
    stopifnot(all(jedge > 0))
    if(!missing(nvert)) {
      stopifnot(all(iedge <= nvert))
      stopifnot(all(jedge <= nvert))
    }
  }
  # zero length data, or not enough to make vees
  if(length(iedge) < 2)
    return(data.frame(i=numeric(0),
                      j=numeric(0),
                      k=numeric(0)))
  # call 
  vees <- .Call("graphVees",
                nv = nvert,
                iedge = iedge,
                jedge = jedge)
#                PACKAGE="spatstat")
  names(vees) <- c("i", "j", "k")
  vees <- as.data.frame(vees)
  return(vees)
}

  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/eem.R"
# eem.R
#
# Computes the Stoyan-Grabarnik "exponential energy weights" 
#
# $Revision: 1.4 $ $Date: 2008/07/25 19:51:05 $
#

eem <- function(fit, check=TRUE) {
  verifyclass(fit, "ppm")
  lambda <- fitted.ppm(fit, check=check)
  Q <- quad.ppm(fit)
  Z <- is.data(Q)
  eemarks <- 1/lambda[Z]
  attr(eemarks, "type") <- "eem"
  attr(eemarks, "typename") <- "exponential energy marks"
  return(eemarks)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/effectfun.R"
#
#  effectfun.R
#
#   $Revision: 1.15 $ $Date: 2014/12/11 07:05:21 $
#

effectfun <- function(model, covname, ..., se.fit=FALSE) {
  stopifnot(is.ppm(model))
  dotargs <- list(...)
  # determine names of covariates involved
  intern.names <-
    if(is.marked.ppm(model)) c("x", "y", "marks") else c("x", "y")
  needed.names <- variablesinformula(rhs.of.formula(formula(model)))
  ## validate the relevant covariate 
  if(missing(covname))
    stop("covname must be provided")
  if(!(covname %in% c(intern.names, needed.names)))
    stop(paste("model does not have a covariate called", sQuote(covname)),
         call.=FALSE)
  # check that fixed values for all other covariates are provided 
  given.covs <- names(dotargs)
  if(any(uhoh <- !(needed.names %in% c(given.covs, covname)))) {
    nuh <- sum(uhoh)
    stop(paste(ngettext(nuh,
                        "A value for the covariate",
                        "Values for the covariates"),
               commasep(dQuote(needed.names[uhoh])),
               "must be provided (as",
               ngettext(nuh, "an argument", "arguments"),
               "to effectfun)"))
  }
  # establish type and range of covariate values
  N0 <- 256
  if(covname == "x") {
    covtype <- "real"
    W <- as.owin(data.ppm(model))
    Zr <- W$xrange
    Zvals <- seq(from=Zr[1], to=Zr[2], length.out=N0)
  } else if(covname == "y") {
    covtype <- "real"
    W <- as.owin(data.ppm(model))
    Zr <- W$yrange
    Zvals <- seq(from=Zr[1], to=Zr[2], length.out=N0)
  } else if(covname == "marks") {
    covtype <- "factor"
    Zvals <- levels(marks(data.ppm(model)))
  } else {
    # covariate is external
    if(is.data.frame(covdf <- model$covariates)) {
      Z <- covdf$covname
      covtype <- typeof(Z)
      if(covtype == "double")
        covtype <- "real"
      switch(covtype,
             real={
               Zr <- range(Z)
               Zvals <- seq(from=Zr[1], to=Zr[2], length.out=N0)
             },
             integer={
               Zr <- range(Z)
               Zvals <- seq(from=Zr[1], to=Zr[2], by=ceiling((diff(Zr)+1)/N0))
             },
             factor={
               Zvals <- levels(Z)
             },
             logical={
               Zvals <- c(FALSE, TRUE)
             },
             stop(paste("Cannot handle covariate of type", dQuote(covtype)))
             )
    } else {
      Z <- getdataobjects(covname,
                          environment(formula(model)),
                          model$covariates)[[1]]
      if(is.null(Z))
        stop(paste("Cannot find covariate", sQuote(covname)),
             call.=FALSE)
      # convert to image
      if(!is.im(Z))
        Z <- as.im(Z, W=as.owin(model))
      covtype <- Z$type
      switch(covtype,
             real={
               Zr <- summary(Z)$range
               Zvals <- seq(from=Zr[1], to=Zr[2], length.out=N0)
             },
             factor={
               Zvals <- levels(Z)
             },
             logical={
               Zvals <- c(FALSE, TRUE)
             },
             stop(paste("Cannot handle covariate of type", dQuote(covtype)))
             )
    }
  }
  # set up data frames of fake data for predict method
  # First set up default, constant value for each covariate
  N <- length(Zvals)
  fakeloc <- resolve.defaults(dotargs,
                              list(x=0, y=0))[c("x","y")]
  if(is.marked.ppm(model)) {
    lev <- levels(marks(data.ppm(model)))
    fakeloc$marks <- lev[1]
  }
  fakeloc <- lapply(fakeloc, function(x,N) { rep.int(x[1],N)}, N=N)
  fakecov <- lapply(dotargs, function(x,N) { rep.int(x[1],N)}, N=N)
  # Overwrite value for covariate of interest
  if(covname %in% intern.names)
    fakeloc[[covname]] <- Zvals
  else fakecov[[covname]] <- Zvals
  # convert to data frame
  fakeloc <- do.call("data.frame", fakeloc)
  fakecov <- if(length(fakecov) > 0) do.call("data.frame", fakecov) else NULL
  #
  # Now predict
  pred <- predict(model, locations=fakeloc, covariates=fakecov, se=se.fit)
  if(!se.fit) lambda <- pred else {
    lambda <- pred$estimate
    se     <- pred$se
    sedf <- data.frame(se =se,
                       hi = lambda + 2 * se,
                       lo = lambda - 2 * se)
  }
  #
  dfin <- if(!is.null(fakecov)) cbind(fakeloc, fakecov) else fakeloc 
  dfin <- dfin[covname]
  df <- cbind(dfin, data.frame(lambda=lambda))
  #
  if(covtype != "real") {
    result <- df
    if(se.fit) result <- cbind(result, sedf)
  } else {
    bc <- paren(covname)
    result <- fv(df, argu=covname, 
                 ylab=substitute(lambda(X), list(X=as.name(covname))),
                 labl=c(covname,
                   paste("hat(%s)", bc)),
                 valu="lambda", alim=Zr,
                 desc=c(paste("value of covariate", covname),
                   "fitted intensity"),
                 fname="lambda")
    if(se.fit) {
      result <- bind.fv(result, sedf,
                        labl=c(paste("se[%s]", bc),
                          paste("%s[hi]", bc),
                          paste("%s[lo]", bc)),
                        desc=c("standard error of fitted trend",
                          "upper limit of pointwise 95%% CI for trend",
                          "lower limit of pointwise 95%% CI for trend"))
      fvnames(result, ".") <- c("lambda", "hi", "lo")
      fvnames(result, ".s") <- c("hi", "lo")
      formula(result) <- paste(". ~ ", covname)
    }
  }
  return(result)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/envelope.R"
#
#   envelope.R
#
#   computes simulation envelopes 
#
#   $Revision: 2.69 $  $Date: 2014/12/10 01:18:19 $
#

envelope <- function(Y, fun, ...) {
  UseMethod("envelope")
}

  # .................................................................
  #     A 'simulation recipe' contains the following variables
  #
  #  type = Type of simulation
  #           "csr": uniform Poisson process
  #           "rmh": simulated realisation of fitted Gibbs or Poisson model 
  #          "kppm": simulated realisation of fitted cluster model 
  #          "expr": result of evaluating a user-supplied expression
  #          "list": user-supplied list of point patterns
  #
  #  expr = expression that is repeatedly evaluated to generate simulations
  #
  #    envir = environment in which to evaluate the expression `expr'
  #
  #    'csr' = TRUE iff the model is (known to be) uniform Poisson
  #
  #    pois  = TRUE if model is known to be Poisson
  #  
  #  constraints = additional information about simulation (e.g. 'with fixed n')
  #
  # ...................................................................

simulrecipe <- function(type, expr, envir, csr, pois=csr, constraints="") {
  if(csr && !pois) warning("Internal error: csr=TRUE but pois=FALSE")
  out <- list(type=type,
              expr=expr,
              envir=envir,
              csr=csr,
              pois=pois,
              constraints=constraints)
  class(out) <- "simulrecipe"
  out
}


envelope.ppp <-
  function(Y, fun=Kest, nsim=99, nrank=1, ...,
           simulate=NULL, fix.n=FALSE, fix.marks=FALSE,
           verbose=TRUE, clipdata=TRUE, 
           transform=NULL, global=FALSE, ginterval=NULL,
           alternative=c("two.sided", "less", "greater"),
           savefuns=FALSE, savepatterns=FALSE, nsim2=nsim,
           VARIANCE=FALSE, nSD=2,
           Yname=NULL, maxnerr=nsim, do.pwrong=FALSE,
           envir.simul=NULL) {
  cl <- short.deparse(sys.call())
  if(is.null(Yname)) Yname <- short.deparse(substitute(Y))
  if(is.null(fun)) fun <- Kest
  envir.user <- if(!is.null(envir.simul)) envir.simul else parent.frame()
  envir.here <- sys.frame(sys.nframe())

  ismarked <- is.marked(Y)
  ismulti  <- is.multitype(Y)
  fix.marks <- fix.marks && ismarked
  
  if(!is.null(simulate)) {
    # ...................................................
    # Simulations are determined by 'simulate' argument
    if(fix.n || fix.marks) 
      warning("fix.n and fix.marks were ignored, because 'simulate' was given")
    # Processing is deferred to envelopeEngine
    simrecipe <- simulate
    # Data pattern is argument Y
    X <- Y
  } else if(!fix.n && !fix.marks) {
    # ...................................................
    # Realisations of complete spatial randomness
    # will be generated by rpoispp 
    # Data pattern X is argument Y
    # Data pattern determines intensity of Poisson process
    X <- Y
    sY <- summary(Y, checkdup=FALSE)
    Yintens <- sY$intensity
    nY <- npoints(Y)
    Ywin <- Y$window
    Ymarx <- marks(Y)
    # expression that will be evaluated
    simexpr <- if(is.null(Ymarx)) {
        # unmarked point pattern
        expression(rpoispp(Yintens, win=Ywin))
      } else if(is.null(dim(Ymarx))) {
        # single column of marks
        expression({
          A <- rpoispp(Yintens, win=Ywin);
          j <- sample(nY, npoints(A), replace=TRUE);
          A %mark% Ymarx[j]
        })
      } else {
        # multiple columns of marks
        expression({
          A <- rpoispp(Yintens, win=Ywin);
          j <- sample(nY, npoints(A), replace=TRUE);
          A %mark% Ymarx[j, , drop=FALSE]
        })
      }
    # evaluate in THIS environment
    simrecipe <- simulrecipe(type = "csr",
                             expr = simexpr,
                             envir = envir.here,
                             csr   = TRUE,
                             pois  = TRUE)
  } else if(fix.marks) {
    # ...................................................
    # Data pattern is argument Y
    X <- Y
    # Realisations of binomial process
    # with fixed number of points and fixed marks
    # will be generated by runifpoint
    nY <- npoints(Y)
    Ywin <- as.owin(Y)
    Ymarx <- marks(Y)
    # expression that will be evaluated
    simexpr <- expression(runifpoint(nY, Ywin) %mark% Ymarx)
    # simulation constraints (explanatory string)
    constraints <- if(ismulti) "with fixed number of points of each type" else
                   "with fixed number of points and fixed marks"
    # evaluate in THIS environment
    simrecipe <- simulrecipe(type = "csr",
                             expr = simexpr,
                             envir = envir.here,
                             csr   = TRUE,
                             pois  = TRUE,
                             constraints = constraints)
  } else {
    # ...................................................
    # Data pattern is argument Y
    X <- Y
    # Realisations of binomial process
    # will be generated by runifpoint
    nY <- npoints(Y)
    Ywin <- as.owin(Y)
    Ymarx <- marks(Y)
    # expression that will be evaluated
    simexpr <- if(is.null(Ymarx)) {
      ## unmarked
      expression(runifpoint(nY, Ywin))
    } else if(is.null(dim(Ymarx))) {
      ## single column of marks
      expression({
        A <- runifpoint(nY, Ywin);
        j <- sample(nY, npoints(A), replace=TRUE);
        A %mark% Ymarx[j]
      })
    } else {
      ## multiple columns of marks
      expression({
        A <- runifpoint(nY, Ywin);
        j <- sample(nY, npoints(A), replace=TRUE);
        A %mark% Ymarx[j, ,drop=FALSE]
      })
    }
    # evaluate in THIS environment
    simrecipe <- simulrecipe(type = "csr",
                             expr = simexpr,
                             envir = envir.here,
                             csr   = TRUE,
                             pois  = TRUE,
                             constraints = "with fixed number of points")
  }
  
  envelopeEngine(X=X, fun=fun, simul=simrecipe,
                 nsim=nsim, nrank=nrank, ..., 
                 verbose=verbose, clipdata=clipdata,
                 transform=transform, global=global, ginterval=ginterval,
                 alternative=alternative,
                 savefuns=savefuns, savepatterns=savepatterns, nsim2=nsim2,
                 VARIANCE=VARIANCE, nSD=nSD,
                 Yname=Yname, maxnerr=maxnerr, cl=cl,
                 envir.user=envir.user, do.pwrong=do.pwrong)
}

envelope.ppm <- 
  function(Y, fun=Kest, nsim=99, nrank=1, ..., 
           simulate=NULL, fix.n=FALSE, fix.marks=FALSE,
           verbose=TRUE, clipdata=TRUE, 
           start=NULL,
           control=update(default.rmhcontrol(Y), nrep=nrep), nrep=1e5, 
           transform=NULL, global=FALSE, ginterval=NULL,
           alternative=c("two.sided", "less", "greater"),
           savefuns=FALSE, savepatterns=FALSE, nsim2=nsim,
           VARIANCE=FALSE, nSD=2,
           Yname=NULL, maxnerr=nsim, do.pwrong=FALSE,
           envir.simul=NULL) {
  cl <- short.deparse(sys.call())
  if(is.null(Yname)) Yname <- short.deparse(substitute(Y))
  if(is.null(fun)) fun <- Kest
  envir.user <- if(!is.null(envir.simul)) envir.simul else parent.frame()
  envir.here <- sys.frame(sys.nframe())

  # Extract data pattern X from fitted model Y
  X <- data.ppm(Y)
  
  if(is.null(simulate)) {
    # ...................................................
    # Simulated realisations of the fitted model Y
    # will be generated
    pois <- is.poisson(Y)
    csr <- is.stationary(Y) && pois
    type <- if(csr) "csr" else "rmh"
    # Set up parameters for rmh
    rmodel <- rmhmodel(Y, verbose=FALSE)
    if(is.null(start))
      start <- list(n.start=npoints(X))
    rstart <- rmhstart(start)
    rcontr <- rmhcontrol(control)
    if(fix.marks) {
      rcontr <- update(rcontr, fixall=TRUE, p=1, expand=1)
      nst <- if(is.multitype(X)) table(marks(X)) else npoints(X)
      rstart <- update(rstart, n.start=nst)
      constraints <- "with fixed number of points of each type"
    } else if(fix.n) {
      rcontr <- update(rcontr, p=1, expand=1)
      rstart <- update(rstart, n.start=X$n)
      constraints <- "with fixed number of points"
    } else constraints <- ""
    # pre-digest arguments
    rmhinfolist <- rmh(rmodel, rstart, rcontr, preponly=TRUE, verbose=FALSE)
    # expression that will be evaluated
    simexpr <- expression(rmhEngine(rmhinfolist, verbose=FALSE))
    envir <- envir.here
    # evaluate in THIS environment
    simrecipe <- simulrecipe(type  = type,
                             expr  = simexpr,
                             envir = envir.here,
                             csr   = csr,
                             pois  = pois,
                             constraints = constraints)
  } else {
    # ...................................................
    # Simulations are determined by 'simulate' argument
    # Processing is deferred to envelopeEngine
    simrecipe <- simulate
  }
  envelopeEngine(X=X, fun=fun, simul=simrecipe,
                 nsim=nsim, nrank=nrank, ..., 
                 verbose=verbose, clipdata=clipdata,
                 transform=transform, global=global, ginterval=ginterval,
                 alternative=alternative,
                 savefuns=savefuns, savepatterns=savepatterns, nsim2=nsim2,
                 VARIANCE=VARIANCE, nSD=nSD,
                 Yname=Yname, maxnerr=maxnerr, cl=cl,
                 envir.user=envir.user, do.pwrong=do.pwrong)
}

envelope.kppm <-
  function(Y, fun=Kest, nsim=99, nrank=1, ..., 
           simulate=NULL, verbose=TRUE, clipdata=TRUE, 
           transform=NULL, global=FALSE, ginterval=NULL,
           alternative=c("two.sided", "less", "greater"),
           savefuns=FALSE, savepatterns=FALSE, nsim2=nsim,
           VARIANCE=FALSE, nSD=2, Yname=NULL, maxnerr=nsim,
           do.pwrong=FALSE, envir.simul=NULL)
{
  cl <- short.deparse(sys.call())
  if(is.null(Yname)) Yname <- short.deparse(substitute(Y))
  if(is.null(fun)) fun <- Kest
  envir.user <- if(!is.null(envir.simul)) envir.simul else parent.frame()
  envir.here <- sys.frame(sys.nframe())
  
  # Extract data pattern X from fitted model Y
  X <- Y$X
  
  if(is.null(simulate)) {
    # Simulated realisations of the fitted model Y
    # will be generated using simulate.kppm
    kmodel <- Y
    # expression that will be evaluated
    simexpr <- expression(simulate(kmodel)[[1]])
    # evaluate in THIS environment
    simrecipe <- simulrecipe(type = "kppm",
                             expr = simexpr,
                             envir = envir.here,
                             csr   = FALSE,
                             pois  = FALSE)
  } else {
    # ...................................................
    # Simulations are determined by 'simulate' argument
    # Processing is deferred to envelopeEngine
    simrecipe <- simulate
  }
  envelopeEngine(X=X, fun=fun, simul=simrecipe,
                 nsim=nsim, nrank=nrank, ..., 
                 verbose=verbose, clipdata=clipdata,
                 transform=transform, global=global, ginterval=ginterval,
                 alternative=alternative,
                 savefuns=savefuns, savepatterns=savepatterns, nsim2=nsim2,
                 VARIANCE=VARIANCE, nSD=nSD,
                 Yname=Yname, maxnerr=maxnerr, cl=cl,
                 envir.user=envir.user, do.pwrong=do.pwrong)

}

## .................................................................
##   Engine for simulating and computing envelopes
## .................................................................
#
#  X is the data point pattern, which could be ppp, pp3, ppx etc
#  X determines the class of pattern expected from the simulations
#

envelopeEngine <-
  function(X, fun, simul,
           nsim=99, nrank=1, ..., 
           verbose=TRUE, clipdata=TRUE, 
           transform=NULL, global=FALSE, ginterval=NULL,
           alternative=c("two.sided", "less", "greater"),
           savefuns=FALSE, savepatterns=FALSE,
           saveresultof=NULL,
           weights=NULL,
           nsim2=nsim,
           VARIANCE=FALSE, nSD=2,
           Yname=NULL, maxnerr=nsim, internal=NULL, cl=NULL,
           envir.user=envir.user,
           expected.arg="r",
           do.pwrong=FALSE) {
  #
  envir.here <- sys.frame(sys.nframe())

  alternative <- match.arg(alternative)
  
  # ----------------------------------------------------------
  # Determine Simulation
  # ----------------------------------------------------------
  
  # Identify class of patterns to be simulated, from data pattern X
  Xclass <- if(is.ppp(X)) "ppp" else
            if(is.pp3(X)) "pp3" else
            if(is.ppx(X)) "ppx" else
            stop("Unrecognised class of point pattern")
  Xobjectname <- paste("point pattern of class", sQuote(Xclass))

  # Option to use weighted average
  if(use.weights <- !is.null(weights)) {
    # weight can be either a numeric vector or a function
    if(is.numeric(weights)) {
      compute.weights <- FALSE
      weightfun <- NULL
    } else if(is.function(weights)) {
      compute.weights <- TRUE
      weightfun <- weights
      weights <- NULL  
    } else stop("weights should be either a function or a numeric vector")
  } else compute.weights <- FALSE
    
  # Undocumented option to generate patterns only.
  patterns.only <- identical(internal$eject, "patterns")

  # Undocumented option to evaluate 'something' for each pattern
  if(savevalues <- !is.null(saveresultof)) {
    stopifnot(is.function(saveresultof))
    SavedValues <- list()
  }

  # Identify type of simulation from argument 'simul'
  if(inherits(simul, "simulrecipe")) {
    # ..................................................
    # simulation recipe is given
    simtype <- simul$type
    simexpr <- simul$expr
    envir   <- simul$envir
    csr     <- simul$csr
    pois    <- simul$pois
    constraints <- simul$constraints
  } else {
    # ...................................................
    # simulation is specified by argument `simulate' to envelope()
    simulate <- simul
    # which should be an expression, or a list of point patterns,
    # or an envelope object.
    csr <- FALSE
    # override
    if(!is.null(icsr <- internal$csr)) csr <- icsr
    pois <- csr
    constraints <- ""
#    model <- NULL
    if(inherits(simulate, "envelope")) {
      # envelope object: see if it contains stored point patterns
      simpat <- attr(simulate, "simpatterns")
      if(!is.null(simpat))
        simulate <- simpat
      else
        stop(paste("The argument", sQuote("simulate"),
                   "is an envelope object but does not contain",
                   "any saved point patterns."))
    }
    if(is.expression(simulate)) {
      # The user-supplied expression 'simulate' will be evaluated repeatedly
      simtype <- "expr"
      simexpr <- simulate
      envir <- envir.user
    } else if(is.list(simulate) &&
              (   (is.ppp(X) && all(unlist(lapply(simulate, is.ppp))))
               || (is.pp3(X) && all(unlist(lapply(simulate, is.pp3))))
               || (is.ppx(X) && all(unlist(lapply(simulate, is.ppx)))))) {
      # The user-supplied list of point patterns will be used
      simtype <- "list"
      SimDataList <- simulate
      # expression that will be evaluated
      simexpr <- expression(SimDataList[[i]])
      envir <- envir.here
      # ensure that `i' is defined
      i <- 1
      # any messages?
      if(!is.null(mess <- attr(simulate, "internal"))) {
        # determine whether these point patterns are realisations of CSR
        csr <- !is.null(mc <- mess$csr) && mc
      }
    } else stop(paste(sQuote("simulate"),
                      "should be an expression, or a list of point patterns"))
  }
  # -------------------------------------------------------------------
  # Determine clipping window
  # ------------------------------------------------------------------

  if(clipdata) {
    # Generate one realisation
    Xsim <- eval(simexpr, envir=envir)
    if(!inherits(Xsim, Xclass))
      switch(simtype,
             csr=stop(paste("Internal error:", Xobjectname, "not generated")),
             rmh=stop(paste("Internal error: rmh did not return an",
               Xobjectname)),
             kppm=stop(paste("Internal error: simulate.kppm did not return an",
               Xobjectname)),
             expr=stop(paste("Evaluating the expression", sQuote("simulate"),
               "did not yield an", Xobjectname)),
             list=stop(paste("Internal error: list entry was not an",
               Xobjectname)),
             stop(paste("Internal error:", Xobjectname, "not generated"))
             )
    # Extract window
    clipwin <- Xsim$window
    if(!is.subset.owin(clipwin, X$window))
      warning("Window containing simulated patterns is not a subset of data window")
  }
  
  # ------------------------------------------------------------------
  # Summary function to be applied 
  # ------------------------------------------------------------------

  if(is.null(fun))
    stop("Internal error: fun is NULL")

  # Name of function, for error messages
  fname <- if(is.name(substitute(fun))) short.deparse(substitute(fun)) else
  if(is.character(fun)) fun else "fun"
  fname <- sQuote(fname)

  # R function to apply
  if(is.character(fun)) {
    gotfun <- try(get(fun, mode="function"))
    if(inherits(gotfun, "try-error"))
      stop(paste("Could not find a function named", sQuote(fun)))
    fun <- gotfun
  } else if(!is.function(fun)) 
    stop(paste("unrecognised format for function", fname))
  fargs <- names(formals(fun))
  if(!any(c(expected.arg, "...") %in% fargs))
    stop(paste(fname, "should have",
               ngettext(length(expected.arg), "an argument", "arguments"),
               "named", commasep(sQuote(expected.arg)),
               "or a", sQuote("..."), "argument"))
  usecorrection <- any(c("correction", "...") %in% fargs)
  
  # ---------------------------------------------------------------------
  # validate other arguments
  if((nrank %% 1) != 0)
    stop("nrank must be an integer")
  if((nsim %% 1) != 0)
    stop("nsim must be an integer")
  stopifnot(nrank > 0 && nrank < nsim/2)

  rgiven <- any(expected.arg %in% names(list(...)))

  if(tran <- !is.null(transform)) {
    stopifnot(is.expression(transform))
    # prepare expressions to be evaluated each time 
    transform.funX    <- inject.expr("with(funX,.)",    transform)
    transform.funXsim <- inject.expr("with(funXsim,.)", transform)
    # .... old code using 'eval.fv' ......
    # transform.funX <- dotexpr.to.call(transform, "funX", "eval.fv")
    # transform.funXsim <- dotexpr.to.call(transform, "funXsim", "eval.fv")
    # 'transform.funX' and 'transform.funXsim' are unevaluated calls to eval.fv
  }
  if(!is.null(ginterval)) 
    stopifnot(is.numeric(ginterval) && length(ginterval) == 2)
    
  # ---------------------------------------------------------------------
  # Evaluate function for data pattern X
  # ------------------------------------------------------------------
  Xarg <- if(!clipdata) X else X[clipwin]
  corrx <- if(usecorrection) list(correction="best") else NULL
  funX <- do.call(fun,
                  resolve.defaults(list(Xarg),
                                   list(...),
                                   corrx))
                                     
  if(!inherits(funX, "fv"))
    stop(paste("The function", fname,
               "must return an object of class", sQuote("fv")))

  ## warn about 'dangerous' arguments
  if(!is.null(dang <- attr(funX, "dangerous")) &&
     any(uhoh <- dang %in% names(list(...)))) {
    nuh <- sum(uhoh)
    warning(paste("Envelope may be invalid;",
                  ngettext(nuh, "argument", "arguments"),
                  commasep(sQuote(dang[uhoh])),
                  ngettext(nuh, "appears", "appear"),
                  "to have been fixed."),
            call.=FALSE)
  }
  
  argname <- fvnames(funX, ".x")
  valname <- fvnames(funX, ".y")
  has.theo <- "theo" %in% fvnames(funX, "*")
  csr.theo <- csr && has.theo

  if(tran) {
    # extract only the recommended value
    if(csr.theo) 
      funX <- funX[, c(argname, valname, "theo")]
    else
      funX <- funX[, c(argname, valname)]
    # apply the transformation to it
    funX <- eval(transform.funX)
  }
    
  rvals <- funX[[argname]]
  fX    <- funX[[valname]]

  # default domain over which to maximise
  alim <- attr(funX, "alim")
  if(global && is.null(ginterval))
    ginterval <- if(rgiven || is.null(alim)) range(rvals) else alim
  
  #--------------------------------------------------------------------
  # Determine number of simulations
  # ------------------------------------------------------------------
  #
  ## determine whether dual simulations are required
  ## (one set of simulations to calculate the theoretical mean,
  ##  another independent set of simulations to obtain the critical point.)
  dual <- (global && !csr.theo && !VARIANCE)
  Nsim <- if(!dual) nsim else (nsim + nsim2)

  # if taking data from a list of point patterns,
  # check there are enough of them
  if(simtype == "list" && Nsim > length(SimDataList))
    stop(paste("Number of simulations",
               paren(if(!dual)
                     paste(nsim) else
                     paste(nsim, "+", nsim2, "=", Nsim)
                     ),
               "exceeds number of point pattern datasets supplied"))

  # Undocumented secret exit
  # ------------------------------------------------------------------
  if(patterns.only) {
    # generate simulated realisations and return only these patterns
    if(verbose) {
      action <- if(simtype == "list") "Extracting" else "Generating"
      descrip <- switch(simtype,
                        csr = "simulations of CSR",
                        rmh = paste("simulated realisations of fitted",
                          if(pois) "Poisson" else "Gibbs",
                          "model"),
                        kppm = "simulated realisations of fitted cluster model",
                        expr = "simulations by evaluating expression",
                        list = "point patterns from list",
                        "simulated realisations")
      if(!is.null(constraints) && nzchar(constraints))
        descrip <- paste(descrip, constraints)
      explan <- if(dual) paren(paste(nsim2, "to estimate the mean and",
                                     nsim, "to calculate envelopes")) else ""
      splat(action, Nsim, descrip, explan, "...")
    }
    XsimList <- list()
  # start simulation loop 
    for(i in 1:Nsim) {
      if(verbose) progressreport(i, Nsim)
      Xsim <- eval(simexpr, envir=envir)
      if(!inherits(Xsim, Xclass))
        switch(simtype,
               csr={
                 stop(paste("Internal error:", Xobjectname, "not generated"))
               },
               rmh={
                 stop(paste("Internal error: rmh did not return an",
                            Xobjectname))
               },
               kppm={
                 stop(paste("Internal error: simulate.kppm did not return an",
                            Xobjectname))
               },
               expr={
                 stop(paste("Evaluating the expression", sQuote("simulate"),
                            "did not yield an", Xobjectname))
               },
               list={
                 stop(paste("Internal error: list entry was not an",
                            Xobjectname))
               },
               stop(paste("Internal error:", Xobjectname, "not generated"))
               )
      XsimList[[i]] <- Xsim
    }
    if(verbose) {
      cat(paste("Done.\n"))
      flush.console()
    }
    attr(XsimList, "internal") <- list(csr=csr)
    return(XsimList)
  }
  
  # capture main decision parameters
  envelopeInfo <-  list(call=cl,
                        Yname=Yname,
                        valname=valname,
                        csr=csr,
                        csr.theo=csr.theo,
                        pois=pois,
                        simtype=simtype,
                        constraints=constraints,
                        nrank=nrank,
                        nsim=nsim,
                        Nsim=Nsim,
                        global=global,
                        dual=dual,
                        nsim2=nsim2,
                        VARIANCE=VARIANCE,
                        nSD=nSD,
                        alternative=alternative,
                        use.weights=use.weights,
                        do.pwrong=do.pwrong)

  # ----------------------------------------
  ######### SIMULATE #######################
  # ----------------------------------------

  if(verbose) {
    action <- if(simtype == "list") "Extracting" else "Generating"
    descrip <- switch(simtype,
                      csr = "simulations of CSR",
                      rmh = paste("simulated realisations of fitted",
                        if(pois) "Poisson" else "Gibbs",
                        "model"),
                      kppm = "simulated realisations of fitted cluster model",
                      expr = "simulations by evaluating expression",
                      list = "point patterns from list",
                      "simulated patterns")
    if(!is.null(constraints) && nzchar(constraints))
      descrip <- paste(descrip, constraints)
    explan <- if(dual) paren(paste(nsim2, "to estimate the mean and",
                                   nsim, "to calculate envelopes")) else ""
    splat(action, Nsim, descrip, explan, "...")
  }
  # determine whether simulated point patterns should be saved
  catchpatterns <- savepatterns && simtype != "list"
  Caughtpatterns <- list()
  # allocate space for computed function values
  nrvals <- length(rvals)
  simvals <- matrix(, nrow=nrvals, ncol=Nsim)
  # allocate space for weights to be computed
  if(compute.weights)
    weights <- numeric(Nsim)
  
  # inferred values of function argument 'r' or equivalent parameters
  if(identical(expected.arg, "r")) {
    # Kest, etc
    inferred.r.args <- list(r=rvals)
  } else if(identical(expected.arg, c("rmax", "nrval"))) {
    # K3est, etc
    inferred.r.args <- list(rmax=max(rvals), nrval=length(rvals))
  } else
  stop(paste("Don't know how to infer values of", commasep(expected.arg)))
    
  # arguments for function
  funargs <-
    resolve.defaults(inferred.r.args,
                     list(...),
                     if(usecorrection) list(correction="best") else NULL)
  
  # start simulation loop
  nerr <- 0
  for(i in 1:Nsim) {
    ok <- FALSE
    # safely generate a random pattern and apply function
    while(!ok) {
      Xsim <- eval(simexpr, envir=envir)
      # check valid point pattern
      if(!inherits(Xsim, Xclass))
        switch(simtype,
               csr=stop(paste("Internal error:", Xobjectname, "not generated")),
               rmh=stop(paste("Internal error: rmh did not return an",
                 Xobjectname)),
               kppm=stop(paste("Internal error:",
                 "simulate.kppm did not return an",
                 Xobjectname)),
               expr=stop(paste("Evaluating the expression", sQuote("simulate"),
                 "did not yield an", Xobjectname)),
               list=stop(paste("Internal error: list entry was not an",
                 Xobjectname)),
               stop(paste("Internal error:", Xobjectname, "not generated"))
               )
      if(catchpatterns)
        Caughtpatterns[[i]] <- Xsim
      if(savevalues)
        SavedValues[[i]] <- saveresultof(Xsim)
      if(compute.weights) {
        wti <- weightfun(Xsim)
        if(!is.numeric(wti))
          stop("weightfun did not return a numeric value")
        if(length(wti) != 1)
          stop("weightfun should return a single numeric value")
        weights[i] <- wti
      }
      # apply function safely
      funXsim <- try(do.call(fun, append(list(Xsim), funargs)))

      ok <- !inherits(funXsim, "try-error")
      
      if(!ok) {
        nerr <- nerr + 1
        if(nerr > maxnerr)
          stop("Exceeded maximum number of errors")
        cat("[retrying]\n")
      } 
    }

    # sanity checks
    if(i == 1) {
      if(!inherits(funXsim, "fv"))
        stop(paste("When applied to a simulated pattern, the function",
                   fname, "did not return an object of class",
                   sQuote("fv")))
      argname.sim <- fvnames(funXsim, ".x")
      valname.sim <- fvnames(funXsim, ".y")
      if(argname.sim != argname)
        stop(paste("The objects returned by", fname,
                   "when applied to a simulated pattern",
                   "and to the data pattern",
                   "are incompatible. They have different argument names",
                   sQuote(argname.sim), "and", sQuote(argname), 
                   "respectively"))
      if(valname.sim != valname)
        stop(paste("When", fname, "is applied to a simulated pattern",
                   "it provides an estimate named", sQuote(valname.sim), 
                   "whereas the estimate for the data pattern is named",
                   sQuote(valname),
                   ". Try using the argument", sQuote("correction"),
                   "to make them compatible"))
      rfunX    <- with(funX,    ".x")
      rfunXsim <- with(funXsim, ".x")
      if(!identical(rfunX, rfunXsim))
        stop(paste("When", fname, "is applied to a simulated pattern,",
                   "the values of the argument", sQuote(argname.sim),
                   "are different from those used for the data."))
    }

    if(tran) {
      # extract only the recommended value
      if(csr.theo) 
        funXsim <- funXsim[, c(argname, valname, "theo")]
      else
        funXsim <- funXsim[, c(argname, valname)]
      # apply the transformation to it
      funXsim <- eval(transform.funXsim)
    }

    # extract the values for simulation i
    simvals.i <- funXsim[[valname]]
    if(length(simvals.i) != nrvals)
      stop("Vectors of function values have incompatible lengths")
      
    simvals[ , i] <- funXsim[[valname]]
    if(verbose)
      progressreport(i, Nsim)
  }
  ##  end simulation loop
  
  if(verbose) {
    cat("\nDone.\n")
    flush.console()
  }

  # ...........................................................
  # save functions and/or patterns if so commanded

  if(savefuns) {
    alldata <- cbind(rvals, simvals)
    simnames <- paste("sim", 1:Nsim, sep="")
    colnames(alldata) <- c("r", simnames)
    alldata <- as.data.frame(alldata)
    SimFuns <- fv(alldata,
                  argu="r",
                  ylab=attr(funX, "ylab"),
                  valu="sim1",
                  fmla= deparse(. ~ r),
                  alim=attr(funX, "alim"),
                  labl=names(alldata),
                  desc=c("distance argument r",
                    paste("Simulation ", 1:Nsim, sep="")),
                  fname=attr(funX, "fname"),
                  yexp=attr(funX, "yexp"))
    fvnames(SimFuns, ".") <- simnames
  } 
  if(savepatterns)
    SimPats <- if(simtype == "list") SimDataList else Caughtpatterns

  ######### COMPUTE ENVELOPES #######################

  etype <- if(global) "global" else if(VARIANCE) "variance" else "pointwise"
  if(dual) {
    jsim <- 1:nsim
    jsim.mean <- nsim + 1:nsim2
  } else {
    jsim <- jsim.mean <- NULL
  }

  result <- envelope.matrix(simvals, funX=funX,
                            jsim=jsim, jsim.mean=jsim.mean,
                            type=etype, alternative=alternative,
                            csr=csr, use.theory=csr.theo,
                            nrank=nrank, ginterval=ginterval, nSD=nSD,
                            Yname=Yname, do.pwrong=do.pwrong,
                            weights=weights)

  # tack on envelope information
  attr(result, "einfo") <- envelopeInfo

  # tack on functions and/or patterns if so commanded   
  if(savefuns)
    attr(result, "simfuns") <- SimFuns
  if(savepatterns) {
    attr(result, "simpatterns") <- SimPats
    attr(result, "datapattern") <- X
  }
  # save function weights 
  if(use.weights)
    attr(result, "weights") <- weights

  # undocumented - tack on values of some other quantity
  if(savevalues) {
    attr(result, "simvalues") <- SavedValues
    attr(result, "datavalue") <- saveresultof(X)
  }
  return(result)
}


plot.envelope <- function(x, ..., main) {
  if(missing(main)) main <- short.deparse(substitute(x))
  shade.given <- ("shade" %in% names(list(...)))
  shade.implied <- !is.null(fvnames(x, ".s"))
  if(!(shade.given || shade.implied)) {
    # ensure x has default 'shade' attribute
    # (in case x was produced by an older version of spatstat)
    if(all(c("lo", "hi") %in% colnames(x)))
      fvnames(x, ".s") <- c("lo", "hi")
    else warning("Unable to determine shading for envelope")
  }
  NextMethod("plot", main=main)
}

print.envelope <- function(x, ...) {
  e <- attr(x, "einfo")
  g <- e$global
  csr <- e$csr
  pois <- e$pois
  if(is.null(pois)) pois <- csr
  simtype <- e$simtype
  constraints <- e$constraints
  nr <- e$nrank
  nsim <- e$nsim
  V <- e$VARIANCE
  fname <- flat.deparse(attr(x, "ylab"))
  type <- if(V) paste("Pointwise", e$nSD, "sigma") else
          if(g) "Simultaneous" else "Pointwise"
  splat(type, "critical envelopes for", fname,
        "\nand observed value for", sQuote(e$Yname))
  if(!is.null(valname <- e$valname) && waxlyrical('extras'))
    splat("Edge correction:", dQuote(valname))
  ## determine *actual* type of simulation
  descrip <-
    if(csr) "simulations of CSR"
    else if(!is.null(simtype)) {
      switch(simtype,
             csr="simulations of CSR",
             rmh=paste("simulations of fitted",
               if(pois) "Poisson" else "Gibbs",
               "model"),
             kppm="simulations of fitted cluster model",
             expr="evaluations of user-supplied expression",
             list="point pattern datasets in user-supplied list",
             funs="columns of user-supplied data")
    } else "simulations of fitted model"
  if(!is.null(constraints) && nzchar(constraints))
    descrip <- paste(descrip, constraints)
  #  
  splat("Obtained from", nsim, descrip)
  #
  if(waxlyrical('extras')) {
    if(!is.null(e$dual) && e$dual) 
      splat("Theoretical (i.e. null) mean value of", fname,
            "estimated from a separate set of",
            e$nsim2, "simulations")
    if(!is.null(attr(x, "simfuns"))) 
      splat("(All simulated function values are stored)")
    if(!is.null(attr(x, "simpatterns"))) 
      splat("(All simulated point patterns are stored)")
  }
  splat("Alternative:", e$alternative)
  if(!V && waxlyrical('extras')) {
    ## significance interpretation!
    alpha <- if(g) { nr/(nsim+1) } else { 2 * nr/(nsim+1) }
    splat("Significance level of",
          if(g) "simultaneous" else "pointwise",
          "Monte Carlo test:",
          paste0(if(g) nr else 2 * nr,
                 "/", nsim+1),
          "=", signif(alpha, 3))
  }
  if(waxlyrical('gory') && !is.null(pwrong <- attr(x, "pwrong"))) {
    splat("\t[Estimated significance level of pointwise excursions:",
          paste0("pwrong=", signif(pwrong, 3), "]"))
  }
  NextMethod("print")
}
                  
summary.envelope <- function(object, ...) {
  e <- attr(object, "einfo")
  g <- e$global
  V <- e$VARIANCE
  nr <- e$nrank
  nsim <- e$nsim
  csr <- e$csr
  pois <- e$pois
  if(is.null(pois)) pois <- csr
  has.theo <- "theo" %in% fvnames(object, "*")
  csr.theo <- csr && has.theo
  simtype <- e$simtype
  constraints <- e$constraints
  alternative <- e$alternative
  fname <- deparse(attr(object, "ylab"))
  type <- if(V) paste("Pointwise", e$nSD, "sigma") else
          if(g) "Simultaneous" else "Pointwise"
  splat(type, "critical envelopes for", fname, 
      "\nand observed value for", sQuote(e$Yname))
  # determine *actual* type of simulation
  descrip <-
    if(csr) "simulations of CSR"
    else if(!is.null(simtype)) {
      switch(simtype,
             csr="simulations of CSR",
             rmh=paste("simulations of fitted",
               if(pois) "Poisson" else "Gibbs",
               "model"),
             kppm="simulations of fitted cluster model",
             expr="evaluations of user-supplied expression",
             list="point pattern datasets in user-supplied list",
             funs="columns of user-supplied data",
             "simulated point patterns")
    } else "simulations of fitted model"
  if(!is.null(constraints) && nzchar(constraints))
    descrip <- paste(descrip, constraints)
  #  
  splat("Obtained from", nsim, descrip)
  #
  if(waxlyrical('extras')) {
    if(!is.null(e$dual) && e$dual) 
      splat("Theoretical (i.e. null) mean value of", fname,
            "estimated from a separate set of",
            e$nsim2, "simulations")
    if(!is.null(attr(object, "simfuns")))
      splat("(All", nsim, "simulated function values",
            "are stored in attr(,", dQuote("simfuns"), ") )")
    if(!is.null(attr(object, "simpatterns")))
      splat("(All", nsim, "simulated point patterns",
            "are stored in attr(,", dQuote("simpatterns"), ") )")
  }
  #
  splat("Alternative:", alternative)
  if(V) {
    # nSD envelopes
    splat(switch(alternative,
                 two.sided = "Envelopes",
                 "Critical boundary"),
          "computed as sample mean",
          switch(alternative,
                 two.sided="plus/minus",
                 less="minus",
                 greater="plus"),
          e$nSD, "sample standard deviations")
  } else {
    # critical envelopes
    lo.ord <- if(nr == 1) "minimum" else paste(ordinal(nr), "smallest")
    hi.ord <- if(nr == 1) "maximum" else paste(ordinal(nr), "largest")
    if(g) 
      splat(switch(alternative,
                   two.sided = "Envelopes",
                   "Critical boundary"),
            "computed as",
            if(csr.theo) "theoretical curve" else "mean of simulations",
            switch(alternative,
                   two.sided="plus/minus",
                   less="minus",
                   greater="plus"),
            hi.ord,
            "simulated value of maximum", 
            switch(alternative,
                   two.sided="absolute",
                   less="negative",
                   greater="positive"),
            "deviation")
    else {
      if(alternative != "less")
        splat("Upper envelope: pointwise", hi.ord, "of simulated curves")
      if(alternative != "greater")
        splat("Lower envelope: pointwise", lo.ord, "of simulated curves")
    }
    symmetric <- (alternative == "two.sided") && !g
    alpha <- if(!symmetric) { nr/(nsim+1) } else { 2 * nr/(nsim+1) }
    splat("Significance level of Monte Carlo test:",
          paste0(if(!symmetric) nr else 2 * nr,
                 "/", nsim+1),
          "=", alpha)
  } 
  splat("Data:", e$Yname)
  return(invisible(NULL))
}
  

# envelope.matrix

# core functionality to compute envelope values

# theory = funX[["theo"]]
# observed = fX

envelope.matrix <- function(Y, ...,
                            rvals=NULL, observed=NULL, theory=NULL, 
                            funX=NULL,
                            nsim=NULL, nsim2=NULL,
                            jsim=NULL, jsim.mean=NULL,
                            type=c("pointwise", "global", "variance"),
                            alternative=c("two.sided", "less", "greater"),
                            csr=FALSE, use.theory = csr, 
                            nrank=1, ginterval=NULL, nSD=2,
                            savefuns=FALSE,
                            check=TRUE,
                            Yname=NULL,
                            do.pwrong=FALSE,
                            weights=NULL,
                            precomputed=NULL) {
  if(is.null(Yname))
    Yname <- short.deparse(substitute(Y))

  type <- match.arg(type)
  alternative <- match.arg(alternative)

  if(!is.null(funX))
    stopifnot(is.fv(funX))

  pwrong <- NULL
  use.weights <- !is.null(weights)
  cheat <- !is.null(precomputed)

  if(is.null(rvals) && is.null(observed) && !is.null(funX)) {
    # assume funX is summary function for observed data
    rvals <- with(funX, .x)
    observed <- with(funX, .y)
    theory <- if(use.theory && "theo" %in% names(funX)) with(funX, theo) else NULL
  } else if(check) {
    # validate vectors of data
    if(is.null(rvals)) stop("rvals must be supplied")
    if(is.null(observed)) stop("observed must be supplied")
    if(!is.null(Y)) stopifnot(length(rvals) == nrow(Y))
    stopifnot(length(observed) == length(rvals))
  }

  if(use.theory) {
    use.theory <- !is.null(theory)
    if(use.theory && check) stopifnot(length(theory) == length(rvals))
  }

  simvals <- Y
  fX <- observed

  atr <- if(!is.null(funX)) attributes(funX) else
         list(alim=range(rvals),
              ylab=quote(f(r)),
              yexp=quote(f(r)),
              fname="f")

  fname <- atr$fname
  
  if(!cheat) {
    # ................   standard calculation .....................
    # validate weights
    if(use.weights) 
      check.nvector(weights, ncol(simvals), 
                    things="simulated functions", naok=TRUE)

    # determine numbers of columns used
      Ncol <- ncol(simvals)
      if(Ncol < 2)
        stop("Need at least 2 columns of function values")
      
      if(is.null(jsim) && !is.null(nsim)) {
        # usual case - 'nsim' determines 'jsim'
        if(nsim > Ncol)
          stop(paste(nsim, "simulations are not available; only",
                     Ncol, "columns provided"))
        jsim <- 1:nsim
        if(!is.null(nsim2)) {
          # 'nsim2' determines 'jsim.mean'
          if(nsim + nsim2 > Ncol)
            stop(paste(nsim, "+", nsim2, "=", nsim+nsim2, 
                       "simulations are not available; only",
                       Ncol, "columns provided"))
          jsim.mean <- nsim + 1:nsim2
        }
      }
      
      restrict.columns <- !is.null(jsim)
      dual <- !is.null(jsim.mean)

  } else {
    # ................ precomputed values ..................
    # validate weights
    if(use.weights) 
      check.nvector(weights, nsim,
                    things="simulations", naok=TRUE)
    restrict.columns <- FALSE
    dual <- FALSE
  }

  shadenames <- NULL
  
  switch(type,
         pointwise = {
           # ....... POINTWISE ENVELOPES ...............................
           if(cheat) {
             stopifnot(checkfields(precomputed, c("lo", "hi")))
             lo <- precomputed$lo
             hi <- precomputed$hi
           } else {
             simvals[is.infinite(simvals)] <- NA
             if(restrict.columns) {
               simvals <- simvals[,jsim]
               if(use.weights) weights <- weights[jsim]
             }
             nsim <- ncol(simvals)
             nsim.mean <- NULL
             if(nrank == 1) {
               lohi <- apply(simvals, 1, range)
             } else {
               lohi <- apply(simvals, 1,
                             function(x, n) { sort(x)[n] },
                             n=c(nrank, nsim-nrank+1))
             }
             lo <- lohi[1,]
             hi <- lohi[2,]
           }
           lo.name <- "lower pointwise envelope of %s from simulations"
           hi.name <- "upper pointwise envelope of %s from simulations"
           ##
           switch(alternative,
                  two.sided = { },
                  less = {
                    hi <- rep.int(Inf, length(hi))
                    hi.name <- "infinite upper limit"
                  },
                  greater = {
                    lo <- rep.int(-Inf, length(lo))
                    lo.name <- "infinite upper limit"
                  })
           #
           if(use.theory) {
             results <- data.frame(r=rvals,
                                   obs=fX,
                                   theo=theory,
                                   lo=lo,
                                   hi=hi)
           } else {
             m <- if(cheat) precomputed$mmean else 
                  if(!use.weights) apply(simvals, 1, mean, na.rm=TRUE) else
                  apply(simvals, 1, weighted.mean, w=weights, na.rm=TRUE)
             results <- data.frame(r=rvals,
                                   obs=fX,
                                   mmean=m,
                                   lo=lo,
                                   hi=hi)
           }
           shadenames <- c("lo", "hi")
           if(do.pwrong) {
             # estimate the p-value for the 'wrong test'
             if(cheat) {
               pwrong <- precomputed$pwrong
               do.pwrong <- !is.null(pwrong) && !badprobability(pwrong, FALSE)
             } else {
               dataranks <- t(apply(simvals, 1, rank, ties.method="random"))
               upper.signif <- (dataranks <= nrank)
               lower.signif <- (dataranks >= nsim-nrank+1)
               is.signif <- switch(alternative,
                                   less = lower.signif,
                                   greater = upper.signif,
                                   two.sided = lower.signif | upper.signif)
               is.signif.somewhere <- apply(is.signif, 2, any)
               pwrong <- sum(is.signif.somewhere)/nsim
             }
           }
         },
         global = {
           # ..... SIMULTANEOUS ENVELOPES ..........................
           if(cheat) {
             # ... use precomputed values ..
             stopifnot(checkfields(precomputed, c("lo", "hi")))
             lo <- precomputed$lo
             hi <- precomputed$hi
             if(use.theory) {
               reference <- theory
             } else {
               stopifnot(checkfields(precomputed, "mmean"))
               reference <- precomputed$mmean
             }
             nsim.mean <- NULL
             domain <- rep.int(TRUE, length(rvals))
           } else {
             # ... normal case: compute envelopes from simulations
             if(!is.null(ginterval)) {
               domain <- (rvals >= ginterval[1]) & (rvals <= ginterval[2])
               funX <- funX[domain, ]
               simvals <- simvals[domain, ]
             } else domain <- rep.int(TRUE, length(rvals))
             simvals[is.infinite(simvals)] <- NA
             if(use.theory) {
               reference <- theory[domain]
               if(restrict.columns) {
                 simvals <- simvals[, jsim]
                 if(use.weights) weights <- weights[jsim]
               }
               nsim.mean <- NULL
             } else if(dual) {
               # Estimate the mean from one set of columns
               # Form envelopes from another set of columns
               simvals.mean <- simvals[, jsim.mean]
               reference <- mmean <-
                 if(!use.weights) apply(simvals.mean, 1, mean, na.rm=TRUE) else
                 apply(simvals.mean, 1, weighted.mean, w=weights[jsim.mean],
                       na.rm=TRUE)
               nsim.mean <- ncol(simvals.mean)
               # retain only columns used for envelope
               simvals <- simvals[, jsim]
             } else {
               # Compute the mean and envelopes using the same data
               if(restrict.columns) {
                 simvals <- simvals[, jsim]
                 if(use.weights) weights <- weights[jsim]
               }
               reference <- mmean <-
                 if(!use.weights) apply(simvals.mean, 1, mean, na.rm=TRUE) else
                 apply(simvals.mean, 1, weighted.mean, w=weights, na.rm=TRUE)
               nsim.mean <- NULL
             }
             nsim <- ncol(simvals)
             # compute max deviations
             deviations <- sweep(simvals, 1, reference)
             deviations <- switch(alternative,
                                  two.sided = abs(deviations),
                                  less = pmax(0, -deviations),
                                  greater = pmax(0, deviations))
             deviations <- matrix(deviations,
                                  nrow=nrow(simvals), ncol=ncol(simvals))
             suprema <- apply(deviations, 2, max, na.rm=TRUE)
             # ranked deviations
             dmax <- sort(suprema)[nsim-nrank+1]
             # simultaneous bands
             lo <- reference - dmax
             hi <- reference + dmax
           }

           lo.name <- "lower critical boundary for %s"
           hi.name <- "upper critical boundary for %s"

           switch(alternative,
                  two.sided = { },
                  less = {
                    hi <- rep.int(Inf, length(hi))
                    hi.name <- "infinite upper boundary"
                  },
                  greater = {
                    lo <- rep.int(-Inf, length(lo))
                    lo.name <- "infinite lower boundary"
                  })

           if(use.theory)
             results <- data.frame(r=rvals[domain],
                                   obs=fX[domain],
                                   theo=reference,
                                   lo=lo,
                                   hi=hi)
           else
             results <- data.frame(r=rvals[domain],
                                   obs=fX[domain],
                                   mmean=reference,
                                   lo=lo,
                                   hi=hi)
           shadenames <- c("lo", "hi")
           if(do.pwrong)
             warning(paste("Argument", sQuote("do.pwrong=TRUE"), "ignored;",
                           "it is not relevant to global envelopes"))
         },
         variance={
           # ....... POINTWISE MEAN, VARIANCE etc ......................
           if(cheat) {
             # .... use precomputed values ....
             stopifnot(checkfields(precomputed, c("Ef", "varf")))
             Ef   <- precomputed$Ef
             varf <- precomputed$varf
           } else {
             # .... normal case: compute from simulations
             simvals[is.infinite(simvals)] <- NA
             if(restrict.columns) {
               simvals <- simvals[, jsim]
               if(use.weights) weights <- weights[jsim]
             }
             nsim <- ncol(simvals)
             if(!use.weights) {
               Ef   <- apply(simvals, 1, mean, na.rm=TRUE)
               varf <- apply(simvals, 1, var,  na.rm=TRUE)
             } else {
               Ef   <- apply(simvals, 1, weighted.mean, w=weights, na.rm=TRUE)
               varf <- apply(simvals, 1, weighted.var,  w=weights, na.rm=TRUE)
             }
           }
           nsim.mean <- NULL
           # derived quantities
           sd <- sqrt(varf)
           stdres <- (fX-Ef)/sd
           stdres[!is.finite(stdres)] <- NA
           # critical limits
           lo <- Ef - nSD * sd
           hi <- Ef + nSD * sd
           lo.name <- paste("lower", nSD, "sigma critical limit for %s")
           hi.name <- paste("upper", nSD, "sigma critical limit for %s")
           # confidence interval 
           loCI <- Ef - nSD * sd/sqrt(nsim)
           hiCI <- Ef + nSD * sd/sqrt(nsim)
           loCI.name <- paste("lower", nSD, "sigma confidence bound",
                              "for mean of simulated %s")
           hiCI.name <- paste("upper", nSD, "sigma confidence bound",
                              "for mean of simulated %s")
           ##
           switch(alternative,
                  two.sided = { },
                  less = {
                    hi <- hiCI <- rep.int(Inf, length(hi))
                    hi.name <- "infinite upper boundary"
                    hiCI.name <- "infinite upper confidence limit"
                  },
                  greater = {
                    lo <- loCI <- rep.int(-Inf, length(lo))
                    lo.name <- "infinite lower boundary"
                    loCI.name <- "infinite lower confidence limit"
                  })
           # put together
           if(use.theory) {
             results <- data.frame(r=rvals,
                                   obs=fX,
                                   theo=theory,
                                   lo=lo,
                                   hi=hi)
             shadenames <- c("lo", "hi")
             morestuff <- data.frame(mmean=Ef,
                                     var=varf,
                                     res=fX-Ef,
                                     stdres=stdres,
                                     loCI=loCI,
                                     hiCI=hiCI)
             loCIlabel <- if(alternative == "greater") "-infinity" else
                         makefvlabel(NULL, NULL, fname, "loCI")
             hiCIlabel <- if(alternative == "less") "infinity" else 
                         makefvlabel(NULL, NULL, fname, "hiCI")
             mslabl <- c(makefvlabel(NULL, "bar", fname),
                         makefvlabel("var", "hat", fname),
                         makefvlabel("res", "hat", fname),
                         makefvlabel("stdres", "hat", fname),
                         loCIlabel,
                         hiCIlabel)
             wted <- if(use.weights) "weighted " else NULL
             msdesc <- c(paste0(wted, "sample mean of %s from simulations"),
                         paste0(wted, "sample variance of %s from simulations"),
                         "raw residual",
                         "standardised residual",
                         loCI.name, hiCI.name)
           } else {
             results <- data.frame(r=rvals,
                                   obs=fX,
                                   mmean=Ef,
                                   lo=lo,
                                   hi=hi)
             shadenames <- c("lo", "hi")
             morestuff <- data.frame(var=varf,
                                     res=fX-Ef,
                                     stdres=stdres,
                                     loCI=loCI,
                                     hiCI=hiCI)
             loCIlabel <- if(alternative == "greater") "-infinity" else
                         makefvlabel(NULL, NULL, fname, "loCI")
             hiCIlabel <- if(alternative == "less") "infinity" else 
                         makefvlabel(NULL, NULL, fname, "hiCI")
             mslabl <- c(makefvlabel("var", "hat", fname),
                         makefvlabel("res", "hat", fname),
                         makefvlabel("stdres", "hat", fname),
                         loCIlabel,
                         hiCIlabel)
             msdesc <- c(paste0(if(use.weights) "weighted " else NULL,
                                "sample variance of %s from simulations"),
                         "raw residual",
                         "standardised residual",
                         loCI.name, hiCI.name)
           }
           if(do.pwrong) {
             # estimate the p-value for the 'wrong test'
             if(cheat) {
               pwrong <- precomputed$pwrong
               do.pwrong <- !is.null(pwrong) && !badprobability(pwrong, FALSE)
             } else {
               upper.signif <- (simvals > hi)
               lower.signif <- (simvals < lo)
               is.signif <- switch(alternative,
                                   less = lower.signif,
                                   greater = upper.signif,
                                   two.sided = lower.signif | upper.signif)
               is.signif.somewhere <- apply(is.signif, 2, any)
               pwrong <- sum(is.signif.somewhere)/nsim
             }
           }
         }
         )

  ############  WRAP UP #########################

  if(use.theory) {
    # reference is computed curve `theo'
    reflabl <- makefvlabel(NULL, NULL, fname, "theo")
    refdesc <- paste0("theoretical value of %s", if(csr) " for CSR" else NULL)
  } else {
    # reference is sample mean of simulations
    reflabl <- makefvlabel(NULL, "bar", fname)
    refdesc <- paste0(if(use.weights) "weighted " else NULL,
                      "sample mean of %s from simulations")
  }

  lolabl <- if(alternative == "greater") "-infinity" else
             makefvlabel(NULL, "hat", fname, "lo")
  hilabl <- if(alternative == "less") "infinity" else
             makefvlabel(NULL, "hat", fname, "hi")
  result <- fv(results,
               argu="r",
               ylab=atr$ylab,
               valu="obs",
               fmla= deparse(. ~ r),
               alim=atr$alim,
               labl=c("r",
                 makefvlabel(NULL, "hat", fname, "obs"),
                 reflabl,
                 lolabl,
                 hilabl),
               desc=c("distance argument r",
                 "observed value of %s for data pattern",
                 refdesc, lo.name, hi.name),
               fname=atr$fname,
               yexp =atr$yexp)

  # columns to be plotted by default
  dotty <- c("obs", if(use.theory) "theo" else "mmean", "hi", "lo")

  if(type == "variance") {
    # add more stuff
    result <- bind.fv(result, morestuff, mslabl, msdesc)
    if(use.theory) dotty <- c(dotty, "mmean")
  }

  fvnames(result, ".") <- dotty
  fvnames(result, ".s") <- shadenames

  unitname(result) <- unitname(funX)
  class(result) <- c("envelope", class(result))

  # tack on envelope information
  attr(result, "einfo") <- list(global = (type =="global"),
                                alternative=alternative,
                                csr = csr,
                                use.theory = use.theory,
                                csr.theo = csr && use.theory,
                                simtype = "funs",
                                constraints = "",
                                nrank = nrank,
                                nsim = nsim,
                                VARIANCE = (type == "variance"),
                                nSD = nSD,
                                valname = NULL,
                                dual = dual,
                                nsim = nsim,
                                nsim2 = nsim.mean,
                                Yname = Yname,
                                do.pwrong=do.pwrong,
                                use.weights=use.weights)

  # tack on saved functions
  if(savefuns) {
    alldata <- cbind(rvals, simvals)
    simnames <- paste("sim", 1:nsim, sep="")
    colnames(alldata) <- c("r", simnames)
    alldata <- as.data.frame(alldata)
    SimFuns <- fv(alldata,
                   argu="r",
                   ylab=atr$ylab,
                   valu="sim1",
                   fmla= deparse(. ~ r),
                   alim=atr$alim,
                   labl=names(alldata),
                   desc=c("distance argument r",
                     paste("Simulation ", 1:nsim, sep="")))
    fvnames(SimFuns, ".") <- simnames
    attr(result, "simfuns") <- SimFuns
  }
  if(do.pwrong)
    attr(result, "pwrong") <- pwrong
  if(use.weights)
    attr(result, "weights") <- weights
  return(result)
}


envelope.envelope <- function(Y, fun=NULL, ...,
                              transform=NULL, global=FALSE, VARIANCE=FALSE) {

  Yname <- short.deparse(substitute(Y))

  stopifnot(inherits(Y, "envelope"))
  Yorig <- Y

  aargh <- list(...)

  X  <- attr(Y, "datapattern")
  sf <- attr(Y, "simfuns")
  sp <- attr(Y, "simpatterns")
  wt <- attr(Y, "weights")
  einfo <- attr(Y, "einfo")

  csr <- aargh$internal$csr %orifnull% einfo$csr

  if(is.null(fun) && is.null(sf)) {
    # No simulated functions - must compute them from simulated patterns
    if(is.null(sp))
      stop(paste("Cannot compute envelope:",
                 "Y does not contain simulated functions",
                 "(was not generated with savefuns=TRUE)",
                 "and does not contain simulated patterns",
                 "(was not generated with savepatterns=TRUE)"))
    # set default fun=Kest
    fun <- Kest
  }
  
  if(!is.null(fun)) {
    # apply new function 
    # point patterns are required
    if(is.null(sp))
      stop(paste("Object Y does not contain simulated point patterns",
                 "(attribute", dQuote("simpatterns"), ");",
                 "cannot apply a new", sQuote("fun")))
    if(is.null(X))
      stop(paste("Cannot apply a new", sQuote("fun"),
                 "; object Y generated by an older version of spatstat"))
    ## send signal if simulations were CSR
    internal <- aargh$internal
    if(csr) {
        if(is.null(internal)) internal <- list()
        internal$csr <- TRUE
    }
    ## compute new envelope
    result <- do.call(envelope,
                      resolve.defaults(list(Y=X, fun=fun, simulate=sp),
                                       aargh,
                                       list(transform=transform,
                                            global=global,
                                            VARIANCE=VARIANCE,
                                            internal=internal,
                                            Yname=Yname,
                                            nsim=einfo$nsim,
                                            nsim2=einfo$nsim2,
                                            weights=wt),
                                       .StripNull=TRUE))
  } else {
    # compute new envelope with existing simulated functions
    if(is.null(sf)) 
      stop(paste("Y does not contain a", dQuote("simfuns"), "attribute",
                 "(it was not generated with savefuns=TRUE)"))

    if(!is.null(transform)) {
      # Apply transformation to Y and sf
      stopifnot(is.expression(transform))
      ##      cc <- dotexpr.to.call(transform, "Y", "eval.fv")
      cc <- inject.expr("with(Y, .)", transform)
      Y <- eval(cc)
      ##      cc <- dotexpr.to.call(transform, "sf", "eval.fv")
      cc <- inject.expr("with(sf, .)", transform)
      sf <- eval(cc)
    }

    # extract simulated function values
    df <- as.data.frame(sf)
    rname <- fvnames(sf, ".x")
    df <- df[, (names(df) != rname)]

    # interface with 'envelope.matrix'
    etype <- if(global) "global" else if(VARIANCE) "variance" else "pointwise"
    result <- do.call(envelope.matrix,
                      resolve.defaults(list(Y=as.matrix(df)),
                                       aargh,
                                       list(type=etype,
                                            csr=csr,
                                            funX=Y, 
                                            Yname=Yname,
                                            weights=wt),
                                       .StripNull=TRUE))
  }

  if(!is.null(transform)) {
    # post-process labels
    labl <- attr(result, "labl")
    dnames <- colnames(result)
    dnames <- dnames[dnames %in% fvnames(result, ".")]
    # expand "."
    ud <- as.call(lapply(c("cbind", dnames), as.name))
    expandtransform <- eval(substitute(substitute(tr, list(.=ud)),
                                       list(tr=transform[[1]])))
    # compute new labels 
    attr(result, "fname") <- attr(Yorig, "fname")
    mathlabl <- as.character(fvlegend(result, expandtransform))
    # match labels to columns
    evars <- all.vars(expandtransform)
    used.dotnames <- evars[evars %in% dnames]
    mathmap <- match(colnames(result), used.dotnames)
    okmath <- !is.na(mathmap)
    # update appropriate labels
    labl[okmath] <- mathlabl[mathmap[okmath]]
    attr(result, "labl") <- labl
  }
  
  # Tack on envelope info
  copyacross <- c("Yname", "csr.theo", "simtype", "constraints")
  attr(result, "einfo")[copyacross] <- attr(Yorig, "einfo")[copyacross]
  attr(result, "einfo")$csr <- csr
  # Save data
  
  return(result)
}

pool <- function(...) {
  UseMethod("pool")
}

pool.envelope <- function(..., savefuns=FALSE, savepatterns=FALSE) {
  Yname <- short.deparse(sys.call())
  if(nchar(Yname) > 60) Yname <- paste(substr(Yname, 1, 40), "[..]")
  Elist <- unname(list(...))
  nE <-  length(Elist)
  if(nE == 0) return(NULL)
  # ........ validate envelopes .....................
  # All arguments must be envelopes
  notenv <- !unlist(lapply(Elist, inherits, what="envelope"))
  if(any(notenv)) {
    n <- sum(notenv)
    why <- paste(ngettext(n, "Argument", "Arguments"),
                 commasep(which(notenv)),
                 ngettext(n, "does not", "do not"),
                 "belong to the class",
                 dQuote("envelope"))
    stop(why)
  }
  # Only one envelope?
  if(nE == 1)
    return(Elist[[1]])
  # envelopes must be compatible
  ok <- do.call(compatible, Elist)
  if(!ok)
    stop("Envelopes are not compatible")
  # ... reconcile parameters in different envelopes .......
  eilist <- lapply(Elist, attr, which="einfo")
  global    <- resolveEinfo(eilist, "global",   FALSE)
  VARIANCE  <- resolveEinfo(eilist, "VARIANCE", FALSE)
  alternative      <- resolveEinfo(eilist, "alternative", FALSE)
  resolveEinfo(eilist, "simtype",  "funs",
               "Envelopes were generated using different types of simulation")
  resolveEinfo(eilist, "constraints",  "",
               "Envelopes were generated using different types of conditioning")
  resolveEinfo(eilist, "csr.theo", FALSE, NULL)
  csr         <- resolveEinfo(eilist, "csr", FALSE, NULL)
  use.weights <- resolveEinfo(eilist, "use.weights" , FALSE,
     "Weights were used in some, but not all, envelopes: they will be ignored")
  #
  weights <-
    if(use.weights) unlist(lapply(Elist, attr, which="weights")) else NULL
  type <- if(global) "global" else if(VARIANCE) "variance" else "pointwise"
    
  # ........ validate saved functions .....................
  if(savefuns || !VARIANCE) {
    # Individual simulated functions are required
    SFlist <- lapply(Elist, attr, which="simfuns")
    isnul <- unlist(lapply(SFlist, is.null))
    if(any(isnul)) {
      n <- sum(isnul)
      comply <- if(!VARIANCE) "compute the envelope:" else
                "save the simulated functions:"
      why <- paste("Cannot", comply,
                   ngettext(n, "argument", "arguments"),
                   commasep(which(isnul)),
                   ngettext(n, "does not", "do not"),
                   "contain a", dQuote("simfuns"), "attribute",
                   "(not generated with savefuns=TRUE)")
      stop(why)
    }
    # Simulated functions must be the same function
    fnames <- unique(lapply(SFlist, attr, which="fname"))
    if(length(fnames) > 1) {
      fnames <- unlist(lapply(fnames, flatfname))
      stop(paste("Envelope objects contain values",
                 "of different functions:",
                 commasep(sQuote(fnames))))
    }
    # vectors of r values must be identical
    rlist <- lapply(SFlist, function(z) { with(z, .x) })
    rvals <- rlist[[1]]
    samer <- unlist(lapply(rlist, identical, y=rvals))
    if(!all(samer))
      stop(paste("Simulated function values are not compatible",
                 "(different values of function argument)"))
  }
  # compute pooled envelope
  switch(type,
         global = ,
         pointwise = {
           # assemble function values into one matrix
           getsimvals <- function(z) {
             rname <- fvnames(z, ".x")
             as.matrix(as.data.frame(z)[, names(z) != rname])
           }
           matlist <- lapply(SFlist, getsimvals)
           bigmat <- do.call(cbind, matlist)
           # ..... ready to compute
           result <- envelope(bigmat, funX=Elist[[1]],
                              type=type, alternative=alternative, csr=csr, Yname=Yname,
                              weights=weights,
                              savefuns=savefuns)
         },
         variance = {
           # Pool sample means and variances
           nsims <- unlist(lapply(eilist, getElement, name="nsim"))
           mmeans <- lapply(Elist, getElement, name="mmean")
           vars   <- lapply(Elist, getElement, name="var")
           mmeans <- matrix(unlist(mmeans), ncol=nE)
           vars   <- matrix(unlist(vars),   ncol=nE)
           if(!use.weights) {
             w.mean <- nsims
             d.mean <- sum(nsims)
             w.var  <- nsims - 1
             d.var  <- sum(nsims) - 1
           } else {
             weightlist <- lapply(Elist, attr, which="weights")
             w.mean <- unlist(lapply(weightlist, sum))
             d.mean <- sum(w.mean)
             ssw <- unlist(lapply(weightlist, function(x) {sum((x/sum(x))^2)}))
             w.var  <- w.mean * (1 - ssw)
             d.var <-  d.mean * (1 - sum(ssw))
           }
           poolmmean <- as.numeric(mmeans %*% matrix(w.mean/d.mean, ncol=1))
           within <- vars %*% matrix(w.var, ncol=1)
           between <- ((mmeans - poolmmean[])^2) %*% matrix(w.mean, ncol=1)
           poolvar <- as.numeric((within + between)/d.var)
           # feed precomputed data to envelope.matrix
           pc <- list(Ef=poolmmean[],
                      varf=poolvar[])
           nsim <- sum(nsims)
           result <- envelope.matrix(NULL, funX=Elist[[1]],
                                     type=type, alternative=alternative,
                                     csr=csr, Yname=Yname,
                                     weights=weights,
                                     savefuns=savefuns,
                                     nsim=nsim,
                                     precomputed=pc)
         })
  
  # Copy envelope info that is not handled by envelope.matrix
  copyacross <- c("Yname", "csr.theo", "simtype", "constraints")
  attr(result, "einfo")[copyacross] <- attr(Elist[[1]], "einfo")[copyacross]
  
  # ..............saved patterns .....................
  if(savepatterns) {
    SPlist <- lapply(Elist, attr, which="simpatterns")
    isnul <- unlist(lapply(SPlist, is.null))
    if(any(isnul)) {
      n <- sum(isnul)
      why <- paste("Cannot save the simulated patterns:",
                   ngettext(n, "argument", "arguments"),
                   commasep(which(isnul)),
                   ngettext(n, "does not", "do not"),
                   "contain a", dQuote("simpatterns"), "attribute",
                   "(not generated with savepatterns=TRUE)")
      warning(why)
    } else {
      attr(result, "simpatterns") <- Reduce(SPlist, append)
    }
  }

  dotnames   <- lapply(Elist, fvnames, a=".")
  dn <- dotnames[[1]]
  if(all(unlist(lapply(dotnames, identical, y=dn))))
    fvnames(result, ".") <- dn
  
  shadenames <- lapply(Elist, fvnames, a=".s")
  sh <- shadenames[[1]]
  if(all(unlist(lapply(shadenames, identical, y=sh))))
    fvnames(result, ".s") <- sh
  
  return(result)
}

# resolve matching entries in different envelope objects
#   x is a list of envelope info objects

resolveEinfo <- function(x, what, fallback, warn) {
  y <- unique(unlist(lapply(x, getElement, name=what)))
  if(length(y) == 1)
    return(y)
  if(missing(warn))
    warn <- paste("Envelopes were generated using different values",
                  "of argument", paste(sQuote(what), ";", sep=""),
                  "reverting to default value")
  if(!is.null(warn))
    warning(warn, call.=FALSE)
  return(fallback)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/envelope3.R"
#
#   envelope3.R
#
#   simulation envelopes for pp3 
#
#   $Revision: 1.9 $  $Date: 2014/11/10 05:59:29 $
#

envelope.pp3 <-
  function(Y, fun=K3est, nsim=99, nrank=1, ..., 
           simulate=NULL, verbose=TRUE, 
           transform=NULL, global=FALSE, ginterval=NULL,
           alternative=c("two.sided", "less", "greater"),
           savefuns=FALSE, savepatterns=FALSE, nsim2=nsim,
           VARIANCE=FALSE, nSD=2,
           Yname=NULL, maxnerr=nsim,
           do.pwrong=FALSE, envir.simul=NULL) {
  cl <- short.deparse(sys.call())
  if(is.null(Yname)) Yname <- short.deparse(substitute(Y))
  if(is.null(fun)) fun <- K3est

  if("clipdata" %in% names(list(...)))
    stop(paste("The argument", sQuote("clipdata"),
               "is not available for envelope.pp3"))
  
  envir.user <- if(!is.null(envir.simul)) envir.simul else parent.frame()
  envir.here <- sys.frame(sys.nframe())
  
  if(is.null(simulate)) {
    # ...................................................
    # Realisations of complete spatial randomness
    # will be generated by rpoispp
    # Data pattern X is argument Y
    # Data pattern determines intensity of Poisson process
    X <- Y
    sY <- summary(Y)
    Yintens <- sY$intensity
    Ydomain <- Y$domain
    # expression that will be evaluated
    simexpr <- 
      if(!is.marked(Y)) {
        # unmarked point pattern
        expression(rpoispp3(Yintens, domain=Ydomain))
      } else {
        stop("Sorry, simulation of marked 3D point patterns is not yet implemented")
      }
    # evaluate in THIS environment
    simrecipe <- simulrecipe(type = "csr",
                             expr = simexpr,
                             envir = envir.here,
                             csr   = TRUE)
  } else {
    # ...................................................
    # Simulations are determined by 'simulate' argument
    # Processing is deferred to envelopeEngine
    simrecipe <- simulate
    # Data pattern is argument Y
    X <- Y
  }
  envelopeEngine(X=X, fun=fun, simul=simrecipe,
                 nsim=nsim, nrank=nrank, ..., 
                 verbose=verbose, clipdata=FALSE,
                 transform=transform, global=global, ginterval=ginterval,
                 alternative=alternative,
                 savefuns=savefuns, savepatterns=savepatterns, nsim2=nsim2,
                 VARIANCE=VARIANCE, nSD=nSD,
                 Yname=Yname, maxnerr=maxnerr, cl=cl,
                 envir.user=envir.user,
                 expected.arg=c("rmax", "nrval"),
                 do.pwrong=do.pwrong)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/envelopelpp.R"
#
#  envelopelpp.R
#
#  $Revision: 1.17 $   $Date: 2014/11/10 05:58:17 $
#
#  Envelopes for 'lpp' objects
#
#

envelope.lpp <-
  function(Y, fun=linearK, nsim=99, nrank=1, ..., 
           simulate=NULL, verbose=TRUE, 
           transform=NULL, global=FALSE, ginterval=NULL,
           alternative=c("two.sided", "less", "greater"),
           savefuns=FALSE, savepatterns=FALSE, nsim2=nsim,
           VARIANCE=FALSE, nSD=2,
           Yname=NULL, do.pwrong=FALSE, envir.simul=NULL) {
  cl <- short.deparse(sys.call())
  if(is.null(Yname)) Yname <- short.deparse(substitute(Y))
  if(is.null(fun)) fun <- linearK

  if("clipdata" %in% names(list(...)))
    stop(paste("The argument", sQuote("clipdata"),
               "is not available for envelope.lpp"))
  
  envir.user <- if(!is.null(envir.simul)) envir.simul else parent.frame()
  envir.here <- sys.frame(sys.nframe())
  
  if(is.null(simulate)) {
    # ...................................................
    # Realisations of complete spatial randomness
    # will be generated by rpoisppOnLines
    # Data pattern X is argument Y
    # Data pattern determines intensity of Poisson process
    X <- Y
    nY <- if(!is.marked(Y)) npoints(Y) else table(marks(Y))
    NETWORK <- Y$domain
    totlen <- sum(lengths.psp(NETWORK$lines))
    Yintens <- nY/totlen
    # expression that will be evaluated
    simexpr <- expression(rpoislpp(Yintens, NETWORK))
    # evaluate in THIS environment
    simrecipe <- simulrecipe(type = "csr",
                             expr = simexpr,
                             envir = envir.here,
                             csr   = TRUE)
  } else {
    # ...................................................
    # Simulations are determined by 'simulate' argument
    # Processing is deferred to envelopeEngine
    simrecipe <- simulate
    # Data pattern is argument Y
    X <- Y
  }
  envelopeEngine(X=X, fun=fun, simul=simrecipe,
                 nsim=nsim, nrank=nrank, ..., 
                 verbose=verbose, clipdata=FALSE,
                 transform=transform, global=global, ginterval=ginterval,
                 alternative=alternative,
                 savefuns=savefuns, savepatterns=savepatterns, nsim2=nsim2,
                 VARIANCE=VARIANCE, nSD=nSD,
                 Yname=Yname, cl=cl,
                 envir.user=envir.user, do.pwrong=do.pwrong)
}

envelope.lppm <-
  function(Y, fun=linearK, nsim=99, nrank=1, ..., 
           simulate=NULL, verbose=TRUE, 
           transform=NULL, global=FALSE, ginterval=NULL,
           alternative=c("two.sided", "less", "greater"),
           savefuns=FALSE, savepatterns=FALSE, nsim2=nsim,
           VARIANCE=FALSE, nSD=2,
           Yname=NULL, do.pwrong=FALSE, envir.simul=NULL) {
  cl <- short.deparse(sys.call())
  if(is.null(Yname)) Yname <- short.deparse(substitute(Y))
  if(is.null(fun)) fun <- linearK

  if("clipdata" %in% names(list(...)))
    stop(paste("The argument", sQuote("clipdata"),
               "is not available for envelope.pp3"))

  envir.user <- if(!is.null(envir.simul)) envir.simul else parent.frame()
  envir.here <- sys.frame(sys.nframe())
  
  if(is.null(simulate)) {
    # ...................................................
    # Simulated realisations of the fitted model Y
    # will be generated using rpoisppOnLines
    if(!is.poisson.ppm(Y$fit))
      stop("Simulation of non-Poisson models is not yet implemented")
    X <- Y$X
    MODEL <- Y
    NETWORK <- X$domain
    lambdaFit <- predict(MODEL)
    LMAX <-
      if(is.im(lambdaFit)) max(lambdaFit) else unlist(lapply(lambdaFit, max))
    simexpr <- expression(rpoislpp(lambdaFit, NETWORK, lmax=LMAX))
    # evaluate in THIS environment
    simrecipe <- simulrecipe(type = "lppm",
                             expr = simexpr,
                             envir = envir.here,
                             csr   = FALSE)
  } else {
    # ...................................................
    # Simulations are determined by 'simulate' argument
    # Processing is deferred to envelopeEngine
    simrecipe <- simulate
    # Data pattern is argument Y
    X <- Y
  }
  envelopeEngine(X=X, fun=fun, simul=simrecipe,
                 nsim=nsim, nrank=nrank, ..., 
                 verbose=verbose, clipdata=FALSE,
                 transform=transform, global=global, ginterval=ginterval,
                 alternative=alternative,
                 savefuns=savefuns, savepatterns=savepatterns, nsim2=nsim2,
                 VARIANCE=VARIANCE, nSD=nSD,
                 Yname=Yname, cl=cl,
                 envir.user=envir.user, do.pwrong=do.pwrong)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/eval.fasp.R"
#
#     eval.fasp.R
#
#
#        eval.fasp()             Evaluate expressions involving fasp objects
#
#        compatible.fasp()       Check whether two fasp objects are compatible
#
#     $Revision: 1.9 $     $Date: 2014/11/10 07:36:27 $
#

eval.fasp <- function(expr, envir, dotonly=TRUE) {
  # convert syntactic expression to 'expression' object
  e <- as.expression(substitute(expr))
  # convert syntactic expression to call
#  elang <- substitute(expr)
  # find names of all variables in the expression
  varnames <- all.vars(e)
  if(length(varnames) == 0)
    stop("No variables in this expression")
  # get the actual variables
  if(missing(envir)) {
    envir <- sys.parent()
  } else if(is.list(envir)) {
    envir <- list2env(envir, parent=parent.frame())
  }
  vars <- lapply(as.list(varnames), get, envir=envir)
  names(vars) <- varnames
  # find out which ones are fasp objects
  isfasp <- unlist(lapply(vars, inherits, what="fasp"))
  if(!any(isfasp))
    stop("No fasp objects in this expression")
  fasps <- vars[isfasp]
  nfasps <- length(fasps)
  # test whether the fasp objects are compatible
  if(nfasps > 1 && !(do.call("compatible", unname(fasps))))
    stop(paste(if(nfasps > 2) "some of" else NULL,
               "the objects",
               commasep(sQuote(names(fasps))),
               "are not compatible"))
  # copy first object as template
  result <- fasps[[1]]
  which <- result$which
  nr <- nrow(which)
  nc <- ncol(which)
  # create environment for evaluation
  fenv <- new.env()
  # for each [i,j] extract fv objects and evaluate expression
  for(i in seq_len(nr))
    for(j in seq_len(nc)) {
      # extract fv objects at position [i,j]
      funs <- lapply(fasps, function(x, i, j) { as.fv(x[i,j]) }, i=i, j=j)
      # insert into list of argument values
      vars[isfasp] <- funs
      # assign them into the right environment
      for(k in seq_along(vars)) 
        assign(varnames[k], vars[[k]], envir=fenv)
      # evaluate
      resultij <- eval(substitute(eval.fv(ee,ff,dd),
                                  list(ee=e, ff=fenv, dd=dotonly)))
      # insert back into fasp
      result$fns[[which[i,j] ]] <- resultij
  }
  result$title <- paste("Result of eval.fasp(", e, ")", sep="")
  return(result)
}

compatible.fasp <- function(A, B, ...) {
  verifyclass(A, "fasp")
  if(missing(B)) return(TRUE)
  verifyclass(B, "fasp")
  dimA <- dim(A$which)
  dimB <- dim(B$which)
  if(!all(dimA == dimB))
    return(FALSE)
  for(i in seq_len(dimA[1])) 
    for(j in seq_len(dimA[2])) {
      Aij <- as.fv(A[i,j])
      Bij <- as.fv(B[i,j])
      if(!compatible.fv(Aij, Bij))
        return(FALSE)
    }
  # A and B agree
  if(length(list(...)) == 0) return(TRUE)
  # recursion
  return(compatible.fasp(B, ...))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/eval.fv.R"
#
#     eval.fv.R
#
#
#        eval.fv()             Evaluate expressions involving fv objects
#
#        compatible.fv()       Check whether two fv objects are compatible
#
#     $Revision: 1.28 $     $Date: 2014/11/11 10:33:33 $
#

eval.fv <- local({

  # main function
  eval.fv <- function(expr, envir, dotonly=TRUE) {
    # convert syntactic expression to 'expression' object
    e <- as.expression(substitute(expr))
    # convert syntactic expression to call
    elang <- substitute(expr)
    # find names of all variables in the expression
    varnames <- all.vars(e)
    if(length(varnames) == 0)
      stop("No variables in this expression")
    # get the actual variables
    if(missing(envir)) {
      envir <- parent.frame()
    } else if(is.list(envir)) {
      envir <- list2env(envir, parent=parent.frame())
    }
    vars <- lapply(as.list(varnames), get, envir=envir)
    names(vars) <- varnames
    # find out which ones are fv objects
    fvs <- unlist(lapply(vars, is.fv))
    nfuns <- sum(fvs)
    if(nfuns == 0)
      stop("No fv objects in this expression")
    # extract them
    funs <- vars[fvs]
    # restrict to columns identified by 'dotnames'
    if(dotonly) 
      funs <- lapply(funs, restrict.to.dot)
    # test whether the fv objects are compatible
    if(nfuns > 1 && !(do.call("compatible", unname(funs)))) {
      warning(paste(if(nfuns > 2) "some of" else NULL,
                    "the functions",
                    commasep(sQuote(names(funs))),
                    "were not compatible: enforcing compatibility"))
      funs <- do.call(harmonise.fv, funs)
    }
    # copy first object as template
    result <- funs[[1]]
    labl <- attr(result, "labl")
    origdotnames   <- fvnames(result, ".")
    origshadenames <- fvnames(result, ".s")
    # determine which function estimates are supplied
    argname <- fvnames(result, ".x")
    nam <- names(result)
    ynames <- nam[nam != argname]
    # for each function estimate, evaluate expression
    for(yn in ynames) {
      # extract corresponding estimates from each fv object
      funvalues <- lapply(funs, "[[", i=yn)
      # insert into list of argument values
      vars[fvs] <- funvalues
      # evaluate
      result[[yn]] <- eval(e, vars, enclos=envir)
    }
    # determine mathematical labels.
    # 'yexp' determines y axis label
    # 'ylab' determines y label in printing and description
    # 'fname' is sprintf-ed into 'labl' for legend
    yexps <- lapply(funs, attr, which="yexp")
    ylabs <- lapply(funs, attr, which="ylab")
    fnames <- lapply(funs, getfname)
    # Repair 'fname' attributes if blank
    blank <- unlist(lapply(fnames, function(z) { !any(nzchar(z)) }))
    if(any(blank)) {
      # Set function names to be object names as used in the expression
      for(i in which(blank))
        attr(funs[[i]], "fname") <- fnames[[i]] <- names(funs)[i]
    }
    # Remove duplicated names
    # Typically occurs when combining several K functions, etc.
    # Tweak fv objects so their function names are their object names
    # as used in the expression
    if(anyDuplicated(fnames)) {
      newfnames <- names(funs)
      for(i in 1:nfuns)
        funs[[i]] <- rebadge.fv(funs[[i]], new.fname=newfnames[i])
      fnames <- newfnames
    }
    if(anyDuplicated(ylabs)) {
      flatnames <- lapply(funs, flatfname)
      for(i in 1:nfuns) {
        new.ylab <- substitute(f(r), list(f=flatnames[[i]]))
        funs[[i]] <- rebadge.fv(funs[[i]], new.ylab=new.ylab)
      }
      ylabs <- lapply(funs, attr, which="ylab")
    }
    if(anyDuplicated(yexps)) {
      newfnames <- names(funs)
      for(i in 1:nfuns) {
        new.yexp <- substitute(f(r), list(f=as.name(newfnames[i])))
        funs[[i]] <- rebadge.fv(funs[[i]], new.yexp=new.yexp)
      }
      yexps <- lapply(funs, attr, which="yexp")
    }
    # now compute y axis labels for the result
    attr(result, "yexp") <- eval(substitute(substitute(e, yexps),
                                            list(e=elang)))
    attr(result, "ylab") <- eval(substitute(substitute(e, ylabs),
                                            list(e=elang)))
    # compute fname equivalent to expression
    if(nfuns > 1) {
      # take original expression
      the.fname <- paren(flatten(deparse(elang)))
    } else if(nzchar(oldname <- flatfname(funs[[1]]))) {
      # replace object name in expression by its function name
      namemap <- list(as.name(oldname)) 
      names(namemap) <- names(funs)[1]
      the.fname <- deparse(eval(substitute(substitute(e, namemap),
                                           list(e=elang))))
    } else the.fname <- names(funs)[1]
    attr(result, "fname") <- the.fname
    # now compute the [modified] y labels
    labelmaps <- lapply(funs, fvlabelmap, dot=FALSE)
    for(yn in ynames) {
      # labels for corresponding columns of each argument
      funlabels <- lapply(labelmaps, "[[", i=yn)
      # form expression involving these columns
      labl[match(yn, names(result))] <-
        flatten(deparse(eval(substitute(substitute(e, f),
                                        list(e=elang, f=funlabels)))))
    }
    attr(result, "labl") <- labl
    # copy dotnames and shade names from template
    fvnames(result, ".") <- origdotnames[origdotnames %in% names(result)]
    if(!is.null(origshadenames) && all(origshadenames %in% names(result)))
      fvnames(result, ".s") <- origshadenames
    return(result)
  }

  # helper functions
  restrict.to.dot <- function(z) {
    argu <- fvnames(z, ".x")
    dotn <- fvnames(z, ".")
    shadn <- fvnames(z, ".s")
    ok <- colnames(z) %in% unique(c(argu, dotn, shadn))
    return(z[, ok])
  }
  getfname <- function(x) { if(!is.null(y <- attr(x, "fname"))) y else "" }
  flatten <- function(x) { paste(x, collapse=" ") }
  eval.fv
})
    
compatible <- function(A, B, ...) {
  UseMethod("compatible")
}

compatible.fv <- function(A, B, ...) {
  verifyclass(A, "fv")
  if(missing(B)) {
    answer <- if(length(...) == 0) TRUE else compatible(A, ...)
    return(answer)
  }
  verifyclass(B, "fv")
  # are columns the same?
  namesmatch <-
    identical(all.equal(names(A),names(B)), TRUE) &&
    (fvnames(A, ".x") == fvnames(B, ".x")) &&
    (fvnames(A, ".y") == fvnames(B, ".y"))
  if(!namesmatch)
    return(FALSE)
  # are 'r' values the same ?
  rA <- with(A, .x)
  rB <- with(B, .x)
  approx.equal <- function(x, y) { max(abs(x-y)) <= .Machine$double.eps }
  rmatch <- (length(rA) == length(rB)) && approx.equal(rA, rB)
  if(!rmatch)
    return(FALSE)
  # A and B are compatible
  if(length(list(...)) == 0)
    return(TRUE)
  # recursion
  return(compatible.fv(B, ...))
}

# force a list of images to be compatible with regard to 'x' values

harmonize <- harmonise <- function(...) {
  UseMethod("harmonise")
}

harmonize.fv <- harmonise.fv <- function(...) {
  argh <- list(...)
  n <- length(argh)
  if(n < 2) return(argh)
  isfv <- unlist(lapply(argh, is.fv))
  if(!all(isfv))
    stop("All arguments must be fv objects")
  ## determine range of argument
  ranges <- lapply(argh, function(f) { range(with(f, .x)) })
  xrange <- c(max(unlist(lapply(ranges, min))),
              min(unlist(lapply(ranges, max))))
  if(diff(xrange) < 0)
    stop("No overlap in ranges of argument")
  ## determine finest resolution
  xsteps <- unlist(lapply(argh, function(f) { mean(diff(with(f, .x))) }))
  finest <- which.min(xsteps)
  ## extract argument values
  xx <- with(argh[[finest]], .x)
  xx <- xx[xrange[1] <= xx & xx <= xrange[2]]
  xrange <- range(xx)
  ## convert each fv object to a function
  funs <- lapply(argh, as.function, value="*")
  ## evaluate at common argument
  result <- vector(mode="list", length=n)
  for(i in 1:n) {
    ai <- argh[[i]]
    fi <- funs[[i]]
    xxval <- list(xx=xx)
    names(xxval) <- fvnames(ai, ".x")
    starnames <- fvnames(ai, "*")
    ## ensure they are given in same order as current columns
    starnames <- colnames(ai)[colnames(ai) %in% starnames]
    yyval <- lapply(starnames,
                    function(v,xx,fi) fi(xx, v),
                    xx=xx, fi=fi)
    names(yyval) <- starnames
    ri <- do.call("data.frame", append(xxval, yyval))
    fva <- .Spatstat.FvAttrib
    attributes(ri)[fva] <- attributes(ai)[fva]
    class(ri) <- c("fv", class(ri))
    attr(ri, "alim") <- intersect.ranges(attr(ai, "alim"), xrange)
    result[[i]] <- ri
  }
  names(result) <- names(argh)
  return(result)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/eval.im.R"
#
#     eval.im.R
#
#        eval.im()             Evaluate expressions involving images
#
#        compatible.im()       Check whether two images are compatible
#
#        harmonise.im()       Harmonise images
#        commonGrid()
#
#     $Revision: 1.37 $     $Date: 2014/11/10 07:37:31 $
#

eval.im <- local({

  eval.im <- function(expr, envir, harmonize=TRUE) {
    e <- as.expression(substitute(expr))
    ## get names of all variables in the expression
    varnames <- all.vars(e)
    allnames <- all.names(e, unique=TRUE)
    funnames <- allnames[!(allnames %in% varnames)]
    if(length(varnames) == 0)
      stop("No variables in this expression")
    ## get the values of the variables
    if(missing(envir)) {
      envir <- sys.parent()
    } else if(is.list(envir)) {
      envir <- list2env(envir, parent=parent.frame())
    }
    vars <- lapply(as.list(varnames), function(x, e) get(x, envir=e), e=envir)
    names(vars) <- varnames
    funs <- lapply(as.list(funnames), function(x, e) get(x, envir=e), e=envir)
    names(funs) <- funnames
    ## find out which variables are images
    ims <- unlist(lapply(vars, is.im))
    if(!any(ims))
      stop("No images in this expression")
    images <- vars[ims]
    nimages <- length(images)
    ## test that the images are compatible
    if(!(do.call("compatible", unname(images)))) {
      whinge <- paste(if(nimages > 2) "some of" else NULL,
                      "the images",
                      commasep(sQuote(names(images))),
                      if(!harmonize) "are" else "were",
                      "not compatible")
      if(!harmonize) {
        stop(whinge, call.=FALSE)
      } else {
        warning(whinge, call.=FALSE)
        images <- do.call("harmonise.im", images)
      }
    }
    ## trap a common error: using fv object as variable
    isfun <- unlist(lapply(vars, is.fv))
    if(any(isfun))
      stop("Cannot use objects of class fv as variables in eval.im")
    ## replace each image by its matrix of pixel values, and evaluate
    imagevalues <- lapply(images, getImValues)
    template <- images[[1]]
    ## This bit has been repaired:
    vars[ims] <- imagevalues
    v <- eval(e, append(vars, funs))
    ##
    ## reshape, etc
    result <- im(v,
                 xcol=template$xcol, yrow=template$yrow,
                 xrange=template$xrange, yrange=template$yrange, 
                 unitname=unitname(template))
    return(result)
  }
  
  ## extract pixel values without destroying type information
  getImValues <- function(x) {
    v <- as.matrix(x)
    dim(v) <- NULL
    return(v)
  }

  eval.im
})

compatible.im <- function(A, B, ..., tol=1e-6) {
  verifyclass(A, "im")
  if(missing(B)) return(TRUE)
  verifyclass(B, "im")
  if(!all(A$dim == B$dim))
    return(FALSE)
  xdiscrep <- max(abs(A$xrange - B$xrange),
                 abs(A$xstep - B$xstep),
                 abs(A$xcol - B$xcol))
  ydiscrep <- max(abs(A$yrange - B$yrange),
                 abs(A$ystep - B$ystep),
                 abs(A$yrow - B$yrow))
  xok <- (xdiscrep < tol * min(A$xstep, B$xstep))
  yok <- (ydiscrep < tol * min(A$ystep, B$ystep))
  uok <- compatible.units(unitname(A), unitname(B))
  if(!(xok && yok && uok))
    return(FALSE)
  ## A and B are compatible
  if(length(list(...)) == 0)
    return(TRUE)
  ## recursion
  return(compatible.im(B, ..., tol=tol))
}

## force a list of images to be compatible

harmonize.im <- harmonise.im <- function(...) {
  argz <- list(...)
  n <- length(argz)
  if(n < 2) return(argz)
  result <- vector(mode="list", length=n)
  isim <- unlist(lapply(argz, is.im))
  if(!any(isim))
    stop("No images supplied")
  imgs <- argz[isim]
  ## if any windows are present, extract bounding box
  iswin <- unlist(lapply(argz, is.owin))
  bb0 <- if(!any(iswin)) NULL else do.call("boundingbox", unname(argz[iswin]))
  if(length(imgs) == 1 && is.null(bb0)) {
    ## only one 'true' image: use it as template.
    result[isim] <- imgs
    Wtemplate <- imgs[[1]]
  } else {
    ## test for compatible units
    un <- lapply(imgs, unitname)
    uok <- unlist(lapply(un, compatible.units, y=un[[1]]))
    if(!all(uok))
      stop("Images have incompatible units of length")
    ## find the image with the highest resolution
    xsteps <- unlist(lapply(imgs, function(a) { a$xstep }))
    which.finest <- which.min(xsteps)
    finest <- imgs[[which.finest]]
    ## get the bounding box
    bb <- do.call("boundingbox", lapply(unname(imgs), as.rectangle))
    if(!is.null(bb0)) bb <- boundingbox(bb, bb0)
    ## determine new raster coordinates
    xcol <- prolongseq(finest$xcol, bb$xrange)
    yrow <- prolongseq(finest$yrow, bb$yrange)
    xy <- list(x=xcol, y=yrow)
    ## resample all images on new raster
    newimgs <- lapply(imgs, as.im, xy=xy)
    result[isim] <- newimgs
    Wtemplate <- newimgs[[which.finest]]
  }
  ## convert other data to images
  if(any(notim <- !isim)) 
    result[notim] <- lapply(argz[notim], as.im, W=as.mask(Wtemplate))
  names(result) <- names(argz)
  return(result)
}

## Return just the corresponding template window

commonGrid <- local({
  ## auxiliary function
  gettype <- function(x) {
    if(is.im(x) || is.mask(x)) "raster" else
    if(is.owin(x) || is.ppp(x) || is.psp(x)) "spatial" else
    "none"
  }

  commonGrid <- function(...) {
    argz <- list(...)
    type <- unlist(lapply(argz, gettype))
    israster <- (type == "raster")
    haswin   <- (type != "none")

    if(any(israster)) {
      ## Get raster data
      rasterlist <- argz[israster]
    } else {
      ## No existing raster data - apply default resolution
      if(!any(haswin))
        stop("No spatial data supplied")
      wins <- lapply(argz[haswin], as.owin)
      rasterlist <- lapply(wins, as.mask)
    }

    ## Find raster object with finest resolution
    if(length(rasterlist) == 1) {
      ## only one raster object
      finest <- rasterlist[[1]]
    } else {
      ## test for compatible units
      un <- lapply(rasterlist, unitname)
      uok <- unlist(lapply(un, compatible.units, y=un[[1]]))
      if(!all(uok))
        stop("Objects have incompatible units of length")
      ## find the image/mask with the highest resolution
      xsteps <- unlist(lapply(rasterlist, function(a) { a$xstep }))
      which.finest <- which.min(xsteps)
      finest <- rasterlist[[which.finest]]
    }
    ## determine the bounding box
    bb <- do.call("boundingbox", lapply(unname(argz[haswin]), as.rectangle))
    ## determine new raster coordinates
    xcol <- prolongseq(finest$xcol, bb$xrange)
    yrow <- prolongseq(finest$yrow, bb$yrange)
    xy <- list(x=xcol, y=yrow)
    ## generate template
    Wtemplate <- as.mask(bb, xy=xy)
    return(Wtemplate)
  }

  commonGrid
})

im.apply <- function(X, FUN, ...) {
  stopifnot(is.list(X))
  if(!all(unlist(lapply(X, is.im))))
    stop("All elements of imlist must be pixel images")
  fun <- if(is.character(FUN)) get(FUN) else
         if(is.function(FUN)) FUN else stop("Unrecognised format for FUN")
  ## ensure images are compatible
  X <- do.call(harmonise.im, X)
  template <- X[[1]]
  ## extract numerical values and convert to matrix with one column per image
  vlist <- lapply(X, function(z) as.vector(as.matrix(z)))
  vals <- matrix(unlist(vlist), ncol=length(X))
  colnames(vals) <- names(X)
  ok <- complete.cases(vals)
  if(!any(ok)) {
    ## empty result
    return(as.im(NA, W=template))
  }
  ## apply function
  resultok <- apply(vals[ok,, drop=FALSE], 1, fun, ...)
  if(length(resultok) != sum(ok))
    stop("FUN should yield one value per pixel")
  ## pack up, with attention to type of data
  d <- dim(template)
  resultmat <- matrix(resultok[1], d[1], d[2])
  resultmat[ok] <- resultok
  resultmat[!ok] <- NA
  result <- as.im(resultmat, W=X[[1]])
  if(is.factor(resultok)) levels(result) <- levels(resultok)
  return(result)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/evalcovar.R"
#'
#' evalcovar.R
#'
#'   evaluate covariate values at data points and at pixels
#'
#' $Revision: 1.17 $ $Date: 2014/12/19 07:53:03 $
#'

evalCovar <- function(model, covariate, ...) {
  UseMethod("evalCovar")
}

evalCovar.ppm <- function(model, covariate, ...,
                          lambdatype=c("cif", "trend", "intensity"),
                          dimyx=NULL, eps=NULL,
                          jitter=TRUE, 
                          modelname=NULL, covname=NULL,
                          dataname=NULL) {
  lambdatype <- match.arg(lambdatype)
  #' evaluate covariate values at data points and at pixels
  csr <- is.poisson.ppm(model) && is.stationary.ppm(model)
  #' determine names
  if(is.null(modelname))
    modelname <- if(csr) "CSR" else short.deparse(substitute(model))
  if(is.null(covname)) {
    covname <- singlestring(short.deparse(substitute(covariate)))
    if(is.character(covariate)) covname <- covariate
  }
  if(is.null(dataname))
    dataname <- model$Qname

  info <-  list(modelname=modelname, covname=covname,
                dataname=dataname, csr=csr,
                spacename="two dimensions")
  
  X <- data.ppm(model)
  W <- as.owin(model)

  #' explicit control of pixel resolution
  if(!is.null(dimyx) || !is.null(eps))
    W <- as.mask(W, dimyx=dimyx, eps=eps)

  #' evaluate covariate 
  if(is.character(covariate)) {
    #' One of the characters 'x' or 'y'
    #' Turn it into a function.
    ns <- length(covariate)
    if(ns == 0) stop("covariate is empty")
    if(ns > 1) stop("more than one covariate specified")
    covname <- covariate
    covariate <- switch(covariate,
                     x=function(x,y,m){x},
                     y=function(x,y,m){y},
                     stop(paste("Unrecognised covariate", dQuote(covariate))))
  } 
  
  if(!is.marked(model)) {
    #' ...................  unmarked .......................
    if(is.im(covariate)) {
      type <- "im"
      #' evaluate at data points by interpolation
      ZX <- interp.im(covariate, X$x, X$y)
      #' fix boundary glitches
      if(any(uhoh <- is.na(ZX)))
        ZX[uhoh] <- safelookup(covariate, X[uhoh])
      #' covariate values for pixels inside window
      Z <- covariate[W, drop=FALSE]
      #' corresponding mask
      W <- as.owin(Z)
    } else if(is.function(covariate)) {
      type <- "function"
      #' evaluate exactly at data points
      ZX <- covariate(X$x, X$y)
      if(!all(is.finite(ZX)))
        warning("covariate function returned NA or Inf values")
      #' window
      W <- as.mask(W)
      #' covariate in window
      Z <- as.im(covariate, W=W)
      #' collapse function body to single string
      covname <- singlestring(covname)
    } else if(is.null(covariate)) {
      stop("The covariate is NULL", call.=FALSE)
    } else stop(paste("The covariate should be",
                      "an image, a function(x,y)",
                      "or one of the characters",
                      sQuote("x"), "or", sQuote("y")),
                call.=FALSE)
    #' values of covariate in window
    Zvalues <- as.vector(Z[W, drop=TRUE])
    #' corresponding fitted [conditional] intensity values
    lambda <- as.vector(predict(model, locations=W,
                                type=lambdatype)[W, drop=TRUE])
    #' pixel area (constant)
    pixelarea <- with(Z, xstep * ystep)
  } else {
    #' ...................  marked .......................
    if(!is.multitype(model))
      stop("Only implemented for multitype models (factor marks)")
    marx <- marks(X, dfok=FALSE)
    possmarks <- levels(marx)
    npts <- npoints(X)
    #' single image: replicate 
    if(is.im(covariate)) {
      covariate <- rep(list(covariate), times=length(possmarks))
      names(covariate) <- as.character(possmarks)
    }
    #'
    if(is.list(covariate) && all(unlist(lapply(covariate, is.im)))) {
      #' list of images
      type <- "im"
      if(length(covariate) != length(possmarks))
        stop("Number of images does not match number of possible marks")
      #' evaluate covariate at each data point by interpolation
      ZX <- numeric(npts)
      for(k in seq_along(possmarks)) {
        ii <- (marx == possmarks[k])
        covariate.k <- covariate[[k]]
        values <- interp.im(covariate.k, x=X$x[ii], y=X$y[ii])
        #' fix boundary glitches
        if(any(uhoh <- is.na(values)))
          values[uhoh] <- safelookup(covariate.k, X[ii][uhoh])
        ZX[ii] <- values
      }
      #' restrict covariate images to window 
      Z <- lapply(covariate, function(x,W){x[W, drop=FALSE]}, W=W)
      #' extract pixel locations and pixel values
      Zframes <- lapply(Z, as.data.frame)
      #' covariate values at each pixel inside window
      Zvalues <- unlist(lapply(Zframes, function(df) { df[ , 3] }))
      #' pixel locations 
      locn <- lapply(Zframes, function(df) { df[ , 1:2] })
      #' tack on mark values
      for(k in seq_along(possmarks))
        locn[[k]] <- cbind(locn[[k]], data.frame(marks=possmarks[k]))
      loc <- do.call("rbind", locn)
      #' corresponding fitted [conditional] intensity values
      lambda <- predict(model, locations=loc, type=lambdatype)
      #' pixel areas
      pixelarea <- unlist(lapply(Z, function(z) {
        with(z, rep.int(xstep * ystep, sum(!is.na(v))))
      }))
    } else if(is.function(covariate)) {
      type <- "function"
      #' evaluate exactly at data points
      ZX <- covariate(X$x, X$y, marx)
      #' same window
      W <- as.mask(W)
      #' covariate in window
      Z <- list()
      g <- function(x,y,m,f) { f(x,y,m) }
      for(k in seq_along(possmarks))
        Z[[k]] <- as.im(g, m=possmarks[k], f=covariate, W=W)
      Zvalues <- unlist(lapply(Z, function(z) { as.data.frame(z)[,3] }))
      #' corresponding fitted [conditional] intensity values
      lambda <- predict(model, locations=W, type=lambdatype)
      lambda <- unlist(lapply(lambda, function(z) { as.data.frame(z)[,3] }))
      if(length(lambda) != length(Zvalues))
        stop("Internal error: length(lambda) != length(Zvalues)")
      #' collapse function body to single string
      covname <- singlestring(covname)
      #' pixel areas
      pixelarea <- unlist(lapply(Z, function(z) {
        with(z, rep.int(xstep * ystep, sum(!is.na(v))))
      }))
    } else if(is.null(covariate)) {
      stop("The covariate is NULL", call.=FALSE)
    } else stop(paste("For a multitype point process model,",
                      "the covariate should be an image, a list of images,",
                      "a function(x,y,m)", 
                      "or one of the characters",
                      sQuote("x"), "or", sQuote("y")),
                call.=FALSE)
  }    
  #' ..........................................................

  #' apply jittering to avoid ties
  if(jitter) {
    nX <- length(ZX)
    dZ <- 0.3 * quantile(diff(sort(unique(c(ZX, Zvalues)))), 1/min(20, nX))
    ZX <- ZX + rnorm(nX, sd=dZ)
    Zvalues <- Zvalues + rnorm(length(Zvalues), sd=dZ)
  }

  lambdaname <- if(is.poisson(model)) "intensity" else lambdatype
  lambdaname <- paste("the fitted", lambdaname)
  check.finite(lambda, xname=lambdaname, usergiven=FALSE)
  check.finite(Zvalues, xname="the covariate", usergiven=TRUE)
  
  #' wrap up 
  values <- list(Zimage    = Z,
                 Zvalues   = Zvalues,
                 lambda    = lambda,
                 weights   = pixelarea,
                 ZX        = ZX,
                 type      = type)
  return(list(values=values, info=info))
}

evalCovar.lppm <- function(model, covariate, ...,
                           lambdatype=c("cif", "trend", "intensity"),
                           eps=NULL, nd=1000,
                           jitter=TRUE, 
                           modelname=NULL, covname=NULL,
                           dataname=NULL) {
  lambdatype <- match.arg(lambdatype)
  #' evaluate covariate values at data points and at pixels
  csr <- is.poisson(model) && is.stationary(model)

  #' determine names
  if(is.null(modelname))
    modelname <- if(csr) "CSR" else short.deparse(substitute(model))
  if(is.null(covname)) {
    covname <- singlestring(short.deparse(substitute(covariate)))
    if(is.character(covariate)) covname <- covariate
  }
  if(is.null(dataname))
    dataname <- model$Xname
  info <-  list(modelname=modelname, covname=covname,
                dataname=dataname, csr=csr,
                spacename="linear network")

  #' convert character covariate to function
  if(is.character(covariate)) {
    #' One of the characters 'x' or 'y'
    #' Turn it into a function.
    ns <- length(covariate)
    if(ns == 0) stop("covariate is empty")
    if(ns > 1) stop("more than one covariate specified")
    covname <- covariate
    covariate <- switch(covariate,
                     x=function(x,y,m){x},
                     y=function(x,y,m){y},
                     stop(paste("Unrecognised covariate", dQuote(covariate))))
  }
  
  #' extract model components
  X <- model$X
  fit <- model$fit
  #'
  L <- as.linnet(X)
  Q <- quad.ppm(fit)
  isdat <- is.data(Q)
  U <- union.quad(Q)
  wt <- w.quad(Q)
  
  #' evaluate covariate
  if(!is.marked(model)) {
    #' ...................  unmarked .......................
    if(is.im(covariate)) {
      if(inherits(covariate, "linim")) {
        type <- "linim"
        Zimage <- covariate
      } else {
        type <- "im"
        Zimage <- as.linim(covariate, L)
      }
      #' evaluate at quadrature points by interpolation
      Zvalues <- interp.im(covariate, U$x, U$y)
      #' fix boundary glitches
      if(any(uhoh <- is.na(Zvalues)))
        Zvalues[uhoh] <- safelookup(covariate, U[uhoh])
      #' extract data values
      ZX <- Zvalues[isdat]
    } else if(is.function(covariate)) {
      type <- "function"
      Zimage <- as.linim(covariate, L)
      #' evaluate exactly at quadrature points
      Zvalues <- covariate(U$x, U$y)
      if(!all(is.finite(Zvalues)))
        warning("covariate function returned NA or Inf values")
      #' extract data values
      ZX <- Zvalues[isdat]
      #' collapse function body to single string
      covname <- singlestring(covname)
    } else if(is.null(covariate)) {
      stop("The covariate is NULL", call.=FALSE)
    } else stop(paste("The covariate should be",
                      "an image, a function(x,y)",
                      "or one of the characters",
                      sQuote("x"), "or", sQuote("y")),
                call.=FALSE)
    #' corresponding fitted [conditional] intensity values
    lambda <- as.vector(predict(model, locations=U, type=lambdatype))
  } else {
    #' ...................  marked .......................
    if(!is.multitype(model))
      stop("Only implemented for multitype models (factor marks)")
    marx <- marks(U, dfok=FALSE)
    possmarks <- levels(marx)
    #' single image: replicate 
    if(is.im(covariate))
      covariate <- lapply(possmarks, function(x,v){v}, v=covariate)
    #'
    if(is.list(covariate) && all(unlist(lapply(covariate, is.im)))) {
      #' list of images
      if(length(covariate) != length(possmarks))
        stop("Number of images does not match number of possible marks")
      #' determine type of data
      islinim <- unlist(lapply(covariate, inherits, what="linim"))
      type <- if(all(islinim)) "linim" else "im"
      Zimage <- covariate
      Zimage[!islinim] <- lapply(Zimage[!islinim], as.linim, L=L)
      #' evaluate covariate at each data point by interpolation
      Zvalues <- numeric(npoints(U))
      for(k in seq_along(possmarks)) {
        ii <- (marx == possmarks[k])
        covariate.k <- covariate[[k]]
        values <- interp.im(covariate.k, x=U$x[ii], y=U$y[ii])
        #' fix boundary glitches
        if(any(uhoh <- is.na(values)))
          values[uhoh] <- safelookup(covariate.k, U[ii][uhoh])
        Zvalues[ii] <- values
      }
      #' extract data values
      ZX <- Zvalues[isdat]
      #' corresponding fitted [conditional] intensity values
      lambda <- predict(model, locations=U, type=lambdatype)
      if(length(lambda) != length(Zvalues))
        stop("Internal error: length(lambda) != length(Zvalues)")
    } else if(is.function(covariate)) {
      type <- "function"
      #' evaluate exactly at quadrature points
      Zvalues <- covariate(U$x, U$y, marx)
      #' extract data values
      ZX <- Zvalues[isdat]
      #' corresponding fitted [conditional] intensity values
      lambda <- predict(model, locations=U, type=lambdatype)
      if(length(lambda) != length(Zvalues))
        stop("Internal error: length(lambda) != length(Zvalues)")
      #' images
      Zimage <- list()
      g <- function(x,y,m,f) { f(x,y,m) }
      for(k in seq_along(possmarks))
        Zimage[[k]] <- as.linim(g, L=L, m=possmarks[k], f=covariate)
      #' collapse function body to single string
      covname <- singlestring(covname)
    } else if(is.null(covariate)) {
      stop("The covariate is NULL", call.=FALSE)
    } else stop(paste("For a multitype point process model,",
                      "the covariate should be an image, a list of images,",
                      "a function(x,y,m)", 
                      "or one of the characters",
                      sQuote("x"), "or", sQuote("y")),
                call.=FALSE)
  }    
  #' ..........................................................

  #' apply jittering to avoid ties
  if(jitter) {
    nX <- length(ZX)
    dZ <- 0.3 * quantile(diff(sort(unique(c(ZX, Zvalues)))), 1/min(20, nX))
    ZX <- ZX + rnorm(nX, sd=dZ)
    Zvalues <- Zvalues + rnorm(length(Zvalues), sd=dZ)
  }

  lambdaname <- if(is.poisson(model)) "intensity" else lambdatype
  lambdaname <- paste("the fitted", lambdaname)
  check.finite(lambda, xname=lambdaname, usergiven=FALSE)
  check.finite(Zvalues, xname="the covariate", usergiven=TRUE)

  #' wrap up 
  values <- list(Zimage    = Zimage,
                 Zvalues   = Zvalues,
                 lambda    = lambda,
                 weights   = wt,
                 ZX        = ZX,
                 type      = type)
  return(list(values=values, info=info))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/ewcdf.R"
#
#     ewcdf.R
#
#     $Revision: 1.7 $  $Date: 2013/12/18 02:33:22 $
#
#  With contributions from Kevin Ummel
#

ewcdf <- function(x, weights=rep(1/length(x), length(x)))
{
  stopifnot(length(x) == length(weights))
  # remove NA's together
  nbg <- is.na(x) 
  x <- x[!nbg]
  weights <- weights[!nbg]
  n <- length(x)
  if (n < 1)
    stop("'x' must have 1 or more non-missing values")
  stopifnot(all(weights >= 0))
  # sort in increasing order of x value
  ox <- fave.order(x)
  x <- x[ox]
  w <- weights[ox]
  # find jump locations and match
  vals <- sort(unique(x))
  xmatch <- factor(match(x, vals), levels=seq_along(vals))
  # sum weight in each interval
  wmatch <- tapply(w, xmatch, sum)
  wmatch[is.na(wmatch)] <- 0
  cumwt <- cumsum(wmatch)
  # make function
  rval <- approxfun(vals, cumwt,
                    method = "constant", yleft = 0, yright = sum(wmatch),
                    f = 0, ties = "ordered")
  class(rval) <- c("ewcdf", "ecdf", "stepfun", class(rval))
  assign("w", w, envir=environment(rval))
  attr(rval, "call") <- sys.call()
  return(rval)
}

  # Hacked from stats:::print.ewcdf
print.ewcdf <- function (x, digits = getOption("digits") - 2L, ...) {
  cat("Weighted empirical CDF \nCall: ")
  print(attr(x, "call"), ...)
  env <- environment(x)
  xx <- get("x", envir=env)
  ww <- get("w", envir=env)
  n <- length(xx)
  i1 <- 1L:min(3L, n)
  i2 <- if (n >= 4L) max(4L, n - 1L):n else integer()
  numform <- function(x) paste(formatC(x, digits = digits), collapse = ", ")
  cat(" x[1:", n, "] = ", numform(xx[i1]), if (n > 3L) 
      ", ", if (n > 5L) 
      " ..., ", numform(xx[i2]), "\n", sep = "")
  cat(" weights[1:", n, "] = ", numform(ww[i1]), if (n > 3L) 
      ", ", if (n > 5L) 
      " ..., ", numform(ww[i2]), "\n", sep = "")
  invisible(x)
}

quantile.ewcdf <- function(x, probs=seq(0,1,0.25), names=TRUE, ...) {
  trap.extra.arguments(..., .Context="quantile.ewcdf")
  env <- environment(x)
  xx <- get("x", envir=env)
  Fxx <- get("y", envir=env)
  n <- length(xx)
  eps <- 100 * .Machine$double.eps
  if(any((p.ok <- !is.na(probs)) & (probs < -eps | probs > 1 + eps))) 
    stop("'probs' outside [0,1]")
  if (na.p <- any(!p.ok)) {
    o.pr <- probs
    probs <- probs[p.ok]
    probs <- pmax(0, pmin(1, probs))
  }
  np <- length(probs)
  if (n > 0 && np > 0) {
    qs <- numeric(np)
    for(k in 1:np) qs[k] <- xx[min(which(Fxx >= probs[k]))]
  } else {
    qs <- rep(NA_real_, np)
  }
  if (names && np > 0L) {
    dig <- max(2L, getOption("digits"))
    probnames <-
      if(np < 100) formatC(100 * probs, format="fg", width=1, digits=dig) else
      format(100 * probs, trim = TRUE, digits = dig)
    names(qs) <- paste0(probnames, "%")
  }
  if (na.p) {
    o.pr[p.ok] <- qs
    names(o.pr) <- rep("", length(o.pr))
    names(o.pr)[p.ok] <- names(qs)
    o.pr
  } else qs
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/exactMPLEstrauss.R"
#
# exactMPLEstrauss.R
#
# 'exact' MPLE for stationary Strauss process
#
#  $Revision: 1.6 $  $Date: 2014/11/10 07:39:41 $
#

exactMPLEstrauss <- local({

  # main function
  exactMPLEstrauss <- function(X, R, ngrid=2048, plotit=FALSE, project=TRUE) {
#    n <- npoints(X)
    W <- as.owin(X)
    # border correction
    WminR <- erosion(W, R)
    bR <- (bdist.points(X) >= R)
    nR <- sum(bR)
    # evaluate neighbour counts for data points
    Tcounts <- crosspaircounts(X, X, R) - 1
    sumT  <- sum(Tcounts[bR])
    # determine the coefficients a_k for k = 0, 1, ...
    Z <- scanmeasure(X, R, dimyx=ngrid)
    Z <- Z[WminR, drop=FALSE]
    kcounts <- tabulate(as.vector(Z$v) + 1L)
    pixarea <- with(Z, xstep * ystep)
    A <- kcounts * pixarea
    # find optimal log(gamma)
    op <- optim(log(0.5), lpl, sco, method="L-BFGS-B",
                control=list(fnscale=-1),
                lower=-Inf, upper=if(project) 0 else Inf,
                A=A, sumT=sumT, nR=nR)
    loggamma <- op$par
    # plot?
    if(plotit) {
      x <- seq(log(1e-4), if(project) 0 else log(1e4), length=512)
      plot(x, lpl(x, A, sumT, nR),
           type="l",
           xlab=expression(log(gamma)),
           ylab=expression(log(PL(gamma))))
      abline(v=loggamma, lty=3)
    }
    # derive optimal beta 
    kmax <-length(A) - 1
    polypart <- A %*% exp(outer(0:kmax, loggamma))
    beta <- nR/polypart
    logbeta <- log(beta)
    result <- c(logbeta, loggamma)
    names(result) <- c("(Intercept)", "Interaction")
    return(result)
  }

  # helper functions (vectorised)
  # log pseudolikelihood
  lpl <- function(theta, A=A, sumT=sumT, nR=nR) {
    kmax <-length(A) - 1
    polypart <- A %*% exp(outer(0:kmax, theta))
    nR * (log(nR) - log(polypart) - 1) + theta * sumT
  }
  # pseudoscore
  sco <- function(theta, A=A, sumT=sumT, nR=nR) {
    kmax <- length(A) - 1
    kseq <- 0:kmax
    mat <- exp(outer(kseq, theta))
    polypart <- A %*% mat
    Dpolypart <- (A * kseq) %*% mat
    sumT - nR * Dpolypart/polypart
  }

  exactMPLEstrauss
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/exactPdt.R"
#
#	exactPdt.R
#	R function exactPdt() for exact distance transform of pixel image
#
#	$Revision: 4.16 $	$Date: 2014/10/24 00:22:30 $
#

"exactPdt"<-
  function(w)
{
  verifyclass(w, "owin")
  if(w$type != "mask")
    stop(paste("Input must be a window of type", sQuote("mask")))
#	
  nr <- w$dim[1]
  nc <- w$dim[2]
# input image will be padded out with a margin of width 2 on all sides
  mr <- mc <- 2L
  # full dimensions of padded image
  Nnr <- nr + 2 * mr
  Nnc <- nc + 2 * mc
  N <- Nnr * Nnc
  # output image (subset): rows & columns (R indexing)
  rmin <- mr + 1
  rmax <- Nnr - mr
  cmin <- mc + 1
  cmax <- Nnc - mc
  # do padding
  x <- matrix(FALSE, nrow=Nnr, ncol=Nnc)
  x[rmin:rmax, cmin:cmax] <- w$m
  #
  res <- .C("ps_exact_dt_R",
            as.double(w$xrange[1]),
            as.double(w$yrange[1]),
            as.double(w$xrange[2]),
            as.double(w$yrange[2]),
            nr = as.integer(nr),
            nc = as.integer(nc),
            mr = as.integer(mr),
            mc = as.integer(mc),
            inp = as.integer(t(x)),
            distances = as.double (double(N)),
            rows      = as.integer(integer(N)),
            cols      = as.integer(integer(N)),
            boundary  = as.double (double(N)))
  dist <- matrix(res$distances,
                 ncol=Nnc, nrow=Nnr, byrow = TRUE)[rmin:rmax, cmin:cmax]
  rows <- matrix(res$rows,
                 ncol=Nnc, nrow=Nnr, byrow = TRUE)[rmin:rmax, cmin:cmax]
  cols <- matrix(res$cols,
                 ncol=Nnc, nrow=Nnr, byrow = TRUE)[rmin:rmax, cmin:cmax]
  bdist<- matrix(res$boundary,
                 ncol=Nnc, nrow=Nnr, byrow = TRUE)[rmin:rmax, cmin:cmax]
  # convert from C to R indexing
  rows <- rows + 1L - as.integer(mr)
  cols <- cols + 1L - as.integer(mc)
  return(list(d=dist,row=rows,col=cols,b=bdist, w=w))
}

project2set <- function(X, W, ...) {
  stopifnot(is.ppp(X))
  W <- as.mask(W, ...)
  eW <- exactPdt(W)
  ## grid location of X
  XX <- nearest.raster.point(X$x, X$y, W)
  ijX <- cbind(XX$row, XX$col)
  ## look up values of 'eW' at this location 
  iY <- eW$row[ijX]
  jY <- eW$col[ijX]
  ## convert to spatial coordinates
  Y <- ppp(W$xcol[jY], W$yrow[iY], window=W)
  return(Y)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/exactdt.R"
#
#	exactdt.S
#	S function exactdt() for exact distance transform
#
#	$Revision: 4.16 $	$Date: 2014/10/24 00:22:30 $
#

exactdt <- local({

  die <- function(why) { stop(paste("ppp object format corrupted:", why)) }

  exactdt <- function(X, ...) {
    verifyclass(X, "ppp")
    w <- X$window
    if(spatstat.options("exactdt.checks.data")) {
      ## check validity of ppp structure 
      bb <- as.rectangle(w)
      xr <- bb$xrange
      yr <- bb$yrange
      rx <- range(X$x)
      ry <- range(X$y)
      if(rx[1] < xr[1] || rx[2] > xr[2]) die("x-coordinates out of bounds")
      if(ry[1] < yr[1] || ry[2] > yr[2]) die("y-coordinates out of bounds")
      if(length(X$x) != length(X$y))
        die("x and y vectors have different length")
      if(length(X$x) != X$n) die("length of x,y vectors does not match n")
    }
    w <- as.mask(w, ...)
    ## dimensions of result
    nr <- w$dim[1]
    nc <- w$dim[2]
    ## margins in C array 
    mr <- 2
    mc <- 2
    ## full dimensions of allocated storage
    Nnr <- nr + 2 * mr
    Nnc <- nc + 2 * mc
    N <- Nnr * Nnc
    ## output rows & columns (R indexing)
    rmin <- mr + 1
    rmax <- Nnr - mr
    cmin <- mc + 1
    cmax <- Nnc - mc
    ## go
    res <- .C("exact_dt_R",
              as.double(X$x),
              as.double(X$y),
              as.integer(X$n),
              as.double(w$xrange[1]),
              as.double(w$yrange[1]),
              as.double(w$xrange[2]),
              as.double(w$yrange[2]),
              nr = as.integer(nr),
              nc = as.integer(nc),
              mr = as.integer(mr),
              mc = as.integer(mc),
              distances = as.double(double(N)),
              indices = as.integer(integer(N)),
              boundary = as.double(double(N)))
    ## extract 
    dist <- matrix(res$distances,
                   ncol=Nnc, nrow=Nnr, byrow = TRUE)[rmin:rmax, cmin:cmax]
    inde <- matrix(res$indices,
                   ncol=Nnc, nrow=Nnr, byrow = TRUE)[rmin:rmax, cmin:cmax]
    bdry <- matrix(res$boundary,
                   ncol=Nnc, nrow=Nnr, byrow = TRUE)[rmin:rmax, cmin:cmax]
    ## convert index from C to R indexing
    inde <- inde + 1L
    return(list(d = dist, i = inde, b = bdry, w=w))
  }

  exactdt
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/fardist.R"
##
##  fardist.R
##
## Farthest distance to boundary, and circumradius
##
##  $Revision: 1.7 $ $Date: 2014/10/24 00:22:30 $

fardist <- function(X, ...) {
  UseMethod("fardist")
}

fardist.owin <- function(X, ..., squared=FALSE) {
  verifyclass(X, "owin")
  M <- as.mask(X, ...)
  V <- if(is.mask(X)) vertices(M) else vertices(X)
  nx <- dim(M)[2]
  ny <- dim(M)[1]
  x0 <- M$xcol[1]
  y0 <- M$yrow[1]
  xstep <- M$xstep
  ystep <- M$ystep
  if(squared) {
    z <- .C("fardist2grid",
            nx = as.integer(nx),
            x0 = as.double(x0),
            xstep = as.double(xstep),
            ny = as.integer(ny),
            y0 = as.double(y0),
            ystep = as.double(ystep),
            np = as.integer(length(V$x)),
            xp = as.double(V$x),
            yp = as.double(V$y),
            dfar = as.double(numeric(nx * ny)))
  } else {
    z <- .C("fardistgrid",
            nx = as.integer(nx),
            x0 = as.double(x0),
            xstep = as.double(xstep),
            ny = as.integer(ny),
            y0 = as.double(y0),
            ystep = as.double(ystep),
            np = as.integer(length(V$x)),
            xp = as.double(V$x),
            yp = as.double(V$y),
            dfar = as.double(numeric(nx * ny)))
  }
  out <- im(z$dfar, xcol=M$xcol, yrow=M$yrow,
            xrange=M$xrange, yrange=M$yrange, unitname=unitname(M))
  if(!is.rectangle(X))
    out <- out[X, drop=FALSE]
  return(out)
}
  
fardist.ppp <- function(X, ..., squared=FALSE) {
  verifyclass(X, "ppp")
  V <- vertices(Window(X))
  D2 <- crossdist(X$x, X$y, V$x, V$y, squared=TRUE) 
  D2max <- apply(D2, 1, max)
  if(squared) return(D2max) else return(sqrt(D2max))
}

circumradius <- function(x, ...) {
  UseMethod("circumradius")
}

circumradius.owin <- function(x, ...) {
  sqrt(min(fardist(x, ..., squared=TRUE)))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/fasp.R"
#
#	fasp.R
#
#	$Revision: 1.32 $	$Date: 2013/07/05 06:13:00 $
#
#
#-----------------------------------------------------------------------------
#

# creator
fasp <- function(fns, which, formulae=NULL,
                 dataname=NULL, title=NULL, rowNames=NULL, colNames=NULL,
                 checkfv=TRUE) {
  stopifnot(is.list(fns))
  stopifnot(is.matrix(which))
  stopifnot(length(fns) == length(which))
  n   <- length(which)

  if(checkfv)
    for(i in seq_len(n))
      if(!is.fv(fns[[i]]))
        stop(paste("fns[[", i, "]] is not an fv object", sep=""))

  # set row and column labels
  if(!is.null(rowNames))
    rownames(which) <- rowNames
  if(!is.null(colNames))
    colnames(which) <- colNames

  if(!is.null(formulae)) {
    # verify format and convert to character vector
    formulae <- FormatFaspFormulae(formulae, "formulae")
    # ensure length matches length of "fns"
    if(length(formulae) == 1 && n > 1)
        # single formula - replicate it
        formulae <- rep.int(formulae, n)
    else 
        stopifnot(length(formulae) == length(which))
  }

  rslt <- list(fns=fns, 
               which=which, default.formula=formulae,
               dataname=dataname, title=title)
  class(rslt) <- "fasp"
  return(rslt)
}

# subset extraction operator

"[.fasp" <-
  function(x, I, J, drop=TRUE, ...) {

        verifyclass(x, "fasp")
        
        m <- nrow(x$which)
        n <- ncol(x$which)
        
        if(missing(I)) I <- 1:m
        if(missing(J)) J <- 1:n
        if(!is.vector(I) || !is.vector(J))
          stop("Subset operator is only implemented for vector indices")

        # determine index subset for lists 'fns', 'titles' etc
        included <- rep.int(FALSE, length(x$fns))
        w <- as.vector(x$which[I,J])
        if(length(w) == 0)
          stop("result is empty")
        included[w] <- TRUE

        # if only one cell selected, and drop=TRUE:
        if((sum(included) == 1) && drop)
          return(x$fns[included][[1]])
        
        # determine positions in shortened lists
        whichIJ <- x$which[I,J,drop=FALSE]
        newk <- cumsum(included)
        newwhich <- matrix(newk[whichIJ],
                           ncol=ncol(whichIJ), nrow=nrow(whichIJ))
        rownames(newwhich) <- rownames(x$which)[I]
        colnames(newwhich) <- colnames(x$which)[J]

        # default plotting formulae - could be NULL
        deform <- x$default.formula
        
        # create new fasp object
        Y <- fasp(fns      = x$fns[included],
                  formulae = if(!is.null(deform)) deform[included] else NULL,
                  which    = newwhich,
                  dataname = x$dataname,
                  title    = x$title)
        return(Y)
}

dim.fasp <- function(x) { dim(x$which) }

# print method

print.fasp <- function(x, ...) {
  verifyclass(x, "fasp")
  cat(paste("Function array (class", sQuote("fasp"), ")\n"))
  dim <- dim(x$which)
  cat(paste("Dimensions: ", dim[1], "x", dim[2], "\n"))
  cat(paste("Title:", if(is.null(x$title)) "(None)" else x$title, "\n"))
  invisible(NULL)
}

# other methods

as.fv.fasp <- function(x) do.call("cbind.fv", x$fns)

dimnames.fasp <- function(x) {
  return(dimnames(x$which))
}

"dimnames<-.fasp" <- function(x, value) {
  w <- x$which
  dimnames(w) <- value
  x$which <- w
  return(x)
}

pool.fasp <- function(...) {
  Alist <- list(...)
  Yname <- short.deparse(sys.call())
  if(nchar(Yname) > 60) Yname <- paste(substr(Yname, 1, 40), "[..]")
  nA <-  length(Alist)
  if(nA == 0) return(NULL)
  # validate....
  # All arguments must be fasp objects
  notfasp <- !unlist(lapply(Alist, inherits, what="fasp"))
  if(any(notfasp)) {
    n <- sum(notfasp)
    why <- paste(ngettext(n, "Argument", "Arguments"),
                 commasep(which(notfasp)),
                 ngettext(n, "does not", "do not"),
                 "belong to the class",
                 dQuote("fasp"))
    stop(why)
  }
  # All arguments must have envelopes
  has.env <- function(z) {
    all(unlist(lapply(z$fns, inherits, what="envelope")))
  }
  notenv <- !unlist(lapply(Alist, has.env))
  if(any(notenv)) {
    n <- sum(notenv)
    why <- paste(ngettext(n, "Argument", "Arguments"),
                 commasep(which(notenv)),
                 ngettext(n, "does not", "do not"),
                 "contain envelope data")
    stop(why)
  }
  
  if(nA == 1) return(Alist[[1]])
  
  # All arguments must have the same dimensions
  witches <- lapply(Alist, function(z) { z$which })
  witch1 <- witches[[1]]
  same <- unlist(lapply(witches, identical, y=witch1))
  if(!all(same))
    stop("Function arrays do not have the same array dimensions")
  
  # OK.
  # Pool envelopes at each position
  result <- Alist[[1]]
  fns <- result$fns
  for(k in seq_along(fns)) {
    funks <- lapply(Alist, function(z, k) { z$fns[[k]] }, k=k)
    fnk <- do.call("pool.envelope", funks)
    attr(fnk, "einfo")$Yname <- Yname
    fns[[k]] <- fnk
  }
  result$fns <- fns

  return(result)
}

# other functions

FormatFaspFormulae <- function(f, argname) {
  # f should be a single formula object, a list of formula objects,
  # a character vector, or a list containing formulae and strings.
  # It will be converted to a character vector.
  
  zapit <- function(x, argname) {
    if(inherits(x, "formula")) deparse(x)
    else if(is.character(x)) x
    else stop(paste("The entries of",
                    sQuote(argname),
                    "must be formula objects or strings"))
  }

  result <-
    if(is.character(f))
      f
    else if(inherits(f, "formula"))
      deparse(f)
    else if(is.list(f))
      unlist(lapply(f, zapit, argname=argname))
    else stop(paste(sQuote(argname),
                    "should be a formula, a list of formulae,",
                    "or a character vector"))

  return(result)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/fgk3.R"
#
#	$Revision: 1.19 $	$Date: 2014/10/24 00:22:30 $
#
#	Estimates of F, G and K for three-dimensional point patterns
#
#
#  ............ user interface .............................
#

K3est <- function(X, ...,
                  rmax=NULL, nrval=128,
                  correction=c("translation", "isotropic"))
{
  stopifnot(inherits(X, "pp3"))
  correction <- pickoption("correction", correction,
                           c(translation="translation",
			     trans="translation",
                             isotropic="isotropic",
                             iso="isotropic",
                             best="isotropic"),
                           multi=TRUE)
  trap.extra.arguments(..., .Context="In K3est")
  B <- X$domain
  if(is.null(rmax))
    rmax <- diameter(B)/2
  r <- seq(from=0, to=rmax, length.out=nrval)

  # this will be the output data frame
  K <- data.frame(r=r, theo= (4/3) * pi * r^3)
  desc <- c("distance argument r", "theoretical Poisson %s")
  K <- fv(K, "r", substitute(K3(r), NULL),
          "theo", , c(0,rmax/2), c("r","%s[pois](r)"), desc, fname="K3")

  # extract the x,y,z ranges as a vector of length 6
  flatbox <- unlist(B[1:3])

  # extract coordinates
  coo <- coords(X)
  
  if(any(correction %in% "translation")) {
    u <- k3engine(coo$x, coo$y, coo$z, flatbox,
                  rmax=rmax, nrval=nrval, correction="translation")
    Kt <- u$f
    K <- bind.fv(K, data.frame(trans=Kt), "%s[trans](r)",
                 "translation-corrected estimate of %s",
                 "trans")
  }
  if(any(correction %in% "isotropic")) {
    u <- k3engine(coo$x, coo$y, coo$z, flatbox,
                  rmax=rmax, nrval=nrval, correction="isotropic")
    Ki <- u$f
    K <- bind.fv(K, data.frame(iso=Ki), "%s[iso](r)",
                 "isotropic-corrected estimate of %s",
                 "iso")
  }
  # default is to display them all
  formula(K) <- . ~ r
  unitname(K) <- unitname(X)
  return(K)
}
                  
G3est <- function(X, ...,
                  rmax=NULL, nrval=128,
                  correction=c("rs", "km", "Hanisch"))
{
  stopifnot(inherits(X, "pp3"))
  correction <- pickoption("correction", correction,
                           c(rs="rs",
                             border="rs",
                             km="km",
                             KM="km",
                             Hanisch="han",
                             hanisch="han",
                             best="km"),
                           multi=TRUE)
  trap.extra.arguments(..., .Context="In G3est")
  B <- X$domain
  if(is.null(rmax))
    rmax <- diameter(B)/2
  r <- seq(from=0, to=rmax, length.out=nrval)

  coo <- coords(X)
  lambda <- nrow(coo)/volume(B)
  
  # this will be the output data frame
  G <- data.frame(r=r, theo= 1 - exp( - lambda * (4/3) * pi * r^3))
  desc <- c("distance argument r", "theoretical Poisson %s")
  G <- fv(G, "r", substitute(G3(r), NULL),
          "theo", , c(0,rmax/2), c("r","%s[pois](r)"), desc, fname="G3")

  # extract the x,y,z ranges as a vector of length 6
  flatbox <- unlist(B[1:3])

  # collect four histograms for censored data
  u <- g3Cengine(coo$x, coo$y, coo$z, flatbox,
                 rmax=rmax, nrval=nrval)

  if("rs" %in% correction) 
    G <- bind.fv(G, data.frame(rs=u$rs), "%s[rs](r)",
                  "reduced sample estimate of %s",
                  "rs")
  if("km" %in% correction)
    G <- bind.fv(G, data.frame(km=u$km), "%s[km](r)",
                  "Kaplan-Meier estimate of %s",
                  "km")
  if("han" %in% correction) 
    G <- bind.fv(G, data.frame(han=u$han), "%s[han](r)",
                  "Normalised Hanisch estimate of %s",
                  "han")
  # default is to display them all
  formula(G) <- . ~ r
  unitname(G) <- unitname(X)
  return(G)
}

F3est <- function(X, ...,
                  rmax=NULL, nrval=128, vside=NULL,
                  correction=c("rs", "km", "cs"),
                  sphere=c("fudge", "ideal", "digital"))
{
  stopifnot(inherits(X, "pp3"))
  sphere <- match.arg(sphere)
  correction <- pickoption("correction", correction,
                           c(rs="rs",
                             border="rs",
                             km="km",
                             KM="km",
                             Kaplan="km",
                             cs="cs",
                             CS="cs",
                             best="km"),
                           multi=TRUE)
  trap.extra.arguments(..., .Context="In F3est")
  B <- X$domain
  if(is.null(rmax))
    rmax <- diameter(B)/2
  r <- seq(from=0, to=rmax, length.out=nrval)

  coo <- coords(X)
  vol <- volume(B)
  lambda <- nrow(coo)/vol

  # determine voxel size
  if(missing(vside)) {
    voxvol <- vol/spatstat.options("nvoxel")
    vside <- voxvol^(1/3)
    # ensure the shortest side is a whole number of voxels
    s <- shortside(B)
    m <- ceiling(s/vside)
    vside <- s/m
  }

  # compute theoretical value
  switch(sphere,
         ideal = {
           volsph <- (4/3) * pi * r^3
           spherename <- "ideal sphere"
         },
         fudge = {
           volsph <- 0.78 * (4/3) * pi * r^3
           spherename <- "approximate sphere"
         },
         digital = {
           volsph <- digital.volume(c(0, rmax), nrval, vside)
           spherename <- "digital sphere"
         })
  theo.desc <- paste("theoretical Poisson %s using", spherename)
           
  # this will be the output data frame
  FF <- data.frame(r     = r,
                   theo  = 1 - exp( - lambda * volsph))
  desc <- c("distance argument r", theo.desc)
  labl <- c("r","%s[pois](r)")
  FF <- fv(FF, "r", substitute(F3(r), NULL),
          "theo", , c(0,rmax/2), labl, desc, fname="F3")

  # extract the x,y,z ranges as a vector of length 6
  flatbox <- unlist(B[1:3])

  # go
  u <- f3Cengine(coo$x, coo$y, coo$z, flatbox,
                 rmax=rmax, nrval=nrval, vside=vside)

  if("rs" %in% correction) 
    FF <- bind.fv(FF, data.frame(rs=u$rs), "%s[rs](r)",
                  "reduced sample estimate of %s",
                  "rs")
  if("km" %in% correction)
    FF <- bind.fv(FF, data.frame(km=u$km), "%s[km](r)",
                  "Kaplan-Meier estimate of %s",
                  "km")
  if("cs" %in% correction)
    FF <- bind.fv(FF, data.frame(cs=u$cs), "%s[cs](r)",
                  "Chiu-Stoyan estimate of %s",
                  "cs")
  # default is to display them all
  formula(FF) <- . ~ r
  unitname(FF) <- unitname(X)
  return(FF)
}

pcf3est <- function(X, ...,
                    rmax=NULL, nrval=128,
                    correction=c("translation", "isotropic"),
                    delta=NULL, adjust=1, biascorrect=TRUE)
{
  stopifnot(inherits(X, "pp3"))
  correction <- pickoption("correction", correction,
                           c(translation="translation",
                             trans="translation",
                             isotropic="isotropic",
                             iso="isotropic",
                             best="isotropic"),
                           multi=TRUE)
  trap.extra.arguments(..., .Context="In pcf3est")
  B <- X$domain
  if(is.null(rmax))
    rmax <- diameter(B)/2
  r <- seq(from=0, to=rmax, length.out=nrval)

  if(is.null(delta)) {
    lambda <- npoints(X)/volume(B)
    delta <- adjust * 0.26/lambda^(1/3)
  }
  if(biascorrect) {
    # bias correction
    rondel <- r/delta
    biasbit <- ifelseAX(rondel > 1, 1, (3/4)*(rondel + 2/3 - (1/3)*rondel^3))
  }

  # this will be the output data frame
  g <- data.frame(r=r, theo=rep.int(1, length(r)))
  desc <- c("distance argument r", "theoretical Poisson %s")
  g <- fv(g, "r", substitute(pcf3(r), NULL),
          "theo", , c(0,rmax/2), c("r","%s[pois](r)"), desc, fname="pcf3")

  # extract the x,y,z ranges as a vector of length 6
  flatbox <- unlist(B[1:3])

  # extract coordinates
  coo <- coords(X)
  
  if(any(correction %in% "translation")) {
    u <- pcf3engine(coo$x, coo$y, coo$z, flatbox,
                  rmax=rmax, nrval=nrval, correction="translation", delta=delta)
    gt <- u$f
    if(biascorrect)
      gt <- gt/biasbit
    g <- bind.fv(g, data.frame(trans=gt), "%s[trans](r)",
                 "translation-corrected estimate of %s",
                 "trans")
  }
  if(any(correction %in% "isotropic")) {
    u <- pcf3engine(coo$x, coo$y, coo$z, flatbox,
                  rmax=rmax, nrval=nrval, correction="isotropic", delta=delta)
    gi <- u$f
    if(biascorrect)
      gi <- gi/biasbit
    g <- bind.fv(g, data.frame(iso=gi), "%s[iso](r)",
                 "isotropic-corrected estimate of %s",
                 "iso")
  }
  # default is to display them all
  formula(g) <- . ~ r
  unitname(g) <- unitname(X)
  attr(g, "delta") <- delta
  return(g)
}

#  ............ low level code ..............................
#
k3engine <- function(x, y, z, box=c(0,1,0,1,0,1),
                     rmax=1, nrval=100, correction="translation") 
{
  code <- switch(correction, translation=0, isotropic=1)
  res <- .C("RcallK3",
            as.double(x), as.double(y), as.double(z), 
            as.integer(length(x)),
            as.double(box[1]), as.double(box[2]), 
            as.double(box[3]), as.double(box[4]), 
            as.double(box[5]), as.double(box[6]), 
            as.double(0), as.double(rmax), 
            as.integer(nrval),
            f = as.double(numeric(nrval)),
            num = as.double(numeric(nrval)),
            denom = as.double(numeric(nrval)),
            as.integer(code))
  return(list(range = c(0,rmax),
              f = res$f, num=res$num, denom=res$denom, 
              correction=correction))
}
#
#
#
g3engine <- function(x, y, z, box=c(0,1,0,1,0,1), 
                     rmax=1, nrval=10, correction="Hanisch G3") 
{
	code <- switch(correction, "minus sampling"=1, "Hanisch G3"=3)
	res <- .C("RcallG3",
		as.double(x), as.double(y), as.double(z), 
		as.integer(length(x)),
		as.double(box[1]), as.double(box[2]), 
		as.double(box[3]), as.double(box[4]), 
		as.double(box[5]), as.double(box[6]), 
		as.double(0), as.double(rmax), 
		as.integer(nrval),
		f = as.double(numeric(nrval)),
		num = as.double(numeric(nrval)),
		denom = as.double(numeric(nrval)),
		as.integer(code))
	return(list(range = range, f = res$f, num=res$num, denom=res$denom, 
		correction=correction))
}
#
#
f3engine <- function(x, y, z, box=c(0,1,0,1,0,1), 
	vside=0.05, 
	range=c(0,1.414), nval=25, correction="minus sampling") 
	
{
#
	code <- switch(correction, "minus sampling"=1, no=0)
	res <- .C("RcallF3",
		as.double(x), as.double(y), as.double(z), 
		as.integer(length(x)),
		as.double(box[1]), as.double(box[2]), 
		as.double(box[3]), as.double(box[4]), 
		as.double(box[5]), as.double(box[6]), 
		as.double(vside), 
		as.double(range[1]), as.double(range[2]),
		m=as.integer(nval),
		num = as.integer(integer(nval)),
		denom = as.integer(integer(nval)),
		as.integer(code))
	r <- seq(from=range[1], to=range[2], length.out=nval)
	f <- with(res, ifelseXB(denom > 0, num/denom, 1))

	return(list(r = r, f = f, num=res$num, denom=res$denom, 
		correction=correction))
}

f3Cengine <- function(x, y, z, box=c(0,1,0,1,0,1), 
	vside=0.05, rmax=1, nrval=25)
{
#
  res <- .C("RcallF3cen",
            as.double(x), as.double(y), as.double(z), 
            as.integer(length(x)),
            as.double(box[1]), as.double(box[2]), 
            as.double(box[3]), as.double(box[4]), 
            as.double(box[5]), as.double(box[6]), 
            as.double(vside), 
            as.double(0), as.double(rmax),
            m=as.integer(nrval),
            obs = as.integer(integer(nrval)),
            nco = as.integer(integer(nrval)),
            cen = as.integer(integer(nrval)),
            ncc = as.integer(integer(nrval)),
            upperobs = as.integer(integer(1)),
            uppercen = as.integer(integer(1)))
  r <- seq(from=0, to=rmax, length.out=nrval)
  #
  obs <- res$obs
  nco <- res$nco
  cen <- res$cen
  ncc <- res$ncc
  upperobs <- res$upperobs
  uppercen <- res$uppercen
  #
  breaks <- breakpts.from.r(r)
  km <- kaplan.meier(obs, nco, breaks, upperobs=upperobs)
  rs <- reduced.sample(nco, cen, ncc, uppercen=uppercen)
  #
  ero <- eroded.volumes(as.box3(box), r)
  H <- cumsum(nco/ero)
  cs <- H/max(H[is.finite(H)])
  #
  return(list(rs=rs, km=km$km, hazard=km$lambda, cs=cs, r=r))
}

g3Cengine <- function(x, y, z, box=c(0,1,0,1,0,1), 
	rmax=1, nrval=25)
{
#
  res <- .C("RcallG3cen",
            as.double(x), as.double(y), as.double(z), 
            as.integer(length(x)),
            as.double(box[1]), as.double(box[2]), 
            as.double(box[3]), as.double(box[4]), 
            as.double(box[5]), as.double(box[6]), 
            as.double(0), as.double(rmax),
            m=as.integer(nrval),
            obs = as.integer(integer(nrval)),
            nco = as.integer(integer(nrval)),
            cen = as.integer(integer(nrval)),
            ncc = as.integer(integer(nrval)),
            upperobs = as.integer(integer(1)),
            uppercen = as.integer(integer(1)))
  r <- seq(from=0, to=rmax, length.out=nrval)
  #
  obs <- res$obs
  nco <- res$nco
  cen <- res$cen
  ncc <- res$ncc
  upperobs <- res$upperobs
  uppercen <- res$uppercen
  #
  breaks <- breakpts.from.r(r)
  km <- kaplan.meier(obs, nco, breaks, upperobs=upperobs)
  rs <- reduced.sample(nco, cen, ncc, uppercen=uppercen)
  #
  ero <- eroded.volumes(as.box3(box), r)
  H <- cumsum(nco/ero)
  han <- H/max(H[is.finite(H)])
  return(list(rs=rs, km=km$km, hazard=km$lambda, han=han, r=r))
}

pcf3engine <- function(x, y, z, box=c(0,1,0,1,0,1),
                       rmax=1, nrval=100, correction="translation",
                       delta=rmax/10) 
{
  code <- switch(correction, translation=0, isotropic=1)
  res <- .C("Rcallpcf3",
            as.double(x), as.double(y), as.double(z), 
            as.integer(length(x)),
            as.double(box[1]), as.double(box[2]), 
            as.double(box[3]), as.double(box[4]), 
            as.double(box[5]), as.double(box[6]), 
            as.double(0), as.double(rmax), 
            as.integer(nrval),
            f = as.double(numeric(nrval)),
            num = as.double(numeric(nrval)),
            denom = as.double(numeric(nrval)),
            method=as.integer(code),
            delta=as.double(delta))
	return(list(range = c(0,rmax),
                    f = res$f, num=res$num, denom=res$denom, 
                    correction=correction))
}
#
# ------------------------------------------------------------
# volume of a sphere (exact and approximate)
#

sphere.volume <- function(range=c(0,1.414), nval=10) 
{
  rr <- seq(from=range[1], to=range[2], length.out=nval)
  return( (4/3) * pi * rr^3)
}

digital.volume <- function(range=c(0, 1.414),  nval=25, vside= 0.05) 
{
#	Calculate number of points in digital sphere 
#	by performing distance transform for a single point
#	in the middle of a suitably large box
#
#	This takes EIGHT TIMES AS LONG as the corresponding empirical F-hat !!!
#
	w <- 2 * range[2] + 2 * vside
#
	dvol <- .C("RcallF3",
                   as.double(w/2), as.double(w/2), as.double(w/2),
                   as.integer(1),
                   as.double(0), as.double(w), 
                   as.double(0), as.double(w), 
                   as.double(0), as.double(w), 
                   as.double(vside),
                   as.double(range[1]), as.double(range[2]),
                   as.integer(nval),
                   num = as.integer(integer(nval)),
                   denom = as.integer(integer(nval)),
                   as.integer(0))$num
#	
        (vside^3) * dvol 
      }

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/fii.R"
#
# fii.R
#
# Class of fitted interpoint interactions
#
#
fii <- function(interaction=NULL, coefs=numeric(0),
                Vnames=character(0), IsOffset=NULL) {
  if(is.null(interaction)) 
    interaction <- Poisson()
  stopifnot(is.interact(interaction))
  if(is.poisson.interact(interaction)) {
    if(length(Vnames) > 0)
      stop("Coefficients inappropriate for Poisson process")
  }
  if(is.null(IsOffset))
    IsOffset <- rep.int(FALSE, length(Vnames))
  else {
    stopifnot(is.logical(IsOffset))
    stopifnot(length(IsOffset) == length(Vnames))
  } 
  out <- list(interaction=interaction,
              coefs=coefs,
              Vnames=Vnames,
              IsOffset=IsOffset)
  class(out) <- c("fii", class(out))
  return(out)
}

summary.fii <- function(object, ...) {
  y <- unclass(object)
  INTERACT <- object$interaction
  coefs    <- object$coefs
  Vnames   <- object$Vnames
  IsOffset <- object$IsOffset
  y$poisson <- is.poisson.interact(INTERACT)
  thumbnail <- NULL
  if(y$poisson) {
    thumbnail <- "Poisson()"
  } else {
    if(!is.null(INTERACT$interpret)) {
      # invoke auto-interpretation feature
      sensible <-  
        if(newstyle.coeff.handling(INTERACT))
          (INTERACT$interpret)(coefs[Vnames[!IsOffset]], INTERACT)
        else 
          (INTERACT$interpret)(coefs, INTERACT)
      if(!is.null(sensible)) {
        header <- paste("Fitted", sensible$inames)
        printable <- sensible$printable
        # Try to make a thumbnail description
        param <- sensible$param
        ipar <- INTERACT$par
        if(all(unlist(lapply(param, length)) == 1) &&
           all(unlist(lapply(ipar, length)) == 1)) {
          allargs <- append(ipar, param)
          allargs <- lapply(allargs, signif, digits=4)
          thumbnail <- fakecallstring(INTERACT$creator, allargs)
        } 
      } else {
        # no fitted interaction parameters (e.g. Hard Core)
        header <- NULL
        printable <- NULL
        thumbnail <- paste0(INTERACT$creator, "()")
      }
    } else {
      # fallback
      sensible <- NULL
      VN <- Vnames[!IsOffset]
      if(length(VN) > 0) {
        header <- "Fitted interaction terms"
        icoef <- coefs[VN]
        printable <-  exp(unlist(icoef))
        ricoef <- lapply(icoef, signif, digits=4)
        thumbnail <- fakecallstring(INTERACT$creator, ricoef)
      } else {
        header <- NULL
        printable <- NULL
        thumbnail <- paste0(INTERACT$creator, "()")
      }
    }
    y <- append(y, list(sensible=sensible,
                        header=header,
                        printable=printable,
                        thumbnail=thumbnail))
  }
  class(y) <- c("summary.fii", class(y))
  return(y)
}

print.fii <- function(x, ...) {
  sx <- summary(x)
  do.call(print.summary.fii,
          resolve.defaults(list(x=sx, brief=TRUE), list(...)))
  return(invisible(NULL))
}

print.summary.fii <- local({

  #'  hide internal arguments
  print.summary.fii <- function(x, ...) {
    PrintIt(x, ...)
  }
  
  PrintIt <- function(x, ..., prefix="Interaction: ",
                      banner=TRUE,
                      family = waxlyrical('extras'),
                      brief = !family,
                      tiny = !waxlyrical('errors')) {
    if(tiny) {
      #' use thumbnail if available
      thumbnail <- x$thumbnail
      if(!is.null(thumbnail)) {
        splat(thumbnail)
        return(invisible(NULL))
      }
    }
    terselevel <- spatstat.options('terse')
    if(banner && !brief)
      cat(prefix)
    if(x$poisson) {
      splat("Poisson process")
      parbreak(terselevel)
    } else {
      print(x$interaction, family=family, brief=TRUE, banner=banner)
      if(!is.null(x$printable)) {
        nvalues <- length(x$printable)
        nheader <- length(x$header)
        if(nvalues == 1) {
          splat(paste(paste0(x$header, ":\t"), x$printable))
        } else if(nvalues == nheader) {
          for(i in 1:nheader) {
            hdi <- x$header[i]
            xpi <- x$printable[[i]]
            if(!is.list(xpi) && length(xpi) == 1) {
              splat(paste0(hdi, ":\t", xpi))
            } else {
              splat(paste0(hdi, ":"))
              print(xpi)
            }
          } 
        } else {
          splat(x$header)
          print(x$printable)
        } 
      }
    }
    if(!brief) {
      co <- x$coefs[x$Vnames[!x$IsOffset]]
      if(length(co) > 0) {
        parbreak(terselevel)
        splat("Relevant coefficients:")
        print(co)
      }
    }
    return(invisible(NULL))
  }

  print.summary.fii
})


coef.summary.fii <- function(object, ...) {
  object$printable
}

reach.fii <- function(x, ..., epsilon=0) {
  inte <- x$interaction
  coeffs <- x$coefs
  Vnames <- x$Vnames

  if(is.poisson.interact(inte))
    return(0)

  # get 'irange' function from interaction object
  irange <- inte$irange

  if(is.null(irange))
    return(Inf)

  # apply 'irange' function using fitted coefficients
  if(newstyle.coeff.handling(inte))
    ir <- irange(inte, coeffs[Vnames], epsilon=epsilon)
  else 
    ir <- irange(inte, coeffs, epsilon=epsilon)
  
  if(is.na(ir))
    ir <- Inf

  return(ir)
}

plot.fii <- function(x, ...) {
  inte <- x$interaction
  if(is.poisson.interact(inte)) {
    message("Poisson interaction; nothing plotted")
    return(invisible(NULL))
  }
  plfun <- inte$plot %orifnull% inte$family$plot
  if(is.null(plfun)) 
    stop("Plotting not implemented for this type of interaction")
  plfun(x, ...)
}


fitin <- function(object) {
  UseMethod("fitin")
}

fitin.ppm <- function(object) {
  f <- object$fitin
  if(!is.null(f))
    return(f)
  # For compatibility with older versions
  inte <- object$interaction
  if(is.null(inte)) 
    f <- fii() # Poisson
  else {
    coefs <- coef(object)
    Vnames <- object$internal$Vnames
    IsOffset <- object$internal$IsOffset
    # Internal names of regressor variables 
    f <- fii(inte, coefs, Vnames, IsOffset)
  }
  unitname(f) <- unitname(data.ppm(object))
  return(f)
}

as.interact.fii <- function(object) {
  verifyclass(object, "fii")
  return(object$interaction)
}

coef.fii <- function(object, ...) {
  verifyclass(object, "fii")
  return(object$coefs)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/fiksel.R"
#
#
#    fiksel.R
#
#    $Revision: 1.10 $	$Date: 2014/11/24 04:30:03 $
#
#    Fiksel interaction 
#    
#    ee Stoyan Kendall Mcke 1987 p 161
#
# -------------------------------------------------------------------
#	

Fiksel <- local({

  # ......... auxiliary functions ...........

  fikselterms <- function(U, X, r, kappa, EqualPairs=NULL) {
    answer <- crossfikselterms(U, X, r, kappa)
    nU <- npoints(U)
    # subtract contrinbutions from identical pairs (exp(-0) = 1 for each)
    if(length(EqualPairs) > 0) {
      idcount <- as.integer(table(factor(EqualPairs[,2], levels=1:nU)))
      answer <- answer - idcount
    }
    return(answer)
  }

  crossfikselterms <- function(X, Y, r, kappa) {
    stopifnot(is.numeric(r))
    # sort in increasing order of x coordinate
    oX <- fave.order(X$x)
    oY <- fave.order(Y$x)
    Xsort <- X[oX]
    Ysort <- Y[oY]
    nX <- npoints(X)
    nY <- npoints(Y)
    # call C routine
    out <- .C("Efiksel",
            nnsource = as.integer(nX),
            xsource  = as.double(Xsort$x),
            ysource  = as.double(Xsort$y),
            nntarget = as.integer(nY),
            xtarget  = as.double(Ysort$x),
            ytarget  = as.double(Ysort$y),
            rrmax    = as.double(r),
            kkappa   = as.double(kappa),
            values   = as.double(double(nX)))
    answer <- integer(nX)
    answer[oX] <- out$values
    return(answer)
  }


  # ........ template object ..............
  
  BlankFiksel <- 
  list(
         name   = "Fiksel process",
         creator = "Fiksel",
         family  = "pairwise.family",  # evaluated later
         pot    = function(d, par) {
           v <- (d <= par$r) * exp( - d * par$kappa)
           v[ d <= par$hc ] <-  (-Inf)
           v
         },
         par    = list(r = NULL, hc = NULL, kappa=NULL),  # filled in later
         parnames = c("interaction distance",
                      "hard core distance",
                      "rate parameter"), 
         selfstart = function(X, self) {
           # self starter for Fiksel
           nX <- npoints(X)
           if(nX < 2) {
             # not enough points to make any decisions
             return(self)
           }
           md <- minnndist(X)
           if(!is.na(hc <- self$par$hc)) {
             # value fixed by user or previous invocation
             # check it
             if(md < hc)
               warning(paste("Hard core distance is too large;",
                             "some data points will have zero probability"))
             return(self)
           }
           if(md == 0) 
             warning(paste("Pattern contains duplicated points:",
                           "hard core must be zero"))
           # take hc = minimum interpoint distance * n/(n+1)
           hcX <- md * nX/(nX+1)
           Fiksel(r=self$par$r, hc = hcX, kappa=self$par$kappa)
         },
         init   = function(self) {
           r <- self$par$r
           hc <- self$par$hc
           kappa <- self$par$kappa
           check.1.real(r)
           check.1.real(kappa)
           if(!is.na(hc)) {
             check.1.real(hc)
             stopifnot(hc > 0)
             stopifnot(r > hc)
           } else stopifnot(r > 0)
         },
         update = NULL,       # default OK
         print = NULL,         # default OK
         interpret =  function(coeffs, self) {
           a <- as.numeric(coeffs[1])
           return(list(param=list(a=a),
                       inames="interaction strength a",
                       printable=signif(a)))
         },
         valid = function(coeffs, self) {
           a <- (self$interpret)(coeffs, self)$param$a
           return(is.finite(a))
         },
         project = function(coeffs, self) {
           if((self$valid)(coeffs, self))
             return(NULL)
           hc <- self$par$hc
           if(hc > 0) return(Hardcore(hc)) else return(Poisson()) 
         },
         irange = function(self, coeffs=NA, epsilon=0, ...) {
           r <- self$par$r
           hc <- self$par$hc
           if(any(is.na(coeffs)))
             return(r)
           a <- coeffs[1]
           if(abs(a) <= epsilon)
             return(hc)
           else
             return(r)
         },
       version=NULL, # evaluated later
       # fast evaluation is available for the border correction only
       can.do.fast=function(X,correction,par) {
         return(all(correction %in% c("border", "none")))
       },
       fasteval=function(X,U,EqualPairs,pairpot,potpars,correction, ...) {
         # fast evaluator for Fiksel interaction
         if(!all(correction %in% c("border", "none")))
           return(NULL)
         if(spatstat.options("fasteval") == "test")
           message("Using fast eval for Fiksel")
         r <- potpars$r
         hc <- potpars$hc
         kappa <- potpars$kappa
         hclose <- strausscounts(U, X, hc, EqualPairs)
         fikselbit <- fikselterms(U, X, r, kappa, EqualPairs)
         answer <- ifelseXB(hclose == 0, fikselbit, -Inf)
         return(matrix(answer, ncol=1))
       },
       Mayer=function(coeffs, self) {
         # second Mayer cluster integral
         a <- as.numeric(coeffs[1])
         r     <- self$par$r
         hc    <- self$par$hc
         kappa <- self$par$kappa
         f <- function(x, kappa, a){ 2 * pi * x *
                                       (1 - exp(a * exp(-x * kappa))) }
         hardbit <- integrate(f=f, lower=hc, upper=r,
                              a=a, kappa=kappa)
         mess <- hardbit[["message"]]
         if(!identical(mess, "OK")) {
           warning(mess)
           return(NA)
         }
         return(pi * hc^2 + hardbit$value)
       }
  )
  class(BlankFiksel) <- "interact"

  Fiksel <- function(r, hc=NA, kappa) {
    instantiate.interact(BlankFiksel, list(r = r, hc = hc, kappa=kappa))
  }

  Fiksel <- intermaker(Fiksel, BlankFiksel)
  
  Fiksel
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/fitted.mppm.R"
# 
#  fitted.mppm.R
#
# method for 'fitted' for mppm objects
#
#   $Revision: 1.2 $   $Date: 2014/11/10 07:42:09 $
# 

fitted.mppm <- function(object, ...,
                        type="lambda", dataonly=FALSE) {
#  sumry <- summary(object)

  type <- pickoption("type", type, c(lambda="lambda",
                                     cif   ="lambda",
                                     trend ="trend"), multi=FALSE, exact=FALSE)
  # extract fitted model object and data frame
  glmfit  <- object$Fit$FIT
  glmdata <- object$Fit$moadf
  # interaction names
  Vnames <- unlist(object$Fit$Vnamelist)
  interacting <- (length(Vnames) > 0)
    
  # Modification of `glmdata' may be required
  if(interacting) 
    switch(type,
           trend={
             # zero the interaction statistics
             glmdata[ , Vnames] <- 0
           },
           lambda={
             # Find any dummy points with zero conditional intensity
             forbid <- matrowany(as.matrix(glmdata[, Vnames]) == -Inf)
             # exclude from predict.glm
             glmdata <- glmdata[!forbid, ]
           })

  # Compute predicted [conditional] intensity values
  values <- predict(glmfit, newdata=glmdata, type="response")
  # Note: the `newdata' argument is necessary in order to obtain
  # predictions at all quadrature points. If it is omitted then
  # we would only get predictions at the quadrature points j
  # where glmdata$SUBSET[j]=TRUE.

  if(interacting && type=="lambda") {
   # reinsert zeroes
    vals <- numeric(length(forbid))
    vals[forbid] <- 0
    vals[!forbid] <- values
    values <- vals
  }

  names(values) <- NULL
  
  id <- glmdata$id
  if(dataonly) {
    # extract only data values
    isdata <- (glmdata$.mpl.Y != 0)
    values <- values[isdata]
    id     <- id[isdata]
  }

  return(split(values, id))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/fitted.ppm.R"
# 
#  fitted.ppm.R
#
# method for 'fitted' for ppm objects
#
#   $Revision: 1.12 $   $Date: 2014/10/07 05:13:22 $
# 

fitted.ppm <- function(object, ..., type="lambda", dataonly=FALSE,
                       new.coef=NULL, leaveoneout=FALSE,
                       drop=FALSE, check=TRUE, repair=TRUE) {
  verifyclass(object, "ppm")
  
  if(check && damaged.ppm(object)) {
    if(!repair)
      stop("object format corrupted; try update(object, use.internal=TRUE)")
    message("object format corrupted; repairing it.")
    object <- update(object, use.internal=TRUE)
  }

  if(leaveoneout) {
    ## Leave-one-out calculation for data points only
    if(missing(dataonly)) dataonly <- TRUE
    if(!dataonly)
      stop("Leave-one-out calculation requires dataonly=FALSE")
    if(!is.null(new.coef))
      stop("Leave-one-out calculation requires new.coef=NULL")
  }
  
  fitcoef <- coef(object)
  if(!is.null(new.coef)) {
    # validate
    if(length(new.coef) != length(fitcoef))
      stop(paste("Argument new.coef has wrong length",
                 length(new.coef), ": should be", length(fitcoef)))
    coeffs <- new.coef
  } else {
    coeffs <- fitcoef
  }
  
  uniform <- is.poisson.ppm(object) && no.trend.ppm(object)

  typelist <- c("lambda", "cif",    "trend")
  typevalu <- c("lambda", "lambda", "trend")
  if(is.na(m <- pmatch(type, typelist)))
    stop(paste("Unrecognised choice of ", sQuote("type"),
               ": ", sQuote(type), sep=""))
  type <- typevalu[m]
  
  if(uniform) {
    lambda <- exp(coeffs[[1]])
    Q <- quad.ppm(object, drop=drop)
    lambda <- rep.int(lambda, n.quad(Q))
  } else {
    glmdata <- getglmdata(object, drop=drop)
    glmfit  <- getglmfit(object)
    Vnames <- object$internal$Vnames
    interacting <- (length(Vnames) != 0)
    
    # Modification of `glmdata' may be required
    if(interacting) 
      switch(type,
           trend={
             # zero the interaction statistics
             glmdata[ , Vnames] <- 0
           },
           lambda={
             # Find any dummy points with zero conditional intensity
             forbid <- matrowany(as.matrix(glmdata[, Vnames]) == -Inf)
             # exclude from predict.glm
             glmdata <- glmdata[!forbid, ]
           })

    # Compute predicted [conditional] intensity values
    changecoef <- !is.null(new.coef) || (object$method != "mpl")
    lambda <- GLMpredict(glmfit, glmdata, coeffs, changecoef=changecoef)
    
    # Note: the `newdata' argument is necessary in order to obtain
    # predictions at all quadrature points. If it is omitted then
    # we would only get predictions at the quadrature points j
    # where glmdata$SUBSET[j]=TRUE. Assuming drop=FALSE.

    if(interacting && type=="lambda") {
     # reinsert zeroes
      lam <- numeric(length(forbid))
      lam[forbid] <- 0
      lam[!forbid] <- lambda
      lambda <- lam
    }

  }
  if(dataonly)
    lambda <- lambda[is.data(quad.ppm(object))]

  if(leaveoneout) {
    ## Perform leverage calculation
    dfb <- dfbetas(object)
    delta <- with(dfb, 'discrete')[with(dfb, 'is.atom'),,drop=FALSE]
    ## adjust fitted value
    mom <- model.matrix(object)[is.data(quad.ppm(object)),,drop=FALSE]
    if(type == "trend" && !uniform && interacting)
      mom[, Vnames] <- 0
    lambda <- lambda * exp(- rowSums(delta * mom))
  }
  return(lambda)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/flipxy.R"
#
# flipxy.R
#
# flip x and y coordinates
#
# $Revision: 1.2 $ $Date: 2014/09/29 04:20:32 $ 
#

flipxy <- function(X) {
  UseMethod("flipxy")
}

flipxy.ppp <- function(X) {
  stopifnot(is.ppp(X))
  ppp(X$y, X$x, marks=X$marks,
      window=flipxy(X$window), unitname=unitname(X),
      check=FALSE)
}

flipxypolygon <- function(p) {
  # flip x and y coordinates, and reinstate anticlockwise order
  oldy <- p$y
  p$y <- rev(p$x)
  p$x <- rev(oldy)
  # area and hole status unchanged
  return(p)
}

flipxy.owin <- function(X) {
  verifyclass(X, "owin")
  switch(X$type,
         rectangle={
           W <- owin(X$yrange, X$xrange, unitname=unitname(X))
         },
         polygonal={
           bdry <- lapply(X$bdry, flipxypolygon)
           W <- owin(poly=bdry, check=FALSE, unitname=unitname(X))
         },
         mask={
           W <- owin(mask=t(X$m),
                     xy=list(x=X$yrow, y=X$xcol),
                     unitname=unitname(X))
         },
         stop("Unrecognised window type")
         )
  return(W)
}

flipxy.psp <- function(X) {
  stopifnot(is.psp(X))
  flipends <- (X$ends)[, c(2,1,4,3), drop=FALSE]
  as.psp(flipends, window=flipxy(X$window), marks=X$marks,
         unitname=unitname(X), check=FALSE)
}

flipxy.im <- function(X) {
  im(t(X$v), xcol=X$yrow, yrow=X$xcol, unitname=unitname(X))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/formulae.R"
#
#
#   formulae.S
#
#   Functions for manipulating model formulae
#
#	$Revision: 1.20 $	$Date: 2014/04/14 08:05:01 $
#
#   identical.formulae()
#          Test whether two formulae are identical
#
#   termsinformula()
#          Extract the terms from a formula
#
#   sympoly()
#          Create a symbolic polynomial formula
#
#   polynom()
#          Analogue of poly() but without dynamic orthonormalisation
#
# -------------------------------------------------------------------
#	

# new generic

"formula<-" <- function(x, ..., value) {
  UseMethod("formula<-")
}


identical.formulae <- function(x, y) {
  # workaround for bug in all.equal.formula in R 2.5.0
  if(is.null(y) && !is.null(x))
    return(FALSE)
  return(identical(all.equal(x,y), TRUE))
}

termsinformula <- function(x) {
  if(is.null(x)) return(character(0))
  if(class(x) != "formula")
    stop("argument is not a formula")
  attr(terms(x), "term.labels")
}

variablesinformula <- function(x) {
  if(is.null(x)) return(character(0))
  if(class(x) != "formula")
    stop("argument is not a formula")
  all.vars(as.expression(x))
}

offsetsinformula <- function(x) {
  if(is.null(x)) return(character(0))
  if(class(x) != "formula")
    stop("argument is not a formula")
  tums <- terms(x)
  offs <- attr(tums, "offset")
  if(length(offs) == 0) return(character(0))
  vars <- attr(tums, "variables")
  termnames <- unlist(lapply(vars, deparse))[-1]
  termnames[offs]
}
  
lhs.of.formula <- function(x) {
  if(!inherits(x, "formula"))
    stop("x must be a formula")
  if(length(as.list(x)) == 3) {
    # formula has a response: return it
    return(x[[2]])
  }
  return(NULL)
}

rhs.of.formula <- function(x, tilde=TRUE) {
  if(!inherits(x, "formula"))
    stop("x must be a formula")
  if(length(as.list(x)) == 3) {
    # formula has a response: strip it
    x <- x[-2]
  }
  if(!tilde) # remove the "~"
    x <- x[[2]]
  return(x)
}


sympoly <- function(x,y,n) {

   if(nargs()<2) stop("Degree must be supplied.")
   if(nargs()==2) n <- y
   eps <- abs(n%%1)
   if(eps > 0.000001 | n <= 0) stop("Degree must be a positive integer")
   
   x <- deparse(substitute(x))
   temp <- NULL
   left <- "I("
   rght <- ")"
   if(nargs()==2) {
	for(i in 1:n) {
		xhat <- if(i==1) "" else paste("^",i,sep="")
		temp <- c(temp,paste(left,x,xhat,rght,sep=""))
	}
   }
   else {
	y <- deparse(substitute(y))
	for(i in 1:n) {
		for(j in 0:i) {
			k <- i-j
			xhat <- if(k<=1) "" else paste("^",k,sep="")
			yhat <- if(j<=1) "" else paste("^",j,sep="")
			xbit <- if(k>0) x else ""
			ybit <- if(j>0) y else ""
			star <- if(j*k>0) "*" else ""
			term <- paste(left,xbit,xhat,star,ybit,yhat,rght,sep="")
			temp <- c(temp,term)
		}
	}
      }
   as.formula(paste("~",paste(temp,collapse="+")))
 }


polynom <- function(x, ...) {
  rest <- list(...)
  # degree not given
  if(length(rest) == 0)
    stop("degree of polynomial must be given")
  #call with single variable and degree
  if(length(rest) == 1) {
    degree <- ..1
    if((degree %% 1) != 0 || length(degree) != 1 || degree < 1)
      stop("degree of polynomial should be a positive integer")

    # compute values
    result <- outer(x, 1:degree, "^")

    # compute column names - the hard part !
    namex <- deparse(substitute(x))
    # check whether it needs to be parenthesised
    if(!is.name(substitute(x))) 
      namex <- paste("(", namex, ")", sep="")
    # column names
    namepowers <- if(degree == 1) namex else 
                       c(namex, paste(namex, "^", 2:degree, sep=""))
    namepowers <- paste("[", namepowers, "]", sep="")
    # stick them on
    dimnames(result) <- list(NULL, namepowers)
    return(result)
  }
  # call with two variables and degree
  if(length(rest) == 2) {

    y <- ..1
    degree <- ..2

    # list of exponents of x and y, in nice order
    xexp <- yexp <- numeric()
    for(i in 1:degree) {
      xexp <- c(xexp, i:0)
      yexp <- c(yexp, 0:i)
    }
    nterms <- length(xexp)
    
    # compute 

    result <- matrix(, nrow=length(x), ncol=nterms)
    for(i in 1:nterms) 
      result[, i] <- x^xexp[i] * y^yexp[i]

    #  names of these terms
    
    namex <- deparse(substitute(x))
    # namey <- deparse(substitute(..1)) ### seems not to work in R
    zzz <- as.list(match.call())
    namey <- deparse(zzz[[3]])

    # check whether they need to be parenthesised
    # if so, add parentheses
    if(!is.name(substitute(x))) 
      namex <- paste("(", namex, ")", sep="")
    if(!is.name(zzz[[3]])) 
      namey <- paste("(", namey, ")", sep="")

    nameXexp <- c("", namex, paste(namex, "^", 2:degree, sep=""))
    nameYexp <- c("", namey, paste(namey, "^", 2:degree, sep=""))

    # make the term names
       
    termnames <- paste(nameXexp[xexp + 1],
                       ifelse(xexp > 0 & yexp > 0, ".", ""),
                       nameYexp[yexp + 1],
                       sep="")
    termnames <- paste("[", termnames, "]", sep="")

    dimnames(result) <- list(NULL, termnames)
    # 
    return(result)
  }
  stop("Can't deal with more than 2 variables yet")
}

expand.polynom <- local({
  powername <- function(x, n) {
    ifelse(n == 0, "",
           ifelse(n == 1,
                  x,
                  paste0(x, "^", n)))
  }
  power1name <- function(x, n) {
    px <- powername(x, n)
    ifelse(n <= 1, px, paste0("I", paren(px)))
  }
  power2name <- function(x, y, n, m) {
    ifelse(n == 0,
           power1name(y, m),
           ifelse(m == 0,
                  power1name(x, n),
                  paste0("I", paren(paste(powername(x, n),
                                          powername(y, m), sep="*")))))
  }

  fiddle <- function(f) {
    opname <- f[[1]]
    if(identical(opname, as.name('I'))) {
      ## expressions enclosed in I() are protected
      return(f)
    }
    if(!identical(opname, as.name('polynom'))) {
      tbd <- unlist(lapply(f, function(z) { 'polynom' %in% all.names(z) }))
      if(any(tbd)) {
        ## descend recursively
        for(i in which(tbd)) 
          f[[i]] <- fiddle(f[[i]])
      }
      return(f)
    }
    ## polynom(..., d)
    n <- length(f)
    if(!(n %in% c(3,4)))
      stop("Syntax of polynom() call not understood")
    degree <- f[[n]]
    if (!is.numeric(degree) || length(degree) != 1 ||
        (degree%%1) != 0 || degree < 1) 
      stop("degree of polynomial should be a positive integer")
    if(n == 3) {
      ## polynom(x, d)
      xlang <- f[[2]]
      xstring <- if(length(xlang) == 1) paste(xlang) else paren(format(xlang))
      xpowers <- power1name(xstring, 1:degree)
      xpolystring <- paste(xpowers, collapse=" + ")
      xpolylang <- as.formula(paste("~", xpolystring))[[2]]
      return(xpolylang)
    } else if(n == 4) {
      ## polynom(x, y, d)
      xlang <- f[[2]]
      ylang <- f[[3]]
      xstring <- if(length(xlang) == 1) paste(xlang) else paren(format(xlang))
      ystring <- if(length(ylang) == 1) paste(ylang) else paren(format(ylang))
      mat <- matrix(, 1+degree, 1+degree)
      totdeg <- col(mat) - 1
      yd <- row(mat) - 1
      xd <- totdeg - yd
      xdeg <- xd[xd >= 0]
      ydeg <- yd[xd >= 0]
      xypowers <- power2name(xstring, ystring, xdeg, ydeg)[xdeg + ydeg > 0]
      xypolystring <- paste(xypowers, collapse=" + ")
      xypolylang <- as.formula(paste("~", xypolystring))[[2]]
      return(xypolylang)
    }
  }

  expand.polynom <- function(f) {
    ## replaces polynom(...) by x + I(x^2) + ... inside a formula f
    g <- fiddle(f)
    environment(g) <- environment(f)
    return(g)
  }

  expand.polynom
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/fryplot.R"
#
#  fryplot.R
#
#  $Revision: 1.13 $ $Date: 2014/11/10 07:42:41 $
#

fryplot <- function(X, ..., width=NULL, from=NULL, to=NULL, axes=FALSE) {
  Xname <- short.deparse(substitute(X))
  X <- as.ppp(X)
  b <- as.rectangle(X)
  halfspan <- with(b, c(diff(xrange), diff(yrange)))
  if(!is.null(width)) {
    halfwidth <- ensure2vector(width)/2
    halfspan <- pmin.int(halfspan, halfwidth)
  }
  bb <- owin(c(-1,1) * halfspan[1], c(-1,1) * halfspan[2])
  Y <- frypoints(X, from=from, to=to, dmax=diameter(bb))[bb]
  do.call("plot.ppp",
          resolve.defaults(list(x=Y),
                           list(...),
                           list(main=paste("Fry plot of", Xname))))
  if(axes) {
    lines(c(0,0), c(-1,1) * halfspan[1])
    lines(c(-1,1) * halfspan[2], c(0,0))
  }
  return(invisible(NULL))
}

frypoints <- function(X, from=NULL, to=NULL, dmax=Inf) {
  X <- as.ppp(X)
  b <- as.rectangle(X)
  bb <- owin(c(-1,1) * diff(b$xrange), c(-1,1) * diff(b$yrange))
  n <- X$n
  xx <- X$x
  yy <- X$y
  ## determine (dx, dy) for all relevant pairs
  if(is.null(from) && is.null(to)) {
    if(is.infinite(dmax)) {
      dx <- outer(xx, xx, "-")
      dy <- outer(yy, yy, "-")
      notsame <- matrix(TRUE, n, n)
      diag(notsame) <- FALSE
      DX <- as.vector(dx[notsame])
      DY <- as.vector(dy[notsame])
      I <- row(notsame)[notsame]
    } else {
      cl <- closepairs(X, dmax)
      DX <- cl$dx
      DY <- cl$dy
      I  <- cl$j  ## sic: I is the index of the 'TO' element
    }
  } else {
    seqn <- seq_len(n)
    from <- if(is.null(from)) seqn else seqn[from]
    to   <- if(is.null(to))   seqn else seqn[to]
    if(is.infinite(dmax)) {
      dx <- outer(xx[to], xx[from], "-")
      dy <- outer(yy[to], yy[from], "-")
      notsame <- matrix(TRUE, n, n)
      diag(notsame) <- FALSE
      notsame <- notsame[to, from, drop=FALSE]
      DX <- as.vector(dx[notsame])
      DY <- as.vector(dy[notsame])
      I <- row(notsame)[notsame]
    } else {
      cl <- crosspairs(X[from], X[to], dmax)
      ok <- with(cl, from[i] != to[j])
      DX <- cl$dx[ok]
      DY <- cl$dy[ok]
      I  <- cl$j[ok]
    }
  }
  ## form into point pattern
  Fry <- ppp(DX, DY, window=bb, check=FALSE)
  if(is.marked(X)) {
    marx <- as.data.frame(marks(X))
    marxto <- if(is.null(to)) marx else marx[to, ,drop=FALSE]
    marks(Fry) <- marxto[I, ]
  }
  return(Fry)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/funxy.R"
#
#   funxy.R
#
#   Class of functions of x,y location with a spatial domain
#
#   $Revision: 1.3 $   $Date: 2014/10/24 00:22:30 $
#

funxy <- function(f, W=NULL) {
  stopifnot(is.function(f))
  stopifnot(is.owin(W))
  class(f) <- c("funxy", class(f))
  attr(f, "W") <- W
  return(f)
}

print.funxy <- function(x, ...) {
  cat(paste("function(x,y) of class", sQuote("funxy"), "\n"))
  print(as.owin(x))
}

as.owin.funxy <- function(W, ..., fatal=TRUE) {
  W <- attr(W, "W")
  as.owin(W, ..., fatal=fatal)
}

domain.funxy <- Window.funxy <- function(X, ...) { as.owin(X) }

#   Note that 'distfun' (and other classes inheriting from funxy)
#   has a method for as.owin that takes precedence over as.owin.funxy
#   and this will affect the behaviour of the following plot methods
#   because 'distfun' does not have its own plot method.

plot.funxy <- function(x, ...) {
  xname <- short.deparse(substitute(x))
  W <- as.owin(x)
  do.call("do.as.im",
          resolve.defaults(list(x, action="plot"),
                           list(...),
                           list(main=xname, W=W)))
  invisible(NULL)
}

contour.funxy <- function(x, ...) {
  xname <- deparse(substitute(x))
  W <- as.owin(x)
  do.call("do.as.im",
          resolve.defaults(list(x, action="contour"),
                           list(...),
                           list(main=xname, W=W)))
  invisible(NULL)
}

persp.funxy <- function(x, ...) {
  xname <- deparse(substitute(x))
  W <- as.rectangle(as.owin(x))
  do.call("do.as.im",
          resolve.defaults(list(x, action="persp"),
                           list(...),
                           list(main=xname, W=W)))
  invisible(NULL)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/fv.R"
##
##
##    fv.R
##
##    class "fv" of function value objects
##
##    $Revision: 1.123 $   $Date: 2014/11/11 10:34:13 $
##
##
##    An "fv" object represents one or more related functions
##    of the same argument, such as different estimates of the K function.
##
##    It is a data.frame with additional attributes
##    
##         argu       column name of the function argument (typically "r")
##
##         valu       column name of the recommended function
##
##         ylab       generic label for y axis e.g. K(r)
##
##         fmla       default plot formula
##
##         alim       recommended range of function argument
##
##         labl       recommended xlab/ylab for each column
##
##         desc       longer description for each column 
##
##         unitname   name of unit of length for 'r'
##
##         shade      (optional) column names of upper & lower limits
##                    of shading - typically a confidence interval
##
##    Objects of this class are returned by Kest(), etc
##
##################################################################
## creator

fv <- function(x, argu="r", ylab=NULL, valu, fmla=NULL,
               alim=NULL, labl=names(x), desc=NULL, unitname=NULL,
               fname=NULL, yexp=ylab) {
  stopifnot(is.data.frame(x))
  ## check arguments
  stopifnot(is.character(argu))
  if(!is.null(ylab))
    stopifnot(is.character(ylab) || is.language(ylab))
  if(!missing(yexp)) {
    if(is.null(yexp)) yexp <- ylab
    else stopifnot(is.language(yexp))
  }
  stopifnot(is.character(valu))
  
  if(!(argu %in% names(x)))
    stop(paste(sQuote("argu"), "must be the name of a column of x"))

  if(!(valu %in% names(x)))
    stop(paste(sQuote("valu"), "must be the name of a column of x"))

  if(is.null(fmla))
    fmla <- paste(valu, "~", argu)
  else if(inherits(fmla, "formula")) {
    ## convert formula to string
    fmla <- flat.deparse(fmla)
  } else if(!is.character(fmla))
    stop(paste(sQuote("fmla"), "should be a formula or a string"))

  if(missing(alim)) {
    ## Note: if alim is given as NULL, it is not changed.
    argue <- x[[argu]]
    alim <- range(argue[is.finite(argue)], na.rm=TRUE)
  } else if(!is.null(alim)) {
    if(!is.numeric(alim) || length(alim) != 2)
      stop(paste(sQuote("alim"), "should be a vector of length 2"))
  }
  
  if(!is.character(labl))
    stop(paste(sQuote("labl"), "should be a vector of strings"))
  stopifnot(length(labl) == ncol(x))
  if(is.null(desc))
    desc <- character(ncol(x))
  else {
    stopifnot(is.character(desc))
    stopifnot(length(desc) == ncol(x))
    nbg <- is.na(desc)
    if(any(nbg)) desc[nbg] <- ""
  }
  if(!is.null(fname))
    stopifnot(is.character(fname) && length(fname) %in% 1:2)
  ## pack attributes
  attr(x, "argu") <- argu
  attr(x, "valu") <- valu
  attr(x, "ylab") <- ylab
  attr(x, "yexp") <- yexp
  attr(x, "fmla") <- fmla
  attr(x, "alim") <- alim
  attr(x, "labl") <- labl
  attr(x, "desc") <- desc
  attr(x, "units") <- as.units(unitname)
  attr(x, "fname") <- fname
  attr(x, "dotnames") <- NULL
  attr(x, "shade") <- NULL
  ## 
  class(x) <- c("fv", class(x))
  return(x)
}

.Spatstat.FvAttrib <- c(
                        "argu",
                        "valu",
                        "ylab",
                        "yexp",
                        "fmla",
                        "alim",
                        "labl",
                        "desc",
                        "units",
                        "fname",
                        "dotnames",
                        "shade")

as.data.frame.fv <- function(x, ...) {
  stopifnot(is.fv(x))
  fva <- .Spatstat.FvAttrib
  attributes(x)[fva] <- NULL
  class(x) <- "data.frame"
  x
}

is.fv <- function(x) {
  inherits(x, "fv")
}

## 

as.fv <- function(x) { UseMethod("as.fv") }

as.fv.fv <- function(x) x

as.fv.data.frame <- function(x) {
  if(ncol(x) < 2) stop("Need at least 2 columns")
  return(fv(x, names(x)[1], , names(x)[2]))
}

as.fv.matrix <- function(x)  {
  y <- as.data.frame(x)
  if(any(bad <- is.na(names(y))))
    names(y)[bad] <- paste0("V", which(bad))
  return(as.fv.data.frame(y))
}

## other methods for as.fv are described in the files for the relevant classes.

vanilla.fv <- function(x) {
  ## remove everything except basic fv characteristics
  retain <- c("names", "row.names", .Spatstat.FvAttrib)
  attributes(x) <- attributes(x)[retain]
  class(x) <- c("fv", "data.frame")
  return(x)
}

print.fv <- local({
  
  maxwords <- function(z, m) { max(0, which(cumsum(nchar(z) + 1) <= m+1)) }
  usewords <- function(z, n) paste(z[1:n], collapse=" ")

  print.fv <- function(x, ..., tight=FALSE) {
    verifyclass(x, "fv")
    terselevel <- spatstat.options("terse")
    showlabels <- waxlyrical('space', terselevel)
    showextras <- waxlyrical('extras', terselevel)
    nama <- names(x)
    a <- attributes(x)
    if(!is.null(ylab <- a$ylab)) {
      if(is.language(ylab))
        ylab <- flat.deparse(ylab)
    }
    if(!inherits(x, "envelope")) {
      splat("Function value object",
            paren(paste("class", sQuote("fv"))))
      if(!is.null(ylab)) {
        xlab <- fvlabels(x, expand=TRUE)[[a$argu]]
        splat("for the function", xlab, "->", ylab)
      }
    }
    ## Descriptions ..
    desc <- a$desc
    ## .. may require insertion of ylab
    if(!is.null(ylab))
      desc <- sprintf(desc, ylab)
    ## Labels ..
    labl <- fvlabels(x, expand=TRUE)
    ## Avoid overrunning text margin
    maxlinewidth <- options('width')[[1]]
    key.width <- max(nchar(nama))
    labl.width <- if(showlabels) max(nchar(labl), nchar("Math.label")) else 0
    desc.width <- max(nchar(desc), nchar("Description"))
    fullwidth <- key.width + labl.width + desc.width + 2
    if(fullwidth > maxlinewidth && tight) {
      ## try shortening the descriptions so that it all fits on one line
      spaceleft <- maxlinewidth - (key.width + labl.width + 2)
      desc <- truncline(desc, spaceleft)
      desc.width <- max(nchar(desc), nchar("Description"))    
      fullwidth <- key.width + labl.width + desc.width + 2
    }
    spaceleft <- maxlinewidth - (key.width + 1)
    if(desc.width > spaceleft) {
      ## Descriptions need to be truncated to max line width
      desc <- truncline(desc, spaceleft)
      desc.width <- max(nchar(desc), nchar("Description"))    
      fullwidth <- key.width + labl.width + desc.width + 2
    }
    if(showextras) {
      fullwidth <- pmin(maxlinewidth, fullwidth)
      fullline <- paste0(rep(".", fullwidth), collapse="")
      cat(fullline, fill=TRUE)
    }
    df <- data.frame(Math.label=labl,
                     Description=desc,
                     row.names=nama,
                     stringsAsFactors=FALSE)
    if(!showlabels) df <- df[,-1,drop=FALSE]
    print(df, right=FALSE)
  ##
    if(showextras) {
      cat(fullline, fill=TRUE)
      splat("Default plot formula: ",
            flat.deparse(as.formula(a$fmla)))
      splat("where", dQuote("."), "stands for",
            commasep(sQuote(fvnames(x, ".")), ", "))
      if(!is.null(a$shade)) 
        splat("Columns", commasep(sQuote(a$shade)), 
              "will be plotted as shading (by default)")
      alim <- a$alim
      splat("Recommended range of argument",
            paste0(a$argu, ":"),
            if(!is.null(alim)) prange(signif(alim, 5)) else "not specified")
      rang <- signif(range(with(x, .x)), 5)
      splat("Available range", "of argument",
            paste0(a$argu, ":"), prange(rang))
      ledge <- summary(unitname(x))$legend
      if(!is.null(ledge))
        splat(ledge)
    }
    return(invisible(NULL))
  }

  print.fv
})



## manipulating the names in fv objects

.Spatstat.FvAbbrev <- c(
                        ".x",
                        ".y",
                        ".s",
                        ".",
                        "*",
                        ".a")

fvnames <- function(X, a=".") {
  verifyclass(X, "fv")
  if(!is.character(a) || length(a) > 1)
    stop("argument a must be a character string")
  switch(a,
         ".y"={
           return(attr(X, "valu"))
         },
         ".x"={
           return(attr(X, "argu"))
         },
         ".s"={
           return(attr(X, "shade"))
         },
         "." = {
           ## The specified 'dotnames'
           dn <- attr(X, "dotnames")
           if(is.null(dn)) 
             dn <- fvnames(X, "*")
           return(dn)
         },
         "*"=,
         ".a"={
           ## all column names other than the function argument
           allvars <- names(X)
           argu <- attr(X, "argu")
           nam <- allvars[allvars != argu]
           nam <- rev(nam) ## convention
           return(nam)
         },
         {
           if(a %in% names(X)) return(a)
           stop(paste("Unrecognised abbreviation", dQuote(a)))
         }
       )
}

"fvnames<-" <- function(X, a=".", value) {
  verifyclass(X, "fv")
  if(!is.character(a) || length(a) > 1)
    stop(paste("argument", sQuote("a"), "must be a character string"))
  ## special cases
  if(a == "." && length(value) == 0) {
    ## clear the dotnames
    attr(X, "dotnames") <- NULL
    return(X)
  }
  if(a == ".a" || a == "*") {
    warning("Column names unchanged: use names(x) <- value to change them")
    return(X)
  }

  ## validate the names
  switch(a,
         ".x"=,
         ".y"={
           if(!is.character(value) || length(value) != 1)
             stop("value should be a single string")
         },
         ".s"={
           if(!is.character(value) || length(value) != 2)
             stop("value should be a vector of 2 character strings")
         },
         "."={
           if(!is.character(value))
             stop("value should be a character vector")
         },
         stop(paste("Unrecognised abbreviation", dQuote(a)))
       )
  ## check the names match existing column names
  tags <- names(X)
  if(any(nbg <- !(value %in% tags))) 
    stop(paste(ngettext(sum(nbg), "The string", "The strings"),
               commasep(dQuote(value[nbg])),
               ngettext(sum(nbg),
                        "does not match the name of any column of X", 
                        "do not match the names of any columns of X")))
  ## reassign names
  switch(a,
         ".x"={
           attr(X, "argu") <- value
         },
         ".y"={
           attr(X, "valu") <- value
         },
         ".s"={
           attr(X, "shade") <- value
         },
         "."={
           attr(X, "dotnames") <- value
         })
  return(X)
}

"names<-.fv" <- function(x, value) {
  nama <- colnames(x)
  indx <- which(nama == fvnames(x, ".x"))
  indy <- which(nama == fvnames(x, ".y"))
  inds <- which(nama %in% fvnames(x, ".s"))
  ind. <- which(nama %in% fvnames(x, "."))
  ## rename columns of data frame
  x <- NextMethod("names<-")
  ## adjust other tags
  fvnames(x, ".x") <- value[indx]
  fvnames(x, ".y") <- value[indy]
  fvnames(x, ".")  <- value[ind.]
  if(length(inds) > 0)
    fvnames(x, ".s") <- value[inds]
  return(x)
}

fvlabels <- function(x, expand=FALSE) {
  lab <- attr(x, "labl")
  if(expand && !is.null(fname <- attr(x, "fname"))) {
    ## expand plot labels using function name
    nstrings <- max(substringcount("%s", lab))
    ## pad with blanks
    nextra <- nstrings - length(fname)
    if(nextra > 0) 
      fname <- c(fname, rep("", nextra))
    ## render
    lab <- do.call(sprintf, append(list(lab), as.list(fname)))
  }
  ## remove empty space
  lab <- gsub(" ", "", lab)
  names(lab) <- names(x)
  return(lab)
}

"fvlabels<-" <- function(x, value) {
  stopifnot(is.fv(x))
  stopifnot(is.character(value))
  stopifnot(length(value) == length(fvlabels(x)))
  attr(x, "labl") <- value
  return(x)
}

flatfname <- function(x) {
  fn <- if(is.character(x)) x else attr(x, "fname")
  if(length(fn) > 1)
    fn <- paste0(fn[1], "[", paste(fn[-1], collapse=" "), "]")
  as.name(fn)
}

makefvlabel <- function(op=NULL, accent=NULL, fname, sub=NULL, argname="r") {
  ## de facto standardised label
  a <- "%s"
  if(!is.null(accent)) 
    a <- paste0(accent, paren(a))     ## eg hat(%s)
  if(!is.null(op))
    a <- paste0("bold", paren(op), "~", a)  ## eg bold(var)~hat(%s)
  if(is.null(sub)) {
    if(length(fname) != 1) {
      a <- paste0(a, "[%s]")
      a <- paren(a, "{")
    }
  } else {
    if(length(fname) == 1) {
      a <- paste0(a, paren(sub, "["))
    } else {
      a <- paste0(a, paren("%s", "["), "^", paren(sub, "{"))
      a <- paren(a, "{")
    }
  } 
  a <- paste0(a, paren(argname))
  return(a)
}

fvlabelmap <- local({
  magic <- function(x) {
    subx <- paste("substitute(", x, ", NULL)")
    out <- try(eval(parse(text=subx)), silent=TRUE)
    if(inherits(out, "try-error"))
      out <- as.name(make.names(subx))
    out
  }

  fvlabelmap <- function(x, dot=TRUE) {
    labl <- fvlabels(x, expand=TRUE)
    ## construct mapping from identifiers to labels
    map <- as.list(labl)
    map <- lapply(map, magic)
    names(map) <- colnames(x)
    if(dot) {
      ## also map "." and ".a" to name of target function
      if(!is.null(ye <- attr(x, "yexp")))
        map <- append(map, list("."=ye, ".a"=ye))
      ## map other fvnames to their corresponding labels
      map <- append(map, list(".x"=map[[fvnames(x, ".x")]],
                              ".y"=map[[fvnames(x, ".y")]]))
      if(!is.null(fvnames(x, ".s"))) {
        shex <- unname(map[fvnames(x, ".s")])
        shadexpr <- substitute(c(A,B), list(A=shex[[1]], B=shex[[2]]))
        map <- append(map, list(".s" = shadexpr))
      }
    }
    return(map)
  }

  fvlabelmap
})

## map from abbreviations to expressions involving the column names,
## for use in eval(substitute(...))
fvexprmap <- function(x) {
  dotnames <- fvnames(x, ".")
  u <- if(length(dotnames) == 1) as.name(dotnames) else 
       as.call(lapply(c("cbind", dotnames), as.name))
  ux <- as.name(fvnames(x, ".x"))
  uy <- as.name(fvnames(x, ".y"))
  umap <- list(.=u, .a=u, .x=ux, .y=uy)
  if(!is.null(fvnames(x, ".s"))) {
    shnm <- fvnames(x, ".s")
    shadexpr <- substitute(cbind(A,B), list(A=as.name(shnm[1]),
                                            B=as.name(shnm[2])))
    umap <- append(umap, list(.s = shadexpr))
  }
  return(umap)
}

fvlegend <- function(object, elang) {
  ## Compute mathematical legend(s) for column(s) in fv object 
  ## transformed by language expression 'elang'.
  ## The expression must already be in 'expanded' form.
  ## The result is an expression, or expression vector.
  ## The j-th entry of the vector is an expression for the
  ## j-th column of function values.
  ee <- distributecbind(as.expression(elang))
  map <- fvlabelmap(object, dot = TRUE)
  eout <- as.expression(lapply(ee, function(ei, map) {
    eval(substitute(substitute(e, mp), list(e = ei, mp = map)))
  }, map = map))
  return(eout)
}  

bind.fv <- function(x, y, labl=NULL, desc=NULL, preferred=NULL) {
  verifyclass(x, "fv")
  ax <- attributes(x)
  if(is.fv(y)) {
    ## y is already an fv object
    ay <- attributes(y)
    if(!identical(ax$fname, ay$fname)) {
      ## x and y represent different functions
      ## expand the labels separately 
      fvlabels(x) <- fvlabels(x, expand=TRUE)
      fvlabels(y) <- fvlabels(y, expand=TRUE)
      ax <- attributes(x)
      ay <- attributes(y)
    }
    ## check compatibility of 'r' values
    xr <- ax$argu
    yr <- ay$argu
    rx <- x[[xr]]
    ry <- y[[yr]]
    if((length(rx) != length(rx)) || 
               (max(abs(rx-ry)) > .Machine$double.eps))
      stop("fv objects x and y have incompatible domains")
    ## reduce y to data frame and strip off 'r' values
    ystrip <- as.data.frame(y)
    yrpos <- which(colnames(ystrip) == yr)
    ystrip <- ystrip[, -yrpos, drop=FALSE]
    ## determine descriptors
    if(is.null(labl)) labl <- attr(y, "labl")[-yrpos]
    if(is.null(desc)) desc <- attr(y, "desc")[-yrpos]
    ##
    y <- ystrip
  } else {
    ## y is a matrix or data frame
    y <- as.data.frame(y)
  }
  
  ## check for duplicated column names
  allnames <- c(colnames(x), colnames(y))
  if(any(dup <- duplicated(allnames))) {
    nbg <- unique(allnames[dup])
    nn <- length(nbg)
    warning(paste("The column",
                  ngettext(nn, "name", "names"),
                  commasep(sQuote(nbg)),
                  ngettext(nn, "was", "were"),
                  "duplicated. Unique names were generated"))
    allnames <- make.names(allnames, unique=TRUE, allow_ = FALSE)
    colnames(y) <- allnames[ncol(x) + seq_len(ncol(y))]
  }
      
  if(is.null(labl))
    labl <- paste("%s[", colnames(y), "](r)", sep="")
  else if(length(labl) != ncol(y))
    stop(paste("length of", sQuote("labl"),
               "does not match number of columns of y"))
  if(is.null(desc))
    desc <- character(ncol(y))
  else if(length(desc) != ncol(y))
    stop(paste("length of", sQuote("desc"),
               "does not match number of columns of y"))
  if(is.null(preferred))
    preferred <- ax$valu

  xy <- cbind(as.data.frame(x), y)
  z <- fv(xy, ax$argu, ax$ylab, preferred, ax$fmla, ax$alim,
          c(ax$labl, labl),
          c(ax$desc, desc),
          unitname=unitname(x),
          fname=ax$fname,
          yexp=ax$yexp)
  return(z)
}

cbind.fv <- function(...) {
  a <- list(...)
  n <- length(a)
  if(n == 0)
    return(NULL)
  if(n == 1) {
    ## single argument - extract it
    a <- a[[1]]
    ## could be an fv object 
    if(is.fv(a))
      return(a)
    n <- length(a)
  }
  z <- a[[1]]
  if(!is.fv(z))
    stop("First argument should be an object of class fv")
  if(n > 1)
    for(i in 2:n) 
      z <- bind.fv(z, a[[i]])
  return(z)
}

collapse.fv <- function(..., same=NULL, different=NULL) {
  x <- list(...)
  n <- length(x)
  if(n == 0)
    return(NULL)
  if(n == 1)  {
    ## single argument - could be a list - extract it
    x1 <- x[[1]]
    if(!is.fv(x1))
      x <- x1
  } 
  if(!all(unlist(lapply(x, is.fv))))
    stop("arguments should be objects of class fv")
  if(is.null(same)) same <- character(0)
  if(is.null(different)) different <- character(0)
  if(anyDuplicated(c(same, different)))
    stop(paste("The arguments", sQuote("same"), "and", sQuote("different"),
               "should not have entries in common"))
  either <- c(same, different)
  ## validate
  nbg <- unlist(lapply(x, function(z, e) { e[!(e %in% names(z))] }, e=either))
  nbg <- unique(nbg)
  if((nbad <- length(nbg)) > 0)
    stop(paste(ngettext(nbad, "The name", "The names"),
               commasep(sQuote(nbg)),
               ngettext(nbad, "is", "are"),
               "not present in the function objects"))
  ## names for different versions
  versionnames <- names(x)
  if(is.null(versionnames))
    versionnames <- paste("x", seq_along(x), sep="")
  shortnames <- abbreviate(versionnames)
  ## extract the common values
  y <- x[[1]]
  if(length(same) > 0 && !(fvnames(y, ".y") %in% same))
    fvnames(y, ".y") <- same[1]
  z <- y[, c(fvnames(y, ".x"), same)]
  dotnames <- same
  ## now merge the different values
  for(i in seq_along(x)) {
    ## extract values for i-th object
    xi <- x[[i]]
    wanted <- (names(xi) %in% different)
    y <- as.data.frame(xi)[, wanted, drop=FALSE]
    desc <- attr(xi, "desc")[wanted]
    labl <- attr(xi, "labl")[wanted]
    ## relabel
    prefix <- shortnames[i]
    preamble <- versionnames[i]
    names(y) <- if(ncol(y) == 1) prefix else paste(prefix,names(y),sep="")
    dotnames <- c(dotnames, names(y))
    ## glue onto fv object
    z <- bind.fv(z, y,
                 labl=paste(prefix, labl, sep="~"),
                 desc=paste(preamble, desc))
  }
  fvnames(z, ".") <- dotnames
  return(z)
}

## rename one of the columns of an fv object
tweak.fv.entry <- function(x, current.tag, new.labl=NULL, new.desc=NULL, new.tag=NULL) {
  hit <- (names(x) == current.tag)
  if(!any(hit))
    return(x)
  ## update descriptions of column
  i <- min(which(hit))
  if(!is.null(new.labl)) attr(x, "labl")[i] <- new.labl
  if(!is.null(new.desc)) attr(x, "desc")[i] <- new.desc
  ## adjust column tag
  if(!is.null(new.tag)) {
    names(x)[i] <- new.tag
    ## update dotnames
    dn <- fvnames(x, ".")
    if(current.tag %in% dn ) {
      dn[dn == current.tag] <- new.tag
      fvnames(x, ".") <- dn
    }
    ## if the tweaked column is the preferred value, adjust accordingly
    if(attr(x, "valu") == current.tag)
      attr(x, "valu") <- new.tag
    ## if the tweaked column is the function argument, adjust accordingly
    if(attr(x, "argu") == current.tag)
      attr(x, "valu") <- new.tag
  }
  return(x)
}


## change some or all of the auxiliary text in an fv object
rebadge.fv <- function(x, new.ylab, new.fname,
                       tags, new.desc, new.labl,
                       new.yexp=new.ylab, new.dotnames,
                       new.preferred, new.formula, new.tags) {
  if(!missing(new.ylab)) 
    attr(x, "ylab") <- new.ylab
  if(!missing(new.yexp) || !missing(new.ylab))
    attr(x, "yexp") <- new.yexp
  if(!missing(new.fname))
    attr(x, "fname") <- new.fname
  if(!missing(tags) && !(missing(new.desc) && missing(new.labl) && missing(new.tags))) {
    nama <- names(x)
    desc <- attr(x, "desc")
    labl <- attr(x, "labl")
    valu <- attr(x, "valu")
    for(i in seq_along(tags))
    if(!is.na(m <- match(tags[i], nama))) {
      if(!missing(new.desc)) desc[m] <- new.desc[i]
      if(!missing(new.labl)) labl[m] <- new.labl[i]
      if(!missing(new.tags)) {
        names(x)[m] <- new.tags[i]
        if(tags[i] == valu)
          attr(x, "valu") <- new.tags[i]
      }
    }
    attr(x, "desc") <- desc
    attr(x, "labl") <- labl
  }
  if(!missing(new.dotnames))
    fvnames(x, ".") <- new.dotnames
  if(!missing(new.preferred)) {
    stopifnot(new.preferred %in% names(x))
    attr(x, "valu") <- new.preferred
  }
  if(!missing(new.formula))
    formula(x) <- new.formula
  return(x)
}

## common invocations to label a function like Kdot or Kcross
rebadge.as.crossfun <- function(x, main, sub=NULL, i, j) {
  i <- make.parseable(i)
  j <- make.parseable(j)
  if(is.null(sub)) {
    ylab <- substitute(main[i, j](r),
                       list(main=main, i=i, j=j))
    fname <- c(main, paste0("list", paren(paste(i, j, sep=","))))
    yexp <- substitute(main[list(i, j)](r),
                       list(main=main, i=i, j=j))
  } else {
    ylab <- substitute(main[sub, i, j](r),
                       list(main=main, sub=sub, i=i, j=j))
    fname <- c(main, paste0("list", paren(paste(sub, i, j, sep=","))))
    yexp <- substitute(main[list(sub, i, j)](r),
                       list(main=main, sub=sub, i=i, j=j))
  }
  y <- rebadge.fv(x, new.ylab=ylab, new.fname=fname, new.yexp=yexp)
  return(y)
}

rebadge.as.dotfun <- function(x, main, sub=NULL, i) {
  i <- make.parseable(i)
  if(is.null(sub)) {
    ylab <- substitute(main[i ~ dot](r),
                       list(main=main, i=i))
    fname <- c(main, paste0(i, "~symbol(\"\\267\")"))
    yexp <- substitute(main[i ~ symbol("\267")](r),
                       list(main=main, i=i))
  } else {
    ylab <- substitute(main[sub, i ~ dot](r),
                       list(main=main, sub=sub, i=i))
    fname <- c(main, paste0("list",
                            paren(paste0(sub, ",",
                                         i, "~symbol(\"\\267\")"))))
    yexp <- substitute(main[list(sub, i ~ symbol("\267"))](r),
                       list(main=main, sub=sub, i=i))
  }
  y <- rebadge.fv(x, new.ylab=ylab, new.fname=fname, new.yexp=yexp)
  return(y)
}

## subset extraction operator
"[.fv" <-
  function(x, i, j, ..., drop=FALSE)
{
  igiven <- !missing(i)
  jgiven <- !missing(j)
  y <- as.data.frame(x)
  if(igiven && jgiven)
    z <- y[i, j, drop=drop]
  else if(igiven)
    z <- y[i, , drop=drop]
  else if(jgiven)
    z <- y[ , j, drop=drop]
  else z <- y

  ## return only the selected values as a data frame or vector.
  if(drop) return(z)

  if(!jgiven) 
    selected <- seq_len(ncol(x))
  else {
    nameindices <- seq_along(names(x))
    names(nameindices) <- names(x)
    selected <- as.vector(nameindices[j])
  }

  nama <- names(z)
  argu <- attr(x, "argu")
  if(!(argu %in% nama))
    stop(paste("The function argument", sQuote(argu), "must not be removed"))
  valu <- attr(x, "valu")
  if(!(valu %in% nama))
    stop(paste("The default column of function values",
               sQuote(valu), "must not be removed"))

  ## If range of argument was implicitly changed, adjust "alim"
  alim <- attr(x, "alim")
  rang <- range(z[[argu]])
  alim <- intersect.ranges(alim, rang, fatal=FALSE)

  result <- fv(z, argu=attr(x, "argu"),
               ylab=attr(x, "ylab"),
               valu=attr(x, "valu"),
               fmla=attr(x, "fmla"),
               alim=alim,
               labl=attr(x, "labl")[selected],
               desc=attr(x, "desc")[selected],
               unitname=attr(x, "units"),
               fname=attr(x,"fname"),
               yexp=attr(x, "yexp"))
  
  ## carry over preferred names, if possible
  dotn <- fvnames(x, ".")
  fvnames(result, ".") <- dotn[dotn %in% colnames(result)]
  shad <- fvnames(x, ".s")
  if(!is.null(shad) && all(shad %in% colnames(result)))
    fvnames(result, ".s") <- shad
  return(result)
}  

## Subset and column replacement methods
## to guard against deletion of columns

"[<-.fv" <- function(x, i, j, value) {
  if(!missing(j)) {
    ## check for alterations to structure of object
    if((is.character(j) && !all(j %in% colnames(x))) ||
       (is.numeric(j) && any(j > ncol(x))))
      stop("Use bind.fv to add new columns to an object of class fv")
    if(is.null(value) && missing(i)) {
      ## column(s) will be removed
      co <- seq_len(ncol(x))
      names(co) <- colnames(x)
      keepcol <- setdiff(co, co[j])
      return(x[ , keepcol, drop=FALSE])
    }
  }
  NextMethod("[<-")
}

"$<-.fv" <- function(x, name, value) {
  j <- which(colnames(x) == name)
  if(is.null(value)) {
    ## column will be removed
    if(length(j) != 0)
      return(x[, -j, drop=FALSE])
    return(x)
  }
  if(length(j) == 0) {
    ## new column
    df <- data.frame(1:nrow(x), value)[,-1,drop=FALSE]
    colnames(df) <- name
    y <- bind.fv(x, df, desc=paste("Additional variable", sQuote(name)))
    return(y)
  }
  NextMethod("$<-")
}

## method for 'formula'

formula.fv <- function(x, ...) {
  attr(x, "fmla")
}

## method for 'formula<-'
## (generic is defined in formulae.R)

"formula<-.fv" <- function(x, ..., value) {
  if(is.null(value))
    value <- paste(fvnames(x, ".y"), "~", fvnames(x, ".x"))
  else if(inherits(value, "formula")) {
    ## convert formula to string
    value <- flat.deparse(value)
  } else if(!is.character(value))
    stop("Assignment value should be a formula or a string")
  attr(x, "fmla") <- value
  return(x)
}

##   method for with()

  
with.fv <- function(data, expr, ..., fun=NULL, enclos=NULL) {
  if(any(names(list(...)) == "drop"))
    stop("Outdated argument 'drop' used in with.fv")
  cl <- short.deparse(sys.call())
  verifyclass(data, "fv")
  if(is.null(enclos)) 
    enclos <- parent.frame()
   ## convert syntactic expression to 'expression' object
#  e <- as.expression(substitute(expr))
  ## convert syntactic expression to call
  elang <- substitute(expr)
  ## map "." etc to names of columns of data
  datanames <- names(data)
  xname <- fvnames(data, ".x")
  yname <- fvnames(data, ".y")
  ux <- as.name(xname)
  uy <- as.name(yname)
  dnames <- datanames[datanames %in% fvnames(data, ".")]
  ud <- as.call(lapply(c("cbind", dnames), as.name))
  anames <- datanames[datanames %in% fvnames(data, ".a")]
  ua <- as.call(lapply(c("cbind", anames), as.name))
  if(!is.null(fvnames(data, ".s"))) {
    snames <- datanames[datanames %in% fvnames(data, ".s")]
    us <- as.call(lapply(c("cbind", snames), as.name))
  } else us <- NULL
  expandelang <- eval(substitute(substitute(ee,
                                      list(.=ud, .x=ux, .y=uy, .s=us, .a=ua)),
                           list(ee=elang)))
  evars <- all.vars(expandelang)
  used.dotnames <- evars[evars %in% dnames]
  ## evaluate expression
  datadf <- as.data.frame(data)
  results <- eval(expandelang, as.list(datadf), enclos=enclos)
  ## --------------------
  ## commanded to return numerical values only?
  if(!is.null(fun) && !fun)
    return(results)

  if(!is.matrix(results) && !is.data.frame(results)) {
    ## result is a vector
    if(is.null(fun)) fun <- FALSE
    if(!fun || length(results) != nrow(datadf))
      return(results)
    results <- matrix(results, ncol=1)
  } else {
    ## result is a matrix or data frame
    if(is.null(fun)) fun <- TRUE
    if(!fun || nrow(results) != nrow(datadf))
      return(results)
  }
  ## result is a matrix or data frame of the right dimensions
  ## make a new fv object
  ## ensure columns of results have names
  if(is.null(colnames(results)))
    colnames(results) <- paste("col", seq_len(ncol(results)), sep="")
  resultnames <- colnames(results)
  ## get values of function argument
  xvalues <- datadf[[xname]]
  ## tack onto result matrix
  results <- cbind(xvalues, results)
  colnames(results) <- c(xname, resultnames)
  results <- data.frame(results)
  ## check for alteration of column names
  oldnames <- resultnames
  resultnames <- colnames(results)[-1]
  if(any(resultnames != oldnames))
    warning("some column names were illegal and have been changed")
  ## determine mapping (if any) from columns of output to columns of input
  namemap <- match(colnames(results), names(datadf))
  okmap <- !is.na(namemap)
  ## Build up fv object
  ## decide which of the columns should be the preferred value
  newyname <- if(yname %in% resultnames) yname else resultnames[1]
  ## construct default plot formula
  fmla <- flat.deparse(as.formula(paste(". ~", xname)))
  dotnames <- resultnames
  ## construct description strings
  desc <- character(ncol(results))
  desc[okmap] <- attr(data, "desc")[namemap[okmap]]
  desc[!okmap] <- paste("Computed value", resultnames[!okmap])
  ## function name (fname) and mathematical expression for function (yexp)
  oldyexp <- attr(data, "yexp")
  oldfname <- attr(data, "fname")
  if(is.null(oldyexp)) {
    fname <- cl
    yexp <- substitute(f(xname), list(f=as.name(fname), xname=as.name(xname)))
  } else {
    ## map 'cbind(....)' to "." for name of function only
    cb <- paste("cbind(",
                paste(used.dotnames, collapse=","),
                ")", sep="")
    compresselang <- gsub(cb, ".", flat.deparse(expandelang), fixed=TRUE)
    compresselang <- as.formula(paste(compresselang, "~1"))[[2]]
    ## construct mapping using original function name
    labmap <- fvlabelmap(data, dot=TRUE)
    labmap[["."]] <- oldyexp
    yexp <- eval(substitute(substitute(ee, ff), 
                            list(ee=compresselang, ff=labmap)))
    labmap2 <- labmap
    labmap2[["."]] <- as.name(oldfname)
    fname <- eval(substitute(substitute(ee, ff), 
                             list(ee=compresselang,
                                  ff=labmap2)))
    fname <- paren(flat.deparse(fname))
  }
  ## construct mathematical labels
  mathlabl <- as.character(fvlegend(data, expandelang))
  mathlabl <- gsub("[[:space:]]+", " ", mathlabl)
  labl <- colnames(results)
  mathmap <- match(labl, used.dotnames)
  okmath <- !is.na(mathmap)
  labl[okmath] <- mathlabl[mathmap[okmath]]
  ## form fv object and return
  out <- fv(results, argu=xname, valu=newyname, labl=labl,
            desc=desc, alim=attr(data, "alim"), fmla=fmla,
            unitname=unitname(data), fname=fname, yexp=yexp, ylab=yexp)
  fvnames(out, ".") <- dotnames
  return(out)
}

## method for 'range'

range.fv <- local({

  range1fv <- function(x, ..., na.rm=TRUE, finite=na.rm) {
    xdat <- as.matrix(as.data.frame(x))
    yall <- fvnames(x, ".")
    ydat <- xdat[, yall]
    range(ydat, na.rm=na.rm, finite=finite)
  }
  
  range.fv <- function(..., na.rm=TRUE, finite=na.rm) {
    aarg <- list(...)
    isfun <- sapply(aarg, is.fv)
    if(any(isfun)) 
      aarg[isfun] <- lapply(aarg[isfun], range1fv, na.rm=na.rm, finite=finite)
    do.call("range", append(aarg, list(na.rm=na.rm, finite=finite)))
  }

  range.fv
})

min.fv <- function(..., na.rm=TRUE, finite=na.rm) {
  range(..., na.rm=TRUE, finite=na.rm)[1]
}

max.fv <- function(..., na.rm=TRUE, finite=na.rm) {
  range(..., na.rm=TRUE, finite=na.rm)[2]
}

  
## stieltjes integration for fv objects

stieltjes <- function(f, M, ...) {
  ## stieltjes integral of f(x) dM(x)
  if(!is.fv(M))
    stop("M must be an object of class fv")
  if(!is.function(f))
    stop("f must be a function")
  ## integration variable
  argu <- attr(M, "argu")
  x <- M[[argu]]
  ## values of integrand
  fx <- f(x, ...)
  ## estimates of measure
  valuenames <- names(M) [names(M) != argu]
  Mother <- as.data.frame(M)[, valuenames]
  Mother <- as.matrix(Mother, nrow=nrow(M))
  ## increments of measure
  dM <- apply(Mother, 2, diff)
  dM <- rbind(dM, 0)
  dM[is.na(dM)] <- 0
  ## integrate f(x) dM(x)
  results <- apply(fx * dM, 2, sum)
  results <- as.list(results)
  names(results) <- valuenames
  return(results)
}

prefixfv <- function(x, tagprefix="", descprefix="", lablprefix=tagprefix,
                     whichtags=fvnames(x, "*")) {
  ## attach a prefix to fv information 
  stopifnot(is.fv(x))
  att <- attributes(x)
  relevant <- names(x) %in% whichtags
  oldtags <- names(x)[relevant]
  newtags <- paste(tagprefix, oldtags, sep="")
  newlabl <- paste(lablprefix, att$labl[relevant], sep="")
  newdesc <- paste(descprefix, att$desc[relevant])
  y <- rebadge.fv(x, tags=oldtags,
                  new.desc=newdesc,
                  new.labl=newlabl,
                  new.tags=newtags)
  return(y)
}

reconcile.fv <- function(...) {
  ## reconcile several fv objects by finding the columns they share in common
  z <- list(...)
  if(!all(unlist(lapply(z, is.fv)))) {
    if(length(z) == 1 && is.list(z[[1]]) && all(unlist(lapply(z[[1]], is.fv))))
      z <- z[[1]]
    else    
      stop("all arguments should be fv objects")
  }
  n <- length(z)
  if(n <= 1) return(z)
  ## find columns that are common to all estimates
  keepcolumns <- names(z[[1]])
  keepvalues <- fvnames(z[[1]], "*")
  for(i in 2:n) {
    keepcolumns <- intersect(keepcolumns, names(z[[i]]))
    keepvalues <- intersect(keepvalues, fvnames(z[[i]], "*"))
  }
  if(length(keepvalues) == 0)
    stop("cannot reconcile fv objects: they have no columns in common")
  ## determine name of the 'preferred' column
  prefs <- unlist(lapply(z, fvnames, a=".y"))
  prefskeep <- prefs[prefs %in% keepvalues]
  if(length(prefskeep) > 0) {
    ## pick the most popular
    chosen <- unique(prefskeep)[which.max(table(prefskeep))]
  } else {
    ## drat - pick a value arbitrarily
    chosen <- keepvalues[1]
  }
  z <- lapply(z, rebadge.fv, new.preferred=chosen)
  z <- lapply(z, "[.fv", j=keepcolumns)
  ## also clip to the same r values
  rmax <- min(unlist(lapply(z, function(x) { max(with(x, .x)) })))
  z <- lapply(z, function(x, rmax) { x[ with(x, .x) <= rmax, ] }, rmax=rmax)
  return(z)
}

as.function.fv <- function(x, ..., value=".y", extrapolate=FALSE) {
  trap.extra.arguments(...)
  ## extract function argument
  xx <- with(x, .x)
  ## extract all function values 
  yy <- as.data.frame(x)[, fvnames(x, "*"), drop=FALSE]
  ## determine which value(s) to supply
  if(!is.character(value))
    stop("value should be a character string or vector specifying columns of x")
  if(!all(value %in% colnames(yy))) {
    expandvalue <- try(fvnames(x, value))
    if(!inherits(expandvalue, "try-error")) {
      value <- expandvalue
    } else stop("Unable to determine columns of x")
  }
  yy <- yy[,value]
  argname <- fvnames(x, ".x")
  ## determine extrapolation rule (1=NA, 2=most extreme value)
  stopifnot(is.logical(extrapolate))
  stopifnot(length(extrapolate) %in% 1:2)
  endrule <- 1 + extrapolate
  ## make function(s)
  if(length(value) == 1) {
    ## make a single 'approxfun' and return it
    f <- approxfun(xx, yy, rule=endrule)
    ## magic
    names(formals(f))[1] <- argname
    body(f)[[4]] <- as.name(argname)
  } else {
    ## make a list of 'approxfuns' 
    funs <- lapply(yy,
                   function(z, u, endrule) { approxfun(x=u, y=z, rule=endrule)},
                   u=xx,
                   endrule=endrule)
    ## return a function which selects the appropriate 'approxfun' and executes
    f <- function(x, what=value) {
      what <- match.arg(what)
      funs[[what]](x)
    }
    ## recast function definition
    ## ('any sufficiently advanced technology...')
    formals(f)[[2]] <- value
    names(formals(f))[1] <- argname
    body(f)[[3]][[2]] <- as.name(argname)
  }
  class(f) <- c("fvfun", class(f))
  attr(f, "fname") <- attr(x, "fname")
  attr(f, "yexp") <- attr(x, "yexp")
  return(f)
}

print.fvfun <- function(x, ...) {
  y <- args(x)
  yexp <- as.expression(attr(x, "yexp"))
  body(y) <- as.name(paste("Returns interpolated value of", yexp))
  print(y, ...)
  return(invisible(NULL))
}

findcbind <- function(root, depth=0, maxdepth=1000) {
  ## recursive search through a parse tree to find calls to 'cbind'
  if(depth > maxdepth) stop("Reached maximum depth")
  if(length(root) == 1) return(NULL)
  if(identical(as.name(root[[1]]), as.name("cbind"))) return(list(numeric(0)))
  out <- NULL
  for(i in 2:length(root)) {
    di <- findcbind(root[[i]], depth+1, maxdepth)
    if(!is.null(di))
      out <- append(out, lapply(di, function(z,i){ c(i,z)}, i=i))
  }
  return(out)
}

.MathOpNames <- c("+", "-", "*", "/",
                  "^", "%%", "%/%",
                  "&", "|", "!",
                  "==", "!=", "<", "<=", ">=", ">")

distributecbind <- function(x) {
  ## x is an expression involving a call to 'cbind'
  ## return a vector of expressions, each obtained by replacing 'cbind(...)'
  ## by one of its arguments in turn.
  stopifnot(typeof(x) == "expression")
  xlang <- x[[1]]
  locations <- findcbind(xlang)
  if(length(locations) == 0)
    return(x)
  ## cbind might occur more than once
  ## check that the number of arguments is the same each time
  narg <-
    unique(unlist(lapply(locations,
                         function(loc, y) {
                           if(length(loc) > 0) length(y[[loc]]) else length(y)
                         },
                         y=xlang))) - 1
  if(length(narg) > 1) 
    return(NULL)
  out <- NULL
  if(narg > 0) {
    for(i in 1:narg) {
      ## make a version of the expression
      ## in which cbind() is replaced by its i'th argument
      fakexlang <- xlang
      for(loc in locations) {
        if(length(loc) > 0) {
          ## usual case: 'loc' is integer vector representing nested index
          cbindcall <- xlang[[loc]]
          ## extract i-th argument
          argi <- cbindcall[[i+1]]
          ## if argument is an expression, enclose it in parentheses
          if(length(argi) > 1 && paste(argi[[1]]) %in% .MathOpNames)
            argi <- substitute((x), list(x=argi))
          ## replace cbind call by its i-th argument
          fakexlang[[loc]] <- argi
        } else {
          ## special case: 'loc' = integer(0) representing xlang itself
          cbindcall <- xlang
          ## extract i-th argument
          argi <- cbindcall[[i+1]]
          ## replace cbind call by its i-th argument
          fakexlang <- cbindcall[[i+1]]
        }
      }
      ## add to final expression
      out <- c(out, as.expression(fakexlang))
    }
  }
  return(out)
}

## Form a new 'fv' object as a ratio

ratfv <- function(df, numer, denom, ..., ratio=TRUE) {
  ## Determine y
  if(!missing(df)) {
    y <- fv(df, ...)
    num <- NULL
  } else {
    ## Compute numer/denom
    ## Numerator must be a data frame
    num <- fv(numer, ...)    
    ## Denominator may be a data frame or a constant
    force(denom)
    y <- eval.fv(num/denom)
    ## relabel
    y <- fv(as.data.frame(y), ...)
  }
  if(!ratio)
    return(y)
  if(is.null(num)) {
    ## Compute num = y * denom
    ## Denominator may be a data frame or a constant
    force(denom)
    num <- eval.fv(y * denom)
    ## ditch labels
    num <- fv(as.data.frame(num), ...)
  }
  ## make denominator an fv object
  if(is.data.frame(denom)) {
    den <- fv(denom, ...)
  } else {
    ## scalar
    check.1.real(denom, "Unless it is a data frame,")
    ## replicate it in all the data columns
    dendf <- as.data.frame(num)
    valuecols <- (names(num) != fvnames(num, ".x"))
    dendf[, valuecols] <- denom
    den <- fv(dendf, ...)
  } 
  ## tweak the descriptions
  ok <- (names(y) != fvnames(y, ".x"))
  attr(num, "desc")[ok] <- paste("numerator of",   attr(num, "desc")[ok])
  attr(den, "desc")[ok] <- paste("denominator of", attr(den, "desc")[ok])
  ## form ratio object
  y <- rat(y, num, den, check=FALSE)
  return(y)
}

## Tack new column(s) onto a ratio fv object

bind.ratfv <- function(x, numerator, denominator, 
                       labl = NULL, desc = NULL, preferred = NULL,
                       ratio=TRUE) {
  y <- bind.fv(x, numerator/denominator,
               labl=labl, desc=desc, preferred=preferred)
  if(!ratio)
    return(y)
  stopifnot(inherits(x, "rat"))
  num <- attr(x, "numerator")
  den <- attr(x, "denominator")
  ## convert scalar denominator to data frame
  if(!is.data.frame(denominator)) {
    check.1.real(denominator, "Unless it is a data frame,")
    dvalue <- denominator
    denominator <- numerator
    denominator[] <- dvalue
  }
  num <- bind.fv(num, numerator,
                 labl=labl, desc=paste("numerator of", desc),
                 preferred=preferred)
  den <- bind.fv(den, denominator,
                 labl=labl, desc=paste("denominator of", desc),
                 preferred=preferred)
  y <- rat(y, num, den, check=FALSE)
  return(y)
}

conform.ratfv <- function(x) {
  ## harmonise display properties in components of a ratio
  stopifnot(inherits(x, "rat"), is.fv(x))
  num <- attr(x, "numerator")
  den <- attr(x, "denominator")
  formula(num) <- formula(den) <- formula(x)
  fvnames(num, ".") <- fvnames(den, ".") <- fvnames(x, ".")
  unitname(num)     <- unitname(den)     <- unitname(x)
  attr(x, "numerator") <- num
  attr(x, "denominator") <- den
  return(x)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/geyer.R"
#
#
#    geyer.S
#
#    $Revision: 2.28 $	$Date: 2014/12/20 14:21:08 $
#
#    Geyer's saturation process
#
#    Geyer()    create an instance of Geyer's saturation process
#                 [an object of class 'interact']
#
#	

Geyer <- local({

  # .......... template ..........

  BlankGeyer <- 
  list(
         name     = "Geyer saturation process",
         creator  = "Geyer",
         family   = "pairsat.family",  # evaluated later
         pot      = function(d, par) {
                         (d <= par$r)  # same as for Strauss
                    },
         par      = list(r = NULL, sat=NULL),  # filled in later
         parnames = c("interaction distance","saturation parameter"),
         init     = function(self) {
                      r <- self$par$r
                      sat <- self$par$sat
                      if(!is.numeric(r) || length(r) != 1 || r <= 0)
                       stop("interaction distance r must be a positive number")
                      if(!is.numeric(sat) || length(sat) != 1 || sat < 1)
                       stop("saturation parameter sat must be a number >= 1")
                    },
         update = NULL, # default OK
         print = NULL,    # default OK
         plot = function(fint, ..., d=NULL, plotit=TRUE) {
           verifyclass(fint, "fii")
           inter <- fint$interaction
           unitz <- unitname(fint)
           if(!identical(inter$name, "Geyer saturation process"))
             stop("Tried to plot the wrong kind of interaction")
           #' fitted interaction coefficient
           theta <- fint$coefs[fint$Vnames]
           #' interaction radius
           r <- inter$par$r
           sat <- inter$par$sat
           xlim <- resolve.1.default(list(xlim=c(0, 1.25 * r)), list(...)) 
           rmax <- max(xlim, d)
           if(is.null(d)) {
             d <- seq(from=0, to=rmax, length.out=1024)
           } else {
             stopifnot(is.numeric(d) &&
                       all(is.finite(d)) &&
                       all(diff(d) > 0))
           }
           #' compute interaction between two points at distance d
           y <- exp(theta * sat * (d <= r))
           #' compute `fv' object
           fun <- fv(data.frame(r=d, h=y, one=1),
                     "r", substitute(h(r), NULL), "h", cbind(h,one) ~ r,
                     xlim, c("r", "h(r)", "1"),
                     c("distance argument r",
                       "maximal interaction h(r)",
                       "reference value 1"),
                     unitname=unitz)
           if(plotit)
             do.call("plot.fv",
                     resolve.defaults(list(fun),
                                      list(...),
                                      list(ylim=range(0,1,y))))
           return(invisible(fun))
         },
         #' end of function 'plot'
         interpret =  function(coeffs, self) {
           loggamma <- as.numeric(coeffs[1])
           gamma <- exp(loggamma)
           return(list(param=list(gamma=gamma),
                       inames="interaction parameter gamma",
                       printable=dround(gamma)))
         },
         valid = function(coeffs, self) {
           loggamma <- as.numeric(coeffs[1])
           sat <- self$par$sat
           return(is.finite(loggamma) && (is.finite(sat) || loggamma <= 0))
         },
         project = function(coeffs, self) {
           if((self$valid)(coeffs, self)) return(NULL) else return(Poisson())
         },
         irange = function(self, coeffs=NA, epsilon=0, ...) {
           r <- self$par$r
           if(any(!is.na(coeffs))) {
             loggamma <- coeffs[1]
             if(!is.na(loggamma) && (abs(loggamma) <= epsilon))
               return(0)
           }
           return(2 * r)
         },
       version=NULL, # evaluated later
       # fast evaluation is available for the border correction only
       can.do.fast=function(X,correction,par) {
         return(all(correction %in% c("border", "none")))
       },
       fasteval=function(X,U,EqualPairs,pairpot,potpars,correction,
                         ..., halfway=FALSE, check=TRUE) {
         # fast evaluator for Geyer interaction
         if(!all(correction %in% c("border", "none")))
           return(NULL)
         if(spatstat.options("fasteval") == "test")
           message("Using fast eval for Geyer")
         r   <- potpars$r
         sat <- potpars$sat
         # first ensure all data points are in U
         nX <- npoints(X)
         nU <- npoints(U)
         Xseq  <- seq_len(nX)
         if(length(EqualPairs) == 0) {
           # no data points currently included 
           missingdata <- rep.int(TRUE, nX)
         } else {
           Xused <- EqualPairs[,1]
           missingdata <- !(Xseq %in% Xused)
         }
         somemissing <- any(missingdata)
         if(somemissing) {
           # add the missing data points
           nmiss <- sum(missingdata)
           U <- superimpose(U, X[missingdata], W=X$window, check=check)
           # correspondingly augment the list of equal pairs
           originalrows <- seq_len(nU)
           newXindex <- Xseq[missingdata]
           newUindex <- nU + seq_len(nmiss)
           EqualPairs <- rbind(EqualPairs, cbind(newXindex, newUindex))
           nU <- nU + nmiss
         }
         # determine saturated pair counts
         counts <- strausscounts(U, X, r, EqualPairs) 
         satcounts <- pmin.int(sat, counts)
         satcounts <- matrix(satcounts, ncol=1)
         if(halfway) {
           # trapdoor used by suffstat()
           answer <- satcounts
         } else if(sat == Inf) {
           # no saturation: fast code
           answer <- 2 * satcounts
         } else {
           # extract counts for data points
           Uindex <- EqualPairs[,2]
           Xindex <- EqualPairs[,1]
           Xcounts <- integer(npoints(X))
           Xcounts[Xindex] <- counts[Uindex]
           # evaluate change in saturated counts of other data points
           change <- geyercounts(U, X, r, sat, Xcounts, EqualPairs)
           answer <- satcounts + change
           answer <- matrix(answer, ncol=1)
         }
         if(somemissing)
           answer <- answer[originalrows, , drop=FALSE]
         return(answer)
       },
       delta2 = function(X,inte,correction, ...) {
         # Sufficient statistic for second order conditional intensity
         # h(X[i] | X) - h(X[i] | X[-j])
         # Geyer interaction
         r   <- inte$par$r
         sat <- inte$par$sat
         result <- geyerdelta2(X,r,sat)
         return(result)
       }
  )
  class(BlankGeyer) <- "interact"
  
  Geyer <- function(r, sat) {
    instantiate.interact(BlankGeyer, list(r = r, sat=sat))
  }

  Geyer <- intermaker(Geyer, BlankGeyer)
  
  Geyer
})

  # ........... externally visible auxiliary functions .........
  
geyercounts <- function(U, X, r, sat, Xcounts, EqualPairs) {
  # evaluate effect of adding dummy point or deleting data point
  # on saturated counts of other data points
  stopifnot(is.numeric(r))
  stopifnot(is.numeric(sat))
  # for C calls we need finite numbers
  stopifnot(is.finite(r))
  stopifnot(is.finite(sat))
  # sort in increasing order of x coordinate
  oX <- fave.order(X$x)
  oU <- fave.order(U$x)
  Xsort <- X[oX]
  Usort <- U[oU]
  nX <- npoints(X)
  nU <- npoints(U)
  Xcountsort <- Xcounts[oX]
  # inverse: data point i has sorted position i' = rankX[i]
  rankX <- integer(nX)
  rankX[oX] <- seq_len(nX)
  rankU <- integer(nU)
  rankU[oU] <- seq_len(nU)
  # map from quadrature points to data points
  Uindex <- EqualPairs[,2]
  Xindex <- EqualPairs[,1]
  Xsortindex <- rankX[Xindex]
  Usortindex <- rankU[Uindex]
  Cmap <- rep.int(-1, nU)
  Cmap[Usortindex] <- Xsortindex - 1
  # call C routine
  zz <- .C("Egeyer",
           nnquad = as.integer(nU),
           xquad  = as.double(Usort$x),
           yquad  = as.double(Usort$y),
           quadtodata = as.integer(Cmap),
           nndata = as.integer(nX),
           xdata  = as.double(Xsort$x),
           ydata  = as.double(Xsort$y),
           tdata  = as.integer(Xcountsort),
           rrmax  = as.double(r),
           ssat   = as.double(sat),
           result = as.double(numeric(nU)))
  result <- zz$result[rankU]
  return(result)
}

geyerdelta2 <- local({

  geyerdelta2 <- function(X, r, sat) {
    # Sufficient statistic for second order conditional intensity
    # Geyer model
    stopifnot(is.numeric(sat) && length(sat) == 1 && sat >= 0)
    # X could be a ppp or quad.
    if(is.ppp(X)) {
      # evaluate \Delta_{x_i} \Delta_{x_j} S(x) for data points x_i, x_j
      # i.e.  h(X[i]|X) - h(X[i]|X[-j]) where h is first order cif statistic
      return(geydelppp(X, r, sat))
    } else if(inherits(X, "quad")) {
      # evaluate \Delta_{u_i} \Delta_{u_j} S(x) for quadrature points u_i, u_j
      return(geydelquad(X, r, sat))
    } else stop("Internal error: X should be a ppp or quad object")
  }

  geydelppp <- function(X, r, sat) {
    # initialise
    nX <- npoints(X)
    result <- matrix(0, nX, nX)
    # identify all r-close pairs (ordered pairs i ~ j)
    a <- closepairs(X, r, what="indices")
    I <- a$i
    J <- a$j
    IJ <- cbind(I,J)
    # count number of r-neighbours for each point
    # (consistently with the above)
    tvals <- table(factor(I, levels=1:nX))
    # Compute direct part
    # (arising when i~j) 
    tI <- tvals[I]
    tJ <- tvals[J]
    result[IJ] <-
      pmin(sat, tI) - pmin(sat, tI - 1) + pmin(sat, tJ) - pmin(sat, tJ - 1)
    # Compute indirect part
    # (arising when i~k and j~k for another point k)
    # First find all such triples 
    ord <- (I < J)
    vees <- edges2vees(I[ord], J[ord], nX)
    # evaluate contribution of (k, i, j)
    KK <- vees$i
    II <- factor(vees$j, levels=1:nX)
    JJ <- factor(vees$k, levels=1:nX)
    tKK <- tvals[KK]
    contribKK <- pmin(sat, tKK) - 2 * pmin(sat, tKK-1) + pmin(sat, tKK-2)
    # for each (i, j), sum the contributions over k 
    delta3 <- tapply(contribKK, list(I=II, J=JJ), sum)
    delta3[is.na(delta3)] <- 0
    # symmetrise and combine
    result <- result + delta3 + t(delta3)
    # if X is a ppp, return now
    if(is.null(D))
      return(result)
  }

  geydelquad <- function(Q, r, sat) {
    Z <- is.data(Q)
    U <- union.quad(Q)
    nU <- npoints(U)
    nX <- npoints(Q$data)
    result <- matrix(0, nU, nU)
    # identify all r-close pairs U[i], U[j]
    a <- closepairs(U, r, what="indices")
    I <- a$i
    J <- a$j
    IJ <- cbind(I, J)
    # tag which ones are data points
    zI <- Z[I]
    zJ <- Z[J]
    # count t(U[i], X)
    IzJ <- I[zJ]
    JzJ <- J[zJ]
    tvals <- table(factor(IzJ, levels=1:nU))
    # Compute direct part
    # (arising when U[i]~U[j]) 
    tI <- tvals[I]
    tJ <- tvals[J]
    tIJ <- tI - zJ
    tJI <- tJ - zI
    result[IJ] <-  pmin(sat, tIJ + 1) - pmin(sat, tIJ) +
                   pmin(sat, tJI + 1) - pmin(sat, tJI) 
    # Compute indirect part
    # (arising when U[i]~X[k] and U[j]~X[k] for another point X[k])
    # First find all such triples
    # Group close pairs X[k] ~ U[j] by index k
    spl <- split(IzJ, factor(JzJ, levels=1:nX))
    grlen <- unlist(lapply(spl, length))
    # Assemble list of triples U[i], X[k], U[j]
    # by expanding each pair U[i], X[k]
    JJ <- unlist(spl[JzJ])
    II <- rep(IzJ, grlen[JzJ])
    KK <- rep(JzJ, grlen[JzJ])
    # remove identical pairs i = j
    ok <- II != JJ
    II <- II[ok]
    JJ <- JJ[ok]
    KK <- KK[ok]
    # evaluate contribution of each triple
    tKK <- tvals[KK]
    zII <- Z[II]
    zJJ <- Z[JJ]
    tKIJ <- tKK - zII - zJJ 
    contribKK <-
      pmin(sat, tKIJ + 2) - 2 * pmin(sat, tKIJ + 1) + pmin(sat, tKIJ)
    # for each (i, j), sum the contributions over k 
    II <- factor(II, levels=1:nU)
    JJ <- factor(JJ, levels=1:nU)
    delta4 <- tapply(contribKK, list(I=II, J=JJ), sum)
    delta4[is.na(delta4)] <- 0
    # combine
    result <- result + delta4
    return(result)
  }

  geyerdelta2
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/hardcore.R"
#
#
#    hardcore.S
#
#    $Revision: 1.10 $	$Date: 2014/10/24 00:22:30 $
#
#    The Hard core process
#
#    Hardcore()     create an instance of the Hard Core process
#                      [an object of class 'interact']
#	
#
# -------------------------------------------------------------------
#	

Hardcore <- local({

  BlankHardcore <- 
  list(
         name   = "Hard core process",
         creator = "Hardcore",
         family  = "pairwise.family",  # evaluated later
         pot    = function(d, par) {
           v <- 0 * d
           v[ d <= par$hc ] <-  (-Inf)
           attr(v, "IsOffset") <- TRUE
           v
         },
         par    = list(hc = NULL),  # filled in later
         parnames = "hard core distance", 
         selfstart = function(X, self) {
           # self starter for Hardcore
           nX <- npoints(X)
           if(nX < 2) {
             # not enough points to make any decisions
             return(self)
           }
           md <- minnndist(X)
           if(md == 0) {
             warning(paste("Pattern contains duplicated points:",
                           "impossible under Hardcore model"))
             return(self)
           }
           if(!is.na(hc <- self$par$hc)) {
             # value fixed by user or previous invocation
             # check it
             if(md < hc)
               warning(paste("Hard core distance is too large;",
                             "some data points will have zero probability"))
             return(self)
           }
           # take hc = minimum interpoint distance * n/(n+1)
           hcX <- md * nX/(nX+1)
           Hardcore(hc = hcX)
       },
         init   = function(self) {
           hc <- self$par$hc
           if(length(hc) != 1)
             stop("hard core distance must be a single value")
           if(!is.na(hc) && !(is.numeric(hc) && hc > 0))
             stop("hard core distance hc must be a positive number, or NA")
         },
         update = NULL,       # default OK
         print = NULL,        # default OK
         interpret =  function(coeffs, self) {
           return(NULL)
         },
         valid = function(coeffs, self) {
           return(TRUE)
         },
         project = function(coeffs, self) {
           return(NULL)
         },
         irange = function(self, coeffs=NA, epsilon=0, ...) {
           hc <- self$par$hc
           return(hc)
         },
       version=NULL, # evaluated later
       # fast evaluation is available for the border correction only
       can.do.fast=function(X,correction,par) {
         return(all(correction %in% c("border", "none")))
       },
       fasteval=function(X,U,EqualPairs,pairpot,potpars,correction, ...) {
         # fast evaluator for Hardcore interaction
         if(!all(correction %in% c("border", "none")))
           return(NULL)
         if(spatstat.options("fasteval") == "test")
           message("Using fast eval for Hardcore")
         hc <- potpars$hc
         # call evaluator for Strauss process
         counts <- strausscounts(U, X, hc, EqualPairs)
         # all counts should be zero
         v <- matrix(ifelseAB(counts > 0, -Inf, 0), ncol=1)
         attr(v, "IsOffset") <- TRUE
         return(v)
       },
       Mayer=function(coeffs, self) {
         # second Mayer cluster integral
         hc <- self$par$hc
         return(pi * hc^2)
       },
       Percy=function(d, coeffs, par, ...) {
         ## term used in Percus-Yevick type approximation
         H <- par$hc
         t <- abs(d/(2*H))
         t <- pmin.int(t, 1)
         y <- 2 * H^2 * (pi - acos(t) + t * sqrt(1 - t^2))
         return(y)
       }
  )
  class(BlankHardcore) <- "interact"
  
  Hardcore <- function(hc=NA) {
    instantiate.interact(BlankHardcore, list(hc=hc))
  }

  Hardcore <- intermaker(Hardcore, BlankHardcore)
  
  Hardcore
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/harmonic.R"
#
#
#   harmonic.R
#
#	$Revision: 1.2 $	$Date: 2004/01/07 08:57:39 $
#
#   harmonic()
#          Analogue of polynom() for harmonic functions only
#
# -------------------------------------------------------------------
#	

harmonic <- function(x,y,n) {
  if(missing(n))
    stop("the order n must be specified")
  n <- as.integer(n)
  if(is.na(n) || n <= 0)
    stop("n must be a positive integer")

  if(n > 3)
    stop("Sorry, harmonic() is not implemented for degree > 3")

  namex <- deparse(substitute(x))
  namey <- deparse(substitute(y))
  if(!is.name(substitute(x))) 
      namex <- paste("(", namex, ")", sep="")
  if(!is.name(substitute(y))) 
      namey <- paste("(", namey, ")", sep="")
  
  switch(n,
         {
           result <- cbind(x, y)
           names <- c(namex, namey)
         },
         {
           result <- cbind(x, y,
                           x*y, x^2-y^2)
           names <- c(namex, namey,
                      paste("(", namex, ".", namey, ")", sep=""),
                      paste("(", namex, "^2-", namey, "^2)", sep=""))
         },
         {
           result <- cbind(x, y,
                           x * y, x^2-y^2, 
                           x^3 - 3 * x * y^2, y^3 - 3 * x^2 * y)
           names <- c(namex, namey,
                      paste("(", namex, ".", namey, ")", sep=""),
                      paste("(", namex, "^2-", namey, "^2)", sep=""),
                      paste("(", namex, "^3-3", namex, ".", namey, "^2)",
                            sep=""),
                      paste("(", namey, "^3-3", namex, "^2.", namey, ")",
                            sep="")
                      )
         }
         )
  dimnames(result) <- list(NULL, names)
  return(result)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/hermite.R"
##
##  hermite.R
##
##  Gauss-Hermite quadrature
##
##  $Revision: 1.4 $  $Date: 2014/04/13 08:24:52 $
##

HermiteCoefs <- function(order) {
  ## compute coefficients of Hermite polynomial (unnormalised)
  x <- 1
  if(order > 0) 
    for(n in 1:order)
      x <- c(0, 2 * x) - c(((0:(n-1)) * x)[-1], 0, 0)
  return(x)
}

gauss.hermite <- function(f, mu=0, sd=1, ..., order=5) {
  stopifnot(is.function(f))
  stopifnot(length(mu) == 1)
  stopifnot(length(sd) == 1)
  ## Hermite polynomial coefficients (un-normalised)
  Hn <- HermiteCoefs(order)
  Hn1 <- HermiteCoefs(order-1)
  ## quadrature points
  x <- sort(Re(polyroot(Hn)))
  ## weights
  Hn1x <- matrix(Hn1, nrow=1) %*% t(outer(x, 0:(order-1), "^"))
  w <- 2^(order-1) * factorial(order) * sqrt(pi)/(order * Hn1x)^2
  ## adjust
  ww <- w/sqrt(pi)
  xx <- mu + sd * sqrt(2) * x
  ## compute
  ans <- 0
  for(i in seq_along(x))
    ans <- ans + ww[i] * f(xx[i], ...)
  return(ans)
}

dmixpois <- local({

  dpoisG <- function(x, ..., k, g) dpois(k, g(x))

  function(x, mu, sd, invlink=exp, GHorder=5) 
    gauss.hermite(dpoisG, mu=mu, sd=sd, g=invlink, k=x, order=GHorder)
})

pmixpois <- local({
  ppoisG <- function(x, ..., q, g, lot) ppois(q, g(x), lower.tail=lot)

  function(q, mu, sd, invlink=exp, lower.tail = TRUE, GHorder=5) 
    gauss.hermite(ppoisG, mu=mu, sd=sd, g=invlink, q=q, order=GHorder,
                 lot=lower.tail)
})
  
qmixpois <- function(p, mu, sd, invlink=exp, lower.tail = TRUE, GHorder=5) {
  ## guess upper limit
  ## Guess upper and lower limits
  pmin <- min(p, 1-p)/2
  lam.hi <- invlink(qnorm(pmin, mean=max(mu), sd=max(sd), lower.tail=FALSE))
  lam.lo <- invlink(qnorm(pmin, mean=min(mu), sd=max(sd), lower.tail=TRUE))
  kmin <- qpois(pmin, lam.lo, lower.tail=TRUE)
  kmax <- qpois(pmin, lam.hi, lower.tail=FALSE)
  kk <- kmin:kmax
  pp <- pmixpois(kk, mu, sd, invlink, lower.tail=TRUE, GHorder)
  ans <- if(lower.tail) kk[findInterval(p, pp, all.inside=TRUE)] else
         rev(kk)[findInterval(1-p, rev(1-pp), all.inside=TRUE)]
  return(ans)
}
  
rmixpois <- function(n, mu, sd, invlink=exp) {
  lam <- invlink(rnorm(n, mean=mu, sd=sd))
  y <- rpois(n, lam)
  return(y)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/hexagons.R"
## hexagons.R
## $Revision: 1.4 $ $Date: 2014/07/21 09:12:05 $

hexgrid <- function(W, s, offset=c(0,0), origin=NULL, trim=TRUE) {
  W <- as.owin(W)
  check.1.real(s)
  stopifnot(s > 0)
  hstep <- 3 * s
  vstep <- sqrt(3) * s
  R <- grow.rectangle(as.rectangle(W), hstep)
  xr <- R$xrange
  yr <- R$yrange
  ## initial positions for 'odd' and 'even grids
  p0 <- as2vector(origin %orifnull% centroid.owin(R))
  p0 <- p0 + as2vector(offset)
  q0 <- p0 + c(hstep, vstep)/2
  ## 'even' points
  p0 <- c(startinrange(p0[1], hstep, xr),
          startinrange(p0[2], vstep, yr))
  if(!any(is.na(p0))) {
    xeven <- prolongseq(p0[1], xr, step=hstep)
    yeven <- prolongseq(p0[2], yr, step=vstep)
    xyeven <- expand.grid(x=xeven, y=yeven)
  } else xyeven <- list(x=numeric(0), y=numeric(0))
  ## 'odd' points
  q0 <- c(startinrange(q0[1], hstep, xr),
          startinrange(q0[2], vstep, yr))
  if(!any(is.na(q0))) {
    xodd <- prolongseq(q0[1], xr, step=hstep)
    yodd <- prolongseq(q0[2], yr, step=vstep)
    xyodd <- expand.grid(x=xodd, y=yodd)
  } else xyodd <- list(x=numeric(0), y=numeric(0))
  ##
  xy <- concatxy(xyeven, xyodd)
  XY <- as.ppp(xy, W=R)
  ##
  if(trim) return(XY[W])
  ok <- inside.owin(XY, w=dilation.owin(W, s))
  return(XY[ok])
}

hextess <- function(W, s, offset=c(0,0), origin=NULL, trim=TRUE) {
  W <- as.owin(W)
  G <- hexgrid(W=W, s=s, offset=offset, origin=origin, trim=FALSE)
  if(trim && is.mask(W)) {
    ## Result is a pixel image tessellation
    ## Determine pixel resolution by extending 'W' to larger domain of 'G'
    rasta <- harmonise.im(as.im(1, W), as.owin(G))[[1]]
    rasta <- as.mask(rasta)
    ## Tweak G to have mask window
    G$window <- rasta
    ##
    img <- nnmap(G, what="which")
    result <- tess(image=img)
    return(result)
  }
  ## Result is a polygonal tessellation
  Gxy <- as.matrix(as.data.frame(G))
  n <- nrow(Gxy)
  ## Hexagon centred at origin
  hex0 <- disc(npoly=6, radius=s)
  ## Form hexagons
  hexes <- vector(mode="list", length=n)
  for(i in 1:n) 
    hexes[[i]] <- shift(hex0, Gxy[i,])
  ## Determine whether tiles intersect window wholly or partly
  suspect <- rep(TRUE, n)
  GW <- G[W]
  GinW <- inside.owin(G, w=W) 
  suspect[GinW] <- (bdist.points(GW) <= s)
  ## Compute intersection of tiles with window
  trimmed <- hexes
  trimmed[suspect] <- trimmed.suspect <- 
    lapply(trimmed[suspect], intersect.owin, B=W, fatal=FALSE)
  nonempty <- rep(TRUE, n)
  nonempty[suspect] <- !unlist(lapply(trimmed.suspect, is.empty))
  if(trim) {
    ## return the tiles intersected with W
    result <- tess(tiles=trimmed[nonempty], window=W)
  } else {
    ## return the tiles that have nonempty intersection with W
    result <- tess(tiles=hexes[nonempty])
  }
  return(result)
}


  
  
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/hierpair.family.R"
#
#
#    hierpair.family.R
#
#    $Revision: 1.1 $	$Date: 2014/12/03 02:46:13 $
#
#    The family of hierarchical pairwise interactions
#
#
# -------------------------------------------------------------------
#	

hierpair.family <-
  list(
       name  = "hierpair",
       print = function(self) {
         spatstat:::splat("Hierarchical pairwise interaction family")
       },
       plot = function(fint, ..., d=NULL, plotit=TRUE) {
         verifyclass(fint, "fii")
         inter <- fint$interaction
         if(is.null(inter) || is.null(inter$family)
            || inter$family$name != "hierpair")
           stop("Tried to plot the wrong kind of interaction")
         # get fitted coefficients of interaction terms
         # and set coefficients of offset terms to 1
         Vnames <- fint$Vnames
         IsOffset <- fint$IsOffset
         coeff <- rep.int(1, length(Vnames))
         names(coeff) <- Vnames
         coeff[!IsOffset] <- fint$coefs[Vnames[!IsOffset]]
         # 
         pairpot <- inter$pot
         potpars <- inter$par
         rmax <- reach(fint, epsilon=1e-3)
         xlim <- list(...)$xlim
         if(is.infinite(rmax)) {
           if(!is.null(xlim))
             rmax <- max(xlim)
           else {
             warning("Reach of interaction is infinite; need xlim to plot it")
             return(invisible(NULL))
           }
         }
         if(is.null(d)) {
           dmax <- 1.25 * rmax
           d <- seq(from=0, to=dmax, length.out=1024)
         } else {
           stopifnot(is.numeric(d) &&
                     all(is.finite(d)) &&
                     all(diff(d) > 0))
           dmax <- max(d)
         }
         if(is.null(xlim))
           xlim <- c(0, dmax)
         types <- potpars$types
         if(is.null(types))
           stop("Unable to determine types of points")
         if(!is.factor(types))
           types <- factor(types, levels=types)
         ## compute each potential and store in `fasp' object
         m <- length(types)
         nd <- length(d)
         dd <- matrix(rep.int(d, m), nrow=nd * m, ncol=m)
         tx <- rep.int(types, rep.int(nd, m))
         ty <- types
         p <- pairpot(dd, tx, ty, potpars)
         if(length(dim(p))==2)
           p <- array(p, dim=c(dim(p),1), dimnames=NULL)
         if(dim(p)[3] != length(coeff))
           stop("Dimensions of potential do not match coefficient vector")
         for(k in seq_len(dim(p)[3]))
           p[,,k] <- multiply.only.finite.entries( p[,,k] , coeff[k] )
         y <- exp(apply(p, c(1,2), sum))
         ylim <- range(0, 1.1, y, finite=TRUE)
         fns <- vector(m^2, mode="list")
         which <- matrix(, m, m)
         for(i in seq_len(m)) {
           for(j in seq_len(m)) {
             ## relevant position in matrix
             ijpos <- i + (j-1) * m
             which[i,j] <- ijpos
             ## extract values of potential
             yy <- y[tx == types[i], j]
             ## make fv object
             fns[[ijpos]] <- fv(data.frame(r=d, h=yy, one=1),
                                "r", quote(h(r)), "h", cbind(h,one) ~ r,
                                xlim, c("r", "h(r)", "1"),
                                c("distance argument r",
                                  "pairwise interaction term h(r)",
                                  "reference value 1"))
           }
         }
         funz <- fasp(fns, which=which,
                      formulae=list(cbind(h, one) ~ r),
                      title="Fitted pairwise interactions",
                      rowNames=paste(types), colNames=paste(types))
         if(plotit)
           do.call("plot.fasp",
                   resolve.defaults(list(funz),
                                    list(...),
                                    list(ylim=ylim,
                                         ylab="Pairwise interaction",
                                         xlab="Distance")))
         return(invisible(funz))
       },
       # end of function `plot'
       # ----------------------------------------------------
       eval  = function(X,U,EqualPairs,pairpot,potpars,correction,
           ..., Reach=NULL, precomputed=NULL, savecomputed=FALSE,
           pot.only=FALSE) {
         ##
         ## This is the eval function for the `hierpair' family.
         ## 

fop <- names(formals(pairpot))
if(identical(all.equal(fop, c("d", "par")), TRUE))
  marx <- FALSE
else if(identical(all.equal(fop, c("d", "tx", "tu", "par")), TRUE))
  marx <- TRUE
else 
  stop("Formal arguments of pair potential function are not understood")

## edge correction argument

if(length(correction) > 1)
  stop("Only one edge correction allowed at a time!")

if(!any(correction == c("periodic", "border", "translate", "translation", "isotropic", "Ripley", "none")))
  stop(paste("Unrecognised edge correction", sQuote(correction)))

 no.correction <- 

#### Compute basic data

   # Decide whether to apply faster algorithm using 'closepairs'
   use.closepairs <- FALSE &&
     (correction %in% c("none", "border", "translate", "translation")) &&
     !is.null(Reach) && is.finite(Reach) &&
     is.null(precomputed) && !savecomputed 

if(!is.null(precomputed)) {
  # precomputed
  X <- precomputed$X
  U <- precomputed$U
  EqualPairs <- precomputed$E
  M <- precomputed$M
} else {
  U <- as.ppp(U, X$window)   # i.e. X$window is DEFAULT window
  if(!use.closepairs) 
    # Form the matrix of distances
    M <- crossdist(X, U, periodic=(correction=="periodic"))
}

nX <- npoints(X)
nU <- npoints(U)
dimM <- c(nX, nU)

# Evaluate the pairwise potential without edge correction

if(use.closepairs)
  POT <- evalPairPotential(X,U,EqualPairs,pairpot,potpars,Reach)
else if(!marx) 
  POT <- pairpot(M, potpars)
else
  POT <- pairpot(M, marks(X), marks(U), potpars)

# Determine whether each column of potential is an offset

  IsOffset <- attr(POT, "IsOffset")

# Check errors and special cases

if(!is.matrix(POT) && !is.array(POT)) {
  if(length(POT) == 0 && X$n ==  0) # empty pattern
    POT <- array(POT, dim=c(dimM,1))
  else
    stop("Pair potential did not return a matrix or array")
}

if(length(dim(POT)) == 1 || any(dim(POT)[1:2] != dimM)) {
        whinge <- paste0(
           "The pair potential function ",short.deparse(substitute(pairpot)),
           " must produce a matrix or array with its first two dimensions\n",
           "the same as the dimensions of its input.\n")
	stop(whinge)
}

# make it a 3D array
if(length(dim(POT))==2)
        POT <- array(POT, dim=c(dim(POT),1), dimnames=NULL)
                          
if(correction == "translate" || correction == "translation") {
        edgewt <- edge.Trans(X, U)
        # sanity check ("everybody knows there ain't no...")
        if(!is.matrix(edgewt))
          stop("internal error: edge.Trans() did not yield a matrix")
        if(nrow(edgewt) != X$n || ncol(edgewt) != length(U$x))
          stop("internal error: edge weights matrix returned by edge.Trans() has wrong dimensions")
        POT <- c(edgewt) * POT
} else if(correction == "isotropic" || correction == "Ripley") {
        # weights are required for contributions from QUADRATURE points
        edgewt <- t(edge.Ripley(U, t(M), X$window))
        if(!is.matrix(edgewt))
          stop("internal error: edge.Ripley() did not return a matrix")
        if(nrow(edgewt) != X$n || ncol(edgewt) != length(U$x))
          stop("internal error: edge weights matrix returned by edge.Ripley() has wrong dimensions")
        POT <- c(edgewt) * POT
}

# No pair potential term between a point and itself
if(length(EqualPairs) > 0) {
  nplanes <- dim(POT)[3]
  for(k in 1:nplanes)
    POT[cbind(EqualPairs, k)] <- 0
}

# Return just the pair potential?
if(pot.only)
  return(POT)

# Sum the pairwise potentials 

V <- apply(POT, c(2,3), sum)

# attach the original pair potentials
attr(V, "POT") <- POT

# attach the offset identifier
attr(V, "IsOffset") <- IsOffset

# pass computed information out the back door
if(savecomputed)
  attr(V, "computed") <- list(E=EqualPairs, M=M)
return(V)

},
######### end of function $eval
       suffstat = function(model, X=NULL, callstring="hierpair.family$suffstat") {
# for hierarchical pairwise models only  (possibly nonstationary)
  verifyclass(model, "ppm")
  if(!identical(model$interaction$family$name,"hierpair"))
    stop("Model is not a hierarchical pairwise interaction process")

  if(is.null(X)) {
    X <- data.ppm(model)
    modelX <- model
  } else {
    verifyclass(X, "ppp")
    modelX <- update(model, X, method="mpl")
  }

  # find data points which do not contribute to pseudolikelihood
  mplsubset <- getglmdata(modelX)$.mpl.SUBSET
  mpldata   <- is.data(quad.ppm(modelX))
  contribute <- mplsubset[mpldata]

  Xin  <- X[contribute]
  Xout <- X[!contribute]
  
  # partial model matrix arising from ordered pairs of data points
  # which both contribute to the pseudolikelihood
  Empty <- X[integer(0)]
  momINxIN <- partialModelMatrix(Xin, Empty, model, "suffstat")

  # partial model matrix at data points which contribute to the pseudolikelihood
  momIN <-
    partialModelMatrix(X, Empty, model, "suffstat")[contribute, , drop=FALSE]
  
  # partial model matrix arising from ordered pairs of data points
  # the second of which does not contribute to the pseudolikelihood
  mom <- partialModelMatrix(Xout, Xin, model, "suffstat")
  indx <- Xout$n + seq_len(Xin$n)
  momINxOUT <- mom[indx, , drop=FALSE]

  ## determine which canonical covariates are true second-order terms
  ## eg 'mark1x1' 
  typ <- levels(marks(X))
  vn <- paste0("mark", typ, "x", typ)
  order2  <- names(coef(model)) %in% vn
  order1  <- !order2

  result <- 0 * coef(model)
  
  if(any(order1)) {
    # first order contributions (including 'mark1x2' etc)
    o1terms  <- momIN[ , order1, drop=FALSE]
    o1sum   <- colSums(o1terms)
    result[order1] <- o1sum
  }
  if(any(order2)) {
    # adjust for double counting of ordered pairs in INxIN but not INxOUT
    o2termsINxIN  <- momINxIN[, order2, drop=FALSE]
    o2termsINxOUT <- momINxOUT[, order2, drop=FALSE]
    o2sum   <- colSums(o2termsINxIN)/2 + colSums(o2termsINxOUT)
    result[order2] <- o2sum
  }

  return(result)
  },
######### end of function $suffstat
  delta2 = function(X, inte, correction, ...) {
  # Sufficient statistic for second order conditional intensity
  # for hierarchical pairwise interaction processes
  # Equivalent to evaluating pair potential.
    X <- as.ppp(X)
    nX <- npoints(X)
    E <- cbind(1:nX, 1:nX)
    R <- reach(inte)
    result <- hierpair.family$eval(X,X,E,
                                   inte$pot,inte$par,
                                   correction,
                                   pot.only=TRUE,
                                   Reach=R)
  }
######### end of function $delta2
)
######### end of list

class(hierpair.family) <- "isf"

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/hierstrauss.R"
##
##    hierstrauss.R
##
##    $Revision: 1.2 $	$Date: 2014/12/24 03:15:34 $
##
##    The hierarchical Strauss process
##
##    HierStrauss()    create an instance of the hierarchical Strauss process
##                 [an object of class 'interact']
##	
## -------------------------------------------------------------------
##	

HierStrauss <- local({

  # ......... define interaction potential

  HSpotential <- function(d, tx, tu, par) {
     # arguments:
     # d[i,j] distance between points X[i] and U[j]
     # tx[i]  type (mark) of point X[i]
     # tu[j]  type (mark) of point U[j]
     #
     # get matrix of interaction radii r[ , ]
     r <- par$radii
     #
     # get possible marks and validate
     if(!is.factor(tx) || !is.factor(tu))
	stop("marks of data and dummy points must be factor variables")
     lx <- levels(tx)
     lu <- levels(tu)
     if(length(lx) != length(lu) || any(lx != lu))
	stop("marks of data and dummy points do not have same possible levels")

     if(!identical(lx, par$types))
        stop("data and model do not have the same possible levels of marks")
     if(!identical(lu, par$types))
        stop("dummy points and model do not have the same possible levels of marks")
     
     # ensure factor levels are acceptable for column names (etc)
     lxname <- make.names(lx, unique=TRUE)

     ## list all ordered pairs of types to be checked
     uptri <- par$archy$relation & !is.na(r)
     mark1 <- (lx[row(r)])[uptri]
     mark2 <- (lx[col(r)])[uptri]
     ## corresponding names
     mark1name <- (lxname[row(r)])[uptri]
     mark2name <- (lxname[col(r)])[uptri]
     vname <- apply(cbind(mark1name,mark2name), 1, paste, collapse="x")
     vname <- paste("mark", vname, sep="")
     npairs <- length(vname)
     ## create logical array for result
     z <- array(FALSE, dim=c(dim(d), npairs),
                dimnames=list(character(0), character(0), vname))
     # go....
     if(length(z) > 0) {
       ## assemble the relevant interaction distance for each pair of points
       rxu <- r[ tx, tu ]
       ## apply relevant threshold to each pair of points
       str <- (d <= rxu)
       ## score
       for(i in 1:npairs) {
         # data points with mark m1
         Xsub <- (tx == mark1[i])
         # quadrature points with mark m2
         Qsub <- (tu == mark2[i])
         # assign
         z[Xsub, Qsub, i] <- str[Xsub, Qsub]
       }
     }
     return(z)
   }
   #### end of 'pot' function ####

  # ........ auxiliary functions ..............
  delHS <- function(which, types, radii, archy) {
    radii[which] <- NA
    if(all(is.na(radii))) return(Poisson())
    return(HierStrauss(types=types, radii=radii, archy=archy))
  }
  
  # Set up basic object except for family and parameters
  BlankHSobject <- 
  list(
       name     = "Hierarchical Strauss process",
       creator  = "HierStrauss",
       family   = "hierpair.family", # evaluated later
       pot      = HSpotential,
       par      = list(types=NULL, radii=NULL, archy=NULL), # filled in later
       parnames = c("possible types",
                    "interaction distances",
                    "hierarchical order"),
       selfstart = function(X, self) {
         if(is.null(self$par$types)) types <- levels(marks(X))
         if(is.null(self$par$archy)) archy <- types
         HierStrauss(types=types,radii=self$par$radii,archy=self$par$archy)
       },
       init = function(self) {
         types <- self$par$types
         if(!is.null(types)) {
           radii <- self$par$radii
           nt <- length(types)
           MultiPair.checkmatrix(radii, nt, sQuote("radii"), asymmok=TRUE)
           if(length(types) == 0)
             stop(paste("The", sQuote("types"),"argument should be",
                        "either NULL or a vector of all possible types"))
           if(any(is.na(types)))
             stop("NA's not allowed in types")
           if(is.factor(types)) {
             types <- levels(types)
           } else {
             types <- levels(factor(types, levels=types))
           }
         }
       },
       update = NULL, # default OK
       print = function(self) {
         radii <- self$par$radii
         types <- self$par$types
         archy <- self$par$archy
         cat(paste(nrow(radii), "types of points\n"))
         if(!is.null(types) && !is.null(archy)) {
           cat("Possible types and ordering: \n")
           print(archy)
         } else if(!is.null(types)) {
           cat("Possible types: \n")
           print(types)
         } else cat("Possible types:\t not yet determined\n")
         cat("Interaction radii:\n")
         print(hiermat(radii, self$par$archy))
         invisible(NULL)
       },
       interpret = function(coeffs, self) {
         # get possible types
         typ <- self$par$types
         ntypes <- length(typ)
         # get matrix of Strauss interaction radii
         r <- self$par$radii
         # list all unordered pairs of types
         uptri <- self$par$archy$relation & !is.na(r)
         index1 <- (row(r))[uptri]
         index2 <- (col(r))[uptri]
         npairs <- length(index1)
         # extract canonical parameters; shape them into a matrix
         gammas <- matrix(NA, ntypes, ntypes)
         dimnames(gammas) <- list(typ, typ)
         gammas[ cbind(index1, index2) ] <- exp(coeffs)
         #
         return(list(param=list(gammas=gammas),
                     inames="interaction parameters gamma_ij",
                     printable=hiermat(round(gammas, 4), self$par$archy)))
       },
       valid = function(coeffs, self) {
         # interaction parameters gamma[i,j]
         gamma <- (self$interpret)(coeffs, self)$param$gammas
         # interaction radii
         radii <- self$par$radii
         # parameters to estimate
         required <- !is.na(radii) & self$par$archy$relation
         # all required parameters must be finite
         if(!all(is.finite(gamma[required]))) return(FALSE)
         # DIAGONAL interaction parameters must be non-explosive
         d <- diag(rep(TRUE, nrow(radii)))
         return(all(gamma[required & d] <= 1))
       },
       project  = function(coeffs, self) {
         # interaction parameters gamma[i,j]
         gamma <- (self$interpret)(coeffs, self)$param$gammas
         # interaction radii and types
         radii <- self$par$radii
         types <- self$par$types
         # problems?
         uptri <- self$par$archy$relation
         required <- !is.na(radii) & uptri
         okgamma  <- !uptri | (is.finite(gamma) & (gamma <= 1))
         naughty  <- required & !okgamma
         # 
         if(!any(naughty))  
           return(NULL)
         if(spatstat.options("project.fast")) {
           # remove ALL naughty terms simultaneously
           return(delHS(naughty, types, radii, archy))
         } else {
           # present a list of candidates
           rn <- row(naughty)
           cn <- col(naughty)
           ord <- self$par$archy$ordering
           uptri <- (ord[rn] <= ord[cn]) 
           upn <- uptri & naughty
           rowidx <- as.vector(rn[upn])
           colidx <- as.vector(cn[upn])
           mats <- lapply(as.data.frame(rbind(rowidx, colidx)),
                          matrix, ncol=2)
           inters <- lapply(mats, delHS, types=types, radii=radii, archy=archy)
           return(inters)
         }
       },
       irange = function(self, coeffs=NA, epsilon=0, ...) {
         r <- self$par$radii
         active <- !is.na(r) & self$par$archy$relation
         if(any(!is.na(coeffs))) {
           gamma <- (self$interpret)(coeffs, self)$param$gammas
           gamma[is.na(gamma)] <- 1
           active <- active & (abs(log(gamma)) > epsilon)
         }
         if(any(active)) return(max(r[active])) else return(0)
       },
       version=NULL # to be added
       )
  class(BlankHSobject) <- "interact"

  # finally create main function
  HierStrauss <- function(radii, types=NULL, archy=NULL) {
    if(!is.null(types)) {
      if(is.null(archy)) archy <- seq_len(length(types))
      archy <- hierarchicalordering(archy, types)
    } 
    out <- instantiate.interact(BlankHSobject,
                                list(types=types,
                                     radii=radii,
                                     archy=archy))
    if(!is.null(types))
      dimnames(out$par$radii) <- list(types, types)
    return(out)
  }

  HierStrauss <- intermaker(HierStrauss, BlankHSobject)
  
  HierStrauss
})


hierarchicalordering <- function(i, s) {
  s <- as.character(s)
  n <- length(s)
  possible <- if(is.character(i)) s else seq_len(n)
  j <- match(i, possible)
  if(any(uhoh <- is.na(j)))
    stop(paste("Unrecognised",
               ngettext(sum(uhoh), "level", "levels"),
               sQuote(i[uhoh]),
               "amongst possible levels",
               commasep(sQuote(s))))
  if(length(j) < n)
    stop("Ordering is incomplete")
  ord <- order(j)
  m <- matrix(, n, n)
  rel <- matrix(ord[row(m)] <= ord[col(m)], n, n)
  dimnames(rel) <- list(s, s)
  x <- list(indices=j, ordering=ord, labels=s, relation=rel)
  class(x) <- "hierarchicalordering"
  x
}

print.hierarchicalordering <- function(x, ...) {
  cat(paste(x$labels[x$indices], collapse=" > "))
  cat("\n")
}
                     
hiermat <- function (x, h) 
{
  stopifnot(is.matrix(x))
  x[] <- as.character(x)
  if(inherits(h, "hierarchicalordering")) ## allows h to be NULL, etc
    x[!(h$relation)] <- ""
  return(noquote(x))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/ho.R"
#
#  ho.R
#
#  Huang-Ogata method 
#
#  $Revision: 1.14 $ $Date: 2014/02/11 11:01:08 $
#

ho.engine <- function(model, ..., nsim=100, nrmh=1e5,
                        start=NULL,
                        control=list(nrep=nrmh), verb=TRUE) {
  verifyclass(model, "ppm")

  if(is.null(start)) 
    start <- list(n.start=data.ppm(model)$n)
  
  # check that the model can be simulated
  if(!valid.ppm(model)) {
    warning("Fitted model is invalid - cannot be simulated")
    return(NULL)
  }
  
  # compute the observed value of the sufficient statistic
  X <- data.ppm(model)
  sobs <- suffstat(model, X)
  
  # generate 'nsim' realisations of the fitted model
  # and compute the sufficient statistics of the model
  rmhinfolist <- rmh(model, start, control, preponly=TRUE, verbose=FALSE)
  if(verb) cat("Simulating... ")
  for(i in 1:nsim) {
    if(verb) progressreport(i, nsim)
    Xi <- rmhEngine(rmhinfolist, verbose=FALSE)
    v <- suffstat(model,Xi)
    if(i == 1) 
      svalues <- matrix(, nrow=nsim, ncol=length(v))
    svalues[i, ] <- v
  }
  if(verb) cat("Done.\n\n")
  # calculate the sample mean and variance of the
  # sufficient statistic for the simulations
  smean <- apply(svalues, 2, mean, na.rm=TRUE)
  svar <- var(svalues, na.rm=TRUE)
  # value of canonical parameter from MPL fit
  theta0 <- coef(model)
  # Newton-Raphson update
  Vinverse <- solve(svar)
  theta <- theta0 + as.vector(Vinverse %*% (sobs - smean))
  ## update model
  newmodel <- model
  newmodel$coef <- theta
  newmodel$coef.orig <- theta0
  newmodel$method <- "ho"
  newmodel$fitter <- "ho"
  newmodel$fisher <- svar
  newmodel$varcov <- Vinverse
  # recompute fitted interaction
  newmodel$fitin <- NULL
  newmodel$fitin <- fitin(newmodel)
  ## update pseudolikelihood value using code in logLik.ppm
  newmodel$maxlogpl.orig <- model$maxlogpl
  newmodel$maxlogpl <- logLik(newmodel, new.coef=theta, warn=FALSE)
  ##
  return(newmodel)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/hopskel.R"
##
## hopskel.R
##     Hopkins-Skellam test
##
##  $Revision: 1.2 $  $Date: 2014/09/23 08:24:36 $

hopskel <- function(X) {
  stopifnot(is.ppp(X))
  n <- npoints(X)
  if(n < 2) return(NA)
  dX <- nndist(X)
  U <- runifpoint(n, Window(X))
  dU <- nncross(U, X, what="dist")
  A <- mean(dX^2)/mean(dU^2)
  return(A)
}

hopskel.test <- function(X, ..., 
                         alternative=c("two.sided", "less", "greater",
                           "clustered", "regular"),
                         method=c("asymptotic", "MonteCarlo"),
                         nsim=999
                         ) {
  Xname <- short.deparse(substitute(X))

  verifyclass(X, "ppp")
  W <- Window(X)
  n <- npoints(X)

  method <- match.arg(method)
  
  # alternative hypothesis
  alternative <- match.arg(alternative)
  if(alternative == "clustered") alternative <- "less"
  if(alternative == "regular") alternative <- "greater"
  altblurb <-
    switch(alternative,
           two.sided="two-sided",
           less="clustered (A < 1)",
           greater="regular (A > 1)")

  ## compute observed value
  statistic <- hopskel(X)
  ## p-value
  switch(method,
         asymptotic = {
           ## F-distribution
           nn <- 2 * n
           p.value <-
             switch(alternative,
                    less = pf(statistic, nn, nn, lower.tail=TRUE),
                    greater = pf(statistic, nn, nn, lower.tail=FALSE),
                    two.sided = 2 *
                    pf(statistic, nn, nn, lower.tail=(statistic < 1)))
           pvblurb <- "using F distribution"
         },
         MonteCarlo = {
           ## Monte Carlo p-value
           sims <- numeric(nsim)
           for(i in 1:nsim) {
             Xsim <- runifpoint(n, win=W)
             sims[i] <- hopskel(Xsim)
             p.upper <- (1 + sum(sims >= statistic))/(1 + nsim)
             p.lower <- (1 + sum(sims <= statistic))/(1 + nsim)
             p.value <- switch(alternative,
                               less=p.lower,
                               greater=p.upper,
                               two.sided=2*min(p.lower, p.upper))
           }
           pvblurb <- paste("Monte Carlo test based on",
                            nsim, "simulations of CSR with fixed n")
         })

  statistic <- as.numeric(statistic)
  names(statistic) <- "A"
  
  out <- list(statistic=statistic,
              p.value=p.value,
              alternative=altblurb,
              method=c("Hopkins-Skellam test of CSR", pvblurb),
              data.name=Xname)
  class(out) <- "htest"
  return(out)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/hybrid.R"
#
#
#    hybrid.R
#
#    $Revision: 1.5 $	$Date: 2014/12/17 10:54:07 $
#
#    Hybrid of several interactions
#
#    Hybrid()    create a hybrid of several interactions
#                 [an object of class 'interact']
#	
#
# -------------------------------------------------------------------
#	

Hybrid <- local({

  Hybrid <- function(...) {
    interlist <- list(...)
    n <- length(interlist)
    if(n == 0)
      stop("No arguments given")
    #' arguments may be interaction objects or ppm objects
    isinter <- unlist(lapply(interlist, is.interact))
    isppm   <- unlist(lapply(interlist, is.ppm))
    if(any(nbg <- !(isinter | isppm)))
      stop(paste(ngettext(sum(nbg), "Argument", "Arguments"),
                 paste(which(nbg), collapse=", "),
                 ngettext(sum(nbg), "is not an interaction",
                          "are not interactions")))
    #' ensure the list contains only interaction objects
    if(any(isppm))
      interlist[isppm] <- lapply(interlist[isppm], as.interact)
    #' recursively expand any components that are themselves hybrids
    while(any(ishybrid <- unlist(lapply(interlist, is.hybrid)))) {
      i <- min(which(ishybrid))
      n <- length(interlist)
      expandi <- interlist[[i]]$par
      interlist <- c(if(i > 1) interlist[1:(i-1)] else NULL,
                     expandi,
                     if(i < n) interlist[(i+1):n] else NULL)
    }
    #' 
    ncomponents <- length(interlist)
    if(ncomponents == 1) {
      #' single interaction - return it
      return(interlist[[1]])
    }
    #' ensure all components have names
    names(interlist) <- good.names(names(interlist),
                                   "HybridComponent", 1:ncomponents)
    out <- 
      list(
        name     = "Hybrid interaction",
        creator  = "Hybrid",
        family    = hybrid.family,
        pot      = NULL,
        par      = interlist,
        parnames = names(interlist),
        selfstart = function(X, self) {
          ilist <- self$par
          sslist <- lapply(ilist, getElement, name="selfstart")
          has.ss <- sapply(sslist, is.function)
          if(any(has.ss)) {
            ilist[has.ss] <- lapply(ilist[has.ss], invokeSelfStart, Y=X)
            self$par <- ilist
          }
          return(self)
        },
        init     = NULL,
        update = NULL,  # default OK
        print = function(self, ..., family=FALSE, brief=FALSE) {
          if(family)
            print.isf(self$family)
          ncomponents <- length(self$par)
          clabs <- self$parnames
          splat("Hybrid of", ncomponents, "components:",
                commasep(sQuote(clabs)))
          for(i in 1:ncomponents) {
            splat(paste0(clabs[i], ":"))
            print(self$par[[i]], ..., family=family, brief=brief)
          }
          parbreak()
          return(invisible(NULL))
        },
        interpret =  function(coeffs, self) {
          interlist <- self$par
          result <- list(param=list(),
                         inames=character(0),
                         printable=list())
          for(i in 1:length(interlist)) {
            interI <- interlist[[i]]
            nameI  <- names(interlist)[[i]]
            nameI. <- paste(nameI, ".", sep="")
            #' find coefficients with prefix that exactly matches nameI.
            Cname  <- names(coeffs)
            prefixlength <- nchar(nameI.)
            Cprefix <- substr(Cname, 1, prefixlength)
            relevant <- (Cprefix == nameI.)
            #' extract them
            if(any(relevant)) {
              Crelevant <- coeffs[relevant]
              names(Crelevant) <-
                substr(Cname[relevant], prefixlength+1, max(nchar(Cname)))
              #' invoke the self-interpretation of interI
              interpretI <- interI$interpret
              if(is.function(interpretI)) {
                resultI <- interpretI(Crelevant, interI)
                paramI  <- resultI$param
                prinI   <- resultI$printable
                inamesI <- resultI$inames
                inamesI <- paste(nameI, inamesI)
                if(length(prinI) > 0) {
                  result$param     <- append(result$param, paramI)
                  result$printable <- append(result$printable, list(prinI))
                  result$inames <- c(result$inames, inamesI)
                }
              }
            }
          }
          return(result)
        },
        valid = function(coeffs, self) {
          #' check validity via mechanism used for 'rmhmodel' 
          siminfo <- .Spatstat.Rmhinfo[["Hybrid interaction"]]
          Z <- siminfo(coeffs, self)
          cifs   <- Z$cif
          pars   <- Z$par
          ntypes <- Z$ntypes
          if((Ncif <- length(cifs)) == 1) {
            #' single cif
            pars <- append(pars, list(beta=rep.int(1, ntypes)))
          } else {
            for(i in 1:Ncif) 
              pars[[i]] <- append(pars[[i]], list(beta=rep.int(1, ntypes[i])))
          }
          RM <- rmhmodel(cif=cifs, par=pars, types=1:max(ntypes), 
                         stopinvalid=FALSE)
          return(RM$integrable)
        },
        project = function(coeffs, self) {
          if((self$valid)(coeffs, self)) return(NULL)
          #' separate into components
          spl <- splitHybridInteraction(coeffs, self)
          interlist <- spl$interlist
          coeflist  <- spl$coeflist
          #' compute projection for each component interaction
          Ncif <- length(interlist)
          projlist <- vector(mode="list", length=Ncif)
          nproj    <- integer(Ncif)
          for(i in 1:Ncif) {
            coefsI <- coeflist[[i]]
            interI <- interlist[[i]]
            if(!is.interact(interI))
              stop("Internal error: interlist entry is not an interaction")
            projI <- interI$project
            if(is.null(projI))
              stop(paste("Projection is not yet implemented for a",
                         interI$name))
            p <- projI(coefsI, interI)
            #' p can be NULL (indicating no projection required for interI)
            #' or a single interaction or a list of interactions.
            if(is.null(p)) {
              if(Ncif == 1) return(NULL) # no projection required
              p <- list(NULL)
              nproj[i] <- 0
            } else if(is.interact(p)) {
              p <- list(p)
              nproj[i] <- 1
            } else if(is.list(p) && all(unlist(lapply(p, is.interact)))) {
              nproj[i] <- length(p)
            } else
              stop("Internal error: result of projection had wrong format")
            projlist[[i]] <- p
          }
          #' for interaction i there are nproj[i] **new** interactions to try.
          if(all(nproj == 0))
            return(NULL)
          if(spatstat.options("project.fast")) {
            #' Single interaction required.
            #' Extract first entry from each list
            #' (there should be only one entry, but...)
            qlist <- lapply(projlist, function(z) z[[1]])
            #' replace NULL entries by corresponding original interactions
            isnul <- unlist(lapply(qlist, is.null))
            if(all(isnul))
              return(NULL)
            if(any(isnul))
              qlist[isnul] <- interlist[isnul]
            names(qlist) <- names(interlist)
            #' build hybrid and return
            result <- do.call("Hybrid", qlist)
            return(result)
          } 
          #' Full case
          result <- list()
          for(i in which(nproj > 0)) {
            ntry <- nproj[i]
            tries <- projlist[[i]]
            for(j in 1:ntry) {
              #' assemble list of component interactions for hybrid
              qlist <- interlist
              qlist[[i]] <- tries[[j]]
              #' eliminate Poisson
              ispois <- unlist(lapply(qlist, is.poisson))
              if(all(ispois)) {
                #' collapse to single Poisson
                h <- Poisson()
              } else {
                if(any(ispois)) qlist <- qlist[!ispois]
                h <- do.call("Hybrid", qlist)
              }
              result <- append(result, list(h))
            }
          }
          #' 'result' is a list of interactions, each a hybrid
          if(length(result) == 1)
            result <- result[[1]]
          return(result)
        },
        irange = function(self, coeffs=NA, epsilon=0, ...) {
          interlist <- self$par
          answer <- 0
          for(i in 1:length(interlist)) {
            interI <- interlist[[i]]
            nameI  <- names(interlist)[[i]]
            nameI. <- paste(nameI, ".", sep="")
            #' find coefficients with prefix that exactly matches nameI.
            if(all(is.na(coeffs)))
              Crelevant <- NA
            else {
              Cname  <- names(coeffs)
              prefixlength <- nchar(nameI.)
              Cprefix <- substr(Cname, 1, prefixlength)
              relevant <- (Cprefix == nameI.)
              #' extract them
              Crelevant <- coeffs[relevant]
              names(Crelevant) <-
                substr(Cname[relevant], prefixlength+1, max(nchar(Cname)))
            }
            #' compute reach 
            reachI <- interI$irange
            if(is.function(reachI)) {
              resultI <- reachI(interI,
                                coeffs=Crelevant, epsilon=epsilon, ...)
              answer <- max(answer, resultI)
            }
          }
          return(answer)
        },
        version=versionstring.spatstat()
        )
    class(out) <- "interact"
    return(out)
  }

  invokeSelfStart <- function(inte, Y) {
    ss <- inte$selfstart
    if(!is.function(ss)) return(inte)
    return(ss(Y, inte))
  }

  Hybrid
})


is.hybrid <- function(x) { UseMethod("is.hybrid") }

is.hybrid.interact <- function(x) {
  return(is.interact(x) && (x$name == "Hybrid interaction"))
}

is.hybrid.ppm <- function(x) {
  return(is.hybrid(as.interact(x)))
}

splitHybridInteraction <- function(coeffs, inte) {
  # For hybrids, $par is a list of the component interactions,
  # but coeffs is a numeric vector. 
  # Split the coefficient vector into the relevant coeffs for each interaction
  interlist <- inte$par
  N <- length(interlist)
  coeflist <- vector(mode="list", length=N)
  for(i in 1:N) {
    interI <- interlist[[i]]
    # forbid hybrids-of-hybrids - these should not occur anyway
    if(interI$name == "Hybrid interaction")
      stop("A hybrid-of-hybrid interactions is not implemented")
    # nameI is the tag that identifies I-th component in hybrid
    nameI  <- names(interlist)[[i]]
    nameI. <- paste(nameI, ".", sep="")
    # find coefficients with prefix that exactly matches nameI.
    Cname  <- names(coeffs)
    prefixlength <- nchar(nameI.)
    Cprefix <- substr(Cname, 1, prefixlength)
    relevant <- (Cprefix == nameI.)
    # extract coefficients
    #   (there may be none, if this interaction is Poisson or an 'offset')
    coeffsI <- coeffs[relevant]
    # remove the prefix so the coefficients are recognisable to interaction
    if(any(relevant)) 
      names(coeffsI) <-
        substr(Cname[relevant], prefixlength+1, max(nchar(Cname)))
    # store
    coeflist[[i]] <- coeffsI
  }
  names(coeflist) <- names(interlist)
  return(list(coeflist=coeflist, interlist=interlist))
}

Hybrid <- intermaker(Hybrid, list(creator="Hybrid",
                                  name="general hybrid Gibbs process",
                                  par=list("..."=42),
                                  parnames=list("any list of interactions")))
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/hybrid.family.R"
#
#   hybrid.family.R
#
#    $Revision: 1.7 $	$Date: 2014/05/21 03:27:15 $
#
#    Hybrid interactions
#
#    hybrid.family:      object of class 'isf' defining pairwise interaction
#	
# -------------------------------------------------------------------
#	

hybrid.family <-
  list(
       name  = "hybrid",
       print = function(self) {
         cat("Hybrid interaction family\n")
       },
       plot = function(fint, ..., d=NULL, plotit=TRUE, separate=FALSE) {
         # plot hybrid interaction if possible
         verifyclass(fint, "fii")
         inter <- fint$interaction
         if(is.null(inter) || is.null(inter$family)
            || inter$family$name != "hybrid")
           stop("Tried to plot the wrong kind of interaction")
         if(is.null(d)) {
           # compute reach and determine max distance for plots
           dmax <- 1.25 * reach(inter)
           if(!is.finite(dmax)) {
             # interaction has infinite reach
             # Are plot limits specified?
             xlim <- resolve.defaults(list(...), list(xlim=c(0, Inf)))
             if(all(is.finite(xlim))) dmax <- max(xlim) else 
             stop("Interaction has infinite reach; need to specify xlim or d")
           }
           d <- seq(0, dmax, length=256)
         }
         # get fitted coefficients of interaction terms
         # and set coefficients of offset terms to 1         
         Vnames <- fint$Vnames
         IsOffset <- fint$IsOffset
         coeff <- rep.int(1, length(Vnames))
         names(coeff) <- Vnames
         coeff[!IsOffset] <- fint$coefs[Vnames[!IsOffset]]         
         # extract the component interactions 
         interlist <- inter$par
         # check that they are all pairwise interactions
         families <- unlist(lapply(interlist, function(x) { x$family$name }))
         if(!separate && !all(families == "pairwise")) {
           warning(paste("Cannot compute the resultant function;",
                         "not all components are pairwise interactions;",
                         "plotting each component separately"))
           separate <- TRUE
         }
         # deal with each interaction
         ninter <- length(interlist)
         results <- list()
         for(i in 1:ninter) {
           interI <- interlist[[i]]
           nameI  <- names(interlist)[[i]]
           nameI. <- paste(nameI, ".", sep="")
           # find coefficients with prefix that exactly matches nameI.
           prefixlength <- nchar(nameI.)
           Vprefix <- substr(Vnames, 1, prefixlength)
           relevant <- (Vprefix == nameI.)
           # construct fii object for this component
           fitinI <- fii(interI,
                         coeff[relevant], Vnames[relevant], IsOffset[relevant])
           # convert to fv object
           a <- plot(fitinI, ..., d=d, plotit=FALSE)
           aa <- list(a)
           names(aa) <- nameI
           results <- append(results, aa)
         }
         # computation of resultant is only implemented for fv objects
         if(!separate && !all(unlist(lapply(results, is.fv)))) {
           warning(paste("Cannot compute the resultant function;",
                         "not all interaction components yielded an fv object;",
                         "plotting separate results for each component"))
           separate <- TRUE
         }
         # return separate 'fv' or 'fasp' objects if required
         results <- as.listof(results)
         if(separate) {
           if(plotit) {
             main0 <- "Pairwise interaction components"
             do.call("plot", resolve.defaults(list(results),
                                              list(...),
                                              list(main=main0)))
           }
           return(invisible(results))
         }
         # multiply together to obtain resultant pairwise interaction
         ans <- results[[1]]
         if(ninter >= 2) {
           for(i in 2:ninter) {
             Fi <- results[[i]]
             ans <- eval.fv(ans * Fi)
           }
           copyover <- c("ylab", "yexp", "labl", "desc", "fname")
           attributes(ans)[copyover] <- attributes(results[[1]])[copyover]
         }
         main0 <- "Resultant pairwise interaction"
         if(plotit)
           do.call("plot", resolve.defaults(list(ans),
                                            list(...),
                                            list(main=main0)))
         return(invisible(ans))
       },
       eval  = function(X,U,EqualPairs,pot,pars,correction, ...) {
         # `pot' is ignored; `pars' is a list of interactions
         nU <- length(U$x)
         V <- matrix(, nU, 0)
         IsOffset <- logical(0)
         for(i in 1:length(pars)) {
           # extract i-th component interaction
           interI <- pars[[i]]
           nameI  <- names(pars)[[i]]
           # compute potential for i-th component
           VI <- evalInteraction(X, U, EqualPairs, interI, correction, ...)
           if(ncol(VI) > 0) {
             if(ncol(VI) > 1 && is.null(colnames(VI))) # make up names
               colnames(VI) <- paste("Interaction", seq(ncol(VI)), sep=".")
             # prefix label with name of i-th component 
             colnames(VI) <- paste(nameI, dimnames(VI)[[2]], sep=".")
             # handle IsOffset
             offI <- attr(VI, "IsOffset")
             if(is.null(offI))
               offI <- rep.int(FALSE, ncol(VI))
             # tack on
             IsOffset <- c(IsOffset, offI)
             # append to matrix V
             V <- cbind(V, VI)
           }
         }
         if(any(IsOffset))
           attr(V, "IsOffset") <- IsOffset
         return(V)
       },
       delta2 = function(X, inte, correction, ...) {
         ## Sufficient statistic for second order conditional intensity
         result <- NULL
         interlist <- inte$par
         for(ii in interlist) {
           v <- NULL
           ## look for 'delta2' in component interaction 'ii'
           if(!is.null(delta2 <- ii$delta2) && is.function(delta2)) 
             v <- delta2(X, ii, correction)
           ## look for 'delta2' in family of component 'ii'
           if(is.null(v) &&
              !is.null(delta2 <- ii$family$delta2) &&
              is.function(delta2))
             v <- delta2(X, ii, correction)
           if(is.null(v)) {
             ## no special algorithm available: generic algorithm needed
             return(NULL)
           }
           result <- abind(result, v, along=3)
         }
         return(result)
       },
       suffstat = NULL
)

class(hybrid.family) <- "isf"


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/hyperframe.R"
#
#  hyperframe.R
#
# $Revision: 1.52 $  $Date: 2014/10/24 00:22:30 $
#

hyperframe <- function(...,
                       row.names=NULL, check.rows=FALSE, check.names=TRUE,
                       stringsAsFactors=default.stringsAsFactors()) {
  aarg <- list(...)
  nama <- names(aarg)

  # number of columns (= variables)
  nvars <- length(aarg)
  
  if(nvars == 0) {
    # zero columns - return
    result <- list(nvars=0,
                   ncases=0,
                   vname=character(0),
                   vtype=factor(,
                     levels=c("dfcolumn","hypercolumn","hyperatom")),
                   vclass=character(0),
                   df=data.frame(),
                   hyperatoms=list(),
                   hypercolumns=list())
    class(result) <- c("hyperframe", class(result))
    return(result)
  }

  # check column names
  if(is.null(nama))
    nama <- paste("V", 1:nvars, sep="")
  else if(any(unnamed <- (nama == ""))) 
    nama[unnamed] <- paste("V", seq_len(sum(unnamed)), sep="")
  nama <- make.names(nama, unique=TRUE)
  names(aarg) <- nama
  
  # Each argument must be either
  #    - a vector suitable as a column in a data frame
  #    - a list of objects of the same class
  #    - a single object of some class
  
  is.dfcolumn <- function(x) {
    is.atomic(x) && (is.vector(x) || is.factor(x))
  }
  is.hypercolumn <- function(x) {
    if(!is.list(x))
      return(FALSE)
    if(length(x) <= 1)
      return(TRUE)
    cla <- class(x[[1]])
    all(sapply(x, function(xi,cla) { identical(class(xi), cla) }, cla=cla))
  }
  dfcolumns    <- sapply(aarg, is.dfcolumn)
  hypercolumns <- sapply(aarg, is.hypercolumn)
  hyperatoms   <- !(dfcolumns | hypercolumns)

  # Determine number of rows (= cases) 
  columns <- dfcolumns | hypercolumns
  if(!any(columns)) 
    ncases <- 1
  else {
    heights <- rep.int(1, nvars)
    heights[columns] <-  unlist(lapply(aarg[columns], length))
    u <- unique(heights)
    if(length(u) > 1) {
      u <- u[u != 1]
      if(length(u) > 1)
        stop(paste("Column lengths are inconsistent:",
                   paste(u, collapse=",")))
    }
    ncases <- u
    if(ncases > 1 && all(heights[dfcolumns] == 1)) {
      # force the data frame to have 'ncases' rows
      aarg[dfcolumns] <- lapply(aarg[dfcolumns], rep, ncases)
      heights[dfcolumns] <- ncases
    }
    if(any(stubs <- hypercolumns & (heights != ncases))) {
      ## hypercolumns of height 1 should be hyperatoms
      aarg[stubs] <- lapply(aarg[stubs], "[[", 1)
      hypercolumns[stubs] <- FALSE
      hyperatoms[stubs] <- TRUE
    }
  }

  # Collect the data frame columns into a data frame
  if(!any(dfcolumns))
    df <- as.data.frame(matrix(, ncases, 0), row.names=row.names)
  else {
    df <- do.call("data.frame", append(aarg[dfcolumns],
                                     list(row.names=row.names,
                                          check.rows=check.rows,
                                          check.names=check.names,
                                          stringsAsFactors=stringsAsFactors)))
    names(df) <- nama[dfcolumns]
  }

  # Storage type of each variable
  vtype <- character(nvars)
  vtype[dfcolumns] <- "dfcolumn"
  vtype[hypercolumns] <- "hypercolumn"
  vtype[hyperatoms] <- "hyperatom"
  vtype=factor(vtype, levels=c("dfcolumn","hypercolumn","hyperatom"))

  # Class of each variable
  class1 <- function(x) { class(x)[1] }
  vclass <- character(nvars)
  if(any(dfcolumns))
    vclass[dfcolumns] <- unlist(lapply(as.list(df), class1))
  if(any(hyperatoms))
    vclass[hyperatoms] <- unlist(lapply(aarg[hyperatoms], class1))
  if(any(hypercolumns))
    vclass[hypercolumns] <- unlist(lapply(aarg[hypercolumns],
                                          function(x) { class1(x[[1]]) }))
  
  # Put the result together
  result <- list(nvars=nvars,
                 ncases=ncases,
                 vname=nama,
                 vtype=vtype,
                 vclass=vclass,
                 df=df,
                 hyperatoms=aarg[hyperatoms],
                 hypercolumns=aarg[hypercolumns])
  
    class(result) <- c("hyperframe", class(result))
    return(result)
}

is.hyperframe <- function(x) inherits(x, "hyperframe")

print.hyperframe <- function(x, ...) {
  ux <- unclass(x)
  nvars <- ux$nvars
  ncases <- ux$ncases
  if(nvars * ncases == 0) {
    cat(paste("NULL hyperframe with", ncases,
              ngettext(ncases, "row (=case)", "rows (=cases)"),
              "and", nvars,
              ngettext(nvars, "column (=variable)", "columns (=variables)"),
              "\n"))
  } else {
    cat("Hyperframe:\n")
    print(as.data.frame(x, discard=FALSE), ...)
  }
  return(invisible(NULL))
}

dim.hyperframe <- function(x) {
  with(unclass(x), c(ncases, nvars))
}

summary.hyperframe <- function(object, ..., brief=FALSE) {
  x <- unclass(object)
  y <- list(
            nvars = x$nvars,
            ncases = x$ncases,
            dim = c(x$ncases, x$nvars),
            typeframe = data.frame(VariableName=x$vname, Class=x$vclass),
            storage = x$vtype,
            col.names = x$vname)
  classes <- x$vclass
  names(classes) <- x$vname
  y$classes <- classes
  # Ordinary data frame columns
  df <- x$df
  y$dfnames <- names(df)
  y$df <- if(length(df) > 0 && !brief) summary(df) else NULL
  y$row.names <- row.names(df)
  class(y) <- c("summary.hyperframe", class(y))
  return(y)
}

print.summary.hyperframe <- function(x, ...) {
  nvars <- x$nvars
  ncases <- x$ncases
  cat(paste(if(nvars * ncases == 0) "NULL" else NULL,
            "hyperframe with", ncases,
            ngettext(ncases, "row (=case)", "rows (=cases)"),
            "and", nvars,
            ngettext(nvars, "column (=variable)", "columns (=variables)"),
            "\n"))
  if(nvars == 0)
    return(invisible(NULL))
  # Variable names and types
  print(x$typeframe)
  # Ordinary data frame columns
  if(!is.null(x$df)) {
    cat("Summary of data frame columns:\n")
    print(x$df, ...)
  }
  return(invisible(NULL))
}

names.hyperframe <- function(x) { unclass(x)$vname }

"names<-.hyperframe" <- function(x, value) {
  x <- unclass(x)
  stopifnot(is.character(value))
  value <- make.names(value)
  if(length(value) != x$nvars)
    stop("Incorrect length for vector of names")
  vtype <- x$vtype
  names(x$df)           <- value[vtype == "dfcolumn"]
  names(x$hyperatoms)   <- value[vtype == "hyperatom"]
  names(x$hypercolumns) <- value[vtype == "hypercolumn"]
  x$vname <- value
  class(x) <- c("hyperframe", class(x))
  return(x)
}

row.names.hyperframe <- function(x) {
  return(row.names(unclass(x)$df))
}

"row.names<-.hyperframe" <- function(x, value) {
  y <- unclass(x)
  df <- y$df
  row.names(df) <- value
  y$df <- df
  class(y) <- c("hyperframe", class(y))
  return(y)
}


## conversion to hyperframe

as.hyperframe <- function(x, ...) {
  UseMethod("as.hyperframe")
}

as.hyperframe.hyperframe <- function(x, ...) {
  return(x)
}

as.hyperframe.data.frame <- function(x, ..., stringsAsFactors=FALSE) {
  xlist <- if(missing(x)) NULL else as.list(x)
  do.call("hyperframe",
          resolve.defaults(
                           xlist,
                           list(...),
                           list(row.names=rownames(x),
                                stringsAsFactors=stringsAsFactors),
                           .StripNull=TRUE))
}

as.hyperframe.anylist <- 
as.hyperframe.listof <- function(x, ...) {
  if(!missing(x)) {
    xname <- sensiblevarname(short.deparse(substitute(x)), "x")
    xlist <- list(x)
    names(xlist) <- xname
  } else xlist <- NULL
  do.call("hyperframe",
          resolve.defaults(
                           xlist,
                           list(...),
                           list(row.names=rownames(x)),
                           .StripNull=TRUE))
}

as.hyperframe.default <- function(x, ...) {
  as.hyperframe(as.data.frame(x, ...))
}

#### conversion to other types

as.data.frame.hyperframe <- function(x, row.names = NULL,
                                     optional = FALSE, ...,
                                     discard=TRUE, warn=TRUE) {
  ux <- unclass(x)
  if(is.null(row.names))
    row.names <- row.names(ux$df)
  vtype <- ux$vtype
  vclass <- ux$vclass
  dfcol <- (vtype == "dfcolumn")
  if(discard) { 
    nhyper <- sum(!dfcol)
    if(nhyper > 0 && warn)
      warning(paste(nhyper, 
                    ngettext(nhyper, "variable", "variables"),
                    "discarded in conversion to data frame"))
    df <- as.data.frame(ux$df, row.names=row.names, optional=optional, ...)
  } else {
    lx <- as.list(x)
    nrows <- ux$ncases
    vclassstring <- paren(vclass)
    if(any(!dfcol)) 
      lx[!dfcol] <- lapply(as.list(vclassstring[!dfcol]),
                           rep.int, times=nrows)
    df <- do.call("data.frame", append(lx, list(row.names=row.names)))
    colnames(df) <- ux$vname
  }
  return(df)
}

as.list.hyperframe <- function(x, ...) {
  ux <- unclass(x)
  nama <- ux$vname
  names(nama) <- nama
  out <- lapply(nama, function(nam, x) { x[, nam, drop=TRUE] }, x=x)
  if(ux$ncases == 1)
    out <- lapply(out, listof)
  out <- lapply(out, "names<-", value=row.names(x))
  return(out)
}

# evaluation

eval.hyper <- function(e, h, simplify=TRUE, ee=NULL) {
  .Deprecated("with.hyperframe", package="spatstat")
  if(is.null(ee))
    ee <- as.expression(substitute(e))
  with.hyperframe(h, simplify=simplify, ee=ee)
}

with.hyperframe <- function(data, expr, ..., simplify=TRUE, ee=NULL,
                            enclos=NULL) {
  if(!inherits(data, "hyperframe"))
    stop("data must be a hyperframe")
  if(is.null(ee))
    ee <- as.expression(substitute(expr))
  if(is.null(enclos))
    enclos <- parent.frame()
  n <- nrow(data)
  out <- vector(mode="list", length=n)
  datalist <- as.list(data)
  for(i in 1:n) {
    rowi <- lapply(datalist, "[[", i)  # ensures the result is always a list
    outi <- eval(ee, rowi, enclos)
    if(!is.null(outi))
      out[[i]] <- outi
  }
  names(out) <- row.names(data)
  if(simplify && all(unlist(lapply(out, is.vector)))) {
    # if all results are atomic vectors of equal length,
    # return a matrix or vector.
    lenfs <- unlist(lapply(out, length))
    if(all(unlist(lapply(out, is.atomic))) &&
            length(unique(lenfs)) == 1) {
      out <- t(as.matrix(as.data.frame(out)))
      row.names(out) <- row.names(data)
      out <- out[,,drop=TRUE]
      return(out)
    }
  }
  out <- hyperframe(result=out, row.names=row.names(data))$result
  return(out)
}

cbind.hyperframe <- function(...) {
  aarg <- list(...)
  narg <- length(aarg)
  if(narg == 0)
    return(hyperframe())
  namarg <- names(aarg)
  if(is.null(namarg))
    namarg <- rep.int("", narg)
  ishyper <- unlist(lapply(aarg, inherits, what="hyperframe"))
  isdf <- unlist(lapply(aarg, inherits, what="data.frame"))
  columns <- list()
  for(i in 1:narg) {
    if(ishyper[i] || isdf[i]){
      if(ncol(aarg[[i]]) > 0) {
        newcolumns <- as.list(aarg[[i]])
        if(namarg[i] != "")
          names(newcolumns) <- paste(namarg[i], ".", names(newcolumns), sep="")
        columns <- append(columns, newcolumns)
      }
    } else {
      nextcolumn <- list(aarg[[i]])
      names(nextcolumn) <- namarg[i]
      columns <- append(columns, nextcolumn)
    }
  }
  result <- do.call("hyperframe", columns)
  return(result)
}

rbind.hyperframe <- function(...) {
  argh <- list(...)
  if(length(argh) == 0)
    return(NULL)
  # convert them all to hyperframes
  argh <- lapply(argh, as.hyperframe)
  #
  nargh <- length(argh)
  if(nargh == 1)
    return(argh[[1]])
  # check for compatibility of dimensions & names
  dfs <- lapply(argh, as.data.frame, discard=FALSE)
  dfall <- do.call(rbind, dfs)
  # check that data frame columns also match
  dfs0 <- lapply(argh, as.data.frame, discard=TRUE, warn=FALSE)
  df0all <- do.call(rbind, dfs0)
  # assemble data
  rslt <- list()
  nam <- names(dfall) 
  nam0 <- names(df0all)
  for(k in seq_along(nam)) {
    nama <- nam[k]
    if(nama %in% nam0) {
      # data frame column: already made
      rslt[[k]] <- dfall[,k]
    } else {
      # hypercolumns or hyperatoms: extract them
      hdata <- lapply(argh,
                      function(x,nama) { x[, nama, drop=FALSE] },
                      nama=nama)
      hdata <- lapply(lapply(hdata, as.list), getElement, name=nama)
      # append them
      hh <- hdata[[1]]
      for(j in 2:nargh) {
        hh <- append(hh, hdata[[j]])
      }
      rslt[[k]] <- hh
    }
  }
  # make hyperframe
  names(rslt) <- nam
  out <- do.call(hyperframe, append(rslt, list(stringsAsFactors=FALSE)))
  return(out)
}

plot.hyperframe <-
  function(x, e, ..., main, arrange=TRUE,
           nrows=NULL, ncols=NULL,
           parargs=list(mar=c(1,1,3,1) * marsize),
           marsize=0.1) {
  xname <- short.deparse(substitute(x))
  main <- if(!missing(main)) main else xname

  if(missing(e)) {
    # default: plot first column that contains objects
    ok <- (summary(x)$storage %in% c("hypercolumn", "hyperatom"))
    if(any(ok)) {
      j <- min(which(ok))
      x <- x[,j, drop=TRUE]
      x <- as.listof(x)
      plot(x, ..., main=main, arrange=arrange, nrows=nrows, ncols=ncols)
      return(invisible(NULL))
    } else {
      # hyperframe does not contain any objects
      # invoke plot.data.frame
      x <- as.data.frame(x)
      plot(x, ..., main=main)
      return(invisible(NULL))
    }
  }

  if(!is.language(e))
    stop(paste("Argument e should be a call or an expression;",
               "use quote(...) or expression(...)"))
  ee <- as.expression(e)

  if(!arrange) {
    # No arrangement specified: just evaluate the plot expression 'nr' times
    with(x, ee=ee)
    return(invisible(NULL))
  }

  # Arrangement
  # Decide whether to plot a main header
  banner <- (sum(nchar(as.character(main))) > 0)
  if(length(main) > 1)
    main <- paste(main, collapse="\n")
  nlines <- if(!is.character(main)) 1 else length(unlist(strsplit(main, "\n")))
  # determine arrangement of plots
  # arrange like mfrow(nrows, ncols) plus a banner at the top
  n <- summary(x)$ncases
  if(is.null(nrows) && is.null(ncols)) {
    nrows <- as.integer(floor(sqrt(n)))
    ncols <- as.integer(ceiling(n/nrows))
  } else if(!is.null(nrows) && is.null(ncols))
    ncols <- as.integer(ceiling(n/nrows))
  else if(is.null(nrows) && !is.null(ncols))
    nrows <- as.integer(ceiling(n/ncols))
  else stopifnot(nrows * ncols >= length(x))
  nblank <- ncols * nrows - n
  # declare layout
  mat <- matrix(c(seq_len(n), numeric(nblank)),
                byrow=TRUE, ncol=ncols, nrow=nrows)
  heights <- rep.int(1, nrows)
  if(banner) {
    # Increment existing panel numbers
    # New panel 1 is the banner
    panels <- (mat > 0)
    mat[panels] <- mat[panels] + 1
    mat <- rbind(rep.int(1,ncols), mat)
    heights <- c(0.1 * (1 + nlines), heights)
  }
  # initialise plot
  layout(mat, heights=heights)
  # plot banner
  if(banner) {
    opa <- par(mar=rep.int(0,4), xpd=TRUE)
    plot(numeric(0),numeric(0),type="n",ann=FALSE,axes=FALSE,
         xlim=c(-1,1),ylim=c(-1,1))
    cex <- resolve.defaults(list(...), list(cex.title=2))$cex.title
    text(0,0,main, cex=cex)
  }
  # plot panels
  npa <- do.call("par", parargs)
  if(!banner) opa <- npa
  with(x, ee=ee)
  # revert
  layout(1)
  par(opa)
  return(invisible(NULL))
}


str.hyperframe <- function(object, ...) {
  d <- dim(object)
  x <- unclass(object)
  argh <- resolve.defaults(list(...), list(nest.lev=0, indent.str="  .."))
  cat(paste("'hyperframe':\t",
            d[1], ngettext(d[1], "row", "rows"),
            "and",
            d[2], ngettext(d[2], "column", "columns"),
            "\n"))
  nr <- d[1]
  nc <- d[2]
  if(nc > 0) {
    vname <- x$vname
    vclass <- x$vclass
    vtype  <- as.character(x$vtype)
    indentstring <- with(argh, paste(rep.int(indent.str, nest.lev), collapse=""))
    for(j in 1:nc) {
      tag <- paste("$", vname[j])
      switch(vtype[j],
             dfcolumn={
               desc <- vclass[j]
               if(nr > 0) {
                 vals <- object[1:min(nr,3),j,drop=TRUE]
                 vals <- paste(paste(format(vals), collapse=" "), "...")
               } else vals <- ""
             },
             hypercolumn=,
             hyperatom={
               desc <- "objects of class"
               vals <- vclass[j]
             })
      cat(paste(paste(indentstring, tag, sep=""),
                ":", desc, vals, "\n"))
    }
  }
  return(invisible(NULL))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/hypersub.R"
##
## hypersub.R
##
##
##  subset operations for hyperframes
##
##  $Revision: 1.17 $    $Date: 2014/11/11 10:21:17 $
##

"[.hyperframe" <- function(x, i, j, drop=FALSE, strip=drop, ...) {
  x <- unclass(x)
  if(!missing(i)) {
    y <- x
    y$df     <- x$df[i, , drop=FALSE]
    y$ncases <- nrow(y$df)
    y$hypercolumns <- lapply(x$hypercolumns, function(z,k) { z[k] }, k=i)
    x <- y
  }
  if(!missing(j)) {
    y <- x
    patsy <- seq_len(y$nvars)
    names(patsy) <- y$vname
    jj <- patsy[j]
    names(jj) <- NULL
    y$nvars <- length(jj)
    y$vname <- vname <- x$vname[jj]
    y$vtype <- vtype <- x$vtype[jj]
    y$vclass <- x$vclass[jj]
    if(ncol(x$df) != 0) 
      y$df    <- x$df[ , vname[vtype == "dfcolumn"], drop=FALSE]
    y$hyperatoms <- x$hyperatoms[ vname[ vtype == "hyperatom" ]]
    y$hypercolumns <- x$hypercolumns[ vname [ vtype == "hypercolumn" ] ]
    x <- y
  }
  if(drop) {
    nrows <- x$ncases
    ncols <- x$nvars
    if(nrows == 1 && ncols == 1 && strip) {
      ## return a single object 
      y <- switch(as.character(x$vtype),
                  dfcolumn    = x$df[, , drop=TRUE],
                  hypercolumn = (x$hypercolumns[[1]])[[1]],
                  hyperatom   = x$hyperatoms[[1]])
      return(y)
    } else if(nrows == 1) {
      ## return the row as a vector or a list
      if(strip && all(x$vtype == "dfcolumn"))
        return(x$df[ , , drop=TRUE])
      n <- x$nvars
      y <- vector(mode="list", length=n)
      names(y) <- nama <- x$vname
      for(i in seq_len(n)) {
        nami <- nama[i]
        y[[i]] <- switch(as.character(x$vtype[i]),
                         dfcolumn = x$df[ , nami, drop=TRUE],
                         hyperatom = x$hyperatoms[[nami]],
                         hypercolumn = (x$hypercolumns[[nami]])[[1]]
                         )
      }
      return(y)
    } else if(ncols == 1) {
      ## return a column as a 'listof' or a vector
      switch(as.character(x$vtype),
             dfcolumn = {
               return(x$df[, , drop=TRUE])
             },
             hypercolumn = {
               y <- as.listof(x$hypercolumns[[1]])
               names(y) <- row.names(x$df)
               return(y)
             },
             hyperatom = {
               ## replicate it to make a hypercolumn
               ha <- x$hyperatoms[1]
               names(ha) <- NULL
               hc <- rep.int(ha, x$ncases)
               hc <- as.listof(hc)
               names(hc) <- row.names(x$df)
               return(hc)
             }
           )
    }
  }
  class(x) <- c("hyperframe", class(x))
  return(x)
}

"$.hyperframe" <- function(x,name) {
  m <- match(name, unclass(x)$vname)
  if(is.na(m))
    return(NULL)
  return(x[, name, drop=TRUE, strip=FALSE])
}

"$<-.hyperframe" <- function(x, name, value) {
  rown <- row.names(x)
  x <- as.list(x)
  dfcol <- is.atomic(value) && (is.vector(value) || is.factor(value))
  if(!dfcol && !is.null(value))
    value <- as.list(value)
  x[[name]] <- value
  y <- do.call("hyperframe", append(x, list(row.names=rown,
                                            stringsAsFactors=FALSE)))
  return(y)
}

"[<-.hyperframe" <- 
function (x, i, j, value)
{
  sumry <- summary(x)
  colnam <- sumry$col.names
  dimx <- sumry$dim
  igiven <- !missing(i)
  jgiven <- !missing(j)
  if(!igiven) i <- seq_len(dimx[1])
  if(!jgiven) j <- seq_len(dimx[2])
#  singlerow    <- ((is.integer(i) && length(i) == 1 && i > 0)
#                   || (is.character(i) && length(i) == 1)
#                   || (is.logical(i) && sum(i) == 1))
  singlecolumn <- ((is.integer(j) && length(j) == 1 && j > 0)
                   || (is.character(j) && length(j) == 1)
                   || (is.logical(j) && sum(j) == 1))
  if(!igiven && jgiven) {
    # x[, j] <- value
    if(singlecolumn) {
      # expecting single hypercolumn
      if(is.logical(j)) j <- names(x)[j]
      y <- get("$<-.hyperframe")(x, j, value)
    } else {
      # expecting hyperframe 
      xlist <- as.list(x)
      xlist[j] <- as.list(as.hyperframe(value))
      # the above construction accepts all indices including extra entries
      y <- do.call("hyperframe", append(xlist,
                                        list(row.names=row.names(x))))
    }
  } else {
    ## x[, ] <- value or x[i, ] <- value or x[i,j] <- value 
    ## convert indices to positive integers
    rowseq <- seq_len(dimx[1])
    colseq <- seq_len(dimx[2])
    names(rowseq) <- row.names(x)
    names(colseq) <- colnam
    I <- rowseq[i]
    J <- colseq[j]
    ## convert to lists 
    xlist <- as.list(x)
    hv <- if(is.hyperframe(value)) value else as.hyperframe(as.listof(value))
    vlist <- as.list(hv)
    nrowV <- dim(hv)[1]
    ncolV <- dim(hv)[2]
    if(nrowV != length(I)) {
      if(nrowV == 1) {
        ## replicate
        vlist <- lapply(vlist, rep, times=nrowV)
      } else stop(paste("Replacement value has wrong number of rows:",
                        nrowV, "should be", length(I)),
                  call.=FALSE)
    }
    if(ncolV != length(J)) {
      if(ncolV == 1) {
        ## replicate
        vlist <- rep(vlist, times=ncolV)
      } else stop(paste("Replacement value has wrong number of columns:",
                        ncolV, "should be", length(J)),
                  call.=FALSE)
    }
    ## replace entries
    for(jj in J) 
      xlist[[jj]][I] <- vlist[[jj]][I]
    ## put back together
    y <- do.call("hyperframe", append(xlist,
                                      list(row.names=row.names(x))))
  } 
  return(y)
}


split.hyperframe <- function(x, f, drop=FALSE, ...) {
  y <- data.frame(id=seq_len(nrow(x)))
  z <- split(y, f, drop=drop)
  z <- lapply(z, getElement, name="id")
  out <- lapply(z, function(i, x) x[i,], x=x)
  return(out)
}

"split<-.hyperframe" <- function(x, f, drop=FALSE, ..., value) {
  ix <- split(seq_len(nrow(x)), f, drop = drop, ...)
  n <- length(value)
  j <- 0
  for (i in ix) {
    j <- j%%n + 1
    x[i, ] <- value[[j]]
  }
  x
}
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/idw.R"
#
#  idw.R
#
#  Inverse-distance weighted smoothing
#
#  $Revision: 1.5 $ $Date: 2014/10/24 00:22:30 $

idw <- function(X, power=2, at="pixels", ...) {
  stopifnot(is.ppp(X) && is.marked(X))
  marx <- marks(X)
  if(is.data.frame(marx)) {
    if(ncol(marx) > 1) {
      # multiple columns of marks - process one-by-one
      out <- list()
      for(j in 1:ncol(marx)) 
        out[[j]] <- idw(X %mark% marx[,j], power=power, at=at, ...)
      names(out) <- names(marx)
      switch(at,
             pixels = { out <- as.listof(out) },
             points = { out <- as.data.frame(out) })
      return(out)
    } else 
      marx <- marx[,1]
  }
  if(!is.numeric(marx))
    stop("Marks must be numeric")
  check.1.real(power)
  switch(at,
         pixels = {
           # create grid
           W <- as.mask(as.owin(X), ...)
           dim <- W$dim
           npixels <- prod(dim)
           # call C
           z <- .C("Cidw",
                   x = as.double(X$x),
                   y = as.double(X$y),
                   v = as.double(marx),
                   n = as.integer(npoints(X)),
                   xstart = as.double(W$xcol[1]),
                   xstep  = as.double(W$xstep),
                   nx     = as.integer(dim[2]),
                   ystart = as.double(W$yrow[1]),
                   ystep  = as.double(W$ystep),
                   ny     = as.integer(dim[1]),
                   power  = as.double(power),
                   num    = as.double(numeric(npixels)),
                   den    = as.double(numeric(npixels)),
                   rat    = as.double(numeric(npixels)))
           out <- as.im(matrix(z$rat, dim[1], dim[2]), W=W)
         },
         points={
           npts <- npoints(X)
           z <- .C("idwloo",
                   x = as.double(X$x),
                   y = as.double(X$y),
                   v = as.double(marx),
                   n = as.integer(npts),
                   power  = as.double(power),
                   num    = as.double(numeric(npts)),
                   den    = as.double(numeric(npts)),
                   rat    = as.double(numeric(npts)))
           out <- z$rat
         })
  return(out)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/images.R"
#
#       images.R
#
#      $Revision: 1.123 $     $Date: 2014/12/04 10:03:57 $
#
#      The class "im" of raster images
#
#     im()     object creator
#
#     is.im()   tests class membership
#
#     rasterx.im(), rastery.im()    
#                      raster X and Y coordinates
#
#     nearest.pixel()   
#     lookup.im()
#                      facilities for looking up pixel values
#
################################################################
########   basic support for class "im"
################################################################
#
#   creator 

im <- function(mat, xcol=seq_len(ncol(mat)), yrow=seq_len(nrow(mat)), 
               xrange=NULL, yrange=NULL,
               unitname=NULL) {

  typ <- typeof(mat)
  if(typ == "double")
    typ <- "real"

  miss.xcol <- missing(xcol)
  miss.yrow <- missing(yrow)
  
  # determine dimensions
  if(is.matrix(mat)) {
    nr <- nrow(mat)
    nc <- ncol(mat)
    if(length(xcol) != nc)
      stop("Length of xcol does not match ncol(mat)")
    if(length(yrow) != nr)
      stop("Length of yrow does not match nrow(mat)")
  } else {
    if(miss.xcol || miss.yrow)
      stop(paste(sQuote("mat"),
                 "is not a matrix and I can't guess its dimensions"))
    stopifnot(length(mat) == length(xcol) * length(yrow))
    nc <- length(xcol)
    nr <- length(yrow)
  }

  # deal with factor case
  if(is.factor(mat)) {
    typ <- "factor"
  } else if(!is.null(lev <- levels(mat))) {
    typ <- "factor"
    mat <- factor(mat, levels=lev)
  }

  # Ensure 'mat' is a matrix (without destroying factor information)
  if(!is.matrix(mat))
    dim(mat) <- c(nr, nc)

  # set up coordinates
  if((miss.xcol || length(xcol) <= 1) && !is.null(xrange) ) {
    # use 'xrange' 
    xstep <- diff(xrange)/nc
    xcol <- seq(from=xrange[1] + xstep/2, to=xrange[2] - xstep/2, length.out=nc)
  } else if(length(xcol) > 1) {
    # use 'xcol'
    # ensure spacing is constant
    xcol <- seq(from=min(xcol), to=max(xcol), length.out=length(xcol))
    xstep <- diff(xcol)[1]
    xrange <- range(xcol) + c(-1,1) * xstep/2
  } else stop("Cannot determine pixel width")
  
  if((miss.yrow || length(yrow) <= 1) && !is.null(yrange)) {
    # use 'yrange'
    ystep <- diff(yrange)/nr
    yrow <- seq(from=yrange[1] + ystep/2, to=yrange[2] - ystep/2, length.out=nr)
  } else if(length(yrow) > 1) {
    # use 'yrow'
    # ensure spacing is constant
    yrow <- seq(from=min(yrow), to=max(yrow), length.out=length(yrow))
    ystep <- diff(yrow)[1]
    yrange <- range(yrow) + c(-1,1) * ystep/2
  }  else stop("Cannot determine pixel height")

  unitname <- as.units(unitname)

  # get rid of those annoying 8.67e-19 printouts
  swat <- function(x) {ifelseAX(abs(x) < .Machine$double.eps, 0, x)}
  xrange <- swat(xrange)
  yrange <- swat(yrange)
  
  out <- list(v   = mat,
              dim = c(nr, nc),
              xrange   = xrange,
              yrange   = yrange,
              xstep    = xstep,
              ystep    = ystep,
              xcol    = xcol,
              yrow    = yrow,
              type    = typ,
              units   = unitname)
  class(out) <- "im"
  return(out)
}

is.im <- function(x) {
  inherits(x,"im")
}

levels.im <- function(x) {
  levels(x$v)
}

"levels<-.im" <- function(x, value) {
  if(x$type != "factor") 
    stop("image is not factor-valued")
  levels(x$v) <- value
  x
}

################################################################
########   methods for class "im"
################################################################

shift.im <- function(X, vec=c(0,0), ..., origin=NULL) {
  verifyclass(X, "im")
  if(!is.null(origin)) {
    stopifnot(is.character(origin))
    if(!missing(vec))
      warning("argument vec ignored; overruled by argument origin")
    origin <- pickoption("origin", origin, c(centroid="centroid",
                                             midpoint="midpoint",
                                             bottomleft="bottomleft"))
    W <- as.owin(X)
    locn <- switch(origin,
                   centroid={ unlist(centroid.owin(W)) },
                   midpoint={ c(mean(W$xrange), mean(W$yrange)) },
                   bottomleft={ c(W$xrange[1], W$yrange[1]) })
    return(shift(X, -locn))
  }
  X$xrange <- X$xrange + vec[1]
  X$yrange <- X$yrange + vec[2]
  X$xcol <- X$xcol + vec[1]
  X$yrow <- X$yrow + vec[2]
  attr(X, "lastshift") <- vec
  return(X)
}

"Frame<-.im" <- function(X, value) {
  stopifnot(is.rectangle(value))
  if(!is.subset.owin(value, Frame(X))) {
    ## first expand
    X <- X[value, drop=FALSE]
  }
  X[value, drop=TRUE]
}


"[.im" <- local({

  disjoint <- function(r, s) { (r[2] < s[1]) || (r[1] > s[2])  }
  clip <- function(r, s) { c(max(r[1],s[1]), min(r[2],s[2])) }
  inrange <- function(x, r) { (x >= r[1]) & (x <= r[2]) }

  Extract.im <- function(x, i, j, ...,
                         drop=TRUE, tight=FALSE, raster=NULL,
                         rescue=is.owin(i)) {

    ## detect 'blank' arguments like second argument in x[i, ] 
    ngiven <- length(sys.call())
    nmatched <- length(match.call())
    nblank <- ngiven - nmatched
    itype <- if(missing(i)) "missing" else "given"
    jtype <- if(missing(j)) "missing" else "given"
    if(nblank == 1) {
      if(!missing(i)) jtype <- "blank"
      if(!missing(j)) itype <- "blank"
    } else if(nblank == 2) {
      itype <- jtype <- "blank"
    }

    if(missing(rescue) && itype != "given")
      rescue <- FALSE
    
    if(itype == "missing" && jtype == "missing") {
      ## no indices: return entire image 
      out <- if(is.null(raster)) x else as.im(raster)
      xy <- expand.grid(y=out$yrow,x=out$xcol)
      if(!is.null(raster)) {
        ## resample image on new pixel raster
        values <- lookup.im(x, xy$x, xy$y, naok=TRUE)
        out <- im(values, out$xcol, out$yrow, unitname=unitname(out))
      }
      if(!drop)
        return(out)
      else {
        v <- out$v
        return(v[!is.na(v)])
      }
    }

    if(itype == "given") {
      ## .................................................................
      ## Try spatial index
      ## .................................................................
      if(verifyclass(i, "owin", fatal=FALSE)) {

        if(jtype == "given")
          warning("Argument j ignored")
      
        ## 'i' is a window
        ## if drop = FALSE, just set values outside window to NA
        ## if drop = TRUE, extract values for all pixels inside window
        ##                 as an image (if 'i' is a rectangle)
        ##                 or as a vector (otherwise)

        ## determine pixel raster for output
        if(!is.null(raster)) {
          out <- as.im(raster)
          do.resample <- TRUE
        } else if(is.subset.owin(i, as.owin(x))) {
          out <- x
          do.resample <- FALSE
        } else {
          ## new window does not contain data window: expand it
          bb <- boundingbox(as.rectangle(i), as.rectangle(x))
          rr <- if(is.mask(i)) i else x
          xcol <- prolongseq(rr$xcol, bb$xrange, rr$xstep)
          yrow <- prolongseq(rr$yrow, bb$yrange, rr$ystep)
          out <- list(xcol=xcol, yrow=yrow)
          do.resample <- TRUE
        }
        xy <- expand.grid(y=out$yrow,x=out$xcol)
        if(do.resample) {
          ## resample image on new pixel raster
          values <- lookup.im(x, xy$x, xy$y, naok=TRUE)
          out <- im(values, out$xcol, out$yrow, unitname=unitname(out))
        }
        inside <- inside.owin(xy$x, xy$y, i)
        if(!drop) {
          ## set other pixels to NA and return image
          out$v[!inside] <- NA
          if(!tight)
            return(out)
        } else if(!(rescue && i$type == "rectangle")) {
          ## return pixel values
          values <- out$v[inside]
          return(values)
        }
        ## return image in smaller rectangle
        if(disjoint(i$xrange, x$xrange) || disjoint(i$yrange, x$yrange))
          ## empty intersection
          return(numeric(0))
        xr <- clip(i$xrange, x$xrange)
        yr <- clip(i$yrange, x$yrange)
        colsub <- inrange(out$xcol, xr)
        rowsub <- inrange(out$yrow, yr)
        ncolsub <- sum(colsub)
        nrowsub <- sum(rowsub)
        if(ncolsub == 0 || nrowsub == 0)
          return(numeric(0))
        marg <- list(mat=out$v[rowsub, colsub, drop=FALSE],
                     unitname=unitname(x))
        xarg <-
          if(ncolsub > 1) list(xcol = out$xcol[colsub]) else list(xrange=xr)
        yarg <-
          if(nrowsub > 1) list(yrow = out$yrow[rowsub]) else list(yrange=yr)
        result <- do.call("im", c(marg, xarg, yarg))
        return(result)
      }
      if(verifyclass(i, "im", fatal=FALSE)) {
        if(jtype == "given")
          warning("Argument j ignored")
        ## logical images OK
        if(i$type == "logical") {
          ## convert to window
          w <- as.owin(eval.im(ifelse1NA(i)))
          return(x[w, drop=drop, ..., raster=raster])
        } else stop("Subset argument \'i\' is an image, but not of logical type")
      }

      if(is.ppp(i)) {
        ## 'i' is a point pattern 
        if(jtype == "given")
          warning("Argument j ignored")
        ## Look up the greyscale values for the points of the pattern
        values <- lookup.im(x, i$x, i$y, naok=TRUE)
        if(drop) 
          values <- values[!is.na(values)]
        if(length(values) == 0) 
          ## ensure the zero-length vector is of the right type
          values <- 
            switch(x$type,
                   factor={ factor(, levels=levels(x)) },
                   integer = { integer(0) },
                   logical = { logical(0) },
                   real = { numeric(0) },
                   complex = { complex(0) },
                   character = { character(0) },
                   { values }
                   )
        return(values)
      }
    }
    ## ............... not a spatial index .............................

    ## Try indexing as a matrix

    ## Construct a matrix index call for possible re-use
    M <- as.matrix(x)
    ycall <- switch(itype,
                    given = {
                      switch(jtype,
                             given   = quote(M[i, j, drop=FALSE]),
                             blank   = quote(M[i,  , drop=FALSE]),
                             missing = quote(M[i,    drop=FALSE]))
                    },
                    blank = {
                      switch(jtype,
                             given   = quote(M[ , j, drop=FALSE]),
                             blank   = quote(M[ ,  , drop=FALSE]),
                             missing = quote(M[ ,    drop=FALSE]))
                    },
                    missing = {
                      switch(jtype,
                             given   = quote(M[j=j,  drop=FALSE]),
                             blank   = quote(M[j= ,  drop=FALSE]),
                             missing = quote(M[      drop=FALSE]))
                    })
    ## try it
    y <- try(eval(as.call(ycall)), silent=TRUE)
    if(!inherits(y, "try-error")) {
      ## valid subset index for a matrix
      if(rescue) {
        ## check whether it's a rectangular block, in correct order
        RR <- row(x$v)
        CC <- col(x$v)
        rcall <- ycall
        rcall[[2]] <- quote(RR)
        ccall <- ycall
        ccall[[2]] <- quote(CC)
        rr <- eval(as.call(rcall))
        cc <- eval(as.call(ccall))
        rseq <- sort(unique(as.vector(rr)))
        cseq <- sort(unique(as.vector(cc)))
        if(all(diff(rseq) == 1) && all(diff(cseq) == 1) &&
           (length(rr) == length(rseq) * length(cseq)) &&
           all(rr == RR[rseq, cseq]) && all(cc == CC[rseq,cseq])) {
          ## yes - make image
          dim(y) <- c(length(rseq), length(cseq))
          Y <- x
          Y$v <- y
          Y$dim <- dim(y)
          Y$xcol <- x$xcol[cseq]
          Y$yrow <- x$yrow[rseq]
          Y$xrange <- range(Y$xcol) + c(-1,1) * x$xstep/2
          Y$yrange <- range(Y$yrow) + c(-1,1) * x$ystep/2
          return(Y)
        }
      }
      ## return pixel values (possibly as matrix)
      return(y)
    }

    ## Last chance!
    if(itype == "given" &&
       !is.matrix(i) &&
       !is.null(ip <- as.ppp(i, W=as.owin(x), fatal=FALSE, check=FALSE))) {
      ## 'i' is convertible to a point pattern 
      ## Look up the greyscale values for the points of the pattern
      values <- lookup.im(x, ip$x, ip$y, naok=TRUE)
      if(drop) 
        values <- values[!is.na(values)]
      if(length(values) == 0) 
        ## ensure the zero-length vector is of the right type
        values <- 
          switch(x$type,
                 factor={ factor(, levels=levels(x)) },
                 integer = { integer(0) },
                 logical = { logical(0) },
                 real = { numeric(0) },
                 complex = { complex(0) },
                 character = { character(0) },
                 { values }
                 )
      return(values)
    }
  
    stop("The subset operation is undefined for this type of index")
  }

  Extract.im
})

update.im <- function(object, ...) {
  ## update internal structure of image after manipulation
  X <- object
  mat <- X$v
  typ <- typeof(mat)
  if(typ == "double")
    typ <- "real"
  ## deal with factor case
  if(is.factor(mat)) {
    typ <- "factor"
  } else if(!is.null(lev <- levels(mat))) {
    typ <- "factor"
    X$v <- factor(mat, levels=lev)
  }
  X$type <- typ
  return(X)
}

"[<-.im" <- function(x, i, j, value) {
  # detect 'blank' arguments like second argument of x[i, ] 
  ngiven <- length(sys.call())
  nmatched <- length(match.call())
  nblank <- ngiven - nmatched
  itype <- if(missing(i)) "missing" else "given"
  jtype <- if(missing(j)) "missing" else "given"
  if(nblank == 1) {
    if(!missing(i)) jtype <- "blank"
    if(!missing(j)) itype <- "blank"
  } else if(nblank == 2) {
    itype <- jtype <- "blank"
  }

  X <- x
  W <- as.owin(X)
  if(is.im(value)) {
    value <- value$v
  }
  stopifnot(is.vector(value) || is.matrix(value) || is.factor(value))

  if(itype == "missing" && jtype == "missing") {
    # no index provided
    # set all pixels to 'value'
    v <- X$v
    v[!is.na(v)] <- value
    X$v <- v
    return(update(X))
  }
  if(itype == "given") {
    # ..................... Try a spatial index ....................
    if(verifyclass(i, "owin", fatal=FALSE)) {
      if(jtype == "given") warning("Index j ignored")
      # 'i' is a window
      if(is.empty(i))
        return(X)
      rxy <- rasterxy.mask(W)
      xx <- rxy$x
      yy <- rxy$y
      ok <- inside.owin(xx, yy, i)
      X$v[ok] <- value
      X$type <- ifelse(is.factor(X$v), "factor", typeof(X$v))
      return(update(X))
    }
    if(verifyclass(i, "im", fatal=FALSE) && i$type == "logical") {
      if(jtype == "given") warning("Index j ignored")
      # convert logical vector to window where entries are TRUE
      i <- as.owin(eval.im(ifelse1NA(i)))
      # continue as above
      rxy <- rasterxy.mask(W)
      xx <- rxy$x
      yy <- rxy$y
      ok <- inside.owin(xx, yy, i)
      X$v[ok] <- value
      X$type <- ifelse(is.factor(X$v), "factor", typeof(X$v))
      return(update(X))
    }
    if(is.ppp(i)) {
      # 'i' is a point pattern
      if(jtype == "given") warning("Index j ignored")
      nv <- length(value)
      np <- npoints(i)
      if(nv != np && nv != 1)
        stop("Length of replacement value != number of point locations")
      # test whether all points are inside window FRAME
      ok <- inside.owin(i$x, i$y, as.rectangle(W))
      if(any(!ok)) {
        warning("Some points are outside the outer frame of the image")
        if(nv == np)
          value <- value[ok]
        i <- i[ok]
      }
      if(npoints(i) > 0) {
        # determine row & column positions for each point 
        loc <- nearest.pixel(i$x, i$y, X)
        # set values
        X$v[cbind(loc$row, loc$col)] <- value
      }
      X$type <- ifelse(is.factor(X$v), "factor", typeof(X$v))
      return(update(X))
    }
  }
  # .................. 'i' is not a spatial index ....................
  
  # Construct a matrix replacement call 
  ycall <- switch(itype,
                  given = {
                    switch(jtype,
                           given   = quote(X$v[i, j] <- value),
                           blank   = quote(X$v[i,  ] <- value),
                           missing = quote(X$v[i]    <- value))
                  },
                  blank = {
                    switch(jtype,
                           given   = quote(X$v[ , j] <- value),
                           blank   = quote(X$v[ ,  ] <- value),
                           missing = quote(X$v[ ] <- value))
                  },
                  missing = {
                    switch(jtype,
                           given   = quote(X$v[j=j] <- value),
                           blank   = quote(X$v[j= ] <- value),
                           missing = quote(X$v[] <- value))
                  })
  # try it
  litmus <- try(eval(as.call(ycall)), silent=TRUE)
  if(!inherits(litmus, "try-error")){
    X$type <- ifelse(is.factor(X$v), "factor", typeof(X$v))
    return(update(X))
  }
  #  Last chance!
  if(itype == "given" &&
     !is.matrix(i) &&
     !is.null(ip <- as.ppp(i, W=W, fatal=FALSE, check=TRUE))) {
    # 'i' is convertible to a point pattern
    if(jtype == "given") warning("Index j ignored")
    nv <- length(value)
    np <- npoints(ip)
    if(nv != np && nv != 1)
      stop("Length of replacement value != number of point locations")
    # test whether all points are inside window FRAME
    ok <- inside.owin(ip$x, ip$y, as.rectangle(W))
    if(any(!ok)) {
      warning("Some points are outside the outer frame of the image")
      if(nv == np)
        value <- value[ok]
      ip <- ip[ok]
    }
    if(npoints(ip) > 0) {
      # determine row & column positions for each point 
      loc <- nearest.pixel(ip$x, ip$y, X)
      # set values
      X$v[cbind(loc$row, loc$col)] <- value
    }
    X$type <- ifelse(is.factor(X$v), "factor", typeof(X$v))
    return(update(X))
  }

  stop("The subset operation is undefined for this type of index")
}

################################################################
########   other tools
################################################################

#
# This function is similar to nearest.raster.point except for
# the third argument 'im' and the different idiom for calculating
# row & column - which could be used in nearest.raster.point()

nearest.pixel <- function(x,y,im) {
  verifyclass(im, "im")
  if(length(x) > 0) {
    nr <- im$dim[1]
    nc <- im$dim[2]
    cc <- round(1 + (x - im$xcol[1])/im$xstep)
    rr <- round(1 + (y - im$yrow[1])/im$ystep)
    cc <- pmax.int(1,pmin.int(cc, nc))
    rr <- pmax.int(1,pmin.int(rr, nr))
  } else cc <- rr <- integer(0)
  return(list(row=rr, col=cc))
}

# Explores the 3 x 3 neighbourhood of nearest.pixel
# and finds the nearest pixel that is not NA

nearest.valid.pixel <- function(x,y,im) {
  rc <- nearest.pixel(x,y,im)
  rr <- rc$row
  cc <- rc$col
  # check whether any pixels are outside image domain
  outside <- is.na(im$v)
  miss <- outside[cbind(rr, cc)]
  if(!any(miss))
    return(rc)
  # for offending pixels, explore 3 x 3 neighbourhood
  nr <- im$dim[1]
  nc <- im$dim[2]
  xcol <- im$xcol
  yrow <- im$yrow
  for(i in which(miss)) {
    rows <- rr[i] + c(-1,0,1)
    cols <- cc[i] + c(-1,0,1)
    rows <- unique(pmax.int(1, pmin.int(rows, nr)))
    cols <- unique(pmax.int(1, pmin.int(cols, nc)))
    rcp <- expand.grid(row=rows, col=cols)
    ok <- !outside[as.matrix(rcp)]
    if(any(ok)) {
      # At least one of the neighbours is valid
      # Find the closest one
      rcp <- rcp[ok,]
      dsq <- with(rcp, (x[i] - xcol[col])^2 + (y[i] - yrow[row])^2)
      j <- which.min(dsq)
      rc$row[i] <- rcp$row[j]
      rc$col[i] <- rcp$col[j]
    }
  }
  return(rc)
}
  

# This function is a generalisation of inside.owin()
# to images other than binary-valued images.

lookup.im <- function(Z, x, y, naok=FALSE, strict=TRUE) {
  verifyclass(Z, "im")

  if(Z$type == "factor")
    Z <- repair.old.factor.image(Z)
  
  if(length(x) != length(y))
    stop("x and y must be numeric vectors of equal length")

  # initialise answer to NA 
  if(Z$type != "factor") {
    niets <- NA
    mode(niets) <- mode(Z$v)
  } else {
    niets <- factor(NA, levels=levels(Z))
  }
  value <- rep.int(niets, length(x))
               
  # test whether inside bounding rectangle
  xr <- Z$xrange
  yr <- Z$yrange
  eps <- sqrt(.Machine$double.eps)
  frameok <- (x >= xr[1] - eps) & (x <= xr[2] + eps) & 
             (y >= yr[1] - eps) & (y <= yr[2] + eps)
  
  if(!any(frameok)) {
    # all points OUTSIDE range - no further work needed
    if(!naok)
      warning("Internal error: all values NA")
    return(value)  # all NA
  }

  # consider only those points which are inside the frame
  xf <- x[frameok]
  yf <- y[frameok]
  # map locations to raster (row,col) coordinates
  if(strict)
    loc <- nearest.pixel(xf,yf,Z)
  else
    loc <- nearest.valid.pixel(xf,yf,Z)
  # look up image values
  vf <- Z$v[cbind(loc$row, loc$col)]
  
  # insert into answer
  value[frameok] <- vf

  if(!naok && any(is.na(value)))
    warning("Internal error: NA's generated")

  return(value)
}
  

## low level

rasterx.im <- function(x) {
  verifyclass(x, "im")
  xx <- x$xcol
  matrix(xx[col(x)], ncol=ncol(x), nrow=nrow(x))
}

rastery.im <- function(x) {
  verifyclass(x, "im")
  yy <- x$yrow
  matrix(yy[row(x)], ncol=ncol(x), nrow=nrow(x))
}

rasterxy.im <- function(x, drop=FALSE) {
  verifyclass(x, "im")
  xx <- x$xcol
  yy <- x$yrow
  ans <- cbind(x=as.vector(xx[col(x)]),
               y=as.vector(yy[row(x)]))
  if(drop) {
    ok <- as.vector(!is.na(x$v))
    ans <- ans[ok, , drop=FALSE]
  }
  return(ans)
}

## user interface 

raster.x <- function(w, drop=FALSE) {
  if(is.owin(w)) return(rasterx.mask(w, drop=drop))
  if(!is.im(w)) stop("w should be a window or an image")
  x <- w$xcol[col(w)]
  x <- if(drop) x[!is.na(w$v), drop=TRUE] else array(x, dim=w$dim)
  return(x)
}
  
raster.y <- function(w, drop=FALSE) {
  if(is.owin(w)) return(rastery.mask(w, drop=drop))
  if(!is.im(w)) stop("w should be a window or an image")
  y <- w$yrow[row(w)]
  y <- if(drop) y[!is.na(w$v), drop=TRUE] else array(y, dim=w$dim)
  return(y)
}

raster.xy <- function(w, drop=FALSE) {
  if(is.owin(w)) return(rasterxy.mask(w, drop=drop))
  if(!is.im(w)) stop("w should be a window or an image")
  y <- w$xcol[col(w)]
  y <- w$yrow[row(w)]
  if(drop) {
    ok <- !is.na(w$v)
    x <- x[ok, drop=TRUE]
    y <- y[ok, drop=TRUE]
  }
  return(list(x=as.numeric(x),
              y=as.numeric(y)))
}

##############

# methods for other functions

xtfrm.im <- function(x) { as.numeric(as.matrix.im(x)) }

as.matrix.im <- function(x, ...) {
  return(x$v)
}

as.array.im <- function(x, ...) {
  m <- as.matrix(x)
  a <- do.call(array, resolve.defaults(list(m),
                                       list(...),
                                       list(dim=c(dim(m), 1))))
  return(a)
}

as.data.frame.im <- function(x, ...) {
  verifyclass(x, "im")
  v <- x$v
  xx <- x$xcol[col(v)]
  yy <- x$yrow[row(v)]
  ok <- !is.na(v)
  xx <- as.vector(xx[ok])
  yy <- as.vector(yy[ok])
  # extract pixel values without losing factor info
  vv <- v[ok]
  dim(vv) <- NULL
  # 
  data.frame(x=xx, y=yy, value=vv, ...)
}
  
mean.im <- function(x, ...) {
  verifyclass(x, "im")
  xvalues <- x[drop=TRUE]
  return(mean(xvalues))
}

sum.im <- function(x, ...) {
  verifyclass(x, "im")
  xvalues <- x[drop=TRUE]
  return(sum(xvalues, ...))
}

median.im <- function(x, ...) {
  verifyclass(x, "im")
  xvalues <- x[drop=TRUE]
  return(median(xvalues, ...))
}

range.im <- function(x, ...) {
  verifyclass(x, "im")
  xvalues <- x[drop=TRUE]
  return(range(xvalues, ...))
}

max.im <- function(x, ...) {
  verifyclass(x, "im")
  xvalues <- x[drop=TRUE]
  return(max(xvalues, ...))
}

min.im <- function(x, ...) {
  verifyclass(x, "im")
  xvalues <- x[drop=TRUE]
  return(min(xvalues, ...))
}

## the following ensures that 'sd' works

as.double.im <- function(x, ...) { as.double(x[], ...) }

##

hist.im <- function(x, ..., probability=FALSE) {
  xname <- short.deparse(substitute(x))
  verifyclass(x, "im")
  main <- paste("Histogram of", xname)
  # default plot arguments
  # extract pixel values
  values <- as.matrix(x)
  dim(values) <- NULL
  # barplot or histogram
  if(x$type %in% c("logical", "factor")) {
    # barplot
    tab <- table(values)
    probs <- tab/sum(tab)
    if(probability) {
      heights <- probs
      ylab <- "Probability"
    } else {
      heights <- tab
      ylab <- "Number of pixels"
    }
    mids <- do.call("barplot",
                   resolve.defaults(list(heights),
                                    list(...),
                                    list(xlab=paste("Pixel value"),
                                         ylab=ylab,
                                         main=main)))
    out <- list(counts=tab, probs=probs, heights=heights,
                mids=mids, xname=xname)
    class(out) <- "barplotdata"
  } else {
    # histogram
    values <- values[!is.na(values)]
    plotit <- resolve.defaults(list(...), list(plot=TRUE))$plot
    if(plotit) {
      ylab <- if(probability) "Probability density" else "Number of pixels"
      out <- do.call("hist.default",
                   resolve.defaults(list(values),
                                    list(...),
                                    list(probability=probability),
                                    list(xlab=paste("Pixel value"),
                                         ylab=ylab,
                                         main=main)))
      out$xname <- xname
    } else {
      # plot.default whinges if `probability' given when plot=FALSE
      out <- do.call("hist.default",
                   resolve.defaults(list(values),
                                    list(...)))
      # hack!
      out$xname <- xname
    }
  }
  return(invisible(out))
}

plot.barplotdata <- function(x, ...) {
  do.call("barplot",
          resolve.defaults(list(height=x$heights),
                           list(...),
                           list(main=paste("Histogram of ", x$xname))))
}

cut.im <- function(x, ...) {
  verifyclass(x, "im")
  typ <- x$type
  if(typ %in% c("factor", "logical", "character")) 
    stop(paste0("cut.im is not defined for ", typ, "-valued images"),
         call.=FALSE)
  vcut <- cut(as.numeric(as.matrix(x)), ...)
  return(im(vcut,
            xcol=x$xcol, yrow=x$yrow,
            xrange=x$xrange, yrange=x$yrange,
            unitname=unitname(x)))
}

quantile.im <- function(x, ...) {
  verifyclass(x, "im")
  q <- do.call("quantile",
               resolve.defaults(list(as.numeric(as.matrix(x))),
                                list(...),
                                list(na.rm=TRUE)))
  return(q)
}

integral.im <- function(x, domain=NULL, ...) {
  verifyclass(x, "im")
  typ <- x$type
  if(!any(typ == c("integer", "real", "complex", "logical")))
    stop(paste("Don't know how to integrate an image of type", sQuote(typ)))
  if(!is.null(domain))
    x <- x[domain, drop=FALSE, tight=TRUE]
  a <- with(x, sum(v, na.rm=TRUE) * xstep * ystep)
  return(a)
}

conform.imagelist <- function(X, Zlist) {
  # determine points of X where all images in Zlist are defined
  ok <- rep.int(TRUE, length(X$x))
  for(i in seq_along(Zlist)) {
    Zi <- Zlist[[i]]
    ZiX <- Zi[X, drop=FALSE]
    ok <- ok & !is.na(ZiX)
  }
  return(ok)
}

split.im <- function(x, f, ..., drop=FALSE) {
  stopifnot(is.im(x))
  if(inherits(f, "tess")) 
    subsets <- tiles(f)
  else if(is.im(f)) {
    if(f$type != "factor")
      f <- eval.im(factor(f))
    subsets <- tiles(tess(image=f))
  } else stop("f should be a tessellation or a factor-valued image")
  if(!is.subset.owin(as.owin(x), as.owin(f)))
    stop("f does not cover the window of x")
  n <- length(subsets)
  out <- vector(mode="list", length=n)
  names(out) <- names(subsets)
  for(i in 1:n)
    out[[i]] <- x[subsets[[i]], drop=drop]
  if(drop)
    return(out)
  else 
    return(as.listof(out))
}

by.im <- function(data, INDICES, FUN, ...) {
  stopifnot(is.im(data))
  V <- split(data, INDICES)
  U <- lapply(V, FUN, ...)
  return(as.listof(U))
}

rebound.im <- function(x, rect) {
  stopifnot(is.im(x))
  stopifnot(is.owin(rect))
  rect <- as.rectangle(rect)
  stopifnot(is.subset.owin(as.rectangle(x), rect))
  # compute number of extra rows/columns
  dx <- x$xstep
  nleft  <- max(0, floor((x$xrange[1]-rect$xrange[1])/dx))
  nright <- max(0, floor((rect$xrange[2]-x$xrange[2])/dx))
  dy <- x$ystep
  nbot <- max(0, floor((x$yrange[1]-rect$yrange[1])/dy))
  ntop <- max(0, floor((rect$yrange[2]-x$yrange[2])/dy))
  # determine exact x and y ranges (to preserve original pixel locations)
  xrange.new <- x$xrange + c(-nleft, nright) * dx
  yrange.new <- x$yrange + c(-nbot,  ntop) * dy
  # expand pixel data matrix
  nr <- x$dim[1]
  nc <- x$dim[2]
  nrnew <- nbot  + nr + ntop
  ncnew <- nleft + nc + nright
  naval <- switch(x$type,
                  factor=,
                  integer=NA_integer_,
                  real=NA_real_,
                  character=NA_character_,
                  complex=NA_complex_,
                  NA)
  vnew <- matrix(naval, nrnew, ncnew)
  if(x$type != "factor") {
    vnew[nbot + (1:nr), nleft + (1:nc)] <- x$v
  } else {
    vnew[nbot + (1:nr), nleft + (1:nc)] <- as.integer(x$v)
    vnew <- factor(vnew, labels=levels(x))
    dim(vnew) <- c(nrnew, ncnew)
  }
  # build new image object
  xnew <- im(vnew,
             xrange = xrange.new,
             yrange = yrange.new,
             unitname = unitname(x))
  return(xnew)
}

sort.im <- function(x, ...) {
  verifyclass(x, "im")
  sort(as.vector(as.matrix(x)), ...)
}

dim.im <- function(x) { x$dim }

# colour images
rgbim <- function(R, G, B, maxColorValue=255, autoscale=FALSE) {
  if(autoscale) {
    R <- scaletointerval(R, 0, maxColorValue)
    G <- scaletointerval(G, 0, maxColorValue)
    B <- scaletointerval(B, 0, maxColorValue)
  }
  eval.im(factor(rgbNA(as.vector(R), as.vector(G), as.vector(B),
                     maxColorValue=maxColorValue)))
}

hsvim <- function(H, S, V, autoscale=FALSE) {
  if(autoscale) {
    H <- scaletointerval(H, 0, 1)
    S <- scaletointerval(S, 0, 1)
    V <- scaletointerval(V, 0, 1)
  }
  eval.im(factor(hsvNA(as.vector(H), as.vector(S), as.vector(V))))
}

scaletointerval <- function(x, from=0, to=1, xrange=range(x)) {
  UseMethod("scaletointerval")
}

scaletointerval.default <- function(x, from=0, to=1, xrange=range(x)) {
  x <- as.numeric(x)
  rr <- if(missing(xrange)) range(x, na.rm=TRUE) else as.numeric(xrange)
  b <- as.numeric(to - from)/diff(rr)
  if(is.finite(b)) {
    y <- from + b * (x - rr[1])
  } else {
    y <- (from+to)/2 + 0 * x
  }
  return(y)
}

scaletointerval.im <- function(x, from=0, to=1, xrange=range(x)) {
  v <- scaletointerval(x$v, from, to, xrange=xrange)
  y <- im(v, x$xcol, x$yrow, x$xrange, x$yrange, unitname(x))
  return(y)
}

zapsmall.im <- function(x, digits) {
  if(missing(digits))
    return(eval.im(zapsmall(x)))
  return(eval.im(zapsmall(x, digits=digits)))
}

domain.im <- Window.im <- function(X, ...) { as.owin(X) }

"Window<-.im" <- function(X, ..., value) {
  verifyclass(value, "owin")
  X[value, drop=FALSE]
}

padimage <- function(X, value, n=1) {
  stopifnot(is.im(X))
  if(missing(value) || n <= 0)
    return(X)
  stopifnot(length(value) == 1)
  if(isfac <- (X$type == "factor")) {
    ## handle factors
    levX <- levels(X)
    if(is.factor(value)) {
      stopifnot(identical(levels(X), levels(value)))
    } else {
      value <- factor(value, levels=levX)
    }
    X <- eval.im(as.integer(X))
    value <- as.integer(value)
  }
  value <- rep(value, n)
  sv <- 1:n
  mX <- as.matrix(X)
  dd <- dim(mX)
  mX <- cbind(matrix(rev(value), dd[1], n, byrow=TRUE),
              as.matrix(X),
              matrix(value, dd[1], n, byrow=TRUE))
  dd <- dim(mX)
  mX <- rbind(matrix(rev(value), n, dd[2]),
              mX,
              matrix(value, n, dd[2]))
  xcol <- with(X, c(xcol[1] - rev(sv) * xstep, xcol, xcol[dim[2]] + sv* xstep))
  yrow <- with(X, c(yrow[1] - rev(sv) * ystep, yrow, yrow[dim[1]] + sv* ystep))
  xr <- with(X, xrange + c(-1,1) * n * xstep)
  yr <- with(X, yrange + c(-1,1) * n * ystep)
  Y <- im(mX,
          xcol=xcol, yrow=yrow, xrange=xr, yrange=yr,
          unitname=unitname(X))
  if(isfac)
    Y <- eval.im(factor(Y, levels=seq_along(levX), labels=levX))
  return(Y)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/infline.R"
#
# infline.R
#
# Infinite lines
#
# $Revision: 1.19 $ $Date: 2013/10/06 08:26:59 $
#

infline <- function(a=NULL, b=NULL, h=NULL, v=NULL, p=NULL, theta=NULL) {
  if(is.null(a) != is.null(b))
    stop("invalid specification of a,b")
  if(is.null(p) != is.null(theta))
    stop("invalid specification of p,theta")
  if(!is.null(h)) 
    out <- data.frame(a=h, b=0, h=h, v=NA, p=h, theta=pi/2)
  else if(!is.null(v)) 
    out <- data.frame(a=NA,b=NA,h=NA,v=v,p=v,theta=ifelseAB(v < 0, pi, 0))
  else if(!is.null(a)) {
    # a, b specified
    z <- data.frame(a=a,b=b)
    a <- z$a
    b <- z$b
    theta <- ifelseAX(b == 0, pi/2, atan(-1/b))
    theta <- theta %% pi
    p <- a * sin(theta)
    out <- data.frame(a=a, b=b,
                      h=ifelseXB(b==0, a, NA),
                      v=NA, p=p, theta=theta)
  } else if(!is.null(p)) {
    # p, theta specified
    z <- data.frame(p=p,theta=theta)
    p <- z$p
    theta <- z$theta
    theta <- theta %% (2*pi)
    if(any(reverse <- (theta >= pi))) {
      theta[reverse] <- theta[reverse] - pi
      p[reverse]     <- -p[reverse]
    }
    vert <- (theta == 0)
    horz <- (cos(theta) == 0)
    gene <- !(vert | horz)
    v <- ifelseXB(vert, p, NA)
    h <- ifelseXB(horz, p, NA)
    a <- ifelseXB(gene, p/sin(theta), NA)
    b <- ifelseXB(gene, -cos(theta)/sin(theta), NA)
    out <- data.frame(a=a,b=b,h=h,v=v,p=p,theta=theta)
  } else stop("No data given!")
  class(out) <- c("infline", class(out))
  return(out)
}

is.infline <- function(x) { inherits(x, "infline") }

plot.infline <- function(x, ...) {
  for(i in seq_len(nrow(x))) {
    xi <- x[i, 1:4]
    xi <- lapply(as.list(xi), function(z){if(is.na(z)) NULL else z})
    do.call("abline", append(xi, list(...)))
  }
  return(invisible(NULL))
}

print.infline <- function(x, ...) {
  n <- nrow(x)
  cat(paste(if(n > 1) n else NULL, "infinite ",
            ngettext(n, "line", "lines"), "\n"))
  print(as.data.frame(x), ...)
  return(invisible(NULL))
}

clip.infline <- function(L, win) {
  # clip a set of infinite straight lines to a window
  win <- as.owin(win)
  stopifnot(inherits(L, "infline"))
  # determine circumcircle of win
  xr <- win$xrange
  yr <- win$yrange
  xmid <- mean(xr)
  ymid <- mean(yr)
  width <- diff(xr)
  height <- diff(yr)
  rmax <- sqrt(width^2 + height^2)/2
  boundbox <- owin(xmid + c(-1,1) * rmax, ymid + c(-1,1) * rmax)
  # compute intersection points with circumcircle 
  p <- L$p
  theta <- L$theta
  hit <- (abs(p) < rmax)
  if(!any(hit)) 
    return(psp(numeric(0),numeric(0),numeric(0),numeric(0), window=win))
  p <- p[hit]
  theta <- theta[hit]
  q <- sqrt(rmax^2 - p^2)
  co <- cos(theta)
  si <- sin(theta)
  X <- psp(x0= xmid + p * co + q * si,
           y0= ymid + p * si - q * co,
           x1= xmid + p * co - q * si,
           y1= ymid + p * si + q * co,
           window=boundbox, check=FALSE)
  # clip to window
  X <- X[win]
  return(X)
}
  
chop.tess <- function(X, L) {
  stopifnot(is.infline(L))
  stopifnot(is.tess(X)||is.owin(X))
  X <- as.tess(X)

  if(X$type == "image") {
    Xim <- X$image
    xr <- Xim$xrange
    yr <- Xim$yrange
    # extract matrices of pixel values and x, y coordinates
    Zmat <- as.integer(as.matrix(Xim))
    xmat <- rasterx.im(Xim)
    ymat <- rastery.im(Xim)
    # process lines
    for(i in seq_len(nrow(L))) {
      # line i chops window into two pieces
      if(!is.na(h <- L[i, "h"])) {
        # horizontal line
        if(h > yr[1] && h < yr[2]) 
          Zmat <- 2 * Zmat + (ymat > h)
      } else if(!is.na(v <- L[i, "v"])) {
        # vertical line
        if(v > xr[1] && v < xr[2])
          Zmat <- 2 * Zmat + (xmat < h)
      } else {
        # generic line y = a + bx
        a <- L[i, "a"]
        b <- L[i, "b"]
        Zmat <- 2 * Zmat + (ymat > a + b * xmat)
      }
    }
    # Now just put back as factor image
    Zim <- im(Zmat, xcol=Xim$xcol, yrow=Xim$yrow, unitname=unitname(Xim))
    Z <- tess(image=Zim)
    return(Z)
  }

  #---- polygonal computation --------
  # get bounding box
  B <- as.rectangle(as.owin(X))
  xr <- B$xrange
  yr <- B$yrange

  # get coordinates
  for(i in seq_len(nrow(L))) {
    # line i chops box B into two pieces
    if(!is.na(h <- L[i, "h"])) {
      # horizontal line
      if(h < yr[1] || h > yr[2])
        Z <- NULL
      else {
        lower <- owin(xr, c(yr[1], h))
        upper <- owin(xr, c(h, yr[2]))
        Z <- tess(tiles=list(lower,upper), window=B)
      }
    } else if(!is.na(v <- L[i, "v"])) {
      # vertical line
      if(v < xr[1] || v > xr[2])
        Z <- NULL
      else {
        left <- owin(c(xr[1], v), yr)
        right <- owin(c(v, xr[2]), yr)
        Z <- tess(tiles=list(left,right), window=B)
      }
    } else {
      # generic line
      a <- L[i, "a"]
      b <- L[i, "b"]
      # Intersect with extended left and right sides of B
      yleft <- a + b * xr[1]
      yright <- a + b * xr[2]
      ylo <- min(yleft, yright, yr[1]) - 1
      yhi <- max(yleft, yright, yr[2]) + 1
      lower <- owin(poly=list(x=xr[c(1,1,2,2)],
                              y=c(yleft,ylo,ylo,yright)))
      upper <- owin(poly=list(x=xr[c(1,2,2,1)],
                              y=c(yleft,yright,yhi,yhi)))
      Bplus <- owin(xr, c(ylo, yhi))
      Z <- tess(tiles=list(lower,upper), window=Bplus)
    }
    # intersect this simple tessellation with X
    if(!is.null(Z)) {
      X <- intersect.tess(X, Z)
      tilenames(X) <- paste("Tile", seq_len(length(tiles(X))))
    }
  }
  return(X)
}



#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/inforder.family.R"
#
#
#    inforder.family.R
#
#    $Revision: 1.2 $	$Date: 2010/07/10 10:22:09 $
#
#    Family of `infinite-order' point process models
#
#    inforder.family:      object of class 'isf' 
#	
#
# -------------------------------------------------------------------
#	

inforder.family <-
  list(
       name  = "inforder",
       print = function(self) {
         cat("Family of infinite-order interactions\n")
       },
       plot = NULL,
       # ----------------------------------------------------
       eval  = function(X,U,EqualPairs,pot,pars,correction, ...) {
  #
  # This is the eval function for the `inforder' family.
  # 
  # This internal function is not meant to be called by the user.
  # It is called by mpl.prepare() during execution of ppm().
  #         
  # The eval functions perform all the manipulations that are common to
  # a given class of interactions. 
  #
  # For the `inforder' family of interactions with infinite order,
  # there are no structures common to all interactions.
  # So this function simply invokes the potential 'pot' directly
  # and expects 'pot' to return the values of the sufficient statistic S(u,X).
  #
  # ARGUMENTS:
  #   All 'eval' functions have the following arguments 
  #   which are called in sequence (without formal names)
  #   by mpl.prepare():
  #       
  #   X           data point pattern                      'ppp' object
  #   U           points at which to evaluate potential   list(x,y) suffices
  #   EqualPairs  two-column matrix of indices i, j such that X[i] == U[j]
  #               (or NULL, meaning all comparisons are FALSE)
  #   pot         potential function 
  #   potpars     auxiliary parameters for pairpot        list(......)
  #   correction  edge correction type                    (string)
  #
  # VALUE:
  #    All `eval' functions must return a        
  #    matrix of values of the total potential
  #    induced by the pattern X at each location given in U.
  #    The rows of this matrix correspond to the rows of U (the sample points);
  #    the k columns are the coordinates of the k-dimensional potential.
  #
  ##########################################################################

  # POTENTIAL:
  # In this case the potential function 'pot' should have arguments
  #    pot(X, U, EqualPairs, pars, correction, ...)
  #         
  # It must return a vector with length equal to the number of points in U,
  # or a matrix with as many rows as there are points in U.

         if(!is.ppp(U))
           U <- ppp(U$x, U$y, window=X$window)
         
         POT <- pot(X, U, EqualPairs, pars, correction, ...)

         if(is.matrix(POT)) {
           if(nrow(POT) != U$n)
             stop("Internal error: the potential returned a matrix with the wrong number of rows")
         } else if(is.array(POT) && length(dim(POT)) > 2)
           stop("Internal error: the potential returned an array with more than 2 dimensions")
         else if(is.vector(POT)) {
           if(length(POT) != U$n)
             stop("Internal error: the potential returned a vector with the wrong length")
           POT <- matrix(POT, ncol=1)
         } else
         stop("Internal error: the return value from the potential is not understood")

         return(POT)
       },
######### end of function $eval
       suffstat = NULL
######### end of function $suffstat
)
######### end of list

class(inforder.family) <- "isf"


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/intensity.R"
#
# intensity.R
#
# Code related to intensity and intensity approximations
#
#  $Revision: 1.13 $ $Date: 2014/12/11 08:25:02 $
#

intensity <- function(X, ...) {
  UseMethod("intensity")
}

intensity.ppp <- function(X, ..., weights=NULL) {
  n <- npoints(X)
  a <- area(Window(X))
  if(is.null(weights)) {
    ## unweighted case - for efficiency
    if(is.multitype(X)) {
      mks <- marks(X)
      answer <- as.vector(table(mks))/a
      names(answer) <- levels(mks)
    } else answer <- n/a
    return(answer)
  }
  ## weighted case 
  if(is.numeric(weights)) {
    check.nvector(weights, n)
  } else if(is.expression(weights)) {
    # evaluate expression in data frame of coordinates and marks
    df <- as.data.frame(X)
    pf <- parent.frame()
    eval.weights <- try(eval(weights, envir=df, enclos=pf))
    if(inherits(eval.weights, "try-error"))
      stop("Unable to evaluate expression for weights", call.=FALSE)
    if(!check.nvector(eval.weights, n, fatal=FALSE, warn=TRUE))
      stop("Result of evaluating the expression for weights has wrong format")
    weights <- eval.weights
  } else stop("Unrecognised format for argument 'weights'")
  ##
  if(is.multitype(X)) {
    mks <- marks(X)
    answer <- as.vector(tapply(weights, mks, sum))/a
    answer[is.na(answer)] <- 0
    names(answer) <- levels(mks)
  } else {
    answer <- sum(weights)/a
  }
  return(answer)
}

intensity.splitppp <- function(X, ..., weights=NULL) {
  if(is.null(weights))
    return(sapply(X, intensity.ppp))
  if(is.expression(weights))
    return(sapply(X, intensity.ppp, weights=weights))
  if(is.numeric(weights)) {
    fsplit <- attr(X, "fsplit")
    n <- length(fsplit)
    check.nvector(weights, n)
    result <- mapply(intensity.ppp, X, weights=split(weights, fsplit))
    result <- simplify2array(result, higher=FALSE)
    return(result)
  }
  stop("Unrecognised format for weights")
}

intensity.ppm <- function(X, ...) {
  if(!identical(valid.ppm(X), TRUE)) {
    warning("Model is invalid - projecting it")
    X <- project.ppm(X)
  }
  if(is.poisson(X)) {
    if(is.stationary(X)) {
      # stationary univariate/multivariate Poisson
      sX <- summary(X, quick="no variances")
      lam <- sX$trend$value
      if(sX$multitype && sX$no.trend) {
        ## trend is ~1; lam should be replicated for each mark
        lev <- levels(marks(data.ppm(X)))
        lam <- rep(lam, length(lev))
        names(lam) <- lev
      }
      return(lam)
    }
    # Nonstationary Poisson
    return(predict(X, ...))
  }
  # Gibbs process
  if(is.multitype(X))
    stop("Not yet implemented for multitype Gibbs processes")
  # Compute first order term
  if(is.stationary(X)) {
    ## activity parameter
    sX <- summary(X, quick="no variances")
    beta <- sX$trend$value
  } else {
    ## activity function (or values of it, depending on '...')
    beta <- predict(X, ...)
  }
  ## apply approximation
  lambda <- PoisSaddleApp(beta, fitin(X))
  return(lambda)
}

PoisSaddleApp <- function(beta, fi) {
  ## apply Poisson-Saddlepoint approximation
  ## given first order term and fitted interaction
  stopifnot(inherits(fi, "fii"))
  inte <- as.interact(fi)
  if(!identical(inte$family$name, "pairwise"))
    stop("Intensity approximation is only available for pairwise interaction models")
  # Stationary, pairwise interaction
  Mayer <- inte$Mayer
  if(is.null(Mayer))
    stop(paste("Sorry, not yet implemented for", inte$name))
  # interaction coefficients
  co <- with(fi, coefs[Vnames[!IsOffset]])
  # compute second Mayer cluster integral
  G <- Mayer(co, inte)
  if(is.null(G) || !is.finite(G)) 
    stop("Internal error in computing Mayer cluster integral")
  if(G < 0)
    stop(paste("Unable to apply Poisson-saddlepoint approximation:",
               "Mayer cluster integral is negative"))
  ## solve
  if(is.im(beta)) {
    lambda <- if(G == 0) eval.im(0 * beta) else eval.im(LambertW(G * beta)/G)
  } else {
    lambda <- if(G == 0) numeric(length(beta)) else LambertW(G * beta)/G
    if(length(lambda) == 1) lambda <- unname(lambda)
  }
  return(lambda)
}


# Lambert's W-function

LambertW <- local({

  yexpyminusx <- function(y,x){y*exp(y)-x}

  W <- function(x) {
    result <- rep.int(NA_real_, length(x))
    ok <- is.finite(x) & (x >= 0)
    if(require(gsl, quietly=TRUE)) {
      result[ok] <- gsl::lambert_W0(x[ok])
    } else {
      for(i in which(ok))
        result[i] <- uniroot(yexpyminusx, c(0, x[i]), x=x[i])$root
    }
    return(result)
  }

  W
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/interact.R"
#
#	interact.S
#
#
#	$Revision: 1.23 $	$Date: 2014/12/13 05:40:46 $
#
#	Class 'interact' representing the interpoint interaction
#               of a point process model
#              (e.g. Strauss process with a given threshold r)
#
#       Class 'isf' representing a generic interaction structure
#              (e.g. pairwise interactions)
#
#	These do NOT specify the "trend" part of the model,
#	only the "interaction" component.
#
#               The analogy is:
#
#                       glm()             ppm()
#
#                       model formula     trend formula
#
#                       family            interaction
#
#               That is, the 'systematic' trend part of a point process
#               model is specified by a 'trend' formula argument to ppm(),
#               and the interpoint interaction is specified as an 'interact'
#               object.
#
#       You only need to know about these classes if you want to
#       implement a new point process model.
#
#       THE DISTINCTION:
#       An object of class 'isf' describes an interaction structure
#       e.g. pairwise interaction, triple interaction,
#       pairwise-with-saturation, Dirichlet interaction.
#       Think of it as determining the "order" of interaction
#       but not the specific interaction potential function.
#
#       An object of class 'interact' completely defines the interpoint
#       interactions in a specific point process model, except for the
#       regular parameters of the interaction, which are to be estimated
#       by ppm() or otherwise. An 'interact' object specifies the values
#       of all the 'nuisance' or 'irregular' parameters. An example
#       is the Strauss process with a given, fixed threshold r
#       but with the parameters beta and gamma undetermined.
#
#       DETAILS:
#
#       An object of class 'isf' contains the following:
#
#	     $name               Name of the interaction structure         
#                                        e.g. "pairwise"
#
#	     $print		 How to 'print()' this object
#				 [A function; invoked by the 'print' method
#                                 'print.isf()']
#
#            $eval               A function which evaluates the canonical
#                                sufficient statistic for an interaction
#                                of this general class (e.g. any pairwise
#                                interaction.)
#
#       If lambda(u,X) denotes the conditional intensity at a point u
#       for the point pattern X, then we assume
#                  log lambda(u, X) = theta . S(u,X)
#       where theta is the vector of regular parameters,
#       and we call S(u,X) the sufficient statistic.
#
#       A typical calling sequence for the $eval function is
#
#            (f$eval)(X, U, E, potentials, potargs, correction)
#
#       where X is the data point pattern, U is the list of points u
#       at which the sufficient statistic S(u,X) is to be evaluated,
#       E is a logical matrix equivalent to (X[i] == U[j]),
#       $potentials defines the specific potential function(s) and
#       $potargs contains any nuisance/irregular parameters of these
#       potentials [the $potargs are passed to the $potentials without
#       needing to be understood by $eval.]
#       $correction is the name of the edge correction method.
#
#
#       An object of class 'interact' contains the following:
#
#
#            $name               Name of the specific potential
#                                        e.g. "Strauss"
#
#            $family              Object of class "isf" describing
#                                the interaction structure
#
#            $pot	         The interaction potential function(s)
#                                -- usually a function or list of functions.
#                                (passed as an argument to $family$eval)
#
#            $par                list of any nuisance/irregular parameters
#                                (passed as an argument to $family$eval)
#
#            $parnames           vector of long names/descriptions
#                                of the parameters in 'par'
#
#            $init()             initialisation action
#                                or NULL indicating none required
#
#            $update()           A function to modify $par
#                                [Invoked by 'update.interact()']
#                                or NULL indicating a default action
#
#	     $print		 How to 'print()' this object
#				 [Invoked by 'print' method 'print.interact()']
#                                or NULL indicating a default action
#
# --------------------------------------------------------------------------

print.isf <- function(x, ...) {
  if(is.null(x)) return(invisible(NULL))
  verifyclass(x, "isf")
  if(!is.null(x$print))
    (x$print)(x)
  invisible(NULL)
}

print.interact <- function(x, ..., family, brief=FALSE, banner=TRUE) {
  verifyclass(x, "interact")
  if(missing(family)) family <- waxlyrical('extras')
  #' Print name of model
  if(banner) {
    if(family && !brief && !is.null(xf <- x$family))
      print.isf(xf)
    splat(if(!brief) "Interaction:" else NULL, x$name)
  }
  # Now print the parameters
  if(!is.null(x$print)) {
     (x$print)(x)
  } else {
    # default
    # just print the parameter names and their values
    cat(paste(x$parnames, ":\t", x$par, "\n", sep=""))
  }
  invisible(NULL)
}

is.interact <- function(x) { inherits(x, "interact") }

update.interact <- function(object, ...) {
  verifyclass(object, "interact")
  if(!is.null(object$update))
    (object$update)(object, ...)
  else {
    # Default
    # First update the version
    if(outdated.interact(object))
      object <- reincarnate.interact(object)
    # just match the arguments in "..."
    # with those in object$par and update them
    want <- list(...)
    if(length(want) > 0) {
      m <- match(names(want),names(object$par))
      nbg <- is.na(m)
      if(any(nbg)) {
        which <- paste((names(want))[nbg])
        warning(paste("Arguments not matched: ", which))
      }
      m <- m[!nbg]
      object$par[m] <- want
    }
    # call object's own initialisation routine
    if(!is.null(object$init))
      (object$init)(object)
    object
  }    
}

  
is.poisson.interact <- function(x) {
  verifyclass(x, "interact")
  is.null(x$family)
}


# Test whether interact object was made by an older version of spatstat

outdated.interact <- function(object) {
  ver <- object$version
  older <- is.null(ver) || (package_version(ver) < versionstring.spatstat())
  return(older)
}


# Test whether the functions in the interaction object
# expect the coefficient vector to contain ALL coefficients,
# or only the interaction coefficients.
# This change was introduced in 1.11-0, at the same time
# as interact objects were given version numbers.

newstyle.coeff.handling <- function(object) {
  stopifnot(inherits(object, "interact"))  
  ver <- object$version
  old <- is.null(ver) || (package_version(ver) < "1.11")
  return(!old)
}

# ######
#
# Re-create an interact object in the current version of spatstat
#
# 

reincarnate.interact <- function(object) {
  # re-creates an interact object in the current version of spatstat

  if(!is.null(object$update)) {
    newobject <- (object$update)(object)
    return(newobject)
  }
  
  par <- object$par
#  pot <- object$pot
  name <- object$name
  
  # get creator function
  creator <- object$creator
  if(is.null(creator)) {
    # old version: look up list
    creator <- .Spatstat.Old.InteractionList[[name]]
    if(is.null(creator))
      stop(paste("Don't know how to update", sQuote(name),
                 "to current version of spatstat"))
  }
  if(is.character(creator))
    creator <- get(creator)
  if(!is.function(creator) && !is.expression(creator))
    stop("Internal error: creator is not a function or expression")

  # call creator
  if(is.expression(creator)) 
    newobject <- eval(creator)
  else {
    # creator is a function
  
    # It's assumed that the creator function's arguments are
    # either identical to components of 'par' (the usual case)
    # or to one of the components of the object itself (Ord, Saturated)
    # or to printfun=object$print (Pairwise).
  
    argnames <- names(formals(creator))
    available <- append(par, object)
    available <- append(available, list(printfun=object$print))
    ok <- argnames %in% names(available)
    if(!all(ok))
      stop(paste("Internal error:",
                 ngettext(sum(!ok), "argument", "arguments"),
                 paste(sQuote(argnames[!ok]), collapse=", "),
                 "in creator function were not understood"))
    newobject <- do.call(creator, available[argnames])
  }
  
  if(!inherits(newobject, "interact"))
    stop("Internal error: creator did not return an object of class interact")

  return(newobject)
}


# This list is necessary to deal with older formats of 'interact' objects
# which did not include the creator name

.Spatstat.Old.InteractionList <-
  list("Diggle-Gratton process"    = "DiggleGratton",
       "Geyer saturation process"  = "Geyer",
       "Lennard-Jones potential"   = "LennardJones",
       "Multitype Strauss process" = "MultiStrauss",
       "Multitype Strauss Hardcore process" = "MultiStraussHard",
       "Ord process with threshold potential"="OrdThresh",
       "Piecewise constant pairwise interaction process"="PairPiece",
       "Poisson process"           = "Poisson",
       "Strauss process"           = "Strauss",
       "Strauss - hard core process" = "StraussHard",
       "Soft core process" = "Softcore",
       # weird ones:
       "Ord process with user-defined potential" = expression(Ord(object$pot)),
       "Saturated process with user-defined potential"
          =expression(Saturated(object$pot)),
       "user-defined pairwise interaction process"=
       expression(
           Pairwise(object$pot,
                    par=object$par,
                    parnames=object$parnames,
                    printfun=object$print))
           
     )
       
as.interact <- function(object) {
  UseMethod("as.interact")
}

as.interact.interact <- function(object) {
  verifyclass(object, "interact")
  return(object)
}


#### internal code for streamlining initialisation of interactions
#
#    x should be a partially-completed 'interact' object
#

instantiate.interact <- function(x, par) {
  if(is.character(x$family)) x$family <- get(x$family)
  # set parameter values
  x$par    <- par
  # validate parameters
  x$init(x)
  x$version <- versionstring.spatstat()
  return(x)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/interactions.R"
#
#
# interactions.R
#
# Works out which interaction is in force for a given point pattern
#
#  $Revision: 1.11 $  $Date: 2014/11/10 08:17:39 $
#
#
impliedpresence <- function(tags, formula, df, extranames=character(0)) {
  # Determines, for each row of the data frame df,
  # whether the variable called tags[j] is required in the formula
  stopifnot(is.data.frame(df))
  stopifnot(inherits(formula, "formula"))
  stopifnot(is.character(tags))
  stopifnot(is.character(extranames))
#  allvars <- variablesinformula(formula)
  if(any(tags %in% names(df)))
    stop(paste(sQuote("tags"),
               "conflicts with the name of a column of",
               sQuote("df")))
  if(any(extranames %in% names(df)))
    stop(paste(sQuote("extranames"),
               "conflicts with the name of a column of",
               sQuote("df")))
  # answer is a matrix 
  nvars <- length(tags)
  nrows <- nrow(df)
  answer <- matrix(TRUE, nrows, nvars)
  # expand data frame with zeroes for each tags and extranames
  for(v in unique(c(tags, extranames)))
    df[ , v] <- 0
  # loop
  for(i in seq(nrow(df))) {
    # make a fake data frame for the formula
    # using the data frame entries from row i
    # (includes 0 values for all other variables)
    pseudat <- df[i, , drop=FALSE]
    # use this to construct a fake model matrix
    mof0 <- model.frame(formula, pseudat)
    mom0 <- model.matrix(formula, mof0)
    for(j in seq(nvars)) {
      # Reset the variable called tags[j] to 1
      pseudatj <- pseudat
      pseudatj[ , tags[j]] <- 1
      # Now create the fake model matrix
      mofj <- model.frame(formula, pseudatj)
      momj <- model.matrix(formula, mofj)
      # Compare the two matrices
      answer[i,j] <- any(momj != mom0)
    }
  }
  return(answer)
}

active.interactions <- function(object) {
  stopifnot(inherits(object, "mppm"))
  interaction <- object$Inter$interaction
  iformula <- object$iformula
  nenv <- new.env()
  environment(iformula) <- nenv 

  itags    <- object$Inter$itags
# The following are currently unused  
#  ninter   <- object$Inter$ninter
#  iused    <- object$Inter$iused
#  trivial  <- object$Inter$trivial

  # names of variables
  dat <- object$data
  datanames <- names(dat)
  dfnames <- summary(dat)$dfnames
  nondfnames <- datanames[!(datanames %in% dfnames)]
  
  # extract data-frame values
  dfdata <- as.data.frame(dat[, dfnames, drop=FALSE], warn=FALSE)
  
  # determine which interaction(s) are in force 
  answer <- impliedpresence(itags, iformula, dfdata, nondfnames)
  colnames(answer) <- names(interaction)
  return(answer)
}

impliedcoefficients <- function(object, tag) {
  stopifnot(inherits(object, "mppm"))
  stopifnot(is.character(tag) && length(tag) == 1)
  fitobj      <- object$Fit$FIT
  Vnamelist   <- object$Fit$Vnamelist
# Not currently used:  
#  fitter      <- object$Fit$fitter
#  interaction <- object$Inter$interaction
#  ninteract   <- object$Inter$ninteract
#  trivial     <- object$Inter$trivial
#  iused       <- object$Inter$iused
  itags       <- object$Inter$itags
  if(!(tag %in% itags))
    stop(paste("Argument", dQuote("tag"),
               "is not one of the interaction names"))
  # (0) Set up
  # Identify the columns of the glm data frame
  # that are associated with this interpoint interaction 
  vnames <- Vnamelist[[tag]]
  if(!is.character(vnames))
    stop("Internal error - wrong format for vnames")
  # The answer is a matrix of coefficients,
  # with one row for each point pattern,
  # and one column for each vname
  answer <- matrix(, nrow=object$npat, ncol=length(vnames))
  colnames(answer) <- vnames

  # (1) make a data frame of covariates
  # Names of all columns in glm data frame
  allnames <- names(object$Fit$moadf)
  # Extract the design covariates
  df <- as.data.frame(object$data, warn=FALSE)
  # Names of all covariates other than design covariates
  othernames <- allnames[!(allnames %in% names(df))]
  # Add columns in which all other covariates are set to 0
  for(v in othernames) df[, v] <- 0
  
  # (2) evaluate linear predictor
  opt <- options(warn= -1)
  eta0 <- predict(fitobj, newdata=df, type="link")
  options(opt)
  
  # (3) for each vname in turn,
  # set the value of the vname to 1 and predict again
  for(j in seq(vnames)) {
    df[[vnames[j] ]] <- 1
    opt <- options(warn= -1)
    etaj <- predict(fitobj, newdata=df, type="link")
    options(opt)
    answer[ ,j] <- etaj - eta0
  }
  return(answer)
}



illegal.iformula <- function(ifmla, itags, dfvarnames) {
  # THIS IS TOO STRINGENT!
  # Check validity of the interaction formula.
  #  ifmla is the formula.
  #  itags is the character vector of interaction names.
  # Check whether the occurrences of `itags' in `iformula' are valid:
  # e.g. no functions applied to `itags[i]'.
  # Returns NULL if legal, otherwise a character string 
  stopifnot(inherits(ifmla, "formula"))
  stopifnot(is.character(itags))
  # formula must not have a LHS
  if(length(ifmla) > 2)
    return("iformula must not have a left-hand side")
  # variables in formula must be interaction tags or data frame variables
  varsinf <- variablesinformula(ifmla)
  if(!all(ok <- varsinf %in% c(itags, dfvarnames))) 
    return(paste(
                 ngettext(sum(!ok), "variable", "variables"),
                 paste(dQuote(varsinf[!ok]), collapse=", "),
                 "not allowed in iformula"))
  # if formula uses no interaction tags, it's trivial
  if(!any(itags %in% variablesinformula(ifmla)))
    return(NULL)
  # create terms object
  tt <- attributes(terms(ifmla))
  # extract all variables appearing in the formula
  vars <- as.list(tt$variables)[-1]
#  nvars <- length(vars)
  varstrings <- sapply(vars, function(x) paste(as.expression(x)))
  # Each variable may be a name or an expression
  v.is.name <- sapply(vars, is.name)
  # a term may be an expression like sin(x), poly(x,y,degree=2)
  v.args <- lapply(vars, function(x) all.vars(as.expression(x)))
  v.n.args <- sapply(v.args, length)
  v.has.itag <- sapply(v.args,
                      function(x,y) { any(y %in% x) },
                         y=itags)
  # interaction tags may only appear as names, not in functions
  if(any(nbg <- v.has.itag & !v.is.name))
    return(paste("interaction tags may not appear inside a function:",
                 paste(dQuote(varstrings[nbg]), collapse=", ")))
  # Interaction between two itags is not defined
  # Inspect the higher-order terms
  fax <- tt$factors
  if(prod(dim(fax)) == 0)
    return(NULL)
  # rows are first order terms, columns are terms of order >= 1
  fvars <- rownames(fax)
  fterms <- colnames(fax)
  fv.args <- lapply(fvars, function(x) all.vars(as.expression(parse(text=x))))
  ft.args <- lapply(fterms,
                    function(tum, fax, fv.args) {
                      basis <- (fax[, tum] != 0)
                      unlist(fv.args[basis])
                    },
                    fax=fax, fv.args=fv.args)
  ft.itags <- lapply(ft.args, intersect, y=itags)
  if(any(sapply(ft.itags, length) > 1))
    return("Interaction between itags is not defined")
  return(NULL)
}

    
                       
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/interp.im.R"
#
# interp.im.R
#
#  $Revision: 1.3 $  $Date: 2014/10/24 00:22:30 $
#

interp.im <- local({

  lukimyu <- function(ccc, rrr, mat, defaults) {
    dimm <- dim(mat)
    within <- (rrr >= 1 & rrr <= dimm[1] & ccc >= 1 & ccc <= dimm[2])
    result <- defaults
    result[within] <- mat[cbind(rrr[within], ccc[within])]
    result
  }

  interp.im <- function(Z, x, y=NULL) {
    stopifnot(is.im(Z))
    if(!is.null(levels(Z)))
      stop("Interpolation is undefined for factor-valued images")
    xy <- xy.coords(x, y)
    x <- xy$x
    y <- xy$y
    ok <- inside.owin(x,y, as.owin(Z))
    ## get default lookup values (for boundary cases)
    fallback <- Z[ppp(x[ok], y[ok], window=as.rectangle(Z), check=FALSE)]
    ## Transform to grid coordinates
    ## so that pixel centres are at integer points,
    ## bottom left of image is (0,0)
    xx <- (x[ok] - Z$xcol[1])/Z$xstep
    yy <- (y[ok] - Z$yrow[1])/Z$ystep
    ## find grid point to left and below
    ## (may transgress boundary)
    xlower <- floor(xx)
    ylower <- floor(yy)
    cc <- as.integer(xlower) + 1
    rr <- as.integer(ylower) + 1
    ## determine whether (x,y) is above or below antidiagonal in square
    dx <- xx - xlower
    dy <- yy - ylower
    below <- (dx + dy <= 1)
    ## if below, interpolate Z(x,y) = (1-x-y)Z(0,0) + xZ(1,0) + yZ(0,1)
    ## if above, interpolate Z(x,y) = (x+y-1)Z(1,1) + (1-x)Z(0,1) + (1-y)Z(1,0)
    V <- Z$v
    values <- ifelse(below,
                     ( (1-dx-dy)*lukimyu(cc,rr,V,fallback)
                      + dx*lukimyu(cc+1,rr,V,fallback)
                      + dy*lukimyu(cc,rr+1,V,fallback)
                      ),
                     ( (dx+dy-1)*lukimyu(cc+1,rr+1,V,fallback)
                      + (1-dx)*lukimyu(cc,rr+1,V,fallback)
                      + (1-dy)*lukimyu(cc+1,rr,V,fallback)
                      ))
    result <- numeric(length(x))
    result[ok] <- values
    result[!ok] <- NA
    return(result)
  }

  interp.im
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/iplot.R"
#
# interactive plot for ppp objects using rpanel
#
#   $Revision: 1.18 $   $Date: 2014/08/27 09:46:17 $
#
#

# Effect:
# when the user types
#                 iplot(x)
# a pop-up panel displays a standard plot of x and
# buttons allowing control of the plot parameters.

# Coding:
# The panel 'p' contains the following internal variables
#      x          Original point pattern
#      w          Window of point pattern
#      xname      Name of x (for main title)
#      mtype      Type of marks of x
#      bb         frame of x 
#      bbmid      midpoint of frame
# The following variables in 'p' are controlled by panel buttons etc
#      split      Logical: whether to split multitype pattern
#      pointmap   Plot character, or "marks" indicating that marks are used
#      zoomfactor Zoom factor 
#      zoomcentre Centre point for zoom
#      charsize   Character expansion factor cex
#      markscale  Mark scale factor markscale
#      

iplot <- function(x, ...) {
  UseMethod("iplot")
}

iplot.ppp <- local({

iplot.ppp <- function(x, ..., xname) {
  if(missing(xname))
    xname <- short.deparse(substitute(x))
  verifyclass(x, "ppp")
  require(rpanel)
  
  if(markformat(x) %in% c("hyperframe", "listof")) 
    marks(x) <- as.data.frame(as.hyperframe(marks(x)))
  if(markformat(x) == "dataframe" && ncol(marks(x)) > 1) {
    warning("Using only the first column of marks")
    marks(x) <- marks(x)[,1]
  }
  mtype <- if(is.multitype(x)) "multitype" else if(is.marked(x)) "marked" else "unmarked"

  bb <- as.rectangle(as.owin(x))
  bbmid <- unlist(centroid.owin(bb))
  ##
  p <- rpanel::rp.control(paste("iplot(", xname, ")", sep=""), 
                          x=x,
                          w=as.owin(x),
                          xname=xname,
                          mtype=mtype,
                          bb=bb,
                          bbmid=bbmid,
                          split=FALSE,
                          pointmap=if(is.marked(x)) "marks" else "o",
                          zoomfactor=1,
                          zoomcentre=bbmid,
                          size=c(700, 400))

# Split panel into three
# Left: plot controls
# Middle: data
# Right: navigation/zoom
  rpanel::rp.grid(p, "gcontrols", pos=list(row=0,column=0))
  rpanel::rp.grid(p, "gdisplay",  pos=list(row=0,column=1))
  rpanel::rp.grid(p, "gnavigate", pos=list(row=0,column=2))

#----- Data display ------------

  # This line is to placate the package checker
  mytkr <- NULL

  # Create data display panel 
  rpanel::rp.tkrplot(p, mytkr, plotfun=do.iplot.ppp, action=click.iplot.ppp,
                     pos=list(row=0,column=0,grid="gdisplay"))

  
#----- Plot controls ------------
  nextrow <- 0
  pozzie <- function(n=nextrow, ...)
    append(list(row=n,column=0,grid="gcontrols"), list(...))
  
# main title
  rpanel::rp.textentry(p, xname, action=redraw.iplot.ppp, title="Plot title",
                       pos=pozzie(0))
  nextrow <- 1

# split ?
  if(mtype == "multitype") {
    rpanel::rp.checkbox(p, split, initval=FALSE, 
                        title="Split according to marks",
                        action=redraw.iplot.ppp,
                        pos=pozzie(1))
    nextrow <- 2
  }

# plot character or mark style
  ptvalues <- c("o", "bullet", "plus")
  ptlabels <- c("open circles", "filled circles", "crosshairs")
  if(is.marked(x)) {
    ptvalues <- c("marks", ptvalues)
    ptlabels <- if(mtype == "multitype")
      c("Symbols depending on mark", ptlabels)
    else c("Circles proportional to mark", ptlabels)
  }
  pointmap <- ptvalues[1]
  rpanel::rp.radiogroup(p, pointmap, vals=ptvalues, labels=ptlabels,
                        title="how to plot points", action=redraw.iplot.ppp,
                        pos=pozzie(nextrow))
  nextrow <- nextrow+1

# plot character size
  charsize <- 1
  rpanel::rp.slider(p, charsize, 0, 5, action=redraw.iplot.ppp, 
                    title="symbol expansion factor (cex)",
                    initval=1, showvalue=TRUE,
                    pos=pozzie(nextrow, sticky=""))
  nextrow <- nextrow+1
  
# mark scale
  if(mtype == "marked") {
    marx <- x$marks
    marx <- marx[is.finite(marx)]
    scal <- mark.scale.default(marx, x$window)
    markscale <- scal
    rpanel::rp.slider(p, markscale,
                      from=scal/10, to = 10*scal,
                      action=redraw.iplot.ppp,
                      initval=scal,
                      title="mark scale factor (markscale)",
                      showvalue=TRUE,
                      pos=pozzie(nextrow))
    nextrow <- nextrow+1
  }

# button to print a summary at console
  rpanel::rp.button(p, title="Print summary information",
                    pos=pozzie(nextrow),
                    action=function(panel) { print(summary(panel$x)); panel} )
#  
#----- Navigation controls ------------
  nextrow <- 0
  navpos <- function(n=nextrow,cc=0, ...)
    append(list(row=n,column=cc,grid="gnavigate"), list(...))

  rpanel::rp.button(p, title="Up", pos=navpos(nextrow,1,sticky=""),
                    action=function(panel) {
                        zo <- panel$zoomfactor
                        ce <- panel$zoomcentre
                        bb <- panel$bb
                        height <- sidelengths(bb)[2]
                        stepsize <- (height/4)/zo
                        panel$zoomcentre <- ce + c(0, stepsize)
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  nextrow <- nextrow + 1
  rpanel::rp.button(p, title="Left", pos=navpos(nextrow,0,sticky="w"),
                    action=function(panel) {
                        zo <- panel$zoomfactor
                        ce <- panel$zoomcentre
                        bb <- panel$bb
                        width <- sidelengths(bb)[1]
                        stepsize <- (width/4)/zo
                        panel$zoomcentre <- ce - c(stepsize, 0)
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  rpanel::rp.button(p, title="Right", pos=navpos(nextrow,2,sticky="e"),
                    action=function(panel) {
                        zo <- panel$zoomfactor
                        ce <- panel$zoomcentre
                        bb <- panel$bb
                        width <- sidelengths(bb)[1]
                        stepsize <- (width/4)/zo
                        panel$zoomcentre <- ce + c(stepsize, 0)
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  nextrow <- nextrow + 1
  rpanel::rp.button(p, title="Down", pos=navpos(nextrow,1,sticky=""),
                    action=function(panel) {
                        zo <- panel$zoomfactor
                        ce <- panel$zoomcentre
                        bb <- panel$bb
                        height <- sidelengths(bb)[2]
                        stepsize <- (height/4)/zo
                        panel$zoomcentre <- ce - c(0, stepsize)
                        CommitAndRedraw(panel)
                        return(panel)
            })
  nextrow <- nextrow + 1

  rpanel::rp.button(p, title="Zoom In", pos=navpos(nextrow,1,sticky=""),
                    action=function(panel) {
                        panel$zoomfactor <- panel$zoomfactor * 2
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  nextrow <- nextrow + 1
  rpanel::rp.button(p, title="Zoom Out", pos=navpos(nextrow,1,sticky=""),
                    action=function(panel) {
                        panel$zoomfactor <- panel$zoomfactor / 2
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  nextrow <- nextrow + 1
  rpanel::rp.button(p, title="Reset", pos=navpos(nextrow,1,sticky=""),
                    action=function(panel) {
                        panel$zoomfactor <- 1
                        panel$zoomcentre <- panel$bbmid
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  nextrow <- nextrow + 1
  rpanel::rp.button(p, title="Redraw", pos=navpos(nextrow,1,sticky=""),
                    action=redraw.iplot.ppp)
  nextrow <- nextrow+1
# quit button 
  rpanel::rp.button(p, title="Quit", quitbutton=TRUE,
                    pos=navpos(nextrow, 1, sticky=""),
                    action= function(panel) { panel })

  invisible(NULL)
}


  # Function to redraw the whole shebang
  redraw.iplot.ppp <- function(panel) {
    rpanel::rp.tkrreplot(panel, mytkr)
    panel
  }


# Function executed when data display is clicked

  click.iplot.ppp <- function(panel, x, y) {
    if(panel$split) {
      cat("Mouse interaction is not supported when the point pattern is split\n")
    } else {
      panel$zoomcentre <- panel$zoomcentre +
        (c(x,y) - panel$bbmid)/panel$zoomfactor
      CommitAndRedraw(panel)
    }
    return(panel)
  }

# function that updates the plot when the control panel is operated

do.iplot.ppp <- function(panel) { 
  use.marks <- TRUE
  pch <- 16
  switch(panel$pointmap,
         marks={
           use.marks <- TRUE
           pch <- NULL
         }, 
         o = {
           use.marks <- FALSE
           pch <- 1
         }, 
         bullet = {
           use.marks <- FALSE
           pch <- 16
         },
         plus = {
           use.marks <- FALSE
           pch <- 3
         })
  # scale and clip the pattern
  x <- panel$x
  w     <- panel$w
  z     <- panel$zoomfactor
  if(is.null(z)) z <- 1
  ce    <- panel$zoomcentre
  bb    <- panel$bb
  bbmid <- panel$bbmid
  scalex <- shift(scalardilate(shift(x, -ce), z), bbmid)
  scalew <- shift(scalardilate(shift(w, -ce), z), bbmid)
  scalex <- scalex[, bb]
  scalew <- intersect.owin(scalew, bb, fatal=FALSE)
  # determine what is plotted under the clipped pattern
  blankargs <- list(type="n")
  dashargs  <- list(lty=3, border="red")
  panel.begin <- 
    if(is.null(scalew)) {
      # empty intersection; just create the plot space
      layered(bb,          plotargs=list(blankargs))
    } else if(identical(bb, scalew)) {
      if(z == 1) {
        # original state
        # window is rectangular 
        # plot the data window as a solid black rectangle
        layered(bb, scalew,  plotargs=list(blankargs, list(lwd=2)))
      } else {
        # zoom view is entirely inside window
        # plot the clipping region as a red dashed rectangle
        layered(bb, plotargs=list(dashargs))
      }
    } else {
      # field of view is not a subset of window
      # plot the clipping region as a red dashed rectangle
      # Then add the data window
      layered(bb, scalew, plotargs=list(dashargs, list(invert=TRUE)))
    }

  # draw it
#  opa <- par(ask=FALSE)
  if(panel$mtype == "multitype" && panel$split) {
    scalex <- split(scalex, un=(panel$pointmap != "marks"))
    plot(scalex, main=panel$xname, 
         use.marks=use.marks, pch=pch, cex=panel$charsize,
         panel.begin=panel.begin)
  } else {
    # draw scaled & clipped window
    plot(panel.begin, main=panel$xname)
    # add points
    if(panel$mtype == "marked" && panel$pointmap == "marks") {
      plot(scalex, add=TRUE, use.marks=use.marks, markscale=panel$markscale)
    } else {
      plot(scalex, add=TRUE, use.marks=use.marks, pch=pch, cex=panel$charsize)
    }
  }
#  par(opa)
  panel
}

CommitAndRedraw <- function(panel) {
  # hack to ensure that panel is immediately updated in rpanel
  require(rpanel)
  ## This is really a triple-colon!
  rpanel:::rp.control.put(panel$panelname, panel)
  # now redraw it
  redraw.iplot.ppp(panel)
}

iplot.ppp
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/iplotlayered.R"
#
# interactive plot 
#
#   $Revision: 1.7 $   $Date: 2014/10/24 00:22:30 $
#
#

iplot.default <- function(x, ..., xname) {
 if(missing(xname))
    xname <- short.deparse(substitute(x))
 x <- as.layered(x)
 iplot(x, ..., xname=xname)
}

iplot.layered <- local({

  CommitAndRedraw <- function(panel) {
    ## hack to ensure that panel is immediately updated in rpanel
    require(rpanel)
    ## This is really a triple-colon!
    rpanel:::rp.control.put(panel$panelname, panel)
    ## now redraw it
    redraw.iplot.layered(panel)
  }
  
  faster.layers <- function(x) {
    if(any(islinnet <- unlist(lapply(x, inherits, what="linnet")))) {
      # convert linnet layers to psp, for efficiency
      x[islinnet] <- lapply(x[islinnet], as.psp)
    }
    repeat{
      islpp <- unlist(lapply(x, inherits, what="lpp"))
      if(!any(islpp))
        break
      # convert an lpp layer to two layers: psp and ppp, for efficiency
      ii <- min(which(islpp))
      pl <- layerplotargs(x)
      n <- length(x)
      xpre <- if(ii == 1) NULL else x[1:ii]
      xpost <- if(ii == n) NULL else x[(ii+1):n]
      ppre <- if(ii == 1) NULL else pl[1:ii]
      ppost <- if(ii == n) NULL else pl[(ii+1):n]
      a <- as.psp(as.linnet(x[[ii]]))
      b <- as.ppp(x[[ii]])
      x <- layered(LayerList=c(xpre, list(a, b), xpost),
                   plotargs=unname(c(ppre, pl[ii], pl[ii], ppost)))
    }
    return(x)
  }
  
iplot.layered <- function(x, ..., xname) {
  if(missing(xname))
    xname <- short.deparse(substitute(x))
  verifyclass(x, "layered")
  require(rpanel)

  x <- faster.layers(x)
  x <- freeze.colourmaps(x)
  bb <- as.rectangle(as.owin(x))
  bbmid <- unlist(centroid.owin(bb))
  
  lnames <- names(x)
  if(sum(nzchar(lnames)) != length(x))
    lnames <- paste("Layer", seq_len(length(x)))
  ##
  p <- rpanel::rp.control(paste("iplot(", xname, ")", sep=""), 
                          x=x,
                          w=as.owin(x),
                          xname=xname,
                          layernames=lnames,
                          bb=bb,
                          bbmid=bbmid,
                          zoomfactor=1,
                          zoomcentre=bbmid,
                          which = rep.int(TRUE, length(x)),
                          size=c(700, 400))

# Split panel into three
# Left: plot controls
# Middle: data
# Right: navigation/zoom
  rpanel::rp.grid(p, "gcontrols", pos=list(row=0,column=0))
  rpanel::rp.grid(p, "gdisplay",  pos=list(row=0,column=1))
  rpanel::rp.grid(p, "gnavigate", pos=list(row=0,column=2))

#----- Data display ------------

  # This line is to placate the package checker
  mytkr <- NULL

  # Create data display panel 
  rpanel::rp.tkrplot(p, mytkr, plotfun=do.iplot.layered,
                     action=click.iplot.layered,
                     pos=list(row=0,column=0,grid="gdisplay"))

  
#----- Plot controls ------------
  nextrow <- 0
  pozzie <- function(n=nextrow, ...)
    append(list(row=n,column=0,grid="gcontrols"), list(...))
  
# main title
  rpanel::rp.textentry(p, xname, action=redraw.iplot.layered,
                       title="Plot title",
                       pos=pozzie(0))
  nextrow <- 1

# select some layers
  nx <- length(x)
  which <- rep.int(TRUE, nx)
  if(nx > 1) {
    rpanel::rp.checkbox(p, which, labels=lnames,
                        action=redraw.iplot.layered,
                        title="Select layers to plot",
                        pos=pozzie(nextrow), sticky="")
    nextrow <- nextrow + 1
  }
  
# button to print a summary at console
  rpanel::rp.button(p, title="Print summary information",
                    pos=pozzie(nextrow),
                    action=function(panel) {
                        lapply(panel$x, function(z) print(summary(z)))
                        return(panel)
                    })
#  
#----- Navigation controls ------------
  nextrow <- 0
  navpos <- function(n=nextrow,cc=0, ...)
    append(list(row=n,column=cc,grid="gnavigate"), list(...))

  rpanel::rp.button(p, title="Up", pos=navpos(nextrow,1,sticky=""),
                    action=function(panel) {
                        zo <- panel$zoomfactor
                        ce <- panel$zoomcentre
                        bb <- panel$bb
                        height <- sidelengths(bb)[2]
                        stepsize <- (height/4)/zo
                        panel$zoomcentre <- ce + c(0, stepsize)
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  nextrow <- nextrow + 1
  rpanel::rp.button(p, title="Left", pos=navpos(nextrow,0,sticky="w"),
                    action=function(panel) {
                        zo <- panel$zoomfactor
                        ce <- panel$zoomcentre
                        bb <- panel$bb
                        width <- sidelengths(bb)[1]
                        stepsize <- (width/4)/zo
                        panel$zoomcentre <- ce - c(stepsize, 0)
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  rpanel::rp.button(p, title="Right", pos=navpos(nextrow,2,sticky="e"),
                    action=function(panel) {
                        zo <- panel$zoomfactor
                        ce <- panel$zoomcentre
                        bb <- panel$bb
                        width <- sidelengths(bb)[1]
                        stepsize <- (width/4)/zo
                        panel$zoomcentre <- ce + c(stepsize, 0)
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  nextrow <- nextrow + 1
  rpanel::rp.button(p, title="Down", pos=navpos(nextrow,1,sticky=""),
                    action=function(panel) {
                        zo <- panel$zoomfactor
                        ce <- panel$zoomcentre
                        bb <- panel$bb
                        height <- sidelengths(bb)[2]
                        stepsize <- (height/4)/zo
                        panel$zoomcentre <- ce - c(0, stepsize)
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  nextrow <- nextrow + 1

  rpanel::rp.button(p, title="Zoom In", pos=navpos(nextrow,1,sticky=""),
                    action=function(panel) {
                        panel$zoomfactor <- panel$zoomfactor * 2
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  nextrow <- nextrow + 1
  rpanel::rp.button(p, title="Zoom Out", pos=navpos(nextrow,1,sticky=""),
                    action=function(panel) {
                        panel$zoomfactor <- panel$zoomfactor / 2
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  nextrow <- nextrow + 1
  rpanel::rp.button(p, title="Reset", pos=navpos(nextrow,1,sticky=""),
                    action=function(panel) {
                        panel$zoomfactor <- 1
                        panel$zoomcentre <- panel$bbmid
                        CommitAndRedraw(panel)
                        return(panel)
                    })
  nextrow <- nextrow + 1
  rpanel::rp.button(p, title="Redraw", pos=navpos(nextrow,1,sticky=""),
                    action=redraw.iplot.layered)
  nextrow <- nextrow+1
# quit button 
  rpanel::rp.button(p, title="Quit", quitbutton=TRUE,
            pos=navpos(nextrow, 1, sticky=""),
            action= function(panel) { panel })

  invisible(NULL)
}


  # Function to redraw the whole shebang
  redraw.iplot.layered <- function(panel) {
    rpanel::rp.tkrreplot(panel, mytkr)
    panel
  }


# Function executed when data display is clicked

  click.iplot.layered <- function(panel, x, y) {
    panel$zoomcentre <- panel$zoomcentre +
      (c(x,y) - panel$bbmid)/panel$zoomfactor
    CommitAndRedraw(panel)
    return(panel)
  }

# function that updates the plot when the control panel is operated

do.iplot.layered <- function(panel) { 
  # scale and clip the pattern
  x <- panel$x[panel$which]
  w     <- panel$w
  z     <- panel$zoomfactor
  if(is.null(z)) z <- 1
  ce    <- panel$zoomcentre
  bb    <- panel$bb
  bbmid <- panel$bbmid
  scalex <- shift(scalardilate(shift(x, -ce), z), bbmid)
  scalew <- shift(scalardilate(shift(w, -ce), z), bbmid)
  scalex <- scalex[, bb]
  scalew <- intersect.owin(scalew, bb, fatal=FALSE)
  # determine what is plotted under the clipped pattern
  blankargs <- list(type="n")
  dashargs  <- list(lty=3, border="red")
  panel.begin <- 
    if(is.null(scalew)) {
      # empty intersection; just create the plot space
      layered(bb,          plotargs=list(blankargs))
    } else if(identical(bb, scalew)) {
      if(z == 1) {
        # original state
        # window is rectangular 
        # plot the data window as a solid black rectangle
        layered(bb, scalew,  plotargs=list(blankargs, list(lwd=2)))
      } else {
        # zoom view is entirely inside window
        # plot the clipping region as a red dashed rectangle
        layered(bb, plotargs=list(dashargs))
      }
    } else {
      # field of view is not a subset of window
      # plot the clipping region as a red dashed rectangle
      # Then add the data window
      layered(bb, scalew, plotargs=list(dashargs, list(invert=TRUE)))
    }
  
  # draw it
  opa <- par(ask=FALSE)
  plot(panel.begin, main=panel$xname)
  plot(scalex, add=TRUE)
  par(opa)
  panel
}

freeze.colourmaps <- function(x) {
  # tweak a layered object to ensure that
  # the colours of image layers don't change with zoom/pan
  isim <- unlist(lapply(x, is.im))
  if(any(isim)) {
    # ensure there are plotargs
    pl <- attr(x, "plotargs")
    if(is.null(pl))
      pl <- rep.int(list(list()), length(x))
    # make sure the plotargs include 'zlim'
    for(i in which(isim)) {
      x.i <- x[[i]]
      if(x.i$type %in% c("integer", "real")) 
        pl[[i]] <- resolve.defaults(pl[[i]], list(zlim=range(x.i)))
    }
    # put back
    attr(x, "plotargs") <- pl
  }
  return(x) 
}

iplot.layered
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/ippm.R"
#
# ippm.R
#
#   $Revision: 2.17 $   $Date: 2014/12/22 07:22:51 $
#
# Fisher scoring algorithm for irregular parameters in ppm trend
#

ippm <- local({

  chucknames <- c("iScore", "start", "nlm.args", "silent", "warn.unused")
  
  ippm <- function(Q, ...,
                   iScore=NULL, 
                   start=list(),
                   covfunargs=start,
                   nlm.args=list(),
                   silent=FALSE,
                   warn.unused=TRUE) {
    ## remember call
    cl <- match.call()
    callframe <- parent.frame()
    callstring <- short.deparse(sys.call())
    ##
    ppmcall <- cl[!(names(cl) %in% chucknames)]
    ppmcall[[1]] <- as.name('ppm')
    ## validate
    if(!is.list(start))
      stop("start should be a list of initial values for irregular parameters")
    if(length(start) == 0) {
      ppmcall <- ppmcall[names(ppmcall) != "covfunargs"]
      return(eval(ppmcall, callframe))
    }
    if(!is.null(iScore)) {
      if(!is.list(iScore) || length(iScore) != length(start))
        stop("iScore should be a list of the same length as start")
      stopifnot(identical(names(iScore), names(start)))
      if(!all(unlist(lapply(iScore, is.function))))
        stop("iScore should be a list of functions")
    }
    ##
    smap <- match(names(start), names(covfunargs))
    if(any(is.na(smap)))
      stop("variables in start should be a subset of variables in covfunargs")
    covfunargs[smap] <- start
    ## fit the initial model and extract information
    ppmcall$covfunargs <- covfunargs
    fit0 <- eval(ppmcall, callframe)
#    lpl0 <- fit0$maxlogpl
#    p <- length(coef(fit0))
    ## examine covariates and trend
    covariates <- fit0$covariates
    isfun <- unlist(lapply(covariates, is.function))
    covfuns <- covariates[isfun]
    ## determine which covariates depend on which irregular parameters
    pnames <- names(start)
    hasarg <- function(f,a) { a %in% names(formals(f)) }
    depmat <- matrix(FALSE, nrow=length(covfuns), ncol=length(pnames))
    rownames(depmat) <- names(covfuns)
    colnames(depmat) <- pnames
    for(j in 1:length(pnames))
      depmat[,j] <- unlist(lapply(covfuns, hasarg, pnames[j]))
    ## find covariates that depend on ANY irregular parameter 
    depvar <- rownames(depmat)[apply(depmat, 1, any)]
    ## check that these covariates appear only in offset terms
    covnames.fitted <- model.covariates(fit0, fitted=TRUE,  offset=FALSE)
    if(any(uhoh <- depvar %in% covnames.fitted))
      stop(paste(ngettext(sum(uhoh), "The covariate", "The covariates"),
                 commasep(sQuote(depvar[uhoh])),
                 "should appear only in offset terms"))
    ## check that every irregular parameter to be updated appears somewhere 
    cov.names.offset <- model.covariates(fit0, fitted=FALSE,  offset=TRUE)
    covfun.names.offset <- intersect(cov.names.offset, names(covfuns))
    usearg <- apply(depmat[covfun.names.offset, , drop=FALSE], 2, any)
    if(!all(usearg)) {
      if(warn.unused) {
        nbad <- sum(!usearg)
        warning(paste("Cannot maximise over the irregular",
                      ngettext(nbad, "parameter", "parameters"),
                      commasep(sQuote(names(usearg)[!usearg])),
                      ngettext(nbad, "because it is", "because they are"),
                      "not used in any term of the model"))
      }
      ## restrict 
      start <- start[usearg]
      if(!is.null(iScore)) iScore <- iScore[usearg]
      pnames <- names(start)
    }
    if(length(start) == 0) {
      ppmcall <- ppmcall[names(ppmcall) != "covfunargs"]
      return(eval(ppmcall, callframe))
    }
    ## parameters for objective function
    fdata <- list(fit0=fit0,
                  nreg=length(coef(fit0)),
                  covfunargs=covfunargs,
                  smap=smap,
                  pnames=pnames,
                  iScore=iScore)
    ## minimise objective
    startvec <- unlist(start)
    typsize <- abs(startvec)
    typsize <- pmax(typsize, min(typsize[typsize > 0]))
    g <- do.call("nlm",
                 resolve.defaults(list(f=objectivefun,
                                       p=startvec,
                                       thedata=fdata),
                                  nlm.args,
                                  list(stepmax=1/2, typsize=typsize)))
    popt <- g$estimate
    ## detect error states
    icode <- g$code
    if(!silent && icode > 2) {
      errmess <- nlmcodes[[icode]]
      if(!is.null(errmess)) warning(errmess) else 
      warning("Unrecognised error code ", paste(icode),
              " returned from nlm", call.=FALSE)
    }
    ## return optimised model
    covfunargs[smap] <- popt
    attr(covfunargs, "fitter") <- "ippm"
    attr(covfunargs, "free") <- names(start)
    fit <- update(fit0, covfunargs=covfunargs, use.internal=TRUE)
    fit$dispatched <- fit[c("call", "callstring", "callframe")]
    fit$call <- cl
    fit$callstring <- callstring
    fit$callframe <- callframe
    class(fit) <- c("ippm", class(fit))
    return(fit)
  }

  ## define objective function
  objectivefun <- function(param, thedata) {
    with(thedata, {
      ## fit model with current irregular parameters
      param <- as.list(param)
      names(param) <- pnames
      covfunargs[smap] <- param
      fit <- update(fit0, covfunargs=covfunargs, use.internal=TRUE)
      lpl <- logLik(fit, warn=FALSE)
      ## return negative logL because nlm performs *minimisation*
      value <- -as.numeric(lpl)
      ## compute derivatives
      stuff <- ppmInfluence(fit, what="derivatives",
                            iScore=iScore,
                            iArgs=param)
      score <- stuff$deriv$score
      if(length(score) == length(coef(fit)) + length(param)) 
        attr(value, "gradient") <- -score[-(1:nreg), drop=FALSE]
      ## attr(value, "hessian") <- -hess[-(1:nreg), -(1:nreg), drop=FALSE]
      return(value)
    })
  }

  ## from help(nlm)
  nlmcodes <- list(c("Relative gradient is close to zero; ",
                     "current iterate is probably solution"),
                   c("Successive iterates are within tolerance; ",
                     "current iterate is probably solution"),
                   c("Last global step failed to locate a point ",
                     "lower than current estimate. ",
                     "Either current estimate is an approximate ",
                     "local minimum of the function ",
                     "or 'steptol' is too large"),
                   "Iteration limit exceeded",
                   c("Maximum step size 'stepmax' ",
                     "exceeded five consecutive times. ",
                     "Either the function is unbounded below, ",
                     "becomes asymptotic to a finite value ",
                     "from above in some direction, ",
                     "or 'stepmax' is too small"))

  ippm
})


update.ippm <- local({

  newformula <- function(old, change, eold, enew) {
    old <- eval(old, eold)
    change <- eval(change, enew)
    old <- as.formula(old, env=eold)
    change <- as.formula(change, env=enew)
    update.formula(old, change)
  }

  update.ippm <- function(object, ..., envir=environment(terms(object))) {
#    call <- match.call()
    new.call <- old.call <- object$call
    old.callframe <- object$callframe
    Qold <- eval(old.call$Q, as.list(envir), enclos=old.callframe)
    argh <- list(...)
    if(any(isfmla <- unlist(lapply(argh, inherits, what="formula")))) {
      if(sum(isfmla) > 1)
        stop("Syntax not understood: several arguments are formulas")
      i <- min(which(isfmla))
      new.fmla <- argh[[i]]
      argh <- argh[-i]
      if(inherits(Qold, "formula")) {
        ## formula will replace 'Q'
        if(is.null(lhs.of.formula(new.fmla))) {
          f <- (. ~ x)
          f[[3]] <- new.fmla[[2]]
          new.fmla <- f
        }
        new.call$Q <- newformula(Qold, new.fmla, old.callframe, envir)
      } else if(inherits(Qold, c("ppp", "quad"))) {
        ## formula will replace 'trend' and may replace 'Q'
        new.fmla <- newformula(formula(object), new.fmla, old.callframe, envir)
        if(!is.null(lhs <- lhs.of.formula(new.fmla))) {
          newQ <- eval(eval(substitute(substitute(l, list("."=Q)),
                                       list(l=lhs,
                                            Q=Qold))),
                       envir=as.list(envir), enclos=old.callframe)
          new.call$Q <- newQ
        }
        new.fmla <- rhs.of.formula(new.fmla)
        if("trend" %in% names(old.call)) {
          new.call$trend <- new.fmla
        } else {
          ## find which argument in the original call was a formula
          wasfmla <- unlist(lapply(old.call,
                                   function(z) {
                                     u <- try(eval(z,
                                                   as.list(envir),
                                                   enclos=old.callframe))
                                     inherits(u, "formula")
                                   }))
          if(any(wasfmla)) {
            new.call[[min(which(wasfmla))]] <- new.fmla
          } else {
            new.call$trend <- new.fmla
          }
        }
      }
    }
    ## silence the warnings about unused covfunargs (unless overruled)
    new.call$warn.unused <- FALSE
    ## other arguments
    if(length(argh) > 0) {
      nama <- names(argh)
      named <- if(is.null(nama)) rep(FALSE, length(argh)) else nzchar(nama)
      if(any(named))
        new.call[nama[named]] <- argh[named]
      if(any(!named))
        new.call[length(new.call) + 1:sum(!named)] <- argh[!named]
    }
    result <- eval(new.call, as.list(envir), enclos=old.callframe)
    return(result)
  }

  update.ippm
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/is.cadlag.R"
is.cadlag <- function (s) 
{
if(!is.stepfun(s)) stop("s is not a step function.\n")
r <- knots(s)
h <- s(r)
n <- length(r)
r1 <- c(r[-1],r[n]+1)
rm <- (r+r1)/2
hm <- s(rm)
identical(all.equal(h,hm),TRUE)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/is.subset.owin.R"
#
#  is.subset.owin.R
#
#  $Revision: 1.13 $   $Date: 2014/10/24 00:22:30 $
#
#  Determine whether a window is a subset of another window
#
#  is.subset.owin()
#

is.subset.owin <- local({
  
  is.subset.owin <- function(A, B) {
    A <- as.owin(A)
    B <- as.owin(B)

    if(identical(A, B))
      return(TRUE)

    A <- rescue.rectangle(A)
    B <- rescue.rectangle(B)
  
    if(is.rectangle(B)) {
      # Some cases can be resolved using convexity of B
    
      # (1) A is also a rectangle
      if(is.rectangle(A)) {
        xx <- A$xrange[c(1,2,2,1)]
        yy <- A$yrange[c(1,1,2,2)]
        ok <- inside.owin(xx, yy, B)
        return(all(ok))
      } 
      # (2) A is polygonal
      # Then A is a subset of B iff,
      # for every constituent polygon of A with positive sign,
      # the vertices are all in B
      if(is.polygonal(A)) {
        ok <- unlist(lapply(A$bdry, okpolygon, B=B))
        return(all(ok))
      }
      # (3) Feeling lucky
      # Test whether the bounding box of A is a subset of B
      # Then a fortiori, A is a subset of B
      AA <- boundingbox(A)
      if(is.subset.owin(AA, B))
        return(TRUE)
    }

    if(!is.mask(A) && !is.mask(B)) {
      # rectangles or polygonal domains
      if(!all(inside.owin(vertices(A), , B)))
        return(FALSE)
      # all vertices of A are inside B.
      if(is.convex(B))
        return(TRUE)
      A <- as.polygonal(A)
      B <- as.polygonal(B)
      if(length(B$bdry) == 1 && length(A$bdry) == 1) {
        # two simply-connected sets 
        # check for boundary crossings
        bx <- crossing.psp(edges(A), edges(B))
        return(npoints(bx) == 0)
      } else {
        # compare area of intersection with area of A
        return(overlap.owin(A,B) >= area(A))
      }
    }
  
   # Discretise
    a <- as.mask(A)
    b <- as.mask(B)
    rxy <- rasterxy.mask(a, drop=TRUE)
    xx <- rxy$x
    yy <- rxy$y
    ok <- inside.owin(xx, yy, b)
    return(all(ok))
    
  }

  okpolygon <- function(a, B) {
    if(Area.xypolygon(a) < 0) return(TRUE)
    ok <- inside.owin(a$x, a$y, B)
    return(all(ok))
  }

  is.subset.owin
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/istat.R"
#
# interactive analysis of point patterns
#
#   $Revision: 1.18 $   $Date: 2014/10/24 00:22:30 $
#
#

istat <- function(x, xname) {
  if(missing(xname))
    xname <- short.deparse(substitute(x))
  verifyclass(x, "ppp")
  # generate simulations of CSR for use in envelopes
  simx <- envelope(x, fun=NULL, nsim=39,
                   internal=list(csr=TRUE, eject="patterns"))
  # initial value of smoothing parameter
  sigma0 <- with(x$window, min(diff(xrange),diff(yrange)))/8
  # create panel
  require(rpanel)
  p <- rpanel::rp.control(paste("istat(", xname, ")", sep=""),
                          x=x,           # point pattern
                          xname=xname,   # name of point pattern
                          simx=simx,   # simulated realisations of CSR
                          stat="data",
                          envel="none",
                          sigma=sigma0,
                          size=c(600, 400))
# Split panel into two halves  
# Left half of panel: display
# Right half of panel: controls
  rpanel::rp.grid(p, "gdisplay",
                  pos=list(row=0,column=0), width=400, height=400)
  rpanel::rp.grid(p, "gcontrols",
                  pos=list(row=0,column=1), width=200, height=400)

#----- Display side ------------

  # This line is to placate the package checker
  mytkr2 <- NULL
  
  rpanel::rp.tkrplot(p, mytkr2, do.istat,
                     pos=list(row=0,column=0,grid="gdisplay"))

  redraw <- function(panel) {
    rpanel::rp.tkrreplot(panel, mytkr2)
    panel
  }
  
#----- Control side ------------
  nextrow <- 0
  pozzie <- function(n=nextrow,s='w')
    list(row=n,column=0,grid="gcontrols",sticky=s)
  
# choice of summary statistic
  ftable <- c(data="data",
              density="kernel smoothed",
              Kest="K-function",
              Lest="L-function",
              pcf="pair correlation",
              Kinhom="inhomogeneous K",
              Linhom="inhomogeneous L",
              Fest="empty space function F",
              Gest="nearest neighbour function G",
              Jest="J-function")
  fvals <- names(ftable)
  flabs <- as.character(ftable)
  stat <- NULL
  rpanel::rp.radiogroup(p, stat, vals=fvals, labels=flabs,
                        title="statistic", action=redraw,
                        pos=pozzie(0))
  nextrow <- 1
# envelopes?
  envel <- NULL
  evals <- c("none", "pointwise", "simultaneous")
  elabs <- c("No simulation envelopes",
             "Pointwise envelopes under CSR",
             "Simultaneous envelopes under CSR")
  rpanel::rp.radiogroup(p, envel, vals=evals, labels=elabs,
                        title="Simulation envelopes", action=redraw,
                        pos=pozzie(nextrow))
  nextrow <- nextrow + 1
# smoothing parameters
  sigma <- NULL
  rect <- as.rectangle(x$window)
  winwid  <- min(abs(diff(rect$xrange)), abs(diff(rect$yrange)))
  rpanel::rp.slider(p, sigma, winwid/80, winwid/2, action=redraw, 
                    title="sigma",
                    initval=winwid/8, showvalue=TRUE, pos=pozzie(nextrow, ''))
  nextrow <- nextrow + 1
  pcfbw <- pcfbwinit <- 0.15/sqrt(5 * x$n/area(x$window))
  rpanel::rp.slider(p, pcfbw, pcfbwinit/10, 4 * pcfbwinit, action=redraw, 
                    title="bw", initval=pcfbwinit,
                    showvalue=TRUE, pos=pozzie(nextrow, ''))
  nextrow <- nextrow + 1
# button to print a summary at console
  rpanel::rp.button(p, title="Print summary information",
                    action=function(panel) { print(summary(panel$x)); panel},
                    pos=pozzie(nextrow))
  nextrow <- nextrow + 1
# quit button 
  rpanel::rp.button(p, title="Quit", quitbutton=TRUE,
                    action= function(panel) { panel }, pos=pozzie(nextrow))

  invisible(NULL)
}

# function that updates the plot when the control panel is operated

do.istat <- function(panel) { 
  x     <- panel$x
  xname <- panel$xname
  envel <- panel$envel
  stat  <- panel$stat
  sigma <- panel$sigma
  simx  <- panel$simx
  if(stat=="data") {
    plot(x, main=xname)
    return(panel)
  }
  out <- 
    switch(envel,
           none=switch(stat,
             density=density(x, sigma=sigma),
             Kest=Kest(x),
             Lest=Lest(x), 
             pcf=pcf(x, bw=panel$pcfbw),
             Kinhom=Kinhom(x, sigma=sigma),
             Linhom=Linhom(x, sigma=sigma),
             Fest=Fest(x),
             Gest=Gest(x),
             Jest=Jest(x)),
           pointwise=switch(stat,
             density=density(x, sigma=sigma),
             Kest=envelope(x, Kest, nsim=39, simulate=simx),
             Lest=envelope(x, Lest, nsim=39, simulate=simx),
             pcf=envelope(x, pcf, bw=panel$pcfbw, nsim=39, simulate=simx),
             Kinhom=envelope(x, Kinhom, nsim=39, sigma=sigma, simulate=simx),
             Linhom=envelope(x, Linhom, nsim=39, sigma=sigma, simulate=simx),
             Fest=envelope(x, Fest, nsim=39, simulate=simx),
             Gest=envelope(x, Gest, nsim=39, simulate=simx),
             Jest=envelope(x, Jest, nsim=39, simulate=simx)),
           simultaneous=switch(stat,
             density=density(x, sigma=sigma),
             Kest=envelope(x, Kest, nsim=19, global=TRUE, simulate=simx),
             Lest=envelope(x, Lest, nsim=19, global=TRUE, simulate=simx),
             pcf=envelope(x, pcf, bw=panel$pcfbw, nsim=19, global=TRUE, simulate=simx),
             Kinhom=envelope(x, Kinhom, nsim=19, sigma=sigma, global=TRUE, simulate=simx),
             Linhom=envelope(x, Linhom, nsim=19, sigma=sigma, global=TRUE, simulate=simx),
             Fest=envelope(x, Fest, nsim=19, global=TRUE, simulate=simx),
             Gest=envelope(x, Gest, nsim=19, global=TRUE, simulate=simx),
             Jest=envelope(x, Jest, nsim=19, global=TRUE, simulate=simx))
           )
  # plot it
  if(stat %in% c("density", "Kinhom", "Linhom")) {
    plot(out, main=paste(stat, "(", xname, ", sigma)", sep=""))
    if(stat == "density")
      points(x)
  } else if(stat == "pcf")
    plot(out, main=paste("pcf(", xname, ", bw)", sep=""))
  else 
    plot(out, main=paste(stat, "(", xname, ")", sep=""))

  return(panel)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/kmrs.R"
#
#	kmrs.S
#
#	S code for Kaplan-Meier, Reduced Sample and Hanisch
#	estimates of a distribution function
#	from _histograms_ of censored data.
#
#	kaplan.meier()
#	reduced.sample()
#       km.rs()
#
#	$Revision: 3.26 $	$Date: 2013/06/27 08:59:16 $
#
#	The functions in this file produce vectors `km' and `rs'
#	where km[k] and rs[k] are estimates of F(breaks[k+1]),
#	i.e. an estimate of the c.d.f. at the RIGHT endpoint of the interval.
#

"kaplan.meier" <-
function(obs, nco, breaks, upperobs=0) {
#	obs: histogram of all observations : min(T_i,C_i)
#	nco: histogram of noncensored observations : T_i such that T_i <= C_i
# 	breaks: breakpoints (vector or 'breakpts' object, see breaks.S)
#       upperobs: number of observations beyond rightmost breakpoint
#  
        breaks <- as.breakpts(breaks)

	n <- length(obs)
	if(n != length(nco)) 
		stop("lengths of histograms do not match")
	check.hist.lengths(nco, breaks)
#
#	
#   reverse cumulative histogram of observations
	d <- revcumsum(obs) + upperobs
#
#  product integrand
	s <- ifelseXB(d > 0, 1 - nco/d, 1)
#
	km <- 1 - cumprod(s)
#  km has length n;  km[i] is an estimate of F(r) for r=breaks[i+1]
#	
	widths <- diff(breaks$val)
        lambda <- numeric(n)
        pos <- (s > 0)
        lambda[pos] <- -log(s[pos])/widths[pos]
#  lambda has length n; lambda[i] is an estimate of
#  the average of \lambda(r) over the interval (breaks[i],breaks[i+1]).
#	
	return(list(km=km, lambda=lambda))
}

"reduced.sample" <-
function(nco, cen, ncc, show=FALSE, uppercen=0)
#	nco: histogram of noncensored observations: T_i such that T_i <= C_i
#	cen: histogram of all censoring times: C_i
#	ncc: histogram of censoring times for noncensored obs:
#		C_i such that T_i <= C_i
#
#	Then nco[k] = #{i: T_i <= C_i, T_i \in I_k}
#	     cen[k] = #{i: C_i \in I_k}
#	     ncc[k] = #{i: T_i <= C_i, C_i \in I_k}.
#
#       The intervals I_k must span an interval [0,R] beginning at 0.
#       If this interval did not include all censoring times,
#       then `uppercen' must be the number of censoring times
#       that were not counted in 'cen'.
{
	n <- length(nco)
	if(n != length(cen) || n != length(ncc))
		stop("histogram lengths do not match")
#
#	denominator: reverse cumulative histogram of censoring times
#		denom(r) = #{i : C_i >= r}
#	We compute 
#		cc[k] = #{i: C_i > breaks[k]}	
#	except that > becomes >= for k=0.
#
	cc <- revcumsum(cen) + uppercen
#
#
#	numerator
#	#{i: T_i <= r <= C_i }
#	= #{i: T_i <= r, T_i <= C_i} - #{i: C_i < r, T_i <= C_i}
#	We compute
#		u[k] = #{i: T_i <= C_i, T_i <= breaks[k+1]}
#			- #{i: T_i <= C_i, C_i <= breaks[k]}
#		     = #{i: T_i <= C_i, C_i > breaks[k], T_i <= breaks[k+1]}
#	this ensures that numerator and denominator are 
#	comparable, u[k] <= cc[k] always.
#
	u <- cumsum(nco) - c(0,cumsum(ncc)[1:(n-1)])
	rs <- u/cc
#
#	Hence rs[k] = u[k]/cc[k] is an estimator of F(r) 
#	for r = breaks[k+1], i.e. for the right hand end of the interval.
#
        if(!show)
          return(rs)
        else
          return(list(rs=rs, numerator=u, denominator=cc))
}

"km.rs" <-
function(o, cc, d, breaks) {
#	o: censored lifetimes min(T_i,C_i)
#	cc: censoring times C_i
#	d: censoring indicators 1(T_i <= C_i)
#	breaks: histogram breakpoints (vector or 'breakpts' object)
#
  breaks <- as.breakpts(breaks)
  bval <- breaks$val
# compile histograms (breakpoints may not span data)
  obs <- whist( o,     breaks=bval)
  nco <- whist( o[d],  breaks=bval)
  cen <- whist( cc,    breaks=bval)
  ncc <- whist( cc[d], breaks=bval)
# number of observations exceeding largest breakpoint
  upperobs <- attr(obs, "high")
  uppercen <- attr(cen, "high")
# go
  km <- kaplan.meier(obs, nco, breaks, upperobs=upperobs)
  rs <- reduced.sample(nco, cen, ncc, uppercen=uppercen)
#
  return(list(rs=rs, km=km$km, hazard=km$lambda,
              r=breaks$r, breaks=bval))
}

"km.rs.opt" <-
function(o, cc, d, breaks, KM=TRUE, RS=TRUE) {
#	o: censored lifetimes min(T_i,C_i)
#	cc: censoring times C_i
#	d: censoring indicators 1(T_i <= C_i)
#	breaks: histogram breakpoints (vector or 'breakpts' object)
#
  breaks <- as.breakpts(breaks)
  bval <- breaks$val
  out <- list(r=breaks$r, breaks=bval)
  if(KM || RS)
    nco <- whist( o[d],  breaks=bval)
  if(KM) {
    obs <- whist( o,     breaks=bval)
    upperobs <- attr(obs, "high")
    km <- kaplan.meier(obs, nco, breaks, upperobs=upperobs)
    out <- append(list(km=km$km, hazard=km$lambda), out)
  }
  if(RS) {
    cen <- whist( cc,    breaks=bval)
    ncc <- whist( cc[d], breaks=bval)
    uppercen <- attr(cen, "high")
    rs <- reduced.sample(nco, cen, ncc, uppercen=uppercen)
    out <- append(list(rs=rs), out)
  }
  return(out)
}


censtimeCDFest <- function(o, cc, d, breaks, ...,
                           KM=TRUE, RS=TRUE, HAN=TRUE, RAW=TRUE,
                           han.denom=NULL, tt=NULL, pmax=0.9) {
# Histogram-based estimation of cumulative distribution function
# of lifetimes subject to censoring.
#	o: censored lifetimes min(T_i,C_i)
#	cc: censoring times C_i
#	d: censoring indicators 1(T_i <= C_i)
#	breaks: histogram breakpoints (vector or 'breakpts' object)
#       han.denom: denominator (eroded area) for each value of r
#       tt: uncensored lifetimes T_i, if known  
  breaks <- as.breakpts(breaks)
  bval <- breaks$val
  rval <- breaks$r
  rmax <- breaks$max
  # Kaplan-Meier and/or Reduced Sample
  out <- km.rs.opt(o, cc, d, breaks, KM=KM, RS=RS)
  # convert to data frame
  out$breaks <- NULL
  df <- as.data.frame(out)
  # Raw ecdf of observed lifetimes if available
  if(RAW && !is.null(tt)) {
    h <- whist(tt[tt <= rmax], breaks=bval)
    df <- cbind(df, data.frame(raw=cumsum(h)/length(tt)))
  }
  # Hanisch
  if(HAN) {
    if(is.null(han.denom))
      stop("Internal error: missing denominator for Hanisch estimator")
    if(length(han.denom) != length(rval))
      stop(paste("Internal error:",
                 "length(han.denom) =", length(han.denom),
                 "!=", length(rval), "= length(rvals)"))
    #  uncensored distances
    x <- o[d]
    # calculate Hanisch estimator
    h <- whist(x[x <= rmax], breaks=bval)
    H <- cumsum(h/han.denom)
    df <- cbind(df, data.frame(han=H/max(H[is.finite(H)])))
  }
  # determine appropriate plotting range
  bestest <- if(KM) "km" else if(HAN) "han" else if(RS) "rs" else "raw"
  alim <- range(df$r[df[[bestest]] <= pmax])
  # convert to fv object
  nama <-  c("r",  "km", "hazard", "han", "rs", "raw")
  avail <- c(TRUE,  KM,  KM,       HAN,   RS,   RAW)
  iscdf <- c(FALSE, TRUE, FALSE,   TRUE,  TRUE, TRUE)
  labl <- c("r", "hat(%s)[km](r)", "lambda(r)", "hat(%s)[han](r)",
            "hat(%s)[bord](r)", "hat(%s)[raw](r)")[avail]
  desc <- c("distance argument r",
            "Kaplan-Meier estimate of %s",
            "Kaplan-Meier estimate of hazard function lambda(r)",
            "Hanisch estimate of %s",
            "border corrected estimate of %s",
            "uncorrected estimate of %s")[avail]
  df <- df[, nama[avail]]
  Z <- fv(df, "r", substitute(CDF(r), NULL), bestest, . ~ r, alim, labl, desc,
          fname="CDF")
  fvnames(Z, ".") <- nama[iscdf & avail]
  return(Z)
}

# simple interface for students and code development

compileCDF <- function(D, B, r, ..., han.denom=NULL, check=TRUE) {
  han <- !is.null(han.denom)
  breaks <- breakpts.from.r(r)
  if(check) {
    stopifnot(length(D) == length(B) && all(D >= 0) && all(B >= 0))
    if(han)
      stopifnot(length(han.denom) == length(r))
  }
  D <- as.vector(D)
  B <- as.vector(B)
  # observed (censored) lifetimes
  o <- pmin.int(D, B)
  # censoring indicators
  d <- (D <= B)
  # go
  result <- censtimeCDFest(o, B, d, breaks,
                           HAN=han, 
                           han.denom=han.denom,
                           RAW=TRUE, tt=D)
  result <- rebadge.fv(result, new.fname="compileCDF")
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/kppm.R"
#
# kppm.R
#
# kluster/kox point process models
#
# $Revision: 1.91 $ $Date: 2014/11/10 10:38:43 $
#

kppm <- function(X, ...) {
  UseMethod("kppm")
}


kppm.formula <-
  function(X, clusters = c("Thomas","MatClust","Cauchy","VarGamma","LGCP"),
           ..., data=NULL) {
  ## remember call
  callstring <- short.deparse(sys.call())
  ## cl <- match.call()

  ########### INTERPRET FORMULA ##############################
  
  if(!inherits(X, "formula"))
    stop(paste("Argument 'X' should be a formula"))
  formula <- X
  
  if(spatstat.options("expand.polynom"))
    formula <- expand.polynom(formula)

  ## check formula has LHS and RHS. Extract them
  if(length(formula) < 3)
    stop(paste("Formula must have a left hand side"))
  Yexpr <- formula[[2]]
  trend <- formula[c(1,3)]
  
  ## FIT #######################################
  thecall <- call("kppm", X=Yexpr, trend=trend,
                  data=data, clusters=clusters)
  ncall <- length(thecall)
  argh <- list(...)
  nargh <- length(argh)
  if(nargh > 0) {
    thecall[ncall + 1:nargh] <- argh
    names(thecall)[ncall + 1:nargh] <- names(argh)
  }
  result <- eval(thecall, parent.frame())

  if(!("callstring" %in% names(list(...))))
    result$callstring <- callstring
  
  return(result)
}

kppm.ppp <- kppm.quad <-
  function(X, trend = ~1,
           clusters = c("Thomas","MatClust","Cauchy","VarGamma","LGCP"),
           data=NULL,
           ...,
           covariates = data,
           method = c("mincon", "clik2", "palm"),
           improve.type = c("none", "clik1", "wclik1", "quasi"),
           improve.args = list(),
           weightfun=NULL,
           control=list(),
           statistic="K",
           statargs=list(),
           rmax = NULL,
           covfunargs=NULL,
           use.gam=FALSE,
           nd=NULL, eps=NULL) {
  Xname <- short.deparse(substitute(X))
  clusters <- match.arg(clusters)
  improve.type <- match.arg(improve.type)
  method <- match.arg(method)
  if(method == "mincon")
    statistic <- pickoption("summary statistic", statistic,
                            c(K="K", g="pcf", pcf="pcf"))
  isquad <- inherits(X, "quad")
  if(!is.ppp(X) && !isquad)
    stop("X should be a point pattern (ppp) or quadrature scheme (quad)")
  if(is.marked(X))
    stop("Sorry, cannot handle marked point patterns")
  po <- ppm(Q=X, trend=trend, covariates=covariates,
            forcefit=TRUE, rename.intercept=FALSE,
            covfunargs=covfunargs, use.gam=use.gam, nd=nd, eps=eps)
  XX <- if(isquad) X$data else X
  # fit
  out <- switch(method,
         mincon = kppmMinCon(X=XX, Xname=Xname, po=po, clusters=clusters,
                             statistic=statistic, statargs=statargs,
                             control=control, rmax=rmax, ...),
         clik2   = kppmComLik(X=XX, Xname=Xname, po=po, clusters=clusters,
                             control=control, weightfun=weightfun, 
                             rmax=rmax, ...),
         palm   = kppmPalmLik(X=XX, Xname=Xname, po=po, clusters=clusters,
                             control=control, weightfun=weightfun, 
                             rmax=rmax, ...))
  #
  class(out) <- c("kppm", class(out))

  # Update intensity estimate with improve.kppm if necessary:
  if(improve.type != "none")
    out <- do.call(improve.kppm,
                   append(list(object = out, type = improve.type),
                          improve.args))
  return(out)
}

kppmMinCon <- function(X, Xname, po, clusters, statistic, statargs, ...) {
  # Minimum contrast fit
  stationary <- is.stationary(po)
  # compute summary function
  if(stationary) {
    StatFun <- if(statistic == "K") "Kest" else "pcf"
    StatName <-
      if(statistic == "K") "K-function" else "pair correlation function"
    Stat <- do.call(StatFun,
                    resolve.defaults(list(X=X),
                                     statargs,
                                     list(correction="best")))
    lambda <- summary(po)$trend$value
  } else {
    StatFun <- if(statistic == "K") "Kinhom" else "pcfinhom"
    StatName <- if(statistic == "K") "inhomogeneous K-function" else
    "inhomogeneous pair correlation function"
    # compute intensity at high resolution if available
    w <- as.owin(po, from="covariates")
    if(!is.mask(w)) w <- NULL
    lambda <- predict(po, locations=w)
    Stat <- do.call(StatFun,
                    resolve.defaults(list(X=X, lambda=lambda),
                                     statargs,
                                     list(correction="best")))
  }
  # determine initial values of parameters
  selfstart <- spatstatClusterModelInfo(clusters)$selfstart
  startpar0 <- selfstart(X) 
  # fit
  switch(clusters,
         Thomas={
           FitFun <- if(statistic == "K") "thomas.estK" else "thomas.estpcf"
           mcfit <-
             do.call(FitFun,
                     resolve.defaults(
                                      list(X=Stat, lambda=lambda),
                                      list(...),
                                      list(startpar=startpar0, dataname=Xname)))
           # kappa = intensity of parents
           kappa <- mcfit$par[["kappa"]]
           # mu = mean number of points per cluster
           mu <- if(stationary) lambda/kappa else eval.im(lambda/kappa)
           isPCP <- TRUE
         },
         MatClust={
           FitFun <- if(statistic == "K") "matclust.estK" else "matclust.estpcf"
           mcfit <-
             do.call(FitFun,
                     resolve.defaults(
                                      list(X=Stat, lambda=lambda),
                                      list(...),
                                      list(startpar=startpar0, dataname=Xname)))
           # kappa = intensity of parents
           kappa <- mcfit$par[["kappa"]]
           # mu = mean number of points per cluster
           mu <- if(stationary) lambda/kappa else eval.im(lambda/kappa)
           isPCP <- TRUE
         },
         Cauchy = {
           FitFun <- if (statistic == "K") "cauchy.estK" else "cauchy.estpcf"
           mcfit <- do.call(FitFun,
                            resolve.defaults(list(X = Stat, 
                                                  lambda = lambda),
                                             list(...),
                                             list(startpar = startpar0,
                                                  dataname = Xname)))
           # kappa = intensity of parents
           kappa <- mcfit$par[["kappa"]]
           # mu = mean number of points per cluster
           mu <- if (stationary) lambda/kappa else eval.im(lambda/kappa)
           isPCP <- TRUE
         }, VarGamma = {
           FitFun <- if (statistic == "K") "vargamma.estK" else "vargamma.estpcf"
           mcfit <- do.call(FitFun,
                            resolve.defaults(list(X = Stat, 
                                                  lambda = lambda),
                                             list(...),
                                             list(startpar = startpar0, 
                                                  dataname = Xname, nu = 0.5)))
           kappa <- mcfit$par[["kappa"]]
           mu <- if (stationary) lambda/kappa else eval.im(lambda/kappa)
           isPCP <- TRUE
         },
         LGCP={
           FitFun <- if(statistic == "K") "lgcp.estK" else "lgcp.estpcf"
           mcfit <-
             do.call(FitFun,
                     resolve.defaults(
                                      list(X=Stat, lambda=lambda),
                                      list(...),
                                      list(startpar=startpar0, dataname=Xname)))
           sigma2 <- mcfit$par[["sigma2"]]
           # mu = mean of log intensity 
           mu <- if(stationary) log(lambda) - sigma2/2 else eval.im(log(lambda) - sigma2/2)
           isPCP <- FALSE
         })

  # all info that depends on the fitting method:
  Fit <- list(method    = "mincon",
              statistic = statistic,
              Stat      = Stat,
              StatFun   = StatFun,
              StatName  = StatName,
              FitFun    = FitFun,
              statargs  = statargs,
              mcfit     = mcfit)
  # results
  out <- list(Xname      = Xname,
              X          = X,
              stationary = stationary,
              clusters   = clusters,
              modelname  = mcfit$info$modelname,
              isPCP      = isPCP,
              po         = po,
              lambda     = lambda,
              mu         = mu,
              par        = mcfit$par,
              modelpar   = mcfit$modelpar,
              covmodel   = mcfit$covmodel,
              Fit        = Fit)
  return(out)
}

kppmComLik <- function(X, Xname, po, clusters, control, weightfun, rmax, ...) {
  W <- as.owin(X)
  if(is.null(rmax))
    rmax <- rmax.rule("K", W, intensity(X))
  # identify pairs of points that contribute
  cl <- closepairs(X, rmax)
  I <- cl$i
  J <- cl$j
  dIJ <- cl$d
  # compute weights for pairs of points
  if(is.function(weightfun)) {
    wIJ <- weightfun(dIJ)
    sumweight <- sum(wIJ)
  } else {
    npairs <- length(dIJ)
    wIJ <- rep.int(1, npairs)
    sumweight <- npairs
  }
  # convert window to mask, saving other arguments for later
  dcm <- do.call.matched("as.mask",
                         append(list(w=W), list(...)),
                         sieve=TRUE)
  M         <- dcm$result
  otherargs <- dcm$otherargs
  # compute intensity at pairs of data points
  # and c.d.f. of interpoint distance in window
  if(stationary <- is.stationary(po)) {
    # stationary unmarked Poisson process
    lambda <- intensity(X)
#    lambdaIJ <- lambda^2
    # compute cdf of distance between two uniform random points in W
    g <- distcdf(W)
    # scaling constant is (area * intensity)^2
    gscale <- npoints(X)^2  
  } else {
    # compute fitted intensity at data points and in window
    lambdaX <- fitted(po, dataonly=TRUE)
    lambda <- lambdaM <- predict(po, locations=M)
    # lambda(x_i) * lambda(x_j)
#    lambdaIJ <- lambdaX[I] * lambdaX[J]
    # compute cdf of distance between two random points in W
    # with density proportional to intensity function
    g <- distcdf(M, dW=lambdaM)
    # scaling constant is (integral of intensity)^2
    gscale <- integral.im(lambdaM)^2
  }
  # trim 'g' to [0, rmax] 
  g <- g[with(g, .x) <= rmax,]
  # get pair correlation function (etc) for model
  info <- spatstatClusterModelInfo(clusters)
  pcfun      <- info$pcf
  funaux     <- info$funaux
  selfstart  <- info$selfstart
  isPCP      <- info$isPCP
  parhandler <- info$parhandler
  modelname  <- info$modelname
  # Assemble information required for computing pair correlation
  pcfunargs <- list(funaux=funaux)
  if(is.function(parhandler)) {
    # Additional parameters of cluster model are required.
    # These may be given as individual arguments,
    # or in a list called 'covmodel'
    clustargs <- if("covmodel" %in% names(otherargs))
                 otherargs[["covmodel"]] else otherargs
    clargs <- do.call(parhandler, clustargs)
    pcfunargs <- append(clargs, pcfunargs)
  } else clargs <- NULL
  # determine starting parameter values
  startpar <- selfstart(X)
  # create local function to evaluate pair correlation
  #  (with additional parameters 'pcfunargs' in its environment)
  paco <- function(d, par) {
    do.call(pcfun, append(list(par=par, rvals=d), pcfunargs))
  }
  # define objective function 
  if(!is.function(weightfun)) {
    # pack up necessary information
    objargs <- list(dIJ=dIJ, sumweight=sumweight, g=g, gscale=gscale, 
                    envir=environment(paco))
    # define objective function (with 'paco' in its environment)
    # Note that this is 1/2 of the log composite likelihood,
    # minus the constant term 
    #       sum(log(lambdaIJ)) - npairs * log(gscale)
    obj <- function(par, objargs) {
      with(objargs,
           sum(log(paco(dIJ, par)))
           - sumweight * log(unlist(stieltjes(paco, g, par=par))),
           enclos=objargs$envir)
    }
  } else {
    # create local function to evaluate  pair correlation(d) * weight(d)
    #  (with additional parameters 'pcfunargs', 'weightfun' in its environment)
    force(weightfun)
    wpaco <- function(d, par) {
      y <- do.call(pcfun, append(list(par=par, rvals=d), pcfunargs))
      w <- weightfun(d)
      return(y * w)
    }
    # pack up necessary information
    objargs <- list(dIJ=dIJ, wIJ=wIJ, sumweight=sumweight, g=g, gscale=gscale, 
                    envir=environment(wpaco))
    # define objective function (with 'paco', 'wpaco' in its environment)
    # Note that this is 1/2 of the log composite likelihood,
    # minus the constant term 
    #       sum(wIJ * log(lambdaIJ)) - sumweight * log(gscale)
    obj <- function(par, objargs) {
      with(objargs,
           sum(wIJ * log(paco(dIJ, par)))
           - sumweight * log(unlist(stieltjes(wpaco, g, par=par))),
           enclos=objargs$envir)
    }
  }    
  # optimize it
  ctrl <- resolve.defaults(list(fnscale=-1), control, list(trace=0))
  opt <- optim(startpar, obj, objargs=objargs, control=ctrl)
  # raise warning/error if something went wrong
  signalStatus(optimStatus(opt), errors.only=TRUE)
  # meaningful model parameters
  optpar <- opt$par
  modelpar <- info$interpret(optpar, lambda)
  # infer parameter 'mu'
  if(isPCP) {
    # Poisson cluster process: extract parent intensity kappa
    kappa <- optpar[["kappa"]]
    # mu = mean cluster size
    mu <- if(stationary) lambda/kappa else eval.im(lambda/kappa)
  } else {
    # LGCP: extract variance parameter sigma2
    sigma2 <- optpar[["sigma2"]]
    # mu = mean of log intensity 
    mu <- if(stationary) log(lambda) - sigma2/2 else
          eval.im(log(lambda) - sigma2/2)    
  }
  # all info that depends on the fitting method:
  Fit <- list(method    = "clik2",
              clfit     = opt,
              weightfun = weightfun,
              rmax      = rmax,
              objfun    = obj,
              objargs   = objargs)
  # pack up
  result <- list(Xname      = Xname,
                 X          = X,
                 stationary = stationary,
                 clusters   = clusters,
                 modelname  = modelname,
                 isPCP      = isPCP,
                 po         = po,
                 lambda     = lambda,
                 mu         = mu,
                 par        = optpar,
                 modelpar   = modelpar,
                 covmodel   = clargs,
                 Fit        = Fit)
  return(result)
}

kppmPalmLik <- function(X, Xname, po, clusters, control, weightfun, rmax, ...) {
  W <- as.owin(X)
  if(is.null(rmax))
    rmax <- rmax.rule("K", W, intensity(X))
  # identify pairs of points that contribute
  cl <- closepairs(X, rmax)
#  I <- cl$i
  J <- cl$j
  dIJ <- cl$d
  # compute weights for pairs of points
  if(is.function(weightfun)) {
    wIJ <- weightfun(dIJ)
#    sumweight <- sum(wIJ)
  } else {
    npairs <- length(dIJ)
    wIJ <- rep.int(1, npairs)
#    sumweight <- npairs
  }
  # convert window to mask, saving other arguments for later
  dcm <- do.call.matched("as.mask",
                         append(list(w=W), list(...)),
                         sieve=TRUE)
  M         <- dcm$result
  otherargs <- dcm$otherargs
  # compute intensity at data points
  # and c.d.f. of interpoint distance in window
  if(stationary <- is.stationary(po)) {
    # stationary unmarked Poisson process
    lambda <- intensity(X)
    lambdaJ <- rep(lambda, length(J))
    # compute cdf of distance between a uniform random point in W
    # and a randomly-selected point in X 
    g <- distcdf(X, M)
    # scaling constant is (integral of intensity) * (number of points)
    gscale <- npoints(X)^2
  } else {
    # compute fitted intensity at data points and in window
    lambdaX <- fitted(po, dataonly=TRUE)
    lambda <- lambdaM <- predict(po, locations=M)
    lambdaJ <- lambdaX[J] 
    # compute cdf of distance between a uniform random point in X 
    # and a random point in W with density proportional to intensity function
    g <- distcdf(X, M, dV=lambdaM)
    # scaling constant is (integral of intensity) * (number of points)
    gscale <- integral.im(lambdaM) * npoints(X)
  }
  # trim 'g' to [0, rmax] 
  g <- g[with(g, .x) <= rmax,]
  # get pair correlation function (etc) for model
  info <- spatstatClusterModelInfo(clusters)
  pcfun      <- info$pcf
  funaux     <- info$funaux
  selfstart  <- info$selfstart
  isPCP      <- info$isPCP
  parhandler <- info$parhandler
  modelname  <- info$modelname
  # Assemble information required for computing pair correlation
  pcfunargs <- list(funaux=funaux)
  if(is.function(parhandler)) {
    # Additional parameters of cluster model are required.
    # These may be given as individual arguments,
    # or in a list called 'covmodel'
    clustargs <- if("covmodel" %in% names(otherargs))
                 otherargs[["covmodel"]] else otherargs
    clargs <- do.call(parhandler, clustargs)
    pcfunargs <- append(clargs, pcfunargs)
  } else clargs <- NULL
  # determine starting parameter values
  startpar <- selfstart(X)
  # create local function to evaluate pair correlation
  #  (with additional parameters 'pcfunargs' in its environment)
  paco <- function(d, par) {
    do.call(pcfun, append(list(par=par, rvals=d), pcfunargs))
  }
  # define objective function 
  if(!is.function(weightfun)) {
    # pack up necessary information
    objargs <- list(dIJ=dIJ, g=g, gscale=gscale,
                    sumloglam=sum(log(lambdaJ)),
                    envir=environment(paco))
    # define objective function (with 'paco' in its environment)
    # This is the log Palm likelihood
    obj <- function(par, objargs) {
      with(objargs,
           sumloglam + sum(log(paco(dIJ, par)))
           - gscale * unlist(stieltjes(paco, g, par=par)),
           enclos=objargs$envir)
    }
  } else {
    # create local function to evaluate  pair correlation(d) * weight(d)
    #  (with additional parameters 'pcfunargs', 'weightfun' in its environment)
    force(weightfun)
    wpaco <- function(d, par) {
      y <- do.call(pcfun, append(list(par=par, rvals=d), pcfunargs))
      w <- weightfun(d)
      return(y * w)
    }
    # pack up necessary information
    objargs <- list(dIJ=dIJ, wIJ=wIJ, g=g, gscale=gscale,
                    wsumloglam=sum(wIJ * log(lambdaJ)),
                    envir=environment(wpaco))
    # define objective function (with 'paco', 'wpaco' in its environment)
    # This is the log Palm likelihood
    obj <- function(par, objargs) {
      with(objargs,
           wsumloglam + sum(wIJ * log(paco(dIJ, par)))
           - gscale * unlist(stieltjes(wpaco, g, par=par)),
           enclos=objargs$envir)
    }
  }    
  # optimize it
  ctrl <- resolve.defaults(list(fnscale=-1), control, list(trace=0))
  opt <- optim(startpar, obj, objargs=objargs, control=ctrl)
  # raise warning/error if something went wrong
  signalStatus(optimStatus(opt), errors.only=TRUE)
  # meaningful model parameters
  optpar <- opt$par
  modelpar <- info$interpret(optpar, lambda)
  # infer parameter 'mu'
  if(isPCP) {
    # Poisson cluster process: extract parent intensity kappa
    kappa <- optpar[["kappa"]]
    # mu = mean cluster size
    mu <- if(stationary) lambda/kappa else eval.im(lambda/kappa)
  } else {
    # LGCP: extract variance parameter sigma2
    sigma2 <- optpar[["sigma2"]]
    # mu = mean of log intensity 
    mu <- if(stationary) log(lambda) - sigma2/2 else
          eval.im(log(lambda) - sigma2/2)    
  }
  # all info that depends on the fitting method:
  Fit <- list(method    = "palm",
              clfit     = opt,
              weightfun = weightfun,
              rmax      = rmax)
  # pack up
  result <- list(Xname      = Xname,
                 X          = X,
                 stationary = stationary,
                 clusters   = clusters,
                 modelname  = modelname,
                 isPCP      = isPCP,
                 po         = po,
                 lambda     = lambda,
                 mu         = mu,
                 par        = optpar,
                 modelpar   = modelpar,
                 covmodel   = clargs,
                 Fit        = Fit)
  return(result)
}

improve.kppm <- local({

  fnc <- function(r, eps, g){ (g(r) - 1)/(g(0) - 1) - eps}

  improve.kppm <- function(object, type=c("quasi", "wclik1", "clik1"),
                           rmax = NULL, eps.rmax = 0.01,
                           dimyx = 50, maxIter = 100, tolerance = 1e-06,
                           fast = TRUE, vcov = FALSE, fast.vcov = FALSE,
                           verbose = FALSE,
                           save.internals = FALSE) {
    verifyclass(object, "kppm")
    type <- match.arg(type)
    if(((type == "quasi" && fast) || (vcov && fast.vcov)) && !require(Matrix))
      stop(paste("Package Matrix must be installed in order for",
                 "the fast option of quasi-likelihood estimation",
                 "for cluster models to work."),
           call.=FALSE)
    gfun <- pcfmodel(object)
    X <- object$X
    win <- as.owin(X)
    ## simple (rectangular) grid quadrature scheme
    ## (using pixels with centers inside owin only)
    mask <- as.mask(win, dimyx = dimyx)
    wt <- pixellate(win, W = mask)
    wt <- wt[mask]
    Uxy <- rasterxy.mask(mask)
    U <- ppp(Uxy$x, Uxy$y, window = win, check=FALSE)
#    nU <- npoints(U)
    Yu <- pixellate(X, W = mask)
    Yu <- Yu[mask]
    
    ## covariates at quadrature points
    po <- object$po
    Z <- model.images(po, mask)
    Z <- sapply(Z, "[", i=U)

    ##obtain initial beta estimate using composite likelihood
    beta0 <- coef(po)
    
    ## determining the dependence range
    if (type != "clik1" && is.null(rmax))
      {
        diamwin <- diameter(win)
        rmax <- if(fnc(diamwin, eps.rmax, gfun) >= 0) diamwin else
                uniroot(fnc, lower = 0, upper = diameter(win),
                        eps=eps.rmax, g=gfun)$root
        if(verbose)
          splat(paste0("type: ", type, ", ",
                       "dependence range: ", rmax, ", ",
                       "dimyx: ", dimyx, ", g(0) - 1:", gfun(0) -1))
      }
    ## preparing the WCL case
    if (type == "wclik1")
      Kmax <- 2*pi * integrate(function(r){r * (gfun(r) - 1)},
                               lower=0, upper=rmax)$value * exp(c(Z %*% beta0))
    ## the g()-1 matrix without tapering
    if (!fast){
      if (verbose)
        cat("computing the g(u_i,u_j)-1 matrix ...")
      gminus1 <- matrix(gfun(c(pairdist(U))) - 1, U$n, U$n)
      if (verbose)
        cat("..Done.\n")
    }
    
    if ( (fast && type == "quasi") | fast.vcov ){
      if (verbose)
        cat("computing the sparse G-1 matrix ...\n")
      ## Non-zero gminus1 entries (when using tapering)
      cp <- crosspairs(U,U,rmax)
      if (verbose)
        cat("crosspairs done\n")
      Gtap <- (gfun(cp$d) - 1)
      if(vcov){
        if(fast.vcov){
          gminus1 <- Matrix::sparseMatrix(i=cp$i, j=cp$j,
                                          x=Gtap, dims=c(U$n, U$n))
        } else{
          if(fast)
            gminus1 <- matrix(gfun(c(pairdist(U))) - 1, U$n, U$n)
        }
      }
      if (verbose & type!="quasi")
        cat("..Done.\n")
    }
       
    if (type == "quasi" && fast){
      mu0 <- exp(c(Z %*% beta0)) * wt
      mu0root <- sqrt(mu0)
      sparseG <- Matrix::sparseMatrix(i=cp$i, j=cp$j,
                                      x=mu0root[cp$i] * mu0root[cp$j] * Gtap,
                                      dims=c(U$n, U$n))
      Rroot <- Matrix::Cholesky(sparseG, perm = TRUE, Imult = 1)
      ##Imult=1 means that we add 1*I
      if (verbose)
        cat("..Done.\n")
    }
    
    ## iterative weighted least squares/Fisher scoring
    bt <- beta0
    noItr <- 1
    repeat {
      mu <- exp(c(Z %*% bt)) * wt
      mu.root <- sqrt(mu)
      ## the core of estimating equation: ff=phi
      ## in case of ql, \phi=V^{-1}D=V_\mu^{-1/2}x where (G+I)x=V_\mu^{1/2} Z
      ff <- switch(type,
                   clik1 = Z,
                   wclik1= Z/(1 + Kmax),
                   quasi = if(fast){
                     Matrix::solve(Rroot, mu.root * Z)/mu.root
                   } else{
                     solve(diag(U$n) + t(gminus1 * mu), Z)
                   }
                   )
      ##alternative
      ##R=chol(sparseG+sparseMatrix(i=c(1:U$n),j=c(1:U$n),
      ##                            x=rep(1,U$n),dims=c(U$n,U$n)))
      ##ff2 <- switch(type,
      ##              clik1 = Z,
      ##              wclik1= Z/(1 + Kmax),
      ##              quasi = if (fast)
      ##                         solve(R,solve(t(R), mu.root * Z))/mu.root
      ##                      else solve(diag(U$n) + t(gminus1 * mu), Z))
      ## print(summary(as.numeric(ff)-as.numeric(ff2)))
      ## the estimating equation: u_f(\beta)
      uf <- (Yu - mu) %*% ff
      ## inverse of minus expectation of Jacobian matrix: I_f
      Jinv <- solve(t(Z * mu) %*% ff)
      if(maxIter==0){
        ## This is a built-in early exit for vcov internal calculations
        break
      }
      deltabt <- as.numeric(uf %*% Jinv)
      if (any(!is.finite(deltabt))) {
        warning(paste("Infinite value, NA or NaN appeared",
                      "in the iterative weighted least squares algorithm.",
                      "Returning the initial intensity estimate unchanged."),
                call.=FALSE)
        return(object)
      }
      ## updating the present estimate of \beta
      bt <- bt + deltabt
      if (verbose)
        splat(paste0("itr: ", noItr, ",\nu_f: ", as.numeric(uf),
                     "\nbeta:", bt, "\ndeltabeta:", deltabt))
      if (max(abs(deltabt/bt)) <= tolerance || max(abs(uf)) <= tolerance)
        break
      if (noItr > maxIter)
        stop("Maximum number of iterations reached without convergence.")
      noItr <- noItr + 1
    }
    out <- object
    out$po$coef.orig <- beta0
    out$po$coef <- bt
    out$lambda <- predict(out$po, locations = as.mask(out$lambda))
    out$improve <- list(type = type,
                        rmax = rmax,
                        dimyx = dimyx,
                        fast = fast,
                        fast.vcov = fast.vcov)
    if(save.internals){
      out$improve <- append(out$improve, list(ff=ff, uf=uf, J.inv=Jinv))
    }
    if(vcov){
      if (verbose)
        cat("computing the asymptotic variance ...\n")
      ## variance of the estimation equation: Sigma_f = Var(u_f(bt))
      trans <- if(fast) Matrix::t else t
      Sig <- trans(ff) %*% (ff * mu) + trans(ff * mu) %*% gminus1 %*% (ff * mu)
      ## note Abdollah's G does not have mu.root inside...
      ## the asymptotic variance of \beta:
      ##         inverse of the Godambe information matrix
      out$vcov <- as.matrix(Jinv %*% Sig %*% Jinv)
    }
    return(out)
  }
  improve.kppm
})


is.kppm <- function(x) { inherits(x, "kppm")}

print.kppm <- function(x, ...) {

  isPCP <- x$isPCP
  # handle outdated objects - which were all cluster processes
  if(is.null(isPCP)) isPCP <- TRUE
  
  cat(paste(if(x$stationary) "Stationary" else "Inhomogeneous",
            if(isPCP) "cluster" else "Cox",
            "point process model\n"))

  if(nchar(x$Xname) < 20)
    cat(paste("Fitted to point pattern dataset", sQuote(x$Xname), "\n"))

  switch(x$Fit$method,
         mincon = {
           cat("Fitted by minimum contrast\n")
           cat(paste("\tSummary statistic:", x$Fit$StatName, "\n"))
         },
         clik  =,
         clik2 = {
           cat("Fitted by maximum second order composite likelihood\n")
           cat(paste("\trmax =", x$Fit$rmax, "\n"))
           if(!is.null(wtf <- x$Fit$weightfun)) {
             cat("\tweight function: ")
             print(wtf)
           }
         },
         palm = {
           cat("Fitted by maximum Palm likelihood\n")
           cat(paste("\trmax =", x$Fit$rmax, "\n"))
           if(!is.null(wtf <- x$Fit$weightfun)) {
             cat("\tweight function: ")
             print(wtf)
           }
         },
         warning(paste("Unrecognised fitting method", sQuote(x$Fit$method)))
         )

  # ............... trend .........................

  print(x$po, what="trend")

  # ..................... clusters ................
  
  cat(paste(if(isPCP) "Cluster" else "Cox",
            "model:", x$modelname, "\n"))
  cm <- x$covmodel
  if(!is.null(cm)) {
    # Covariance model - LGCP only
    cat(paste("\tCovariance model:", cm$model, "\n"))
    margs <- cm$margs
    if(!is.null(margs)) {
      nama <- names(margs)
      tags <- ifelse(nzchar(nama), paste(nama, "="), "")
      tagvalue <- paste(tags, margs)
      cat(paste("\tCovariance parameters:",
                paste(tagvalue, collapse=", "),
                "\n"))
    }
  }
  pa <- x$par
  if (!is.null(pa)) {
    cat(paste("Fitted",
              if(isPCP) "cluster" else "correlation",
              "parameters:\n"))
    print(pa)
  }

  if(!is.null(mu <- x$mu)) {
    if(isPCP) {
      cat("Mean cluster size: ")
      if(!is.im(mu)) cat(mu, "points\n") else cat("[pixel image]\n")
    } else {
      cat("Fitted mean of log of random intensity: ")
      if(!is.im(mu)) cat(mu, "\n") else cat("[pixel image]\n")
    }
  }
  invisible(NULL)
}

plot.kppm <- function(x, ..., what=c("intensity", "statistic")) {
  objectname <- short.deparse(substitute(x))
  plotem <- function(x, ..., main=dmain, dmain) { plot(x, ..., main=main) }
  what <- pickoption("plot type", what,
                    c(statistic="statistic",
                      intensity="intensity"),
                    multi=TRUE)
  # handle older objects
  Fit <- x$Fit
  if(is.null(Fit)) {
    warning("kppm object is in outdated format")
    Fit <- x
    Fit$method <- "mincon"
  } 
  inappropriate <- ((what == "intensity") & (x$stationary)) |
                   ((what == "statistic") & (Fit$method != "mincon"))
  if(any(inappropriate)) {
    what <- what[!inappropriate]
    if(length(what) == 0) return(invisible(NULL))
  }
  pauseit <- interactive() && (length(what) > 1)
  if(pauseit) opa <- par(ask=TRUE)
  for(style in what)
    switch(style,
           intensity={
             plotem(x$po, ...,
                    dmain=c(objectname, "Intensity"),
                    how="image", se=FALSE)
           },
           statistic={
             plotem(Fit$mcfit, ...,
                    dmain=c(objectname, Fit$StatName))
           })
  if(pauseit) par(opa)
  return(invisible(NULL))
}

predict.kppm <- function(object, ...) {
  predict(object$po, ...)
}

fitted.kppm <- function(object, ...) {
  fitted(object$po, ...)
}


simulate.kppm <- function(object, nsim=1, seed=NULL, ...,
                          window=NULL, covariates=NULL,
                          verbose=TRUE, retry=10) {
  starttime <- proc.time()
  verbose <- verbose && (nsim > 1)
  check.1.real(retry)
  # .... copied from simulate.lm ....
  if (!exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE))
    runif(1)
  if (is.null(seed))
    RNGstate <- get(".Random.seed", envir = .GlobalEnv)
  else {
    R.seed <- get(".Random.seed", envir = .GlobalEnv)
    set.seed(seed)
    RNGstate <- structure(seed, kind = as.list(RNGkind()))
    on.exit(assign(".Random.seed", R.seed, envir = .GlobalEnv))
  }
  
  # ..................................
  # determine window for simulation results
  if(!is.null(window)) {
    stopifnot(is.owin(window))
    win <- window
  } else {
    win <- as.owin(object)
  }
  # ..................................
  # determine parameters
  mp <- as.list(object$modelpar)

  # parameter 'mu'
  # = parent intensity of cluster process
  # = mean log intensity of log-Gaussian Cox process
  
  if(is.null(covariates) && (object$stationary || is.null(window))) {
    # use existing 'mu' (scalar or image)
    mu <- object$mu
  } else {
    # recompute 'mu' using new data
    switch(object$clusters,
           Cauchy=,
           VarGamma=,
           Thomas=,
           MatClust={
             # Poisson cluster process
             kappa <- mp$kappa
             lambda <- predict(object, window=win, covariates=covariates)
             mu <- eval.im(lambda/kappa)
           },
           LGCP={
             # log-Gaussian Cox process
             sigma2 <- mp$sigma2
             lambda <- predict(object, window=win, covariates=covariates)
             mu <- eval.im(log(lambda) - sigma2/2)
           },
           stop(paste("Simulation of", sQuote(object$clusters),
                      "processes is not yet implemented"))
           )
  }

  # prepare data for execution
  out <- list()
  switch(object$clusters,
         Thomas={
           kappa <- mp$kappa
           sigma <- mp$sigma
           cmd <- expression(rThomas(kappa,sigma,mu,win))
         },
         MatClust={
           kappa <- mp$kappa
           r     <- mp$R
           cmd   <- expression(rMatClust(kappa,r,mu,win))
         },
         Cauchy = {
           kappa <- mp$kappa
           omega <- mp$omega
           cmd   <- expression(rCauchy(kappa, omega, mu, win))
         },
         VarGamma = {
           kappa  <- mp$kappa
           omega  <- mp$omega
           nu.ker <- object$covmodel$margs$nu.ker
           cmd    <- expression(rVarGamma(kappa, nu.ker, omega, mu, win))
         },
         LGCP={
           sigma2 <- mp$sigma2
           alpha  <- mp$alpha
           cm <- object$covmodel
           model <- cm$model
           margs <- cm$margs
           param <- c(0, sigma2, 0, alpha, unlist(margs))
           if(!is.im(mu)) {
             # simulate in 'win'
             cmd <- expression(rLGCP(model=model, mu=mu, param=param,
                               ..., win=win))
           } else {
             # simulate in as.owin(mu), then change window
             cmd <- expression(rLGCP(model=model, mu=mu, param=param,
                               ...)[win])
           }
         })

  # run
  if(verbose)
    cat(paste("Generating", nsim, "simulations... "))
  for(i in 1:nsim) {
    out[[i]] <- try(eval(cmd))
    if(verbose) progressreport(i, nsim)
  }
  # detect failures
  if(any(bad <- unlist(lapply(out, inherits, what="try-error")))) {
    nbad <- sum(bad)
    gripe <- paste(nbad,
                   ngettext(nbad, "simulation was", "simulations were"),
                   "unsuccessful")
    if(verbose) cat(paste(gripe, "\n"))
    if(retry <= 0) {
      fate <- "returned as NULL"
      out[bad] <- list(NULL)
    } else {
      if(verbose) cat("Retrying...")
      ntried <- 0
      while(ntried < retry) {
        ntried <- ntried + 1
        for(j in which(bad))
          out[[j]] <- try(eval(cmd))
        bad <- unlist(lapply(out, inherits, what="try-error"))
        nbad <- sum(bad)
        if(nbad == 0) break
      }
      if(verbose) cat("Done.\n")
      fate <- if(nbad == 0) "all recomputed" else
              paste(nbad, "simulations still unsuccessful")
      fate <- paste(fate, "after", ntried,
                    ngettext(ntried, "further try", "further tries"))
    }
    warning(paste(gripe, fate, sep=": "))
  }
  if(verbose)
    cat("Done.\n")
  # pack up
  out <- as.listof(out)
  names(out) <- paste("Simulation", 1:nsim)
  attr(out, "seed") <- RNGstate
  out <- timed(out, starttime=starttime)
  return(out)
}

formula.kppm <- function(x, ...) {
  formula(x$po, ...)
}

terms.kppm <- function(x, ...) {
  terms(x$po, ...)
}

labels.kppm <- function(object, ...) {
  labels(object$po, ...)
}

update.kppm <- function(object, trend=~1, ..., clusters=NULL) {
  if(!missing(trend))
    trend <- update(formula(object), trend)
  if(is.null(clusters))
    clusters <- object$clusters
  out <- do.call(kppm,
                 resolve.defaults(list(trend=trend, clusters=clusters),
                                  list(...),
                                  list(X=object$X)))
  out$Xname <- object$Xname
  return(out)
}

unitname.kppm <- function(x) {
  return(unitname(x$X))
}

"unitname<-.kppm" <- function(x, value) {
  unitname(x$X) <- value
  if(!is.null(x$Fit$mcfit)) {
    unitname(x$Fit$mcfit) <- value
  } else if(is.null(x$Fit)) {
    warning("kppm object in outdated format")
    if(!is.null(x$mcfit))
      unitname(x$mcfit) <- value
  }
  return(x)
}

as.fv.kppm <- function(x) as.fv(x$Fit$mcfit)

coef.kppm <- function(object, ...) {
  return(coef(object$po))
}


Kmodel.kppm <- function(model, ...) {
  Kpcf.kppm(model, what="K")
}

pcfmodel.kppm <- function(model, ...) {
  Kpcf.kppm(model, what="pcf")
}

Kpcf.kppm <- function(model, what=c("K", "pcf")) {
  what <- match.arg(what)
  # Extract function definition from internal table
  clusters <- model$clusters
  tableentry <- spatstatClusterModelInfo(clusters)
  if(is.null(tableentry))
    stop("No information available for", sQuote(clusters), "cluster model")
  fun <- tableentry[[what]]
  if(is.null(fun))
    stop("No expression available for", what, "for", sQuote(clusters),
         "cluster model")
  # Extract model parameters
  par <- model$par
  # Extract auxiliary definitions (if applicable)
  funaux <- tableentry$funaux
  # Extract covariance model (if applicable)
  cm <- model$covmodel
  model <- cm$model
  margs <- cm$margs
  #
  f <- function(r) as.numeric(fun(par=par, rvals=r,
                                  funaux=funaux, model=model, margs=margs))
  return(f)
}

is.stationary.kppm <- function(x) {
  return(x$stationary)
}

is.poisson.kppm <- function(x) {
  switch(x$clusters,
         Cauchy=,
         VarGamma=,
         Thomas=,
         MatClust={
           # Poisson cluster process
           mu <- x$mu
           return(!is.null(mu) && (max(mu) == 0))
         },
         LGCP = {
           # log-Gaussian Cox process
           sigma2 <- x$par[["sigma2"]]
           return(sigma2 == 0)
         },
         return(FALSE))
}

# extract ppm component

as.ppm.kppm <- function(object) {
  object$po
}

# other methods that pass through to 'ppm'

as.owin.kppm <- function(W, ..., from=c("points", "covariates"), fatal=TRUE) {
  from <- match.arg(from)
  as.owin(as.ppm(W), ..., from=from, fatal=fatal)
}

domain.kppm <- Window.kppm <- function(X, ..., from=c("points", "covariates")) {
  from <- match.arg(from)
  as.owin(X, from=from)
}

model.images.kppm <- function(object, W=as.owin(object), ...) {
  model.images(as.ppm(object), W=W, ...)
}

model.matrix.kppm <- function(object, data=model.frame(object), ...,
                              Q=NULL, 
                              keepNA=TRUE) {
  if(missing(data)) data <- NULL
  model.matrix(as.ppm(object), data=data, ..., Q=Q, keepNA=keepNA)
}

model.frame.kppm <- function(formula, ...) {
  model.frame(as.ppm(formula), ...)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/layered.R"
#
# layered.R
#
# Simple mechanism for layered plotting
#
#  $Revision: 1.31 $  $Date: 2014/12/02 07:28:50 $
#

layered <- function(..., plotargs=NULL, LayerList=NULL) {
  argh <- list(...)
  if(length(argh) > 0 && !is.null(LayerList))
    stop("LayerList is incompatible with other arguments")
  out <- if(!is.null(LayerList)) LayerList else argh
  n <- length(out)
  if(sum(nzchar(names(out))) != n)
    names(out) <- paste("Layer", seq_len(n))
  if(is.null(plotargs)) {
    plotargs <- rep.int(list(list()), n)
  } else {
    if(!is.list(plotargs))
      stop("plotargs should be a list of lists")
    if(!all(unlist(lapply(plotargs, is.list))))
      plotargs <- list(plotargs)
    np <- length(plotargs)
    if(np == 1) plotargs <- rep(plotargs, n) else if(np != n)
      stop("plotargs should have one component for each element of the list")
  }
  names(plotargs) <- names(out)
  attr(out, "plotargs") <- plotargs
  class(out) <- c("layered", class(out))
  return(out)
}

print.layered <- function(x, ...) {
  splat("Layered object")
  if(length(x) == 0) splat("(no entries)")
  for(i in seq_along(x)) {
    cat(paste("\n", names(x)[i], ":\n", sep=""))
    print(x[[i]])
  }
  pl <- layerplotargs(x)
  hasplot <- (unlist(lapply(pl, length)) > 0)
  if(any(hasplot)) 
    splat("Includes plot arguments for", commasep(names(pl)[hasplot]))
  invisible(NULL)
}

plot.layered <- function(x, ..., which=NULL, plotargs=NULL,
                         add=FALSE, show.all=!add, main=NULL,
                         do.plot=TRUE) {
  if(is.null(main))
    main <- short.deparse(substitute(x))
  n <- length(x)
  if(!is.null(plotargs)) {
    np <- length(plotargs)
    if(!(is.list(plotargs) && all(unlist(lapply(plotargs, is.list)))))
      stop("plotargs should be a list of lists")
  }
  ## select layers
  if(!is.null(which)) {
    x <- x[which]
    nw <- length(x)
    if(!is.null(plotargs)) {
      if(np == n) plotargs <- plotargs[which] else
      if(np == 1) plotargs <- rep(plotargs, nw) else
      if(np != nw) 
        stop("plotargs should have one component for each layer to be plotted")
    }
    n <- nw
  } else if(!is.null(plotargs)) {
    if(np == 1) plotargs <- rep(plotargs, n) else
    if(np != n) stop("plotargs should have one component for each layer")
  }
  ## remove null layers
  if(any(isnul <- unlist(lapply(x, is.null)))) {
    x <- x[!isnul]
    if(!is.null(plotargs))
      plotargs <- plotargs[!isnul]
    n <- length(x)
  }
  ## anything to plot?
  if(n == 0)
    return(invisible(NULL))
  ## Merge plotting arguments
  xplotargs <- layerplotargs(x)
  if(is.null(plotargs)) {
    plotargs <- xplotargs
  } else if(length(xplotargs) > 0) {
    for(i in 1:n)
      plotargs[[i]] <- resolve.defaults(plotargs[[i]], xplotargs[[i]])
  }
  ## Determine bounding box
  a <- plotEachLayer(x, ..., plotargs=plotargs, add=add,
                     show.all=show.all, do.plot=FALSE)
  if(!do.plot)
    return(a)
  bb <- as.rectangle(as.owin(a))
  ## Start plotting
  if(!add && !is.null(bb)) {
    ## initialise new plot using bounding box
    pt <- prepareTitle(main)
    plot(bb, type="n", main=pt$blank)
    add <- TRUE
  }
  # plot the layers
  out <- plotEachLayer(x, ..., main=main,
                       plotargs=plotargs, add=add,
                       show.all=show.all, do.plot=TRUE)
  return(invisible(out))
}

plotEachLayer <- function(x, ..., main,
                          plotargs, add, show.all, do.plot=TRUE) {
  main.given <- !missing(main)
  ## do.plot=TRUE    =>   plot the layers 
  ## do.plot=FALSE   =>   determine bounding boxes
  out <- boxes <- list()
  nama <- names(x)
  firstlayer <- TRUE
  for(i in seq_along(x)) {
    xi <- x[[i]]
    if(length(xi) == 0) {
      # null layer - no plotting
      out[[i]] <- boxes[[i]] <- NULL
    } else {
      ## plot layer i on top of previous layers if any.
      ## By default,
      ##    - show all graphic elements of the first component only;
      ##    - show title 'firstmain' on first component;
      ##    - do not show any component names.
      add.i <- add || !firstlayer
      if(main.given) {
        main.i <- if(firstlayer) main else ""
      } else {
        show.all.i <- resolve.1.default(list(show.all=FALSE),
                                         list(...), 
                                         plotargs[[i]])
        main.i <- if(show.all.i) nama[i] else ""
      }
      dflt <- list(main=main.i,
                   show.all=show.all && firstlayer)
      pla.i <- plotargs[[i]]
      defaultplot <- !(".plot" %in% names(pla.i))
      ## plot layer i, or just determine bounding box
      if(defaultplot &&
         inherits(xi, c("ppp", "psp", "owin", "im", "msr", "layered"))) {
        ## plot method for 'xi' has argument 'do.plot'.
        out[[i]] <- outi <- do.call("plot",
                                    resolve.defaults(list(x=xi,
                                                          add=add.i,
                                                          do.plot=do.plot),
                                                     list(...),
                                                     pla.i,
                                                     dflt))
        boxes[[i]] <- as.rectangle(as.owin(outi))
      } else {
        ## plot method for 'xi' does not have argument 'do.plot'
        if(do.plot) {
          if(defaultplot) {
            plotfun <- "plot"
          } else {
            plotfun <- pla.i[[".plot"]]
            pla.i <- pla.i[names(pla.i) != ".plot"]
          }
          out[[i]] <- outi <- do.call(plotfun,
                                      resolve.defaults(list(x=xi,
                                                            add=add.i),
                                                       list(...),
                                                       pla.i,
                                                       dflt))
        }
        ## convert layer i to box
        boxi <- try(as.rectangle(xi), silent=TRUE)
        boxes[[i]] <- if(!inherits(boxi, "try-error")) boxi else NULL
      }
      firstlayer <- FALSE
    }
  }
  ## one box to bound them all
  if(!all(unlist(lapply(boxes, is.null))))
    attr(out, "bbox") <- do.call(boundingbox, boxes)
  return(out)
}


"[.layered" <- function(x, i, j, drop=FALSE, ...) {
  if(missing(i) && missing(j))
    return(x)
  p <- attr(x, "plotargs")
  x <- unclass(x)
  nx <- length(x)
  if(!missing(i) && !is.null(i)) {
    x <- x[i]
    p <- p[i]
    nx <- length(x)
  }
  isnul <- (unlist(lapply(x, length)) == 0)
  if(!missing(j) && !is.null(j))
    x[!isnul] <- lapply(x[!isnul], "[", i=j)
  if(drop && nx == 1)
    return(x[[1]])
  y <- layered(LayerList=x, plotargs=p)
  return(y)
}

"[[<-.layered" <- function(x, i, value) {
  x[i] <- if(!is.null(value)) list(value) else NULL
  return(x)
}

"[<-.layered" <- function(x, i, value) {
  p <- layerplotargs(x)
  ## invoke list method
  y <- x
  class(y) <- "list"
  y[i] <- value
  # make it a 'layered' object too
  class(y) <- c("layered", class(y))
  # update names and plotargs
  if(any(blank <- !nzchar(names(y)))) {
    names(y)[blank] <- paste("Layer", which(blank))
    pnew <- rep(list(list()), length(y))
    names(pnew) <- names(y)
    m <- match(names(y), names(x))
    mok <- !is.na(m)
    pnew[mok] <- p[m[mok]]
    layerplotargs(y) <- pnew
  } else layerplotargs(y) <- layerplotargs(x)[names(y)]
  return(y)
}

layerplotargs <- function(L) {
  stopifnot(inherits(L, "layered"))
  attr(L, "plotargs")
}

"layerplotargs<-" <- function(L, value) {
  if(!inherits(L, "layered"))
    L <- layered(L)
  if(!is.list(value))
    stop("Replacement value should be a list, or a list-of-lists")
  n <- length(L)
  if(!all(unlist(lapply(value, is.list)))) 
    value <- unname(rep(list(value), n))
  if(length(value) != n) {
    if(length(value) == 1) value <- unname(rep(value, n)) else
    stop("Replacement value is wrong length")
  }
  if(is.null(names(value))) names(value) <- names(L) else
  if(!identical(names(value), names(L)))
    stop("Mismatch in names of list elements")
  attr(L, "plotargs") <- value
  return(L)
}

applytolayers <- function(L, FUN, ...) {
  # Apply FUN to each **non-null** layer,
  # preserving the plot arguments
  pla <- layerplotargs(L)
  if(length(L) > 0) {
    ok <- !unlist(lapply(L, is.null))
    L[ok] <- lapply(L[ok], FUN, ...)
  }
  Z <- layered(LayerList=L, plotargs=pla)
  return(Z)
}
  
shift.layered <- function(X, vec=c(0,0), ...) {
  if(length(list(...)) > 0) {
    if(!missing(vec)) 
      warning("Argument vec ignored; overridden by other arguments")
    ## ensure the same shift is applied to all layers
    s <- shift(X[[1]], ...)
    vec <- getlastshift(s)
  }
  Y <- applytolayers(X, shift, vec=vec)
  attr(Y, "lastshift") <- vec
  return(Y)
}

affine.layered <- function(X, ...) {
  applytolayers(X, affine, ...)
}

rotate.layered <- function(X, ..., centre=NULL) {
  if(!is.null(centre)) {
    X <- shift(X, origin=centre)
    negorigin <- getlastshift(X)
  } else negorigin <- NULL
  Y <- applytolayers(X, rotate, ...)
  if(!is.null(negorigin))
    Y <- shift(Y, -negorigin)
  return(Y)
}

reflect.layered <- function(X) {
  applytolayers(X, reflect)
}

flipxy.layered <- function(X) {
  applytolayers(X, flipxy)
}

scalardilate.layered <- function(X, ...) {
  applytolayers(X, scalardilate, ...)
}
  
rescale.layered <- function(X, s, unitname) {
  if(missing(s)) s <- NULL
  if(missing(unitname)) unitname <- NULL
  applytolayers(X, rescale, s=s, unitname=unitname) 
}


as.owin.layered <- function(W, ..., fatal=TRUE) {
  if(length(W) == 0) {
    if(fatal) stop("Layered object is empty: no window data")
    return(NULL)
  }
  # remove null layers
  isnul <- unlist(lapply(W, is.null))
  W <- W[!isnul]
  if(length(W) == 0) {
    if(fatal) stop("Layered object has no window data")
    return(NULL)
  }
  Wlist <- lapply(unname(W), as.owin, ..., fatal=fatal)
  Wlist <- lapply(Wlist, rescue.rectangle)
  Z <- Wlist[[1]]
  if(length(Wlist) > 1) {
    same <- unlist(lapply(Wlist[-1], identical, y=Z))
    if(!all(same))
      Z <- do.call("union.owin", Wlist)
  }
  return(Z)
}

domain.layered <- Window.layered <- function(X, ...) { as.owin(X) }

as.layered <- function(X) {
  UseMethod("as.layered")
}

as.layered.default <- function(X) {
  layered(X)
}

as.layered.ppp <- function(X) {
  if(!is.marked(X)) return(layered(X))
  if(is.multitype(X)) return(layered(LayerList=split(X)))
  mX <- marks(X)
  if(!is.null(d <- dim(mX)) && d[2] > 1) {
    mx <- as.data.frame(marks(X))
    Y <- lapply(mx, function(z, P) setmarks(P,z), P=X)
    return(layered(LayerList=Y))
  }
  return(layered(X))
}


  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/lennard.R"
#
#
#    lennard.R
#
#    $Revision: 1.19 $	$Date: 2014/12/10 07:23:14 $
#
#    Lennard-Jones potential
#
#
# -------------------------------------------------------------------
#	

LennardJones <- local({

  BlankLJ <- 
    list(
         name     = "Lennard-Jones process",
         creator  = "LennardJones",
         family   = "pairwise.family",  # evaluated later
         pot      = function(d, par) {
           sig0 <- par$sigma0
           if(is.na(sig0)) {
             d6 <- d^{-6}
             p <- array(c(-d6^2,d6),dim=c(dim(d),2))
           } else {
             # expand around sig0 and set large numbers to Inf
             drat <- d/sig0
             d6 <- drat^{-6}
             p <- array(c(-d6^2,d6),dim=c(dim(d),2))
             small <- (drat < 1/4)
             small <- array(c(small, small), dim=c(dim(d), 2))
             p[small] <- -Inf
             big <- (drat > 4)
             big <- array(c(big, big), dim=c(dim(d), 2))
             p[big] <- 0
           }
           return(p)
         },
         par      = list(sigma0=NULL),  # filled in later
         parnames = "Initial approximation to sigma",
         selfstart = function(X, self) {
           # self starter for Lennard Jones
           # attempt to set value of 'sigma0'
           if(!is.na(self$par$sigma0)) {
             # value fixed by user or previous invocation
             return(self)
           }
           if(npoints(X) < 2) {
             # not enough points
             return(self)
           }
           s0 <- minnndist(X)
           if(s0 == 0) {
             warning(paste("Pattern contains duplicated points:",
                           "impossible under Lennard-Jones model"))
             s0 <- mean(nndist(X))
             if(s0 == 0)
               return(self)
           }
           LennardJones(s0)           
         },
         init     = function(...){}, # do nothing
         update = NULL, # default OK
         print = NULL,    # default OK
         interpret =  function(coeffs, self) {
           theta1 <- as.numeric(coeffs[1])
           theta2 <- as.numeric(coeffs[2])
           sig0 <- self$par$sigma0
           if(is.na(sig0))
             sig0 <- 1
           if(sign(theta1) * sign(theta2) == 1) {
             sigma <- sig0 * (theta1/theta2)^(1/6)
             epsilon <- (theta2^2)/(4 * theta1)
           } else {
             sigma <- NA
             epsilon <- NA
           }
           return(list(param=list(sigma=sigma, epsilon=epsilon),
                       inames="interaction parameters",
                       printable=signif(c(sigma=sigma,epsilon=epsilon))))
         },
         valid = function(coeffs, self) {
           p <- unlist(self$interpret(coeffs, self)$param)
           return(all(is.finite(p) & (p > 0)))
         },
         project = function(coeffs, self) {
           if((self$valid)(coeffs, self)) return(NULL) else return(Poisson())
         },
         irange = function(self, coeffs=NA, epsilon=0, ...) {
           if(any(is.na(coeffs)) || epsilon == 0)
             return(Inf)
           sig0 <- self$par$sigma0
           if(is.na(sig0)) sig0 <- 1
           theta1 <- abs(coeffs[1])
           theta2 <- abs(coeffs[2])
           return(sig0 * max((theta1/epsilon)^(1/12), (theta2/epsilon)^(1/6)))
         },
       version=NULL # filled in later
  )
  class(BlankLJ) <- "interact"

  LennardJones <- function(sigma0=NA) {
    if(is.null(sigma0) || !is.finite(sigma0))
      sigma0 <- NA
    instantiate.interact(BlankLJ, list(sigma0=sigma0))
  }

  LennardJones <- intermaker(LennardJones, BlankLJ)
  
  LennardJones
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/levelset.R"
# levelset.R
#
#  $Revision: 1.4 $  $Date: 2013/05/01 07:22:05 $
#
# level set of an image

levelset <- function(X, thresh, compare="<=") {
  # force X and thresh to be evaluated in this frame
  verifyclass(X, "im")
  thresh <- thresh
  switch(compare,
         "<"  = { A <- eval.im(X < thresh) },
         ">"  = { A <- eval.im(X > thresh) },
         "<=" = { A <- eval.im(X <= thresh) },
         ">=" = { A <- eval.im(X >= thresh) },
         "==" = { A <- eval.im(X == thresh) },
         "!=" = { A <- eval.im(X != thresh) },
         stop(paste("unrecognised comparison operator", sQuote(compare))))
  W <- as.owin(eval.im(ifelse1NA(A)))
  return(W)
}

# compute owin containing all pixels where image expression is TRUE

solutionset <- function(..., envir) {
  if(missing(envir))
    envir <- parent.frame()
  A <- eval.im(..., envir=envir)
  if(A$type != "logical")
    stop("Evaluating the expression did not yield a logical-valued image")
  W <- as.owin(eval.im(ifelse1NA(A)))
  return(W)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/leverage.R"
#
#  leverage.R
#
#  leverage and influence
#
#  $Revision: 1.45 $  $Date: 2014/10/07 05:01:05 $
#

leverage <- function(model, ...) {
  UseMethod("leverage")
}

leverage.ppm <- function(model, ...,
                         drop=FALSE, iScore=NULL, iHessian=NULL, iArgs=NULL)
{
  fitname <- short.deparse(substitute(model))
  u <- list(fitname=fitname, fit.is.poisson=is.poisson(model))
  s <- ppmInfluence(model, what="leverage", drop=drop,
                         iScore=iScore, iHessian=iHessian, iArgs=iArgs,
                         ...)
  a <- append(u, s)
  class(a) <- "leverage.ppm"
  return(a)
}

influence.ppm <- function(model, ...,
                          drop=FALSE, iScore=NULL, iHessian=NULL, iArgs=NULL)
{
  fitname <- short.deparse(substitute(model))
  u <- list(fitname=fitname, fit.is.poisson=is.poisson(model))
  s <- ppmInfluence(model, what="influence", drop=drop,
                         iScore=iScore, iHessian=iHessian, iArgs=iArgs,
                         ...)
  a <- append(u, s)
  class(a) <- "influence.ppm"
  return(a)
}

dfbetas.ppm <- function(model, ...,
                        drop=FALSE, iScore=NULL, iHessian=NULL, iArgs=NULL) {
  fitname <- short.deparse(substitute(model))
  u <- list(fitname=fitname, fit.is.poisson=is.poisson(model))
  s <- ppmInfluence(model, what="dfbetas", drop=drop,
                         iScore=iScore, iHessian=iHessian, iArgs=iArgs,
                     ...)
  a <- s$dfbetas
  attr(a, "info") <- u
  return(a)
}


ppmInfluence <- function(fit,
                          what=c("leverage", "influence", "dfbetas",
                            "derivatives", "increments"),
                          ..., iScore=NULL, iHessian=NULL, iArgs=NULL,
                          drop=FALSE,
                          method=c("C", "interpreted"),
                          precomputed=list()) {
  stopifnot(is.ppm(fit))
  what <- match.arg(what, several.ok=TRUE)
  method <- match.arg(method)
  if(is.null(iArgs))
    iArgs <- fit$covfunargs
  gotScore <- !is.null(iScore)
  gotHess <- !is.null(iHessian)
  influencecalc <- any(what %in% c("leverage", "influence", "dfbetas"))
  needHess <- gotScore && influencecalc
  if(!gotHess && needHess)
    stop("Must supply iHessian")
  if(fit$method == "logi" && !spatstat.options("allow.logi.influence"))
    stop("ppm influence measures are not yet implemented for method=logi")
  #
  # extract precomputed values if given
  theta  <- precomputed$coef   %orifnull% coef(fit)
  lam    <- precomputed$lambda %orifnull% fitted(fit, check=FALSE)
  mom    <- precomputed$mom    %orifnull% model.matrix(fit)
  # 
  p <- length(theta)
  vc <- vcov(fit, hessian=TRUE)
  fush <- hess <- solve(vc)
  Q <- quad.ppm(fit)
  # hess = negative hessian of log (pseudo) likelihood
  # fush = E(hess)
  # invhess = solve(hess)
  # vc = solve(fush)
  #
  w <- w.quad(Q)
  loc <- union.quad(Q)
  isdata <- is.data(Q)
  #
  if(length(w) != length(lam))
    stop(paste("Internal error: length(w) = ", length(w),
               "!=", length(lam), "= length(lam)\n"))
  # 
  # second order interaction terms
  # ddS[i,j, ] = Delta_i Delta_j S(x)
  ddS <- NULL
  if(!all(what == "derivatives") && !is.poisson(fit)) {
    ddS <- deltasuffstat(fit, dataonly=FALSE)
    if(is.null(ddS))
      warning("Second order interaction terms are not implemented for this model; they are treated as zero")
  }
  #
  # 
  ## evaluate additional (`irregular') components of score
  iscoremat <- ppmDerivatives(fit, "gradient", iScore, loc, covfunargs=iArgs)
  gotScore <- !is.null(iscoremat)
  needHess <- gotScore && influencecalc
  if(gotScore) {
    ## count regular and irregular parameters
    nreg <- ncol(mom)
    nirr <- ncol(iscoremat)
    ## add extra columns to model matrix
    mom <- cbind(mom, iscoremat)
    REG <- 1:nreg
    IRR <- nreg + 1:nirr
    ## add extra planes of zeroes to second-order model matrix
    ## (zero because the irregular components are part of the trend)
    if(!is.null(ddS)) {
      paddim <- c(dim(ddS)[1:2], nirr)
      ddS <- abind::abind(ddS, array(0, dim=paddim), along=3)
    }
    ## evaluate additional (`irregular') entries of Hessian
    ihessmat <- ppmDerivatives(fit, "hessian", iHessian, loc, covfunargs=iArgs)
    if(gotHess <- !is.null(ihessmat))
    ## recompute negative Hessian of log PL and its mean
    fush <- hessextra <- matrix(0, ncol(mom), ncol(mom))
    ## integral over domain
    switch(method,
           interpreted = {
             for(i in seq(loc$n)) {
               # weight for integrand
               wti <- lam[i] * w[i]
               if(all(is.finite(wti))) {
                 # integral of outer product of score 
                 momi <- mom[i, ]
                 v1 <- outer(momi, momi, "*") * wti
                 if(all(is.finite(v1)))
                   fush <- fush + v1
                 # integral of Hessian
                 # contributions nonzero for irregular parameters
                 if(gotHess) {
                   v2 <- matrix(as.numeric(ihessmat[i,]), nirr, nirr) * wti
                   if(all(is.finite(v2)))
                     hessextra[IRR, IRR] <- hessextra[IRR, IRR] + v2
                 }
               }
             }
             # subtract sum over data points
             if(gotHess) {
               for(i in which(isdata)) {
                 v2 <- matrix(as.numeric(ihessmat[i,]), nirr, nirr) 
                 if(all(is.finite(v2)))
                   hessextra[IRR, IRR] <- hessextra[IRR, IRR] - v2
               }
               hess <- fush + hessextra
               invhess <- solve(hess)
             } else {
               invhess <- hess <- NULL
             }
           },
           C = {
             wlam <- lam * w
             fush <- sumouter(mom, wlam)
             if(gotHess) {
               # integral term
               ok <- is.finite(wlam) & apply(is.finite(ihessmat), 1, all)
               vintegral <-
                 if(all(ok)) wlam %*% ihessmat else
                             wlam[ok] %*% ihessmat[ok,, drop=FALSE]
               # sum over data points
               vdata <- .colSums(ihessmat[isdata, , drop=FALSE],
                                 sum(isdata), ncol(ihessmat),
                                 na.rm=TRUE)
               vcontrib <- vintegral - vdata
               hessextra[IRR, IRR] <-
                 hessextra[IRR, IRR] + matrix(vcontrib, nirr, nirr)
               hess <- fush + hessextra
               invhess <- solve(hess)
             } else {
               invhess <- hess <- NULL
             }
           })
    vc <- solve(fush)
  } else {
    REG <- 1:ncol(mom)
  }
  
  if(!needHess) {
    hess <- fush
    invhess <- vc
  }
  #
  if(drop) {
    ok <- complete.cases(mom)
    Q <- Q[ok]
    mom <- mom[ok, , drop=FALSE]
    loc <- loc[ok]
    lam <- lam[ok]
    w   <- w[ok]
    isdata <- isdata[ok]
    if(!is.null(ddS)) ddS <- ddS[ok, ok, , drop=FALSE]
  }
  # ........  start assembling results .....................
  # 
  result <- list()
  # 
  if("derivatives" %in% what) {
    rawresid <- isdata - lam * w
    score <- matrix(rawresid, nrow=1) %*% mom
    result$deriv <- list(mom=mom, score=score,
                         fush=fush, vc=vc,
                         hess=hess, invhess=invhess)
  }
  if(all(what == "derivatives"))
    return(result)

  # compute effect of adding/deleting each quadrature point
  #    columns index the point being added/deleted
  #    rows index the points affected
  eff <- mom
  if(!is.poisson(fit) && !is.null(ddS)) {
    # effect of addition/deletion of U[j] on score contribution from data points
    ddSX <- ddS[isdata, , , drop=FALSE]
    eff.data <- apply(ddSX, c(2,3), sum)
    # model matrix after addition/deletion of each U[j]
    # mombefore[i,j,] <- mom[i,]
    di <- dim(ddS)
    mombefore <- array(apply(mom, 2, rep, times=di[2]), dim=di)
    changesign <- ifelse(isdata, -1, 1)
    momchange <- ddS
    momchange[ , isdata, ] <- - momchange[, isdata, ]
    momafter <- mombefore + momchange
    # effect of addition/deletion of U[j] on lambda(U[i], X)
    lamratio <- exp(tensor::tensor(momchange[,,REG], theta, 3, 1))
    lamratio <- array(lamratio, dim=dim(momafter))
    # integrate 
    ddSintegrand <- lam * (momafter * lamratio - mombefore)
    eff.back <- changesign * tensor::tensor(ddSintegrand, w, 1, 1)
    # total
    eff <- eff + eff.data - eff.back
  } else ddSintegrand <- NULL

  # 
  if("increments" %in% what) {
    result$increm <- list(ddS=ddS,
                          ddSintegrand=ddSintegrand,
                          isdata=isdata,
                          wQ=w)
  }
  if(!any(c("leverage", "influence", "dfbetas") %in% what))
    return(result)

  # ............ compute leverage, influence, dfbetas ..............
  
  # compute basic contribution from each quadrature point
  nloc <- npoints(loc)
  switch(method,
         interpreted = {
           b <- numeric(nloc)
           for(i in seq(nloc)) {
             effi <- eff[i,, drop=FALSE]
             momi <- mom[i,, drop=FALSE]
             b[i] <- momi %*% invhess %*% t(effi)
           }
         },
         C = {
           b <- bilinearform(mom, invhess, eff)
         })
  
  # .......... leverage .............
  
  if("leverage" %in% what) {
    # values of leverage (diagonal) at points of 'loc'
    h <- b * lam
    levval <- loc %mark% h
    levsmo <- Smooth(levval, sigma=maxnndist(loc))
    # nominal mean level
    a <- area(loc$window)
    levmean <- p/a
    lev <- list(val=levval, smo=levsmo, ave=levmean)
    result$lev <- lev
  }
  # .......... influence .............
  if("influence" %in% what) {
    # values of influence at data points
    X <- loc[isdata]
    M <- (1/p) * b[isdata]
    V <- X %mark% M
    result$infl <- V
  }
  # .......... dfbetas .............
  if("dfbetas" %in% what) {
    vex <- invhess %*% t(eff)
    switch(method,
           interpreted = {
             dis <- con <- matrix(0, nloc, ncol(mom))
             for(i in seq(nloc)) {
               vexi <- vex[,i, drop=FALSE]
               dis[i, ] <- isdata[i] * vexi
               con[i, ] <- - lam[i] * vexi
             }
           },
           C = {
             tvex <- t(vex)
             dis <- isdata * tvex
             con <- - lam  * tvex
           })
    colnames(dis) <- colnames(con) <- colnames(mom)
    result$dfbetas <- msr(Q, dis[isdata, ], con)
  }
  return(result)
}

## extract derivatives from covariate functions
## WARNING: these are not the score components in general

ppmDerivatives <- function(fit, what=c("gradient", "hessian"),
                            Dcovfun=NULL, loc, covfunargs=list()) {
  what <- match.arg(what)
  if(!is.null(Dcovfun)) {
    ## use provided function Dcov to compute derivatives
    Dvalues <- mpl.get.covariates(Dcovfun, loc, covfunargs=covfunargs)
    result <- as.matrix(as.data.frame(Dvalues))
    return(result)
  }
  ## any irregular parameters?
  if(length(covfunargs) == 0)
    return(NULL)
  ## Try to extract derivatives from covariate functions
  ## This often works if the functions were created by symbolic differentiation
  fvalues <- mpl.get.covariates(fit$covariates, loc, covfunargs=covfunargs,
                                need.deriv=TRUE)
  Dlist <- attr(fvalues, "derivatives")[[what]]
  if(length(Dlist) == 0)
    return(NULL)
  switch(what,
         gradient = {
           result <- do.call("cbind", unname(lapply(Dlist, as.data.frame)))
           result <- as.matrix(result)
         },
         hessian = {
           ## construct array containing Hessian matrices
           biga <- do.call(blockdiagarray, Dlist)
           ## flatten matrices 
           result <- matrix(biga, nrow=dim(biga)[1])
         })
  return(result)
}

plot.leverage.ppm <- function(x, ..., showcut=TRUE, col.cut=par("fg")) {
  fitname <- x$fitname
  defaultmain <- paste("Leverage for", fitname)
  y <- x$lev
  do.call("plot.im",
          resolve.defaults(list(y$smo),
                           list(...),
                           list(main=defaultmain)))
  if(showcut && diff(range(y$smo)) != 0) 
    do.call.matched("contour.im",
                    resolve.defaults(list(x=y$smo, levels=y$ave,
                                          add=TRUE, col=col.cut),
                                     list(...),
                                     list(drawlabels=FALSE)),
                    extrargs=c("levels", "drawlabels",
                      "labcex", "col", "lty", "lwd", "frameplot"))
  invisible(NULL)
}

plot.influence.ppm <- function(x, ...) {
  fitname <- x$fitname
  defaultmain <- paste("Influence for", fitname)
  do.call("plot.ppp",
          resolve.defaults(list(x$infl),
                           list(...),
                           list(main=defaultmain)))
}

as.im.leverage.ppm <- function(X, ...) {
  return(X$lev$smo)
}

as.ppp.influence.ppm <- function(X, ...) {
  return(X$infl)
}

as.owin.leverage.ppm <- function(W, ..., fatal=TRUE) {
  as.owin(as.im(W), ..., fatal=fatal)
}

as.owin.influence.ppm <- function(W, ..., fatal=TRUE) {
  as.owin(as.ppp(W), ..., fatal=fatal)
}

domain.leverage.ppm <- domain.influence.ppm <-
  Window.leverage.ppm <- Window.influence.ppm <-
  function(X, ...) { as.owin(X) } 

print.leverage.ppm <- function(x, ...) {
  cat("Point process leverage function\n")
  fitname <- x$fitname
  cat(paste("for model:", fitname, "\n"))
  lev <- x$lev
  cat("\nExact values:\n")
  print(lev$val)
  cat("\nSmoothed values:\n")
  print(lev$smo)
  ## for compatibility we retain the x$fit usage
  if(x$fit.is.poisson %orifnull% is.poisson(x$fit))
    cat(paste("\nAverage value:", lev$ave, "\n"))
  return(invisible(NULL))
}

print.influence.ppm <- function(x, ...) {
  cat("Point process influence measure\n")  
  fitname <- x$fitname
  cat(paste("for model:", fitname, "\n"))
  cat("\nExact values:\n")
  print(x$infl)
  return(invisible(NULL))
}

"[.leverage.ppm" <- function(x, i, ...) {
  if(missing(i)) return(x)
  y <- x$lev
  y$smo <- vi <- y$smo[i, ...]
  if(!is.im(vi)) return(vi)
  y$val <- y$val[i, ...]
  x$lev <- y
  return(x)
}

"[.influence.ppm" <- function(x, i, ...) {
  if(missing(i)) return(x)
  y <- x$infl[i, ...]
  if(!is.ppp(y)) return(y)
  x$infl <- y
  return(x)
}

shift.leverage.ppm <- function(X, ...) {
  vec <- getlastshift(shift(as.owin(X), ...))
  X$lev$val <- shift(X$lev$val, vec=vec)
  X$lev$smo <- shift(X$lev$smo, vec=vec)
  return(putlastshift(X, vec))
}

shift.influence.ppm <- function(X, ...) {
  X$infl <- shift(X$infl, ...)
  return(putlastshift(X, getlastshift(X$infl)))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/linalg.R"
#
# linalg.R
#
# $Revision: 1.8 $ $Date: 2014/10/24 00:22:30 $
#

sumouter <- function(x, w=NULL) {
  stopifnot(is.matrix(x))
  p <- ncol(x)
  n <- nrow(x)
  nama <- colnames(x)
  # transpose (compute outer squares of columns)
  tx <- t(x)
  ok <- apply(is.finite(tx), 2, all)
  if(!is.null(w)) {
    if(length(w) != n)
      stop(paste("The length of w does not match the number of rows of x",
                 "\t(", length(w), "!=", n, ")"))
    ok <- ok & is.finite(w)
  }
  if(!all(ok)) {
    tx <- tx[ , ok, drop=FALSE]
    if(!is.null(w)) w <- w[ok]
  }
  if(is.null(w)) {
    z <- .C("Csumouter",
            x=as.double(tx),
            n=as.integer(n),
            p=as.integer(p),
            y=as.double(numeric(p * p)))
  } else {
    z <- .C("Cwsumouter",
            x=as.double(tx),
            n=as.integer(n),
            p=as.integer(p),
            w=as.double(w),
            y=as.double(numeric(p * p)))
  }
  out <- matrix(z$y, p, p)
  if(!is.null(nama))
     dimnames(out) <- list(nama, nama)
  return(out)
}

quadform <- function(x, v) {
  stopifnot(is.matrix(x))
  p <- ncol(x)
  n <- nrow(x)
  nama <- rownames(x)
  # transpose (evaluate quadratic form for each column)
  tx <- t(x)
  ok <- apply(is.finite(tx), 2, all)
  allok <- all(ok)
  if(!allok) {
    tx <- tx[ , ok, drop=FALSE]
    n <- ncol(tx)
  }
  if(missing(v)) {
    v <- diag(rep.int(1, p))
  } else {
    stopifnot(is.matrix(v))
    if(nrow(v) != ncol(v)) stop("v should be a square matrix")
    stopifnot(ncol(x) == nrow(v))
  }
  z <- .C("Cquadform",
          x=as.double(tx),
          n=as.integer(n),
          p=as.integer(p),
          v=as.double(v),
          y=as.double(numeric(n)))
  result <- z$y
  names(result) <- nama[ok]
  if(allok)
    return(result)
  fullresult <- rep.int(NA_real_, length(ok))
  fullresult[ok] <- result
  names(fullresult) <- nama
  return(fullresult)
}

bilinearform <- function(x, v, y) {
  stopifnot(is.matrix(x))
  stopifnot(is.matrix(y))
  stopifnot(identical(dim(x), dim(y)))
  p <- ncol(x)
  n <- nrow(x)
  nama <- rownames(x)
  # transpose (evaluate quadratic form for each column)
  tx <- t(x)
  ty <- t(y)
  ok <- apply(is.finite(tx), 2, all) & apply(is.finite(ty), 2, all)
  allok <- all(ok)
  if(!allok) {
    tx <- tx[ , ok, drop=FALSE]
    ty <- ty[ , ok, drop=FALSE]
    n <- ncol(tx)
  }
  if(missing(v)) {
    v <- diag(rep.int(1, p))
  } else {
    stopifnot(is.matrix(v))
    if(nrow(v) != ncol(v)) stop("v should be a square matrix")
    stopifnot(ncol(x) == nrow(v))
  }
  z <- .C("Cbiform",
          x=as.double(tx),
          y=as.double(ty),
          n=as.integer(n),
          p=as.integer(p),
          v=as.double(v),
          z=as.double(numeric(n)))
  result <- z$z
  names(result) <- nama[ok]
  if(allok)
    return(result)
  fullresult <- rep.int(NA_real_, length(ok))
  fullresult[ok] <- result
  names(fullresult) <- nama
  return(fullresult)
}

sumsymouter <- function(x, w=NULL) {
  # computes the sum of outer(x[,i,j], x[,j,i]) * w[i,j] over all pairs i != j
  stopifnot(is.array(x) && length(dim(x)) == 3)
  if(dim(x)[2] != dim(x)[3])
    stop("The second and third dimensions of x should be equal")
  if(!is.null(w)) {
    stopifnot(is.matrix(w))
    if(!all(dim(w) == dim(x)[-1]))
      stop("Dimensions of w should match the second and third dimensions of x")
  }
  p <- dim(x)[1]
  n <- dim(x)[2]
  if(is.null(w)) {
    zz <- .C("Csumsymouter",
             x = as.double(x),
             p = as.integer(p),
             n = as.integer(n),
             y = as.double(numeric(p * p)))
  } else {
    zz <- .C("Cwsumsymouter",
             x = as.double(x),
             w = as.double(w),
             p = as.integer(p),
             n = as.integer(n),
             y = as.double(numeric(p * p)))
  }
  matrix(zz$y, p, p)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/linearK.R"
#
# linearK
#
# $Revision: 1.32 $ $Date: 2014/10/24 00:22:30 $
#
# K function for point pattern on linear network
#
#
linearK <- function(X, r=NULL, ..., correction="Ang") {
  stopifnot(inherits(X, "lpp"))
  correction <- pickoption("correction", correction,
                           c(none="none",
                             Ang="Ang",
                             best="Ang"),
                           multi=FALSE)
  # extract info about pattern
  sX <- summary(X)
  np <- sX$npoints
  lengthL <- sX$totlength
  # compute K
  denom <- np * (np - 1)/lengthL
  K <- linearKengine(X, r=r, denom=denom, correction=correction, ...)
  # set appropriate y axis label
  switch(correction,
         Ang  = {
           ylab <- quote(K[L](r))
           fname <- c("K", "L")
         },
         none = {
           ylab <- quote(K[net](r))
           fname <- c("K", "net")
         })
  K <- rebadge.fv(K, new.ylab=ylab, new.fname=fname)
  return(K)
}

linearKinhom <- function(X, lambda=NULL, r=NULL,  ...,
                         correction="Ang", normalise=TRUE) {
  stopifnot(inherits(X, "lpp"))
  correction <- pickoption("correction", correction,
                           c(none="none",
                             Ang="Ang",
                             best="Ang"),
                           multi=FALSE)
  if(is.null(lambda))
    linearK(X, r=r, ..., correction=correction)
  # extract info about pattern
  sX <- summary(X)
#  np <- sX$npoints
  lengthL <- sX$totlength
  #
  lambdaX <- getlambda.lpp(lambda, X, ...)
  #
  invlam <- 1/lambdaX
  invlam2 <- outer(invlam, invlam, "*")
  denom <- if(!normalise) lengthL else sum(invlam)
  K <- linearKengine(X, ...,
                     r=r, reweight=invlam2, denom=denom, correction=correction)
  # set appropriate y axis label
  switch(correction,
         Ang  = {
           ylab <- quote(K[L, inhom](r))
           fname <- c("K", "list(L, inhom)")
         },
         none = {
           ylab <- quote(K[net, inhom](r))
           fname <- c("K", "list(net, inhom)")
         })
  K <- rebadge.fv(K, new.fname=fname, new.ylab=ylab)
  return(K)
}

getlambda.lpp <- function(lambda, X, ...) {
  lambdaname <- deparse(substitute(lambda))
  XX <- as.ppp(X)
  lambdaX <-
    if(is.vector(lambda)) lambda  else
    if(is.function(lambda)) lambda(XX$x, XX$y, ...) else
    if(is.im(lambda)) safelookup(lambda, XX) else 
    if(inherits(lambda, "linim")) safelookup(as.im(lambda), XX) else 
    if(is.ppm(lambda) || inherits(lambda, "lppm"))
      predict(lambda, locations=as.data.frame(XX)) else
    stop(paste(lambdaname, "should be",
               "a numeric vector, function, pixel image, or fitted model"))

  if(!is.numeric(lambdaX))
    stop(paste("Values of", lambdaname, "are not numeric"))
  if((nv <- length(lambdaX)) != (np <- npoints(X)))
     stop(paste("Obtained", nv, "values of", lambdaname,
	   "but point pattern contains", np, "points"))
  if(any(lambdaX < 0))
    stop(paste("Negative values of", lambdaname, "obtained"))
  if(any(lambdaX == 0))
    stop(paste("Zero values of", lambdaname, "obtained"))

  return(lambdaX)
}

linearKengine <- function(X, ..., r=NULL, reweight=NULL, denom=1,
                          correction="Ang", showworking=FALSE) {
  # extract info about pattern
  sX <- summary(X)
  np <- sX$npoints
#  lengthL <- sX$totlength
  # extract linear network
  L <- X$domain
  # extract points
  Y <- as.ppp(X)
  W <- Y$window
  # determine r values
  rmaxdefault <- 0.98 * circumradius(L)
  breaks <- handle.r.b.args(r, NULL, W, rmaxdefault=rmaxdefault)
  r <- breaks$r
  rmax <- breaks$max
  #
  type <- if(correction == "Ang") "L" else "net"
  fname <- c("K", type)
  ylab <- substitute(K[type](r), list(type=type))
  #
  if(np < 2) {
    # no pairs to count: return zero function
    zeroes <- numeric(length(r))
    df <- data.frame(r = r, est = zeroes)
    K <- fv(df, "r", ylab,
            "est", . ~ r, c(0, rmax),
            c("r", makefvlabel(NULL, "hat", fname)), 
            c("distance argument r", "estimated %s"),
            fname = fname)
    return(K)
  }
  # compute pairwise distances  
  D <- pairdist(X)
  #---  compile into K function ---
  if(correction == "none" && is.null(reweight)) {
    # no weights (Okabe-Yamada)
    K <- compileK(D, r, denom=denom, fname=fname)
    K <- rebadge.fv(K, ylab, fname)
    unitname(K) <- unitname(X)
    return(K)
  }
  if(correction == "none")
     edgewt <- 1
  else {
     # inverse m weights (Wei's correction)
     # compute m[i,j]
     m <- matrix(1, np, np)
     for(j in 1:np) 
       m[ -j, j] <- countends(L, Y[-j], D[-j,j])
     if(any(uhoh <- (m == 0))) {
       warning("Internal error: disc boundary count equal to zero")
       m[uhoh] <- 1
     }
     edgewt <- 1/m
  }
  # compute K
  wt <- if(!is.null(reweight)) edgewt * reweight else edgewt
  K <- compileK(D, r, weights=wt, denom=denom, fname=fname)
  # tack on theoretical value
  K <- bind.fv(K, data.frame(theo=r),
               makefvlabel(NULL, NULL, fname, "theo"),
               "theoretical Poisson %s")
  K <- rebadge.fv(K, ylab, fname)
  unitname(K) <- unitname(X)
  fvnames(K, ".") <- rev(fvnames(K, "."))
  # show working
  if(showworking)
    attr(K, "working") <- list(D=D, wt=wt)
  attr(K, "correction") <- correction
  return(K)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/linearKmulti.R"
#
# linearKmulti
#
# $Revision: 1.5 $ $Date: 2014/11/10 10:45:42 $
#
# K functions for multitype point pattern on linear network
#
#

linearKdot <- function(X, i, r=NULL, ..., correction="Ang") {
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  marx <- marks(X)
  lev <- levels(marx)
  if(missing(i)) i <- lev[1] else
    if(!(i %in% lev)) stop(paste("i = ", i , "is not a valid mark"))  
  I <- (marx == i)
  J <- rep(TRUE, npoints(X))  # i.e. all points
  result <- linearKmulti(X, I, J,
                         r=r, correction=correction, ...)
  correction <- attr(result, "correction")
  type <- if(correction == "Ang") "L" else "net"
  result <- rebadge.as.dotfun(result, "K", type, i)
  return(result)
}

linearKcross <- function(X, i, j, r=NULL, ..., correction="Ang") {
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  marx <- marks(X)
  lev <- levels(marx)
  if(missing(i)) i <- lev[1] else
    if(!(i %in% lev)) stop(paste("i = ", i , "is not a valid mark"))
  if(missing(j)) j <- lev[2] else
    if(!(j %in% lev)) stop(paste("j = ", j , "is not a valid mark"))
  #
  if(i == j) {
    result <- linearK(X[marx == i], r=r, correction=correction, ...)
  } else {
    I <- (marx == i)
    J <- (marx == j)
    result <- linearKmulti(X, I, J, r=r, correction=correction, ...)
  }
  # rebrand
  correction <- attr(result, "correction")
  type <- if(correction == "Ang") "L" else "net"
  result <- rebadge.as.crossfun(result, "K", type, i, j)
  return(result)
}

linearKmulti <- function(X, I, J, r=NULL, ..., correction="Ang") {
  stopifnot(inherits(X, "lpp"))
  correction <- pickoption("correction", correction,
                           c(none="none",
                             Ang="Ang",
                             best="Ang"),
                           multi=FALSE)
  
  # extract info about pattern
  sX <- summary(X)
  np <- sX$npoints
  lengthL <- sX$totlength
  # validate I, J
  if(!is.logical(I) || !is.logical(J))
    stop("I and J must be logical vectors")
  if(length(I) != np || length(J) != np)
    stop(paste("The length of I and J must equal",
               "the number of points in the pattern"))
	
  if(!any(I)) stop("no points satisfy I")
#  if(!any(J)) stop("no points satisfy J")
		
  nI <- sum(I)
  nJ <- sum(J)
  nIandJ <- sum(I & J)
#  lambdaI <- nI/lengthL
#  lambdaJ <- nJ/lengthL
  # compute K
  denom <- (nI * nJ - nIandJ)/lengthL
  K <- linearKmultiEngine(X, I, J, r=r, denom=denom,
                          correction=correction, ...)
  # set appropriate y axis label
  correction <- attr(K, "correction")
  type <- if(correction == "Ang") "L" else "net"
  K <- rebadge.as.crossfun(K, "K", type, "I", "J")
  return(K)
}

# ................ inhomogeneous ............................

linearKdot.inhom <- function(X, i, lambdaI, lambdadot,
                             r=NULL, ..., correction="Ang", normalise=TRUE) {
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  marx <- marks(X)
  lev <- levels(marx)
  if(missing(i)) i <- lev[1] else
    if(!(i %in% lev)) stop(paste("i = ", i , "is not a valid mark"))  
  I <- (marx == i)
  J <- rep(TRUE, npoints(X))  # i.e. all points
  # for better error messages
  lambdadot <- getlambda.lpp(lambdadot, X, ...)
  # compute
  result <- linearKmulti.inhom(X, I, J, lambdaI, lambdadot, 
                               r=r, correction=correction, normalise=normalise,
                               ...)
  ## relabel
  correction <- attr(result, "correction")
  type <- if(correction == "Ang") "L, inhom" else "net, inhom"
  result <- rebadge.as.dotfun(result, "K", type, i)
  return(result)
}

linearKcross.inhom <- function(X, i, j, lambdaI, lambdaJ,
                               r=NULL, ...,
                               correction="Ang", normalise=TRUE) {
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  marx <- marks(X)
  lev <- levels(marx)
  if(missing(i)) i <- lev[1] else
    if(!(i %in% lev)) stop(paste("i = ", i , "is not a valid mark"))
  if(missing(j)) j <- lev[2] else
    if(!(j %in% lev)) stop(paste("j = ", j , "is not a valid mark"))
  #
  if(i == j) {
    I <- (marx == i)
    result <- linearKinhom(X[I], lambda=lambdaI, r=r,
                           correction=correction, normalise=normalise, ...)
  } else {
    I <- (marx == i)
    J <- (marx == j)
    result <- linearKmulti.inhom(X, I, J, lambdaI, lambdaJ,
                                 r=r, correction=correction,
                                 normalise=normalise, ...)
  }
  # rebrand
  correction <- attr(result, "correction")
  type <- if(correction == "Ang") "L, inhom" else "net, inhom"
  result <- rebadge.as.crossfun(result, "K", type, i, j)
  return(result)
}

linearKmulti.inhom <- function(X, I, J, lambdaI, lambdaJ,
                               r=NULL, ...,
                               correction="Ang", normalise=TRUE) {
  stopifnot(inherits(X, "lpp"))
  correction <- pickoption("correction", correction,
                           c(none="none",
                             Ang="Ang",
                             best="Ang"),
                           multi=FALSE)
  
  # extract info about pattern
  sX <- summary(X)
  np <- sX$npoints
  lengthL <- sX$totlength
  # validate I, J
  if(!is.logical(I) || !is.logical(J))
    stop("I and J must be logical vectors")
  if(length(I) != np || length(J) != np)
    stop(paste("The length of I and J must equal",
               "the number of points in the pattern"))
	
  if(!any(I)) stop("no points satisfy I")

  # validate lambda vectors
  lambdaI <- getlambda.lpp(lambdaI, X[I], ...)
  lambdaJ <- getlambda.lpp(lambdaJ, X[J], ...)

  # compute K
  weightsIJ <- outer(1/lambdaI, 1/lambdaJ, "*")
  denom <- if(!normalise) lengthL else sum(1/lambdaI)
  K <- linearKmultiEngine(X, I, J, r=r,
                          reweight=weightsIJ, denom=denom,
                          correction=correction, ...)
  # set appropriate y axis label
  correction <- attr(K, "correction")
  type <- if(correction == "Ang") "L, inhom" else "net, inhom"
  K <- rebadge.as.crossfun(K, "K", type, "I", "J")
  return(K)
}

# .............. internal ...............................

linearKmultiEngine <- function(X, I, J, ..., r=NULL, reweight=NULL, denom=1,
                          correction="Ang", showworking=FALSE) {
  # extract info about pattern
#  sX <- summary(X)
#  np <- sX$npoints
#  lengthL <- sX$totlength
  np <- npoints(X)
  # extract linear network
  L <- X$domain
  # extract points
  XP <- as.ppp(X)
  W <- as.owin(XP)
  # determine r values
  rmaxdefault <- 0.98 * circumradius(L)
  breaks <- handle.r.b.args(r, NULL, W, rmaxdefault=rmaxdefault)
  r <- breaks$r
  rmax <- breaks$max
  #
  if(correction == "Ang") {
    fname <- c("K", "list(L, I, J)")
    ylab <- quote(K[L,I,J](r))
  } else {
    fname <- c("K", "list(net, I, J)")
    ylab <- quote(K[net,I,J](r))
  }
  #
  if(np < 2) {
    # no pairs to count: return zero function
    zeroes <- rep(0, length(r))
    df <- data.frame(r = r, est = zeroes)
    K <- fv(df, "r", ylab,
            "est", . ~ r, c(0, rmax),
            c("r", makefvlabel(NULL, "hat", fname)),
            c("distance argument r", "estimated %s"),
            fname = fname)
    return(K)
  }
  #
  nI <- sum(I)
  nJ <- sum(J)
  whichI <- which(I)
  whichJ <- which(J)
  clash <- I & J
  has.clash <- any(clash)
  # compute pairwise distances
  if(exists("crossdist.lpp")) {
    DIJ <- crossdist(X[I], X[J], check=FALSE)
    if(has.clash) {
      # exclude pairs of identical points from consideration
      Iclash <- which(clash[I])
      Jclash <- which(clash[J])
      DIJ[cbind(Iclash,Jclash)] <- Inf
    }
  } else {
    D <- pairdist(X)
    diag(D) <- Inf
    DIJ <- D[I, J]
  }
  #---  compile into K function ---
  if(correction == "none" && is.null(reweight)) {
    # no weights (Okabe-Yamada)
    K <- compileK(DIJ, r, denom=denom, check=FALSE, fname=fname)
    K <- rebadge.as.crossfun(K, "K", "net", "I", "J")
    unitname(K) <- unitname(X)
    attr(K, "correction") <- correction
    return(K)
  }
  if(correction == "none")
     edgewt <- 1
  else {
     # inverse m weights (Ang's correction)
     # compute m[i,j]
     m <- matrix(1, nI, nJ)
     XPI <- XP[I]
     if(!has.clash) {
       for(k in seq_len(nJ)) {
         j <- whichJ[k]
         m[,k] <- countends(L, XPI, DIJ[, k])
       }
     } else {
       # don't count identical pairs
       for(k in seq_len(nJ)) {
         j <- whichJ[k]
         inotj <- (whichI != j)
         m[inotj, k] <- countends(L, XPI[inotj], DIJ[inotj, k])
       }
     }
     edgewt <- 1/m
  }
  # compute K
  wt <- if(!is.null(reweight)) edgewt * reweight else edgewt
  K <- compileK(DIJ, r, weights=wt, denom=denom, check=FALSE, fname=fname)
  ## rebadge and tweak
  K <- rebadge.as.crossfun(K, "K", "L", "I", "J")
  fname <- attr(K, "fname")
  # tack on theoretical value
  K <- bind.fv(K, data.frame(theo=r),
               makefvlabel(NULL, NULL, fname, "pois"),
               "theoretical Poisson %s")
  ## 
  unitname(K) <- unitname(X)
  fvnames(K, ".") <- rev(fvnames(K, "."))
  # show working
  if(showworking)
    attr(K, "working") <- list(DIJ=DIJ, wt=wt)
  attr(K, "correction") <- correction
  return(K)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/lineardisc.R"
#
#
#   disc.R
#
#   $Revision: 1.19 $ $Date: 2014/11/10 05:39:57 $
#
#   Compute the disc of radius r in a linear network
#
#   
lineardisc <- function(L, x=locator(1), r, plotit=TRUE,
                       cols=c("blue", "red", "green")) {
  # L is the linear network (object of class "linnet")
  # x is the centre point of the disc
  # r is the radius of the disc
  #
  stopifnot(inherits(L, "linnet"))
  check.1.real(r)
  lines <- L$lines
  vertices <- L$vertices
  lengths <- lengths.psp(lines)
  win <- L$window
  #
  # project x to nearest segment
  if(missing(x))
    x <- clickppp(1, win, add=TRUE)
  else
    x <- as.ppp(x, win)
  pro <- project2segment(x, lines)
  # which segment?
  startsegment <- pro$mapXY
  # parametric position of x along this segment
  startfraction <- pro$tp
  # vertices at each end of this segment
  A <- L$from[startsegment]
  B <- L$to[startsegment]
  # distances from x to  A and B
  dxA <- startfraction * lengths[startsegment]
  dxB <- (1-startfraction) * lengths[startsegment]
  # is r large enough to reach both A and B?
  startfilled <- (max(dxA, dxB) <= r)
  # compute vector of shortest path distances from x to each vertex j,
  # going through A:
  dxAv <- dxA + L$dpath[A,]
  # going through B:
  dxBv <- dxB + L$dpath[B,]
  # going either through A or through B:
  dxv <- pmin.int(dxAv, dxBv)
  # Thus dxv[j] is the shortest path distance from x to vertex j.
  #
  # Determine which vertices are inside the disc of radius r
  covered <- (dxv <= r)
  # Thus covered[j] is TRUE if the j-th vertex is inside the disc.
  #
  # Determine which line segments are completely inside the disc
  #
  from <- L$from
  to   <- L$to
  # ( a line segment is inside the disc if the shortest distance
  #   from x to one of its endpoints, plus the length of the segment,
  #   is less than r ....
  allinside <- (dxv[from] + lengths <= r) | (dxv[to] + lengths <= r)
  #   ... or alternatively, if the sum of the
  #   two residual distances exceeds the length of the segment )
  residfrom <- pmax.int(0, r - dxv[from])
  residto   <- pmax.int(0, r - dxv[to])
  allinside <- allinside | (residfrom + residto >= lengths)
  # start segment is special
  allinside[startsegment] <- startfilled
  # Thus allinside[k] is TRUE if the k-th segment is inside the disc
  
  # Collect all these segments
  disclines <- lines[allinside]
  #
  # Determine which line segments cross the boundary of the disc
  boundary <- (covered[from] | covered[to]) & !allinside
  # For each of these, calculate the remaining distance at each end
  resid.from <- ifelseXB(boundary, pmax.int(r - dxv[from], 0), 0)
  resid.to   <- ifelseXB(boundary, pmax.int(r - dxv[to],   0), 0)
  # Where the remaining distance is nonzero, create segment and endpoint
  okfrom <- (resid.from > 0)
  okfrom[startsegment] <- FALSE
  if(any(okfrom)) {
    v0 <- vertices[from[okfrom]]
    v1 <- vertices[to[okfrom]]
    tp <- (resid.from/lengths)[okfrom]
    vfrom <- ppp((1-tp)*v0$x + tp*v1$x,
                 (1-tp)*v0$y + tp*v1$y,
                 window=win)
    extralinesfrom <- as.psp(from=v0, to=vfrom)
  } else vfrom <- extralinesfrom <- NULL
  #
  okto <- (resid.to > 0)
  okto[startsegment] <- FALSE
  if(any(okto)) {
    v0 <- vertices[to[okto]]
    v1 <- vertices[from[okto]]
    tp <- (resid.to/lengths)[okto]
    vto <- ppp((1-tp)*v0$x + tp*v1$x,
               (1-tp)*v0$y + tp*v1$y,
               window=win)
    extralinesto <- as.psp(from=v0, to=vto)
  } else vto <- extralinesto <- NULL
  #
  # deal with special case where start segment is not fully covered
  if(!startfilled) {
    vA <- vertices[A]
    vB <- vertices[B]
    rfrac <- r/lengths[startsegment]
    tleft <- pmax.int(startfraction-rfrac, 0)
    tright <- pmin.int(startfraction+rfrac, 1)
    vleft <- ppp((1-tleft) * vA$x + tleft * vB$x,
                 (1-tleft) * vA$y + tleft * vB$y,
                 window=win)
    vright <- ppp((1-tright) * vA$x + tright * vB$x,
                  (1-tright) * vA$y + tright * vB$y,
                  window=win)
    startline <- as.psp(from=vleft, to=vright)
    startends <- superimpose(if(!covered[A]) vleft else NULL,
                             if(!covered[B]) vright else NULL)
  } else startline <- startends <- NULL
  #
  # combine all lines
  disclines <- superimpose(disclines,
                           extralinesfrom, extralinesto, startline,
                           W=win, check=FALSE)
  # combine all disc endpoints
  discends <- superimpose(vfrom, vto, vertices[dxv == r], startends,
                          W=win, check=FALSE)
  #
  if(plotit) {
    if(dev.cur() == 1) {
      # null device - initialise a plot
      plot(L, main="")
    }
    points(x, col=cols[1], pch=16)
    plot(disclines, add=TRUE, col=cols[2], lwd=2)
    plot(discends, add=TRUE, col=cols[3], pch=16)
  }
  return(list(lines=disclines, endpoints=discends))
}

countends <- function(L, x=locator(1), r) {
  # L is the linear network (object of class "linnet")
  # x is the centre point of the disc
  # r is the radius of the disc
  #
  stopifnot(inherits(L, "linnet"))
  lines <- L$lines
  vertices <- L$vertices
  lengths <- lengths.psp(lines)
  dpath <- L$dpath
  win <- L$window
  nv <- vertices$n
  ns <- lines$n
  # get x
  if(missing(x))
    x <- clickppp(1, win, add=TRUE)
  else
    x <- as.ppp(x, win)
  #
  np <- npoints(x)
  if(length(r) != np)
    stop("Length of vector r does not match number of points in x")
  # project x to nearest segment
  pro <- project2segment(x, lines)
  # which segment?
  startsegment <- pro$mapXY
  # parametric position of x along this segment
  startfraction <- pro$tp

  # convert indices to C 
  seg0 <- startsegment - 1L
  from0 <- L$from - 1L
  to0   <- L$to - 1L
  toler <- 0.001 * min(lengths)
  zz <- .C("Ccountends",
           np = as.integer(np),
           f = as.double(startfraction),
           seg = as.integer(seg0),
           r = as.double(r), 
           nv = as.integer(nv), 
           xv = as.double(vertices$x),
           yv = as.double(vertices$y),  
           ns = as.integer(ns),
           from = as.integer(from0),
           to = as.integer(to0), 
           dpath = as.double(dpath),
           lengths = as.double(lengths),
           toler=as.double(toler),
           nendpoints = as.integer(integer(np)))
  zz$nendpoints
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/linearmrkcon.R"
#
# linearmrkcon.R
#
# mark connection function & mark equality function for linear networks
#
# $Revision: 1.1 $ $Date: 2014/02/17 01:44:38 $
#

linearmarkconnect <- function(X, i, j, r=NULL, ...) {
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  marx <- marks(X)
  lev <- levels(marx)
  if(missing(i) || is.null(i)) i <- lev[1] else
    if(!(i %in% lev)) stop(paste("i = ", i , "is not a valid mark"))
  if(missing(j) || is.null(j)) j <- lev[2] else
    if(!(j %in% lev)) stop(paste("j = ", j , "is not a valid mark"))

  pcfij <- linearpcfcross(X, i, j, r=r, ...)
  pcfall <- linearpcf(X, r=r, ...)

  qi <- mean(marx == i)
  qj <- mean(marx == j)

  result <- eval.fv(qi * qj * pcfij/pcfall)
  
  # rebrand
  result <- rebadge.as.crossfun(result, "p", "L", i, j)
  attr(result, "labl") <- attr(pcfij, "labl")
  return(result)
}

linearmarkequal <- function(X, r=NULL, ...) {
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  lev <- levels(marks(X))

  v <- list()
  for(l in lev) v[[l]] <- linearmarkconnect(X, l, l, r=r, ...)

  result <- Reduce(function(A,B){eval.fv(A+B)}, v)
  result <-rebadge.fv(result, 
                      quote(p[L](r)),
                      new.fname=c("p", "L"))
  attr(result, "labl") <- attr(v[[1]], "labl")
  return(result)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/linearpcf.R"
#
# linearpcf.R
#
# $Revision: 1.11 $ $Date: 2014/11/10 10:46:54 $
#
# pair correlation function for point pattern on linear network
#
#
linearpcf <- function(X, r=NULL, ..., correction="Ang") {
  stopifnot(inherits(X, "lpp"))
  correction <- pickoption("correction", correction,
                           c(none="none",
                             Ang="Ang",
                             best="Ang"),
                           multi=FALSE)
  # extract info about pattern
  sX <- summary(X)
  np <- sX$npoints
  lengthL <- sX$totlength
  # compute
  denom <- np * (np - 1)/lengthL
  g <- linearpcfengine(X, r=r, ..., denom=denom, correction=correction)
  # set appropriate y axis label
  switch(correction,
         Ang  = {
           ylab <- quote(g[L](r))
           fname <- c("g", "L")
         },
         none = {
           ylab <- quote(g[net](r))
           fname <- c("g", "net")
         })
  g <- rebadge.fv(g, new.ylab=ylab, new.fname=fname)
  return(g)
}

linearpcfinhom <- function(X, lambda=NULL, r=NULL,  ...,
                           correction="Ang", normalise=TRUE) {
  stopifnot(inherits(X, "lpp"))
  correction <- pickoption("correction", correction,
                           c(none="none",
                             Ang="Ang",
                             best="Ang"),
                           multi=FALSE)
  if(is.null(lambda))
    linearpcf(X, r=r, ..., correction=correction)
  # extract info about pattern
  sX <- summary(X)
  np <- sX$npoints
  lengthL <- sX$totlength
  #
  XX <- as.ppp(X)
  lambdaX <-
    if(is.vector(lambda)) lambda  else
    if(is.function(lambda)) lambda(XX$x, XX$y, ...) else
    if(is.im(lambda)) safelookup(lambda, XX) else 
    if(is.ppm(lambda) || inherits(lambda, "lppm"))
      predict(lambda, locations=as.data.frame(XX)) else
    stop("lambda should be a numeric vector, function, image or ppm object")

  if(!is.numeric(lambdaX))
    stop("Values of lambda are not numeric")
  if((nv <- length(lambdaX)) != np)
     stop(paste("Obtained", nv, "values of lambda",
	   "but point pattern contains", np, "points"))
  if(any(lambdaX < 0))
    stop("Negative values of lambda obtained")
  if(any(lambdaX == 0))
    stop("Zero values of lambda obtained")

  invlam <- 1/lambdaX
  invlam2 <- outer(invlam, invlam, "*")
  denom <- if(!normalise) lengthL else sum(invlam)
  g <- linearpcfengine(X, ..., r=r,
                       reweight=invlam2, denom=denom, correction=correction)
  # extract bandwidth
  bw <- attr(g, "bw")
  # set appropriate y axis label
  switch(correction,
         Ang  = {
           ylab <- quote(g[L, inhom](r))
           fname <- c("g", "list(L, inhom)")
         },
         none = {
           ylab <- quote(g[net, inhom](r))
           fname <- c("g", "list(net, inhom)")
         })
  g <- rebadge.fv(g, new.fname=fname, new.ylab=ylab)
  # reattach bandwidth
  attr(g, "bw") <- bw
  return(g)
}


linearpcfengine <- function(X, ..., r=NULL,
                            reweight=NULL, denom=1, correction="Ang") {
  # extract info about pattern
#  sX <- summary(X)
#  np <- sX$npoints
#  lengthL <- sX$totlength
  np <- npoints(X)
  # extract linear network
  L <- X$domain
  # extract points
  Y <- as.ppp(X)
  W <- Y$window
  # determine r values
  rmaxdefault <- 0.98 * circumradius(L)
  breaks <- handle.r.b.args(r, NULL, W, rmaxdefault=rmaxdefault)
  r <- breaks$r
  rmax <- breaks$max
  #
  type <- if(correction == "Ang") "L" else "net"
  fname <- c("g", type)
  ylab <- substitute(g[type](r), list(type=type))
  #  
  if(np < 2) {
    # no pairs to count: return zero function
    zeroes <- numeric(length(r))
    df <- data.frame(r = r, est = zeroes)
    g <- fv(df, "r", ylab,
            "est", . ~ r, c(0, rmax),
            c("r", makefvlabel(NULL, "hat", fname)), 
            c("distance argument r", "estimated %s"),
            fname = fname)
    return(g)
  }
  # compute pairwise distances  
  D <- pairdist(X)
  #---  compile into pcf ---
  if(correction == "none" && is.null(reweight)) {
    # no weights (Okabe-Yamada)
    g <- compilepcf(D, r, denom=denom, fname=fname)
    unitname(g) <- unitname(X)
    attr(g, "correction") <- correction
    return(g)
  }
  if(correction == "none")
     edgewt <- 1
  else {
     # inverse m weights (Wei's correction)
     # compute m[i,j]
     m <- matrix(1, np, np)
     for(j in 1:np) 
       m[ -j, j] <- countends(L, Y[-j], D[-j,j])
     edgewt <- 1/m
  }
  # compute pcf
  wt <- if(!is.null(reweight)) edgewt * reweight else edgewt
  g <- compilepcf(D, r, weights=wt, denom=denom, ..., fname=fname)
  # extract bandwidth
  bw <- attr(g, "bw")
  # tack on theoretical value
  g <- bind.fv(g, data.frame(theo=rep.int(1,length(r))),
               makefvlabel(NULL, NULL, fname, "pois"),
               "theoretical Poisson %s")
  # tweak
  unitname(g) <- unitname(X)
  fvnames(g, ".") <- rev(fvnames(g, "."))
  # tack on bandwidth again
  attr(g, "bw") <- bw
  attr(g, "correction") <- correction
  return(g)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/linearpcfmulti.R"
#
# linearpcfmulti.R
#
# $Revision: 1.4 $ $Date: 2014/11/10 10:49:57 $
#
# pair correlation functions for multitype point pattern on linear network
#
#

linearpcfdot <- function(X, i, r=NULL, ..., correction="Ang") {
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  marx <- marks(X)
  lev <- levels(marx)
  if(missing(i) || is.null(i)) i <- lev[1] else
    if(!(i %in% lev)) stop(paste("i = ", i , "is not a valid mark"))  
  I <- (marx == i)
  J <- rep(TRUE, npoints(X))  # i.e. all points
  result <- linearpcfmulti(X, I, J,
                           r=r, correction=correction, ...)
  correction <- attr(result, "correction")
  type <- if(correction == "Ang") "L" else "net"
  result <- rebadge.as.dotfun(result, "g", type, i)
  return(result)
}

linearpcfcross <- function(X, i, j, r=NULL, ..., correction="Ang") {
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  marx <- marks(X)
  lev <- levels(marx)
  if(missing(i) || is.null(i)) i <- lev[1] else
    if(!(i %in% lev)) stop(paste("i = ", i , "is not a valid mark"))
  if(missing(j) || is.null(j)) j <- lev[2] else
    if(!(j %in% lev)) stop(paste("j = ", j , "is not a valid mark"))
  #
  if(i == j) {
    result <- linearpcf(X[marx == i], r=r, correction=correction, ...)
  } else {
    I <- (marx == i)
    J <- (marx == j)
    result <- linearpcfmulti(X, I, J, r=r, correction=correction, ...)
  }
  # rebrand
  correction <- attr(result, "correction")
  type <- if(correction == "Ang") "L" else "net"
  result <- rebadge.as.crossfun(result, "g", type, i, j)
  return(result)
}

linearpcfmulti <- function(X, I, J, r=NULL, ..., correction="Ang") {
  stopifnot(inherits(X, "lpp"))
  correction <- pickoption("correction", correction,
                           c(none="none",
                             Ang="Ang",
                             best="Ang"),
                           multi=FALSE)
  
  # extract info about pattern
  sX <- summary(X)
  np <- sX$npoints
  lengthL <- sX$totlength
  # validate I, J
  if(!is.logical(I) || !is.logical(J))
    stop("I and J must be logical vectors")
  if(length(I) != np || length(J) != np)
    stop(paste("The length of I and J must equal",
               "the number of points in the pattern"))
	
  if(!any(I)) stop("no points satisfy I")
#  if(!any(J)) stop("no points satisfy J")
		
  nI <- sum(I)
  nJ <- sum(J)
  nIandJ <- sum(I & J)
#  lambdaI <- nI/lengthL
#  lambdaJ <- nJ/lengthL
  # compute pcf
  denom <- (nI * nJ - nIandJ)/lengthL
  g <- linearPCFmultiEngine(X, I, J, r=r, denom=denom, correction=correction, ...)
  # set appropriate y axis label
  correction <- attr(g, "correction")
  type <- if(correction == "Ang") "L" else "net"
  g <- rebadge.as.crossfun(g, "g", type, "I", "J")
  attr(g, "correction") <- correction
  return(g)
}

# ................ inhomogeneous ............................

linearpcfdot.inhom <- function(X, i, lambdaI, lambdadot,
                             r=NULL, ..., correction="Ang", normalise=TRUE) {
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  marx <- marks(X)
  lev <- levels(marx)
  if(missing(i)) i <- lev[1] else
    if(!(i %in% lev)) stop(paste("i = ", i , "is not a valid mark"))  
  I <- (marx == i)
  J <- rep(TRUE, npoints(X))  # i.e. all points
  # for better error messages
  lambdadot <- getlambda.lpp(lambdadot, X, ...)
  # compute
  result <- linearpcfmulti.inhom(X, I, J, lambdaI, lambdadot, 
                               r=r, correction=correction, normalise=normalise,
                               ...)
  correction <- attr(result, "correction")
  type <- if(correction == "Ang") "L, inhom" else "net, inhom"
  result <- rebadge.as.dotfun(result, "g", type, i)
  return(result)
}

linearpcfcross.inhom <- function(X, i, j, lambdaI, lambdaJ,
                               r=NULL, ...,
                               correction="Ang", normalise=TRUE) {
  if(!is.multitype(X, dfok=FALSE)) 
	stop("Point pattern must be multitype")
  marx <- marks(X)
  lev <- levels(marx)
  if(missing(i)) i <- lev[1] else
    if(!(i %in% lev)) stop(paste("i = ", i , "is not a valid mark"))
  if(missing(j)) j <- lev[2] else
    if(!(j %in% lev)) stop(paste("j = ", j , "is not a valid mark"))
  #
  if(i == j) {
    I <- (marx == i)
    result <- linearpcfinhom(X[I], lambda=lambdaI, r=r,
                           correction=correction, normalise=normalise, ...)
  } else {
    I <- (marx == i)
    J <- (marx == j)
    result <- linearpcfmulti.inhom(X, I, J, lambdaI, lambdaJ,
                                 r=r, correction=correction,
                                 normalise=normalise, ...)
  }
  # rebrand
  correction <- attr(result, "correction")
  type <- if(correction == "Ang") "L, inhom" else "net, inhom"
  result <- rebadge.as.crossfun(result, "g", type, i, j)
  return(result)
}

linearpcfmulti.inhom <- function(X, I, J, lambdaI, lambdaJ,
                               r=NULL, ...,
                               correction="Ang", normalise=TRUE) {
  stopifnot(inherits(X, "lpp"))
  correction <- pickoption("correction", correction,
                           c(none="none",
                             Ang="Ang",
                             best="Ang"),
                           multi=FALSE)
  
  # extract info about pattern
  sX <- summary(X)
  np <- sX$npoints
  lengthL <- sX$totlength
  # validate I, J
  if(!is.logical(I) || !is.logical(J))
    stop("I and J must be logical vectors")
  if(length(I) != np || length(J) != np)
    stop(paste("The length of I and J must equal",
               "the number of points in the pattern"))
	
  if(!any(I)) stop("no points satisfy I")

  # validate lambda vectors
  lambdaI <- getlambda.lpp(lambdaI, X[I], ...)
  lambdaJ <- getlambda.lpp(lambdaJ, X[J], ...)

  # compute pcf
  weightsIJ <- outer(1/lambdaI, 1/lambdaJ, "*")
  denom <- if(!normalise) lengthL else sum(1/lambdaI)
  g <- linearPCFmultiEngine(X, I, J, r=r,
                            reweight=weightsIJ, denom=denom,
                            correction=correction, ...)
  # set appropriate y axis label
  correction <- attr(g, "correction")
  type <- if(correction == "Ang") "L, inhom" else "net, inhom"
  g <- rebadge.as.crossfun(g, "g", type, "I", "J")
  attr(g, "correction") <- correction
  return(g)
}

# .............. internal ...............................

linearPCFmultiEngine <- function(X, I, J, ..., r=NULL, reweight=NULL, denom=1,
                          correction="Ang", showworking=FALSE) {
  # extract info about pattern
#  sX <- summary(X)
#  np <- sX$npoints
#  lengthL <- sX$totlength
  np <- npoints(X)
  # extract linear network
  L <- X$domain
  # extract points
  XP <- as.ppp(X)
  W <- as.owin(XP)
  # determine r values
  rmaxdefault <- 0.98 * circumradius(L)
  breaks <- handle.r.b.args(r, NULL, W, rmaxdefault=rmaxdefault)
  r <- breaks$r
  rmax <- breaks$max
  #
  if(correction == "Ang") {
    fname <- c("g", "list(L, I, J)")
    ylab <- quote(g[L,I,J](r))
  } else {
    fname <- c("g", "list(net, I, J)")
    ylab <- quote(g[net,I,J](r))
  }
  #
   if(np < 2) {
    # no pairs to count: return zero function
    zeroes <- rep(0, length(r))
    df <- data.frame(r = r, est = zeroes)
    g <- fv(df, "r", ylab,
            "est", . ~ r, c(0, rmax),
            c("r", makefvlabel(NULL, "hat", fname)), 
            c("distance argument r", "estimated %s"),
            fname = fname)
    unitname(g) <- unitname(X)
    attr(g, "correction") <- correction
    return(g)
  }
  #
  nI <- sum(I)
  nJ <- sum(J)
  whichI <- which(I)
  whichJ <- which(J)
  clash <- I & J
  has.clash <- any(clash)
  # compute pairwise distances
  if(exists("crossdist.lpp")) {
    DIJ <- crossdist(X[I], X[J], check=FALSE)
    if(has.clash) {
      # exclude pairs of identical points from consideration
      Iclash <- which(clash[I])
      Jclash <- which(clash[J])
      DIJ[cbind(Iclash,Jclash)] <- Inf
    }
  } else {
    D <- pairdist(X)
    diag(D) <- Inf
    DIJ <- D[I, J]
  }
  #---  compile into pair correlation function ---
  if(correction == "none" && is.null(reweight)) {
    # no weights (Okabe-Yamada)
    g <- compilepcf(DIJ, r, denom=denom, check=FALSE, fname=fname)
    g <- rebadge.as.crossfun(g, "g", "net", "I", "J")    
    unitname(g) <- unitname(X)
    attr(g, "correction") <- correction
    return(g)
  }
  if(correction == "none")
     edgewt <- 1
  else {
     # inverse m weights (Ang's correction)
     # compute m[i,j]
     m <- matrix(1, nI, nJ)
     XPI <- XP[I]
     if(!has.clash) {
       for(k in seq_len(nJ)) {
         j <- whichJ[k]
         m[,k] <- countends(L, XPI, DIJ[, k])
       }
     } else {
       # don't count identical pairs
       for(k in seq_len(nJ)) {
         j <- whichJ[k]
         inotj <- (whichI != j)
         m[inotj, k] <- countends(L, XPI[inotj], DIJ[inotj, k])
       }
     }
     edgewt <- 1/m
  }
  # compute pcf
  wt <- if(!is.null(reweight)) edgewt * reweight else edgewt
  g <- compilepcf(DIJ, r, weights=wt, denom=denom, check=FALSE, ...,
                  fname=fname)
  ## rebadge and tweak
  g <- rebadge.as.crossfun(g, "g", "L", "I", "J")
  fname <- attr(g, "fname")
  # tack on theoretical value
  g <- bind.fv(g, data.frame(theo=rep(1,length(r))),
               makefvlabel(NULL, NULL, fname, "pois"),
               "theoretical Poisson %s")
  unitname(g) <- unitname(X)
  fvnames(g, ".") <- rev(fvnames(g, "."))
  # show working
  if(showworking)
    attr(g, "working") <- list(DIJ=DIJ, wt=wt)
  attr(g, "correction") <- correction
  return(g)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/linequad.R"
#
# linequad.R
#
#  $Revision: 1.8 $ $Date: 2013/09/16 09:32:42 $
#
# create quadscheme for a pattern of points lying *on* line segments

linequad <- function(X, Y, ..., eps=NULL, nd=1000) {
  if(is.lpp(X)) {
    # extract local coordinates from lpp object
    coo <- coords(X)
    mapXY <- coo$seg
    tp    <- coo$tp
    Xproj <- as.ppp(X)
    if(!missing(Y))
      warning("Argument Y ignored when X is an lpp object")
    Y <- as.psp(X)
  } else if(is.ppp(X)) {
    # project data points onto segments
    stopifnot(is.psp(Y))
    v <- project2segment(X, Y)
    Xproj <- v$Xproj
    mapXY <- v$mapXY
    tp    <- v$tp
  } else stop("X should be an object of class lpp or ppp")
  
  # handle multitype
  ismulti <- is.multitype(X)
  if(is.marked(X) && !ismulti)
    stop("Not implemented for marked patterns")
  if(ismulti) {
    marx <- marks(X)
    flev <- factor(levels(marx))
  }
  #
  win <- as.owin(Y)
  len <- lengths.psp(Y)
  nseg <- length(len)
  if(is.null(eps)) {
    stopifnot(is.numeric(nd) && length(nd) == 1 & is.finite(nd) && nd > 0)
    eps <- sum(len)/nd
  } else
  stopifnot(is.numeric(eps) && length(eps) == 1 && is.finite(eps) && eps > 0)
  # initialise quad scheme 
  dat <- dum <- ppp(numeric(0), numeric(0), window=win)
  wdat <- wdum <- numeric(0)
  if(ismulti)
    marks(dat) <- marks(dum) <- marx[integer(0)]
  # consider each segment in turn
  YY    <- as.data.frame(Y)
  for(i in 1:nseg) {
    # divide segment into pieces of length eps
    # with shorter bits at each end
    leni <- len[i]
    nwhole <- floor(leni/eps)
    if(leni/eps - nwhole < 0.5 && nwhole > 2)
      nwhole <- nwhole - 1
    rump <- (leni - nwhole * eps)/2
    brks <- c(0, rump + (0:nwhole) * eps, leni)
    nbrks <- length(brks)
    # dummy points at middle of each piece
    sdum <- (brks[-1] + brks[-nbrks])/2
    x <- with(YY, x0[i] + (sdum/leni) * (x1[i]-x0[i]))
    y <- with(YY, y0[i] + (sdum/leni) * (y1[i]-y0[i]))
    newdum <- list(x=x, y=y)
    ndum <- length(sdum)
    IDdum <- 1:ndum
    # relevant data points
    relevant <- (mapXY == i)
    newdat <- Xproj[relevant]
    sdat   <- leni * tp[relevant]
    IDdat  <- findInterval(sdat, brks,
                           rightmost.closed=TRUE, all.inside=TRUE)
    # determine weights
    w <- countingweights(id=c(IDdum, IDdat), areas=diff(brks))
    wnewdum <- w[1:ndum]
    wnewdat <- w[-(1:ndum)]
    #
    if(!ismulti) {
      # unmarked pattern
      dat <- superimpose(dat, newdat, W=win, check=FALSE)
      dum <- superimpose(dum, newdum, W=win, check=FALSE)
      wdat <- c(wdat, wnewdat)
      wdum <- c(wdum, wnewdum)
    } else {
      # marked point pattern
      # attach correct marks to data points
      marks(newdat) <- marx[relevant]
      dat <- superimpose(dat, newdat, W=win, check=FALSE)
      wdat <- c(wdat, wnewdat)
      newdum <- as.ppp(newdum, W=win, check=FALSE)
      # replicate dummy points with each mark
      # also add points at data locations with other marks
      for(k in seq_len(length(flev))) {
        le <- flev[k]
        avoid <- (marks(newdat) != le)
        dum <- superimpose(dum,
                           newdum %mark% le,
                           newdat[avoid] %mark% le,
                           W=win, check=FALSE)
        wdum <- c(wdum, wnewdum, wnewdat[avoid])
      }
    }
  }
  # make quad scheme
  Qout <- quad(dat, dum, c(wdat, wdum))
  # silently attach lines
  attr(Qout, "lines") <- Y
  return(Qout)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/linfun.R"
#
#   linfun.R
#
#   Class of functions of location on a linear network
#
#   $Revision: 1.1 $   $Date: 2014/10/24 00:22:30 $
#

linfun <- function(f, L) {
  stopifnot(is.function(f))
  stopifnot(inherits(L, "linnet"))
  needargs <- c("x", "y", "seg", "tp")
  if(!all(needargs %in% names(formals(f))))
    stop(paste("f must have arguments named", commasep(sQuote(needargs))))
  class(f) <- c("linfun", class(f))
  attr(f, "L") <- L
  return(f)
}

print.linfun <- function(x, ...) {
  L <- as.linnet(x)
  if(!is.null(explain <- attr(x, "explain"))) {
    explain(x)
  } else {
    cat("Function on linear network\n")
    print(as.function(x), ...)
    cat("Function domain:\n")
    print(L)
  }
  invisible(NULL)
}

as.linim.linfun <- function(X, L, ..., eps = NULL, dimyx = NULL, xy = NULL) {
  if(missing(L) || is.null(L))
    L <- as.linnet(X)
  # create template
  Y <- as.linim(1, L, eps=eps, dimyx=dimyx, xy=xy)
  # extract (x,y) and local coordinates
  df <- attr(Y, "df")
  coo <- df[, c("x", "y", "mapXY", "tp")]
  colnames(coo)[3] <- "seg"
  # evaluate function
  vals <- do.call(X, append(as.list(coo), list(...)))
  # replace values
  df$values <- vals
  attr(Y, "df") <- df
  Y[!is.na(Y$v)] <- vals
  return(Y)
}
  
plot.linfun <- function(x, ..., L=NULL, eps = NULL, dimyx = NULL, xy = NULL,
                        main) {
  if(missing(main)) main <- short.deparse(substitute(x))
  if(is.null(L)) L <- as.linnet(x)
  Z <- as.linim(x, eps=eps, dimyx=dimyx, xy=xy, L=L)
  plot(Z, ..., main=main)
}

as.owin.linfun <- function(W, ...) {
  as.owin(as.linnet(W))
}

as.linnet.linfun <- function(X, ...) {
  attr(X, "L")
}

as.function.linfun <- function(x, ...) {
  nax <- names(attributes(x))
  if(!is.null(nax)) {
    retain <- (nax == "srcref")
    attributes(x)[!retain] <- NULL
  }
  return(x)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/linim.R"
#
# linim.R
#
#  $Revision: 1.11 $   $Date: 2014/11/10 11:14:30 $
#
#  Image/function on a linear network
#

linim <- function(L, Z, ..., df=NULL) {
  L <- as.linnet(L)
  stopifnot(is.im(Z))
  if(is.null(df)) {
    # compute the data frame of mapping information
    xx <- rasterx.im(Z)
    yy <- rastery.im(Z)
    mm <- !is.na(Z$v)
    xx <- as.vector(xx[mm])
    yy <- as.vector(yy[mm])
    pixelcentres <- ppp(xx, yy, window=as.rectangle(Z), check=FALSE)
    pixdf <- data.frame(xc=xx, yc=yy)
    # project pixel centres onto lines
    p2s <- project2segment(pixelcentres, as.psp(L))
    projloc <- as.data.frame(p2s$Xproj)
    projmap <- as.data.frame(p2s[c("mapXY", "tp")])
    # extract values
    values <- Z[pixelcentres]
    # bundle
    df <- cbind(pixdf, projloc, projmap, data.frame(values=values))
  } else {
    stopifnot(is.data.frame(df))
    neednames <- c("xc", "yc", "x", "y", "mapXY", "tp", "values")
    ok <- neednames %in% names(df)
    if(any(!ok)) {
      nn <- sum(!ok)
      stop(paste(ngettext(nn, "A column", "Columns"),
                 "named", commasep(sQuote(neednames[!ok])),
                 ngettext(nn, "is", "are"),
                 "missing from argument", sQuote("df")))
    }
  }
  out <- Z
  attr(out, "L") <- L
  attr(out, "df") <- df
  class(out) <- c("linim", class(out))
  return(out)
}

print.linim <- function(x, ...) {
  cat("Image on linear network\n")
  print(attr(x, "L"))
  NextMethod("print")
}

plot.linim <- function(x, ..., style=c("colour", "width"), scale, adjust=1) {
  xname <- short.deparse(substitute(x))
  style <- match.arg(style)
  # colour style: plot as pixel image
  if(style == "colour")
    return(do.call("plot.im",
                   resolve.defaults(list(x),
                                    list(...),
                                    list(main=xname))))
  # width style
  L <- attr(x, "L")
  df <- attr(x, "df")
  Llines <- as.psp(L)
  # initialise plot
  W <- as.owin(L)
  do.call.matched("plot.owin",
                  resolve.defaults(list(x=W, type="n"),
                                   list(...), list(main=xname)),
                  extrargs="type")
  # rescale values to a plottable range
  vr <- range(df$values)
  vr[1] <- min(0, vr[1])
  if(missing(scale)) {
    maxsize <- mean(distmap(Llines))/2
    scale <- maxsize/diff(vr)
  } 
  df$values <- adjust * scale * (df$values - vr[1])
  # split data by segment
  mapXY <- factor(df$mapXY, levels=seq_len(Llines$n))
  dfmap <- split(df, mapXY, drop=TRUE)
  # sort each segment's data by position along segment
  dfmap <- lapply(dfmap, function(z) { z[fave.order(z$tp), ] })
  # plot each segment's data
#  Lends <- Llines$ends
  Lperp <- angles.psp(Llines) + pi/2
  Lfrom <- L$from
  Lto   <- L$to
  Lvert <- L$vertices
  for(i in seq(length(dfmap))) {
    z <- dfmap[[i]]
    segid <- unique(z$mapXY)[1]
    xx <- z$x
    yy <- z$y
    vv <- z$values
    # add endpoints of segment
    leftend <- Lvert[Lfrom[segid]]
    rightend <- Lvert[Lto[segid]]
    xx <- c(leftend$x, xx, rightend$x)
    yy <- c(leftend$y, yy, rightend$y)
    vv <- c(vv[1],     vv, vv[length(vv)])
    # create polygon
    xx <- c(xx, rev(xx))
    yy <- c(yy, rev(yy))
    vv <- c(vv, -rev(vv))/2
    ang <- Lperp[segid]
    xx <- xx + cos(ang) * vv
    yy <- yy + sin(ang) * vv
    do.call.matched("polygon",
                    resolve.defaults(list(x=xx, y=yy),
                                     list(...),
                                     list(border=NA, col=1)))
  }
  return(invisible(NULL))
}

as.im.linim <- function(X, ...) { as.im(X$Z, ...) }

as.linim <- function(X, ...) {
  UseMethod("as.linim")
}

as.linim.default <- function(X, L, ...) {
  stopifnot(inherits(L, "linnet"))
  Y <- as.im(X, W=as.rectangle(as.owin(L)), ...)
  Z <- as.im(as.mask.psp(as.psp(L), as.owin(Y)))
  Y <- eval.im(Z * Y)
  out <- linim(L, Y)
  return(out)
}

as.linim.linim <- function(X, ...) {
  if(length(list(...)) == 0)
    return(X)
  Y <- as.linim.default(X, as.linnet(X), ...)
  return(Y)
}

# analogue of eval.im

eval.linim <- function(expr, envir, harmonize=TRUE) {
  sc <- sys.call()
  # Get names of all variables in the expression
  e <- as.expression(substitute(expr))
  varnames <- all.vars(e)
  allnames <- all.names(e, unique=TRUE)
  funnames <- allnames[!(allnames %in% varnames)]
  if(length(varnames) == 0)
    stop("No variables in this expression")
  # get the values of the variables
  if(missing(envir))
    envir <- sys.parent()
  vars <- lapply(as.list(varnames), function(x, e) get(x, envir=e), e=envir)
  names(vars) <- varnames
  funs <- lapply(as.list(funnames), function(x, e) get(x, envir=e), e=envir)
  names(funs) <- funnames
  # Find out which variables are (linear) images
  islinim <- unlist(lapply(vars, inherits, what="linim"))
  if(!any(islinim))
    stop("There are no linear images (class linim) in this expression")
  # ....................................
  # Evaluate the pixel values using eval.im
  # ....................................
  sc[[1]] <- as.name('eval.im')
  Y <- eval(sc)
  # .........................................
  # Then evaluate data frame entries if feasible
  # .........................................
  dfY <- NULL
  linims <- vars[islinim]
  nlinims <- length(linims)
  dframes <- lapply(linims, attr, which="df")
  nets <- lapply(linims, attr, which="L")
  isim <- unlist(lapply(vars, is.im))
  if(!any(isim & !islinim)) {
    # all images are 'linim' objects
    # Check that the images refer to the same linear network
    if(nlinims > 1) {
      agree <- unlist(lapply(nets[-1], identical, y=nets[[1]]))
      if(!all(agree))
        stop(paste("Images do not refer to the same linear network"))
    }
    dfempty <- unlist(lapply(dframes, is.null))
    if(!any(dfempty)) {
      # replace each image variable by its data frame column of values
      vars[islinim] <- lapply(dframes, getElement, "values")
      # now evaluate expression
      Yvalues <- eval(e, append(vars, funs))
      # pack up
      dfY <- dframes[[1]]
      dfY$values <- Yvalues
    }
  }
  result <- linim(nets[[1]], Y, df=dfY)
  return(result)
}
    
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/linnet.R"
# 
# linnet.R
#    
#    Linear networks
#
#    $Revision: 1.25 $    $Date: 2014/10/24 00:22:30 $
#
# An object of class 'linnet' defines a linear network.
# It includes the following components
#
#        vertices     (ppp)      vertices of network
#
#        m            (matrix)   adjacency matrix
#
#        lines        (psp)      edges of network
#
#        dpath        (matrix)   matrix of shortest path distances
#                                between each pair of vertices
#
#        from, to     (vectors)  map from edges to vertices.
#                                The endpoints of the i-th segment lines[i]
#                                are vertices[from[i]] and vertices[to[i]]
#
#
#  FUNCTIONS PROVIDED:
#       linnet        creates an object of class "linnet" from data
#       print.linnet  print an object of class "linnet"
#       plot.linnet   plot an object of class "linnet"
#

# Make an object of class "linnet" from the minimal data

linnet <- function(vertices, m, edges) {
  if(missing(m) && missing(edges))
    stop("specify either m or edges")
  if(!missing(m) && !missing(edges))
    stop("do not specify both m and edges")
  # validate inputs
  stopifnot(is.ppp(vertices))
  if((nv <- npoints(vertices)) <= 1) {
    m <- matrix(FALSE, nv, nv)
  } else if(!missing(m)) {
    # check logical matrix
    stopifnot(is.matrix(m) && is.logical(m) && isSymmetric(m))
    if(nrow(m) != vertices$n)
      stop("dimensions of matrix m do not match number of vertices")
  } else {
    # check (from, to) pairs
    stopifnot(is.matrix(edges) && ncol(edges) == 2)
    if(any((edges %% 1) != 0))
      stop("Entries of edges list should be integers")
    np <- npoints(vertices)
    if(any(edges > np))
      stop("index out-of-bounds in edges list")
    # convert to adjacency matrix
    m <- matrix(FALSE, np, np)
    m[edges] <- TRUE
    m <- m | t(m)
  }
  # create line segments
  rowm <- row(m)
  colm <- col(m)
  uptri <- m & (rowm < colm)
  from <- as.vector(rowm[uptri])
  to   <- as.vector(colm[uptri])
  xx   <- vertices$x
  yy   <- vertices$y
  lines <- psp(xx[from], yy[from], xx[to], yy[to], window=vertices$window,
               check=FALSE)
  # compute matrix of distances between adjacent vertices
  n <- nrow(m)
  d <- matrix(Inf, n, n)
  diag(d) <- 0
  d[m] <- pairdist(vertices)[m]
  # now compute shortest-path distances between each pair of vertices
  dpath <- dist2dpath(d)
  if(any(is.infinite(dpath)))
    warning("Network is not connected")
  # pack up
  out <- list(vertices=vertices, m=m, lines=lines, from=from, to=to,
              dpath=dpath, window=vertices$window)
  class(out) <- c("linnet", class(out))
  # pre-compute circumradius
  out$circumradius <- circumradius(out)
  return(out)  
}

print.linnet <- function(x, ...) {
  nv <- x$vertices$n
  nl <- x$lines$n
  ne <- sum(x$m)/2
  splat("Linear network with",
        nv, ngettext(nv, "vertex,", "vertices,"), 
        nl, ngettext(nl, "line", "lines"),
        "and",
        ne, ngettext(ne, "edge", "edges"))
  return(invisible(NULL))
}

summary.linnet <- function(object, ...) {
  print(object, ...)
  unitinfo <- summary(unitname(object))
  cat(paste("Total length",
            sum(lengths.psp(object$lines)),
            unitinfo$plural, unitinfo$explain, "\n"))
  print(as.owin(object))
  return(invisible(NULL))
}

plot.linnet <- function(x, ..., main=NULL, add=FALSE,
                        vertices=FALSE, window=FALSE) {
  if(is.null(main))
    main <- short.deparse(substitute(x))
  stopifnot(inherits(x, "linnet"))
  lines <- as.psp(x)
  if(!add) {
    # initialise new plot
    w <- as.owin(lines)
    if(window)
      plot(w, ..., main=main)
    else
      plot(w, ..., main=main, type="n")
  }
  # plot segments and (optionally) vertices
  plot(lines, ..., add=TRUE, main=main)
  if(vertices)
    plot(x$vertices, add=TRUE)
  return(invisible(NULL))
}

as.psp.linnet <- function(x, ..., fatal=TRUE) {
  verifyclass(x, "linnet", fatal=fatal)
  return(x$lines)
}

as.owin.linnet <- function(W, ...) {
  return(as.owin(as.psp(W)))
}

as.linnet <- function(X, ...) {
  UseMethod("as.linnet")
}

as.linnet.linnet <- function(X, ...) { X }

unitname.linnet <- function(x) {
  unitname(x$window)
}

"unitname<-.linnet" <- function(x, value) {
  w <- x$window
  v <- x$vertices
  l <- x$lines
  unitname(w) <- unitname(v) <- unitname(l) <- value
  x$window <- w
  x$vertices <- v
  x$lines <- l
  return(x)
}

diameter.linnet <- function(x) {
  stopifnot(inherits(x, "linnet"))
  max(0, x$dpath)
}

volume.linnet <- function(x) {
  sum(lengths.psp(x$lines))
}

circumradius.linnet <- function(x, ...) {
  stopifnot(inherits(x, "linnet"))
  cr <- x$circumradius
  if(!is.null(cr))
    return(cr)
  dpath <- x$dpath
  if(nrow(dpath) <= 1)
    return(max(0,dpath))
  from  <- x$from
  to    <- x$to
  lines <- x$lines
  nseg  <- lines$n
  leng  <- lengths.psp(lines)
  sA <- sB <- matrix(Inf, nseg, nseg)
  for(i in 1:nseg) {
    # endpoints of segment i
    A <- from[i]
    B <- to[i]
    AB <- leng[i]
    sA[i,i] <- sB[i,i] <- AB/2
    for(j in (1:nseg)[-i]) {
    # endpoints of segment j
      C <- from[j]
      D <- to[j]
      CD <- leng[j]
      AC <- dpath[A,C]
      AD <- dpath[A,D]
      BC <- dpath[B,C]
      BD <- dpath[B,D]
      # max dist from A to any point in segment j
      sA[i,j] <- if(AD > AC + CD) AC + CD else
                if(AC > AD + CD) AD + CD else
                (AC + AD + CD)/2
      # max dist from B to any point in segment j
      sB[i,j] <- if(BD > BC + CD) BC + CD else
                if(BC > BD + CD) BD + CD else
                (BC + BD + CD)/2
    }
  }
  # max dist from each A to any point in another segment
  mA <- apply(sA, 1, max)
  # max dist from each B to any point in another segment
  mB <- apply(sB, 1, max)
  # min of these
  min(mA, mB)
}



####################################################
# affine transformations
####################################################

scalardilate.linnet <- function(X, f, ...) {
  trap.extra.arguments(..., .Context="In scalardilate(X,f)")
  check.1.real(f, "In scalardilate(X,f)")
  stopifnot(is.finite(f) && f > 0)
  Y <- X
  Y$vertices     <- scalardilate(X$vertices, f=f)
  Y$lines        <- scalardilate(X$lines, f=f)
  Y$window       <- scalardilate(X$window, f=f)
  Y$dpath        <- f * X$dpath
  Y$circumradius <- f * X$circumradius
  return(Y)
}

affine.linnet <- function(X,  mat=diag(c(1,1)), vec=c(0,0), ...) {
  verifyclass(X, "linnet")
  if(length(unique(eigen(mat)$values)) == 1) {
    # transformation is an isometry
    scal <- sqrt(abs(det(mat)))
    Y <- X
    Y$vertices     <- affine(X$vertices, mat=mat, vec=vec, ...)
    Y$lines        <- affine(X$lines,    mat=mat, vec=vec, ...)
    Y$window       <- affine(X$window,   mat=mat, vec=vec, ...)
    Y$dpath        <- scal * X$dpath
    Y$circumradius <- scal * X$circumradius
  } else {
    # general case
    vertices <- affine(X$vertices, mat=mat, vec=vec, ...)
    Y <- linnet(vertices, edges=cbind(X$from, X$to))
  }
  return(Y)
}

shift.linnet <- function(X, vec=c(0,0), ..., origin=NULL) {
  verifyclass(X, "linnet")
  Y <- X
  Y$window  <- W <- shift(X$window, vec=vec, ..., origin=origin)
  v <- getlastshift(W)
  Y$vertices <- shift(X$vertices, vec=v, ...)
  Y$lines    <- shift(X$lines, vec=v, ...)
  # tack on shift vector
  attr(Y, "lastshift") <- v
  return(Y)
}

rotate.linnet <- function(X, angle=pi/2, ..., centre=NULL) {
  verifyclass(X, "linnet")
  if(!is.null(centre)) {
    X <- shift(X, origin=centre)
    negorigin <- getlastshift(X)
  } else negorigin <- NULL
  Y <- X
  Y$vertices <- rotate(X$vertices, angle=angle, ...)
  Y$lines    <- rotate(X$lines, angle=angle, ...)
  Y$window   <- rotate(X$window, angle=angle, ...)
  if(!is.null(negorigin))
    Y <- shift(Y, -negorigin)
  return(Y)
}

rescale.linnet <- function(X, s, unitname) {
  if(missing(unitname)) unitname <- NULL
  if(missing(s) || is.null(s)) s <- 1/unitname(X)$multiplier
  Y <- scalardilate(X, f=1/s)
  unitname(Y) <- rescale(unitname(X), s, unitname)
  return(Y)
}

"[.linnet" <- function(x, i, ...) {
  if(!is.owin(i))
    stop("In [.linnet: the index i should be a window", call.=FALSE)
  # Find vertices that lie inside 'i'
  okvert <- inside.owin(x$vertices, w=i)
  # find segments whose endpoints both lie in 'i'
  okedge <- okvert[x$from] & okvert[x$to]
  # assign new serial numbers to vertices, and recode 
  newserial <- cumsum(okvert)
  newfrom <- newserial[x$from[okedge]]
  newto   <- newserial[x$to[okedge]]
  # make new linear network
  xnew <- linnet(x$vertices[i], edges=cbind(newfrom, newto))
  return(xnew)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/listof.R"
#
# listof.R
#
# Methods for class `listof'
#
# plot.listof is defined in plot.splitppp.R
#

"[<-.listof" <- function(x, i, value) {
  # invoke list method
  class(x) <- "list"
  x[i] <- value
  # then make it a 'listof' object too
  class(x) <- c("listof", class(x))
  x
}
  
summary.listof <- function(object, ...) {
  x <- lapply(object, summary, ...)
  class(x) <- "summary.listof"
  x
}

print.summary.listof <- function(x, ...) {
  class(x) <- "listof"
  print(x)
  invisible(NULL)
}

listof <- function(...) {
#  warn.once("listof",
#            "The class listof will be Deprecated",
#            "in future versions of spatstat.",
#            "Use anylist or solist")
  stuff <- list(...)
  class(stuff) <- c("listof", class(stuff))
  return(stuff)
}

as.listof <- function(x) {
  if(!is.list(x))
    x <- list(x)
  if(!inherits(x, "listof"))
    class(x) <- c("listof", class(x))
#  warn.once("listof",
#            "The class listof will be Deprecated",
#            "in future versions of spatstat.",
#            "Use anylist or solist")
  return(x)
}

as.layered.listof <- function(X) {
  layered(LayerList=X)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/localK.R"
#
#	localK.R		Getis-Franklin neighbourhood density function
#
#	$Revision: 1.20 $	$Date: 2014/10/24 00:22:30 $
#
#

"localL" <-
  function(X, ..., correction="Ripley", verbose=TRUE, rvalue=NULL)
{
  localK(X, wantL=TRUE,
         correction=correction, verbose=verbose, rvalue=rvalue)
}

"localLinhom" <-
  function(X, lambda=NULL, ..., correction="Ripley", verbose=TRUE, rvalue=NULL,
           sigma=NULL, varcov=NULL)
{
  localKinhom(X, lambda=lambda, wantL=TRUE, ..., 
              correction=correction, verbose=verbose, rvalue=rvalue,
              sigma=sigma, varcov=varcov)
}

"localK" <-
  function(X, ..., correction="Ripley", verbose=TRUE, rvalue=NULL)
{
  verifyclass(X, "ppp")
  localKengine(X, ..., correction=correction, verbose=verbose, rvalue=rvalue)
}

"localKinhom" <-
  function(X, lambda=NULL, ..., correction="Ripley", verbose=TRUE, rvalue=NULL,
           sigma=NULL, varcov=NULL)
{
  verifyclass(X, "ppp")

  if(is.null(lambda)) {
    # No intensity data provided
    # Estimate density by leave-one-out kernel smoothing
    lambda <- density(X, ..., sigma=sigma, varcov=varcov,
                            at="points", leaveoneout=TRUE)
    lambda <- as.numeric(lambda)
  } else {
    # validate
    if(is.im(lambda)) 
      lambda <- safelookup(lambda, X)
    else if(is.ppm(lambda))
      lambda <- predict(lambda, locations=X, type="trend")
    else if(is.function(lambda)) 
      lambda <- lambda(X$x, X$y)
    else if(is.numeric(lambda) && is.vector(as.numeric(lambda)))
      check.nvector(lambda, npoints(X))
    else stop(paste(sQuote("lambda"),
                    "should be a vector, a pixel image, or a function"))
  }  
  localKengine(X, lambda=lambda, ...,
               correction=correction, verbose=verbose, rvalue=rvalue)
}

"localKengine" <-
  function(X, ..., wantL=FALSE, lambda=NULL,
           correction="Ripley", verbose=TRUE, rvalue=NULL)
{
  npts <- npoints(X)
  W <- X$window
  areaW <- area(W)
  lambda.ave <- npts/areaW
  lambda1.ave <- (npts - 1)/areaW

  weighted <- !is.null(lambda)

  if(is.null(rvalue)) 
    rmaxdefault <- rmax.rule("K", W, lambda.ave)
  else {
    stopifnot(is.numeric(rvalue))
    stopifnot(length(rvalue) == 1)
    stopifnot(rvalue >= 0)
    rmaxdefault <- rvalue
  }
  breaks <- handle.r.b.args(NULL, NULL, W, rmaxdefault=rmaxdefault)
  r <- breaks$r
  rmax <- breaks$max
  
  correction.given <- !missing(correction)
  correction <- pickoption("correction", correction,
                           c(none="none",
                             isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             best="best"),
                           multi=FALSE)

  correction <- implemented.for.K(correction, W$type, correction.given)

  # recommended range of r values
  alim <- c(0, min(rmax, rmaxdefault))

  # identify all close pairs
  rmax <- max(r)
  close <- closepairs(X, rmax)
  DIJ <- close$d
  XI <- ppp(close$xi, close$yi, window=W, check=FALSE)
  I <- close$i
  if(weighted) {
    J <- close$j
    lambdaJ <- lambda[J]
    weightJ <- 1/lambdaJ
  } 
  
  # initialise
  df <- as.data.frame(matrix(NA, length(r), npts))
  labl <- desc <- character(npts)

  bkt <- function(x) { paste("[", x, "]", sep="") }
  
  switch(correction,
         none={
           # uncorrected! For demonstration purposes only!
           for(i in 1:npts) {
             ii <- (I == i)
             wh <- whist(DIJ[ii], breaks$val,
                         if(weighted) weightJ[ii] else NULL)  # no edge weights
             df[,i] <- cumsum(wh)
             icode <- numalign(i, npts)
             names(df)[i] <- paste("un", icode, sep="")
             labl[i] <- paste("%s", bkt(icode), "(r)", sep="")
             desc[i] <- paste("uncorrected estimate of %s",
                              "for point", icode)
             if(verbose) progressreport(i, npts)
           }
           if(!weighted) df <- df/lambda1.ave
         },
         translate={
           # Translation correction
           XJ <- ppp(close$xj, close$yj, window=W, check=FALSE)
           edgewt <- edge.Trans(XI, XJ, paired=TRUE)
           if(weighted)
             edgewt <- edgewt * weightJ
           for(i in 1:npts) {
             ii <- (I == i)
             wh <- whist(DIJ[ii], breaks$val, edgewt[ii])
             Ktrans <- cumsum(wh)
             df[,i] <- Ktrans
             icode <- numalign(i, npts)
             names(df)[i] <- paste("trans", icode, sep="")
             labl[i] <- paste("%s", bkt(icode), "(r)", sep="")
             desc[i] <- paste("translation-corrected estimate of %s",
                              "for point", icode)
             if(verbose) progressreport(i, npts)
           }
           if(!weighted) df <- df/lambda1.ave
           h <- diameter(W)/2
           df[r >= h, ] <- NA
         },
         isotropic={
           # Ripley isotropic correction
           edgewt <- edge.Ripley(XI, matrix(DIJ, ncol=1))
           if(weighted)
             edgewt <- edgewt * weightJ
           for(i in 1:npts) {
             ii <- (I == i)
             wh <- whist(DIJ[ii], breaks$val, edgewt[ii])
             Kiso <- cumsum(wh)
             df[,i] <- Kiso
             icode <- numalign(i, npts)
             names(df)[i] <- paste("iso", icode, sep="")
             labl[i] <- paste("%s", bkt(icode), "(r)", sep="")
             desc[i] <- paste("Ripley isotropic correction estimate of %s", 
                              "for point", icode)
             if(verbose) progressreport(i, npts)
           }
           if(!weighted) df <- df/lambda1.ave
           h <- diameter(W)/2
           df[r >= h, ] <- NA
         })
  # transform values if L required
  if(wantL)
    df <- sqrt(df/pi)
  
  # return vector of values at r=rvalue, if desired
  if(!is.null(rvalue)) {
    nr <- length(r)
    if(r[nr] != rvalue)
      stop("Internal error - rvalue not attained")
    return(as.numeric(df[nr,]))
  }
  # function value table required
  # add r and theo
  if(!wantL) {
    df <- cbind(df, data.frame(r=r, theo=pi * r^2))
    if(!weighted) {
      ylab <- quote(K[loc](r))
      fnam <- "K[loc][',']"
    } else {
      ylab <- quote(Kinhom[loc](r))
      fnam <- "Kinhom[loc][',']"
    }
  } else {
    df <- cbind(df, data.frame(r=r, theo=r))
    if(!weighted) {
      ylab <- quote(L[loc](r))
      fnam <- "L[loc][',']"
    } else {
      ylab <- quote(Linhom[loc](r))
      fnam <- "Linhom[loc][',']"
    }
  }
  desc <- c(desc, c("distance argument r", "theoretical Poisson %s"))
  labl <- c(labl, c("r", "%s[pois](r)"))
  # create fv object
  K <- fv(df, "r", ylab, "theo", , alim, labl, desc, fname=fnam)
  # default is to display them all
  formula(K) <- . ~ r
  unitname(K) <- unitname(X)
  attr(K, "correction") <- correction
  return(K)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/localpcf.R"
#
#   localpcf.R
#
#  $Revision: 1.20 $  $Date: 2014/11/10 11:29:47 $
#
#

localpcf <- function(X, ..., delta=NULL, rmax=NULL, nr=512, stoyan=0.15) {
  if(length(list(...)) > 0)
    warning("Additional arguments ignored")
  stopifnot(is.ppp(X))
  localpcfengine(X, delta=delta, rmax=rmax, nr=nr, stoyan=stoyan)
}

localpcfinhom <- function(X, ..., delta=NULL, rmax=NULL, nr=512, stoyan=0.15,
                     lambda=NULL, sigma=NULL, varcov=NULL) {
  stopifnot(is.ppp(X))
  if(is.null(lambda)) {
    # No intensity data provided
    # Estimate density by leave-one-out kernel smoothing
    lambda <- density(X, ..., sigma=sigma, varcov=varcov,
                            at="points", leaveoneout=TRUE)
    lambda <- as.numeric(lambda)
  } else {
    # validate
    if(is.im(lambda)) 
      lambda <- safelookup(lambda, X)
    else if(is.ppm(lambda))
      lambda <- predict(lambda, locations=X, type="trend")
    else if(is.function(lambda)) 
      lambda <- lambda(X$x, X$y)
    else if(is.numeric(lambda) && is.vector(as.numeric(lambda)))
      check.nvector(lambda, npoints(X))
    else stop(paste(sQuote("lambda"),
                    "should be a vector, a pixel image, or a function"))
  }
  localpcfengine(X,
                 delta=delta, rmax=rmax, nr=nr, stoyan=stoyan,
                 lambda=lambda)
}
 
localpcfengine <- function(X, ...,
                           delta=NULL, rmax=NULL, nr=512, stoyan=0.15,
                           lambda=NULL) {
  m <- localpcfmatrix(X, delta=delta, rmax=rmax, nr=nr, stoyan=stoyan,
                      lambda=lambda)
  r <- attr(m, "r")
  delta <- attr(m, "delta")
  nX <- npoints(X)
  if(nX == 0) {
    df <- data.frame(r=r, theo=rep.int(1, length(r)))
    nama <- desc <- labl <- NULL
  } else {
    # border correction
    dbord <- bdist.points(X)
    m[r[row(m)] > dbord[col(m)]] <- NA
    #
    df <- data.frame(m, r=r, theo=rep.int(1, length(r)))
    icode <- unlist(lapply(seq_len(nX), numalign, nmax=nX))
    nama <- paste("est", icode, sep="")
    desc <- paste("estimate of %s for point", icode)
    labl <- paste("%s[", icode, "](r)", sep="")
  }
  names(df) <- c(nama, "r", "theo")
  desc <- c(desc, "distance argument r", "theoretical Poisson %s")
  labl <- c(labl, "r", "%s[pois](r)")
  # create fv object
  g <- fv(df, "r", quote(localg(r)),
          "theo", , c(0, max(r)), labl, desc, fname="localg")
  # default is to display them all
  formula(g) <- . ~ r
  fvnames(g, ".") <- names(df)[names(df) != "r"]
  unitname(g) <- unitname(X)
  attr(g, "delta") <- delta  
  attr(g, "correction") <- "border"
  return(g)
}

localpcfmatrix <- function(X, i=seq_len(npoints(X)), ...,
                           lambda = NULL,
                           delta=NULL, rmax=NULL,
                           nr=512, stoyan=0.15) {
  missi <- missing(i)
  weighted <- !is.null(lambda)
  nX <- npoints(X)
  nY <- if(missi) nX else length(seq_len(nX)[i])
  W <- as.owin(X)
  lambda.ave <- nX/area(W)
  if(is.null(delta)) 
    delta <- stoyan/sqrt(lambda.ave)
  if(is.null(rmax)) 
    rmax <- rmax.rule("K", W, lambda.ave)
  #
  if(nX == 0 || nY == 0) {
    out <- matrix(0, nr, 0)
  } else {
    # sort points in increasing order of x coordinate
    oX <- fave.order(X$x)
    Xsort <- X[oX]
    idXsort <- (1:nX)[oX]
    if(weighted) {
      lambdaXsort <- lambda[oX]
      weightXsort <- 1/lambdaXsort
    }
    if(missi) {
      Y <- X
      oY <- oX
      Ysort   <- Xsort
      idYsort <- idXsort
    } else {
      # i is some kind of index
      Y <- X[i]
      idY <- (1:nX)[i]
      oY <- fave.order(Y$x)
      Ysort <- Y[oY]
      idYsort <- idY[oY]
    }
    nY <- npoints(Y)
    force(nr)
    # call C
    if(!weighted) {
      zz <- .C("locpcfx",
               nn1 = as.integer(nY),
               x1  = as.double(Ysort$x),
               y1  = as.double(Ysort$y),
               id1 = as.integer(idYsort),
               nn2 = as.integer(nX),
               x2  = as.double(Xsort$x),
               y2  = as.double(Xsort$y),
               id2 = as.integer(idXsort),
               nnr = as.integer(nr),
               rmaxi=as.double(rmax),
               del=as.double(delta),
               pcf=as.double(double(nr * nY)))
    } else {
      zz <- .C("locWpcfx",
               nn1 = as.integer(nY),
               x1  = as.double(Ysort$x),
               y1  = as.double(Ysort$y),
               id1 = as.integer(idYsort),
               nn2 = as.integer(nX),
               x2  = as.double(Xsort$x),
               y2  = as.double(Xsort$y),
               id2 = as.integer(idXsort),
               w2  = as.double(weightXsort),
               nnr = as.integer(nr),
               rmaxi=as.double(rmax),
               del=as.double(delta),
               pcf=as.double(double(nr * nY)))
    }
    out <- matrix(zz$pcf, nr, nY)
    # reorder columns to match original
    out[, oY] <- out
    # rescale
    out <- out/(2 * pi * if(!weighted) lambda.ave else 1)
  }
  # dress up
  attr(out, "r") <- seq(from=0, to=rmax, length.out=nr)
  attr(out, "delta") <- delta
  class(out) <- c("localpcfmatrix", class(out))
  return(out)
}

print.localpcfmatrix <- function(x, ...) {
  cat("Matrix of local pair correlation estimates\n")
  nc <- ncol(x)
  nr <- nrow(x)
  cat(paste("pcf estimates for", nc, ngettext(nc, "point", "points"), "\n"))
  rval <- attr(x, "r")
  cat(paste("r values from 0 to", max(rval), "in", nr, "steps\n"))
  return(invisible(NULL))
}

plot.localpcfmatrix <- function(x, ...) {
  xname <- short.deparse(substitute(x))
  rval <- attr(x, "r")
  do.call("matplot",
          resolve.defaults(list(rval, x),
                           list(...),
                           list(type="l", main=xname,
                                xlab="r", ylab="pair correlation")))
}

"[.localpcfmatrix" <-
  function(x, i, ...) {
    r     <- attr(x, "r")
    delta <- attr(x, "delta")
    class(x) <- "matrix"
    if(missing(i)) {
      x <- x[ , ...]
    } else {
      x <- x[i, ...]
      if(is.matrix(i))
        return(x)
      r <- r[i]
    }
    if(!is.matrix(x))
      x <- matrix(x, nrow=length(r))
    attr(x, "r") <- r
    attr(x, "delta") <- delta
    class(x) <- c("localpcfmatrix", class(x))
    return(x)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/logistic.R"
#
#  logistic.R
#
#   $Revision: 1.18 $  $Date: 2014/12/17 00:52:48 $
#
#  Logistic likelihood method - under development
#

logi.engine <- function(Q,
                        trend = ~1,
                        interaction,
                        ...,
                        covariates=NULL,
                        subsetexpr=NULL,
                        correction="border",
                        rbord=reach(interaction),
                        covfunargs=list(),
                        allcovar=FALSE,
                        vnamebase=c("Interaction", "Interact."),
                        vnameprefix=NULL,
                        justQ = FALSE,
                        savecomputed = FALSE,
                        precomputed = NULL,
                        VB=FALSE
                        ){
  if(is.null(trend)) trend <- ~1 
  if(is.null(interaction)) interaction <- Poisson()
  want.trend <- !identical.formulae(trend, ~1)
  want.inter <- !is.poisson(interaction)
  want.subset <- !is.null(subsetexpr)
  # validate choice of edge correction
  correction <- pickoption("correction", correction,
                           c(border="border",
                             periodic="periodic",
                             isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             none="none"))
  # rbord applies only to border correction
  if(correction == "border") {
    check.1.real(rbord, "In ppm")
    explain.ifnot(rbord >= 0, "In ppm")
  } else rbord <- 0
  # backdoor stuff
  if(!missing(vnamebase)) {
    if(length(vnamebase) == 1)
      vnamebase <- rep.int(vnamebase, 2)
    if(!is.character(vnamebase) || length(vnamebase) != 2)
      stop("Internal error: illegal format of vnamebase")
  }
  if(!is.null(vnameprefix)) {
    if(!is.character(vnameprefix) || length(vnameprefix) != 1)
      stop("Internal error: illegal format of vnameprefix")
  }
  # create dummy points
  if(inherits(Q, "ppp")){
    Xplus <- Q
    Q <- quadscheme.logi(Xplus, ...)
    D <- Q$dummy
    Dinfo <- Q$param
  } else if(checkfields(Q, c("data", "dummy"))) {
    Xplus <- Q$data
    D <- Q$dummy
    Dinfo <- Q$param
    if(is.null(Dinfo)){
      Dinfo <- list(how="given", rho=npoints(D)/(area(D)*markspace.integral(D)))
    }
    Q <- quadscheme.logi(Xplus, D)
  } else stop("Format of object Q is not understood")
  if (justQ) 
    return(Q)
  ### Dirty way of recording arguments so that the model can be refitted later (should probably be done using call, eval, envir, etc.):
  extraargs <- list(covfunargs = covfunargs, allcovar = allcovar, vnamebase = vnamebase, vnameprefix = vnameprefix)
  extraargs <- append(extraargs, list(...))
  ## Dummy intensity
  if(correction == "border" && Dinfo$how=="grid"){
    Dbord <- D[bdist.points(D)>=rbord]
    Dinfo$rho <- npoints(Dbord)/(eroded.areas(as.owin(Dbord), rbord)*markspace.integral(Dbord))
  }
  rho <- Dinfo$rho
  ##Setting the B from Barker dynamics (relative to dummy intensity)
  B <- list(...)$Barker
  if(is.null(B))
    B <- 1
  B <- B*rho
  Dinfo <- append(Dinfo, list(B=B))
  Dinfo <- append(Dinfo, list(extraargs=extraargs))
  # 
  Wplus <- as.owin(Xplus)
  nXplus <- npoints(Xplus)
  U <- superimpose(Xplus, D, W=Wplus, check=FALSE)
#  E <- equalpairs(U, Xplus, marked = is.marked(Xplus))
  E <- cbind(1:nXplus, 1:nXplus)
#  
  computed <- if (savecomputed) list(X = Xplus, Q = Q, U = U) else list()
  # assemble covariate data frame
  if(want.trend || want.subset) {
    tvars <- variablesinformula(trend)
    if(want.subset)
      tvars <- union(tvars, all.vars(subsetexpr))
    ## resolve 'external' covariates
    externalvars <- setdiff(tvars, c("x", "y", "marks"))
    tenv <- environment(trend)
    covariates <- getdataobjects(externalvars, tenv, covariates, fatal=TRUE)
    ## 
    wantxy <- c("x", "y") %in% tvars
    wantxy <- wantxy | rep.int(allcovar, 2)
    cvdf <- data.frame(x=U$x, y=U$y)[, wantxy, drop=FALSE]
    if(!is.null(covariates)) {
      df <- mpl.get.covariates(covariates, U, "quadrature points", covfunargs)
      cvdf <- cbind(cvdf, df)
    }
    wantmarks <- "marks" %in% tvars
    if(wantmarks) cvdf <- cbind(cvdf, marks = marks(U))
  } else cvdf <- NULL
  # evaluate interaction sufficient statistics
  if (!is.null(ss <- interaction$selfstart)) 
    interaction <- ss(Xplus, interaction)
  V <- evalInteraction(Xplus, U, E, interaction, correction, precomputed = precomputed, savecomputed = savecomputed)
  if(!is.matrix(V))
    stop("evalInteraction did not return a matrix")
  if (savecomputed) 
    computed <- append(computed, attr(V, "computed"))
  IsOffset <- attr(V, "IsOffset")
  if(is.null(IsOffset)) IsOffset <- rep.int(FALSE, ncol(V))
  # determine names
  if(ncol(V) > 0) {
    Vnames <- colnames(V)
    if(is.null(Vnames)) {
      nc <- ncol(V)
      Vnames <- if(nc == 1) vnamebase[1] else paste(vnamebase[2], 1:nc, sep="")
      colnames(V) <- Vnames
    } else if(!is.null(vnameprefix)) {
      Vnames <- paste(vnameprefix, Vnames, sep="")
      colnames(V) <- Vnames
    }
  } else Vnames <- character(0)
  # combine all data
  glmdata <- as.data.frame(V)
  if(!is.null(cvdf)) glmdata <- cbind(glmdata, cvdf)
  # construct response and weights
  ok <- if(correction == "border") (bdist.points(U) >= rbord) else rep.int(TRUE, npoints(U))
  # Keep only those quadrature points for which the
  # conditional intensity is nonzero.
  KEEP  <- if(ncol(V)>0) matrowall(V != -Inf) else rep.int(TRUE, npoints(U))
  ok <- ok & KEEP
  wei <- c(rep.int(1,npoints(Xplus)),rep.int(B/rho,npoints(D)))
  resp <- c(rep.int(1,npoints(Xplus)),rep.int(0,npoints(D)))
  ## User-defined subset:
  if(!is.null(subsetexpr)) {
    USERSUBSET <- eval(subsetexpr, glmdata, environment(trend))
    ok <- ok & USERSUBSET
  }
  # add offset, subset and weights to data frame
  # using reserved names beginning with ".logi."
  glmdata <- cbind(glmdata,
                   .logi.Y = resp,
                   .logi.B = B,
                   .logi.w = wei,
                   .logi.ok =ok)
  # build glm formula 
  # (reserved names begin with ".logi.")
  trendpart <- paste(as.character(trend), collapse=" ")
  fmla <- paste(".logi.Y ", trendpart)
  # Interaction terms
  if(want.inter) {
    VN <- Vnames
    # enclose offset potentials in 'offset(.)'
    if(any(IsOffset))
      VN[IsOffset] <- paste("offset(", VN[IsOffset], ")", sep="")
    fmla <- paste(c(fmla, VN), collapse="+")
  }
  # add offset intrinsic to logistic technique
  fmla <- paste(fmla, "offset(-log(.logi.B))", sep="+")
  fmla <- as.formula(fmla)
  # to satisfy package checker: 
  .logi.B <- B
  .logi.w <- wei
  .logi.ok  <- ok
  .logi.Y   <- resp
  # go
  ##fit <- glm(fmla, data=glmdata,
  ##           family=binomial(), subset = .logi.ok, weights = .logi.w)
  fit <- if(VB) 
           vblogit.fmla(fmla, data = glmdata, 
                        subset = .logi.ok, weights = .logi.w, ...)
         else 
           glm(fmla, data = glmdata, 
               family = binomial(), subset = .logi.ok, weights = .logi.w)
  environment(fit$terms) <- sys.frame(sys.nframe())
  ## Fitted coeffs
  co <- coef(fit)
  fitin <- fii(interaction, co, Vnames, IsOffset)

  ## Max. value of log-likelihood:
  maxlogpl <- logLik(fit) + sum(ok*resp*log(B))

  # Stamp with spatstat version number
  spv <- package_version(versionstring.spatstat())
  the.version <- list(major=spv$major,
                      minor=spv$minor,
                      release=spv$patchlevel,
                      date="$Date: 2014/12/17 00:52:48 $")

  ## Compile results
  fit <- list(method      = "logi",
              fitter      = "glm",
              projected   = FALSE,
              coef        = co,
              trend       = trend,
              interaction = interaction,
              Q           = Q,
              correction  = correction,
              rbord       = rbord,
              terms       = terms(trend),
              version     = the.version,
              fitin       = fitin,
              maxlogpl    = maxlogpl,
              covariates  = mpl.usable(covariates),
              varcov      = if(VB) fit$S else NULL,
              internal    = list(Vnames  = Vnames,
                                 IsOffset=IsOffset,
                                 glmdata = glmdata,
                                 glmfit = fit,
                                 logistic = Dinfo,
                                 computed = computed)
              )
  class(fit) <- "ppm"
  return(fit)
}


forbid.logi <- function(object) {
  if(object$method == "logi")
    stop("Sorry, this is not implemented for method=\'logi\'")
  return(invisible(NULL))
}

logi.dummy <- function(X, dummytype = "stratrand", nd = NULL, mark.repeat = FALSE, ...){
  ## Resolving nd inspired by default.n.tiling
  if(is.null(nd)){
    nd <- spatstat.options("ndummy.min")
    if(inherits(X, "ppp"))
      nd <- pmax(nd, 10 * ceiling(2 * sqrt(X$n)/10))
  }
  nd <- ensure2vector(nd)
  marx <- is.multitype(X)
  if(marx)
    lev <- levels(marks(X))
  if(marx && mark.repeat){
    N <- length(lev)
    Dlist <- inDlist <- vector("list", N)
  } else{
    N <- 1
  }
  W <- as.owin(X)
  type <- match.arg(dummytype, c("stratrand", "binomial", "poisson", "grid", "transgrid"))
  B <- boundingbox(W)
  rho <- nd[1]*nd[2]/area(B)
  Dinfo <- list(nd=nd, rho=rho, how=type)
  ## Repeating dummy process for each mark type 1:N (only once if unmarked or mark.repeat = FALSE)
  for(i in 1:N){
    switch(type,
           stratrand={
             D <- as.ppp(stratrand(B, nd[1], nd[2]), W = B)
             inD <- which(inside.owin(D, w = W))
             D <- D[W]
             inD <- paste(i,inD,sep="_")
           },
           binomial={
             D <- runifpoint(nd[1]*nd[2], win=B)
             D <- D[W]
           },
           poisson={
             D <- rpoispp(rho, win = W)
           },
           grid={
             D <- as.ppp(gridcenters(B, nd[1], nd[2]), W = B)
             inD <- which(inside.owin(D, w = W))
             D <- D[W]
             inD <- paste(i,inD,sep="_")
           },
           transgrid={
             D <- as.ppp(gridcenters(B, nd[1], nd[2]), W = B)
             dxy <- c(diff(D$window$xrange),diff(D$window$yrange))/(2*nd)
             coords(D) <- coords(D)+matrix(runif(2,-dxy,dxy),npoints(D),2,byrow=TRUE)
             inD <- which(inside.owin(D, w = W))
             D <- D[W]
             inD <- paste(i,inD,sep="_")
           },
         stop("unknown dummy type"))
    if(marx && mark.repeat){
      marks(D) <- factor(lev[i], levels = lev)
      Dlist[[i]] <- D
      if(type %in% c("stratrand","grid","transgrid"))
        inDlist[[i]] <- inD
    }
  }
  if(marx && mark.repeat){
    inD <- Reduce(append, inDlist)
    D <- Reduce(superimpose, Dlist)
  }
  if(type %in% c("stratrand","grid","transgrid"))
    Dinfo <- append(Dinfo, list(inD=inD))
  if(marx && !mark.repeat){
    marks(D) <- sample(factor(lev, levels=lev), npoints(D), replace = TRUE)
    Dinfo$rho <- Dinfo$rho/length(lev)
  }
  attr(D, "dummy.parameters") <- Dinfo
  return(D)
}

quadscheme.logi <- function(data, dummy, dummytype = "stratrand", nd = NULL, mark.repeat = FALSE, ...){
  data <- as.ppp(data)
  ## If dummy is missing we generate dummy pattern with logi.dummy.
  if(missing(dummy))
    dummy <- logi.dummy(data, dummytype, nd, mark.repeat, ...)
  Dinfo <- attr(dummy, "dummy.parameters")
  D <- as.ppp(dummy)
  if(is.null(Dinfo))
    Dinfo <- list(how="given", rho=npoints(D)/(area(D)*markspace.integral(D)))
  ## Weights:
  n <- npoints(data)+npoints(D)
  w <- area(Window(data))/n
  Q <- quad(data, D, rep(w,n), param=Dinfo)
  class(Q) <- c("logiquad", class(Q))
  return(Q)
}

summary.logiquad <- function(object, ..., checkdup=FALSE) {
  verifyclass(object, "logiquad")
  s <- list(
       data  = summary.ppp(object$data, checkdup=checkdup),
       dummy = summary.ppp(object$dummy, checkdup=checkdup),
       param = object$param)
  class(s) <- "summary.logiquad"
  return(s)
}

print.summary.logiquad <- function(x, ..., dp=3) {
  cat("Quadrature scheme = data + dummy\n")
  Dinfo <- x$param
  if(is.null(Dinfo))
    cat("created by an unknown function.\n")
  cat("Data pattern:\n")
  print(x$data, dp=dp)

  cat("\n\nDummy pattern:\n")
  # How they were computed
    switch(Dinfo$how,
           stratrand={
             cat(paste("(Stratified random dummy points,",
                       paste(Dinfo$nd, collapse=" x "),
                       "grid of cells)\n"))
           },
           binomial={
             cat("(Binomial dummy points)\n")
           },
           poisson={
             cat("(Poisson dummy points)\n")
           },
           grid={
             cat(paste("(Fixed grid of dummy points,",
                       paste(Dinfo$nd, collapse=" x "),
                       "grid)\n"))
           },
           transgrid={
             cat(paste("(Random translation of fixed grid of dummy points,",
                       paste(Dinfo$nd, collapse=" x "),
                       "grid)\n"))
           },
           given=cat("(Dummy points given by user)\n")
       )
  # Description of them
  print(x$dummy, dp=dp)

  return(invisible(NULL))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/lohboot.R"
#
#  lohboot.R
#
#  $Revision: 1.13 $   $Date: 2014/10/08 10:25:26 $
#
#  Loh's bootstrap CI's for local pcf, local K etc
#

lohboot <-
  function(X,
           fun=c("pcf", "Kest", "Lest", "pcfinhom", "Kinhom", "Linhom"),
           ..., nsim=200, confidence=0.95, global=FALSE, type=7) {
  stopifnot(is.ppp(X))
  fun.name <- short.deparse(substitute(fun))
  if(is.character(fun)) {
    fun <- match.arg(fun)
  } else if(is.function(fun)) {
    flist <- list(pcf=pcf, Kest=Kest, Lest=Lest,
                  pcfinhom=pcfinhom, Kinhom=Kinhom, Linhom=Linhom)
    id <- match(list(fun), flist)
    if(is.na(id))
      stop(paste("Loh's bootstrap is not supported for the function",
                 sQuote(fun.name)))
    fun <- names(flist)[id]
  } else stop("Unrecognised format for argument fun")
  # validate confidence level
  stopifnot(confidence > 0.5 && confidence < 1)
  alpha <- 1 - confidence
  if(!global) {
    probs <- c(alpha/2, 1-alpha/2)
    rank <- nsim * probs[2]
  } else {
    probs <- 1-alpha
    rank <- nsim * probs
  }
  if(abs(rank - round(rank)) > 0.001)
    warning(paste("confidence level", confidence,
                  "corresponds to a non-integer rank", paren(rank),
                  "so quantiles will be interpolated"))
  n <- npoints(X)
  # compute local functions
  localfun <- switch(fun,
                     pcf=localpcf,
                     Kest=localK,
                     Lest=localL,
                     pcfinhom=localpcfinhom,
                     Kinhom=localKinhom,
                     Linhom=localLinhom)
  f <- localfun(X, ...)
  theo <- f$theo
  # parse edge correction info
  correction <- attr(f, "correction")
  switch(correction,
         none      = { ctag <- "un";    cadj <- "uncorrected" },
         border    = { ctag <- "bord";  cadj <- "border-corrected" },
         translate = { ctag <- "trans"; cadj <- "translation-corrected" },
         isotropic = { ctag <- "iso";   cadj <- "Ripley isotropic corrected" })
  # first n columns are the local pcfs (etc) for the n points of X
  y <- as.matrix(as.data.frame(f))[, 1:n]
  nr <- nrow(y)
  # average them
  ymean <- .rowMeans(y, na.rm=TRUE, nr, n)
  # resample
  ystar <- matrix(, nrow=nr, ncol=nsim)
  for(i in 1:nsim) {
    # resample n points with replacement
    ind <- sample(n, replace=TRUE)
    # average their local pcfs
    ystar[,i] <- .rowMeans(y[,ind], nr, n, na.rm=TRUE)
  }
  # compute quantiles
  if(!global) {
    # pointwise quantiles
    hilo <- apply(ystar, 1, quantile,
                  probs=probs, na.rm=TRUE, type=type)
  } else {
    # quantiles of deviation
    ydif <- sweep(ystar, 1, ymean)
    ydev <- apply(abs(ydif), 2, max, na.rm=TRUE)
    crit <- quantile(ydev, probs=probs, na.rm=TRUE, type=type)
    hilo <- rbind(ymean - crit, ymean + crit)
  }
  # create fv object
  df <- data.frame(r=f$r,
                   theo=theo,
                   ymean,
                   lo=hilo[1,],
                   hi=hilo[2,])
  colnames(df)[3] <- ctag
  CIlevel <- paste(100 * confidence, "%% confidence", sep="")
  desc <- c("distance argument r",
            "theoretical Poisson %s",
            paste(cadj, "estimate of %s"),
            paste("lower", CIlevel, "limit for %s"),
            paste("upper", CIlevel, "limit for %s"))
  clabl <- paste("hat(%s)[", ctag, "](r)", sep="")
  labl <- c("r", "%s[pois](r)", clabl, "%s[loCI](r)", "%s[hiCI](r)")
  switch(fun,
         pcf={ fname <- "g" ; ylab <- quote(g(r)) },
         Kest={ fname <- "K" ; ylab <- quote(K(r)) },
         Lest={ fname <- "L" ; ylab <- quote(L(r)) },
         pcfinhom={ fname <- "g[inhom]" ; ylab <- quote(g[inhom](r)) },
         Kinhom={ fname <- "K[inhom]" ; ylab <- quote(K[inhom](r)) },
         Linhom={ fname <- "L[inhom]" ; ylab <- quote(L[inhom](r)) })
  g <- fv(df, "r", ylab, ctag, , c(0, max(f$r)), labl, desc, fname=fname)
  formula(g) <- . ~ r
  fvnames(g, ".") <- c(ctag, "theo", "hi", "lo")
  fvnames(g, ".s") <- c("hi", "lo")
  unitname(g) <- unitname(X)
  g
}


    
  
  
  
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/lpp.R"
#
# lpp.R
#
#  $Revision: 1.25 $   $Date: 2014/08/09 01:56:29 $
#
# Class "lpp" of point patterns on linear networks

lpp <- function(X, L) {
  stopifnot(inherits(L, "linnet"))
  localnames <- c("seg", "tp")
  if(checkfields(X, c("x", "y", localnames))) {
    # includes spatial and local coordinates
    X <- as.data.frame(X)
    # local coords
    lo <- X[ , localnames, drop=FALSE]
    # spatial coords and marks
    df <- X[, !(names(X) %in% localnames), drop=FALSE]
    # validate local coordinates
    if(nrow(X) > 0) {
      nedge <- nobjects(as.psp(L))
      if(with(lo, any(seg < 1 || seg > nedge)))
        stop("Segment index coordinate 'seg' exceeds bounds")
      if(with(lo, any(tp < 0 || tp > 1)))
        stop("Local coordinate 'tp' outside [0,1]")
    }
  } else {
    # local coordinates must be computed
    if(!is.ppp(X))
      X <- as.ppp(X, W=L$window)
    # project to segment
    pro <- project2segment(X, as.psp(L))
    # projected points (spatial coordinates and marks)
    df  <- as.data.frame(pro$Xproj)
    # local coordinates
    lo  <- data.frame(seg=pro$mapXY, tp=pro$tp)
  }
  # combine spatial, local, marks
  nmark <- ncol(df) - 2
  if(nmark == 0) {
    df <- cbind(df, lo)
    ctype <- c(rep("s", 2), rep("l", 2))
  } else {
    df <- cbind(df[,1:2], lo, df[, -(1:2), drop=FALSE])
    ctype <- c(rep("s", 2), rep("l", 2), rep("m", nmark))
  }
  out <- ppx(data=df, domain=L, coord.type=ctype)
  class(out) <- c("lpp", class(out))
  return(out)
}

print.lpp <- function(x, ...) {
  stopifnot(inherits(x, "lpp"))
  cat("Point pattern on linear network\n")
  sd <- summary(x$data)
  np <- sd$ncases
  nama <- sd$col.names
  cat(paste(np, ngettext(np, "point", "points"), "\n"))
  if(any(iscoord <- (x$ctype == "spatial")))
    cat(paste(sum(iscoord), "-dimensional space coordinates ",
              paren(paste(nama[iscoord], collapse=",")), "\n", sep=""))
  if(any(istime <- (x$ctype == "temporal")))
    cat(paste(sum(istime), "-dimensional time coordinates ",
              paren(paste(nama[istime], collapse=",")), "\n", sep=""))
  if(any(islocal <- (x$ctype == "local"))) 
    cat(paste(sum(islocal), ngettext(sum(islocal), "column", "columns"),
              "of local coordinates:",
              commasep(sQuote(nama[islocal])), "\n"))
  if(any(ismark <- (x$ctype == "mark"))) 
    cat(paste(sum(ismark), ngettext(sum(ismark), "column", "columns"),
              "of marks:",
              commasep(sQuote(nama[ismark])), "\n"))
  print(x$domain, ...)
  invisible(NULL)
}

plot.lpp <- function(x, ..., main, add=FALSE,
                     use.marks=TRUE, which.marks=NULL,
                     show.all=!add, do.plot=TRUE, multiplot=TRUE) {
  if(missing(main))
    main <- short.deparse(substitute(x))
  ## Handle multiple columns of marks as separate plots
  ##  (unless add=TRUE or which.marks selects a single column
  ##   or multipage = FALSE)
  if(use.marks && is.data.frame(mx <- marks(x))) {
    implied.all <- is.null(which.marks)
    want.several <- implied.all || is.data.frame(mx <- mx[,which.marks])
    do.several <- want.several && !add && multiplot
    if(do.several) {
      ## generate one plot for each column of marks
      y <- as.listof(lapply(mx, function(z, P) setmarks(P,z), P=x))
      out <- do.call("plot",
                     c(list(x=y, main=main, do.plot=do.plot),
                       list(...)))
      return(invisible(out))
    } 
    if(is.null(which.marks)) {
      which.marks <- 1
      if(do.plot) message("Plotting the first column of marks")
    }
  }
  ## determine space required, including legend
  P <- as.ppp(x)
  a <- plot(P, ..., do.plot=FALSE)
  if(!do.plot) return(a)
  ## initialise graphics space
  if(!add) {
    b <- attr(a, "bbox")
    plot(b, type="n", main=main, ..., show.all=FALSE)
  }
  ## plot linear network
  L <- as.linnet(x)
  do.call.matched("plot.linnet",
                  resolve.defaults(list(x=L, add=TRUE),
                                   list(...)),
                  extrargs=c("col", "lty", "lwd"))
  ## plot points, legend, title
  ans <- do.call.matched("plot.ppp",
                         c(list(x=P, add=TRUE, main=main,
                                show.all=show.all),
                           list(...)),
                         extrargs=c("pch", "fg", "bg", "lty", "lwd",
                           "cex.main", "col.main", "line", "outer", "sub"))
  return(invisible(ans))
}


summary.lpp <- function(object, ...) {
  stopifnot(inherits(object, "lpp"))
  L <- object$domain
  npoints <- nrow(object$data)
  totlen <-  sum(lengths.psp(L$lines))
  marx <- marks(object)
  summarx <- if(is.null(marx)) NULL else summary(marx)
  out <- list(npoints=npoints,
              totlength=totlen,
              intensity=npoints/totlen,
              nvert=L$vertices$n,
              nedge=L$lines$n,
              unitinfo=summary(unitname(L)),
              marks=summarx)
  class(out) <- "summary.lpp"
  return(out)
}

print.summary.lpp <- function(x, ...) {
  cat("Point pattern on linear network\n")
  cat(paste(x$npoints, "points\n"))
  cat(paste("Linear network with",
            x$nvert, "vertices and",
            x$nedge, "edges\n"))
  u <- x$unitinfo
  cat(paste("Total edge length", x$totlength, u$plural, u$explain, "\n"))
  cat(paste("Average intensity", x$intensity,
            "points per", if(u$vanilla) "unit length" else u$singular, "\n"))
  if(!is.null(x$marks)) {
    cat("Marks:\n")
    print(x$marks)
  }
  invisible(NULL)
}

intensity.lpp <- function(X, ...) {
  len <- sum(lengths.psp(as.psp(as.linnet(X))))
  if(is.multitype(X)) table(marks(X))/len else npoints(X)/len
}

is.lpp <- function(x) {
  inherits(x, "lpp")
}

as.lpp <- function(x, y=NULL, seg=NULL, tp=NULL, ...,
                   marks=NULL, L=NULL, check=FALSE) {
  nomore <- is.null(y) && is.null(seg) && is.null(tp)
  if(inherits(x, "lpp") && nomore) {
    X <- x
  } else {
    if(!inherits(L, "linnet"))
      stop("L should be a linear network")
    if(is.ppp(x) && nomore) {
      X <- lpp(x, L)
    } else {
      xy <- xy.coords(x,y)[c("x", "y")]
      if(!is.null(seg) && !is.null(tp)) {
        # add segment map information
        xy <- append(xy, list(seg=seg, tp=tp))
      } else {
        # convert to ppp, typically suppressing check mechanism
        xy <- as.ppp(xy, W=as.owin(L), check=check)
      }
      X <- lpp(xy, L)
    }
  }
  if(!is.null(marks))
    marks(X) <- marks
  return(X)
}

as.ppp.lpp <- function(X, ..., fatal=TRUE) {
  verifyclass(X, "lpp", fatal=fatal)
  L <- X$domain
  Y <- as.ppp(coords(X, temporal=FALSE, local=FALSE),
              W=L$window, check=FALSE)
  marks(Y) <- marks(X)
  return(Y)
}

Window.lpp <- function(X, ...) { as.owin(X) }

as.owin.lpp <- function(W,  ..., fatal=TRUE) {
  as.owin(as.ppp(W, ..., fatal=fatal))
}

domain.lpp <- function(X, ...) { as.linnet(X) }

as.linnet.lpp <- function(X, ..., fatal=TRUE) {
  verifyclass(X, "lpp", fatal=fatal)
  X$domain
}
  
"[.lpp" <- function (x, i, ...) {
  # invoke [.ppx
  y <- NextMethod("[")
  class(y) <- c("lpp", class(y))
  return(y)
}

unitname.lpp <- function(x) {
  u <- unitname(x$domain)
  return(u)
}

"unitname<-.lpp" <- function(x, value) {
  w <- x$domain
  unitname(w) <- value
  x$domain <- w
  return(x)
}

"marks<-.lpp" <- function(x, ..., value) {
  Y <- NextMethod("marks<-")
  class(Y) <- c("lpp", class(Y))
  Y
}
  
unmark.lpp <- function(X) {
  Y <- NextMethod("unmark")
  class(Y) <- c("lpp", class(Y))
  Y
}

as.psp.lpp <- function(x, ..., fatal=TRUE){
  verifyclass(x, "lpp", fatal=fatal)
  return(x$domain$lines)
}

local2lpp <- function(L, seg, tp, X=NULL) {
  stopifnot(inherits(L, "linnet"))
  if(is.null(X)) {
    # map to (x,y)
    Ldf <- as.data.frame(L$lines)
    dx <- with(Ldf, x1-x0)
    dy <- with(Ldf, y1-y0)
    x <- with(Ldf, x0[seg] + tp * dx[seg])
    y <- with(Ldf, y0[seg] + tp * dy[seg])
  } else {
    x <- X$x
    y <- X$y
  }
  # compile into data frame
  data <- data.frame(x=x, y=y, seg=seg, tp=tp)
  ctype <- c("s", "s", "l", "l")
  out <- ppx(data=data, domain=L, coord.type=ctype)
  class(out) <- c("lpp", class(out))
  return(out)
}

####################################################
# subset extractor
####################################################

"[.lpp" <- function (x, i, j, ...) {
  if(!missing(i) && !is.null(i)) {
    if(is.owin(i)) {
      # spatial domain: call code for 'j'
      xi <- x[,i]
    } else {
      # usual row-type index
      da <- x$data
      daij <- da[i, , drop=FALSE]
      xi <- ppx(data=daij, domain=x$domain, coord.type=as.character(x$ctype))
      class(xi) <- c("lpp", class(xi))
    }
    x <- xi
  } 
  if(missing(j) || is.null(j))
    return(x)
  stopifnot(is.owin(j))
  W <- j
  L <- x$domain
  da <- x$data
  # Find vertices that lie inside 'j'
  okvert <- inside.owin(L$vertices, w=W)
  # find segments whose endpoints both lie in 'upper'
  okedge <- okvert[L$from] & okvert[L$to]
  # assign new serial numbers to vertices, and recode 
  newserial <- cumsum(okvert)
  newfrom <- newserial[L$from[okedge]]
  newto   <- newserial[L$to[okedge]]
  # make new linear network
  Lnew <- linnet(L$vertices[W], edges=cbind(newfrom, newto))
  # find data points that lie on accepted segments
  coo <- coords(x)
  okxy <- okedge[coo$seg]
  cook <- coo[okxy,]
  # make new lpp object
  dfnew <- data.frame(x=cook$x,
                      y=cook$y,
                      seg=cook$seg,
                      tp=cook$tp)
  ctype <- c(rep("spatial", 2), rep("local", 2))
  xj <- ppx(data=dfnew, domain=Lnew, coord.type=ctype)
  class(xj) <- c("lpp", class(xj))
  marks(xj) <- marks(x[okxy])
  return(xj)
}

####################################################
# affine transformations
####################################################

scalardilate.lpp <- function(X, f, ...) {
  trap.extra.arguments(..., .Context="In scalardilate(X,f)")
  check.1.real(f, "In scalardilate(X,f)")
  stopifnot(is.finite(f) && f > 0)
  Y <- X
  Y$data$x <- f * X$data$x
  Y$data$y <- f * X$data$y
  Y$domain <- scalardilate(X$domain, f)
  return(Y)
}

affine.lpp <- function(X,  mat=diag(c(1,1)), vec=c(0,0), ...) {
  verifyclass(X, "lpp")
  Y <- X
  Y$data[, c("x","y")] <- affinexy(X$data[, c("x","y")], mat=mat, vec=vec)
  Y$domain <- affine(X$domain, mat=mat, vec=vec, ...)
  return(Y)
}

shift.lpp <- function(X, vec=c(0,0), ..., origin=NULL) {
  verifyclass(X, "lpp")
  Y <- X
  Y$domain <- shift(X$domain, vec=vec, ..., origin=origin)
  vec <- getlastshift(Y$domain)
  Y$data[, c("x","y")] <- shiftxy(X$data[, c("x","y")], vec=vec)
  # tack on shift vector
  attr(Y, "lastshift") <- vec
  return(Y)
}

rotate.lpp <- function(X, angle=pi/2, ..., centre=NULL) {
  verifyclass(X, "lpp")
  if(!is.null(centre)) {
    X <- shift(X, origin=centre)
    negorigin <- getlastshift(X)
  } else negorigin <- NULL
  Y <- X
  Y$data[, c("x","y")] <- rotxy(X$data[, c("x","y")], angle=angle)
  Y$domain <- rotate(X$domain, angle=angle, ...)
  if(!is.null(negorigin))
    Y <- shift(Y, -negorigin)
  return(Y)
}

rescale.lpp <- function(X, s, unitname) {
  if(missing(unitname)) unitname <- NULL
  if(missing(s)) s <- 1/unitname(X)$multiplier
  Y <- scalardilate(X, f=1/s)
  unitname(Y) <- rescale(unitname(X), s, unitname)
  return(Y)
}

superimpose.lpp <- function(..., L=NULL) {
  objects <- list(...)
  if(!is.null(L) && !inherits(L, "linnet"))
    stop("L should be a linear network")
  if(length(objects) == 0) {
    if(is.null(L)) return(NULL)
    emptyX <- lpp(list(x=numeric(0), y=numeric(0)), L)
    return(emptyX)
  }
  islpp <- unlist(lapply(objects, is.lpp))
  if(is.null(L) && !any(islpp))
    stop("Cannot determine linear network: no lpp objects given")
  nets <- unique(lapply(objects[islpp], as.linnet))
  if(length(nets) > 1)
    stop("Point patterns are defined on different linear networks")
  if(!is.null(L)) {
    nets <- unique(append(nets, list(L)))
    if(length(nets) > 1)
      stop("Argument L is a different linear network")
  }
  L <- nets[[1]]
  ## convert list(x,y) to linear network, etc
  if(any(!islpp))
    objects[!islpp] <- lapply(objects[!islpp], lpp, L=L)
  ## concatenate coordinates 
  locns <- do.call("rbind", lapply(objects, coords))
  ## concatenate marks (or use names of arguments)
  marx <- superimposeMarks(objects, sapply(objects, npoints))
  ## make combined pattern
  Y <- lpp(locns, L)
  marks(Y) <- marx
  return(Y)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/lppm.R"
#
#  lppm.R
#
#  Point process models on a linear network
#
#  $Revision: 1.23 $   $Date: 2014/11/20 11:04:37 $
#

lppm <- function(X, ...) {
  UseMethod("lppm")
}


lppm.formula <- function(X, interaction=NULL, ..., data=NULL) {
  ## remember call
  callstring <- short.deparse(sys.call())
  ## cl <- match.call()

  ########### INTERPRET FORMULA ##############################
  
  if(!inherits(X, "formula"))
    stop(paste("Argument 'X' should be a formula"))
  formula <- X
  
  if(spatstat.options("expand.polynom"))
    formula <- expand.polynom(formula)

  ## check formula has LHS and RHS. Extract them
  if(length(formula) < 3)
    stop(paste("Formula must have a left hand side"))
  Yexpr <- formula[[2]]
  trend <- formula[c(1,3)]
  
  ## FIT #######################################
  thecall <- call("lppm", X=Yexpr, trend=trend,
                  data=data, interaction=interaction)
  ncall <- length(thecall)
  argh <- list(...)
  nargh <- length(argh)
  if(nargh > 0) {
    thecall[ncall + 1:nargh] <- argh
    names(thecall)[ncall + 1:nargh] <- names(argh)
  }
  result <- eval(thecall, parent.frame())

  if(!("callstring" %in% names(list(...))))
    result$callstring <- callstring
  
  return(result)
}

lppm.lpp <- function(X, ..., eps=NULL, nd=1000) {
  Xname <- short.deparse(substitute(X))
  nama <- names(list(...))
  resv <- c("method", "forcefit")
  if(any(clash <- resv %in% nama))
    warning(paste(ngettext(sum(clash), "Argument", "Arguments"),
                  commasep(sQuote(resv[clash])),
                  "must not be used"))
  stopifnot(inherits(X, "lpp"))
  Q <- linequad(X, eps=eps, nd=nd)
  fit <- ppm(Q, ..., method="mpl", forcefit=TRUE)
  if(!is.poisson.ppm(fit))
    warning("Non-Poisson models currently use Euclidean distance")
  out <- list(X=X, fit=fit, Xname=Xname)
  class(out) <- "lppm"
  return(out)
}

is.lppm <- function(x) { inherits(x, "lppm") }

predict.lppm <- function(object, ..., 
                         type="trend", locations=NULL,
                         new.coef=NULL) {
  type <- pickoption("type", type,
                     c(trend="trend", cif="cif", lambda="cif"))
  X <- object$X
  fit <- object$fit
  L <- as.linnet(X)

  if(!is.null(locations)) {
    # locations given; return a vector of predicted values
    values <- predict(fit, locations=locations, type=type, new.coef=new.coef)
    return(values)
  }
  
  # locations not given; want a pixel image
  # pixellate the lines
  Llines <- as.psp(L)
  linemask <- as.mask.psp(Llines, ...)
  lineimage <- as.im(linemask)
  # extract pixel centres
  xx <- rasterx.mask(linemask)
  yy <- rastery.mask(linemask)
  mm <- linemask$m
  xx <- as.vector(xx[mm])
  yy <- as.vector(yy[mm])
  pixelcentres <- ppp(xx, yy, window=as.rectangle(linemask), check=FALSE)
  pixdf <- data.frame(xc=xx, yc=yy)
  # project pixel centres onto lines
  p2s <- project2segment(pixelcentres, Llines)
  projloc <- as.data.frame(p2s$Xproj)
  projmap <- as.data.frame(p2s[c("mapXY", "tp")])
  projdata <- cbind(pixdf, projloc, projmap)
  # predict at the projected points
  if(!is.multitype(fit)) {
    values <- predict(fit, locations=projloc, type=type, new.coef=new.coef)
    # map to nearest pixels
    Z <- lineimage
    Z[pixelcentres] <- values
    # attach exact line position data
    df <- cbind(projdata, values)
    out <- linim(L, Z, df=df)
  } else {
    # predict for each type
    lev <- levels(marks(data.ppm(fit)))
    out <- list()
    for(k in seq(length(lev))) {
      markk <- factor(lev[k], levels=lev)
      locnk <- cbind(projloc, data.frame(marks=markk))
      values <- predict(fit, locations=locnk, type=type, new.coef=new.coef)
      Z <- lineimage
      Z[pixelcentres] <- values
      df <- cbind(projdata, values)
      out[[k]] <- linim(L, Z, df=df)
    }
    names(out) <- as.character(lev)
    class(out) <- c("listof", class(out))
  }
  return(out)
}

coef.lppm <- function(object, ...) {
  coef(object$fit)
}

print.lppm <- function(x, ...) {
  cat("Point process model on linear network\n")
  print(x$fit)
  cat("Linear network:\n")
  print(as.linnet(x))
  cat(paste("Original data:", x$Xname, "\n"))
  return(invisible(NULL))
}

plot.lppm <- function(x, ..., type="trend") {
  xname <- short.deparse(substitute(x))
  y <- predict(x, type=type)
  do.call("plot", resolve.defaults(list(y),
                                   list(...),
                                   list(main=xname)))
}
  
anova.lppm <- function(object, ..., test=NULL, override=FALSE) {
  stuff <- list(object=object, ...)
  # extract ppm objects where appropriate
  stuff <- lapply(stuff, function(z) { if(inherits(z, "lppm")) z$fit else z })
  # analysis of deviance for 
  do.call("anova.ppm", append(stuff, list(test=test, override=override)))
}

update.lppm <- function(object, ...) {
  stopifnot(inherits(object, "lppm"))
  X <- object$X
  fit <- object$fit
  Xname <- object$Xname
  aargh <- list(...)
  islpp <- unlist(lapply(aargh, inherits, what="lpp"))
  if(!any(islpp)) {
    # pass arguments through to update.ppm
    newfit <- do.call("update.ppm", append(list(fit), aargh))
    newX <- X
  } else {
    # trap point pattern argument & convert to quadscheme
    if((npp <- sum(islpp)) > 1)
      stop(paste("Arguments not understood:", npp, "lpp objects given"))
    newX <- aargh[[which(islpp)]]
    newQ <- linequad(newX)
    newfit <- do.call("update.ppm",
                      append(list(fit, newQ), aargh[!islpp]))
  } 
  if(!is.poisson.ppm(newfit))
    warning("Non-Poisson models currently use Euclidean distance")
  out <- list(X=newX, fit=newfit, Xname=Xname)
  class(out) <- "lppm"
  return(out)
}

terms.lppm <- function(x, ...) {
  terms(x$fit, ...)
}

logLik.lppm <- function(object, ...) {
  logLik(object$fit, ...)
}

formula.lppm <- function(x, ...) {
  formula(x$fit, ...)
}

extractAIC.lppm <- function(fit, ...) {
  extractAIC(fit$fit, ...)
}

as.owin.lppm <- function(W, ..., fatal=TRUE) {
  stopifnot(inherits(W, "lppm"))
  as.owin(as.linnet(W), ..., fatal=fatal)
}

Window.lppm <- function(X, ...) { as.owin(X) }


model.images.lppm <- function(object, L=as.linnet(object), ...) {
  stopifnot(inherits(object, "lppm"))
  stopifnot(inherits(L, "linnet"))
  m <- model.images(object$fit, W=as.rectangle(L), ...)
  if(length(m) > 0) {
    ## restrict images to L
    rasta <- as.mask(m[[1]])
    DL <- as.mask.psp(as.psp(L), xy=rasta)
    ZL <- as.im(DL)
    if(!is.hyperframe) {
      ## list of images
      m <- lapply(m, function(x, Z) eval.im(x * Z), Z=ZL)
      ## convert to linim
      m <- lapply(m, function(x, L) linim(L,x), L=L)
      return(as.listof(m))
    } else {
      ## hyperframe, each column being a list of images
      mm <- lapply(as.list(m),
                   function(a) {
                     b <- lapply(a, function(x, Z) eval.im(x * Z), Z=ZL)
                     b <- lapply(b, function(x, L) linim(L,x), L=L)
                     return(as.listof(b))
                   })
      m <- do.call(hyperframe, mm)
    }
  }
  return(m)
}
  
model.matrix.lppm <- function(object, data=model.frame(object),
                             ..., keepNA=TRUE) {
  stopifnot(inherits(object, "lppm"))
  model.matrix(object$fit, data=data, ..., keepNA=keepNA)
}

model.frame.lppm <- function(formula, ...) {
  stopifnot(inherits(formula, "lppm"))
  model.frame(formula$fit, ...)
}

domain.lppm <- as.linnet.lppm <- function(X, ...) {
  as.linnet(X$X, ...)
}

nobs.lppm <- function(object, ...) {
  npoints(object$X)
}

is.poisson.lppm <- function(x) { is.poisson(x$fit) }

is.stationary.lppm <- function(x) { is.stationary(x$fit) }

is.multitype.lppm <- function(X, ...) { is.multitype(X$fit) }

is.marked.lppm <- function(X, ...) { is.marked(X$fit) }

vcov.lppm <- function(object, ...) {
  if(!is.poisson(object))
    stop("vov.lppm is only implemented for Poisson models")
  vcov(object$fit, ...)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/lurking.R"
# Lurking variable plot for arbitrary covariate.
#
#
# $Revision: 1.40 $ $Date: 2014/12/19 16:26:13 $
#

lurking <- function(object, covariate, type="eem",
                    cumulative=TRUE,
                    clipwindow=default.clipwindow(object),
                    rv = NULL,
                    plot.sd=is.poisson(object), 
                    envelope=FALSE, nsim=39, nrank=1,
                    plot.it=TRUE,
                    typename,
                    covname, oldstyle=FALSE,
                    check=TRUE, ..., splineargs=list(spar=0.5),
                    verbose=TRUE) {
  cl <- match.call()
  # default name for covariate
  if(missing(covname)) {
    covname <- if(is.name(cl$covariate)) as.character(cl$covariate) else
               if(is.language(cl$covariate)) format(cl$covariate) else NULL
  }

  if(!identical(envelope, FALSE)) {
    ## compute simulation envelope
    Xsim <- NULL
    if(!identical(envelope, TRUE)) {
      ## some kind of object
      Y <- envelope
      if(is.list(Y) && all(sapply(Y, is.ppp))) {
        Xsim <- Y
        envelope <- TRUE
      } else if(inherits(Y, "envelope")) {
        Xsim <- attr(Y, "simpatterns")
        if(is.null(Xsim))
          stop("envelope does not contain simulated point patterns")
        envelope <- TRUE
      } else stop("Unrecognised format of argument: envelope")
      nXsim <- length(Xsim)
      if(missing(nsim) && (nXsim < nsim)) {
        warning(paste("Only", nXsim, "simulated patterns available"))
        nsim <- nXsim
      }
    }
  }
    
  # validate object
  if(is.ppp(object)) {
    X <- object
    object <- ppm(X ~1, forcefit=TRUE)
  } else verifyclass(object, "ppm")

  # may need to refit the model
  if(plot.sd && is.null(getglmfit(object)))
    object <- update(object, forcefit=TRUE, use.internal=TRUE)

  
  # match type argument
  type <- pickoption("type", type,
                     c(eem="eem",
                       raw="raw",
                       inverse="inverse",
                       pearson="pearson",
                       Pearson="pearson"))
  if(missing(typename))
    typename <- switch(type,
                       eem="exponential energy weights",
                       raw="raw residuals",
                       inverse="inverse-lambda residuals",
                       pearson="Pearson residuals")

  # extract spatial locations
  Q <- quad.ppm(object)
  datapoints <- Q$data
  quadpoints <- union.quad(Q)
  Z <- is.data(Q)
  wts <- w.quad(Q)
  # subset of quadrature points used to fit model
  subQset <- getglmsubset(object)
  if(is.null(subQset)) subQset <- rep.int(TRUE, n.quad(Q))
  
  #################################################################
  # compute the covariate

  if(is.im(covariate)) {
    covvalues <- covariate[quadpoints, drop=FALSE]
  } else if(is.vector(covariate) && is.numeric(covariate)) {
    covvalues <- covariate
    if(length(covvalues) != quadpoints$n)
      stop("Length of covariate vector,", length(covvalues), "!=",
           quadpoints$n, ", number of quadrature points")
  } else if(is.expression(covariate)) {
    # Expression involving covariates in the model
    glmdata <- getglmdata(object)
    # Fix special cases
    if(is.null(glmdata)) {
      # default 
      glmdata <- data.frame(x=quadpoints$x, y=quadpoints$y)
      if(is.marked(quadpoints))
        glmdata$marks <- marks(quadpoints)
    }
    # ensure x and y are in data frame 
    if(!all(c("x","y") %in% names(glmdata))) {
      glmdata$x <- quadpoints$x
      glmdata$y <- quadpoints$y
    } 
    if(!is.null(object$covariates)) {
      # Expression may involve an external covariate that's not used in model
      neednames <- all.vars(covariate)
      if(!all(neednames %in% colnames(glmdata))) {
        moredata <- mpl.get.covariates(object$covariates, quadpoints,
                                       covfunargs=object$covfunargs)
        use <- !(names(moredata) %in% colnames(glmdata))
        glmdata <- cbind(glmdata, moredata[,use,drop=FALSE])
      }
    }
    # Evaluate expression
    sp <- parent.frame()
    covvalues <- eval(covariate, envir= glmdata, enclos=sp)
    if(!is.numeric(covvalues))
      stop("The evaluated covariate is not numeric")
  } else 
    stop(paste("The", sQuote("covariate"), "should be either",
               "a pixel image, an expression or a numeric vector"))

  #################################################################
  # Validate covariate values

  nbg <- is.na(covvalues)
  if(any(offending <- nbg && subQset)) {
    if(is.im(covariate))
      warning(paste(sum(offending), "out of", length(offending),
                    "quadrature points discarded because",
                    ngettext(sum(offending), "it lies", "they lie"),
                    "outside the domain of the covariate image"))
    else
      warning(paste(sum(offending), "out of", length(offending),
                 "covariate values discarded because",
                 ngettext(sum(offending), "it is NA", "they are NA")))
  }
  # remove points
  ok <- !nbg & subQset
  Q <- Q[ok]
  covvalues <- covvalues[ok]
  quadpoints <- quadpoints[ok]
  # adjust
  Z <- is.data(Q)
  wts <- w.quad(Q)
  if(any(is.infinite(covvalues) | is.nan(covvalues)))
    stop("covariate contains Inf or NaN values")

  # Quadrature points marked by covariate value
  covq <- quadpoints %mark% as.numeric(covvalues)

  ################################################################
  # Residuals/marks attached to appropriate locations.
  # Stoyan-Grabarnik weights are attached to the data points only.
  # Others (residuals) are attached to all quadrature points.

  resvalues <- 
    if(!is.null(rv)) rv
    else if(type=="eem") eem(object, check=check)
    else residuals.ppm(object, type=type, check=check)
  
  if(inherits(resvalues, "msr")) {
    # signed or vector-valued measure
    resvalues <- resvalues$val
    if(ncol(as.matrix(resvalues)) > 1)
      stop("Not implemented for vector measures; use [.msr to split into separate components")
  }

  if(type != "eem")
    resvalues <- resvalues[ok]

  res <- (if(type == "eem") datapoints else quadpoints) %mark% as.numeric(resvalues)

  # ... and the same locations marked by the covariate
  covres <- if(type == "eem") covq[Z] else covq

  # NAMES OF THINGS
  # name of the covariate
  if(is.null(covname)) 
    covname <- if(is.expression(covariate)) covariate else "covariate"
  # type of residual/mark
  if(missing(typename)) 
    typename <- if(!is.null(rv)) "rv" else ""

  #######################################################################
  # START ANALYSIS
  # Clip to subwindow if needed
  clip <- !is.poisson.ppm(object) ||
              (!missing(clipwindow) && !is.null(clipwindow))
  if(clip) {
    covq <- covq[clipwindow]
    res <- res[clipwindow]
    covres <- covres[clipwindow]
    clipquad <- inside.owin(quadpoints$x, quadpoints$y, clipwindow)
    wts <- wts[ clipquad ]
  }

  # -----------------------------------------------------------------------
  # (A) EMPIRICAL CUMULATIVE FUNCTION
  # based on data points if type="eem", otherwise on quadrature points

    # cumulative sums which ignore NA's
    cumsumna <- function(x) {
      x[is.na(x)] <- 0
      return(cumsum(x))
    }

      # Reorder the data/quad points in order of increasing covariate value
      # and then compute the cumulative sum of their residuals/marks
    markscovres <- marks(covres)
    o <- fave.order(markscovres)
    covsort <- markscovres[o]
    cummark <- cumsumna(marks(res)[o])
      # we'll plot(covsort, cummark) in the cumulative case

  # (B) THEORETICAL MEAN CUMULATIVE FUNCTION
  # based on all quadrature points
    
      # Range of covariate values
    covqmarks <- marks(covq)
    covrange <- range(covqmarks, na.rm=TRUE)
      # Suitable breakpoints
    cvalues <- seq(from=covrange[1], to=covrange[2], length.out=100)
    csmall <- cvalues[1] - diff(cvalues[1:2])
    cbreaks <- c(csmall, cvalues)
      # cumulative area as function of covariate values
    covclass <- cut(covqmarks, breaks=cbreaks)
    increm <- tapply(wts, covclass, sum)
    cumarea <- cumsumna(increm)
      # compute theoretical mean (when model is true)
    mean0 <- if(type == "eem") cumarea else numeric(length(cumarea))
      # we'll plot(cvalues, mean0) in the cumulative case

  # (A'),(B') DERIVATIVES OF (A) AND (B)
  #  Required if cumulative=FALSE  
  #  Estimated by spline smoothing (with x values jittered)
    if(!cumulative) {
      # fit smoothing spline to (A) 
      ss <- do.call("smooth.spline",
                    append(list(covsort, cummark),
                           splineargs)
                    )
      # estimate derivative of (A)
      derivmark <- predict(ss, covsort, deriv=1)$y 
      # similarly for (B) 
      ss <- do.call("smooth.spline",
                    append(list(cvalues, mean0),
                           splineargs)
                    )
      derivmean <- predict(ss, cvalues, deriv=1)$y
    }
  
  # -----------------------------------------------------------------------
  # Store what will be plotted
  
   if(cumulative) {
     empirical <- data.frame(covariate=covsort, value=cummark)
     theoretical <- data.frame(covariate=cvalues, mean=mean0)
   } else {
     empirical <- data.frame(covariate=covsort, value=derivmark)
     theoretical <- data.frame(covariate=cvalues, mean=derivmean)
   }

  # ------------------------------------------------------------------------
  
    # (C) STANDARD DEVIATION if desired
    # (currently implemented only for Poisson)
    # (currently implemented only for cumulative case)

    if(plot.sd && !is.poisson.ppm(object))
      warning(paste("standard deviation is calculated for Poisson model;",
                    "not valid for this model"))

    if(plot.sd && cumulative) {
      # Fitted intensity at quadrature points
      lambda <- fitted.ppm(object, type="trend", check=check)
      lambda <- lambda[ok]
      # Fisher information for coefficients
      asymp <- vcov(object,what="internals")
      Fisher <- asymp$fisher
      # Local sufficient statistic at quadrature points
      suff <- asymp$suff
      suff <- suff[ok, ,drop=FALSE]
      # Clip if required
      if(clip) {
        lambda <- lambda[clipquad]
        suff   <- suff[clipquad, , drop=FALSE]  # suff is a matrix
      }
      # First term: integral of lambda^(2p+1)
      switch(type,
             pearson={
               varI <- cumarea
             },
             raw={
               # Compute sum of w*lambda for quadrature points in each interval
               dvar <- tapply(wts * lambda, covclass, sum)
               # tapply() returns NA when the table is empty
               dvar[is.na(dvar)] <- 0
               # Cumulate
               varI <- cumsum(dvar)
             },
             inverse=, # same as eem
             eem={
               # Compute sum of w/lambda for quadrature points in each interval
               dvar <- tapply(wts / lambda, covclass, sum)
               # tapply() returns NA when the table is empty
               dvar[is.na(dvar)] <- 0
               # Cumulate
               varI <- cumsum(dvar)
             })

      # variance-covariance matrix of coefficients
      V <- try(solve(Fisher), silent=TRUE)
      if(inherits(V, "try-error")) {
        warning("Fisher information is singular; reverting to oldstyle=TRUE")
        oldstyle <- TRUE
      }
      
      # Second term: B' V B
      if(oldstyle) {
        varII <- 0
      } else {
        # lamp = lambda^(p + 1)
        lamp <- switch(type,
                       raw     = lambda, 
                       pearson = sqrt(lambda),
                       inverse =,
                       eem     = as.integer(lambda > 0))
        # Compute sum of w * lamp * suff for quad points in intervals
        Bcontrib <- as.vector(wts * lamp) * suff
        dB <- matrix(, nrow=length(cumarea), ncol=ncol(Bcontrib))
        for(j in seq_len(ncol(dB))) 
          dB[,j] <- tapply(Bcontrib[,j], covclass, sum, na.rm=TRUE)
        # tapply() returns NA when the table is empty
        dB[is.na(dB)] <- 0
        # Cumulate columns
        B <- apply(dB, 2, cumsum)
        # compute B' V B for each i 
        varII <- diag(B %*% V %*% t(B))
      }
      #
      # variance of residuals
      varR <- varI - varII
      # trap numerical errors
      nbg <- (varR < 0)
      if(any(nbg)) {
        ran <- range(varR)
        varR[nbg] <- 0
        relerr <- abs(ran[1]/ran[2])
        nerr <- sum(nbg)
        if(relerr > 1e-6) {
          warning(paste(nerr, "negative",
                        ngettext(nerr, "value (", "values (min="),
                        signif(ran[1], 4), ")",
                        "of residual variance reset to zero",
                        "(out of", length(varR), "values)"))
        }
      }
      theoretical$sd <- sqrt(varR)
    }

  ## 
  if(envelope) {
    ## compute envelopes by simulation
    cl$plot.it <- FALSE
    cl$envelope <- FALSE
    cl$rv <- NULL
    if(is.null(Xsim))
      Xsim <- simulate(object, nsim=nsim, progress=verbose)
    values <- NULL
    if(verbose) cat("Processing.. ")
    for(i in seq_len(nsim)) {
      cl$object <- update(object, Xsim[[i]])
      result.i <- eval(cl, parent.frame())
      ## interpolate empirical values onto common sequence
      f.i <- with(result.i$empirical,
                  approxfun(covariate, value, rule=2))
      val.i <- f.i(theoretical$covariate)
      values <- cbind(values, val.i)
      if(verbose) progressreport(i, nsim)
    }
    if(verbose) cat("Done.\n")
    hilo <- if(nrank == 1) apply(values, 1, range) else
            apply(values, 1, function(x, n) { sort(x)[n] },
                  n=c(nrank, nsim-nrank+1))
    theoretical$upper <- hilo[1,]
    theoretical$lower <- hilo[2,]
  }
    # ---------------  PLOT THEM  ----------------------------------
    if(plot.it) {
      # work out plot range
      mr <- range(0, empirical$value, theoretical$mean, na.rm=TRUE)
      if(!is.null(theoretical$sd))
        mr <- range(mr,
                    theoretical$mean + 2 * theoretical$sd,
                    theoretical$mean - 2 * theoretical$sd,
                    na.rm=TRUE)
      if(!is.null(theoretical$upper))
        mr <- range(mr, theoretical$upper, theoretical$lower, na.rm=TRUE)

      # start plot
      vname <- paste(if(cumulative)"cumulative" else "marginal", typename)
      do.call("plot",
              resolve.defaults(
                               list(covrange, mr),
                               list(type="n"),
                               list(...),
                               list(xlab=covname, ylab=vname)))
      # envelopes
      if(!is.null(theoretical$upper)) {
        xx <- with(theoretical, c(covariate, rev(covariate)))
        yy <- with(theoretical, c(upper, rev(lower)))
        do.call.matched(polygon,
                        resolve.defaults(list(x=xx, y=yy),
                                         list(...),
                                         list(border=NA, col="grey")))
      }
      # (A)/(A') Empirical
      lines(value ~ covariate, empirical, ...)
      # (B)/(B') Theoretical mean
      do.call("lines",
              resolve.defaults(
                               list(mean ~ covariate, theoretical),
                               list(...),
                               list(lty=2)))
      # (C) Standard deviation 
      if(!is.null(theoretical$sd)) {
        do.call("lines",
                resolve.defaults(
                                 list(mean + 2 * sd ~ covariate, theoretical),
                                 list(...),
                                 list(lty=3)))
        do.call("lines",
                resolve.defaults(
                                 list(mean - 2 * sd ~ covariate, theoretical),
                                 list(...),
                                 list(lty=3)))
      }
    }
  
    # ----------------  RETURN COORDINATES ----------------------------
  stuff <- list(empirical=empirical, theoretical=theoretical)

  return(invisible(stuff))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/markcorr.R"
##
##
##     markcorr.R
##
##     $Revision: 1.69 $ $Date: 2014/11/10 10:58:11 $
##
##    Estimate the mark correlation function
##    and related functions 
##    
## ------------------------------------------------------------------------

markvario <- local({

  halfsquarediff <- function(m1, m2) { ((m1-m2)^2)/2 }

  markvario <- 
    function(X, correction=c("isotropic", "Ripley", "translate"),
             r=NULL, method="density", ..., normalise=FALSE) {
      m <- onecolumn(marks(X))
      if(!is.numeric(m))
        stop("Marks are not numeric")
      if(missing(correction))
        correction <- NULL
      ## Compute estimates
      v <- markcorr(X, f=halfsquarediff, 
                    r=r, correction=correction, method=method,
                    normalise=normalise, ...)
      ## adjust theoretical value
      v$theo <- if(normalise) 1 else var(m)    
      ## fix labels
      v <- rebadge.fv(v,
                      quote(gamma(r)),
                      "gamma")
      return(v)
    }

  markvario
})

markconnect <- local({

  indicateij <- function(m1, m2, i, j) { (m1 == i) & (m2 == j) }
  
  markconnect <- function(X, i, j, r=NULL, 
                          correction=c("isotropic", "Ripley", "translate"),
                          method="density", ..., normalise=FALSE) {
    stopifnot(is.ppp(X) && is.multitype(X))
    if(missing(correction))
      correction <- NULL
    marx <- marks(X)
    lev  <- levels(marx)
    if(missing(i)) i <- lev[1]
    if(missing(j)) j <- lev[2]
    ## compute estimates
    p <- markcorr(X, f=indicateij, r=r,
                  correction=correction, method=method,
                  ...,
                  fargs=list(i=i, j=j),
                  normalise=normalise)
    ## alter theoretical value and fix labels
    if(!normalise) {
      pipj <- mean(marx==i) * mean(marx==j) 
      p$theo <- pipj
    } else {
      p$theo <- 1
    }
    p <- rebadge.fv(p,
                    new.ylab=substitute(p[i,j](r), list(i=paste(i),j=paste(j))),
                    new.fname=c("p", paste0("list(", i, ",", j, ")")),
                    new.yexp=substitute(p[list(i,j)](r),
                      list(i=paste(i),j=paste(j))))
    return(p)
  }
  markconnect
})


Emark <- local({

  f1 <- function(m1, m2) { m1 }

  Emark <- function(X, r=NULL, 
                    correction=c("isotropic", "Ripley", "translate"),
                    method="density", ..., normalise=FALSE) {
    stopifnot(is.ppp(X) && is.marked(X) && is.numeric(marks(X)))
    if(missing(correction))
      correction <- NULL
    E <- markcorr(X, f1, r=r,
                  correction=correction, method=method,
                  ..., normalise=normalise)
    E <- rebadge.fv(E, quote(E(r)), "E")
    return(E)
  }

  Emark
})

Vmark <- local({

  f2 <- function(m1, m2) { m1^2 }

  Vmark <- function(X, r=NULL, 
                    correction=c("isotropic", "Ripley", "translate"),
                    method="density", ..., normalise=FALSE) {
    if(missing(correction))
      correction <- NULL
    E <- Emark(X, r=r, correction=correction, method=method, ...,
             normalise=FALSE)
    E2 <- markcorr(X, f2, r=E$r,
                   correction=correction, method=method,
                   ..., normalise=FALSE)
    V <- eval.fv(E2 - E^2)
    if(normalise) {
      sig2 <- var(marks(X))
      V <- eval.fv(V/sig2)
    }
    V <- rebadge.fv(V, quote(V(r)), "V")
    attr(V, "labl") <- attr(E, "labl")
    return(V)
  }

  Vmark
})

############## workhorses 'markcorr' and 'markcorrint' ####################

markcorrint <-
  function(X, f=NULL, r=NULL, 
           correction=c("isotropic", "Ripley", "translate"), ...,
           f1=NULL, normalise=TRUE, returnL=FALSE, fargs=NULL) {
  ## Computes the analogue of Kest(X)
  ## where each pair (x_i,x_j) is weighted by w(m_i,m_j)
  ##
  ## If multiplicative=TRUE then w(u,v) = f(u) f(v)
  ## If multiplicative=FALSE then w(u,v) = f(u, v)
  ##
  stopifnot(is.ppp(X) && is.marked(X))
  is.marked(X, dfok=FALSE)
  W <- Window(X)
  ## validate test function
  h <- check.testfun(f, f1, X)
  f     <- h$f
  f1    <- h$f1
  ftype <- h$ftype
  multiplicative <- ftype %in% c("mul", "product")
  ## 
  ## check corrections
  correction.given <- !missing(correction) && !is.null(correction)
  if(is.null(correction))
    correction <- c("isotropic", "Ripley", "translate")
  correction <- pickoption("correction", correction,
                           c(none="none",
                             border="border",
                             "bord.modif"="bord.modif",
                             isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             best="best"),
                           multi=TRUE)

  correction <- implemented.for.K(correction, W$type, correction.given)

  isborder  <- correction %in% c("border", "bord.modif")
  if(any(isborder) && !multiplicative) {
    whinge <- paste("Border correction is not valid unless",
                    "test function is of the form f(u,v) = f1(u)*f1(v)")
    correction <- correction[!isborder]
    if(length(correction) == 0)
      stop(whinge)
    else
      warning(whinge)
  }
  ## estimated intensity
  lambda <- intensity(X)
  mX <- marks(X)
  switch(ftype,
         mul={
           wt <- mX/lambda
           K <- Kinhom(X, r=r, reciplambda=wt, correction=correction, ...)
           Ef2 <- mean(mX)^2
         },
         equ={
           fXX <- outer(mX, mX, "==")
           wt <- fXX/lambda^2
           K <- Kinhom(X, r=r, reciplambda2=wt, correction=correction, ...)
           mtable <- table(mX)
           Ef2 <- sum(mtable^2)/length(mX)^2
         },
         product={
           f1X <- do.call(f1, append(list(mX), fargs))
           wt <- f1X/lambda
           K <- Kinhom(X, r=r, reciplambda=wt, correction=correction, ...)
           Ef2 <- mean(f1X)^2
         },
         general={
           fXX <- do.call("outer", append(list(mX, mX, f), fargs))
           wt <- fXX/lambda^2
           K <- Kinhom(X, r=r, reciplambda2=wt, correction=correction, ...)
           Ef2 <- mean(fXX)
         })
  K$theo <- K$theo * Ef2
  labl <- attr(K, "labl")
  if(normalise)
    K <- eval.fv(K/Ef2)
  if(returnL)
    K <- eval.fv(sqrt(K/pi))
  attr(K, "labl") <- labl
  if(normalise && !returnL) {
    ylab <- quote(K[f](r))
    fnam <- c("K", "f")
  } else if(normalise && returnL) {
    ylab <- quote(L[f](r))
    fnam <- c("L", "f")
  } else if(!normalise && !returnL) {
    ylab <- quote(C[f](r))
    fnam <- c("C", "f")
  } else {
    ylab <- quote(sqrt(C[f](r)/pi))
    fnam <- "sqrt(C[f]/pi)"
  }
  K <- rebadge.fv(K, ylab, fnam)
  return(K)
}

markcorr <-
  function(X, f = function(m1, m2) { m1 * m2}, r=NULL, 
           correction=c("isotropic", "Ripley", "translate"),
           method="density", ..., f1=NULL, normalise=TRUE, fargs=NULL)
{
  ## mark correlation function with test function f
  stopifnot(is.ppp(X) && is.marked(X))
  
  ## set defaults to NULL
  if(missing(f)) f <- NULL
  if(missing(correction)) correction <- NULL
  
  ## handle data frame of marks
  marx <- marks(X, dfok=TRUE)
  if(is.data.frame(marx)) {
    nc <- ncol(marx)
    result <- list()
    for(j in 1:nc) {
      Xj <- X %mark% marx[,j]
      result[[j]] <- markcorr(Xj, f=f, r=r, correction=correction,
                              method=method, ...,
                              f1=f1, normalise=normalise, fargs=fargs)
    }
    result <- as.listof(result)
    names(result) <- colnames(marx)
    return(result)
  }
  
  ## validate test function
  h <- check.testfun(f, f1, X)
  f     <- h$f
  f1    <- h$f1
  ftype <- h$ftype
  ##
  ## 
  npts <- npoints(X)
  W <- X$window

  
  ## determine r values 
  rmaxdefault <- rmax.rule("K", W, npts/area(W))
  breaks <- handle.r.b.args(r, NULL, W, rmaxdefault=rmaxdefault)
  r <- breaks$r
  rmax <- breaks$max
        
  if(length(method) > 1)
    stop("Select only one method, please")
  if(method=="density" && !breaks$even)
    stop(paste("Evenly spaced r values are required if method=",
               sQuote("density"), sep=""))
        
  ## available selection of edge corrections depends on window
  correction.given <- !missing(correction) && !is.null(correction)
  if(is.null(correction))
    correction <- c("isotropic", "Ripley", "translate")
  correction <- pickoption("correction", correction,
                           c(none="none",
                             border="border",
                             "bord.modif"="bord.modif",
                             isotropic="isotropic",
                             Ripley="isotropic",
                             translate="translate",
                             translation="translate",
                             best="best"),
                           multi=TRUE)
  
  correction <- implemented.for.K(correction, W$type, correction.given)

  ## Denominator
  ## Ef = Ef(M,M') when M, M' are independent
  ## Apply f to every possible pair of marks, and average
  Ef <- switch(ftype,
               mul = {
                 mean(marx)^2
               },
               equ = {
                 mtable <- table(marx)
                 sum(mtable^2)/sum(mtable)^2
               },
               product={
                 f1m <- do.call(f1, append(list(marx), fargs))
                 mean(f1m)^2
               },
               general = {
                 if(is.null(fargs))
                   mean(outer(marx, marx, f))
                 else
                   mean(do.call("outer", append(list(marx,marx,f),fargs)))
               },
               stop("Internal error: invalid ftype"))

  if(normalise) {
    theory <- 1
    Efdenom <- Ef
  } else {
    theory <- Ef
    Efdenom <- 1
  }

  if(normalise) {
    ## check validity of denominator
    if(Efdenom == 0)
      stop("Cannot normalise the mark correlation; the denominator is zero")
    else if(Efdenom < 0)
      warning(paste("Problem when normalising the mark correlation:",
                    "the denominator is negative"))
  }
  
  ## this will be the output data frame
  result <- data.frame(r=r, theo= rep.int(theory,length(r)))
  desc <- c("distance argument r",
            "theoretical value (independent marks) for %s")
  alim <- c(0, min(rmax, rmaxdefault))
  ## determine conventional name of function
  if(ftype %in% c("mul", "equ")) {
    if(normalise) {
      ylab <- quote(k[mm](r))
      fnam <- c("k", "mm")
    } else {
      ylab <- quote(c[mm](r))
      fnam <- c("c", "mm")
    }
  } else {
    if(normalise) {
      ylab <- quote(k[f](r))
      fnam <- c("k", "f")
    } else {
      ylab <- quote(c[f](r))
      fnam <- c("c", "f")
    }
  }
  result <- fv(result, "r", ylab, "theo", , alim,
               c("r","{%s[%s]^{iid}}(r)"), desc, fname=fnam)

  ## find close pairs of points
  close <- closepairs(X, rmax)
  dIJ <- close$d
  I   <- close$i
  J   <- close$j
  XI <- ppp(close$xi, close$yi, window=W, check=FALSE)

  ## apply f to marks of close pairs of points
  ##
  mI <- marx[I]
  mJ <- marx[J]
  ff <- switch(ftype,
               mul = mI * mJ,
               equ = (mI == mJ),
               product={
                 if(is.null(fargs)) {
                   fI <- f1(mI)
                   fJ <- f1(mJ)
                 } else {
                   fI <- do.call(f1, append(list(mI), fargs))
                   fJ <- do.call(f1, append(list(mJ), fargs))
                 }
                 fI * fJ
               },
               general={
                 if(is.null(fargs))
                   f(marx[I], marx[J])
                 else
                   do.call(f, append(list(marx[I], marx[J]), fargs))
               })

  ## check values of f(M1, M2)
  
  if(is.logical(ff))
    ff <- as.numeric(ff)
  else if(!is.numeric(ff))
    stop("function f did not return numeric values")

  if(any(is.na(ff))) 
    switch(ftype,
           mul=,
           equ=stop("some marks were NA"),
           product=,
           general=stop("function f returned some NA values"))
    
  if(any(ff < 0))
    switch(ftype,
           mul=,
           equ=stop("negative marks are not permitted"),
           product=,
           general=stop("negative values of function f are not permitted"))
    
  #### Compute estimates ##############
        
  if(any(correction == "translate")) {
    ## translation correction
    XJ <- ppp(close$xj, close$yj, window=W, check=FALSE)
    edgewt <- edge.Trans(XI, XJ, paired=TRUE)
    ## get smoothed estimate of mark covariance
    Mtrans <- sewsmod(dIJ, ff, edgewt, Efdenom, r, method, ...)
    result <- bind.fv(result,
                      data.frame(trans=Mtrans), "{hat(%s)[%s]^{trans}}(r)",
                      "translation-corrected estimate of %s",
                      "trans")
  }
  if(any(correction == "isotropic")) {
    ## Ripley isotropic correction
    edgewt <- edge.Ripley(XI, matrix(dIJ, ncol=1))
    ## get smoothed estimate of mark covariance
    Miso <- sewsmod(dIJ, ff, edgewt, Efdenom, r, method, ...)
    result <- bind.fv(result,
                      data.frame(iso=Miso), "{hat(%s)[%s]^{iso}}(r)",
                      "Ripley isotropic correction estimate of %s",
                      "iso")
  }
  ## which corrections have been computed?
  nama2 <- names(result)
  corrxns <- rev(nama2[nama2 != "r"])

  ## default is to display them all
  formula(result) <- (. ~ r)
  fvnames(result, ".") <- corrxns
  ##
  unitname(result) <- unitname(X)
  return(result)
}

sewsmod <- function(d, ff, wt, Ef, rvals, method="smrep", ..., nwtsteps=500) {
  ## Smooth Estimate of Weighted Second Moment Density
  ## (engine for computing mark correlations, etc)
  ## ------
  ## Vectors containing one entry for each (close) pair of points
  ## d = interpoint distance
  ## ff = f(M1, M2) where M1, M2 are marks at the two points
  ## wt = edge correction weight
  ## -----
  ## Ef = E[f(M, M')] where M, M' are independent random marks
  ## 
  d <- as.vector(d)
  ff <- as.vector(ff)
  wt <- as.vector(wt)
  switch(method,
         density={
           fw <- ff * wt
           sum.fw <- sum(fw)
           sum.wt <- sum(wt)
           ## smooth estimate of kappa_f
           est <- density(d, weights=fw/sum.fw,
                          from=min(rvals), to=max(rvals), n=length(rvals),
                          ...)$y
           numerator <- est * sum.fw
           ## smooth estimate of kappa_1
           est0 <- density(d, weights=wt/sum.wt, 
                          from=min(rvals), to=max(rvals), n=length(rvals),
                          ...)$y
           denominator <- est0 * Ef * sum.wt
           result <- numerator/denominator
         },
         sm={
           ## This is slow!
           oldopt <- options(warn=-1)
           smok <- require(sm)
           options(oldopt)
           if(!smok)
             stop(paste("Option method=sm requires package sm,",
                        "which is not available"))

           ## smooth estimate of kappa_f
           fw <- ff * wt
           est <- sm::sm.density(d, weights=fw,
                                 eval.points=rvals,
                                 display="none", nbins=0, ...)$estimate
           numerator <- est * sum(fw)/sum(est)
           ## smooth estimate of kappa_1
           est0 <- sm::sm.density(d, weights=wt,
                                  eval.points=rvals,
                                  display="none", nbins=0, ...)$estimate
           denominator <- est0 * (sum(wt)/ sum(est0)) * Ef
           result <- numerator/denominator
         },
         smrep={
           oldopt <- options(warn=-1)
           smok <- require(sm)
           options(oldopt)
           if(!smok)
             stop(paste("Option method=smrep requires package sm,",
                  "which is not available"))

           hstuff <- resolve.defaults(list(...), list(hmult=1, h.weights=NA))
           if(hstuff$hmult == 1 && all(is.na(hstuff$h.weights)))
             warning("default smoothing parameter may be inappropriate")
           
           ## use replication to effect the weights (it's faster)
           nw <- round(nwtsteps * wt/max(wt))
           drep.w <- rep.int(d, nw)
           fw <- ff * wt
           nfw <- round(nwtsteps * fw/max(fw))
           drep.fw <- rep.int(d, nfw)

           ## smooth estimate of kappa_f
           est <- sm::sm.density(drep.fw,
                                 eval.points=rvals,
                                 display="none", ...)$estimate
           numerator <- est * sum(fw)/sum(est)
           ## smooth estimate of kappa_1
           est0 <- sm::sm.density(drep.w,
                                  eval.points=rvals,
                                  display="none", ...)$estimate
           denominator <- est0 * (sum(wt)/ sum(est0)) * Ef
           result <- numerator/denominator
         },
         loess = {
           ## set up data frame
           df <- data.frame(d=d, ff=ff, wt=wt)
           ## fit curve to numerator using loess
           fitobj <- loess(ff ~ d, data=df, weights=wt, ...)
           ## evaluate fitted curve at desired r values
           Eff <- predict(fitobj, newdata=data.frame(d=rvals))
           ## normalise:
           ## denominator is the sample mean of all ff[i,j],
           ## an estimate of E(ff(M1,M2)) for M1,M2 independent marks
           result <- Eff/Ef
         },
         )
  return(result)
}

############## user interface bits ##################################

check.testfun <- local({
  
  fmul <- function(m1, m2) { m1 * m2 }
  fequ <- function(m1, m2) { m1 == m2 }
  f1id <- function(m) { m }

  check.testfun <- function(f=NULL, f1=NULL, X) {
    ## Validate f or f1 as a test function for point pattern X
    ## Determine function type 'ftype'
    ##      ("mul", "equ", "product" or "general")

    if(is.null(f) && is.null(f1)) {
      ## no functions given
      ## default depends on kind of marks
      if(is.multitype(X)) {
        f <- fequ
        ftype <- "equ"
      } else {
        f1 <- f1id
        ftype <- "mul"
      }
    } else if(!is.null(f1)) {
      ## f1 given
      ## specifies test function of the form f(u,v) = f1(u) f1(v)
      if(!is.null(f))
        warning("argument f ignored (overridden by f1)")
      stopifnot(is.function(f1))
      ftype <- "product"
    } else {
      ## f given 
      if(is.character(fname <- f)) {
        switch(fname,
               "mul"  = {
                 f1 <- f1id
                 ftype <- "mul"
               },
               "equ" = {
                 f <- fequ
                 ftype <- "equ"
               },
               {
                 f <- get(fname)
                 ftype <- "general"
               })
      } else if(is.function(f)) {
        ftype <- if(isTRUE(all.equal(f, fmul))) "mul" else
                 if(isTRUE(all.equal(f, fequ))) "equ" else "general"
        if(ftype == "mul" && is.multitype(X))
          stop(paste("Inappropriate choice of function f;",
                     "point pattern is multitype;",
                     "types cannot be multiplied."))
      } else
        stop("Argument f must be a function or the name of a function")
    }
    return(list(f=f, f1=f1, ftype=ftype))
  }

  check.testfun
})


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/marks.R"
#
# marks.R
#
#   $Revision: 1.40 $   $Date: 2014/06/14 01:51:07 $
#
# stuff for handling marks
#
#

marks <- function(x, ...) {
  UseMethod("marks")
}

marks.default <- function(x, ...) { NULL }

# The 'dfok' switch is temporary
# while we convert the code to accept data frames of marks

marks.ppp <- function(x, ..., dfok=TRUE, drop=TRUE) {
  ma <- x$marks
  if((is.data.frame(ma) || is.matrix(ma))) {
    if(!dfok)
      stop("Sorry, not implemented when the marks are a data frame")
    if(drop && ncol(ma) == 1)
      ma <- ma[,1,drop=TRUE]
  }
  return(ma)
}

# ------------------------------------------------------------------

"marks<-" <- function(x, ..., value) {
  UseMethod("marks<-")
}

"marks<-.ppp" <- function(x, ..., dfok=TRUE, drop=TRUE, value) {
  np <- npoints(x)
  m <- value
  switch(markformat(m),
         none = {
           return(unmark(x))
         },
         vector = {
           # vector of marks
           if(length(m) == 1) m <- rep.int(m, np)
           else if(np == 0) m <- rep.int(m, 0) # ensures marked pattern obtained
           else if(length(m) != np) stop("number of points != number of marks")
           marx <- m
         },
         dataframe = {
           if(!dfok)
             stop("Sorry, data frames of marks are not yet implemented")
           m <- as.data.frame(m)
           # data frame of marks
           if(ncol(m) == 0) {
             # no mark variables
             marx <- NULL
           } else {
             # marks to be attached
             if(nrow(m) == np) {
               marx <- m
             } else {
               # lengths do not match
               if(nrow(m) == 1 || np == 0) {
               # replicate data frame
                 marx <- as.data.frame(lapply(as.list(m),
                                              function(x, k) { rep.int(x, k) },
                                              k=np))
               } else
               stop("number of rows of data frame != number of points")
             }
             # convert single-column data frame to vector?
             if(drop && ncol(marx) == 1)
               marx <- marx[,1,drop=TRUE]
           }
         },
         hyperframe = 
         stop("Hyperframes of marks are not supported in ppp objects; use ppx"),
         stop("Format of marks is not understood")
         )
  # attach/overwrite marks
  Y <- ppp(x$x,x$y,window=x$window,marks=marx, check=FALSE, drop=drop)
  return(Y)
}

"%mark%" <- setmarks <- function(x,value) {
  marks(x) <- value
  return(x)
}

# -------------------------------------------------

markformat <- function(x) {
  UseMethod("markformat")
}

markformat.ppp <- function(x) {
  mf <- x$markformat
  if(is.null(mf)) 
    mf <- markformat(marks(x))
  return(mf)
}

markformat.default <- function(x) {
  if(is.null(x)) return("none")
  if(is.null(dim(x))) {
    if(is.vector(x) || is.factor(x) || is.atomic(x)) return("vector")
    if(inherits(x, "POSIXt") || inherits(x, "Date")) return("vector")
  }
  if(is.data.frame(x) || is.matrix(x)) return("dataframe")
  if(is.hyperframe(x)) return("hyperframe")
  if(inherits(x, "listof")) return("listof")
  stop("Mark format not understood")
}

# ------------------------------------------------------------------

"is.marked" <-
function(X, ...) {
  UseMethod("is.marked")
}

"is.marked.ppp" <-
function(X, na.action="warn", ...) {
  marx <- marks(X, ...)
  if(is.null(marx))
    return(FALSE)
  if((length(marx) > 0) && any(is.na(marx))) {
    gripe <- paste("some mark values are NA in the point pattern",
                   short.deparse(substitute(X)))
    switch(na.action,
           warn = warning(gripe, call.=FALSE),
           fatal = stop(gripe, call.=FALSE),
           ignore = {}
           )
  }
  return(TRUE)
}

"is.marked.default" <-
  function(...) { return(!is.null(marks(...))) }


# ------------------------------------------------------------------

is.multitype <- function(X, ...) {
  UseMethod("is.multitype")
}

is.multitype.default <- function(X, ...) {
  m <- marks(X)
  if(is.null(m))
    return(FALSE)
  if(!is.null(dim(m))) {
    # should have a single column
    if(dim(m)[2] != 1)
      return(FALSE)
    m <- m[,1,drop=TRUE]
  }
  return(is.factor(m))
}

is.multitype.ppp <- function(X, na.action="warn", ...) {
  marx <- marks(X, dfok=TRUE)
  if(is.null(marx))
    return(FALSE)
  if((is.data.frame(marx) || is.hyperframe(marx)) && ncol(marx) > 1)
    return(FALSE)
  if(!is.factor(marx))
    return(FALSE)
  if((length(marx) > 0) && any(is.na(marx)))
    switch(na.action,
           warn = {
             warning(paste("some mark values are NA in the point pattern",
                           short.deparse(substitute(X))))
           },
           fatal = {
             return(FALSE)
           },
           ignore = {}
           )
  return(TRUE)
}

# ------------------------------------------------------------------

unmark <- function(X) {
  UseMethod("unmark")
}

unmark.ppp <- function(X) {
  X$marks <- NULL
  X$markformat <- "none"
  return(X)
}

unmark.splitppp <- function(X) {
  Y <- lapply(X, unmark.ppp)
  class(Y) <- c("splitppp", class(Y))
  return(Y)
}

##### utility functions for subsetting & combining marks #########


marksubset <- function(x, index, format=NULL) {
  if(is.null(format)) format <- markformat(x)
  switch(format,
         none={return(NULL)},
         listof=,
         vector={return(x[index])},
         hyperframe=,
         dataframe={return(x[index,,drop=FALSE])},
         stop("Internal error: unrecognised format of marks"))
}

"%msub%" <- marksubsetop <- function(x,i) { marksubset(x, i) }

"%mrep%" <- markreplicateop <- function(x,n) { 
  format <- markformat(x)
  switch(format,
         none={return(NULL)},
         listof=,
         vector={ return(rep.int(x,n))},
         dataframe={
           return(as.data.frame(lapply(x, rep, times=n)))
         },
         hyperframe={
           xcols <- as.list(x)
           repxcols <- lapply(xcols, rep, times=n)
           return(do.call("hyperframe", repxcols))
         },
         stop("Internal error: unrecognised format of marks"))
}

"%mapp%" <- markappendop <- function(x,y) { 
  fx <- markformat(x)
  fy <- markformat(y)
  agree <- (fx == fy)
  if(all(c(fx,fy) %in% c("dataframe", "hyperframe")))
    agree <- agree && identical(names(x),names(y)) 
  if(!agree)
    stop("Attempted to concatenate marks that are not compatible")
  switch(fx,
         none   = { return(NULL) },
         vector = {
           if(is.factor(x) || is.factor(y))
             return(cat.factor(x,y))
           else return(c(x,y))
         },
         hypeframe=,
         dataframe = { return(rbind(x,y)) },
         listof = {
           z <- append(x,y)
           if(!inherits(z, "listof"))
             z <- as.listof(z)
           return(z)
         },
         stop("Internal error: unrecognised format of marks"))
}

markappend <- function(...) {
  # combine marks from any number of patterns
  marxlist <- list(...)
  # check on compatibility of marks
  mkfmt <- sapply(marxlist,markformat)
  if(length(unique(mkfmt))>1)
    stop(paste("Marks of some patterns are of different format",
               "from those of other patterns."))
  mkfmt <- mkfmt[1]
  # combine the marks
  switch(mkfmt,
         none = {
           return(NULL)
         },
         vector = {
           marxlist <- lapply(marxlist,
                              function(x){as.data.frame.vector(x,nm="v1")})
           marx <- do.call("rbind", marxlist)[,1]
           return(marx)
         },
         hyperframe =,
         dataframe = {
           # check compatibility of data frames
           # (this is redundant but gives more helpful message)
           nama <- lapply(marxlist, names)
           dims <- unlist(lapply(nama, length))
           if(length(unique(dims)) != 1)
             stop("Data frames of marks have different column dimensions.")
           samenames <- unlist(lapply(nama,
                                      function(x,y) { identical(x,y) },
                                      y=nama[[1]]))
           if(!all(samenames))
             stop("Data frames of marks have different names.\n")
           marx <- do.call("rbind", marxlist)
           return(marx)
         },
         listof = {
           marx <- do.call(c, marxlist)
           if(!inherits(marx, "listof"))
             marx <- as.listof(marx)
           return(marx)
         })
  stop("Unrecognised mark format")
}

markcbind <- function(...) {
  # cbind several columns of marks
  marxlist <- list(...)
  mkfmt <- unlist(lapply(marxlist, markformat))
  if(any(vacuous <- (mkfmt == "none"))) {
    marxlist <- marxlist[!vacuous]
    mkfmt    <- mkfmt[!vacuous]
  }
  if(any(isvec <- (mkfmt == "vector"))) {
    ## convert vectors to data frames with invented names
    for(i in which(isvec)) {
      mi <- as.data.frame(marxlist[i])
      colnames(mi) <- paste0("V", i)
      marxlist[[i]] <- mi
    }
    mkfmt[isvec] <- "dataframe"
  }
  if(all(mkfmt == "dataframe")) {
    ## result is a data frame
    marx <- do.call(data.frame, marxlist)
  } else {
    ## result is a hyperframe
    if(!all(ishyp <- (mkfmt == "hyperframe"))) 
      marxlist[!ishyp] <- lapply(marxlist[!ishyp], as.hyperframe)
    marx <- do.call(hyperframe, marxlist)
  }
  return(marx)
}

# extract only the columns of (passably) numeric data from a data frame
numeric.columns <- function(M, logical=TRUE, others=c("discard", "na")) {
  others <- match.arg(others)
  M <- as.data.frame(M)
  if(ncol(M) == 1)
    colnames(M) <- NULL
  process <- function(z, logi, other) {
    if(is.numeric(z)) return(z)
    if(logi && is.logical(z)) return(as.integer(z))
    switch(other,
           na=rep.int(NA_real_, length(z)),
           discard=NULL,
           NULL)
  }
  Mprocessed <- lapply(M, process, logi=logical, other=others)
  isnul <- unlist(lapply(Mprocessed, is.null))
  if(all(isnul)) {
    # all columns have been removed
    # return a data frame with no columns
    return(as.data.frame(matrix(, nrow=nrow(M), ncol=0)))
  }
  Mout <- do.call("data.frame", Mprocessed[!isnul])
  if(ncol(M) == 1 && ncol(Mout) == 1)
    colnames(Mout) <- NULL
  return(Mout)
}

coerce.marks.numeric <- function(X, warn=TRUE) {
  marx <- marks(X)
  if(is.null(dim(marx))) {
    if(is.factor(marx)) {
      if(warn) warning("Factor-valued marks were converted to integer codes",
                       call.=FALSE)
      marx <- as.integer(marx)
      return(X %mark% marx)
    }
  } else {
    marx <- as.data.frame(marx)
    if(any(fax <- unlist(lapply(marx, is.factor)))) {
      if(warn) warning("Factor-valued mark",
                       ngettext(sum(fax), "variable was", "variables were"),
                       "converted to integer codes:",
                       commasep(sQuote(colnames(marx)[fax])),
                       call.=FALSE)
      marx[,fax] <- as.data.frame(lapply(marx[,fax], as.integer))
      return(X %mark% marx)
    }
  }
  return(X)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/marktable.R"
#
#	marktable.R
#
#	Tabulate mark frequencies in r-neighbourhood of each point 
#	for multitype point patterns
#
#	$Revision: 1.6 $	$Date: 2013/02/22 05:34:02 $
#
#       Requested by Ian Robertson <igr@stanford.edu>


"marktable" <- 
function(X, R, exclude=TRUE) 
{
	verifyclass(X, "ppp")
	if(!is.marked(X, dfok=FALSE))
		stop("point pattern has no marks")
        stopifnot(is.numeric(R) && length(R) == 1 && R > 0)
        stopifnot(is.logical(exclude) && length(exclude) == 1)

        m <- marks(X)
        if(!is.factor(m))
          stop("marks must be a factor")
        
        # identify close pairs
        p <- closepairs(X,R,what="indices")
        pi <- p$i
        pj <- p$j
        if(!exclude) {
          # add identical pairs
          n <- X$n
          pi <- c(pi, 1:n)
          pj <- c(pj, 1:n)
        }

        # tabulate
        i <- factor(pi, levels=seq_len(X$n))
        mj <- m[pj]
        mat <- table(point=i, mark=mj)

        return(mat)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/measures.R"
#
#   measures.R
#
#  signed/vector valued measures with atomic and diffuse components
#
#  $Revision: 1.51 $  $Date: 2014/11/10 11:15:31 $
#
msr <- function(qscheme, discrete, density, check=TRUE) {
  if(!inherits(qscheme, "quad"))
    stop("qscheme should be a quadrature scheme")
  nquad <- n.quad(qscheme)
  U <- union.quad(qscheme)
  wt <- w.quad(qscheme)
  Z <- is.data(qscheme)
  ndata <- sum(Z)
  # ensure conformable vectors/matrices
  if(is.vector(discrete) && is.vector(density)) {
    # handle constants
    if(length(discrete) == 1)
      discrete <- rep.int(discrete, ndata)
    if(length(density) == 1)
      density <- rep.int(density, nquad)
    # check lengths
    if(check) {
      check.nvector(discrete, ndata, things="data points", naok=TRUE)
      check.nvector(density,  nquad, things="quadrature points", naok=TRUE)
    }
    discretepad <- numeric(nquad)
    discretepad[Z] <- discrete
  } else {
    if(length(discrete) == 1 && is.matrix(density)) {
      # replicate constant 'discrete' component to matrix of correct size
      discrete <- matrix(discrete, ndata, ncol(density))
    } else if(length(density) == 1 && is.matrix(discrete)) {
      # replicate constant 'density' to matrix of correct size
      density <- matrix(density, nquad, ncol(discrete))
    } else {
      discrete <- as.matrix(discrete)
      density <- as.matrix(density)
    }
    if(check) {
      # check numbers of rows
      check.nmatrix(discrete, ndata, things="data points",
                    naok=TRUE, squarematrix=FALSE)
      check.nmatrix(density,  nquad, things="quadrature points",
                    naok=TRUE, squarematrix=FALSE)
    }
    nd <- ncol(discrete)
    nc <- ncol(density)
    if(nd != nc) {
      if(nd == 1) {
        # replicate columns of discrete component
        discrete <- matrix(rep.int(discrete, nc), ndata, nc)
        colnames(discrete) <- colnames(density)
      } else if(nc == 1) {
        # replicate columns of density component
        density <- matrix(rep.int(density, nd), nquad, nd)
        colnames(density) <- colnames(discrete)
      } else stop(paste("Incompatible numbers of columns in",
                        sQuote("discrete"), paren(nd), "and",
                        sQuote("density"), paren(nc)))
    }
    discretepad <- matrix(0, nquad, max(nd, nc))
    discretepad[Z, ] <- discrete
    colnames(discretepad) <- colnames(density)
  }

  #
  #
  # Discretised measure (value of measure for each quadrature tile)
  val <- discretepad + wt * density
  if(is.matrix(density)) colnames(val) <- colnames(density)
  #
  out <- list(loc = U,
              val = val,
              atoms = Z,
              discrete = discretepad,
              density = density,
              wt = wt)
  class(out) <- "msr"
  return(out)
}

# Translation table for usage of measures
#
#           e.g. res <- residuals(fit, ...)
#
#     OLD                               NEW           
#     res[ ]                       res$val[ ]       with(res, "increment")
#     attr(res, "atoms")           res$atoms        with(res, "is.atom")
#     attr(res, "discrete")        res$discrete     with(res, "discrete")
#     attr(res, "continuous")      res$density      with(res, "density")
#     w.quad(quad.ppm(fit))        res$wt           with(res, "qweights")
#     union.quad(quad.ppm(fit))    res$loc          with(res, "qlocations")
# .................................................

with.msr <- function(data, expr, ...) {
  stopifnot(inherits(data, "msr"))
  stopifnot(is.character(expr)) 
  y <- switch(expr,
              increment  = { data$val },
              is.atom    = { data$atoms },
              discrete   = { data$discrete },
              density    = { data$density },
              continuous = { data$density * data$wt },
              qweights   = { data$wt },
              qlocations = { data$loc },
              stop("Unrecognised option in entry.msr", call.=FALSE))
  return(y)
}

print.msr <- function(x, ...) {
  n <- npoints(x$loc)
  d <- ncol(as.matrix(x$val))
  splat(paste0(if(d == 1) "Scalar" else paste0(d, "-dimensional vector"),
               "-valued measure"))
  if(d > 1 && !is.null(cn <- colnames(x$val)))
    splat("vector components:", commasep(sQuote(cn)))
  if(waxlyrical("extras")) {
    splat("Approximated by", n, "quadrature points")
    print(as.owin(x$loc))
    splat(sum(x$atoms), "atoms")
    splat("Total mass:")
    if(d == 1) {
      splat("discrete =", signif(sum(with(x, "discrete")), 5),
            "  continuous =", signif(sum(with(x, "continuous")), 5),
            "  total =", signif(sum(with(x, "increment")), 5))
    } else {
      if(is.null(cn)) cn <- paste("component", 1:d)
      for(j in 1:d) {
        splat(paste0(cn[j], ":\t"),
              "discrete =", signif(sum(with(x, "discrete")[,j]), 5),
              "  continuous =", signif(sum(with(x, "continuous")[,j]), 5),
              "  total =", signif(sum(with(x, "increment")[,j]), 5))
      }
    }
  }
  return(invisible(NULL))
}

integral.msr <- function(x, ...) {
  stopifnot(inherits(x, "msr"))
  y <- with(x, "increment")
  if(is.matrix(y)) apply(y, 2, sum) else sum(y)
}

augment.msr <- function(x, ..., sigma) {
  ## add a pixel image of the smoothed density component
  stopifnot(inherits(x, "msr"))
  d <- ncol(as.matrix(x$val))
  xloc <- x$loc
  W <- as.owin(xloc)
  if(missing(sigma)) sigma <- maxnndist(xloc, positive=TRUE)
  ## smooth density unless constant
  xdensity <- as.matrix(x$density)
  ra <- apply(xdensity, 2, range)
  varble <- apply(as.matrix(ra), 2, diff) > sqrt(.Machine$double.eps)
  ##
  if(d == 1) {
    smo <- if(!varble) as.im(mean(xdensity), W=W) else
           do.call("Smooth",
                   resolve.defaults(list(X=xloc %mark% xdensity),
                                    list(...),
                                    list(sigma=sigma)))
  } else {
    smo <- vector(mode="list", length=d)
    names(smo) <- colnames(x)
    if(any(varble)) 
      smo[varble] <-
        do.call("Smooth",
                resolve.defaults(list(X=xloc %mark% xdensity[,varble]),
                                 list(...),
                                 list(sigma=sigma)))
    if(any(!varble)) 
      smo[!varble] <- lapply(apply(xdensity[, !varble], 2, mean),
                             function(z, W) as.im(z, W=W),
                             W=W)
  }
  attr(x, "smoothdensity") <- smo
  return(x)
}

plot.msr <- function(x, ..., add=FALSE,
                     how=c("image", "contour", "imagecontour"),
                     main=NULL, 
                     do.plot=TRUE) {
  if(is.null(main)) 
    main <- short.deparse(substitute(x))
  how <- match.arg(how)
  d <- ncol(as.matrix(x$val))
  if(is.null(smo <- attr(x, "smoothdensity"))) {
    x <- augment.msr(x, ...)
    smo <- attr(x, "smoothdensity")
  }
  if(d > 1) {
    ## split into a list of real-valued measures
    lis <- list()
    for(j in 1:d) {
      xj <- x[,j]
      attr(xj, "smoothdensity") <- smo[[j]]
      lis[[j]] <- xj
    }
    lis <- as.listof(lis)
    if(!is.null(cn <- colnames(x$val)))
      names(lis) <- cn
    result <- do.call("plot.listof", resolve.defaults(list(lis),
                                                      list(...),
                                                      list(how=how,
                                                           main=main,
                                                           equal.scales=TRUE)))
    return(invisible(result))
  }
  ## scalar measure
  xatomic <- (x$loc %mark% x$discrete)[x$atoms]
  xtra.im <- graphicsPars("image")
  xtra.pp <- setdiff(graphicsPars("ppp"), c("box", "col"))
  xtra.ow <- graphicsPars("owin")
  ##
  do.image <-  how %in% c("image", "imagecontour")
  do.contour <-  how %in% c("contour", "imagecontour")
  ## allocate space for plot and legend using do.plot=FALSE mechanism
  pdata <- do.call.matched("plot.ppp",
                           resolve.defaults(list(x=xatomic,
                                                 do.plot=FALSE,
                                                 main=main),
                                            list(...),
                                            list(show.all=TRUE)),
                           extrargs=xtra.pp)
  result <- pdata
  bb <- attr(pdata, "bbox")
  if(do.image) {
    idata <- do.call.matched("plot.im",
                             resolve.defaults(list(x=smo,
                                                   main=main,
                                                   do.plot=FALSE),
                                              list(...)),
                             extrargs=xtra.im)
    result <- idata
    bb <- boundingbox(bb, attr(idata, "bbox"))
  }
  ##
  attr(result, "bbox") <- bb
  ##
  if(do.plot) {
    if(!add) {
      blankmain <- prepareTitle(main)$blank
      ## initialise plot
      do.call.matched(plot.owin,
                      resolve.defaults(list(x=bb, type="n", main=blankmain),
                                       list(...)),
                      extrargs=xtra.ow)
    }
    ## display density
    if(do.image) 
      do.call.matched("plot.im",
                      resolve.defaults(list(x=smo, add=TRUE),
                                       list(...),
                                       list(main=main, show.all=TRUE)),
                      extrargs=xtra.im)
    if(do.contour) 
      do.call.matched("contour.im",
                      resolve.defaults(list(x=smo, add=TRUE),
                                       list(...),
                                       list(main=main,
                                            axes=FALSE, show.all=!do.image)),
                      extrargs=c("zlim", "labels", "labcex",
                        ## DO NOT ALLOW 'col' 
                        "drawlabels", "method", "vfont", "lty", "lwd"))
    ## display atoms
    do.call.matched("plot.ppp",
                    resolve.defaults(list(x=xatomic, add=TRUE, main=""),
                                     list(...),
                                     list(show.all=TRUE)),
                    extrargs=xtra.pp)
  }
  return(invisible(result))
}

"[.msr" <- function(x, i, j, ...) {
  valu  <- as.matrix(x$val)
  disc  <- as.matrix(x$discrete)
  dens  <- as.matrix(x$density)
  wt    <- x$wt
  atoms <- x$atoms
  #
  if(!missing(j)) {
    valu <- valu[, j]
    disc <- disc[, j]
    dens <- dens[, j]
  }
  loc <- x$loc
  if(!missing(i)) {
    # use [.ppp to identify which points are retained
    locn  <- loc %mark% seq_len(npoints(loc))
    loci  <- locn[i]
    loc   <- unmark(loci)
    id    <- marks(loci)
    # extract
    valu  <- valu[id, ]
    disc  <- disc[id, ]
    dens  <- dens[id, ]
    wt    <- wt[id]
    atoms <- atoms[id]
  }
  out <- list(loc=loc,
              val=valu,
              atoms=atoms,
              discrete=disc,
              density=dens,
              wt=wt)
  class(out) <- "msr"
  return(out)    
}

dim.msr <- function(x) { dim(as.matrix(x$val)) }

dimnames.msr <- function(x) { list(NULL, colnames(x$val)) }

smooth.msr <- function(X, ...) {
  .Deprecated("Smooth.msr", package="spatstat",
     msg="smooth.msr is deprecated: use the generic Smooth with a capital S")
  Smooth(X, ...)
}

Smooth.msr <- function(X, ..., drop=TRUE) {
  verifyclass(X, "msr")
  loc <- X$loc
  val <- X$val
  result <- density(loc, weights=val, ...)
  if(!drop && is.im(result))
    result <- listof(result)
  return(result)
}

as.owin.msr <- function(W, ..., fatal=TRUE) {
  as.owin(W$loc, ..., fatal=fatal)
}

domain.msr <- Window.msr <- function(X, ...) { as.owin(X) } 

shift.msr <- function(X,  ...) {
  X$loc <- Xloc <- shift(X$loc, ...)
  if(!is.null(smo <- attr(X, "smoothdensity")))
    attr(X, "smoothdensity") <- shift(smo, getlastshift(Xloc))
  putlastshift(X, getlastshift(Xloc))
}

as.layered.msr <- function(X) {
  nc <- ncol(X)
  if(nc == 0) return(layered())
  if(nc == 1) return(layered(X))
  Y <- lapply(seq_len(nc), function(j,x) x[,j], x=X)
  names(Y) <- colnames(X)
  return(layered(LayerList=Y))
}

scalardilate.msr <- function(X, f, ...) {
  X$loc <- Xloc <- scalardilate(X$loc, f, ...)
  putlastshift(X, getlastshift(Xloc))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/mincontrast.R"
#
#  mincontrast.R
#
#  Functions for estimation by minimum contrast
#

##################  base ################################

mincontrast <- local({

  ## objective function (in a format that is re-usable by other code)
  contrast.objective <- function(par, objargs, ...) {
    with(objargs, {
      theo <- theoretical(par=par, rvals, ...)
      if(!is.vector(theo) || !is.numeric(theo))
        stop("theoretical function did not return a numeric vector")
      if(length(theo) != nrvals)
        stop("theoretical function did not return the correct number of values")
      discrep <- (abs(theo^qq - obsq))^pp
      return(sum(discrep))
    })
  }

  mincontrast <- function(observed, theoretical, startpar,
                          ...,
                          ctrl=list(q = 1/4, p = 2, rmin=NULL, rmax=NULL),
                          fvlab=list(label=NULL, desc="minimum contrast fit"),
                          explain=list(dataname=NULL,
                            modelname=NULL, fname=NULL)) {
    verifyclass(observed, "fv")
    stopifnot(is.function(theoretical))
    if(!any("par" %in% names(formals(theoretical))))
      stop(paste("Theoretical function does not include an argument called",
                 sQuote("par")))

    ## enforce defaults
    ctrl <- resolve.defaults(ctrl, list(q = 1/4, p = 2, rmin=NULL, rmax=NULL))
    fvlab <- resolve.defaults(fvlab,
                              list(label=NULL, desc="minimum contrast fit"))
    explain <- resolve.defaults(explain,
                                list(dataname=NULL, modelname=NULL, fname=NULL))
  
    ## extract vector of r values
    argu <- fvnames(observed, ".x")
    rvals <- observed[[argu]]
    
    ## determine range of r values
    rmin <- ctrl$rmin
    rmax <- ctrl$rmax
    if(!is.null(rmin) && !is.null(rmax)) 
      stopifnot(rmin < rmax && rmin >= 0)
    else {
      alim <- attr(observed, "alim") %orifnull% range(rvals)
      if(is.null(rmin)) rmin <- alim[1]
      if(is.null(rmax)) rmax <- alim[2]
    }
    ## extract vector of observed values of statistic
    valu <- fvnames(observed, ".y")
    obs <- observed[[valu]]
    ## restrict to [rmin, rmax]
    if(max(rvals) < rmax)
      stop(paste("rmax=", signif(rmax,4),
                 "exceeds the range of available data",
                 "= [", signif(min(rvals),4), ",", signif(max(rvals),4), "]"))
    sub <- (rvals >= rmin) & (rvals <= rmax)
    rvals <- rvals[sub]
    obs <- obs[sub]
    ## sanity clause
    if(!all(ok <- is.finite(obs))) {
      whinge <- paste("Some values of the empirical function",
                      sQuote(explain$fname),
                      "were infinite or NA.")
      iMAX <- max(which(ok))
      iMIN <- min(which(!ok)) + 1
      if(iMAX > iMIN && all(ok[iMIN:iMAX])) {
        rmin <- rvals[iMIN]
        rmax <- rvals[iMAX]
        obs   <- obs[iMIN:iMAX]
        rvals <- rvals[iMIN:iMAX]
        sub[sub] <- ok
        warning(paste(whinge,
                      "Range of r values was reset to",
                      prange(c(rmin, rmax))),
                call.=FALSE)
      } else stop(paste(whinge, "Please choose a narrower range [rmin, rmax]"),
                  call.=FALSE)
    }
    ## pack data into a list
    objargs <- list(theoretical = theoretical,
                    rvals       = rvals,
                    nrvals      = length(rvals),
                    obsq        = obs^(ctrl$q),   ## for efficiency
                    qq          = ctrl$q,
                    pp          = ctrl$p,
                    rmin        = rmin,
                    rmax        = rmax)
    ## go
    minimum <- optim(startpar, fn=contrast.objective, objargs=objargs, ...)
    ## if convergence failed, issue a warning 
    signalStatus(optimStatus(minimum), errors.only=TRUE)
    ## evaluate the fitted theoretical curve
    fittheo <- theoretical(minimum$par, rvals, ...)
    ## pack it up as an `fv' object
    label <- fvlab$label
    desc  <- fvlab$desc
    if(is.null(label))
      label <- paste("fit(", argu, ")", collapse="")
    fitfv <- bind.fv(observed[sub, ],
                     data.frame(fit=fittheo),
                     label, desc)
    result <- list(par      = minimum$par,
                   fit      = fitfv,
                   opt      = minimum,
                   ctrl     = list(p=ctrl$p,q=ctrl$q,rmin=rmin,rmax=rmax),
                   info     = explain,
                   startpar = startpar,
                   objfun   = contrast.objective,
                   objargs  = objargs,
                   dotargs  = list(...))
    class(result) <- c("minconfit", class(result))
    return(result)
  }

  mincontrast
})

print.minconfit <- function(x, ...) {
  ## explanatory
  cat(paste("Minimum contrast fit ",
            "(",
            "object of class ",
            dQuote("minconfit"),
            ")",
            "\n", sep=""))
  mo <- x$info$modelname
  fu <- x$info$fname
  da <- x$info$dataname
  cm <- x$covmodel
  if(!is.null(mo))
    cat("Model:", mo, fill=TRUE)
  if(!is.null(cm)) {
    ## Covariance/kernel model and nuisance parameters 
    cat("\t", cm$type, "model:", cm$model, fill=TRUE)
    margs <- cm$margs
    if(!is.null(margs)) {
      nama <- names(margs)
      tags <- ifelse(nzchar(nama), paste(nama, "="), "")
      tagvalue <- paste(tags, margs)
      splat("\t", cm$type, "parameters:",
            paste(tagvalue, collapse=", "))
    }
  }
  if(!is.null(fu) && !is.null(da))
    splat("Fitted by matching theoretical", fu, "function to", da)
  else {
    if(!is.null(fu))
      splat(" based on", fu)
    if(!is.null(da))
      splat(" fitted to", da)
  }
  ## Values
  splat("Parameters fitted by minimum contrast ($par):")
  print(x$par, ...)
  mp <- x$modelpar
  if(!is.null(mp)) {
    splat("Derived parameters of",
          if(!is.null(mo)) mo else "model",
          "($modelpar):")
    print(mp)
  }
  ## Diagnostics
  printStatus(optimStatus(x$opt))
  ## Starting values
  splat("Starting values of parameters:")
  print(x$startpar)
  ## Algorithm parameters
  ct <- x$ctrl
  splat("Domain of integration:",
        "[",
        signif(ct$rmin,4),
        ",",
        signif(ct$rmax,4),
        "]")
  splat("Exponents:",
        "p=", paste(signif(ct$p, 3), ",",  sep=""),
        "q=", signif(ct$q,3))
  invisible(NULL)
}
              

plot.minconfit <- function(x, ...) {
  xname <- short.deparse(substitute(x))
  do.call("plot.fv",
          resolve.defaults(list(x$fit),
                           list(...),
                           list(main=xname)))
}

unitname.minconfit <- function(x) {
  unitname(x$fit)
}

"unitname<-.minconfit" <- function(x, value) {
  unitname(x$fit) <- value
  return(x)
}

as.fv.minconfit <- function(x) x$fit

######  convergence status of 'optim' object

optimStatus <- function(x, call=NULL) {
  cgce <- x$convergence
  switch(paste(cgce),
         "0" = {
           simpleMessage(
                         paste("Converged successfully after",
                               x$counts[["function"]],
                               "iterations"),
                         call)
         },
         "1" = simpleWarning("Iteration limit maxit was reached", call),
         "10" = simpleWarning("Nelder-Mead simplex was degenerate", call),
         "51"= {
           simpleWarning(
                         paste("Warning message from L-BGFS-B method:",
                               sQuote(x$message)),
                         call)
         },
         "52"={
           simpleError(
                         paste("Error message from L-BGFS-B method:",
                               sQuote(x$message)),
                         call)
         },
         simpleWarning(paste("Unrecognised error code", cgce), call)
         )
}

signalStatus <- function(x, errors.only=FALSE) {
  stopifnot(inherits(x, "condition"))
  if(inherits(x, "error")) stop(x)
  if(inherits(x, "warning")) warning(x) 
  if(inherits(x, "message") && !errors.only) message(x)
  return(invisible(NULL))
}

printStatus <- function(x, errors.only=FALSE) {
  prefix <-
    if(inherits(x, "error")) "error: " else 
    if(inherits(x, "warning")) "warning: " else NULL
  if(!is.null(prefix) || !errors.only)
    cat(paste(prefix, conditionMessage(x), "\n", sep=""))
  return(invisible(NULL))
}

accumulateStatus <- function(x, stats=NULL) {
  if(is.null(stats))
    stats <- list(values=list(), frequencies=integer(0))
  if(!inherits(x, c("error", "warning", "message")))
    return(stats)
  with(stats,
       {
         same <- unlist(lapply(values, identical, y=x))
         if(any(same)) {
           i <- min(which(same))
           frequencies[i] <- frequencies[i] + 1
         } else {
           values <- append(values, list(x))
           frequencies <- c(frequencies, 1)
         }
       })
  stats <- list(values=values, frequencies=frequencies)
  return(stats)
}

printStatusList <- function(stats) {
  with(stats,
       {
         for(i in seq_along(values)) {
           printStatus(values[i])
           cat(paste("\t", paren(paste(frequencies[i], "times")), "\n"))
         }
       }
       )
  invisible(NULL)
}

  
############### applications (specific models) ##################


## lookup table of explicitly-known K functions and pcf
## and algorithms for computing sensible starting parameters

.Spatstat.ClusterModelInfoTable <- 
  list(
       Thomas=list(
         ## Thomas process: par = (kappa, sigma2)
         modelname = "Thomas process",
         isPCP=TRUE,
         ## K-function
         K = function(par,rvals, ...){
           if(any(par <= 0))
             return(rep.int(Inf, length(rvals)))
           pi*rvals^2+(1-exp(-rvals^2/(4*par[2])))/par[1]
         },
         ## pair correlation function
         pcf= function(par,rvals, ...){
           if(any(par <= 0))
             return(rep.int(Inf, length(rvals)))
           1 + exp(-rvals^2/(4 * par[2]))/(4 * pi * par[1] * par[2])
         },
         ## sensible starting parameters
         selfstart = function(X) {
           kappa <- intensity(X)
           sigma2 <- 4 * mean(nndist(X))^2
           c(kappa=kappa, sigma2=sigma2)
         },
         ## meaningful model parameters
         interpret = function(par, lambda) {
           kappa <- par[["kappa"]]
           sigma <- sqrt(par[["sigma2"]])
           mu <- if(is.numeric(lambda) && length(lambda) == 1)
             lambda/kappa else NA
           c(kappa=kappa, sigma=sigma, mu=mu)
         }
         ),
       ## ...............................................
       MatClust=list(
         ## Matern Cluster process: par = (kappa, R)
         modelname = "Matern cluster process",
         isPCP=TRUE,
         K = function(par,rvals, ..., funaux){
           if(any(par <= 0))
             return(rep.int(Inf, length(rvals)))
           kappa <- par[1]
           R <- par[2]
           Hfun <- funaux$Hfun
           y <- pi * rvals^2 + (1/kappa) * Hfun(rvals/(2 * R))
           return(y)
         },
         pcf= function(par,rvals, ..., funaux){
             if(any(par <= 0))
               return(rep.int(Inf, length(rvals)))
             kappa <- par[1]
             R <- par[2]
             g <- funaux$g
             y <- 1 + (1/(pi * kappa * R^2)) * g(rvals/(2 * R))
             return(y)
           },
         funaux=list(
           Hfun=function(zz) {
             ok <- (zz < 1)
             h <- numeric(length(zz))
             h[!ok] <- 1
             z <- zz[ok]
             h[ok] <- 2 + (1/pi) * (
                                    (8 * z^2 - 4) * acos(z)
                                    - 2 * asin(z)
                                    + 4 * z * sqrt((1 - z^2)^3)
                                    - 6 * z * sqrt(1 - z^2)
                                    )
             return(h)
           },
           DOH=function(zz) {
             ok <- (zz < 1)
             h <- numeric(length(zz))
             h[!ok] <- 0
             z <- zz[ok]
             h[ok] <- (16/pi) * (z * acos(z) - (z^2) * sqrt(1 - z^2))
             return(h)
           },
           ## g(z) = DOH(z)/z has a limit at z=0.
           g=function(zz) {
             ok <- (zz < 1)
             h <- numeric(length(zz))
             h[!ok] <- 0
             z <- zz[ok]
             h[ok] <- (2/pi) * (acos(z) - z * sqrt(1 - z^2))
             return(h)
           }),
         ## sensible starting paramters
         selfstart = function(X) {
           kappa <- intensity(X)
           R <- 2 * mean(nndist(X)) 
           c(kappa=kappa, R=R)
         },
         ## meaningful model parameters
         interpret = function(par, lambda) {
           kappa <- par[["kappa"]]
           R     <- par[["R"]]
           mu    <- if(is.numeric(lambda) && length(lambda) == 1)
             lambda/kappa else NA           
           c(kappa=kappa, R=R, mu=mu)
         }
         ),
       ## ...............................................
       Cauchy=list(
         ## Neyman-Scott with Cauchy clusters: par = (kappa, eta2)
         modelname = "Neyman-Scott process with Cauchy kernel",
         isPCP=TRUE,
         K = function(par,rvals, ...){
           if(any(par <= 0))
             return(rep.int(Inf, length(rvals)))
           pi*rvals^2 + (1 - 1/sqrt(1 + rvals^2/par[2]))/par[1]
         },
         pcf= function(par,rvals, ...){
           if(any(par <= 0))
             return(rep.int(Inf, length(rvals)))
           1 + ((1 + rvals^2/par[2])^(-1.5))/(2 * pi * par[2] * par[1])
         },
         selfstart = function(X) {
           kappa <- intensity(X)
           eta2 <- 4 * mean(nndist(X))^2
           c(kappa = kappa, eta2 = eta2)
         },
         ## meaningful model parameters
         interpret = function(par, lambda) {
           kappa <- par[["kappa"]]
           omega <- sqrt(par[["eta2"]])/2
           mu <- if(is.numeric(lambda) && length(lambda) == 1)
             lambda/kappa else NA
           c(kappa=kappa, omega=omega, mu=mu)
         }
         ),
       ## ...............................................
       VarGamma=list(
         ## Neyman-Scott with VarianceGamma/Bessel clusters: par = (kappa, eta)
         modelname = "Neyman-Scott process with Variance Gamma kernel",
         isPCP=TRUE,
         K = local({
           ## K function requires integration of pair correlation
           xgx <- function(x, par, nu.pcf) {
             ## x * pcf(x) without check on par values
             numer <- (x/par[2])^nu.pcf * besselK(x/par[2], nu.pcf)
             denom <- 2^(nu.pcf+1) * pi * par[2]^2 * par[1] * gamma(nu.pcf + 1)
             return(x * (1 + numer/denom))
           }
           vargammaK <- function(par,rvals, ..., margs){
             ## margs = list(.. nu.pcf.. ) 
             if(any(par <= 0))
               return(rep.int(Inf, length(rvals)))
             nu.pcf <- margs$nu.pcf
             out <- numeric(length(rvals))
             ok <- (rvals > 0)
             rvalsok <- rvals[ok]
             outok <- numeric(sum(ok))
             for (i in 1:length(rvalsok))
               outok[i] <- 2 * pi * integrate(xgx,
                                              lower=0, upper=rvalsok[i],
                                              par=par, nu.pcf=nu.pcf)$value
             out[ok] <- outok
             return(out)
           }
           vargammaK
           }), ## end of 'local'
         pcf= function(par,rvals, ..., margs){
           ## margs = list(..nu.pcf..)
           if(any(par <= 0))
             return(rep.int(Inf, length(rvals)))
           nu.pcf <- margs$nu.pcf
           sig2 <- 1 / (4 * pi * (par[2]^2) * nu.pcf * par[1])
           denom <- 2^(nu.pcf - 1) * gamma(nu.pcf)
           rr <- rvals / par[2]
           ## Matern correlation function
           fr <- ifelseXB(rr > 0,
                        (rr^nu.pcf) * besselK(rr, nu.pcf) / denom,
                        1)
           return(1 + sig2 * fr)
         },
         parhandler = function(..., nu.ker = -1/4) {
           check.1.real(nu.ker)
           stopifnot(nu.ker > -1/2)
           nu.pcf <- 2 * nu.ker + 1
           return(list(type="Kernel",
                       model="VarGamma",
                       margs=list(nu.ker=nu.ker,
                                  nu.pcf=nu.pcf)))
         },
         ## sensible starting values
         selfstart = function(X) {
           kappa <- intensity(X)
           eta <- 2 * mean(nndist(X))
           c(kappa=kappa, eta=eta)
         },
         ## meaningful model parameters
         interpret = function(par, lambda) {
           kappa <- par[["kappa"]]
           omega <- par[["eta"]]
           mu <- if(is.numeric(lambda) && length(lambda) == 1)
             lambda/kappa else NA
           c(kappa=kappa, omega=omega, mu=mu)
         }
         ),
       ## ...............................................
       LGCP=list(
         ## Log Gaussian Cox process: par = (sigma2, alpha)
         modelname = "Log-Gaussian Cox process",
         isPCP=FALSE,
         ## calls relevant covariance function from RandomFields package
         K = function(par, rvals, ..., model, margs) {
           if(any(par <= 0))
             return(rep.int(Inf, length(rvals)))
           if(model == "exponential") {
             ## For efficiency and to avoid need for RandomFields package
             integrand <- function(r,par,...) 2*pi*r*exp(par[1]*exp(-r/par[2]))
           } else {
             ## use RandomFields 
             integrand <- function(r,par,model,margs) {
               modgen <- attr(model, "modgen")
               if(length(margs) == 0) {
                 mod <- modgen(var=par[1], scale=par[2])
               } else {
                 mod <- do.call(modgen,
                                append(list(var=par[1], scale=par[2]),
                                       margs))
               }
               2*pi *r *exp(RFcov(model=mod, x=r))
             }
           }
           nr <- length(rvals)
           th <- numeric(nr)
           if(spatstat.options("fastK.lgcp")) {
             ## integrate using Simpson's rule
             fvals <- integrand(r=rvals, par=par, model=model, margs=margs)
             th[1] <- rvals[1] * fvals[1]/2
             if(nr > 1)
               for(i in 2:nr)
                 th[i] <- th[i-1] +
                   (rvals[i] - rvals[i-1]) * (fvals[i] + fvals[i-1])/2
           } else {
             ## integrate using 'integrate'
             th[1] <- if(rvals[1] == 0) 0 else 
             integrate(integrand,lower=0,upper=rvals[1],
                       par=par,model=model,margs=margs)$value
             for (i in 2:length(rvals)) {
               delta <- integrate(integrand,
                                  lower=rvals[i-1],upper=rvals[i],
                                  par=par,model=model,margs=margs)
               th[i]=th[i-1]+delta$value
             }
           }
           return(th)
         },
         pcf= function(par, rvals, ..., model, margs) {
           if(any(par <= 0))
             return(rep.int(Inf, length(rvals)))
           if(model == "exponential") {
             ## For efficiency and to avoid need for RandomFields package
             gtheo <- exp(par[1]*exp(-rvals/par[2]))
           } else {
             modgen <- attr(model, "modgen")
             if(length(margs) == 0) {
               mod <- modgen(var=par[1], scale=par[2])
             } else {
               mod <- do.call(modgen,
                              append(list(var=par[1], scale=par[2]),
                                     margs))
             }
             gtheo <- exp(RFcov(model=mod, x=rvals))
           }
           return(gtheo)
         },
         parhandler=function(model = "exponential", ...) {
           if(!is.character(model))
             stop("Covariance function model should be specified by name")
           margs <- c(...)
           if(model != "exponential") {
             if(!require(RandomFields))
               stop("The package RandomFields is required")
             ## get the 'model generator' 
             modgen <- mget(paste0("RM", model), inherits=TRUE,
                           ifnotfound=list(NULL))[[1]]
             if(is.null(modgen) || !inherits(modgen, "RMmodelgenerator"))
               stop(paste("Model", sQuote(model), "is not recognised"))
             attr(model, "modgen") <- modgen
           }
           return(list(type="Covariance", model=model, margs=margs))
         },
         ## sensible starting values
         selfstart = function(X) {
           alpha <- 2 * mean(nndist(X))
           c(sigma2=1, alpha=alpha)
         },
         ## meaningful model parameters
         interpret = function(par, lambda) {
           sigma2 <- par[["sigma2"]]
           alpha  <- par[["alpha"]]
           mu <- if(is.numeric(lambda) && length(lambda) == 1 && lambda > 0)
             log(lambda) - sigma2/2 else NA
           c(sigma2=sigma2, alpha=alpha, mu=mu)
         }
         )
  )

spatstatClusterModelInfo <- function(name) {
  if(!is.character(name) || length(name) != 1)
    stop("Argument must be a single character string", call.=FALSE)
  nama2 <- names(.Spatstat.ClusterModelInfoTable)
  if(!(name %in% nama2))
    stop(paste(sQuote(name), "is not recognised;",
               "valid names are", commasep(sQuote(nama2))),
         call.=FALSE)
  out <- .Spatstat.ClusterModelInfoTable[[name]]
  return(out)
}

getdataname <- function(defaultvalue, ..., dataname=NULL) {
  if(!is.null(dataname)) dataname else defaultvalue
}
  
thomas.estK <- function(X, startpar=c(kappa=1,sigma2=1),
                        lambda=NULL, q=1/4, p=2, rmin=NULL, rmax=NULL, ...) {

  dataname <-
    getdataname(short.deparse(substitute(X), 20), ...)

  if(inherits(X, "fv")) {
    K <- X
    if(!identical(attr(K, "fname")[1], "K"))
      warning("Argument X does not appear to be a K-function")
  } else if(inherits(X, "ppp")) {
    K <- Kest(X)
    dataname <- paste("Kest(", dataname, ")", sep="")
    if(is.null(lambda))
      lambda <- summary(X)$intensity
  } else 
    stop("Unrecognised format for argument X")

  startpar <- check.named.vector(startpar, c("kappa","sigma2"))

  info <- spatstatClusterModelInfo("Thomas")
  theoret <- info$K
  
  result <- mincontrast(K, theoret, startpar,
                        ctrl=list(q=q, p=p,rmin=rmin, rmax=rmax),
                        fvlab=list(label="%s[fit](r)",
                          desc="minimum contrast fit of Thomas process"),
                        explain=list(dataname=dataname,
                          fname=attr(K, "fname"),
                          modelname="Thomas process"), ...)
  ## imbue with meaning
  par <- result$par
  names(par) <- c("kappa", "sigma2")
  result$par <- par
  ## infer meaningful model parameters
  result$modelpar <- info$interpret(par, lambda)
  result$internal <- list(model="Thomas")
  return(result)
}

lgcp.estK <- function(X, startpar=c(sigma2=1,alpha=1),
                      covmodel=list(model="exponential"), 
                      lambda=NULL, q=1/4, p=2, rmin=NULL, rmax=NULL, ...) {

  dataname <-
    getdataname(short.deparse(substitute(X), 20), ...)
  
  if(inherits(X, "fv")) {
    K <- X
    if(!identical(attr(K, "fname")[1], "K"))
      warning("Argument X does not appear to be a K-function")
  } else if(inherits(X, "ppp")) {
    K <- Kest(X)
    dataname <- paste("Kest(", dataname, ")", sep="")
    if(is.null(lambda))
      lambda <- summary(X)$intensity
  } else 
    stop("Unrecognised format for argument X")

  startpar <- check.named.vector(startpar, c("sigma2","alpha"))

  info <- spatstatClusterModelInfo("LGCP")
  
  ## digest parameters of Covariance model and test validity
  ph <- info$parhandler
  cmodel <- do.call(ph, covmodel)
  
  theoret <- info$K

  result <- mincontrast(K, theoret, startpar,
                        ctrl=list(q=q, p=p, rmin=rmin, rmax=rmax),
                        fvlab=list(label="%s[fit](r)",
                          desc="minimum contrast fit of LGCP"),
                        explain=list(dataname=dataname,
                          fname=attr(K, "fname"),
                          modelname="log-Gaussian Cox process"),
                        ...,
                        model=cmodel$model,
                        margs=cmodel$margs)
  ## imbue with meaning
  par <- result$par
  names(par) <- c("sigma2", "alpha")
  result$par <- par
  result$covmodel <- cmodel
  ## infer model parameters
  result$modelpar <- info$interpret(par, lambda)
  result$internal <- list(model="lgcp")
  return(result)
}



matclust.estK <- function(X, startpar=c(kappa=1,R=1),
                          lambda=NULL, q=1/4, p=2, rmin=NULL, rmax=NULL, ...) {

  dataname <-
    getdataname(short.deparse(substitute(X), 20), ...)

  if(inherits(X, "fv")) {
    K <- X
    if(!identical(attr(K, "fname")[1], "K"))
      warning("Argument X does not appear to be a K-function")
  } else if(inherits(X, "ppp")) {
    K <- Kest(X)
    dataname <- paste("Kest(", dataname, ")", sep="")
    if(is.null(lambda))
      lambda <- summary(X)$intensity
  } else 
    stop("Unrecognised format for argument X")

  startpar <- check.named.vector(startpar, c("kappa","R"))

  info <- spatstatClusterModelInfo("MatClust")
  theoret <- info$K
  funaux <-  info$funaux
  
  result <- mincontrast(K, theoret, startpar,
                        ctrl=list(q=q, p=p,rmin=rmin, rmax=rmax),
                        fvlab=list(label="%s[fit](r)",
                          desc="minimum contrast fit of Matern Cluster process"),
                        explain=list(dataname=dataname,
                          fname=attr(K, "fname"),
                          modelname="Matern Cluster process"),
                        ...,
                        funaux=funaux)
  ## imbue with meaning
  par <- result$par
  names(par) <- c("kappa", "R")
  result$par <- par
  ## infer model parameters
  result$modelpar <- info$interpret(par, lambda)
  result$internal <- list(model="MatClust")
  return(result)
}


## versions using pcf (suggested by Jan Wild)

thomas.estpcf <- function(X, startpar=c(kappa=1,sigma2=1),
                          lambda=NULL, q=1/4, p=2, rmin=NULL, rmax=NULL, ...,
                          pcfargs=list()){

  dataname <-
    getdataname(short.deparse(substitute(X), 20), ...)

  if(inherits(X, "fv")) {
    g <- X
    if(!identical(attr(g, "fname")[1], "g"))
      warning("Argument X does not appear to be a pair correlation function")
  } else if(inherits(X, "ppp")) {
    g <- do.call("pcf.ppp", append(list(X), pcfargs))
    dataname <- paste("pcf(", dataname, ")", sep="")
    if(is.null(lambda))
      lambda <- summary(X)$intensity
  } else 
    stop("Unrecognised format for argument X")

  startpar <- check.named.vector(startpar, c("kappa","sigma2"))

  info <- spatstatClusterModelInfo("Thomas")
  theoret <- info$pcf
  
  ## avoid using g(0) as it may be infinite
  argu <- fvnames(g, ".x")
  rvals <- g[[argu]]
  if(rvals[1] == 0 && (is.null(rmin) || rmin == 0)) {
    rmin <- rvals[2]
  }
  result <- mincontrast(g, theoret, startpar,
                        ctrl=list(q=q, p=p,rmin=rmin, rmax=rmax),
                        fvlab=list(
                          label="%s[fit](r)",
                          desc="minimum contrast fit of Thomas process"),
                        explain=list(
                          dataname=dataname,
                          fname=attr(g, "fname"),
                          modelname="Thomas process"), ...)
  ## imbue with meaning
  par <- result$par
  names(par) <- c("kappa", "sigma2")
  result$par <- par
  ## infer model parameters
  result$modelpar <- info$interpret(par, lambda)
  result$internal <- list(model="Thomas")
  return(result)
}

matclust.estpcf <- function(X, startpar=c(kappa=1,R=1),
                            lambda=NULL, q=1/4, p=2, rmin=NULL, rmax=NULL, ...,
                            pcfargs=list()){

  dataname <-
    getdataname(short.deparse(substitute(X), 20), ...)

  if(inherits(X, "fv")) {
    g <- X
    if(!identical(attr(g, "fname")[1], "g"))
      warning("Argument X does not appear to be a pair correlation function")
  } else if(inherits(X, "ppp")) {
    g <- do.call("pcf.ppp", append(list(X), pcfargs))
    dataname <- paste("pcf(", dataname, ")", sep="")
    if(is.null(lambda))
      lambda <- summary(X)$intensity
  } else 
    stop("Unrecognised format for argument X")

  startpar <- check.named.vector(startpar, c("kappa","R"))

  info <- spatstatClusterModelInfo("MatClust")
  theoret <- info$pcf
  funaux <-  info$funaux
  
  ## avoid using g(0) as it may be infinite
  argu <- fvnames(g, ".x")
  rvals <- g[[argu]]
  if(rvals[1] == 0 && (is.null(rmin) || rmin == 0)) {
    rmin <- rvals[2]
  }
  result <- mincontrast(g, theoret, startpar,
                        ctrl=list(q=q, p=p,rmin=rmin, rmax=rmax),
                        fvlab=list(label="%s[fit](r)",
                          desc="minimum contrast fit of Matern Cluster process"),
                        explain=list(dataname=dataname,
                          fname=attr(g, "fname"),
                          modelname="Matern Cluster process"),
                        ...,
                        funaux=funaux)
  ## imbue with meaning
  par <- result$par
  names(par) <- c("kappa", "R")
  result$par <- par
  ## infer model parameters
  result$modelpar <- info$interpret(par, lambda)
  result$internal <- list(model="MatClust")
  return(result)
}

lgcp.estpcf <- function(X, startpar=c(sigma2=1,alpha=1),
                      covmodel=list(model="exponential"), 
                        lambda=NULL, q=1/4, p=2, rmin=NULL, rmax=NULL, ...,
                        pcfargs=list()) {
  
  dataname <-
    getdataname(short.deparse(substitute(X), 20), ...)
  
  if(inherits(X, "fv")) {
    g <- X
    if(!identical(attr(g, "fname")[1], "g"))
      warning("Argument X does not appear to be a pair correlation function")
  } else if(inherits(X, "ppp")) {
    g <- do.call("pcf.ppp", append(list(X), pcfargs))
    dataname <- paste("pcf(", dataname, ")", sep="")
    if(is.null(lambda))
      lambda <- summary(X)$intensity
  } else 
    stop("Unrecognised format for argument X")

  startpar <- check.named.vector(startpar, c("sigma2","alpha"))

  info <- spatstatClusterModelInfo("LGCP")
  
  ## digest parameters of Covariance model and test validity
  ph <- info$parhandler
  cmodel <- do.call(ph, covmodel)
  
  theoret <- info$pcf
  
  result <- mincontrast(g, theoret, startpar,
                        ctrl=list(q=q, p=p, rmin=rmin, rmax=rmax),
                        fvlab=list(label="%s[fit](r)",
                          desc="minimum contrast fit of LGCP"),
                        explain=list(dataname=dataname,
                          fname=attr(g, "fname"),
                          modelname="log-Gaussian Cox process"),
                        ...,
                        model=cmodel$model,
                        margs=cmodel$margs)
  ## imbue with meaning
  par <- result$par
  names(par) <- c("sigma2", "alpha")
  result$par <- par
  result$covmodel <- cmodel
  ## infer model parameters
  result$modelpar <- info$interpret(par, lambda)
  result$internal <- list(model="lgcp")
  return(result)
}


cauchy.estK <- function(X, startpar=c(kappa=1,eta2=1),
                        lambda=NULL, q=1/4, p=2, rmin=NULL, rmax=NULL, ...) {

## omega: scale parameter of Cauchy kernel function
## eta: scale parameter of Cauchy pair correlation function
## eta = 2 * omega

  dataname <-
    getdataname(short.deparse(substitute(X), 20), ...)

  if(inherits(X, "fv")) {
    K <- X
    if(!identical(attr(K, "fname")[1], "K"))
      warning("Argument X does not appear to be a K-function")
  } else if(inherits(X, "ppp")) {
    K <- Kest(X)
    dataname <- paste("Kest(", dataname, ")", sep="")
    if(is.null(lambda))
      lambda <- summary(X)$intensity
  } else 
    stop("Unrecognised format for argument X")

  startpar <- check.named.vector(startpar, c("kappa","eta2"))

  info <- spatstatClusterModelInfo("Cauchy")
  theoret <- info$K

  desc <- "minimum contrast fit of Neyman-Scott process with Cauchy kernel"
  result <- mincontrast(K, theoret, startpar,
                        ctrl=list(q=q, p=p,rmin=rmin, rmax=rmax),
                        fvlab=list(label="%s[fit](r)", desc=desc),
                        explain=list(dataname=dataname,
                          fname=attr(K, "fname"),
                          modelname="Cauchy process"), ...)
  ## imbue with meaning
  par <- result$par
  names(par) <- c("kappa", "eta2")
  result$par <- par
  ## infer model parameters
  result$modelpar <- info$interpret(par, lambda)
  result$internal <- list(model="Cauchy")
  return(result)
}


cauchy.estpcf <- function(X, startpar=c(kappa=1,eta2=1),
                          lambda=NULL, q=1/4, p=2, rmin=NULL, rmax=NULL, ...,
                          pcfargs=list()) {

## omega: scale parameter of Cauchy kernel function
## eta: scale parameter of Cauchy pair correlation function
## eta = 2 * omega

  dataname <-
    getdataname(short.deparse(substitute(X), 20), ...)

  if(inherits(X, "fv")) {
    g <- X
    if(!identical(attr(g, "fname")[1], "g"))
      warning("Argument X does not appear to be a pair correlation function")
  } else if(inherits(X, "ppp")) {
    g <- do.call("pcf.ppp", append(list(X), pcfargs))
    dataname <- paste("pcf(", dataname, ")", sep="")
    if(is.null(lambda))
      lambda <- summary(X)$intensity
  } else 
    stop("Unrecognised format for argument X")

  startpar <- check.named.vector(startpar, c("kappa","eta2"))

  info <- spatstatClusterModelInfo("Cauchy")
  theoret <- info$pcf

  ## avoid using g(0) as it may be infinite
  argu <- fvnames(g, ".x")
  rvals <- g[[argu]]
  if(rvals[1] == 0 && (is.null(rmin) || rmin == 0)) {
    rmin <- rvals[2]
  }
  
  desc <- "minimum contrast fit of Neyman-Scott process with Cauchy kernel"
  result <- mincontrast(g, theoret, startpar,
                        ctrl=list(q=q, p=p,rmin=rmin, rmax=rmax),
                        fvlab=list(label="%s[fit](r)", desc=desc),
                        explain=list(dataname=dataname,
                          fname=attr(g, "fname"),
                          modelname="Cauchy process"), ...)
  ## imbue with meaning
  par <- result$par
  names(par) <- c("kappa", "eta2")
  result$par <- par
  ## infer model parameters
  result$modelpar <- info$interpret(par, lambda)
  result$internal <- list(model="Cauchy")
  return(result)
}

## user-callable
resolve.vargamma.shape <- function(..., nu.ker=NULL, nu.pcf=NULL) {
  if(is.null(nu.ker) && is.null(nu.pcf))
    stop("Must specify either nu.ker or nu.pcf", call.=FALSE)
  if(!is.null(nu.ker) && !is.null(nu.pcf))
    stop("Only one of nu.ker and nu.pcf should be specified",
         call.=FALSE)
  if(!is.null(nu.ker)) {
    check.1.real(nu.ker)
    stopifnot(nu.ker > -1/2)
    nu.pcf <- 2 * nu.ker + 1
  } else {
    check.1.real(nu.pcf)
    stopifnot(nu.pcf > 0)
    nu.ker <- (nu.pcf - 1)/2
  }
  return(list(nu.ker=nu.ker, nu.pcf=nu.pcf))
}

vargamma.estK <- function(X, startpar=c(kappa=1,eta=1), nu.ker = -1/4,
                        lambda=NULL, q=1/4, p=2, rmin=NULL, rmax=NULL,
                          nu.pcf=NULL, ...) {

## nu.ker: smoothness parameter of Variance Gamma kernel function
## omega: scale parameter of kernel function
## nu.pcf: smoothness parameter of Variance Gamma pair correlation function
## eta: scale parameter of Variance Gamma pair correlation function
## nu.pcf = 2 * nu.ker + 1    and    eta = omega

  dataname <-
    getdataname(short.deparse(substitute(X), 20), ...)

  if(missing(nu.ker) && !is.null(nu.pcf)) nu.ker <- NULL
  
  if(inherits(X, "fv")) {
    K <- X
    if(!identical(attr(K, "fname")[1], "K"))
      warning("Argument X does not appear to be a K-function")
  } else if(inherits(X, "ppp")) {
    K <- Kest(X)
    dataname <- paste("Kest(", dataname, ")", sep="")
    if(is.null(lambda))
      lambda <- summary(X)$intensity
  } else 
    stop("Unrecognised format for argument X")

  startpar <- check.named.vector(startpar, c("kappa","eta"))

  info <- spatstatClusterModelInfo("VarGamma")
  theoret <- info$K
  
  ## test validity of parameter nu and digest
  ph <- info$parhandler
  cmodel <- ph(nu.ker=nu.ker, nu.pcf=nu.pcf)
  margs <- cmodel$margs

  desc <- "minimum contrast fit of Neyman-Scott process with Variance Gamma kernel"
  result <- mincontrast(K, theoret, startpar,
                        ctrl=list(q=q, p=p,rmin=rmin, rmax=rmax),
                        fvlab=list(label="%s[fit](r)", desc=desc),
                        explain=list(dataname=dataname,
                          fname=attr(K, "fname"),
                          modelname="Variance Gamma process"),
                        margs=margs, ...)
  ## imbue with meaning
  par <- result$par
  names(par) <- c("kappa", "eta")
  result$par <- par
  result$covmodel <- cmodel
  ## infer model parameters
  result$modelpar <- info$interpret(par, lambda)
  result$internal <- list(model="VarGamma")
  return(result)
}


vargamma.estpcf <- function(X, startpar=c(kappa=1,eta=1), nu.ker=-1/4, 
                          lambda=NULL, q=1/4, p=2, rmin=NULL, rmax=NULL, 
                          nu.pcf=NULL, ..., pcfargs=list()) {

## nu.ker: smoothness parameter of Variance Gamma kernel function
## omega: scale parameter of kernel function
## nu.pcf: smoothness parameter of Variance Gamma pair correlation function
## eta: scale parameter of Variance Gamma pair correlation function
## nu.pcf = 2 * nu.ker + 1    and    eta = omega

  dataname <-
    getdataname(short.deparse(substitute(X), 20), ...)

  if(missing(nu.ker) && !is.null(nu.pcf)) nu.ker <- NULL

  if(inherits(X, "fv")) {
    g <- X
    if(!identical(attr(g, "fname")[1], "g"))
      warning("Argument X does not appear to be a pair correlation function")
  } else if(inherits(X, "ppp")) {
    g <- do.call("pcf.ppp", append(list(X), pcfargs))
    dataname <- paste("pcf(", dataname, ")", sep="")
    if(is.null(lambda))
      lambda <- summary(X)$intensity
  } else 
    stop("Unrecognised format for argument X")

  startpar <- check.named.vector(startpar, c("kappa","eta"))

  info <- spatstatClusterModelInfo("VarGamma")
  theoret <- info$pcf

  ## test validity of parameter nu and digest 
  ph <- info$parhandler
  cmodel <- ph(nu.ker=nu.ker, nu.pcf=nu.pcf)
  margs <- cmodel$margs
  
  ## avoid using g(0) as it may be infinite
  argu <- fvnames(g, ".x")
  rvals <- g[[argu]]
  if(rvals[1] == 0 && (is.null(rmin) || rmin == 0)) {
    rmin <- rvals[2]
  }
  
  desc <- "minimum contrast fit of Neyman-Scott process with Variance Gamma kernel"
  result <- mincontrast(g, theoret, startpar,
                        ctrl=list(q=q, p=p,rmin=rmin, rmax=rmax),
                        fvlab=list(label="%s[fit](r)", desc=desc),
                        explain=list(dataname=dataname,
                          fname=attr(g, "fname"),
                          modelname="Variance Gamma process"),
                        margs=margs,
                        ...)
  ## imbue with meaning
  par <- result$par
  names(par) <- c("kappa", "eta")
  result$par <- par
  result$covmodel <- cmodel
  ## infer model parameters
  result$modelpar <- info$interpret(par, lambda)
  result$internal <- list(model="VarGamma")
  return(result)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/minnndist.R"
##
##  minnndist.R
##
## Fast versions of min(nndist(X)), max(nndist(X))
##
##  $Revision: 1.4 $  $Date: 2014/10/24 00:22:30 $

minnndist <- function(X, positive=FALSE) {
  stopifnot(is.ppp(X))
  n <- npoints(X)
  if(n <= 1) return(NA)
  x <- X$x
  y <- X$y
  o <- fave.order(y)
  big <- sqrt(.Machine$double.xmax)
  if(positive) {
      z <- .C("minPnnd2",
              n = as.integer(n),
              x = as.double(x[o]),
              y = as.double(y[o]),
              as.double(big),
              result = as.double(numeric(1)))
  } else {
      z <- .C("minnnd2",
              n = as.integer(n),
              x = as.double(x[o]),
              y = as.double(y[o]),
              as.double(big),
              result = as.double(numeric(1)))
  }
  return(sqrt(z$result))
}

maxnndist <- function(X, positive=FALSE) {
  stopifnot(is.ppp(X))
  n <- npoints(X)
  if(n <= 1) return(NA)
  x <- X$x
  y <- X$y
  o <- fave.order(y)
  big <- sqrt(.Machine$double.xmax)
  if(positive) {
      z <- .C("maxPnnd2",
              n = as.integer(n),
              x = as.double(x[o]),
              y = as.double(y[o]),
              as.double(big),
              result = as.double(numeric(1)))
  } else {
      z <- .C("maxnnd2",
              n = as.integer(n),
              x = as.double(x[o]),
              y = as.double(y[o]),
              as.double(big),
              result = as.double(numeric(1)))
  }
  return(sqrt(z$result))
}

          
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/model.depends.R"
#
# Determine which 'canonical variables' depend on a supplied covariate
#
#   $Revision: 1.8 $  $Date: 2013/04/25 06:37:43 $
#

model.depends <- function(object) {
  # supplied covariates
  fo <- formula(object)
  if(length(as.list(fo)) == 3) {
    # formula has a response: strip it
    fo <- fo[-2]
  }
  covars <- variablesinformula(fo)
  # canonical covariates 
  mm <- model.matrix(object)
  ass <- attr(mm, "assign")
  # model terms
  tt <- terms(object)
  lab <- attr(tt, "term.labels")
  # 'ass' maps canonical covariates to 'lab'
  # determine which canonical covariate depends on which supplied covariate
  depends <- matrix(FALSE, length(ass), length(covars))
  for(i in seq(along=ass)) {
    if(ass[i] == 0) # 0 is the intercept term
      depends[i,] <- FALSE
    else {
      turm <- lab[ass[i]]
      depends[i, ] <- covars %in% all.vars(parse(text=turm))
    }
  }
  rownames(depends) <- colnames(mm)
  colnames(depends) <- covars
  # detect offsets
  if(!is.null(oo <- attr(tt, "offset")) && ((noo <- length(oo)) > 0)) {
    # entries of 'oo' index the list of variables in terms object
    vv <- attr(tt, "variables")
    offdep <- matrix(FALSE, noo, length(covars))
    offnms <- character(noo)
    for(i in seq_len(noo)) {
      offseti <- languageEl(vv, oo[i] + 1)
      offdep[i, ] <- covars %in% all.vars(offseti)
      offnms[i] <- deparse(offseti)
    }
    rownames(offdep) <- offnms
    colnames(offdep) <- covars
    attr(depends, "offset") <- offdep
  }
  return(depends)
}

model.is.additive <- function(object) {
  dep <- model.depends(object)
  hit <- t(dep) %*% dep
  diag(hit) <- 0
  ok <- all(hit == 0)
  return(ok)
}

model.covariates <- function(object, fitted=TRUE, offset=TRUE) {
  md <- model.depends(object)
  nm <- colnames(md)
  keep <- rep.int(FALSE, length(nm))
  # variables used in formula with coefficients
  if(fitted) keep <- apply(md, 2, any)
  # variables used in offset
  if(offset) {
    oo <- attr(md, "offset")
    if(!is.null(oo)) 
      keep <- keep | apply(oo, 2, any)
  }
  return(nm[keep])
}

has.offset.term <- function(object) {
  # model terms
  tt <- terms(object)
  oo  <- attr(tt, "offset")
  return(!is.null(oo) && (length(oo) > 0))
}

has.offset <- function(object) {
  has.offset.term(object) || !is.null(model.offset(model.frame(object)))
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/morisita.R"
#
# morisita.R
#
#  $Revision: 1.1 $  $Date: 2014/10/24 00:22:30 $
#

miplot <- function(X, ...) {
  Xname <- short.deparse(substitute(X))
  X <- as.ppp(X)
  W <- X$window
  N <- X$n
  if(W$type != "rectangle")
    stop("Window of X is not a rectangle - Morisita index undefined")
  a <- min(diff(W$xrange), diff(W$yrange))
  maxnquad <- floor(a/mean(nndist(X)))
  if(maxnquad <= 1)
    stop("Not enough points for a Morisita plot")
  mindex <- numeric(maxnquad)
  for(nquad in 1:maxnquad) {
    qq <- quadratcount(X, nquad, nquad)
    tt <- as.vector(as.table(qq))
    mindex[nquad] <- length(tt) * sum(tt * (tt-1))/(N*(N-1))
  }

  quadsize <- diameter(W)/(1:maxnquad)
  ok <- (quadsize <= a)
  quadsize <- quadsize[ok]
  mindex   <- mindex[ok]
  
  unitinfo <- summary(unitname(W))$axis
  do.call("plot.default",
          resolve.defaults(list(quadsize, mindex),
                           list(...),
                           list(xlim=c(0,max(quadsize)),
                                ylim=c(0,max(1, mindex)),
                                xlab=paste("Diameter of quadrat", unitinfo),
                                ylab="Morisita index",
                                main=paste("Morisita plot for", Xname))))
  abline(h=1, lty=2)
  return(invisible(NULL))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/morphology.R"
#
#  morphology.R
#
#  dilation, erosion, opening, closing
#
#  generic functions
#  and methods for owin, psp, ppp
#
#  $Revision: 1.27 $   $Date: 2014/11/11 03:17:18 $
#

# ............ generic  ............................

erosion  <- function(w, r, ...) { UseMethod("erosion") }

dilation <- function(w, r, ...) { UseMethod("dilation") }

closing  <- function(w, r, ...) { UseMethod("closing") }

opening  <- function(w, r, ...) { UseMethod("opening") }

# ............ methods for class 'owin' ............................


erode.owin <- function(...) {
  .Deprecated("erosion.owin", package="spatstat")
  erosion.owin(...)
}

erosion.owin <- 
  function(w, r, shrink.frame=TRUE, ..., strict=FALSE, polygonal=NULL) {
  verifyclass(w, "owin")
  validradius(r, "erosion")
  if(r == 0 && !strict)
    return(w)

  xr <- w$xrange
  yr <- w$yrange
  
  if(2 * r >= max(diff(xr), diff(yr)))
    stop("erosion distance r too large for frame of window")

  # compute the dimensions of the eroded frame
  exr <- xr + c(r, -r)
  eyr <- yr + c(r, -r)
  ebox <- list(x=exr[c(1,2,2,1)], y=eyr[c(1,1,2,2)])

  ismask <- is.mask(w)
  if(is.empty(w))
    return(emptywindow(ebox))

  # determine type of computation
  if(is.null(polygonal))
    polygonal <- !ismask
  else {
    stopifnot(is.logical(polygonal))
    if(polygonal && ismask) {
      # try to convert
      w <- as.polygonal(w)
      if(is.mask(w))
        polygonal <- FALSE
    }
  }
  
  if(is.rectangle(w) && polygonal) {
    # result is a smaller rectangle
    if(shrink.frame) {
      return(owin(exr, eyr))  # type 'rectangle' 
    } else {
      return(owin(xr, yr, poly=ebox, check=FALSE)) # type 'polygonal'
    }
  }

  if(polygonal) {
    # compute polygonal region using polyclip package
    pnew <- polyclip::polyoffset(w$bdry, -r, jointype="round")
    # ensure correct polarity
    totarea <- sum(unlist(lapply(pnew, Area.xypolygon)))
    if(totarea < 0)
      pnew <- lapply(pnew, reverse.xypolygon)
    if(shrink.frame) {
      return(owin(poly=pnew, check=FALSE))
    } else {
      return(owin( xr,  yr, poly=pnew, check=FALSE))
    }
  }
  
  # otherwise erode the window in pixel image form
  if(w$type == "mask") 
    wnew <- erodemask(w, r, strict=strict)
  else {
    D <- distmap(w, invert=TRUE, ...)
    wnew <- levelset(D, r, if(strict) ">" else ">=")
  }
        
  if(shrink.frame) {
    # trim off some rows & columns of pixel raster
    keepcol <- (wnew$xcol >= exr[1] & wnew$xcol <= exr[2])
    keeprow <- (wnew$yrow >= eyr[1] & wnew$yrow <= eyr[2])
    wnew$xcol <- wnew$xcol[keepcol]
    wnew$yrow <- wnew$yrow[keeprow]
    wnew$dim <- c(sum(keeprow), sum(keepcol))
    wnew$m <- wnew$m[keeprow, keepcol]
    wnew$xrange <- exr
    wnew$yrange <- eyr
  }

  return(wnew)
}	

dilate.owin <- function(...) {
  .Deprecated("dilation.owin", package="spatstat")
  dilation.owin(...)
}

dilation.owin <- 
  function(w, r, ..., polygonal=NULL, tight=TRUE) {
  verifyclass(w, "owin")
  validradius(r, "dilation")
  
  if(r == 0)
    return(w)

  ismask <- is.mask(w)
  if(is.empty(w))
    return(w)

  # determine type of computation
  if(is.null(polygonal)) {
    polygonal <- !ismask
  } else stopifnot(is.logical(polygonal))
  
  if(polygonal) {
    # convert to polygonal 
    w <- as.polygonal(w)
    if(!is.polygonal(w))
      polygonal <- FALSE
  }
  
  # bounding frame
  bb <- if(tight) boundingbox(w) else as.rectangle(w)
  newbox <- grow.rectangle(bb, r)

  # compute dilation
  if(!polygonal) {
    # compute pixel approximation
    epsilon <- sqrt(w$xstep^2 + w$ystep^2)
    r <- max(r, epsilon)
    w <- rebound.owin(w, newbox)
    distant <- distmap(w, ...)
    dil <- levelset(distant, r, "<=")
    return(dil)
  } else {
    # compute polygonal region using polyclip package
    pnew <- polyclip::polyoffset(w$bdry, r, jointype="round")
    # ensure correct polarity
    totarea <- sum(unlist(lapply(pnew, Area.xypolygon)))
    if(totarea < 0)
      pnew <- lapply(pnew, reverse.xypolygon)
    # determine bounding frame, convert to owin
    if(tight) {
      out <- owin(poly=pnew, check=FALSE)
    } else {
      out <- owin(newbox$xrange, newbox$yrange, poly=pnew, check=FALSE)
    }
    return(out)
  }
}

closing.owin <- function(w, r, ..., polygonal=NULL) {
  if(missing(r))
    stop("r is required")
  validradius(r, "closing")
  wplus <- dilation.owin(w, r, ..., polygonal=polygonal, tight=FALSE)
  if(is.empty(wplus))
    return(wplus)
  wclose <- erosion.owin(wplus, r, strict=TRUE)
  wclose <- rebound.owin(wclose, as.rectangle(w))
  return(wclose)
}

opening.owin <- function(w, r, ..., polygonal=NULL) {
  if(missing(r))
    stop("r is required")
  validradius(r, "opening")
  wminus <- erosion.owin(w, r, ..., polygonal=polygonal, shrink.frame=FALSE)
  if(is.empty(wminus))
    return(wminus)
  wopen <- dilation.owin(wminus, r, tight=FALSE)
  wopen <- rebound.owin(wopen, as.rectangle(w))
  return(wopen)
}


border <- function(w, r, outside=FALSE, ...) {
  w <- as.owin(w)
  if(!outside) {
    e <- erosion(w, r, ...)
    b <- setminus.owin(w, e)
  } else {
    d <- dilation(w, r, ...)
    b <- setminus.owin(d, w)
  }
  return(b)
}

# ............ methods for class 'psp' ............................


dilation.psp <- function(w, r, ..., polygonal=TRUE, tight=TRUE) {
  verifyclass(w, "psp")
  x <- w
  validradius(r, "dilation")
  if(r == 0)
    return(w)

  if(is.empty(x))
    return(emptywindow(as.owin(w)))
  
  # bounding frame
  bb <- if(tight) boundingbox(x) else as.rectangle(x)
  newbox <- grow.rectangle(bb, r)
  
  # compute dilation
  if(!polygonal) {
    x <- rebound.psp(x, newbox)
    distant <- distmap(x, ...)
    dil <- levelset(distant, r, "<=")
    return(dil)
  } else if(spatstat.options("old.morpho.psp")) {
    # old code for polygonal case
    ends   <- x$ends
    angles <- angles.psp(x, directed=TRUE)
#    lengths <- lengths.psp(x)
    out <- NULL
    # dilate individual segments
    halfcircle <- seq(from=0, to=pi, length.out=128)[-c(1,128)]
    for(i in seq_len(x$n)) {
      seg <- ends[i,]
      co <- cos(angles[i])
      si <- sin(angles[i])
      # draw sausage around i-th segment
      xx <- c(seg$x0, seg$x1) + r * si
      yy <- c(seg$y0, seg$y1) - r * co
      rightcircle <- angles[i] - pi/2 + halfcircle
      xx <- c(xx, seg$x1 + r * cos(rightcircle))
      yy <- c(yy, seg$y1 + r * sin(rightcircle))
      xx <- c(xx, c(seg$x1, seg$x0) - r * si)
      yy <- c(yy, c(seg$y1, seg$y0) + r * co)
      leftcircle <- angles[i] + pi/2 + halfcircle
      xx <- c(xx, seg$x0 + r * cos(leftcircle))
      yy <- c(yy, seg$y0 + r * sin(leftcircle))
      sausage <- owin(newbox$xrange, newbox$yrange, poly=list(x=xx, y=yy), check=FALSE)
      # add to set
      out <- union.owin(out, sausage, ...)
    }
    return(out)
  } else {
    # new code using 'polyclip' package
    # convert to list of list(x,y)
    ends   <- as.matrix(x$ends)
    n <- nrow(ends)
    plines <- vector(mode="list", length=n)
    for(i in 1:n) plines[[i]] <- list(x=ends[i, c("x0","x1")],
                                      y=ends[i, c("y0","y1")])
    # call
    pnew <- polyclip::polylineoffset(plines, r,
                                     jointype="round", endtype="openround")
    # ensure correct polarity
    totarea <- sum(unlist(lapply(pnew, Area.xypolygon)))
    if(totarea < 0)
      pnew <- lapply(pnew, reverse.xypolygon)
    # convert to owin object
    out <- if(tight) owin(poly=pnew, check=FALSE) else
            owin(newbox$xrange, newbox$yrange, poly=pnew, check=FALSE)
    return(out)
  }
}

closing.psp <- function(w, r, ..., polygonal=TRUE) {
  if(missing(r))
    stop("r is required")
  validradius(r, "closing")
  wplus <- dilation.psp(w, r, ..., polygonal=polygonal, tight=FALSE)
  if(is.empty(wplus))
    return(emptywindow(as.owin(w)))
  wclose <- erosion.owin(wplus, r, strict=TRUE)
  wclose <- rebound.owin(wclose, as.rectangle(w))
  return(wclose)
}

erosion.psp <- function(w, r, ...) {
  idorempty(w, r, "erosion")
}

opening.psp <- function(w, r, ...) {
  idorempty(w, r,"opening")
}

  
# ............ methods for class 'ppp' ............................

dilation.ppp <- function(w, r, ..., polygonal=TRUE, tight=TRUE) {
  verifyclass(w, "ppp")
  validradius(r, "dilation")
  x <- w
  
  if(r == 0)
    return(x)

  if(is.empty(w))
    return(emptywindow(as.owin(w)))
  
  # bounding frame
  bb <- if(tight) boundingbox(x) else as.rectangle(x)
    newbox <- grow.rectangle(bb, r)

  # compute dilation
  if(!polygonal) {
    # compute pixel approximation
    x <- rebound.ppp(x, newbox)
    distant <- distmap(x, ...)
    dil <- levelset(distant, r, "<=")
    return(dil)
  } else {
    # compute polygonal approximation
    # generate discs
    out <- NULL
    for(i in seq_len(x$n)) {
      balli <- disc(r, c(x$x[i], x$y[i]))
      out <- union.owin(out, balli)
    }
    return(out)
  }
}

closing.ppp <- function(w, r, ..., polygonal=TRUE) {
  if(missing(r))
    stop("r is required")
  validradius(r, "closing")
  if(is.empty(w) || w$n <= 3)
    return(emptywindow(as.owin(w)))
  # remove `isolated' points
  ok <- (nndist(w) <= 2 * r)
  if(sum(ok) <= 3)
    return(emptywindow(as.owin(w)))
  w <- w[ok]
  # dilate
  wplus <- dilation.ppp(w, r, ..., polygonal=polygonal, tight=FALSE)
  wclose <- erosion.owin(wplus, r, strict=TRUE)
  wclose <- rebound.owin(wclose, as.rectangle(w))
  return(wclose)
}

erosion.ppp <- function(w, r, ...) {
  idorempty(w, r, "erosion")
}

opening.ppp <- function(w, r, ...) {
  idorempty(w, r,"opening")
}

# ............ utilities ............................

validradius <- local({

  validradius <- function(r, caller="morphological operator") {
  #  rname <- short.deparse(substitute(r))
    if(!is.numeric(r) || length(r) != 1)
      groan("radius r must be a single number", caller)
    if(r < 0)
      groan("radius r must be nonnegative", caller)
    return(TRUE)
  }

  groan <- function(whinge, caller) {
    stop(paste("for", paste(caller, ",", sep=""), whinge), call.=FALSE)
  }

  validradius
})
  
idorempty <- function(w, r, caller="morphological operator") {
  validradius(r, caller)
  if(r == 0)
    return(w)
  else
    return(emptywindow(w))
}
           
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/mpl.R"
#    mpl.R
#
#	$Revision: 5.187 $	$Date: 2014/12/17 09:28:02 $
#
#    mpl.engine()
#          Fit a point process model to a two-dimensional point pattern
#          by maximum pseudolikelihood
#
#    mpl.prepare()
#          set up data for glm procedure
#
# -------------------------------------------------------------------
#

"mpl" <- function(Q,
         trend = ~1,
	 interaction = NULL,
         data = NULL,
	 correction="border",
	 rbord = 0,
         use.gam=FALSE) {
   .Deprecated("ppm", package="spatstat")
   ppm(Q=Q, trend=trend, interaction=interaction,
       covariates=data, correction=correction, rbord=rbord,
       use.gam=use.gam, method="mpl")
}

mpl.engine <- 
  function(Q,
           trend = ~1,
           interaction = NULL,
           ...,
           covariates = NULL,
           subsetexpr = NULL,
           covfunargs = list(),
           correction="border",
           rbord = 0,
           use.gam=FALSE,
           gcontrol=list(),
           famille=NULL,
           forcefit=FALSE,
           nd = NULL,
           eps = eps,
           allcovar=FALSE,
           callstring="",
           precomputed=NULL,
           savecomputed=FALSE,
           preponly=FALSE,
           rename.intercept=TRUE,
           justQ = FALSE,
           weightfactor = NULL)
  {
    ## Extract precomputed data if available
    if(!is.null(precomputed$Q)) {
      Q <- precomputed$Q
      X <- precomputed$X
      P <- precomputed$U
    } else {
      ## Determine quadrature scheme from argument Q
      if(verifyclass(Q, "quad", fatal=FALSE)) {
        ## user-supplied quadrature scheme - validate it
        validate.quad(Q, fatal=TRUE, repair=FALSE, announce=TRUE)
        ## Extract data points
        X <- Q$data
      } else if(verifyclass(Q, "ppp", fatal = FALSE)) {
        ## point pattern - create default quadrature scheme
        X <- Q
        Q <- quadscheme(X, nd=nd, eps=eps, check=FALSE)
      } else 
      stop("First argument Q should be a point pattern or a quadrature scheme")
      ## Data and dummy points together
      P <- union.quad(Q)
    }
    ## secret exit  
    if(justQ) return(Q)
    ##  
    computed <- if(savecomputed) list(X=X, Q=Q, U=P) else NULL
    ##
    ## Validate main arguments
    if(!is.null(trend) && !inherits(trend, "formula"))
      stop(paste("Argument", sQuote("trend"), "must be a formula"))
    if(!is.null(interaction) && !inherits(interaction, "interact"))
      stop(paste("Argument", sQuote("interaction"), "has incorrect format"))
    ##
    check.1.real(rbord, "In ppm")
    explain.ifnot(rbord >= 0, "In ppm")
    ## rbord applies only to border correction
    if(correction != "border") rbord <- 0 
    ##
    ##
    ## Interpret the call
    if(is.null(trend)) {
      trend <- ~1
      environment(trend) <- parent.frame()
    }
    want.trend <- !identical.formulae(trend, ~1)
    want.inter <- !is.null(interaction) && !is.null(interaction$family)

    ## Stamp with spatstat version number
    spv <- package_version(versionstring.spatstat())
    the.version <- list(major=spv$major,
                        minor=spv$minor,
                        release=spv$patchlevel,
                        date="$Date: 2014/12/17 09:28:02 $")

    if(want.inter) {
      ## ensure we're using the latest version of the interaction object
      if(outdated.interact(interaction)) 
        interaction <- update(interaction)
    }

    ##  
  
    if(!want.trend && !want.inter &&
       !forcefit && !allcovar && is.null(subsetexpr)) {
      ## the model is the uniform Poisson process
      ## The MPLE (= MLE) can be evaluated directly
      npts <- npoints(X)
      W    <- as.owin(X)
      if(correction == "border" && rbord > 0) {
        npts <- sum(bdist.points(X) >= rbord)
        areaW <- eroded.areas(W, rbord)
      } else {
        npts <- npoints(X)
        areaW <- area(W)
      }
      volume <- areaW * markspace.integral(X)
      lambda <- npts/volume
      ## fitted canonical coefficient
      co <- log(lambda)
      ## asymptotic variance of canonical coefficient
      varcov <- matrix(1/npts, 1, 1)
      fisher <- matrix(npts,   1, 1)
      se <- sqrt(1/npts)
      ## give names
      tag <- if(rename.intercept) "log(lambda)" else "(Intercept)"
      names(co) <- tag
      dimnames(varcov) <- dimnames(fisher) <- list(tag, tag)
      ## maximised log likelihood
      maxlogpl <- if(npts == 0) 0 else npts * (log(lambda) - 1)
      ##
      rslt <- list(
                   method      = "mpl",
                   fitter      = "exact",
                   projected   = FALSE,
                   coef        = co,
                   trend       = trend,
                   interaction = NULL,
                   fitin       = fii(),
                   Q           = Q,
                   maxlogpl    = maxlogpl,
                   internal    = list(computed=computed, se=se),
                   covariates  = mpl.usable(covariates),
                                        ## covariates are still retained!
                   covfunargs  = covfunargs,
                   subsetexpr  = NULL,
                   correction  = correction,
                   rbord       = rbord,
                   terms       = terms(trend),
                   fisher      = fisher,
                   varcov      = varcov,
                   version     = the.version,
                   problems    = list())
      class(rslt) <- "ppm"
      return(rslt)
    }
    #################  P r e p a r e    D a t a   ######################

    prep <- mpl.prepare(Q, X, P, trend, interaction,
                        covariates, 
                        want.trend, want.inter, correction, rbord,
                        "quadrature points", callstring,
                        subsetexpr=subsetexpr,
                        allcovar=allcovar,
                        precomputed=precomputed, savecomputed=savecomputed,
                        covfunargs=covfunargs,
                        weightfactor=weightfactor,
                        ...)
    ## back door
    if(preponly) {
      ## exit now, returning prepared data frame and internal information
      prep$info <- list(want.trend=want.trend,
                        want.inter=want.inter,
                        correction=correction,
                        rbord=rbord,
                        interaction=interaction)
      return(prep)
    }
  
  
    fmla <- prep$fmla
    glmdata <- prep$glmdata
    problems <- prep$problems
    likelihood.is.zero <- prep$likelihood.is.zero
    is.identifiable <- prep$is.identifiable
    computed <- resolve.defaults(prep$computed, computed)
    IsOffset <- prep$IsOffset

    ## update covariates (if they were resolved from the environment)  
    if(!is.null(prep$covariates))
      covariates <- prep$covariates
  
    ################# F i t    i t   ####################################

    if(!is.identifiable) 
      stop(paste("in", callstring, ":", problems$unidentifiable$print),
           call.=FALSE)
  
    ## to avoid problem with package checker  
    .mpl.W <- glmdata$.mpl.W
    .mpl.SUBSET <- glmdata$.mpl.SUBSET

    ## determine algorithm control parameters
    if(is.null(gcontrol)) gcontrol <- list() else stopifnot(is.list(gcontrol))
    gc <- if(use.gam) "gam.control" else "glm.control"
    gcontrol <- do.call(gc, gcontrol)
  
    ## Fit the generalized linear/additive model.

    if(is.null(famille)) {
      ## the sanctioned technique, using `quasi' family
      if(want.trend && use.gam)
        FIT  <- gam(fmla, family=quasi(link=log, variance=mu), weights=.mpl.W,
                    data=glmdata, subset=.mpl.SUBSET,
                    control=gcontrol)
      else
        FIT  <- glm(fmla, family=quasi(link=log, variance=mu), weights=.mpl.W,
                    data=glmdata, subset=.mpl.SUBSET,
                    control=gcontrol, model=FALSE)
    } else {
      ## for experimentation only!
      if(is.function(famille))
        famille <- famille()
      stopifnot(inherits(famille, "family"))
      if(want.trend && use.gam)
        FIT  <- gam(fmla, family=famille, weights=.mpl.W,
                    data=glmdata, subset=.mpl.SUBSET,
                    control=gcontrol)
      else
        FIT  <- glm(fmla, family=famille, weights=.mpl.W,
                    data=glmdata, subset=.mpl.SUBSET,
                    control=gcontrol, model=FALSE)
    }
    environment(FIT$terms) <- sys.frame(sys.nframe())

  
    ################  I n t e r p r e t    f i t   #######################

    ## Fitted coefficients
    co <- FIT$coef

    ## glm covariates
    W <- glmdata$.mpl.W
    SUBSET <- glmdata$.mpl.SUBSET        
    Z <- is.data(Q)
    Vnames <- prep$Vnames
        
    ## attained value of max log pseudolikelihood
    maxlogpl <-
      if(likelihood.is.zero) { -Inf } else 
    -(deviance(FIT)/2 + sum(log(W[Z & SUBSET])) + sum(Z & SUBSET))

    ## fitted interaction object
    fitin <- if(want.inter) fii(interaction, co, Vnames, IsOffset) else fii()
    unitname(fitin) <- unitname(X)
    ######################################################################
    ## Clean up & return 

    rslt <-
      list(
           method       = "mpl",
           fitter       = if(use.gam) "gam" else "glm",
           projected    = FALSE,
           coef         = co,
           trend        = trend,
           interaction  = if(want.inter) interaction else NULL,
           fitin        = fitin,
           Q            = Q,
           maxlogpl     = maxlogpl, 
           internal     = list(glmfit=FIT, glmdata=glmdata, Vnames=Vnames,
                               IsOffset=IsOffset, fmla=fmla, computed=computed),
           covariates   = mpl.usable(covariates),
           covfunargs   = covfunargs,
           subsetexpr   = subsetexpr,
           correction   = correction,
           rbord        = rbord,
           terms        = terms(trend),
           version      = the.version,
           problems     = problems)
    class(rslt) <- "ppm"
    return(rslt)
  }  



##########################################################################
### /////////////////////////////////////////////////////////////////////
##########################################################################

mpl.prepare <- local({

  mpl.prepare <- function(Q, X, P, trend, interaction, covariates, 
                          want.trend, want.inter, correction, rbord,
                          Pname="quadrature points", callstring="",
                          ...,
                          subsetexpr=NULL,
                          covfunargs=list(),
                          allcovar=FALSE,
                          precomputed=NULL, savecomputed=FALSE,
                          vnamebase=c("Interaction", "Interact."),
                          vnameprefix=NULL,
                          warn.illegal=TRUE,
                          warn.unidentifiable=TRUE,
                          weightfactor=NULL,
                          skip.border=FALSE) {
    ## Q: quadrature scheme
    ## X = data.quad(Q)
    ## P = union.quad(Q)
  
    if(missing(want.trend))
      want.trend <- !is.null(trend) && !identical.formulae(trend, ~1)
    if(missing(want.inter))
      want.inter <- !is.null(interaction) && !is.null(interaction$family)

    want.subset <- !is.null(subsetexpr)
  
    computed <- list()
    problems <- list()
  
    names.precomputed <- names(precomputed)

    likelihood.is.zero <- FALSE
    is.identifiable <- TRUE
  
    if(!missing(vnamebase)) {
      if(length(vnamebase) == 1)
        vnamebase <- rep.int(vnamebase, 2)
      if(!is.character(vnamebase) || length(vnamebase) != 2)
        stop("Internal error: illegal format of vnamebase")
    }
    if(!is.null(vnameprefix)) {
      if(!is.character(vnameprefix) || length(vnameprefix) != 1)
        stop("Internal error: illegal format of vnameprefix")
    }
      
    ################ C o m p u t e     d a t a  ####################

    ## Extract covariate values
    updatecovariates <- FALSE
    covariates.df <- NULL
    if(allcovar || want.trend || want.subset) {
      if("covariates.df" %in% names.precomputed) {
        covariates.df <- precomputed$covariates.df
      } else {
        if(!is.data.frame(covariates)) {
          ## names of 'external' covariates to be found
          covnames <- variablesinformula(trend)
          if(want.subset)
            covnames <- union(covnames, all.vars(subsetexpr))
          if(allcovar)
            covnames <- union(covnames, names(covariates))
          covnames <- setdiff(covnames, c("x", "y", "marks"))
          ## resolve 'external' covariates
          tenv <- environment(trend)
          covariates <- getdataobjects(covnames, tenv, covariates, fatal=TRUE)
          updatecovariates <- any(attr(covariates, "external"))
        }
        ## extract values of covariates ('internal' and 'external')
        covariates.df <- mpl.get.covariates(covariates, P, Pname, covfunargs)
      }
      if(savecomputed)
        computed$covariates.df <- covariates.df
    } 

    ## Form the weights and the ``response variable''.

    if("dotmplbase" %in% names.precomputed) 
      .mpl <- precomputed$dotmplbase
    else {
      nQ <- n.quad(Q)
      wQ <- w.quad(Q)
      mQ <- marks.quad(Q)   ## is NULL for unmarked patterns
      zQ <- is.data(Q)
      yQ <- numeric(nQ)
      yQ[zQ] <- 1/wQ[zQ]
      zeroes <- attr(wQ, "zeroes")
      sQ <- if(is.null(zeroes)) rep.int(TRUE, nQ) else !zeroes
      ## tweak weights ONLY
      if(!is.null(weightfactor))
        wQ <- wQ * weightfactor
      ## pack up
      .mpl <- list(W      = wQ,
                   Z      = zQ,
                   Y      = yQ,
                   MARKS  = mQ, 
                   SUBSET = sQ)
    }

    if(savecomputed)
      computed$dotmplbase <- .mpl
  
    glmdata <- data.frame(.mpl.W = .mpl$W,
                          .mpl.Y = .mpl$Y)

    ## count data and dummy points in specified subset
    izdat <- .mpl$Z[.mpl$SUBSET]
    ndata <- sum(izdat)
#    ndummy <- sum(!izdat)
    
    ## Determine the domain of integration for the pseudolikelihood.
    if(correction == "border") {
      bdP <-
        if("bdP" %in% names.precomputed)
          precomputed$bdP
        else
          bdist.points(P)
      if(savecomputed)
        computed$bdP <- bdP
      .mpl$DOMAIN <- (bdP >= rbord)
    }

    skip.border <- skip.border && (correction == "border")
  
    ####################### T r e n d ##############################

    internal.names <- c(".mpl.W", ".mpl.Y", ".mpl.Z", ".mpl.SUBSET",
                        "SUBSET", ".mpl")

    reserved.names <- c("x", "y", "marks", internal.names)

    if(allcovar || want.trend || want.subset) {
      trendvariables <- variablesinformula(trend)
      ## Check for use of internal names in trend
      cc <- check.clashes(internal.names, trendvariables, "the model formula")
      if(cc != "") stop(cc)
      if(want.subset) {
        subsetvariables <- all.vars(subsetexpr)
        cc <- check.clashes(internal.names, trendvariables,
                            "the subset expression")
        if(cc != "") stop(cc)
        trendvariables <- union(trendvariables, subsetvariables)
      }
      ## Standard variables
      if(allcovar || "x" %in% trendvariables)
        glmdata <- data.frame(glmdata, x=P$x)
      if(allcovar || "y" %in% trendvariables)
        glmdata <- data.frame(glmdata, y=P$y)
      if(("marks" %in% trendvariables) || !is.null(.mpl$MARKS)) {
        if(is.null(.mpl$MARKS))
          stop("Model formula depends on marks, but data do not have marks",
               call.=FALSE)
        glmdata <- data.frame(glmdata, marks=.mpl$MARKS)
      }
      ##
      ## Check covariates
      if(!is.null(covariates.df)) {
        ## Check for duplication of reserved names
        cc <- check.clashes(reserved.names, names(covariates),
                            sQuote("covariates"))
        if(cc != "") stop(cc)
        ## Take only those covariates that are named in the trend formula
        if(!allcovar) 
          needed <- names(covariates.df) %in% trendvariables
        else
          needed <- rep.int(TRUE, ncol(covariates.df))
        if(any(needed)) {
          covariates.needed <- covariates.df[, needed, drop=FALSE]
          ##  Append to `glmdata'
          glmdata <- data.frame(glmdata,covariates.needed)
          ##  Ignore any quadrature points that have NA's in the covariates
          nbg <- is.na(covariates.needed)
          if(any(nbg)) {
            offending <- matcolany(nbg)
            covnames.na <- names(covariates.needed)[offending]
            quadpoints.na <- matrowany(nbg)
            n.na <- sum(quadpoints.na)
            n.tot <- length(quadpoints.na)
            errate <- n.na/n.tot
            pcerror <- round(signif(100 * errate, 2), 2)
            complaint <- paste("Values of the",
                               ngettext(length(covnames.na),
                                        "covariate", "covariates"),
                               paste(sQuote(covnames.na), collapse=", "),
                               "were NA or undefined at",
                               paste(pcerror, "%",
                                     " (", 
                                     n.na,
                                     " out of ",
                                     n.tot,
                                     ")",
                                     sep=""),
                               "of the", Pname)
            warning(paste(complaint,
                          ". Occurred while executing: ",
                          callstring, sep=""),
                    call. = FALSE)
            .mpl$SUBSET <-  .mpl$SUBSET & !quadpoints.na
            details <- list(covnames.na   = covnames.na,
                            quadpoints.na = quadpoints.na,
                            print         = complaint)
            problems <- append(problems,
                               list(na.covariates=details))
          }
        }
      }
    }

    ###################### I n t e r a c t i o n ####################

    Vnames <- NULL
    IsOffset <- NULL

    if(want.inter) {
      ## Form the matrix of "regression variables" V.
      ## The rows of V correspond to the rows of P (quadrature points)
      ## while the column(s) of V are the regression variables (log-potentials)

      E <- precomputed$E %orifnull% equalpairs.quad(Q)

      if(!skip.border) {
        ## usual case
        V <- evalInteraction(X, P, E, interaction, correction,
                             ...,
                             precomputed=precomputed,
                             savecomputed=savecomputed)
      } else {
        ## evaluate only in eroded domain
        if(all(c("Esub", "Usub", "Retain") %in% names.precomputed)) {
          ## use precomputed data
          Psub <- precomputed$Usub
          Esub <- precomputed$Esub
          Retain <- precomputed$Retain
        } else {
          Retain <- .mpl$DOMAIN
          Psub <- P[Retain]
          ## map serial numbers in 'P[Retain]' to serial numbers in 'Psub'
          Pmap <- cumsum(Retain)
          keepE <- Retain[ E[,2] ]
          ## adjust equal pairs matrix
          Esub <- E[ keepE, , drop=FALSE]
          Esub[,2] <- Pmap[Esub[,2]]
        }
        ## call evaluator on reduced data
        ## with 'W=NULL' (currently detected only by AreaInter)
        if(all(c("X", "Q", "U") %in% names.precomputed)) {
          subcomputed <- resolve.defaults(list(E=Esub, U=Psub, Q=Q[Retain]),
                                          precomputed)
        } else subcomputed <- NULL
        V <- evalInteraction(X, Psub, Esub, interaction, correction,
                             ...,
                             W=NULL,
                             precomputed=subcomputed,
                             savecomputed=savecomputed)
        if(savecomputed) {
          computed$Usub <- Psub
          computed$Esub <- Esub
          computed$Retain <- Retain
        }
      }
      
      if(!is.matrix(V))
        stop("interaction evaluator did not return a matrix")
      
      ## extract information about offsets
      IsOffset <- attr(V, "IsOffset")
      if(is.null(IsOffset)) IsOffset <- FALSE
      
      if(skip.border) {
        ## fill in the values in the border region with zeroes.
        Vnew <- matrix(0, nrow=npoints(P), ncol=ncol(V))
        colnames(Vnew) <- colnames(V)
        Vnew[Retain, ] <- V
        ## retain attributes
        attr(Vnew, "IsOffset") <- IsOffset
        attr(Vnew, "computed") <- attr(V, "computed")
        attr(Vnew, "POT") <- attr(V, "POT")
        V <- Vnew
      }
    
      ## extract intermediate computation results 
      if(savecomputed)
        computed <- resolve.defaults(attr(V, "computed"), computed)

      ## Augment data frame by appending the regression variables
      ## for interactions.
      ##
      ## First determine the names of the variables
      ##
      Vnames <- dimnames(V)[[2]]
      if(is.null(Vnames)) {
        ## No names were provided for the columns of V.
        ## Give them default names.
        ## In ppm the names will be "Interaction"
        ##   or "Interact.1", "Interact.2", ...
        ## In mppm an alternative tag will be specified by vnamebase.
        nc <- ncol(V)
        Vnames <- if(nc == 1) vnamebase[1] else paste0(vnamebase[2], 1:nc)
        dimnames(V) <- list(dimnames(V)[[1]], Vnames)
      } else if(!is.null(vnameprefix)) {
        ## Variable names were provided by the evaluator (e.g. MultiStrauss).
        ## Prefix the variable names by a string
        ## (typically required by mppm)
        Vnames <- paste(vnameprefix, Vnames, sep="")
        dimnames(V) <- list(dimnames(V)[[1]], Vnames)
      }
      
      ## Check the names are valid as column names in a dataframe
      okVnames <- make.names(Vnames, unique=TRUE)
      if(any(Vnames != okVnames)) {
        warning(paste("Names of interaction terms",
                      "contained illegal characters;",
                      "names have been repaired."))
        Vnames <- okVnames
      }
    
      ##   Check for name clashes between the interaction variables
      ##   and the formula
      cc <- check.clashes(Vnames, termsinformula(trend), "model formula")
      if(cc != "") stop(cc)
      ##   and with the variables in 'covariates'
      if(!is.null(covariates)) {
        cc <- check.clashes(Vnames, names(covariates), sQuote("covariates"))
        if(cc != "") stop(cc)
      }

      ## OK. append variables.
      glmdata <- data.frame(glmdata, V)   

      ## check IsOffset matches Vnames
      if(length(IsOffset) != length(Vnames)) {
        if(length(IsOffset) == 1)
          IsOffset <- rep.int(IsOffset, length(Vnames))
        else
          stop("Internal error: IsOffset has wrong length", call.=FALSE)
      }
  
      ## Keep only those quadrature points for which the
      ## conditional intensity is nonzero. 

      ##KEEP  <- apply(V != -Inf, 1, all)
      .mpl$KEEP  <- matrowall(V != -Inf)

      .mpl$SUBSET <- .mpl$SUBSET & .mpl$KEEP

      ## Check that there are at least some data and dummy points remaining
      datremain <- .mpl$Z[.mpl$SUBSET]
      somedat <- any(datremain)
      somedum <- !all(datremain)
      if(warn.unidentifiable && !(somedat && somedum)) {
        ## Model would be unidentifiable if it were fitted.
        ## Register problem
        is.identifiable <- FALSE
        if(ndata == 0) {
          complaint <- "model is unidentifiable: data pattern is empty"
        } else {
          offending <- !c(somedat, somedum)
          offending <- c("all data points", "all dummy points")[offending]
          offending <- paste(offending, collapse=" and ")
          complaint <- paste("model is unidentifiable:",
                             offending, "have zero conditional intensity")
        }
        details <- list(data=!somedat,
                        dummy=!somedum,
                        print=complaint)
        problems <- append(problems, list(unidentifiable=details))
      }

      ## check whether the model has zero likelihood:
      ## check whether ANY data points have zero conditional intensity
      if(any(.mpl$Z & !.mpl$KEEP)) {
        howmany <- sum(.mpl$Z & !.mpl$KEEP)
        complaint <- paste(howmany,
                           "data point(s) are illegal",
                           "(zero conditional intensity under the model)")
        details <- list(illegal=howmany,
                        print=complaint)
        problems <- append(problems, list(zerolikelihood=details))
        if(warn.illegal && is.identifiable)
          warning(paste(complaint,
                        ". Occurred while executing: ",
                        callstring, sep=""),
                  call. = FALSE)
        likelihood.is.zero <- TRUE
      }
    }
  
    ##################     S u b s e t   ###################

    if(correction == "border") 
      .mpl$SUBSET <- .mpl$SUBSET & .mpl$DOMAIN
  
    if(!is.null(subsetexpr)) {
      ## user-defined subset expression
      USER.SUBSET <- eval(subsetexpr, glmdata, environment(trend))
      .mpl$SUBSET <- .mpl$SUBSET & USER.SUBSET
    }
                        
    glmdata <- cbind(glmdata,
                     data.frame(.mpl.SUBSET=.mpl$SUBSET,
                                stringsAsFactors=FALSE))

    #################  F o r m u l a   ##################################

    if(!want.trend) trend <- ~1 
    trendpart <- paste(as.character(trend), collapse=" ")
    if(!want.inter)
      rhs <- trendpart
    else {
      VN <- Vnames
      ## enclose offset potentials in 'offset(.)'
      if(any(IsOffset))
        VN[IsOffset] <- paste("offset(", VN[IsOffset], ")", sep="")
      rhs <- paste(c(trendpart, VN), collapse= "+")
    }
    fmla <- paste(".mpl.Y ", rhs)
    fmla <- as.formula(fmla)

    ##  character string of trend formula (without Vnames)
    trendfmla <- paste(".mpl.Y ", trendpart)

    ####
    result <- list(fmla=fmla, trendfmla=trendfmla,
                   covariates=if(updatecovariates) covariates else NULL,
                   glmdata=glmdata, Vnames=Vnames, IsOffset=IsOffset,
                   subsetexpr=subsetexpr,
                   problems=problems,
                   likelihood.is.zero=likelihood.is.zero,
                   is.identifiable=is.identifiable,
                   computed=computed)
    return(result)
  }

  check.clashes <- function(forbidden, offered, where) {
    name.match <- outer(forbidden, offered, "==")
    if(any(name.match)) {
      is.matched <- apply(name.match, 2, any)
      matched.names <- (offered)[is.matched]
      if(sum(is.matched) == 1) {
        return(paste("The variable",sQuote(matched.names),
                   "in", where, "is a reserved name"))
      } else {
        return(paste("The variables",
                   paste(sQuote(matched.names), collapse=", "),
                   "in", where, "are reserved names"))
      }
    }
    return("")
  }

  mpl.prepare
})



####################################################################
####################################################################

mpl.usable <- function(x) {
  ## silently remove covariates that don't have recognised format
  if(length(x) == 0 || is.data.frame(x)) return(x)
  isim   <- unlist(lapply(x, is.im))
  isfun  <- unlist(lapply(x, is.function))
  iswin  <- unlist(lapply(x, is.owin))
  istess <- unlist(lapply(x, is.tess))
  isnum  <- unlist(lapply(x, is.numeric)) & (unlist(lapply(x, length)) == 1)
  recognised <- isim | isfun | iswin | istess | isnum
  if(!all(recognised)) 
    x <- x[recognised]
  return(x)
}

mpl.get.covariates <- local({

  mpl.get.covariates <- function(covariates, locations, type="locations",
                                 covfunargs=list(),
                                 need.deriv=FALSE) {
    covargname <- sQuote(short.deparse(substitute(covariates)))
    locargname <- sQuote(short.deparse(substitute(locations)))
    if(is.null(covfunargs)) covfunargs <- list()
    ##
    x <- locations$x
    y <- locations$y
    if(is.null(x) || is.null(y)) {
      xy <- xy.coords(locations)
      x <- xy$x
      y <- xy$y
    }
    if(is.null(x) || is.null(y))
      stop(paste("Can't interpret", locargname, "as x,y coordinates"))
    n <- length(x)
    if(is.data.frame(covariates)) {
      if(nrow(covariates) != n)
        stop(paste("Number of rows in", covargname, 
                   "does not equal the number of", type))
      return(covariates)
    } else if(is.list(covariates)) {
      if(length(covariates) == 0)
        return(as.data.frame(matrix(, n, 0)))
      isim   <- unlist(lapply(covariates, is.im))
      isfun  <- unlist(lapply(covariates, is.function))
      iswin  <- unlist(lapply(covariates, is.owin))
      istess <- unlist(lapply(covariates, is.tess))
      isnum  <- unlist(lapply(covariates, is.number))
      if(!all(isim | isfun | isnum | iswin | istess))
        stop(paste("Each entry in the list", covargname, 
                   "should be an image, a function,",
                   "a window, a tessellation or a single number"))
      if(sum(nzchar(names(covariates))) < length(covariates))
        stop(paste("Some entries in the list",
                   covargname, "are un-named"))
      ## look up values of each covariate at the quadrature points
      values <- covariates
      values[isim] <- lapply(covariates[isim], lookup.im, x=x, y=y,
                             naok=TRUE, strict=FALSE)
      values[isfun] <- vf <- lapply(covariates[isfun], evalfxy, x=x, y=y,
                                    extra=covfunargs)
      values[isnum] <- lapply(covariates[isnum], rep, length(x))
      values[iswin] <- lapply(covariates[iswin], insidexy, x=x, y=y)
      values[istess] <- lapply(covariates[istess], tileindex, x=x, y=y)
      result <- as.data.frame(values)
      if(need.deriv && any(isfun)) {
        ## check for gradient/hessian attributes of function values
        grad <- lapply(vf, attr, which="gradient")
        hess <- lapply(vf, attr, which="hessian")
        grad <- grad[!unlist(lapply(grad, is.null))]
        hess <- hess[!unlist(lapply(hess, is.null))]
        if(length(grad) > 0 || length(hess) > 0)
          attr(result, "derivatives") <- list(gradient=grad, hessian=hess)
      }
      return(result)
    } 
    stop(paste(covargname, "must be either a data frame or a list"))
  }

  ## functions for 'apply'
  evalfxy <- function(f, x, y, extra) {
    if(length(extra) == 0)
      return(f(x,y))
    ## extra arguments must be matched explicitly by name
    ok <- names(extra) %in% names(formals(f))
    z <- do.call(f, append(list(x,y), extra[ok]))
    return(z)
  }

  insidexy <- function(w, x, y) { inside.owin(x, y, w) }

  is.number <- function(x) { is.numeric(x) && (length(x) == 1) }

  mpl.get.covariates
})

bt.frame <- function(Q, trend=~1, interaction=NULL,
                      ...,
                      covariates=NULL,
                      correction="border", rbord=0,
                      use.gam=FALSE, allcovar=FALSE) {
  prep <- mpl.engine(Q=Q, trend=trend, interaction=interaction,
                     ..., covariates=covariates,
                     correction=correction, rbord=rbord,
                     use.gam=use.gam, allcovar=allcovar,
                     preponly=TRUE, forcefit=TRUE)
  class(prep) <- c("bt.frame", class(prep))
  return(prep)
}


print.bt.frame <- function(x, ...) {
  cat("Model frame for Berman-Turner device\n")
  df <- x$glmdata
  cat(paste("$glmdata: Data frame with", nrow(df), "rows and",
            ncol(df), "columns\n"))
  cat("          Column names:\t")
  cat(paste(paste(names(df),collapse="\t"), "\n"))
  cat("Complete model formula ($fmla):\t")
  print(x$fmla)
  info <- x$info
  if(info$want.trend) {
    cat("Trend:\tyes\nTrend formula string ($trendfmla):\t")
    cat(paste(x$trendfmla, "\n"))
  } else cat("Trend:\tno\n")
  cat("Interaction ($info$interaction):\t")
  inte <- info$interaction
  if(is.null(inte))
    inte <- Poisson()
  print(inte, family=FALSE, brief=TRUE)
  if(!is.poisson.interact(inte)) {
    cat("Internal names of interaction variables ($Vnames):\t")
    cat(paste(x$Vnames, collapse="\t"))
    cat("\n")
  }
  edge <- info$correction
  cat(paste("Edge correction ($info$correction):\t", sQuote(edge), "\n"))
  if(edge == "border") 
    cat(paste("\tBorder width ($info$rbord):\t", info$rbord, "\n"))
  if(length(x$problems) > 0) {
    cat("Problems:\n")
    print(x$problems)
  }
  if(length(x$computed) > 0)
    cat(paste("Frame contains saved computations for",
              commasep(dQuote(names(x$computed)))))
  return(invisible(NULL))
}
  
partialModelMatrix <- function(X, D, model, callstring="", ...) {
  ## X = 'data'
  ## D = 'dummy'
  Q <- quad(X,D)
  P <- union.quad(Q)
  trend <- model$trend
  inter <- model$interaction
  covar <- model$covariates
  prep  <- mpl.prepare(Q, X, P, trend, inter, covar,
                       correction=model$correction,
                       rbord=model$rbord,
                       Pname="data points", callstring=callstring,
                       warn.unidentifiable=FALSE,
                       ...)
  fmla    <- prep$fmla
  glmdata <- prep$glmdata
  mof <- model.frame(fmla, glmdata)
  mom <- model.matrix(fmla, mof)

  if(!identical(all.equal(colnames(mom), names(coef(model))), TRUE))
    warning(paste("Internal error: mismatch between",
                  "column names of model matrix",
                  "and names of coefficient vector in fitted model"))

  attr(mom, "mplsubset") <- glmdata$.mpl.SUBSET
  return(mom)
}
  
oversize.quad <- function(Q, ..., nU, nX) {
  ## Determine whether the quadrature scheme is
  ## too large to handle in one piece (in mpl)
  ## for a generic interaction
  ##    nU = number of quadrature points
  ##    nX = number of data points
  if(missing(nU))
    nU <- n.quad(Q)
  if(missing(nX))
    nX <- npoints(Q$data)
  nmat <- as.double(nU) * nX
  nMAX <- spatstat.options("maxmatrix")
  needsplit <- (nmat > nMAX)
  return(needsplit)
}

## function that should be called to evaluate interaction terms
## between quadrature points and data points

evalInteraction <- function(X, P, E = equalpairs(P, X), 
                            interaction, correction,
                            ...,
                            precomputed=NULL,
                            savecomputed=FALSE) {

  ## evaluate the interaction potential
  ## (does not assign/touch the variable names)

  verifyclass(interaction, "interact")

  ## handle Poisson case
  if(is.poisson(interaction)) {
    out <- matrix(, nrow=npoints(P), ncol=0)
    attr(out, "IsOffset") <- logical(0)
    return(out)
  }
  
  ## determine whether to use fast evaluation in C
  fastok    <- (spatstat.options("fasteval") %in% c("on", "test"))
  if(fastok) {
    cando   <- interaction$can.do.fast
    par     <- interaction$par
    dofast  <- !is.null(cando) && cando(X, correction, par)
  } else dofast <- FALSE

  ## determine whether to split quadscheme into blocks
  if(dofast) {
    dosplit <- FALSE
  } else {
    ## decide whether the quadrature scheme is too large to handle in one piece
    needsplit <- oversize.quad(nU=npoints(P), nX=npoints(X))

    ## not implemented when savecomputed=TRUE
    dosplit   <- needsplit && !savecomputed
    if(needsplit && savecomputed)
      warning(paste("Oversize quadscheme cannot be split into blocks",
                    "because savecomputed=TRUE;",
                    "memory allocation error may occur"))
  }
  
  if(!dosplit) {
    ## normal case
    V <- evalInterEngine(X=X, P=P, E=E,
                         interaction=interaction,
                         correction=correction,
                         ...,
                         precomputed=precomputed,
                         savecomputed=savecomputed)
  } else {
    ## Too many quadrature points: split into blocks
    nX <- npoints(X)
    nP <- npoints(P)
    ## Determine which evaluation points are data points
    Pdata <- E[,2]
    ## hence which are dummy points
    Pall <- seq_len(nP)
    Pdummy <- if(length(Pdata) > 0) Pall[-Pdata] else Pall
    nD <- length(Pdummy)
    ## size of full matrix
#    nmat <- (nD + nX) * nX
    nMAX <- spatstat.options("maxmatrix")
    ## Calculate number of dummy points in largest permissible X * (X+D) matrix 
    nperblock <- max(1, floor(nMAX/nX - nX))
    ## determine number of such blocks 
    nblocks <- ceiling(nD/nperblock)
    nfull <- nblocks - 1
    ## announce
    if(nblocks > 1) 
      message(paste("Large quadrature scheme",
                    "split into blocks to avoid memory size limits;",
                    nD, "dummy points",
                    "split into", nblocks, "blocks,",
                    "the first",
                    if(nfull > 1) paste(nfull, "blocks") else "block",
                    "containing",
                    nperblock, "dummy", ngettext(nperblock, "point", "points"),
                    "and the last block containing",
                    nD - nperblock * nfull, "dummy points"))
    ##
    ##
    seqX <- seq_len(nX)
    EX <- cbind(seqX, seqX)
    ##
    for(iblock in 1:nblocks) {
      first <- min(nD, (iblock - 1) * nperblock + 1)
      last  <- min(nD, iblock * nperblock)
      ## extract dummy points  
      Di <- P[Pdummy[first:last]]
      Pi <- superimpose(X, Di, check=FALSE, W=X$window)
      ## evaluate potential
      Vi <- evalInterEngine(X=X, P=Pi, E=EX, 
                            interaction=interaction,
                            correction=correction,
                            ...,
                            savecomputed=FALSE)
      if(iblock == 1) {
        V <- Vi
      } else {
        ## tack on the glm variables for the extra DUMMY points only
        V <- rbind(V, Vi[-seqX, , drop=FALSE])
      }
    }
    ## The first 'nX' rows of V contain values for X.
    ## The remaining rows of V contain values for dummy points.
    if(length(Pdata) == 0) {
      ## simply discard rows corresponding to data
      V <- V[-seqX, , drop=FALSE]
    } else {
      ## replace data in correct position
      ii <- integer(nP)
      ii[Pdata] <- seqX
      ii[Pdummy] <- (nX+1):nrow(V)
      V <- V[ii, ]
    }
  } 
  return(V)
}

## workhorse function that actually calls relevant code to evaluate interaction

evalInterEngine <- function(X, P, E, 
                            interaction, correction,
                            ...,
                            Reach = NULL,
                            precomputed=NULL,
                            savecomputed=FALSE) {

  ## fast evaluator (C code) may exist
  fasteval <- interaction$fasteval
  cando    <- interaction$can.do.fast
  par      <- interaction$par
  feopt    <- spatstat.options("fasteval")
  dofast   <- !is.null(fasteval) &&
              (is.null(cando) || cando(X, correction,par)) &&
              (feopt %in% c("on", "test"))
    
  V <- NULL
  if(dofast) {
    if(feopt == "test")
      message("Calling fasteval")
    V <- fasteval(X, P, E,
                  interaction$pot, interaction$par, correction, ...)
  }
  if(is.null(V)) {
    ## use generic evaluator for family
    evaluate <- interaction$family$eval
    if(is.null(Reach)) Reach <- reach(interaction)
    if("precomputed" %in% names(formals(evaluate))) {
      ## Use precomputed data
      ## version 1.9-3 onward (pairwise and pairsat families)
      V <- evaluate(X, P, E,
                    interaction$pot,
                    interaction$par,
                    correction, ...,
                    Reach=Reach, 
                    precomputed=precomputed,
                    savecomputed=savecomputed)
    } else {
      ## Cannot use precomputed data
      ## Object created by earlier version of ppm
      ## or not pairwise/pairsat interaction
      V <- evaluate(X, P, E,
                    interaction$pot,
                    interaction$par,
                    correction, ..., Reach=Reach)
    }
  }

  return(V)
}

deltasuffstat <- local({
  
  deltasuffstat <- function(model, ...,
                            restrict=TRUE, dataonly=TRUE, force=FALSE) {
    stopifnot(is.ppm(model))
    if(dataonly) {
      X <- data.ppm(model)
      nX <- npoints(X)
    } else {
      X <- quad.ppm(model)
      nX <- n.quad(X)
    }
    ncoef <- length(coef(model))
    inte <- as.interact(model)
    zeroes <- array(0, dim=c(nX, nX, ncoef)) 
    if(is.poisson(inte))
      return(zeroes)
    
    ## Get names of interaction terms in model (including offsets)
    f <- fitin(model)
    Inames <- f$Vnames
    IsOffset <- f$IsOffset
    ## Offset terms do not contribute to sufficient statistic
    if(all(IsOffset)) 
      return(zeroes)
    
    ## Nontrivial interaction terms must be computed.
    ## Look for member function $delta2 in the interaction
    v <- NULL
    if(!is.null(delta2 <- inte$delta2) && is.function(delta2)) {
      v <- delta2(X, inte, model$correction)
    }
    ## Look for generic $delta2 function for the family
    if(is.null(v) &&
       !is.null(delta2 <- inte$family$delta2) &&
       is.function(delta2))
      v <- delta2(X, inte, model$correction)
    ## no luck?
    if(is.null(v)) {
      if(!force)
        return(NULL)
      ## use brute force algorithm
      v <- if(dataonly) deltasufX(model) else deltasufQ(model)
    }
    ## make it a 3D array
    if(length(dim(v)) == 2)
      v <- array(v, dim=c(dim(v), 1))
  
    if(restrict) {
      ## kill contributions from points outside the domain of pseudolikelihood
      ## (e.g. points in the border region)
      use <- if(dataonly) getppmdatasubset(model) else getglmsubset(model)
      if(any(kill <- !use)) {
        kill <- array(outer(kill, kill, "&"), dim=dim(v))
        v[kill] <- 0
      }
    }

    ## Output array: planes must correspond to model coefficients
    result <- zeroes
    ## Planes of 'v' correspond to interaction terms (including offsets)
    if(length(Inames) != dim(v)[3])
      stop(paste("Internal error: deltasuffstat:",
                 "number of planes of v =", dim(v)[3],
                 "!= number of interaction terms =", length(Inames)),
           call.=FALSE)
    ## Offset terms do not contribute to sufficient statistic
    if(any(IsOffset)) {
      v <- v[ , , !IsOffset, drop=FALSE]
      Inames <- Inames[!IsOffset]
    }
    ## Map planes of 'v' into coefficients
    Imap <- match(Inames, names(coef(model)))
    if(any(is.na(Imap)))
      stop(paste("Internal error: deltasuffstat:",
                 "cannot match interaction coefficients"))
    if(length(Imap) > 0) {
      ## insert 'v' into array
      result[ , , Imap] <- v
    }
    return(result)
  }

  ## compute deltasuffstat using partialModelMatrix

  deltasufX <- function(model) {
    stopifnot(is.ppm(model))
    X <- data.ppm(model)
  
    nX <- npoints(X)
    p <- length(coef(model))

    isdata <- is.data(quad.ppm(model))
    m <- model.matrix(model)[isdata, ]
    ok <- getppmdatasubset(model)

    ## canonical statistic before and after deleting X[j]
    ## mbefore[ , i, j] = h(X[i] | X)
    ## mafter[ , i, j] = h(X[i] | X[-j])
    mafter <- mbefore <- array(t(m), dim=c(p, nX, nX))
  
    ## identify close pairs
    R <- reach(model)
    if(is.finite(R)) {
      cl <- closepairs(X, R, what="indices")
      I <- cl$i
      J <- cl$j
      cl2 <- closepairs(X, 2*R, what="indices")
      I2 <- cl2$i
      J2 <- cl2$j
    } else {
      ## either infinite reach, or something wrong
      IJ <- expand.grid(I=1:nX, J=1:nX)
      IJ <- subset(IJ, I != J)
      I2 <- I <- IJ$I
      J2 <- J <- IJ$J
    }
    ## filter:  I and J must both belong to the nominated subset 
    okIJ <- ok[I] & ok[J]
    I <- I[okIJ]
    J <- J[okIJ]
    ##
    if(length(I) > 0 && length(J) > 0) {
      ## .............. loop over pairs ........................
      ## The following ensures that 'empty' and 'X' have compatible marks 
      empty <- X[integer(0)]
      ## Run through pairs
      for(i in unique(I)) {
        ## all points within 2R
        J2i <- unique(J2[I2==i])
        ## all points within R
        Ji  <- unique(J[I==i])
        nJi <- length(Ji)
        if(nJi > 0) {
          Xi <- X[i]
          ## neighbours of X[i]
          XJi <- X[Ji]
          ## replace X[-i] by X[-i] \cap b(0, 2R)
          X.i <- X[J2i]
          nX.i <- length(J2i)
          ## index of XJi in X.i
          J.i <- match(Ji, J2i)
          if(any(is.na(J.i)))
            stop("Internal error: Ji not a subset of J2i")
          ## equalpairs matrix
          E.i <- cbind(J.i, seq_len(nJi))
          ## values of sufficient statistic 
          ##    h(X[j] | X[-i]) = h(X[j] | X[-c(i,j)]
          ## for all j
          pmj <- partialModelMatrix(X.i, empty, model)[J.i, , drop=FALSE]
          ## sufficient statistic in reverse order
          ##    h(X[i] | X[-j]) = h(X[i] | X[-c(i,j)]
          ## for all j
          pmi <- matrix(, nJi, p)
          for(k in 1:nJi) {
            j <- Ji[k]
            ## X.ij <- X[-c(i,j)]
            X.ij <- X.i[-J.i[k]]
            pmi[k, ] <- partialModelMatrix(X.ij, Xi, model)[nX.i, ]
          }
          ##
          mafter[ , Ji, i] <- t(pmj)
          mafter[ , i, Ji] <- t(pmi)
        }
      }
    }
        
    ##  delta[ ,i,j] = h(X[i] | X) - h(X[i] | X[-j])
    delta <- mbefore - mafter
    ## delta[i, j, ] = h(X[i] | X) - h(X[i] | X[-j])
    delta <- aperm(delta, c(2,3,1))
    return(delta)
  }

  deltasufQ <- function(model) {
    stopifnot(is.ppm(model))

    Q <- quad.ppm(model)
    X <- data.ppm(model)
    U <- union.quad(Q)
    nU <- npoints(U)
    nX <- npoints(X)
    isdata <- is.data(Q)
    isdummy <- !isdata
  
    p <- length(coef(model))
    
    m <- model.matrix(model)[isdata, ]
    ok <- getglmsubset(model)

    ## canonical statistic before and after adding/deleting U[j]
    mafter <- mbefore <- array(t(m), dim=c(p, nU, nU))
    delta <- array(0, dim=dim(mafter))
    ##   mbefore[ , i, j] = h(U[i] | X)
    ## For data points X[j]
    ##   mafter[ , i, j] = h(U[i] | X[-j])
    ##   delta[ , i, j] = h(U[i] | X) - h(U[i] | X[-j])
    ## For dummy points X[j]
    ##   mafter[ , i, j] = h(U[i] | X \cup U[j])
    ##   delta[ , i, j] = h(U[i] | X \cup U[j]) - h(U[i] | X)

    changesign <- ifelseAB(isdata, -1, 1)
  
    ## identify close pairs of quadrature points
    R <- reach(model)
    if(is.finite(R)) {
      cl <- closepairs(U, R, what="indices")
      I <- cl$i
      J <- cl$j
      cl2 <- closepairs(U, 2*R, what="indices")
      I2 <- cl2$i
      J2 <- cl2$j
    } else {
      ## either infinite reach, or something wrong
      IJ <- expand.grid(I=1:nU, J=1:nX)
      IJ <- IJ[ with(IJ, I != J), ]
      I2 <- I <- IJ$I
      J2 <- J <- IJ$J
    }

    ## filter:  I and J must both belong to the nominated subset 
    okIJ <- ok[I] & ok[J]
    I <- I[okIJ]
    J <- J[okIJ]
    ##
    if(length(I) > 0 && length(J) > 0) {
      ## .............. loop over pairs of quadrature points ...............
      ## Run through pairs
      uI <- unique(I)
      zI <- isdata[uI]
      uIdata <- uI[zI]
      uIdummy <- uI[!zI]
      ## Run through pairs i, j where 'i' is a data point
      for(i in uIdata) {
        ## all DATA points within 2R of X[i]
        ## This represents X[-i] 
        J2i <- unique(J2[I2==i])
        J2i <- J2i[isdata[J2i]]
        ## all QUADRATURE points within R of X[i]
        Ji  <- unique(J[I==i])
        nJi <- length(Ji)
        if(nJi > 0) {
          isd <- isdata[Ji]
          ## data points which are neighbours of X[i]
          XJi <- X[Ji[isd]]
          ## dummy points which are neighbours of X[i]
          DJi <- U[Ji[!isd]]
          ## replace X[-i] by X[-i] \cap b(0, 2R)
          X.i <- X[J2i]
          nX.i <- length(J2i)
          ## index of XJi in X.i 
          J.i <- match(Ji[isd], J2i)
          if(any(is.na(J.i)))
            stop("Internal error: Ji[isd] not a subset of J2i")
          ## index of DJi in superimpose(X.i, DJi)
          JDi <- nX.i + seq_len(sum(!isd))
          ## values of sufficient statistic 
          ##    h(X[j] | X[-i]) = h(X[j] | X[-c(i,j)]
          ## for all j
          pmj <- partialModelMatrix(X.i, DJi, model)[c(J.i, JDi), , drop=FALSE]
          ##
          mafter[ , Ji, i] <- t(pmj)
        }
      }
      ## Run through pairs i, j where 'i' is a dummy point
      for(i in uIdummy) {
        ## all DATA points within 2R of U[i]
        J2i <- unique(J2[I2==i])
        J2i <- J2i[isdata[J2i]]
        ## all QUADRATURE points within R of U[i]
        Ji  <- unique(J[I==i])
        nJi <- length(Ji)
        if(nJi > 0) {
          isd <- isdata[Ji]
          JiData <- Ji[isd]
          JiDummy <- Ji[!isd]
          ## data points which are neighbours of U[i]
          XJi <- X[JiData]
          ## dummy points which are neighbours of U[i]
          DJi <- U[JiDummy]
          ## replace X \cup U[i] by (X \cap b(0, 2R)) \cup U[i]
          J2Ui <- c(J2i, i)
          XUi <- U[J2Ui]
          nXUi <- length(J2Ui)
          ## index of XJi in X.i 
          J.i <- match(JiData, J2Ui)
          if(any(is.na(J.i)))
            stop("Internal error: Ji[isd] not a subset of J2i")
          ## index of DJi in superimpose(X.i, DJi)
          JDi <- nXUi + seq_len(length(JiDummy))
          ## values of sufficient statistic 
          ##    h(X[j] | X \cup U[i]) 
          ## for all j
          pmj <- partialModelMatrix(XUi, DJi, model)[c(J.i, JDi), , drop=FALSE]
          ##
          mafter[ , c(JiData, JiDummy), i] <- t(pmj)
        }
      }
    }
        
    ##  delta[ ,i,j] = h(X[i] | X) - h(X[i] | X[-j])
    delta[ , , isdata] <- mbefore[, , isdata] - mafter[ , , isdata]
    ##  delta[ ,i,j] = h(X[i] | X \cup U[j]) - h(X[i] | X)
    delta[ , , isdummy] <- mafter[, , isdummy] - mbefore[ , , isdummy]
    ## rearrange: new delta[i,j,] = old delta[, i, j]
    delta <- aperm(delta, c(2,3,1))
    return(delta)
  }

  deltasuffstat
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/mppm.R"
#
# mppm.R
#
#  $Revision: 1.63 $   $Date: 2014/11/10 10:53:54 $
#

mppm <- function(formula, data, interaction=Poisson(), ...,
                             iformula=NULL,
                             use.gam=FALSE)
{
  # remember call
  cl <- match.call()
  callstring <- paste(short.deparse(sys.call()), collapse="")

  # Validate arguments
  if(!inherits(formula, "formula"))
    stop(paste("Argument", dQuote("formula"), "should be a formula"))
  stopifnot(is.hyperframe(data))
  data.sumry <- summary(data, brief=TRUE)
  npat <- data.sumry$ncases
  if(npat == 0)
    stop(paste("Hyperframe", sQuote("data"), "has zero rows"))
  if(!is.null(iformula) && !inherits(iformula, "formula"))
    stop(paste("Argument", sQuote("iformula"), "should be a formula or NULL"))
  if(! (is.interact(interaction) || is.hyperframe(interaction)))
    stop(paste("The argument", sQuote("interaction"),
               "should be a point process interaction object (class",
               dQuote("interact"), 
               "), or a hyperframe containing such objects", sep=""))


  backdoor <- list(...)$backdoor
  if(is.null(backdoor) || !is.logical(backdoor))
    backdoor <- FALSE

  ############## HANDLE FORMULAS ############################
  
  checkvars <- function(f, b, extra=NULL, bname=short.deparse(substitute(b))){
    fname <- short.deparse(substitute(f))
    fvars <- variablesinformula(f)
    bvars <- if(is.character(b)) b else names(b)
    bvars <- c(bvars, extra)
    nbg <- !(fvars %in% bvars)
    if(any(nbg)) {
      nn <- sum(nbg)
      stop(paste(ngettext(nn, "Variable", "Variables"),
                 commasep(dQuote(fvars[nbg])),
                 "in", fname,
                 ngettext(nn, "is not one of the", "are not"),
                 "names in", bname))
    }
    return(NULL)
  }
  
  #------  Trend Formula ------------------
  
  # check all variables in trend formula are recognised
  checkvars(formula, data.sumry$col.names, extra=c("x","y","id"), bname="data")
  # check formula has LHS and RHS. Extract them
  if(length(formula) < 3)
    stop(paste("Argument", sQuote("formula"),
               "must have a left hand side"))
  Yname <- formula[[2]]
  trend <- formula[c(1,3)]
  if(!is.name(Yname))
    stop("Left hand side of formula should be a single name")
  Yname <- paste(Yname)
  if(!inherits(trend, "formula"))
    stop("Internal error: failed to extract RHS of formula")
  allvars <- variablesinformula(trend)
  
  # --- Interaction formula -----
  
  # names of interactions as they may appear in formulae
  itags <- 
      if(is.hyperframe(interaction)) names(interaction) else "Interaction"
  ninteract <- length(itags)
  # ensure `iformula' is a formula without a LHS
  # and determine which columns of `interaction' are actually used
  if(is.null(iformula)) {
    if(ninteract > 1)
      stop(paste("interaction hyperframe has more than 1 column;",
                 "you must specify the choice of interaction",
                 "using argument",  sQuote("iformula")))
    iused <- TRUE
    iformula <-  as.formula(paste("~", itags))
  } else {
    if(length(iformula) > 2)
      stop(paste("The interaction formula",
                 sQuote("iformula"),
                 "should not have a left hand side"))
    # valid variables in `iformula' are interactions and data frame columns
    permitted <- paste(sQuote("interaction"),
                       "or permitted name in", sQuote("data"))
    checkvars(iformula, itags, extra=c(data.sumry$dfnames, "id"),
              bname=permitted)
    ivars <- variablesinformula(iformula)
    # check which columns of `interaction' are actually used
    iused <- itags %in% ivars
    if(sum(iused) == 0)
       stop("No interaction specified in iformula")
    # OK
    allvars <- c(allvars, ivars)
  } 

  
  # ---- variables required (on RHS of one of the above formulae) -----
  allvars <- unique(allvars)

  
  ########  EXTRACT DATA  #####################################
  
  # Insert extra variable 'id'
  data <- cbind.hyperframe(data, id=factor(1:npat))
  data.sumry <- summary(data, brief=TRUE)
  allvars <- unique(c(allvars, "id"))

  # Extract the list of responses (point pattern/quadscheme)
  Y <- data[, Yname, drop=TRUE]
  if(npat == 1) Y <- list(Y)
  Yclass <- data.sumry$classes[Yname]
  if(Yclass == "ppp") {
    # convert to quadrature schemes, for efficiency's sake
    Y <- lapply(Y, quadscheme)
  } else if(Yclass != "quad")
    stop(paste("Column", dQuote(Yname), "of data",
               "does not consist of point patterns (class ppp)",
               "nor of quadrature schemes (class quad)"))

  # Extract sub-hyperframe of data named in formulae
  datanames <- names(data)
  used.cov.names <- allvars[allvars %in% datanames]
  has.covar <- (length(used.cov.names) > 0) 
  if(has.covar) {
    dfvar <- used.cov.names %in% data.sumry$dfnames
    imvar <- data.sumry$types[used.cov.names] == "im"
    if(any(nbg <- !(dfvar | imvar)))
      stop(paste("Inappropriate format for",
                 ngettext(sum(nbg), "covariate", "covariates"),
                 paste(sQuote(used.cov.names[nbg]), collapse=", "),
                 ": should contain image objects or vector/factor"))
    covariates.hf <- data[, used.cov.names, drop=FALSE]
    has.design <- any(dfvar)
    dfvarnames <- used.cov.names[dfvar]
    datadf <-
      if(has.design)
        as.data.frame(covariates.hf, discard=TRUE, warn=FALSE)
      else NULL
    if(has.design) {
      # check for NA's in design covariates
      if(any(nbg <- apply(is.na(datadf), 2, any)))
        stop(paste("There are NA's in the",
                   ngettext(sum(nbg), "covariate", "covariates"),
                   commasep(dQuote(names(datadf)[nbg]))))
    }
  } else {
    has.design <- FALSE
    datadf     <- NULL
  }
  
  ############### INTERACTION ###################################
  # ensure `interaction' is a hyperframe of `interact' objects
  # with the right number of rows.
  # All entries in a column must represent the same process
  # (possibly with different values of the irregular parameters).
  # Extract the names of the point processes.
  if(is.interact(interaction)) {
    ninteract <- 1
    processes <- list(Interaction=interaction$name)
    interaction <- hyperframe(Interaction=interaction, id=1:npat)[,1]
    constant <- c(Interaction=TRUE)
  } else if(is.hyperframe(interaction)) {
    inter.sumry <- summary(interaction)
    ninteract <- inter.sumry$nvars
    # ensure it has the same number of rows as 'data'
    nr <- inter.sumry$ncases
    if(nr == 1 && npat > 1) {
      interaction <- cbind.hyperframe(id=1:npat, interaction)[,-1]
      inter.sumry <- summary(interaction)
    } else if(nr != npat)
      stop(paste("Number of rows in", sQuote("interaction"),
                 "=", nr, "!=", npat, "=",
                 "number of rows in", sQuote("data")))
    # check all columns contain interaction objects
    ok <- (inter.sumry$classes == "interact")
    if(!all(ok)) {
      nbg <- names(interaction)[!ok]
      nn <- sum(!ok)
      stop(paste(ngettext(nn, "Column", "Columns"),
                 paste(sQuote(nbg), collapse=", "),
                 ngettext(nn, "does", "do"),
                 "not consist of interaction objects"))
    }
    # all entries in a column must represent the same process type
    # (with possibly different values of the irregular parameters)
    consistentname <- function(x) {
      xnames <- unlist(lapply(x, function(y) { y$name }))
      return(length(unique(xnames)) == 1)
    }
    ok <- unlist(lapply(as.list(interaction), consistentname))
    if(!all(ok)) {
      nbg <- names(interaction)[!ok]
      stop(paste("Different interactions may not appear in a single column.",
                 "Violated by",
                 paste(sQuote(nbg), collapse=", ")))
    }
    processes <- lapply(as.list(interaction), function(z) { z[[1]]$name })
    
    # determine whether all entries in a column are EXACTLY the same
    # (=> have the same parameters)
    constant <- (inter.sumry$storage == "hyperatom")
    checkconstant <- function(x) {
      if(length(x) <= 1)
        return(TRUE)
      y <- x[[1]]
      all(unlist(lapply(x[-1], identical, y=y)))
    }
    if(any(!constant)) {
      others <- interaction[,!constant]
      constant[!constant] <- unlist(lapply(as.list(others), checkconstant))
    }
  }
  # check for trivial (Poisson) interactions
  ispoisson <- function(x) all(unlist(lapply(x, is.poisson.interact)))
  trivial <- unlist(lapply(as.list(interaction), ispoisson))
  
  # check that iformula does not combine two interactions on one row
  nondfnames <- datanames[!(datanames %in% data.sumry$dfnames)]
  ip <- impliedpresence(itags, iformula, datadf, nondfnames)
  if(any(apply(ip, 1, sum) > 1))
    stop("iformula invokes more than one interaction on a single row")
  
  #
  #################### BERMAN-TURNER DEVICE #########################
  #
  # set up list to contain the glm variable names for each interaction.
  Vnamelist <- rep(list(character(0)), ninteract)
  names(Vnamelist) <- itags
  # set up list to contain 'IsOffset'
  Isoffsetlist <- rep(list(logical(0)), ninteract)
  names(Isoffsetlist) <- itags
  ##
  # ---------------- L O O P ---------------------------------
  for(i in 1:npat) {
    # extract responses and covariates for presentation to ppm()
    Yi <- Y[[i]]
    covariates <-
      if(has.covar) covariates.hf[i, , drop=TRUE, strip=FALSE] else NULL
    if(has.design) {
      # convert each data frame value to an image
      covariates[dfvarnames] <-
        lapply(as.list(as.data.frame(covariates[dfvarnames])),
               as.im, W=Yi$data$window)
    }
    
    # Generate data frame and glm info for this point pattern
    # First the trend covariates
    prep0 <- bt.frame(Yi, trend, Poisson(), ..., covariates=covariates,
                 allcovar=TRUE, use.gam=use.gam)
    glmdat <- prep0$glmdata
    
    # now the nontrivial interaction terms
    for(j in (1:ninteract)[iused & !trivial]) {
      inter <- interaction[i,j,drop=TRUE]
      prepj <- bt.frame(Yi, ~1, inter, ..., covariates=covariates,
                   allcovar=TRUE, use.gam=use.gam,
                   vnamebase=itags[j], vnameprefix=itags[j])
      # store GLM variable names & check consistency
      vnameij <- prepj$Vnames
      if(i == 1)
        Vnamelist[[j]] <- vnameij
      else if(!identical(vnameij, Vnamelist[[j]]))
        stop("Internal error: Unexpected conflict in glm variable names")
      # store offset indicator vectors
      isoffset.ij <- prepj$IsOffset
      if(i == 1)
        Isoffsetlist[[j]] <- isoffset.ij
      else if(!identical(isoffset.ij, Isoffsetlist[[j]]))
        stop("Internal error: Unexpected conflict in offset indicators")
      # GLM data frame for this interaction
      glmdatj <- prepj$glmdata
      if(nrow(glmdatj) != nrow(glmdat))
        stop("Internal error: differing numbers of rows in glm data frame")
      iterms.ij <- glmdatj[vnameij]
      subset.ij <- glmdatj$.mpl.SUBSET
      # tack on columns of interaction terms
      glmdat <- cbind(glmdat, iterms.ij)
      # update subset (quadrature points where cif is positive)
      glmdat$.mpl.SUBSET <- glmdat$.mpl.SUBSET & subset.ij
    }

    # assemble the Mother Of All Data Frames
    if(i == 1)
      moadf <- glmdat
    else {
      # There may be new or missing columns
      recognised <- names(glmdat) %in% names(moadf)
      if(any(!recognised)) {
        newnames <- names(glmdat)[!recognised]
        zeroes <- as.data.frame(matrix(0, nrow(moadf), length(newnames)))
        names(zeroes) <- newnames
        moadf <- cbind(moadf, zeroes)
      }
      provided   <- names(moadf)  %in% names(glmdat)
      if(any(!provided)) {
        absentnames <- names(moadf)[!provided]
        zeroes <- as.data.frame(matrix(0, nrow(glmdat), length(absentnames)))
        names(zeroes) <- absentnames
        glmdat <- cbind(glmdat, zeroes)
      }
      # Finally they are compatible
      moadf <- rbind(moadf, glmdat)
    }
  }
  # ---------------- E N D   o f    L O O P  --------------------------
  #
  # backdoor exit - Berman-Turner frame only - used by predict.mppm 
  if(backdoor)
    return(moadf)
  #
  #
  # --------------------------------------------------------------------
  # 
  # Construct the glm formula for the Berman-Turner device
  # 
  # Get trend part from the last-computed prep0
  fmla  <- prep0$trendfmla
  # Tack on the RHS of the interaction formula
  if(!all(trivial))
    fmla <- paste(fmla, "+", as.character(iformula)[[2]])
  # Make it a formula
  fmla <- as.formula(fmla)

  # Ensure that each interaction name is recognised.
  #
  # To the user, an interaction is identified by its `tag' name
  # (default tag: "Interaction")
  #
  # Internally, an interaction is fitted using its sufficient statistic
  # which may be 0, 1 or k-dimensional. 
  # The column names of the sufficient statistic are the Vnames
  # returned from ppm.
  # The Poisson process is a special case: it is 0-dimensional (no Vnames).
  #
  # For k-dimensional sufficient statistics, we modify the formulae,
  # replacing the interaction name by (vname1 + vname2 + .... + vnamek)
  # 
  for(j in (1:ninteract)[iused]) {
    vnames <- Vnamelist[[j]]
    tag    <- itags[j]
    isoffset <- Isoffsetlist[[j]]
    if(any(isoffset)) {
      # enclose names of offset variables in 'offset()'
      vnames[isoffset] <- paste("offset(", vnames[isoffset], ")", sep="")
    }
    if(trivial[j]) 
      # Poisson case: add a column of zeroes
      moadf[[tag]] <- 0
    else if(!identical(vnames, tag)) {
      if(length(vnames) == 1) 
      # tag to be replaced by vname
        vn <- paste("~", vnames[1])
      else 
      # tag to be replaced by (vname1 + vname2 + .... + vnamek)
        vn <- paste("~(", paste(vnames, collapse=" + "), ")")
      # pull out formula representation of RHS
      vnr <- as.formula(vn)[[2]]
      # make substitution rule: list(<tag>=<vnr>)
      vnsub <- list(vnr)
      names(vnsub) <- tag
      # perform substitution in trend formula
      fmla <- eval(substitute(substitute(fom, vnsub), list(fom=fmla)))
    }
  }

  fmla <- as.formula(fmla)
  # Fix scoping problem
  assign("glmmsubset", moadf$.mpl.SUBSET, envir=environment(fmla))
  # Satisfy package checker
  glmmsubset <- .mpl.SUBSET <- moadf$.mpl.SUBSET
  .mpl.W      <- moadf$.mpl.W
  
  # ---------------- FIT THE MODEL ------------------------------------
  want.trend <- prep0$info$want.trend
  if(want.trend && use.gam) {
    fitter <- "gam"
    FIT  <- gam(fmla, family=quasi(link=log, variance=mu), weights=.mpl.W,
                data=moadf, subset=(.mpl.SUBSET=="TRUE"),
                control=gam.control(maxit=50))
    deviants <- deviance(FIT)
  } else {
    fitter <- "glm"
    FIT  <- glm(fmla, family=quasi(link=log, variance=mu), weights=.mpl.W,
                data=moadf, subset=(.mpl.SUBSET=="TRUE"),
                control=glm.control(maxit=50))
    deviants <- deviance(FIT)
  }
  # maximised log-pseudolikelihood
  W <- moadf$.mpl.W
  SUBSET <- moadf$.mpl.SUBSET
  Z <- (moadf$.mpl.Y != 0)
  maxlogpl <- -(deviants/2 + sum(log(W[Z & SUBSET])) + sum(Z & SUBSET))
  #
  # ---------------- PACK UP THE RESULT --------------------------------
  #
  result <- list(Call = list(callstring=callstring, cl=cl),
                 Info =
                 list(
                      has.covar=has.covar,
                      has.design=has.design,
                      Yname=Yname,
                      used.cov.names=used.cov.names,
                      allvars=allvars,
                      names.data=names(data),
                      is.df.column=(data.sumry$storage == "dfcolumn"),
                      rownames=row.names(data),
                      correction=prep0$info$correction,
                      rbord=prep0$info$rbord),
                 Fit=
                 list(fitter=fitter,
                      use.gam=use.gam,
                      fmla=fmla,
                      FIT=FIT,
                      moadf=moadf,
                      Vnamelist=Vnamelist),
                 Inter =
                 list(ninteract=ninteract,
                      interaction=interaction,
                      iformula=iformula,
                      iused=iused,
                      itags=itags,
                      processes=processes,
                      trivial=trivial,
                      constant=constant),
                 formula=formula,
                 trend=trend,
                 iformula=iformula,
                 npat=npat,
                 data=data,
                 Y=Y,
                 maxlogpl=maxlogpl,
                 datadf=datadf)
                 

  class(result) <- c("mppm", class(result))
  return(result)
}

is.mppm <- function(x) {
  inherits(x, "mppm")
}

coef.mppm <- function(object, ...) {
  coef(object$Fit$FIT)
}


print.mppm <- function(x, ...) {
  print(summary(x, ..., brief=TRUE))
}

is.poisson.mppm <- function(x) {
  trivial <- x$Inter$trivial
  iused <- x$Inter$iused
  all(trivial[iused])
}

quad.mppm <- function(x) {
  x$Y
}

data.mppm <- function(x) {
  lapply(x$Y, function(z) { z$data })
}

windows.mppm <- function(x) {
  lapply(x$Y, function(z) {z$data$window})
}

logLik.mppm <- function(object, ...) {
  if(!is.poisson.mppm(object))
    warning(paste("log likelihood is not available for non-Poisson model;",
                  "log-pseudolikelihood returned"))
  ll <- object$maxlogpl
  attr(ll, "df") <- length(coef(object))
  class(ll) <- "logLik"
  return(ll)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/multihard.R"
#
#
#    multihard.R
#
#    $Revision: 1.12 $	$Date: 2014/12/23 05:42:19 $
#
#    The Hard core process
#
#    Hardcore()     create an instance of the Hard Core process
#                      [an object of class 'interact']
#	
#
# -------------------------------------------------------------------
#	

MultiHard <- local({

  # .... multitype hard core potential
  
  MHpotential <- function(d, tx, tu, par) {
     # arguments:
     # d[i,j] distance between points X[i] and U[j]
     # tx[i]  type (mark) of point X[i]
     # tu[i]  type (mark) of point U[j]
     #
     # get matrices of interaction radii
     h <- par$hradii

     # get possible marks and validate
     if(!is.factor(tx) || !is.factor(tu))
	stop("marks of data and dummy points must be factor variables")
     lx <- levels(tx)
     lu <- levels(tu)
     if(length(lx) != length(lu) || any(lx != lu))
	stop("marks of data and dummy points do not have same possible levels")

     if(!identical(lx, par$types))
        stop("data and model do not have the same possible levels of marks")
     if(!identical(lu, par$types))
        stop("dummy points and model do not have the same possible levels of marks")

     # ensure factor levels are acceptable for column names (etc)
     lxname <- make.names(lx, unique=TRUE)
     
     # list all UNORDERED pairs of types to be checked
     # (the interaction must be symmetric in type, and scored as such)
     uptri <- (row(h) <= col(h)) & (!is.na(h))
     mark1 <- (lx[row(h)])[uptri]
     mark2 <- (lx[col(h)])[uptri]
     # corresponding names
     mark1name <- (lxname[row(h)])[uptri]
     mark2name <- (lxname[col(h)])[uptri]
     vname <- apply(cbind(mark1name,mark2name), 1, paste, collapse="x")
     vname <- paste("mark", vname, sep="")
     npairs <- length(vname)
     # list all ORDERED pairs of types to be checked
     # (to save writing the same code twice)
     different <- mark1 != mark2
     mark1o <- c(mark1, mark2[different])
     mark2o <- c(mark2, mark1[different])
     nordpairs <- length(mark1o)
     # unordered pair corresponding to each ordered pair
     ucode <- c(1:npairs, (1:npairs)[different])
     #
     # create numeric array for result
     z <- array(0, dim=c(dim(d), npairs),
                dimnames=list(character(0), character(0), vname))
     # go....
     if(length(z) > 0) {
       # apply the relevant hard core distance to each pair of points
       hxu <- h[ tx, tu ]
       forbid <- (d < hxu)
       forbid[is.na(forbid)] <- FALSE
       # form the potential 
       value <- array(0, dim=dim(d))
       value[forbid] <- -Inf
       # assign value[i,j] -> z[i,j,k] where k is relevant interaction code
       for(i in 1:nordpairs) {
         # data points with mark m1
         Xsub <- (tx == mark1o[i])
         # quadrature points with mark m2
         Qsub <- (tu == mark2o[i])
         # assign
         z[Xsub, Qsub, ucode[i]] <- value[Xsub, Qsub]
       }
     }
     attr(z, "IsOffset") <- TRUE
     return(z)
   }
   #### end of 'pot' function ####

  # ............ template object ...................
  
  BlankMH <- 
  list(
       name     = "Multitype Hardcore process",
       creator  = "MultiHard",
       family   = "pairwise.family",  # evaluated later
       pot      = MHpotential,
       par      = list(types=NULL, hradii = NULL), # filled in later
       parnames = c("possible types", "hardcore distances"),
       pardesc  = c("vector of possible types",
                    "matrix of hardcore distances"),
       selfstart = function(X, self) {
         types <- self$par$types
         hradii <- self$par$hradii
         if(!is.null(types) && !is.null(hradii)) return(self)
         if(is.null(types)) types <- levels(marks(X))
         if(is.null(hradii)) {
           marx <- marks(X)
           d <- nndist(X, by=marx)
           h <- aggregate(d, by=list(from=marx), min)
           h <- as.matrix(h[, -1, drop=FALSE])
           m <- table(marx)
           mm <- outer(m, m, pmin)
           hradii <- h * mm/(mm+1)
           dimnames(hradii) <- list(types, types)
         }
         MultiHard(types=types,hradii=hradii)
       },
       init     = function(self) {
         types <- self$par$types
         if(!is.null(types)) {
           h <- self$par$hradii
           nt <- length(types)
           MultiPair.checkmatrix(h, nt, sQuote("hradii"))
           if(length(types) == 0)
             stop(paste("The", sQuote("types"),
                        "argument should be",
                        "either NULL or a vector of all possible types"))
           if(any(is.na(types)))
             stop("NA's not allowed in types")
           if(is.factor(types)) {
             types <- levels(types)
           } else {
             types <- levels(factor(types, levels=types))
           }
         }
       },
       update = NULL,  # default OK
       print = function(self) {
         h <- self$par$hradii
         cat(paste(nrow(h), "types of points\n"))
         types <- self$par$types
         if(!is.null(types)) {
           cat("Possible types: \n")
           print(noquote(types))
         } else cat("Possible types: \t not yet determined\n")
         cat("Hardcore radii:\n")
         print(h)
         invisible()
       },
       interpret = function(coeffs, self) {
        # there are no regular parameters (woo-hoo!)
         return(NULL)
       },
       valid = function(coeffs, self) {
         return(TRUE)
       },
       project = function(coeffs, self) {
         return(NULL)
       },
       irange = function(self, coeffs=NA, epsilon=0, ...) {
         h <- self$par$hradii
         return(max(0, h, na.rm=TRUE))
       },
       version=NULL # fix later
  )
  class(BlankMH) <- "interact"

  MultiHard <- function(hradii=NULL, types=NULL) {
    if((missing(hradii) || !is.matrix(hradii)) && is.matrix(types)) {
      ## old syntax: (types=NULL, hradii)
      hradii <- types
      types <- NULL
    }
    out <- instantiate.interact(BlankMH, list(types=types, hradii = hradii))
    if(!is.null(types))
      dimnames(out$par$hradii) <- list(types, types)
    return(out)
  }

  MultiHard <- intermaker(MultiHard, BlankMH)
  
  MultiHard
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/multipair.util.R"
##
##
##    multipair.util.R
##
##    $Revision: 1.13 $	$Date: 2014/04/29 01:13:35 $
##
##    Utilities for multitype pairwise interactions
##	
## -------------------------------------------------------------------
##	

MultiPair.checkmatrix <-
  function(mat, n, matname, naok=TRUE, zerook=TRUE, asymmok=FALSE) {
    if(missing(matname))
      matname <- short.deparse(substitute(mat))
    if(!is.matrix(mat))
      stop(paste(matname, "must be a matrix"))
    if(any(dim(mat) != rep.int(n,2)))
      stop(paste(matname, "must be a square matrix,",
                 "of size", n, "x", n))
    isna <- is.na(mat)
    if(!naok && any(isna))
      stop(paste("NA entries not allowed in", matname))
    if(any(mat[!isna] < 0))
      stop(paste("Negative entries not allowed in", matname))
    if(!zerook && any(mat[!isna] == 0))
      stop(paste("Zero entries not allowed in", matname))
    if(!asymmok && !isSymmetric(mat))
      stop(paste(matname, "must be a symmetric matrix"))
  }

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/multistrauss.R"
#
#
#    multistrauss.S
#
#    $Revision: 2.21 $	$Date: 2014/04/30 07:57:47 $
#
#    The multitype Strauss process
#
#    MultiStrauss()    create an instance of the multitype Strauss process
#                 [an object of class 'interact']
#	
# -------------------------------------------------------------------
#	

MultiStrauss <- local({

  # ......... define interaction potential

  MSpotential <- function(d, tx, tu, par) {
     # arguments:
     # d[i,j] distance between points X[i] and U[j]
     # tx[i]  type (mark) of point X[i]
     # tu[j]  type (mark) of point U[j]
     #
     # get matrix of interaction radii r[ , ]
     r <- par$radii
     #
     # get possible marks and validate
     if(!is.factor(tx) || !is.factor(tu))
	stop("marks of data and dummy points must be factor variables")
     lx <- levels(tx)
     lu <- levels(tu)
     if(length(lx) != length(lu) || any(lx != lu))
	stop("marks of data and dummy points do not have same possible levels")

     if(!identical(lx, par$types))
        stop("data and model do not have the same possible levels of marks")
     if(!identical(lu, par$types))
        stop("dummy points and model do not have the same possible levels of marks")
     
     # ensure factor levels are acceptable for column names (etc)
     lxname <- make.names(lx, unique=TRUE)

     # list all UNORDERED pairs of types to be checked
     # (the interaction must be symmetric in type, and scored as such)
     uptri <- (row(r) <= col(r)) & !is.na(r)
     mark1 <- (lx[row(r)])[uptri]
     mark2 <- (lx[col(r)])[uptri]
     # corresponding names
     mark1name <- (lxname[row(r)])[uptri]
     mark2name <- (lxname[col(r)])[uptri]
     vname <- apply(cbind(mark1name,mark2name), 1, paste, collapse="x")
     vname <- paste("mark", vname, sep="")
     npairs <- length(vname)
     # list all ORDERED pairs of types to be checked
     # (to save writing the same code twice)
     different <- mark1 != mark2
     mark1o <- c(mark1, mark2[different])
     mark2o <- c(mark2, mark1[different])
     nordpairs <- length(mark1o)
     # unordered pair corresponding to each ordered pair
     ucode <- c(1:npairs, (1:npairs)[different])
     #
     # create logical array for result
     z <- array(FALSE, dim=c(dim(d), npairs),
                dimnames=list(character(0), character(0), vname))
     # go....
     if(length(z) > 0) {
       # assemble the relevant interaction distance for each pair of points
       rxu <- r[ tx, tu ]
       # apply relevant threshold to each pair of points
       str <- (d <= rxu)
       # assign str[i,j] -> z[i,j,k] where k is relevant interaction code
       for(i in 1:nordpairs) {
         # data points with mark m1
         Xsub <- (tx == mark1o[i])
         # quadrature points with mark m2
         Qsub <- (tu == mark2o[i])
         # assign
         z[Xsub, Qsub, ucode[i]] <- str[Xsub, Qsub]
       }
     }
     return(z)
   }
   #### end of 'pot' function ####

  # ........ auxiliary functions ..............
  delMS <- function(which, types, radii) {
    radii[which] <- NA
    if(all(is.na(radii))) return(Poisson())
    return(MultiStrauss(types, radii))
  }
  
  # Set up basic object except for family and parameters
  BlankMSobject <- 
  list(
       name     = "Multitype Strauss process",
       creator  = "MultiStrauss",
       family   = "pairwise.family", # evaluated later
       pot      = MSpotential,
       par      = list(types=NULL, radii = NULL), # to be filled in later
       parnames = c("possible types", "interaction distances"),
       pardesc  = c("vector of possible types",
                    "matrix of hardcore distances"),
       selfstart = function(X, self) {
         if(!is.null(self$par$types)) return(self)
         types <- levels(marks(X))
         MultiStrauss(types=types,radii=self$par$radii)
       },
       init = function(self) {
         types <- self$par$types
         if(!is.null(types)) {
           radii <- self$par$radii
           nt <- length(types)
           MultiPair.checkmatrix(radii, nt, sQuote("radii"))
           if(length(types) == 0)
             stop(paste("The", sQuote("types"),"argument should be",
                        "either NULL or a vector of all possible types"))
           if(any(is.na(types)))
             stop("NA's not allowed in types")
           if(is.factor(types)) {
             types <- levels(types)
           } else {
             types <- levels(factor(types, levels=types))
           }
         }
       },
       update = NULL, # default OK
       print = function(self) {
         radii <- self$par$radii
         types <- self$par$types
         cat(paste(nrow(radii), "types of points\n"))
         if(!is.null(types)) {
           cat("Possible types: \n")
           print(noquote(types))
         } else cat("Possible types:\t not yet determined\n")
         cat("Interaction radii:\n")
         print(self$par$radii)
         invisible()
       },
       interpret = function(coeffs, self) {
         # get possible types
         typ <- self$par$types
         ntypes <- length(typ)
         # get matrix of Strauss interaction radii
         r <- self$par$radii
         # list all unordered pairs of types
         uptri <- (row(r) <= col(r)) & (!is.na(r))
         index1 <- (row(r))[uptri]
         index2 <- (col(r))[uptri]
         npairs <- length(index1)
         # extract canonical parameters; shape them into a matrix
         gammas <- matrix(, ntypes, ntypes)
         dimnames(gammas) <- list(typ, typ)
         expcoef <- exp(coeffs)
         gammas[ cbind(index1, index2) ] <- expcoef
         gammas[ cbind(index2, index1) ] <- expcoef
         #
         return(list(param=list(gammas=gammas),
                     inames="interaction parameters gamma_ij",
                     printable=dround(gammas)))
       },
       valid = function(coeffs, self) {
         # interaction parameters gamma[i,j]
         gamma <- (self$interpret)(coeffs, self)$param$gammas
         # interaction radii
         radii <- self$par$radii
         # parameters to estimate
         required <- !is.na(radii)
         gr <- gamma[required]
         return(all(is.finite(gr) & gr <= 1))
       },
       project  = function(coeffs, self) {
         # interaction parameters gamma[i,j]
         gamma <- (self$interpret)(coeffs, self)$param$gammas
         # interaction radii and types
         radii <- self$par$radii
         types <- self$par$types
         # problems?
         required <- !is.na(radii)
         okgamma  <- is.finite(gamma) & (gamma <= 1)
         naughty  <- required & !okgamma
         # 
         if(!any(naughty))  
           return(NULL)
         if(spatstat.options("project.fast")) {
           # remove ALL naughty terms simultaneously
           return(delMS(naughty, types, radii))
         } else {
           # present a list of candidates
           rn <- row(naughty)
           cn <- col(naughty)
           uptri <- (rn <= cn) 
           upn <- uptri & naughty
           rowidx <- as.vector(rn[upn])
           colidx <- as.vector(cn[upn])
           matindex <- function(v) { matrix(c(v, rev(v)),
                                            ncol=2, byrow=TRUE) }
           mats <- lapply(as.data.frame(rbind(rowidx, colidx)), matindex)
           inters <- lapply(mats, delMS, types=types, radii=radii)
           return(inters)
         }
       },
       irange = function(self, coeffs=NA, epsilon=0, ...) {
         r <- self$par$radii
         active <- !is.na(r)
         if(any(!is.na(coeffs))) {
           gamma <- (self$interpret)(coeffs, self)$param$gammas
           gamma[is.na(gamma)] <- 1
           active <- active & (abs(log(gamma)) > epsilon)
         }
         if(any(active)) return(max(r[active])) else return(0)
       },
       version=NULL # to be added
       )
  class(BlankMSobject) <- "interact"

  # finally create main function
  MultiStrauss <- function(radii, types=NULL) {
    if((missing(radii) || !is.matrix(radii)) && is.matrix(types)) {
      ## old syntax: (types=NULL, radii)
      radii <- types
      types <- NULL
    }
    out <- instantiate.interact(BlankMSobject, list(types=types, radii = radii))
    if(!is.null(types))
      dimnames(out$par$radii) <- list(types, types)
    return(out)
  }

  MultiStrauss <- intermaker(MultiStrauss, BlankMSobject)
  
  MultiStrauss
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/multistrhard.R"
#
#
#    multistrhard.S
#
#    $Revision: 2.31 $	$Date: 2014/12/23 05:42:03 $
#
#    The multitype Strauss/hardcore process
#
#    MultiStraussHard()
#                 create an instance of the multitype Strauss/ harcore
#                 point process
#                 [an object of class 'interact']
#	
# -------------------------------------------------------------------
#	

doMultiStraussHard <- local({
  
  # ........  define potential ......................

  MSHpotential <- function(d, tx, tu, par) {
     # arguments:
     # d[i,j] distance between points X[i] and U[j]
     # tx[i]  type (mark) of point X[i]
     # tu[i]  type (mark) of point U[j]
     #
     # get matrices of interaction radii
     r <- par$iradii
     h <- par$hradii

     # get possible marks and validate
     if(!is.factor(tx) || !is.factor(tu))
	stop("marks of data and dummy points must be factor variables")
     lx <- levels(tx)
     lu <- levels(tu)
     if(length(lx) != length(lu) || any(lx != lu))
	stop("marks of data and dummy points do not have same possible levels")

     if(!identical(lx, par$types))
        stop("data and model do not have the same possible levels of marks")
     if(!identical(lu, par$types))
        stop("dummy points and model do not have the same possible levels of marks")
                   
     # ensure factor levels are acceptable for column names (etc)
     lxname <- make.names(lx, unique=TRUE)

     # list all UNORDERED pairs of types to be checked
     # (the interaction must be symmetric in type, and scored as such)
     uptri <- (row(r) <= col(r)) & (!is.na(r) | !is.na(h))
     mark1 <- (lx[row(r)])[uptri]
     mark2 <- (lx[col(r)])[uptri]
     # corresponding names
     mark1name <- (lxname[row(r)])[uptri]
     mark2name <- (lxname[col(r)])[uptri]
     vname <- apply(cbind(mark1name,mark2name), 1, paste, collapse="x")
     vname <- paste("mark", vname, sep="")
     npairs <- length(vname)
     # list all ORDERED pairs of types to be checked
     # (to save writing the same code twice)
     different <- mark1 != mark2
     mark1o <- c(mark1, mark2[different])
     mark2o <- c(mark2, mark1[different])
     nordpairs <- length(mark1o)
     # unordered pair corresponding to each ordered pair
     ucode <- c(1:npairs, (1:npairs)[different])
     #
     # create numeric array for result
     z <- array(0, dim=c(dim(d), npairs),
                dimnames=list(character(0), character(0), vname))
     # go....
     if(length(z) > 0) {
       # apply the relevant interaction distance to each pair of points
       rxu <- r[ tx, tu ]
       str <- (d < rxu)
       str[is.na(str)] <- FALSE
       # and the relevant hard core distance
       hxu <- h[ tx, tu ]
       forbid <- (d < hxu)
       forbid[is.na(forbid)] <- FALSE
       # form the potential
       value <- str
       value[forbid] <- -Inf
       # assign value[i,j] -> z[i,j,k] where k is relevant interaction code
       for(i in 1:nordpairs) {
         # data points with mark m1
         Xsub <- (tx == mark1o[i])
         # quadrature points with mark m2
         Qsub <- (tu == mark2o[i])
         # assign
         z[Xsub, Qsub, ucode[i]] <- value[Xsub, Qsub]
       }
     }
     return(z)
   }
  # ............... end of potential function ...................

  # .......... auxiliary functions .................
  
  delMSH <- function(which, types, iradii, hradii, ihc) {
    iradii[which] <- NA
    if(any(!is.na(iradii))) {
      # some gamma interactions left
      # return modified MultiStraussHard with fewer gamma parameters
      return(MultiStraussHard(types, iradii, hradii))
    } else if(any(!ihc)) {
      # no gamma interactions left, but some active hard cores
      return(MultiHard(types, hradii))
    } else return(Poisson())
  }

  # ...........................................................
  
  # Set up basic object except for family and parameters

  BlankMSHobject <- 
    list(
         name     = "Multitype Strauss Hardcore process",
         creator  = "MultiStraussHard",
         family   = "pairwise.family", # evaluated later
         pot      = MSHpotential,
         par      = list(types=NULL, iradii=NULL, hradii=NULL),  # to be added
         parnames = c("possible types",
                      "interaction distances",
                      "hardcore distances"),
         pardesc  = c("vector of possible types",
                      "matrix of interaction distances",
                      "matrix of hardcore distances"),
         selfstart = function(X, self) {
           types <- self$par$types
           hradii <- self$par$hradii
           if(!is.null(types) && !is.null(hradii)) return(self)
           if(is.null(types)) types <- levels(marks(X))
           if(is.null(hradii)) {
             marx <- marks(X)
             d <- nndist(X, by=marx)
             h <- aggregate(d, by=list(from=marx), min)
             h <- as.matrix(h[, -1, drop=FALSE])
             m <- table(marx)
             mm <- outer(m, m, pmin)
             hradii <- h * mm/(mm+1)
             dimnames(hradii) <- list(types, types)
           }
           MultiStraussHard(types=types,hradii=hradii,iradii=self$par$iradii)
	 },
         init     = function(self) {
           types <- self$par$types
           iradii <- self$par$iradii
           hradii <- self$par$hradii
           if(!is.null(types)) {
             if(!is.null(dim(types)))
               stop(paste("The", sQuote("types"),
                          "argument should be a vector"))
             if(length(types) == 0)
               stop(paste("The", sQuote("types"),"argument should be",
                          "either NULL or a vector of all possible types"))
             if(any(is.na(types)))
               stop("NA's not allowed in types")
             if(is.factor(types)) {
               types <- levels(types)
             } else {
               types <- levels(factor(types, levels=types))
             }
             nt <- length(types)
             MultiPair.checkmatrix(iradii, nt, sQuote("iradii"))
             MultiPair.checkmatrix(hradii, nt, sQuote("hradii"))
           }
           ina <- is.na(iradii)
           hna <- is.na(hradii)
           if(all(ina))
             stop(paste("All entries of", sQuote("iradii"),
                        "are NA"))
           both <- !ina & !hna
           if(any(iradii[both] <= hradii[both]))
             stop("iradii must be larger than hradii")
         },
         update = NULL,  # default OK
         print = function(self) {
           types <- self$par$types
           iradii <- self$par$iradii
           hradii <- self$par$hradii
           nt <- nrow(iradii)
           cat(paste(nt, "types of points\n"))
           if(!is.null(types)) {
             cat("Possible types: \n")
             print(noquote(types))
           } else cat("Possible types:\t not yet determined\n")
           cat("Interaction radii:\n")
           print(iradii)
           cat("Hardcore radii:\n")
           print(hradii)
           invisible()
         },
        interpret = function(coeffs, self) {
          # get possible types
          typ <- self$par$types
          ntypes <- length(typ)
          # get matrices of interaction radii
          r <- self$par$iradii
          h <- self$par$hradii
          # list all relevant unordered pairs of types
          uptri <- (row(r) <= col(r)) & (!is.na(r) | !is.na(h))
          index1 <- (row(r))[uptri]
          index2 <- (col(r))[uptri]
          npairs <- length(index1)
          # extract canonical parameters; shape them into a matrix
          gammas <- matrix(, ntypes, ntypes)
          dimnames(gammas) <- list(typ, typ)
          expcoef <- exp(coeffs)
          gammas[ cbind(index1, index2) ] <- expcoef
          gammas[ cbind(index2, index1) ] <- expcoef
          #
          return(list(param=list(gammas=gammas),
                      inames="interaction parameters gamma_ij",
                      printable=dround(gammas)))
        },
        valid = function(coeffs, self) {
           # interaction radii r[i,j]
           iradii <- self$par$iradii
           # hard core radii r[i,j]
           hradii <- self$par$hradii
           # interaction parameters gamma[i,j]
           gamma <- (self$interpret)(coeffs, self)$param$gammas
           # Check that we managed to estimate all required parameters
           required <- !is.na(iradii)
           if(!all(is.finite(gamma[required])))
             return(FALSE)
           # Check that the model is integrable
           # inactive hard cores ...
           ihc <- (is.na(hradii) | hradii == 0)
           # .. must have gamma <= 1
           return(all(gamma[required & ihc] <= 1))
         },
         project = function(coeffs, self) {
           # types
           types <- self$par$types
           # interaction radii r[i,j]
           iradii <- self$par$iradii
           # hard core radii r[i,j]
           hradii <- self$par$hradii
           # interaction parameters gamma[i,j]
           gamma <- (self$interpret)(coeffs, self)$param$gammas
           # required gamma parameters
           required <- !is.na(iradii)
           # inactive hard cores
           ihc <- is.na(hradii) | (hradii == 0)
           # problems
           okgamma <- is.finite(gamma) & (gamma <= 1)
           naughty <- ihc & required & !okgamma
           if(!any(naughty))
             return(NULL)
           #
           if(spatstat.options("project.fast")) {
             # remove ALL naughty terms simultaneously
             return(delMSH(naughty, types, iradii, hradii, ihc))
           } else {
             # present a list of candidates
             rn <- row(naughty)
             cn <- col(naughty)
             uptri <- (rn <= cn) 
             upn <- uptri & naughty
             rowidx <- as.vector(rn[upn])
             colidx <- as.vector(cn[upn])
             matindex <- function(v) { matrix(c(v, rev(v)),
                                              ncol=2, byrow=TRUE) }
             mats <- lapply(as.data.frame(rbind(rowidx, colidx)), matindex)
             inters <- lapply(mats, delMSH,
                              types=types, iradii=iradii,
                              hradii=hradii, ihc=ihc)
             return(inters)           }
         },
         irange = function(self, coeffs=NA, epsilon=0, ...) {
           r <- self$par$iradii
           h <- self$par$hradii
           ractive <- !is.na(r)
           hactive <- !is.na(h)
           if(any(!is.na(coeffs))) {
             gamma <- (self$interpret)(coeffs, self)$param$gammas
             gamma[is.na(gamma)] <- 1
             ractive <- ractive & (abs(log(gamma)) > epsilon)
           }
           if(!any(c(ractive,hactive)))
             return(0)
           else
             return(max(c(r[ractive],h[hactive])))
         },
         version=NULL # to be added
         )
  class(BlankMSHobject) <- "interact"

  # Finally define MultiStraussHard function
  doMultiStraussHard <- function(iradii, hradii, types=NULL) {
    out <- instantiate.interact(BlankMSHobject,
                                list(types=types,
                                     iradii = iradii, hradii = hradii))
    if(!is.null(types)) 
      dimnames(out$par$iradii) <- 
        dimnames(out$par$hradii) <- list(types, types)
    return(out)
  }

  doMultiStraussHard
})


MultiStraussHard <- local({

  MultiStraussHard <- function(iradii, hradii, types=NULL) {
    ## try new syntax
    newcall <- match.call()
    newcall[[1]] <- as.name('doMultiStraussHard')
    out <- try(eval(newcall, parent.frame()), silent=TRUE)
    if(is.interact(out))
      return(out)
    ## try old syntax
    oldcall <- match.call(function(types=NULL, iradii, hradii) {})
    oldcall[[1]] <- as.name('doMultiStraussHard')
    out <- try(eval(oldcall, parent.frame()), silent=TRUE)
    if(is.interact(out))
      return(out)
    ## Syntax is wrong: generate error using new syntax rules
    doMultiStraussHard(iradii=iradii, hradii=hradii, types=types)
  }


  BlankMSHobject <- get("BlankMSHobject",
                        envir=environment(doMultiStraussHard))
  
  MultiStraussHard <- intermaker(MultiStraussHard, BlankMSHobject)

  MultiStraussHard
})


  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nearestsegment.R"
#
#  nearestsegment.R
#
#  $Revision: 1.11 $  $Date: 2014/11/10 11:27:12 $
#
# Given a point pattern X and a line segment pattern Y,
# for each point x of X, determine which segment of Y is closest to x
# and find the point on Y closest to x.
#

nearestsegment <- function(X,Y) {
  return(ppllengine(X,Y,"identify"))
}

project2segment <- function(X, Y) {
  return(ppllengine(X,Y,"project"))
}
  
ppllengine <- function(X, Y, action="project", check=FALSE) {
  stopifnot(is.ppp(X))
  stopifnot(is.psp(Y))
  stopifnot(action %in% c("distance", "identify", "project"))
  # deal with empty patterns
  if(Y$n == 0)
    stop("Segment pattern Y contains 0 segments; projection undefined")
  if(X$n == 0) {
    nowt <- numeric(0)
    none <- integer(0)
    switch(action,
           identify = return(none),
           distance = return(list(dist=nowt, which=none)),
           project  = return(list(Xproj=X, mapXY=none, d=nowt, tp=nowt)))
  }
  #              
  XX <- as.matrix(as.data.frame(unmark(X)))
  YY <- as.matrix(as.data.frame(unmark(Y)))
  # determine which segment lies closest to each point
  huge <- max(diameter(as.rectangle(as.owin(X))),
              diameter(as.rectangle(as.owin(Y))))
  d <- distppllmin(XX, YY, huge^2)
  mapXY <- d$min.which
  if(action == "identify")
    return(mapXY)
  else if(action == "distance") 
    return(data.frame(dist=d$min.d, which=mapXY))
  
  # combine relevant rows of data
  alldata <- as.data.frame(cbind(XX, YY[mapXY, ,drop=FALSE]))
  colnames(alldata) <- c("x", "y", "x0", "y0", "x1", "y1")
  # coordinate geometry
  dx <- with(alldata, x1-x0)
  dy <- with(alldata, y1-y0)
  leng <- sqrt(dx^2 + dy^2)
  # rotation sines & cosines (may include 0/0)
  co <- dx/leng
  si <- dy/leng
  # vector to point from first endpoint of segment
  xv <- with(alldata, x - x0)
  yv <- with(alldata, y - y0)
  # rotate coordinate system so that x axis is parallel to line segment
  xpr <- xv * co + yv * si
#  ypr <- - xv * si + yv * co
  # determine whether projection is an endpoint or interior point of segment
  ok <- is.finite(xpr)
  left <- !ok | (xpr <= 0)
  right <- ok &  (xpr >= leng)
  # location of projected point in rotated coordinates
  xr <- with(alldata, ifelseAX(left, 0, ifelseXY(right, leng, xpr)))
  # back to standard coordinates
  xproj <- with(alldata, x0 + ifelseXB(ok, xr * co, 0))
  yproj <- with(alldata, y0 + ifelseXB(ok, xr * si, 0))
  Xproj <- ppp(xproj, yproj, window=X$window, marks=X$marks, check=check)
  # parametric coordinates
  tp <- xr/leng
  tp[!is.finite(tp)] <- 0
  # 
  return(list(Xproj=Xproj, mapXY=mapXY, d=d$min.d, tp=tp))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/news.R"
#
# news.R
#
#  News and warnings
#
latest.news <- function(package="spatstat") {
  # get version number
  v <- read.dcf(file=system.file("DESCRIPTION", package=package),
                fields="Version")
  ne <- eval(substitute(news(Version >= v0, package=package), list(v0=v)))
  page(ne, method="print")
  return(invisible(ne))
}

class(latest.news) <- "autoexec"

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nnclean.R"
#
#  nnclean.R
#
# Nearest-neighbour clutter removal
#
# Adapted from statlib file NNclean.q
# Authors: Simon Byers and Adrian Raftery
#
#  $Revision: 1.14 $   $Date: 2014/11/10 10:55:29 $
#

nnclean <- function(X, k, ...) {
  UseMethod("nnclean")
}

nnclean.pp3 <- function(X, k, ...,
                        convergence = 0.001, plothist = FALSE,
                        verbose=TRUE, maxit=50)
{
  # Adapted from statlib file NNclean.q
  # Authors: Simon Byers and Adrian Raftery
  # Adapted for spatstat by Adrian Baddeley

  Xname <- short.deparse(substitute(X))
  
  stopifnot(inherits(X, "pp3"))
  validposint(k, "nnclean.pp3")

  kthNND <- nndist(X, k=k)  
  
  # apply classification algorithm
  em <- do.call(nncleanEngine,
                resolve.defaults(list(kthNND, k=k),
                                 list(...),
                                 list(d=3, tol=convergence, plothist=plothist,
                                      verbose=verbose, maxit=maxit,
                                      Xname=Xname)))

  # tack results onto point pattern as marks
  pp <- em$probs
  zz <- factor(em$z, levels=c(0,1))
  levels(zz) <- c("noise", "feature")
  mm <- hyperframe(prob=pp, label=zz)
  marks(X) <- cbind(marks(X), mm)
  attr(X, "theta") <- em[c("lambda1", "lambda2", "p")]
  attr(X, "info") <- em[c("d", "niter", "maxit", "converged")]
  attr(X, "hist") <- em$hist
  return(X)
}

nnclean.ppp <-
  function(X, k, ...,
           edge.correct = FALSE, wrap = 0.1,
           convergence = 0.001, plothist = FALSE,
           verbose=TRUE, maxit=50)
{
  # Adapted from statlib file NNclean.q
  # Authors: Simon Byers and Adrian Raftery
  # Adapted for spatstat by Adrian Baddeley

  Xname <- short.deparse(substitute(X))
  
  validposint(k, "nnclean.ppp")

  if(!edge.correct) {
    # compute vector of k-th nearest neighbour distances
    kthNND <- nndist(X, k=k)
  } else {
    # replicate data periodically
    # (ensuring original points are listed first)
    Xbox <- X[as.rectangle(X)]
    Xpand <- periodify(Xbox, ix=c(0,-1,1), iy=c(0,-1,1), check=FALSE)
    # trim to margin
    W <- expand.owin(X$window, (1+2*wrap)^2)
    Xpand <- Xpand[W]
    kthNND <- nndist(Xpand, k=k)
  }

  # apply classification algorithm
  em <- do.call(nncleanEngine,
                resolve.defaults(list(kthNND, k=k),
                                 list(...),
                                 list(d=2, tol=convergence, plothist=plothist,
                                      verbose=verbose, maxit=maxit,
                                      Xname=Xname)))

  # extract results
  pp <- em$probs
  zz <- em$z
  zz <- factor(zz, levels=c(0,1))
  levels(zz) <- c("noise", "feature")
  df <- data.frame(class=zz,prob=pp) 

  if(edge.correct) {
    # trim back to original point pattern
    df <- df[seq_len(X$n), ]
  }
  
  # tack on
  marx <- marks(X, dfok=TRUE)
  if(is.null(marx))
    marks(X, dfok=TRUE) <- df
  else 
    marks(X, dfok=TRUE) <- cbind(df, marx)

  attr(X, "theta") <- em[c("lambda1", "lambda2", "p")]
  attr(X, "info") <- em[c("d", "niter", "maxit", "converged")]
  attr(X, "hist") <- em$hist
  return(X)
}

nncleanEngine <-
  function(kthNND, k, d, ..., 
           tol = 0.001, maxit = 50,
           plothist = FALSE, lineargs = list(), 
           verbose=TRUE, Xname="X")
{
  ## Adapted from statlib file NNclean.q
  ## Authors: Simon Byers and Adrian Raftery
  ## Adapted for spatstat by Adrian Baddeley
  
  n <- length(kthNND)

  ## Undocumented extension by Adrian Baddeley 2014
  ## Allow different dimensions in feature and noise.
  ## d[1] is cluster dimension.
  
  d <- ensure2vector(d)
  alpha.d <- (2. * pi^(d/2.))/(d * gamma(d/2.))

  # raise to power d for efficiency
  kNNDpowd1 <- kthNND^(d[1])
  kNNDpowd2 <- kthNND^(d[2])
  
  #
  # Now use kthNND in E-M algorithm
  # First set up starting guesses.
  #
  #
  probs <- numeric(n)
  thresh <- (min(kthNND) + diff(range(kthNND))/3.)
  high <- (kthNND > thresh)
  delta <- as.integer(high)
  p <- 0.5
  lambda1 <- k/(alpha.d[1] * mean(kNNDpowd1[!high]))
  lambda2 <- k/(alpha.d[2] * mean(kNNDpowd2[ high]))
  loglik.old <- 0.
  loglik.new <- 1.
  #
  # Iterator starts here, 
  #
  Z <- !kthNND
  niter <- 0
  while(abs(loglik.new - loglik.old)/(1 + abs(loglik.new)) > tol) {
    if(niter >= maxit) {
      warning(paste("E-M algorithm failed to converge in",
                    maxit, ngettext(maxit, "iteration", "iterations")),
              call.=FALSE)
      break
    }
    niter <- niter + 1
    # E - step
    f1 <- dknn(kthNND[!Z], lambda=lambda1, k = k, d = d[1])
    f2 <- dknn(kthNND[!Z], lambda=lambda2, k = k, d = d[2])
    delta[!Z] <- (p * f1)/(p * f1 + (1 - p) * f2)
    delta[Z] <- 0
    # M - step
    sumdelta <- sum(delta)
    negdelta <- 1. - delta
    p <- sumdelta/n
    lambda1 <- (k * sumdelta)/(alpha.d[1] * sum(kNNDpowd1 * delta))
    lambda2 <- (k * (n - sumdelta))/(alpha.d[2] * sum(kNNDpowd2 * negdelta))
    # evaluate marginal loglikelihood
    loglik.old <- loglik.new
    loglik.new <- sum( - p * lambda1 * alpha.d[1] * (kNNDpowd1 * delta)
                      - (1. - p) * lambda2 * alpha.d[2] * (kNNDpowd2 * negdelta)
                      + delta * k * log(lambda1 * alpha.d[1]) +
			negdelta * k * log(lambda2 * alpha.d[2]))
    if(verbose) 
      cat(paste("Iteration", niter, "\tlogLik =", loglik.new,
                "\tp =", signif(p,4), "\n"))
  }
  if(plothist) {
    ## compute plot limits to include both histogram and density
    xlim <- c(0, max(kthNND))
    H <- do.call("hist",
                 resolve.defaults(list(kthNND, plot=FALSE, warn.unused=FALSE),
                                  list(...), 
                                  list(nclass=40)))
    barheights <- H$density
    support <- seq(from=xlim[1], to=xlim[2], length.out = 200)
    fittedy <- p * dknn(support, lambda=lambda1, k = k, d = d[1]) +
      (1 - p) * dknn(support, lambda=lambda2, k = k, d = d[2])
    ylim <- range(c(0, barheights, fittedy))
    xlab <- paste("Distance to", ordinal(k), "nearest neighbour")
    ## now plot it (unless overridden by plot=FALSE)
    reallyplot <- resolve.1.default("plot", list(...), list(plot=TRUE))
    H <- do.call("hist",
                 resolve.defaults(list(kthNND, probability=TRUE),
                                  list(...),
                                  list(plot=TRUE,
                                       warn.unused=reallyplot,
                                       nclass=40,
                                       xlim = xlim, ylim=ylim,
                                       xlab = xlab,
                                       ylab = "Probability density",
                                       axes = TRUE, main="")))
    H$xname <- xlab
    if(reallyplot) {
      box()
      do.call("lines", resolve.defaults(list(x=support, y=fittedy),
                                        lineargs,
                                        list(col="green", lwd=2)))
    }
  }
  #
  delta1 <- dknn(kthNND[!Z], lambda=lambda1, k = k, d = d[1])
  delta2 <- dknn(kthNND[!Z], lambda=lambda2, k = k, d = d[2])
  probs[!Z] <- delta1/(delta1 + delta2)
  probs[Z] <- 1
  #
  if(verbose) {
    cat("Estimated parameters:\n")
    cat(paste("p [cluster] =", signif(p, 5), "\n"))
    cat(paste("lambda [cluster] =", signif(lambda1, 5), "\n"))
    cat(paste("lambda [noise]   =", signif(lambda2, 5), "\n"))
  }
  #
  # z will be the classifications. 1= in cluster. 0= in noise. 
  #
  return(list(z = round(probs),
              probs = probs,
              lambda1 = lambda1, lambda2 = lambda2, p = p,
              kthNND = kthNND, d=d, n=n, k=k,
              niter = niter, maxit = maxit,
              converged = (niter >= maxit),
              hist=if(plothist) H else NULL))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nncorr.R"
#
# nncorr.R
#
# $Revision: 1.8 $  $Date: 2013/04/25 06:37:43 $
#

nnmean <- function(X) {
  stopifnot(is.ppp(X) && is.marked(X))
  m <- numeric.columns(marks(X), logical=TRUE, others="na")
#  nv <- ncol(m)
  nnid <- nnwhich(X)
  ok <- (nndist(X) <= bdist.points(X))
  if(!any(ok))
    stop("Insufficient data")
  numer <- unlist(lapply(as.data.frame(m[nnid[ok], ]), mean, na.rm=TRUE))
  denom <- unlist(lapply(as.data.frame(m),             mean, na.rm=TRUE))
  ans <- rbind(unnormalised=numer,
               normalised  =numer/denom)
  return(ans)
}

nnvario <- function(X) {
  stopifnot(is.ppp(X) && is.marked(X))
  m <- numeric.columns(marks(X), logical=TRUE, others="na")
  f <- function(m1,m2) { ((m1-m2)^2)/2 }
  ans <- nncorr(X %mark% m, f, denominator=diag(var(m)))
  return(ans)
}

nncorr <- function(X, f = function(m1,m2) { m1 * m2}, ...,
                   use = "all.obs",
                   method = c("pearson", "kendall", "spearman"),
                   denominator=NULL) {
  stopifnot(is.ppp(X) && is.marked(X))
  m <- as.data.frame(marks(X))
  nv <- ncol(m)
  if(nv == 1) colnames(m) <- ""
  #
  if(missing(method) || is.null(method))
    method <- "pearson"
  # 
  if(missing(f)) f <- NULL
  if(!is.null(f) && !is.function(f)) {
    if(nv == 1) stop("f should be a function")
    # could be a list of functions
    if(!(is.list(f) && all(unlist(lapply(f, is.function)))))
      stop("f should be a function or a list of functions")
    if(length(f) != nv)
      stop("Length of list f does not match number of mark variables")
  }
  # optional denominator(s)
  if(!is.null(denominator) && !(length(denominator) %in% c(1, nv)))
    stop("Denominator has incorrect length")
  # multi-dimensional case
  if(nv > 1) {
    # replicate things
    if(is.function(f)) f <- rep.int(list(f), nv)
    if(length(denominator) <= 1) denominator <- rep.int(list(denominator), nv)
    #
    result <- matrix(NA, nrow=3, ncol=nv)
    outnames <- c("unnormalised", "normalised", "correlation")
    dimnames(result) <- list(outnames, colnames(m))
    for(j in 1:nv) {
      mj <- m[,j, drop=FALSE]
      denj <- denominator[[j]]
      nncj <- nncorr(X %mark% mj, f=f[[j]], use=use, method=method,
                     denominator=denj)
      kj <- length(nncj)
      result[1:kj,j] <- nncj
    }
    if(all(is.na(result[3, ]))) result <- result[1:2, ]
    return(result)
  }
  # one-dimensional
  m <- m[,1,drop=TRUE]
  # select 'f' appropriately for X
  chk <- check.testfun(f, X=X)
  f     <- chk$f
  ftype <- chk$ftype
  # denominator
  Efmm <-
    if(!is.null(denominator)) denominator else 
    switch(ftype,
           mul={ 
             mean(m)^2
           },
           equ={
             sum(table(m)^2)/length(m)^2
           },
           general={
             mean(outer(m, m, f, ...))
           })
  # border method
  nn <- nnwhich(X)
  ok <- (nndist(X) <= bdist.points(X))
  if(!any(ok))
    stop("Insufficient data")
  mY <- m[nn[ok]]
  mX <- m[ok]
  Efmk <- switch(ftype,
                 mul = {
                   mean(mX * mY, ...)
                 },
                 equ = {
                   mean(mX == mY, ...)
                 }, 
                 general = {
                   mean(f(mX, mY, ...))
                 })
  #
  answer <- c(unnormalised=Efmk,
              normalised=Efmk/Efmm)
  if(ftype == "mul") {
    classic <- cor(mX, mY, use=use, method=method)
    answer <- c(answer, correlation=classic)
  }
  return(answer)
}
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nncross.R"
#
#   nncross.R
#
#
#    $Revision: 1.27 $  $Date: 2014/10/24 00:22:30 $
#
#  Copyright (C) Adrian Baddeley, Jens Oehlschlaegel and Rolf Turner 2000-2012
#  Licence: GNU Public Licence >= 2

nncross <- function(X, Y, ...) {
  UseMethod("nncross")
}

nncross.default <- function(X, Y, ...) {
  X <- as.ppp(X, W=boundingbox)
  nncross(X, Y, ...)
}

nncross.ppp <- function(X, Y, iX=NULL, iY=NULL,
                    what = c("dist", "which"),
                    ...,
                    k = 1,
                    sortby=c("range", "var", "x", "y"),
                    is.sorted.X = FALSE,
                    is.sorted.Y = FALSE) {
  stopifnot(is.ppp(Y) || is.psp(Y))
  sortby <- match.arg(sortby)
  what   <- match.arg(what, choices=c("dist", "which"), several.ok=TRUE)
  want.dist  <- "dist" %in% what 
  want.which <- "which" %in% what
  want.both  <- want.dist && want.which

  if(!missing(k)) {
    # k can be a single integer or an integer vector
    if(length(k) == 0)
      stop("k is an empty vector")
    else if(length(k) == 1) {
      if(k != round(k) || k <= 0)
        stop("k is not a positive integer")
    } else {
      if(any(k != round(k)) || any(k <= 0))
        stop(paste("some entries of the vector",
                   sQuote("k"), "are not positive integers"))
    }
  }
  k <- as.integer(k)
  kmax <- max(k)
  nk <- length(k)

  # trivial cases
  nX <- npoints(X)
  nY <- nobjects(Y)
  # deal with null cases
  if(nX == 0)
    return(as.data.frame(list(dist=matrix(0, nrow=0, ncol=nk),
                which=matrix(0L, nrow=0, ncol=nk))[what]))
  if(nY == 0)
    return(as.data.frame(list(dist=matrix(Inf, nrow=nX, ncol=nk),
                             which=matrix(NA, nrow=nX, ncol=nk))[what]))
  
  # Y is a line segment pattern 
  if(is.psp(Y)) {
    if(!identical(k, 1L))
      stop("Sorry, the case k > 1 is not yet implemented for psp objects")
    return(ppllengine(X,Y,"distance")[, what])
  }

  # Y is a point pattern
  if(is.null(iX) != is.null(iY))
    stop("If one of iX, iY is given, then both must be given")
  exclude <- (!is.null(iX) || !is.null(iY))
  if(exclude) {
    stopifnot(is.integer(iX) && is.integer(iY))
    if(length(iX) != nX)
      stop("length of iX does not match the number of points in X")
    if(length(iY) != nY)
      stop("length of iY does not match the number of points in Y")
  }

  if((is.sorted.X || is.sorted.Y) && !(sortby %in% c("x", "y")))
     stop(paste("If data are already sorted,",
                "the sorting coordinate must be specified explicitly",
                "using sortby = \"x\" or \"y\""))

  # decide whether to sort on x or y coordinate
  switch(sortby,
         range = {
           WY <- as.owin(Y)
           sortby.y <- (diff(WY$xrange) < diff(WY$yrange))
         },
         var = {
           sortby.y <- (var(Y$x) < var(Y$y))
         },
         x={ sortby.y <- FALSE},
         y={ sortby.y <- TRUE}
         )

  # The C code expects points to be sorted by y coordinate.
  if(sortby.y) {
    Xx <- X$x
    Xy <- X$y
    Yx <- Y$x
    Yy <- Y$y
  } else {
    Xx <- X$y
    Xy <- X$x
    Yx <- Y$y
    Yy <- Y$x
  }
  # sort only if needed
  if(!is.sorted.X){
    oX <- fave.order(Xy)
    Xx <- Xx[oX]
    Xy <- Xy[oX]
    if(exclude) iX <- iX[oX]
  }
  if (!is.sorted.Y){
    oY <- fave.order(Yy)
    Yx <- Yx[oY]
    Yy <- Yy[oY]
    if(exclude) iY <- iY[oY]
  }

  # number of neighbours that are well-defined
  kmaxcalc <- min(nY, kmax)
  
  if(kmaxcalc == 1) {
    # ............... single nearest neighbour ..................
    # call C code
    nndv <- if(want.dist) numeric(nX) else numeric(1)
    nnwh <- if(want.which) integer(nX) else integer(1)
    if(!exclude) iX <- iY <- integer(1)

    huge <- 1.1 * diameter(boundingbox(as.rectangle(X), as.rectangle(Y)))

    z <- .C("nnXinterface",
            n1=as.integer(nX),
            x1=as.double(Xx),
            y1=as.double(Xy),
            id1=as.integer(iX),
            n2=as.integer(nY),
            x2=as.double(Yx),
            y2=as.double(Yy),
            id2=as.integer(iY),
            exclude = as.integer(exclude),
            wantdist = as.integer(want.dist),
            wantwhich = as.integer(want.which),
            nnd=as.double(nndv),
            nnwhich=as.integer(nnwh),
            huge=as.double(huge))

    if(want.which) {
      nnwcode <- z$nnwhich #sic. C code now increments by 1
      if(any(uhoh <- (nnwcode == 0))) {
        warning("NA's produced in nncross()$which")
        nnwcode[uhoh] <- NA
      }
    }
  
    # reinterpret in original ordering
    if(is.sorted.X){
      if(want.dist) nndv <- z$nnd
      if(want.which) nnwh <- if(is.sorted.Y) nnwcode else oY[nnwcode]
    } else {
      if(want.dist) nndv[oX] <- z$nnd
      if(want.which) nnwh[oX] <- if(is.sorted.Y) nnwcode else oY[nnwcode]
    }

    if(want.both) return(data.frame(dist=nndv, which=nnwh))
    return(if(want.dist) nndv else nnwh)

  } else {
    # ............... k nearest neighbours ..................
    # call C code
    nndv <- if(want.dist) numeric(nX * kmaxcalc) else numeric(1)
    nnwh <- if(want.which) integer(nX * kmaxcalc) else integer(1)
    if(!exclude) iX <- iY <- integer(1)

    huge <- 1.1 * diameter(boundingbox(as.rectangle(X), as.rectangle(Y)))
  
    z <- .C("knnXinterface",
            n1=as.integer(nX),
            x1=as.double(Xx),
            y1=as.double(Xy),
            id1=as.integer(iX),
            n2=as.integer(nY),
            x2=as.double(Yx),
            y2=as.double(Yy),
            id2=as.integer(iY),
            kmax=as.integer(kmaxcalc),
            exclude = as.integer(exclude),
            wantdist = as.integer(want.dist),
            wantwhich = as.integer(want.which),
            nnd=as.double(nndv),
            nnwhich=as.integer(nnwh),
            huge=as.double(huge))

    # extract results
    nnD <- z$nnd
    nnW <- z$nnwhich
    # map 0 to NA
    if(want.which && any(uhoh <- (nnW == 0))) {
      nnW[uhoh] <- NA
      if(want.dist) nnD[uhoh] <- Inf
    }
    # reinterpret indices in original ordering
    if(!is.sorted.Y) nnW <- oY[nnW]
    # reform as matrices
    NND <- if(want.dist) matrix(nnD, nrow=nX, ncol=kmaxcalc, byrow=TRUE) else 0
    NNW <- if(want.which) matrix(nnW, nrow=nX, ncol=kmaxcalc, byrow=TRUE) else 0
    if(!is.sorted.X){
      # rearrange rows to correspond to original ordering of points
      if(want.dist) NND[oX, ] <- NND
      if(want.which) NNW[oX, ] <- NNW
    }
    # the return value should correspond to the original vector k
    if(kmax > kmaxcalc) {
      # add columns of NA / Inf
      kextra <- kmax - kmaxcalc
      if(want.dist)
        NND <- cbind(NND, matrix(Inf, nrow=nX, ncol=kextra))
      if(want.which)
        NNW <- cbind(NNW, matrix(NA_integer_, nrow=nX, ncol=kextra))
    }
    if(length(k) < kmax) {
      # select only the specified columns
      if(want.dist)
        NND <- NND[, k, drop=TRUE]
      if(want.which)
        NNW <- NNW[, k, drop=TRUE]
    }

    result <- as.data.frame(list(dist=NND, which=NNW)[what])
    colnames(result) <- c(if(want.dist) paste0("dist.", k) else NULL,
                          if(want.which) paste0("which.",k) else NULL)
    if(ncol(result) == 1)
      result <- result[, , drop=TRUE]
    return(result)
  }
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nncross3D.R"
#
#   nncross3D.R
#
#    $Revision: 1.7 $  $Date: 2014/10/24 00:22:30 $
#
#  Copyright (C) Adrian Baddeley, Jens Oehlschlaegel and Rolf Turner 2000-2013
#  Licence: GNU Public Licence >= 2

nncross.pp3 <- function(X, Y, iX=NULL, iY=NULL,
                    what = c("dist", "which"),
                    ...,
                    k = 1,
                    sortby=c("range", "var", "x", "y", "z"),
                    is.sorted.X = FALSE,
                    is.sorted.Y = FALSE) {
  stopifnot(is.pp3(Y))
  sortby <- match.arg(sortby)
  what   <- match.arg(what, choices=c("dist", "which"), several.ok=TRUE)
  want.dist  <- "dist" %in% what 
  want.which <- "which" %in% what
  want.both  <- want.dist && want.which

  if(!missing(k)) {
    # k can be a single integer or an integer vector
    if(length(k) == 0)
      stop("k is an empty vector")
    else if(length(k) == 1) {
      if(k != round(k) || k <= 0)
        stop("k is not a positive integer")
    } else {
      if(any(k != round(k)) || any(k <= 0))
        stop(paste("some entries of the vector",
                   sQuote("k"), "are not positive integers"))
    }
  }
  k <- as.integer(k)
  kmax <- max(k)
  nk <- length(k)

  # trivial cases
  nX <- npoints(X)
  nY <- nobjects(Y)
  # deal with null cases
  if(nX == 0)
    return(as.data.frame(list(dist=matrix(0, nrow=0, ncol=nk),
                which=matrix(0L, nrow=0, ncol=nk))[what]))
  if(nY == 0)
    return(as.data.frame(list(dist=matrix(Inf, nrow=nX, ncol=nk),
                             which=matrix(NA, nrow=nX, ncol=nk))[what]))
  
  if(is.null(iX) != is.null(iY))
    stop("If one of iX, iY is given, then both must be given")
  exclude <- (!is.null(iX) || !is.null(iY))
  if(exclude) {
    stopifnot(is.integer(iX) && is.integer(iY))
    if(length(iX) != nX)
      stop("length of iX does not match the number of points in X")
    if(length(iY) != nY)
      stop("length of iY does not match the number of points in Y")
  }

  if((is.sorted.X || is.sorted.Y) && !(sortby %in% c("x", "y", "z")))
     stop(paste("If data are already sorted,",
                "the sorting coordinate must be specified explicitly",
                "using sortby = \"x\" or \"y\" or \"z\""))

  # decide which coordinate to sort on
  switch(sortby,
         range = {
           s <- sidelengths(as.box3(Y))
           sortcoord <- c("x", "y", "z")[which.min(s)]
         },
         var = {
           v <- apply(coords(Y), 2, var)
           sortcoord <- c("x", "y", "z")[which.min(v)]           
         },
         x={ sortcoord <- "x" },
         y={ sortcoord <- "y" },
         z={ sortcoord <- "z" }
         )

  # The C code expects points to be sorted by z coordinate.
  XX <- coords(X)
  YY <- coords(Y)
  switch(sortcoord,
         x = {
           # rotate x axis to z axis
           XX <- XX[, c(3,2,1)]
           YY <- YY[, c(3,2,1)]
         },
         y = {
           # rotate y axis to z axis
           XX <- XX[, c(3,1,2)]
           YY <- YY[, c(3,1,2)]
         },
         z = { })

  # sort only if needed
  if(!is.sorted.X){
    oX <- fave.order(XX[,3])
    XX <- XX[oX, , drop=FALSE]
    if(exclude) iX <- iX[oX]
  }
  if (!is.sorted.Y){
    oY <- fave.order(YY[,3])
    YY <- YY[oY, , drop=FALSE]
    if(exclude) iY <- iY[oY]
  }

  # number of neighbours that are well-defined
  kmaxcalc <- min(nY, kmax)
  
  if(kmaxcalc == 1) {
    # ............... single nearest neighbour ..................
    # call C code
    nndv <- if(want.dist) numeric(nX) else numeric(1)
    nnwh <- if(want.which) integer(nX) else integer(1)
    if(!exclude) iX <- iY <- integer(1)

    huge <- 1.1 * diameter(bounding.box3(as.box3(X),as.box3(Y)))
  
    z <- .C("nnX3Dinterface",
            n1=as.integer(nX),
            x1=as.double(XX[,1]),
            y1=as.double(XX[,2]),
            z1=as.double(XX[,3]),
            id1=as.integer(iX),
            n2=as.integer(nY),
            x2=as.double(YY[,1]),
            y2=as.double(YY[,2]),
            z2=as.double(YY[,3]),
            id2=as.integer(iY),
            exclude = as.integer(exclude),
            wantdist = as.integer(want.dist),
            wantwhich = as.integer(want.which),
            nnd=as.double(nndv),
            nnwhich=as.integer(nnwh),
            huge=as.double(huge))

    if(want.which) {
      # conversion to R indexing is done in C code
      nnwcode <- z$nnwhich
      if(any(uhoh <- (nnwcode == 0))) {
        warning("Internal error: NA's produced in nncross()$which")
        nnwcode[uhoh] <- NA
      }
    }
  
    # reinterpret in original ordering
    if(is.sorted.X){
      if(want.dist) nndv <- z$nnd
      if(want.which) nnwh <- if(is.sorted.Y) nnwcode else oY[nnwcode]
    } else {
      if(want.dist) nndv[oX] <- z$nnd
      if(want.which) nnwh[oX] <- if(is.sorted.Y) nnwcode else oY[nnwcode]
    }

    if(want.both) return(data.frame(dist=nndv, which=nnwh))
    return(if(want.dist) nndv else nnwh)

  } else {
    # ............... k nearest neighbours ..................
    # call C code
    nndv <- if(want.dist) numeric(nX * kmaxcalc) else numeric(1)
    nnwh <- if(want.which) integer(nX * kmaxcalc) else integer(1)
    if(!exclude) iX <- iY <- integer(1)
    huge <- 1.1 * diameter(bounding.box3(as.box3(X),as.box3(Y)))
  
    z <- .C("knnX3Dinterface",
            n1=as.integer(nX),
            x1=as.double(XX[,1]),
            y1=as.double(XX[,2]),
            z1=as.double(XX[,3]),
            id1=as.integer(iX),
            n2=as.integer(nY),
            x2=as.double(YY[,1]),
            y2=as.double(YY[,2]),
            z2=as.double(YY[,3]),
            id2=as.integer(iY),
            kmax=as.integer(kmaxcalc),
            exclude = as.integer(exclude),
            wantdist = as.integer(want.dist),
            wantwhich = as.integer(want.which),
            nnd=as.double(nndv),
            nnwhich=as.integer(nnwh),
            huge=as.double(huge))

    # extract results
    nnD <- z$nnd
    nnW <- z$nnwhich
    # map 0 to NA
    if(want.which && any(uhoh <- (nnW == 0))) {
      nnW[uhoh] <- NA
      if(want.dist) nnD[uhoh] <- Inf
    }
    # reinterpret indices in original ordering
    if(!is.sorted.Y) nnW <- oY[nnW]
    # reform as matrices
    NND <- if(want.dist) matrix(nnD, nrow=nX, ncol=kmaxcalc, byrow=TRUE) else 0
    NNW <- if(want.which) matrix(nnW, nrow=nX, ncol=kmaxcalc, byrow=TRUE) else 0
    if(!is.sorted.X){
      # rearrange rows to correspond to original ordering of points
      if(want.dist) NND[oX, ] <- NND
      if(want.which) NNW[oX, ] <- NNW
    }
    # the return value should correspond to the original vector k
    if(kmax > kmaxcalc) {
      # add columns of NA / Inf
      kextra <- kmax - kmaxcalc
      if(want.dist)
        NND <- cbind(NND, matrix(Inf, nrow=nX, ncol=kextra))
      if(want.which)
        NNW <- cbind(NNW, matrix(NA_integer_, nrow=nX, ncol=kextra))
    }
    if(length(k) < kmax) {
      # select only the specified columns
      if(want.dist)
        NND <- NND[, k, drop=TRUE]
      if(want.which)
        NNW <- NNW[, k, drop=TRUE]
    }

    result <- as.data.frame(list(dist=NND, which=NNW)[what])
    if(ncol(result) == 1)
      result <- result[, , drop=TRUE]
    return(result)
  }
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nndensity.R"
#
#  nndensity.R
#
#  Density estimation based on nn distance
#
#  $Revision: 1.3 $  $Date: 2014/10/24 00:22:30 $
#

nndensity <- function(x, ...) {
  UseMethod("nndensity")
}

nndensity.ppp <- function(x, k, ..., verbose=TRUE) {
  if(missing(k) || is.null(k)) {
    k <- round(sqrt(npoints(x)))
    if(verbose) cat(paste("k=", k, "\n"))
  } else if(k == 1) warning("k=1 will produce strange results")
  # distance to k-th nearest neighbour
  D <- nnmap(x, k=k, what="dist", ...)
  # area searched
  A <- eval.im(pi * D^2)
  # distance to boundary
  B <- bdist.pixels(as.owin(D))
  # handle edge effects
  edge <- solutionset(B < D)
  # centres of all pixels where edge effect occurs
  xy <- rasterxy.mask(edge, drop=TRUE)
  # corresponding values of distance
  rr <- D[edge, drop=TRUE]
  # compute actual search area
  X <- as.ppp(xy, W=as.owin(x), check=FALSE)
  A[edge] <- discpartarea(X, matrix(rr, ncol=1))
  # finally compute intensity estimate
  L <- eval.im(k/A)
  return(L)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nndist.R"
#
#   nndist.R
#
#   nearest neighbour distances (nndist) and identifiers (nnwhich)
#
#   $Revision: 1.6 $ $Date: 2014/10/24 00:22:30 $
#

nndist <- function(X, ...) {
  UseMethod("nndist")
}

nndist.ppp <- local({

  nndist.ppp <- function(X, ..., k=1, by=NULL, method="C") {
    verifyclass(X, "ppp")
    trap.extra.arguments(..., .Context="In nndist.ppp")
    if(is.null(by)) # usual case
      return(nndist.default(X$x, X$y, k=k, by=by, method=method))
    return(nndistby(X, k=k, by=by))
  }

  nndistby <- function(X, k, by) {
    # split by factor 
    idX <- seq_len(npoints(X))
    Y <- split(X %mark% idX, f=by, un=FALSE)
    distY <- lapply(Y, nndistsub, XX=X, iX=idX, k=k)
    result <- do.call("cbind", distY)
    return(result)
  }

  nndistsub <- function(Z, XX, iX, k) {
    nncross(XX, Z, iX=iX, iY=marks(Z), k=k, what="dist")
  }

  nndist.ppp
})

nndist.default <-
  function(X, Y=NULL, ..., k=1, by=NULL, method="C")
{
	#  computes the vector of nearest-neighbour distances 
	#  for the pattern of points (x[i],y[i])
	#
  xy <- xy.coords(X,Y)[c("x","y")]
  x <- xy$x
  y <- xy$y

  # validate
  n <- length(x)
  if(length(y) != n)
    stop("lengths of x and y do not match")
  
  # other arguments ignored
  trap.extra.arguments(..., .Context="In nndist.default")

  # split by factor ?
  if(!is.null(by)) {
    X <- as.ppp(xy, W=boundingbox)
    return(nndist(X, by=by, k=k))
  }
  
  # k can be a single integer or an integer vector
  if(length(k) == 0)
    stop("k is an empty vector")
  else if(length(k) == 1) {
    if(k != round(k) || k <= 0)
      stop("k is not a positive integer")
  } else {
    if(any(k != round(k)) || any(k <= 0))
      stop(paste("some entries of the vector",
           sQuote("k"), "are not positive integers"))
  }
  k <- as.integer(k)
  kmax <- max(k)

  # trivial cases
  if(n <= 1) {
    # empty pattern => return numeric(0)
    # or pattern with only 1 point => return Inf
    nnd <- matrix(Inf, nrow=n, ncol=kmax)
    nnd <- nnd[,k, drop=TRUE]
    return(nnd)
  }
  
  # number of neighbours that are well-defined
  kmaxcalc <- min(n-1, kmax)

  # calculate k-nn distances for k <= kmaxcalc
  
  if(kmaxcalc == 1) {
    # calculate nearest neighbour distance only
    switch(method,
         interpreted={
           #  matrix of squared distances between all pairs of points
           sq <- function(a, b) { (a-b)^2 }
           squd <-  outer(x, x, sq) + outer(y, y, sq)
           #  reset diagonal to a large value so it is excluded from minimum
           diag(squd) <- Inf
           #  nearest neighbour distances
           nnd <- sqrt(apply(squd,1,min))
         },
         C={
           nnd<-numeric(n)
           o <- fave.order(y)
           big <- sqrt(.Machine$double.xmax)
           z<- .C("nndistsort",
                  n= as.integer(n),
                  x= as.double(x[o]), y= as.double(y[o]), nnd= as.double(nnd),
                  as.double(big))
           nnd[o] <- z$nnd
         },
         stop(paste("Unrecognised method", sQuote(method)))
         )
  } else {
    # case kmaxcalc > 1
    switch(method,
           interpreted={
             if(n <= 1000) {
               # form n x n matrix of squared distances
               D2 <- pairdist.default(x, y, method=method, squared=TRUE)
               # find k'th smallest squared distance
               diag(D2) <- Inf
               NND2 <- t(apply(D2, 1, sort))[, 1:kmaxcalc]
               nnd <- sqrt(NND2)
             } else {
               # avoid creating huge matrix
               # handle one row of D at a time
               NND2 <- matrix(numeric(n * kmaxcalc), nrow=n, ncol=kmaxcalc)
               for(i in seq_len(n)) {
                 D2i <- (x - x[i])^2 + (y - y[i])^2
                 D2i[i] <- Inf
                 NND2[i,] <- sort(D2i)[1:kmaxcalc]
               }
               nnd <- sqrt(NND2)
             }
           },
           C={
             nnd<-numeric(n * kmaxcalc)
             o <- fave.order(y)
             big <- sqrt(.Machine$double.xmax)
             z<- .C("knndsort",
                    n    = as.integer(n),
                    kmax = as.integer(kmaxcalc),
                    x    = as.double(x[o]),
                    y    = as.double(y[o]),
                    nnd  = as.double(nnd),
                    huge = as.double(big))
             nnd <- matrix(nnd, nrow=n, ncol=kmaxcalc)
             nnd[o, ] <- matrix(z$nnd, nrow=n, ncol=kmaxcalc, byrow=TRUE)
           },
           stop(paste("Unrecognised method", sQuote(method)))
           )
  }

  # post-processing
  if(kmax > kmaxcalc) {
    # add columns of Inf
    infs <- matrix(Inf, nrow=n, ncol=kmax-kmaxcalc)
    nnd <- cbind(nnd, infs)
  }

  if(kmax > 1)
    colnames(nnd) <- paste0("dist.", 1:kmax)
  
  if(length(k) < kmax) {
    # select only the specified columns
    nnd <- nnd[, k, drop=TRUE]
  }
  
  return(nnd)
}


nnwhich <- function(X, ...) {
  UseMethod("nnwhich")
}

nnwhich.ppp <- local({

  nnwhich.ppp <- function(X, ..., k=1, by=NULL, method="C") {
    verifyclass(X, "ppp")
    trap.extra.arguments(..., .Context="In nnwhich.ppp")
    if(is.null(by))
      return(nnwhich.default(X$x, X$y, k=k, method=method))
    return(nnwhichby(X, k=k, by=by))
  }

  nnwhichby <- function(X, k, by) {
    # split by factor 
    idX <- seq_len(npoints(X))
    Y <- split(X %mark% idX, f=by, un=FALSE)
    whichY <- lapply(Y, nnwhichsub, XX=X, iX=idX, k=k)
    result <- do.call("cbind", whichY)
    return(result)
  }

  nnwhichsub <- function(Z, XX, iX, k) {
    # marks(Z) gives original serial numbers of subset Z
    iY <- marks(Z)
    Zid <- nncross(XX, Z, iX=iX, iY=iY, k=k, what="which")
    nk <- length(k)
    if(nk == 1) {
      Yid <- iY[Zid]
    } else {
      Zid <- as.vector(as.matrix(Zid))
      Yid <- iY[Zid]
      Yid <- data.frame(which=matrix(Yid, ncol=nk))
    }
    return(Yid)
  }

  nnwhich.ppp
})


nnwhich.default <-
  function(X, Y=NULL, ..., k=1, by=NULL, method="C")
{
	#  identifies nearest neighbour of each point in
	#  the pattern of points (x[i],y[i])
	#
  xy <- xy.coords(X,Y)[c("x","y")]
  x <- xy$x
  y <- xy$y

  # validate
  n <- length(x)
  if(length(y) != n)
    stop("lengths of x and y do not match")
  
  # other arguments ignored
  trap.extra.arguments(..., .Context="In nnwhich.default")

  # split by factor ?
  if(!is.null(by)) {
    X <- as.ppp(xy, W=boundingbox)
    return(nnwhich(X, by=by, k=k))
  }
  
  # k can be a single integer or an integer vector
  if(length(k) == 0)
    stop("k is an empty vector")
  else if(length(k) == 1) {
    if(k != round(k) || k <= 0)
      stop("k is not a positive integer")
  } else {
    if(any(k != round(k)) || any(k <= 0))
      stop(paste("some entries of the vector",
           sQuote("k"), "are not positive integers"))
  }
  k <- as.integer(k)
  kmax <- max(k)

  # special cases
  if(n <= 1) {
    # empty pattern => return integer(0)
    # or pattern with only 1 point => return NA
    nnw <- matrix(as.integer(NA), nrow=n, ncol=kmax)
    nnw <- nnw[,k, drop=TRUE]
    return(nnw)
  }

  # number of neighbours that are well-defined
  kmaxcalc <- min(n-1, kmax)

  # identify k-nn for k <= kmaxcalc

  if(kmaxcalc == 1) {
    # identify nearest neighbour only
    switch(method,
           interpreted={
             #  matrix of squared distances between all pairs of points
             sq <- function(a, b) { (a-b)^2 }
             squd <-  outer(x, x, sq) + outer(y, y, sq)
             #  reset diagonal to a large value so it is excluded from minimum
             diag(squd) <- Inf
             #  nearest neighbours
             nnw <- apply(squd,1,which.min)
           },
           C={
             nnw <- integer(n)
             o <- fave.order(y)
             big <- sqrt(.Machine$double.xmax)
             z<- .C("nnwhichsort",
                    n = as.integer(n),
                    x = as.double(x[o]),
                    y = as.double(y[o]),
                    nnwhich = as.integer(nnw),
                    huge = as.double(big))
             witch <- z$nnwhich # sic 
             if(any(witch <= 0))
               stop("Internal error: non-positive index returned from C code")
             if(any(witch > n))
               stop("Internal error: index returned from C code exceeds n")
             nnw[o] <- o[witch]
           },
           stop(paste("Unrecognised method", sQuote(method)))
           )
  } else {
    # case kmaxcalc > 1
    switch(method,
           interpreted={
             if(n <= 1000) {
               # form n x n matrix of squared distances
               D2 <- pairdist.default(x, y, method=method, squared=TRUE)
               # find k'th smallest squared distance
               diag(D2) <- Inf
               nnw <- t(apply(D2, 1, fave.order))[, 1:kmaxcalc]
             } else {
               # avoid creating huge matrix
               # handle one row of D at a time
               nnw <- matrix(as.integer(NA), nrow=n, ncol=kmaxcalc)
               for(i in seq_len(n)) {
                 D2i <- (x - x[i])^2 + (y - y[i])^2
                 D2i[i] <- Inf
                 nnw[i,] <- fave.order(D2i)[1:kmaxcalc]
               }      
             }
           },
           C={
             nnw <- matrix(integer(n * kmaxcalc), nrow=n, ncol=kmaxcalc)
             o <- fave.order(y)
             big <- sqrt(.Machine$double.xmax)
             z<- .C("knnsort",
                    n = as.integer(n),
                    kmax = as.integer(kmaxcalc),
                    x = as.double(x[o]),
                    y = as.double(y[o]),
                    nnd = as.double(numeric(n * kmaxcalc)),
                    nnwhich = as.integer(nnw),
                    huge = as.double(big))
             witch <- z$nnwhich # sic
             witch <- matrix(witch, nrow=n, ncol=kmaxcalc, byrow=TRUE)
             if(any(witch <= 0))
               stop("Internal error: non-positive index returned from C code")
             if(any(witch > n))
               stop("Internal error: index returned from C code exceeds n")
             # convert back to original ordering
             nnw[o,] <- matrix(o[witch], nrow=n, ncol=kmaxcalc)
           },
           stop(paste("Unrecognised method", sQuote(method)))
           )
  }
  
  # post-processing
  if(kmax > kmaxcalc) {
    # add columns of NA's
    nas <- matrix(as.numeric(NA), nrow=n, ncol=kmax-kmaxcalc)
    nnw <- cbind(nnw, nas)
  }

  if(kmax > 1)
    colnames(nnw) <- paste0("which.", 1:kmax)

  if(length(k) < kmax) {
    # select only the specified columns
    nnw <- nnw[, k, drop=TRUE]
  }
  return(nnw)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nndistlpp.R"
#
# nndistlpp.R
#
#  $Revision: 1.4 $ $Date: 2014/11/10 12:08:48 $
#
# Methods for nndist, nnwhich, nncross for linear networks
#
# nndist.lpp
#   Calculates the nearest neighbour distances in the shortest-path metric
#   for a point pattern on a linear network.

nndist.lpp <- function(X, ..., method="C") {
  stopifnot(inherits(X, "lpp"))
  stopifnot(method %in% c("C", "interpreted"))
  #
  L <- X$domain
  Y <- as.ppp(X)
  n <- npoints(Y)
  #
  Lseg  <- L$lines
  Lvert <- L$vertices
  from  <- L$from
  to    <- L$to
  dpath <- L$dpath

  if(n == 0) return(numeric(0))
  if(n == 1) return(NA)
  
  # find nearest segment for each point
  # This is given by local coordinates, if available (spatstat >= 1.28-0)
  loco <- coords(X, local=TRUE, spatial=FALSE, temporal=FALSE)
  pro <- if(!is.null(seg <- loco$seg)) seg else nearestsegment(X, Lseg)

  if(method == "interpreted") {
    D <- pairdist(X, method="interpreted")
    diag(D) <- Inf
    return(apply(D, 1, min))
  } else {
    # C code
    # convert indices to start at 0
    from0 <- from - 1L
    to0   <- to - 1L
    segmap <- pro - 1L
    # upper bound on interpoint distance
    huge <- max(dpath) + 2 * max(lengths.psp(Lseg))
    # space for result
    ans <- double(n)
    # call C
    zz <- .C("linnndist",
             np = as.integer(n),
             xp = as.double(Y$x),
             yp = as.double(Y$y),
             nv = as.integer(Lvert$n),
             xv = as.double(Lvert$x),
             yv = as.double(Lvert$y),
             ns = as.double(L$n),
             from = as.integer(from0),
             to = as.integer(to0),
             dpath = as.double(dpath),
             segmap = as.integer(segmap),
             huge = as.double(huge),
             answer = as.double(ans))
    ans <- zz$answer
  }
  return(ans)
}

# nnwhich.lpp
# Identifies the nearest neighbours in the shortest-path metric
# for a point pattern on a linear network.
#

nnwhich.lpp <- function(X, ..., method="C") {
  stopifnot(inherits(X, "lpp"))
  stopifnot(method %in% c("C", "interpreted"))
  #
  L <- X$domain
  Y <- as.ppp(X)
  n <- npoints(Y)
  #
  Lseg  <- L$lines
  Lvert <- L$vertices
  from  <- L$from
  to    <- L$to
  dpath <- L$dpath
  
  if(n == 0) return(integer(0))
  if(n == 1) return(as.integer(NA))
  
  # find nearest segment for each point
  # This is given by local coordinates, if available (spatstat >= 1.28-0)
  loco <- coords(X, local=TRUE, spatial=FALSE, temporal=FALSE)
  pro <- loco$seg %orifnull% nearestsegment(X, L$lines)

  if(method == "interpreted") {
    D <- pairdist(X, method="interpreted")
    diag(D) <- Inf
    return(apply(D, 1, which.min))
  } else {
    # C code
    # convert indices to start at 0
    from0 <- from - 1
    to0   <- to - 1
    segmap <- pro - 1
    # upper bound on interpoint distance
    huge <- max(dpath) + 2 * max(lengths.psp(Lseg))
    # space for result
    nnd <- double(n)
    nnw <- integer(n)
    # call C
    zz <- .C("linnnwhich",
             np = as.integer(n),
             xp = as.double(Y$x),
             yp = as.double(Y$y),
             nv = as.integer(Lvert$n),
             xv = as.double(Lvert$x),
             yv = as.double(Lvert$y),
             ns = as.double(L$n),
             from = as.integer(from0),
             to = as.integer(to0),
             dpath = as.double(dpath),
             segmap = as.integer(segmap),
             huge = as.double(huge),
             nndist = as.double(nnd),
             nnwhich = as.integer(nnw))
    # convert C indexing to R indexing
    nnw <- zz$nnwhich + 1L
    # any zeroes occur if points have no neighbours.
    nnw[nnw == 0] <- NA
  }
  return(nnw)
}

# nncross.lpp
# Identifies the nearest neighbours in the shortest-path metric
# from one point pattern on a linear network to ANOTHER pattern
# on the SAME network.
#

nncross.lpp <- function(X, Y, iX=NULL, iY=NULL, what = c("dist", "which"), ..., method="C") {
  stopifnot(inherits(X, "lpp"))
  stopifnot(inherits(Y, "lpp"))
  what   <- match.arg(what, choices=c("dist", "which"), several.ok=TRUE)
  stopifnot(method %in% c("C", "interpreted"))
  check <- resolve.defaults(list(...), list(check=TRUE))$check
  #
  L <- as.linnet(X)
  if(check && !identical(L, as.linnet(Y))) 
    stop("X and Y are on different linear networks")
  #
  nX <- npoints(X)
  nY <- npoints(Y)
  P <- as.ppp(X)
  Q <- as.ppp(Y)
  #
  Lseg  <- L$lines
  Lvert <- L$vertices
  from  <- L$from
  to    <- L$to
  dpath <- L$dpath
  
  # deal with null cases
  if(nX == 0)
    return(data.frame(dist=numeric(0), which=integer(0))[, what])
  if(nY == 0)
    return(data.frame(dist=rep(Inf, nX), which=rep(NA_integer_, nX))[, what])

  # find nearest segment for each point
  Xpro <- coords(X, local=TRUE, spatial=FALSE, temporal=FALSE)$seg
  Ypro <- coords(Y, local=TRUE, spatial=FALSE, temporal=FALSE)$seg

  # handle serial numbers
  if(is.null(iX) != is.null(iY))
    stop("If one of iX, iY is given, then both must be given")
  exclude <- (!is.null(iX) || !is.null(iY))
  if(exclude) {
    stopifnot(is.integer(iX) && is.integer(iY))
    if(length(iX) != nX)
      stop("length of iX does not match the number of points in X")
    if(length(iY) != nY)
      stop("length of iY does not match the number of points in Y")
  }

  if(method == "interpreted") {
    D <- crossdist(X, method="interpreted")
    if(exclude)
      D[outer(iX, iY, "==")] <- Inf
    nnd <- if("dist" %in% what) apply(D, 1, min) else NA
    nnw <- if("which" %in% what) apply(D, 1, which.min) else NA
  } else {
    # C code
    # convert indices to start at 0
    from0 <- from - 1
    to0   <- to - 1
    Xsegmap <- Xpro - 1
    Ysegmap <- Ypro - 1
    # upper bound on interpoint distance
    huge <- max(dpath) + 2 * diameter(as.rectangle(as.owin(L)))
    # space for result
    nnd <- double(nX)
    nnw <- integer(nX)
    # call C
    if(!exclude) {
      zz <- .C("linndcross",
               np = as.integer(nX),
               xp = as.double(P$x),
               yp = as.double(P$y),
               nq = as.integer(nY),
               xq = as.double(Q$x),
               yq = as.double(Q$y),
               nv = as.integer(Lvert$n),
               xv = as.double(Lvert$x),
               yv = as.double(Lvert$y),
               ns = as.double(L$n),
               from = as.integer(from0),
               to = as.integer(to0),
               dpath = as.double(dpath),
               psegmap = as.integer(Xsegmap),
               qsegmap = as.integer(Ysegmap),
               huge = as.double(huge),
               nndist = as.double(nnd),
               nnwhich = as.integer(nnw))
    } else {
      zz <- .C("linndxcross",
               np = as.integer(nX),
               xp = as.double(P$x),
               yp = as.double(P$y),
               nq = as.integer(nY),
               xq = as.double(Q$x),
               yq = as.double(Q$y),
               nv = as.integer(Lvert$n),
               xv = as.double(Lvert$x),
               yv = as.double(Lvert$y),
               ns = as.double(L$n),
               from = as.integer(from0),
               to = as.integer(to0),
               dpath = as.double(dpath),
               psegmap = as.integer(Xsegmap),
               qsegmap = as.integer(Ysegmap),
               idP = as.integer(iX),
               idQ = as.integer(iY),
               huge = as.double(huge),
               nndist = as.double(nnd),
               nnwhich = as.integer(nnw))
    }
    nnd <- zz$nndist
    # convert C indexing to R indexing
    nnw <- zz$nnwhich + 1L
    # any zeroes occur if points have no neighbours.
    nnw[nnw == 0] <- NA
  }
  result <- data.frame(dist=nnd, which=nnw)[, what]
  return(result)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nnfun.R"
#
#   nnfun.R
#
#   nearest neighbour function (returns a function of x,y)
#
#   $Revision: 1.5 $   $Date: 2014/10/24 00:22:30 $
#

nnfun <- function(X, ...) {
  UseMethod("nnfun")
}

nnfun.ppp <- function(X, ..., k=1) {
  # this line forces X to be bound
  stopifnot(is.ppp(X))
  if(length(k) != 1) stop("k should be a single integer")
  g <- function(x,y=NULL) {
    Y <- xy.coords(x, y)[c("x", "y")]
    nncross(Y, X, what="which", k=k)
  }
  attr(g, "Xclass") <- "ppp"
  g <- funxy(g, as.rectangle(as.owin(X)))
  class(g) <- c("nnfun", class(g))
  return(g)
}

nnfun.psp <- function(X, ...) {
  # this line forces X to be bound
  stopifnot(is.psp(X))
  g <- function(x,y=NULL) {
    Y <-  xy.coords(x, y)[c("x", "y")]
    nncross(Y, X, what="which")
  }
  attr(g, "Xclass") <- "psp"
  g <- funxy(g, as.rectangle(as.owin(X)))
  class(g) <- c("nnfun", class(g))
  return(g)
}

as.owin.nnfun <- function(W, ..., fatal=TRUE) {
  X <- get("X", envir=environment(W))
  as.owin(X, ..., fatal=fatal)
}

domain.nnfun <- Window.nnfun <- function(X, ...) { as.owin(X) }

as.im.nnfun <- function(X, W=NULL, ...,
                           eps=NULL, dimyx=NULL, xy=NULL,
                           na.replace=NULL) {
  if(is.null(W)) {
    env <- environment(X)
    Xdata  <- get("X", envir=env)
    k <- mget("k", envir=env, inherits=FALSE, ifnotfound=list(1))[[1]]
    Z <- nnmap(Xdata, k=k, what="which", eps=eps, dimyx=dimyx, xy=xy)
    if(!is.null(na.replace))
      Z$v[is.null(Z$v)] <- na.replace
    return(Z)
  }
  # use as.im.function
  NextMethod("as.im")
}

print.nnfun <- function(x, ...) {
  env <- environment(x)
  X <- get("X", envir=env)
  k <- mget("k", envir=env, inherits=FALSE, ifnotfound=list(1))[[1]]
  xtype <- attr(x, "Xclass")
  typestring <- switch(xtype,
                       ppp="point pattern",
                       psp="line segment pattern",
                       paste("object of class", sQuote(xtype)))
  Kth <- if(k == 1) "Nearest" else paste0(ordinal(k), "-Nearest")
  cat(paste(Kth, "Neighbour Index function for ", typestring, "\n"))
  print(X)
  return(invisible(NULL))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nnfunlpp.R"
#
# nnfunlpp.R
#
#   method for 'nnfun' for class 'lpp'
#
#   $Revision: 1.1 $ $Date: 2014/10/24 00:22:30 $
#

nnfun.lpp <- local({

  nnfun.lpp <- function(X, ...) {
    stopifnot(inherits(X, "lpp"))
    force(X)
    L <- as.linnet(X)
    f <- function(x, y=NULL, seg=NULL, tp=NULL, ...) {
      # L is part of the environment
      Y <- as.lpp(x=x, y=y, seg=seg, tp=tp, L=L)
      i <- nncross.lpp(Y, X, what="which")
      return(i)
    }
    f <- linfun(f, L)
    attr(f, "explain") <- uitleggen
    return(f)
  }

  uitleggen <- function(x, ...) {
    cat("Nearest neighbour function for lpp object\n")
    X <-  get("X", envir=environment(x))
    print(X)
  }

  nnfun.lpp
})


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nnmap.R"
#
#  nnmap.R
#
#    nearest or k-th nearest neighbour of each pixel
#
#  $Revision: 1.7 $  $Date: 2014/10/24 00:22:30 $
#

nnmap <- function(X, k=1, what = c("dist", "which"), ...,
                  W=as.owin(X),
                  is.sorted.X=FALSE,
                  sortby=c("range", "var", "x", "y")) {
  stopifnot(is.ppp(X))
  sortby <- match.arg(sortby)
  outputarray <- resolve.1.default("outputarray", ..., outputarray=FALSE)
  
  W <- as.owin(W)
  huge <- 1.1 * diameter(boundingbox(as.rectangle(X), as.rectangle(W)))
  
  what   <- match.arg(what, choices=c("dist", "which"), several.ok=TRUE)
  want.dist  <- "dist" %in% what 
  want.which <- "which" %in% what
  want.both  <- want.dist && want.which

  if(!missing(k)) {
    # k can be a single integer or an integer vector
    if(length(k) == 0)
      stop("k is an empty vector")
    else if(length(k) == 1) {
      if(k != round(k) || k <= 0)
        stop("k is not a positive integer")
    } else {
      if(any(k != round(k)) || any(k <= 0))
        stop(paste("some entries of the vector",
                   sQuote("k"), "are not positive integers"))
    }
  }
  k <- as.integer(k)
  kmax <- max(k)
  nk <- length(k)

  # note whether W is `really' a rectangle
  isrect <- is.rectangle(rescue.rectangle(W))

  # set up pixel array
  M <- do.call.matched("as.mask",
                       resolve.defaults(list(...), list(w=W)))
  Mdim <- M$dim
  nxcol <- Mdim[2]
  nyrow <- Mdim[1]
  npixel <- nxcol * nyrow
  
  nX <- npoints(X)
  if(nX == 0) {
    # trivial - avoid potential problems in C code
    NND <- if(want.dist) array(Inf, dim=c(nk, Mdim)) else 0
    NNW <- if(want.which) array(NA_integer_, dim=c(nk, Mdim)) else 0
  } else {
    # usual case 
    if(is.sorted.X && !(sortby %in% c("x", "y")))
      stop(paste("If data are already sorted,",
                 "the sorting coordinate must be specified explicitly",
                 "using sortby = \"x\" or \"y\""))

    # decide whether to sort on x or y coordinate
    switch(sortby,
           range = {
             s <- sidelengths(as.rectangle(X))
             sortby.y <- (s[1] < s[2])
           },
           var = {
             sortby.y <- (var(X$x) < var(X$y))
           },
           x={ sortby.y <- FALSE},
           y={ sortby.y <- TRUE}
           )

    # The C code expects points to be sorted by x coordinate.
    if(sortby.y) {
      oldM <- M
      X <- flipxy(X)
      W <- flipxy(W)
      M <- flipxy(M)
      Mdim <- M$dim
    }
    xx <- X$x
    yy <- X$y
    # sort only if needed
    if(!is.sorted.X){
      oX <- fave.order(xx)
      xx <- xx[oX]
      yy <- yy[oX]
    }

    # number of neighbours that are well-defined
    kmaxcalc <- min(nX, kmax)

    # prepare to call C code
    nndv <- if(want.dist) numeric(npixel * kmaxcalc) else numeric(1)
    nnwh <- if(want.which) integer(npixel * kmaxcalc) else integer(1)

    # ............. call C code ............................
    
    if(kmaxcalc == 1) {
      zz <- .C("nnGinterface",
               nx = as.integer(nxcol),
               x0 = as.double(M$xcol[1]),
               xstep = as.double(M$xstep),
               ny = as.integer(nyrow),
               y0 = as.double(M$yrow[1]),
               ystep = as.double(M$ystep),
               np = as.integer(nX),
               xp = as.double(xx),
               yp = as.double(yy),
               wantdist = as.integer(want.dist),
               wantwhich = as.integer(want.which),
               nnd = as.double(nndv),
               nnwhich = as.integer(nnwh),
               huge = as.double(huge))
    } else {
      zz <- .C("knnGinterface",
               nx = as.integer(nxcol),
               x0 = as.double(M$xcol[1]),
               xstep = as.double(M$xstep),
               ny = as.integer(nyrow),
               y0 = as.double(M$yrow[1]),
               ystep = as.double(M$ystep),
               np = as.integer(nX),
               xp = as.double(xx),
               yp = as.double(yy),
               kmax = as.integer(kmaxcalc),
               wantdist = as.integer(want.dist),
               wantwhich = as.integer(want.which),
               nnd = as.double(nndv),
               nnwhich = as.integer(nnwh),
               huge = as.double(huge))
    }
    
    # extract results
    nnW <- zz$nnwhich
    nnD <- zz$nnd
    # map index 0 to NA
    if(want.which && any(uhoh <- (nnW == 0))) {
      nnW[uhoh] <- NA
      if(want.dist) nnD[uhoh] <- Inf
    }
    # reinterpret indices in original ordering
    if(!is.sorted.X) nnW <- oX[nnW]
  
    # reform as arrays 
    NND <- if(want.dist) array(nnD, dim=c(kmaxcalc, Mdim)) else 0
    NNW <- if(want.which) array(nnW, dim=c(kmaxcalc, Mdim)) else 0
    if(sortby.y) {
      # flip x and y back again
      if(want.dist) NND <- aperm(NND, c(1, 3, 2))
      if(want.which) NNW <- aperm(NNW, c(1, 3, 2))
      M <- oldM
      Mdim <- dim(M)
    }
    
    # the return value should correspond to the original vector k
    if(kmax > kmaxcalc) {
      # pad with NA / Inf
      if(want.dist) {
        NNDcalc <- NND
        NND <- array(Inf, dim=c(kmax, Mdim))
        NND[1:kmaxcalc, , ] <- NNDcalc
      }
      if(want.which) {
        NNWcalc <- NNW
        NNW <- array(NA_integer_, dim=c(kmax, Mdim))
        NNW[1:kmaxcalc, , ] <- NNWcalc
      }
    }
    if(length(k) < kmax) {
      # select only the specified planes
      if(want.dist)
        NND <- NND[k, , , drop=FALSE]
      if(want.which)
        NNW <- NNW[k, , , drop=FALSE]
    }
  }

  # secret backdoor
  if(outputarray) {
    # return result as an array or pair of arrays
    result <- if(want.both) { list(dist=NND, which=NNW) } else
              if(want.dist) NND else NNW
    attr(result, "pixarea") <- with(M, xstep * ystep)
    return(result)
  }

  # format result as a list of images
  result <- list()
  if(want.dist) {
    dlist <- list()
    for(i in 1:nk) {
      DI <- as.im(NND[i,,], M)
      if(!isrect) DI <- DI[M, drop=FALSE]
      dlist[[i]] <- DI
    }
    names(dlist) <- k
    result[["dist"]] <- if(nk > 1) dlist else dlist[[1]]
  }
  if(want.which) {
    wlist <- list()
    for(i in 1:nk) {
      WI <- as.im(NNW[i,,], M)
      if(!isrect) WI <- WI[M, drop=FALSE]
      wlist[[i]] <- WI
    }
    names(wlist) <- k
    result[["which"]] <- if(nk > 1) wlist else wlist[[1]]
  }
  if(!want.both) result <- result[[1]]
  return(result)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nnmark.R"
#
# nnmark.R
#
# $Revision: 1.5 $ $Date: 2014/09/05 06:08:49 $

nnmark <- function(X, ..., k=1, at=c("pixels", "points")) {
  stopifnot(is.ppp(X))
  stopifnot(is.marked(X))
  at <- match.arg(at)
  mX <- marks(X)
  switch(at,
         pixels = {
           Y <- nnmap(X, k=k, what="which", ...)
           switch(markformat(X),
                  vector={
                    result <- eval.im(mX[Y])
                  },
                  dataframe = {
                    result <- as.listof(lapply(mX, function(z) eval.im(z[Y])))
                  },
                  stop("Marks must be a vector or dataframe"))
         },
         points = {
           Y <- nnwhich(X, k=k)
           switch(markformat(X),
                  vector={
                    result <- mX[Y]
                  },
                  dataframe = {
                    result <- mX[Y,, drop=FALSE]
                    row.names(result) <- NULL
                  },
                  stop("Marks must be a vector or dataframe"))
         })
  return(result)
}



  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/nnorient.R"
##
## nnorient.R
##
## nearest neighbour pair orientation distribution
##
## Function \vartheta(phi) defined in
## Illian et al (2008) equ (4.5.3) page 253
##
##  $Revision: 1.3 $ $Date: 2014/12/05 07:31:57 $

nnorient <- function(X, ..., cumulative=FALSE, correction, k = 1,
                     unit=c("degree", "radian"),
                     domain=NULL, ratio=FALSE) {
  stopifnot(is.ppp(X))
  check.1.integer(k)
  stopifnot(k>=1)
  W <- Window(X)

  if(!is.null(domain))
    stopifnot(is.subset.owin(domain, W))

  unit <- match.arg(unit)
  switch(unit,
         degree = {
           FullCircle <- 360
           Convert <- 180/pi
         },
         radian = {
           FullCircle <- 2 * pi
           Convert <- 1
         })

  ## choose correction(s)
  correction.given <- !missing(correction) && !is.null(correction)
  if(!correction.given)
    correction <- c("bord.modif", "none")

  correction <- pickoption("correction", correction,
                           c(none="none",
                             bord.modif="bord.modif",
                             good="good",
                             best="best"),
                           multi=TRUE)
  correction[correction %in% c("good", "best")] <- "bord.modif"

  ## process point pattern
  Xcoord <- coords(X)
  Ycoord <- Xcoord[nnwhich(X, k=k), ]
  if(!is.null(domain)) {
    inD <- inside.owin(Xcoord$x, Xcoord$y, domain)
    Xcoord <- Xcoord[inD,]
    Ycoord <- Ycoord[inD,]
  } else 
  
  dYX <- Ycoord-Xcoord
  ANGLE <- with(dYX, atan2(y, x) * Convert) %% FullCircle
  nangles <- length(ANGLE)
  
  ## initialise output object
  Nphi <- 512
  breaks <- make.even.breaks(bmax=FullCircle, npos=Nphi-1)
  phi <- breaks$r
  Odf <- data.frame(phi  = phi,
                    theo = (if(cumulative) phi else 1)/FullCircle)
  desc <- c("angle argument phi",
            "theoretical isotropic %s")
  NOletter <- if(cumulative) "Theta" else "vartheta"
  NOsymbol <- as.name(NOletter)
  NNO <- ratfv(Odf, NULL, denom=nangles,
              argu="phi",
              ylab=substitute(fn(phi), list(fn=NOsymbol)),
              valu="theo",
              fmla = . ~ phi,
              alim = c(0, FullCircle),
              c("phi",
                "{%s[%s]^{pois}}(phi)"),
              desc,
              fname=NOletter,
              yexp=substitute(fn(phi), list(fn=NOsymbol)))

  ## ^^^^^^^^^^^^^^^  Compute edge corrected estimates ^^^^^^^^^^^^^^^^
  
  if(any(correction == "none")) {
    ## uncorrected! For demonstration purposes only!
    if(cumulative) {
      wh <- whist(ANGLE, breaks$val)  # no weights
      num.un <- cumsum(wh)
    } else {
      kd <- circdensity(ANGLE, ..., n=Nphi, unit=unit)
      num.un <- kd$y * nangles
    }
    den.un <- nangles
    ## uncorrected estimate 
    NNO <- bind.ratfv(NNO,
                     data.frame(un=num.un), den.un,
                    "{hat(%s)[%s]^{un}}(phi)",
                    "uncorrected estimate of %s",
                    "un",
                    ratio=ratio)
  }

  if("bord.modif" %in% correction) {
    ## border type correction
    bX <- bdist.points(X)
    nndX <- nndist(X, k=k)
    if(!is.null(domain)) {
      bX <- bX[inD]
      nndX <- nndX[inD]
    }
    ok <- (nndX < bX)
    nok <- sum(ok)
    rr <- seq(0, max(bX), length=256)
    Ar <- eroded.areas(W, rr)
    Arf <- approxfun(rr, Ar, rule=2)
    AI <- Arf(bX)
    edgewt <- ifelse(ok, pmin(area(W)/AI, 100), 0)
    if(cumulative) {
      wh <- whist(ANGLE, breaks$val, edgewt)
      num.bm <- cumsum(wh)/mean(edgewt)
    } else {
      w <- edgewt/sum(edgewt)
      kd <- circdensity(ANGLE, ..., weights=w, n=Nphi, unit=unit)
      num.bm <- kd$y * nok
    }
    den.bm <- nok
    NNO <- bind.ratfv(NNO,
                      data.frame(bordm=num.bm),
                      den.bm,
                      "{hat(%s)[%s]^{bordm}}(phi)",
                      "modified border-corrected estimate of %s",
                      "bordm",
                      ratio=ratio)
  }
 
  unitname(NNO) <- switch(unit,
                         degree = c("degree", "degrees"),
                         radian = c("radian", "radians"))
  return(NNO)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/objsurf.R"
#
#  objsurf.R
#
#  surface of the objective function for an M-estimator
#
#  $Revision: 1.3 $ $Date: 2013/11/12 15:53:11 $
#

objsurf <- function(x, ...) {
  UseMethod("objsurf")
}

objsurf.kppm <- function(x, ..., ngrid=32, ratio=1.5, verbose=TRUE) {
  Fit <- x$Fit
  switch(Fit$method,
         mincon = {
           result <- objsurf(Fit$mcfit, ...,
                             ngrid=ngrid, ratio=ratio, verbose=verbose)
         },
         clik = {
           optpar  <- x$par
           objfun  <- Fit$objfun
           objargs <- Fit$objargs
           result  <- objsurfEngine(objfun, optpar, objargs, ...,
                                    ngrid=ngrid, ratio=ratio, verbose=verbose)
         })
  return(result)
}

objsurf.minconfit <- function(x, ..., ngrid=32, ratio=1.5, verbose=TRUE) {
  optpar  <- x$par
  objfun  <- x$objfun
  objargs <- x$objargs
  dotargs <- x$dotargs
  objsurfEngine(objfun, optpar, objargs, ...,
                dotargs=dotargs,
                ngrid=ngrid, ratio=ratio, verbose=verbose)
}

objsurfEngine <- function(objfun, optpar, objargs, 
                          ...,
                          dotargs=list(),
                          objname="objective", 
                          ngrid=32, ratio=1.5, verbose=TRUE) {
  trap.extra.arguments(...)
  if(!is.function(objfun))
    stop("Object is in an outdated format and needs to be re-fitted")
  npar    <- length(optpar)
  if(npar != 2)
    stop("Only implemented for functions of 2 arguments")
  # create grid of parameter values
  ratio <- ensure2vector(ratio)
  ngrid <- ensure2vector(ngrid)
  stopifnot(all(ratio > 1))
  xgrid <- seq(optpar[1]/ratio[1], optpar[1] * ratio[1], length=ngrid[1])
  ygrid <- seq(optpar[2]/ratio[2], optpar[2] * ratio[2], length=ngrid[2])
  pargrid <- expand.grid(xgrid, ygrid)
  colnames(pargrid) <- names(optpar)
  # evaluate
  if(verbose) cat(paste("Evaluating", nrow(pargrid), "function values..."))
  values <- do.call("apply",
                    append(list(pargrid, 1, objfun, objargs=objargs), dotargs))
  if(verbose) cat("Done.\n")
  result <- list(x=xgrid, y=ygrid, z=matrix(values, ngrid[1], ngrid[2]))
  attr(result, "optpar") <- optpar
  attr(result, "objname") <- "contrast"
  class(result) <- "objsurf"
  return(result)
}

print.objsurf <- function(x, ...) {
  cat("Objective function surface\n")
  optpar <- attr(x, "optpar")
  objname <- attr(x, "objname")
  nama <- names(optpar)
  cat("Parameter ranges:\n")
  cat(paste(paste0(nama[1], ":"), prange(range(x$x)), "\n"))
  cat(paste(paste0(nama[2], ":"), prange(range(x$y)), "\n"))
  cat(paste("Function value:", objname, "\n"))
  invisible(NULL)
}

image.objsurf <- plot.objsurf <- function(x, ...) {
  xname <- short.deparse(substitute(x))
  optpar <- attr(x, "optpar")
  nama <- names(optpar)
  do.call("image",
          resolve.defaults(list(x=unclass(x)),
                           list(...),
                           list(xlab=nama[1], ylab=nama[2], main=xname)))
  abline(v=optpar[1], lty=3)
  abline(h=optpar[2], lty=3)
  invisible(NULL)
}

contour.objsurf <- function(x, ...) {
  xname <- short.deparse(substitute(x))
  optpar <- attr(x, "optpar")
  nama <- names(optpar)
  do.call("contour",
          resolve.defaults(list(x=unclass(x)),
                           list(...),
                           list(xlab=nama[1], ylab=nama[2], main=xname)))
  abline(v=optpar[1], lty=3)
  abline(h=optpar[2], lty=3)
  invisible(NULL)
}

  
persp.objsurf <- function(x, ...) {
  xname <- short.deparse(substitute(x))
  optpar <- attr(x, "optpar")
  objname <- attr(x, "objname")
  nama <- names(optpar)
  r <- do.call("persp",
               resolve.defaults(list(x=x$x, y=x$y, z=x$z),
                                list(...),
                                list(xlab=nama[1], ylab=nama[2],
                                     zlab=objname, main=xname)))
  invisible(r)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/options.R"
#
#     options.R
#
#     Spatstat options and other internal states
#
#    $Revision: 1.59 $   $Date: 2014/11/12 10:24:25 $
#
#

.spEnv <- new.env()

putSpatstatVariable <- function(name, value) {
  assign(name, value, envir=.spEnv)
}
getSpatstatVariable <- function(name) {
  get(name, envir=.spEnv)
}

putSpatstatVariable("Spatstat.Options", list())
putSpatstatVariable("Spatstat.ProgressBar", NULL)
putSpatstatVariable("Spatstat.ProgressData", NULL)
putSpatstatVariable("warnedkeys", character(0))

## Kovesi's uniform colour map, row 29, linear 'bmy'
putSpatstatVariable("DefaultImageColours", 
c("#000C7D", "#000D7E", "#000D80", "#000E81", "#000E83", "#000E85", 
"#000F86", "#000F88", "#00108A", "#00108B", "#00118D", "#00118F", 
"#001190", "#001292", "#001293", "#001295", "#001396", "#001398", 
"#001399", "#00149A", "#00149C", "#00149D", "#00149E", "#00159F", 
"#0015A0", "#0015A1", "#0015A2", "#0015A3", "#0015A4", "#0016A5", 
"#0016A6", "#0016A6", "#0016A7", "#0016A8", "#0016A8", "#0016A8", 
"#0A16A9", "#1516A9", "#1D15A9", "#2315A9", "#2915A9", "#2F15A8", 
"#3414A8", "#3914A7", "#3E13A6", "#4313A5", "#4712A4", "#4C12A3", 
"#5011A2", "#5311A1", "#5710A0", "#5A0F9F", "#5E0F9E", "#610E9E", 
"#640E9D", "#670D9C", "#6A0D9B", "#6C0C9A", "#6F0B99", "#720B98", 
"#740A98", "#770A97", "#790996", "#7C0896", "#7E0895", "#800794", 
"#810794", "#840693", "#860692", "#880692", "#8A0591", "#8C0591", 
"#8E0490", "#900490", "#92048F", "#94038F", "#96038E", "#98038E", 
"#9A028D", "#9C028D", "#9E028D", "#A0018C", "#A2018C", "#A4018B", 
"#A6018B", "#A8008A", "#AA008A", "#AB0089", "#AD0089", "#AF0088", 
"#B10088", "#B30087", "#B50087", "#B70086", "#B80086", "#BA0086", 
"#BC0085", "#BE0085", "#C00084", "#C20084", "#C30083", "#C50083", 
"#C70082", "#C90082", "#CB0081", "#CD0081", "#CE0080", "#D00080", 
"#D20080", "#D40080", "#D5007F", "#D7007F", "#D9007E", "#DA007E", 
"#DC007D", "#DD007C", "#DF017C", "#E1027B", "#E2047B", "#E4067A", 
"#E5087A", "#E70B79", "#E80D78", "#E91078", "#EB1277", "#EC1477", 
"#ED1676", "#EF1875", "#F01A75", "#F11C74", "#F31E73", "#F42073", 
"#F52272", "#F62471", "#F72671", "#F82870", "#FA2A6F", "#FB2C6F", 
"#FC2E6E", "#FD306D", "#FE326C", "#FE346C", "#FE366B", "#FE386A", 
"#FE3A6A", "#FE3D69", "#FE3F68", "#FE4167", "#FE4366", "#FE4566", 
"#FE4765", "#FE4964", "#FE4B63", "#FE4D62", "#FE5062", "#FE5261", 
"#FE5460", "#FE565F", "#FE585E", "#FE5A5D", "#FE5D5C", "#FE5F5B", 
"#FE615B", "#FE635A", "#FE6559", "#FE6758", "#FE6A57", "#FE6C56", 
"#FE6E55", "#FE7054", "#FE7253", "#FE7452", "#FE7651", "#FE7850", 
"#FE7A4E", "#FE7C4D", "#FE7E4C", "#FE7F4B", "#FE804A", "#FE8249", 
"#FE8448", "#FE8647", "#FE8745", "#FE8944", "#FE8B43", "#FE8D42", 
"#FE8E40", "#FE903F", "#FE923E", "#FE943C", "#FE953B", "#FE9739", 
"#FE9938", "#FE9A36", "#FE9C35", "#FE9E33", "#FE9F32", "#FEA130", 
"#FEA22F", "#FEA42E", "#FEA52C", "#FEA72B", "#FEA82A", "#FEAA29", 
"#FEAB28", "#FEAD27", "#FEAE26", "#FEB026", "#FEB125", "#FEB324", 
"#FEB423", "#FEB523", "#FEB722", "#FEB822", "#FEBA21", "#FEBB20", 
"#FEBC20", "#FEBE1F", "#FEBF1F", "#FEC11F", "#FEC21E", "#FEC31E", 
"#FEC51E", "#FEC61D", "#FEC71D", "#FEC91D", "#FECA1D", "#FECB1D", 
"#FECD1D", "#FECE1C", "#FECF1C", "#FED11C", "#FED21C", "#FED31C", 
"#FED51C", "#FED61D", "#FED71D", "#FED91D", "#FEDA1D", "#FEDB1D", 
"#FEDD1D", "#FEDE1E", "#FEDF1E", "#FEE11E", "#FEE21E", "#FEE31F", 
"#FEE51F", "#FEE61F", "#FEE720", "#FEE820", "#FEEA21", "#FEEB21", 
"#FEEC22", "#FEEE22", "#FEEF23", "#FEF023"))

warn.once <- function(key, ...) {
  warned <- getSpatstatVariable("warnedkeys")
  if(!(key %in% warned)) {
    warning(paste(...), call.=FALSE)
    putSpatstatVariable("warnedkeys", c(warned, key))
  }
  return(invisible(NULL))
}

".Spat.Stat.Opt.Table" <-
  list(
       allow.logi.influence=list(
         ## whether leverage/influence calculations are permitted
         ## on a fitted model with method='logi'
         default=FALSE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       checkpolygons = list(
         ## superseded
         default=FALSE,
         check=function(x) {
           warning("spatstat.options('checkpolygons') will be ignored in future versions of spatstat", call.=FALSE)
           return(is.logical(x) && length(x) == 1)
         },
         valid="a single logical value"
         ),
       checksegments = list(
         ## default value of 'check' for psp objects
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1},
         valid="a single logical value"
         ),
       closepairs.newcode=list(
         ## use new code for 'closepairs'
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       crossing.psp.useCall=list(
         ## use new code for 'crossing.psp'
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       crosspairs.newcode=list(
         ## use new code for 'crosspairs'
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       densityC=list(
         ## use C routines for 'density.ppp'
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       exactdt.checks.data=list(
         ## whether 'exactdt' checks validity of return value
         default=FALSE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       expand=list(
         ## default area expansion factor
         default=2,
         check=function(x) {
           is.numeric(x) && length(x) == 1 && x > 1
         },
         valid="a single numeric value, greater than 1"
       ),
       expand.polynom=list(
         ## whether to expand polynom() in ppm formulae
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       fasteval=list(
         ## whether to use 'fasteval' code if available
         default="on",
         check=function(x) { x %in% c("off", "on", "test") },
         valid="one of the strings \'off\', \'on\' or \'test\'"
       ),
       fastK.lgcp=list(
         ## whether to cut a few corners in 'lgcp.estK'
         default=FALSE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       fixpolygons = list(
         ## whether to repair polygons automatically
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1},
         valid="a single logical value"
         ),
       gpclib=list(
         ## defunct!
         default=FALSE,
         check=function(x) {
           message("gpclib is no longer needed")
           return(TRUE)
         },
         valid="a single logical value"
         ),
       huge.npoints=list(
         ## threshold to trigger a warning from rpoispp 
         default=1e6,
         check=function(x) {
           is.numeric(x) && length(x) == 1 && (x == ceiling(x)) && x > 1024
         },
         valid="a single integer, greater than 1024"
       ),
       image.colfun=list(
         ## default colour scheme for plot.im
#         default=function(n){topo.colors(n)},
         default=function(n) {
           z <- getSpatstatVariable("DefaultImageColours")
           interp.colours(z, n)
         },
         check=function(x) {
           if(!is.function(x) || length(formals(x)) == 0) return(FALSE)
           y <- x(42)
           if(length(y) != 42 || !is.character(y)) return(FALSE)
           z <- try(col2rgb(y), silent=TRUE)
           return(!inherits(z, "try-error"))
         },
         valid="a function f(n) that returns character strings, interpretable as colours"
         ),
       Kcom.remove.zeroes=list(
         ## whether Kcom removes zero distances
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       maxedgewt=list(
         ## maximum edge correction weight 
         default=100,
         check=function(x){
           is.numeric(x) && length(x) == 1 && is.finite(x) && x >= 1
         },
         valid="a finite numeric value, not less than 1"
       ),
       maxmatrix=list(
         ## maximum size of matrix of pairs of points in mpl.R
         default=2^24, # 16,777,216
         check=function(x) {
           is.numeric(x) && length(x) == 1 && (x == ceiling(x)) && x > 1024
         },
         valid="a single integer, greater than 1024"
       ),
       monochrome = list(
         ## switch for monochrome colour scheme
         default=FALSE,
         check=function(x) { is.logical(x) && length(x) == 1},
         valid="a single logical value"
         ),
       n.bandwidth=list(
         ## number of values of bandwidth to try in bandwidth selection
         default=32,
         check=function(x) {
           is.numeric(x) && (length(x) == 1) && (x == ceiling(x)) && (x > 2)
         },
         valid="a single integer, greater than 2"
       ),
       ndummy.min=list(
         ## minimum grid size for dummy points
         default=32,
         check=function(x) {
           is.numeric(x) && length(x) <= 2 && all(x == ceiling(x)) && all(x > 1)
         },
         valid="a single integer or a pair of integers, greater than 1"
       ),
       ngrid.disc=list(
         ## number of grid points used to calculate area in area-interaction
         default=128,
         check=function(x) {
           is.numeric(x) && length(x) == 1 && (x == ceiling(x)) && x > 1
         },
         valid="a single integer, greater than 1"
       ),
       npixel=list(
         ## default pixel dimensions
         default=128,
         check=function(x){
           is.numeric(x) && (length(x) %in% c(1,2)) && is.finite(x) &&
           all(x == ceiling(x)) && all(x > 1) 
         },
         valid="an integer, or a pair of integers, greater than 1"
        ),
       nvoxel=list(
         ## default total number of voxels
         default=2^22,
         check=function(x) {
           is.numeric(x) && length(x) == 1 && (x == ceiling(x)) && x > 2^12
         },
         valid="a single integer, greater than 2^12"
       ),
       old.morpho.psp=list(
         ## use old code for morphological operations
         default=FALSE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       par.binary=list(
         ## default graphics parameters for masks
         default=list(),
         check=is.list,
         valid="a list"
         ),
       par.contour=list(
         ## default graphics parameters for 'contour'
         default=list(),
         check=is.list,
         valid="a list"
         ),
       par.fv=list(
         ## default graphics parameters for 'plot.fv'
         default=list(),
         check=is.list,
         valid="a list"
         ),
       par.persp=list(
         ## default graphics parameters for 'persp' plots
         default=list(),
         check=is.list,
         valid="a list"
         ),
       par.points=list(
         ## default graphics parameters for 'points'
         default=list(),
         check=is.list,
         valid="a list"
         ),
       print.ppm.SE=list(
         ## under what conditions to print estimated SE in print.ppm
         default="poisson",
         check=function(x) { is.character(x) && length(x) == 1 &&
                             x %in% c("always", "poisson", "never") },
         valid="one of the strings \'always\', \'poisson\' or \'never\'"
       ),
       progress = list(
         ## how to display progress reports
         default="tty",
         check=function(x){ x %in% c("tty", "txtbar") },
         valid=paste("one of the strings", dQuote("tty"),
           "or", dQuote("txtbar"))
         ),
       project.fast=list(
         ## whether to cut corners when projecting an invalid ppm object
         default=FALSE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       psstA.ngrid=list(
         ## size of point grid for computing areas in psstA
         default=32,
         check=function(x) {
           is.numeric(x) && length(x) == 1 && (x == ceiling(x)) && x >= 8
         },
         valid="a single integer, greater than or equal to 8"
       ),
       psstA.nr=list(
         ## number of 'r' values to consider in psstA
         default=30,
         check=function(x) {
           is.numeric(x) && length(x) == 1 && (x == ceiling(x)) && x >= 4
         },
         valid="a single integer, greater than or equal to 4"
       ),
       psstG.remove.zeroes=list(
         ## whether to remove zero distances in psstG
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
      eroded.intensity=list(
         ## whether to compute intensity estimate in eroded window
         ## e.g. for Kcom, Gcom
         default=FALSE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       rmh.nrep=list(
         ## default value of parameter 'nrep' in rmh
         default=5e5, 
         check=function(x) {
           is.numeric(x) && length(x) == 1 && (x == ceiling(x)) && x > 0
         },
         valid="a single integer, greater than 0"
       ),
       rmh.p=list(
         ## default value of parameter 'p' in rmh
         default=0.9,
         check=function(x) { is.numeric(x) && length(x) == 1 &&
                             x >= 0 && x <= 1 },
         valid="a single numerical value, between 0 and 1"
       ),
       rmh.q=list(
         ## default value of parameter 'q' in rmh
         default=0.9,
         check=function(x) { is.numeric(x) && length(x) == 1 &&
                             x > 0 && x < 1 },
         valid="a single numerical value, strictly between 0 and 1"
       ),
       scalable = list(
         ## whether certain calculations in ppm should be scalable
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1},
         valid="a single logical value"
         ),
       selfcrossing.psp.useCall=list(
         ## whether to use new code in selfcrossing.psp
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       terse = list(
         ## Level of terseness in printed output (higher => more terse)
         default=0,
         check=function(x) { length(x) == 1 && (x %in% 0:4) },
         valid="an integer between 0 and 4"
       ),
       use.Krect=list(
         ## whether to use function Krect in Kest(X) when window is rectangle
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       Cwhist=list(
         ## whether to use C code for whist
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       ),
       Cbdrymask=list(
         ## whether to use C code for bdry.mask
         default=TRUE,
         check=function(x) { is.logical(x) && length(x) == 1 },
         valid="a single logical value"
       )
       )
# end of options list

reset.spatstat.options <- function() {
  Spatstat.Options <- lapply(.Spat.Stat.Opt.Table,
                               function(z) { z$default })
  putSpatstatVariable("Spatstat.Options", Spatstat.Options)
  invisible(Spatstat.Options)  
}

reset.spatstat.options()

"spatstat.options" <-
function (...) 
{
    Spatstat.Options <- getSpatstatVariable("Spatstat.Options")
    called <- list(...)    

    if(length(called) == 0)
    	return(Spatstat.Options)

    if(is.null(names(called)) && length(called)==1) {
      # spatstat.options(x) 
      x <- called[[1]]
      if(is.null(x))
        return(Spatstat.Options)  # spatstat.options(NULL)
      if(is.list(x))
        called <- x 
    }
    
    if(is.null(names(called))) {
        # spatstat.options("par1", "par2", ...)
	ischar <- unlist(lapply(called, is.character))
	if(all(ischar)) {
          choices <- unlist(called)
          ok <- choices %in% names(Spatstat.Options)
          if(!all(ok))
            stop(paste("Unrecognised option(s):", called[!ok]))
          if(length(called) == 1)
            return(Spatstat.Options[[choices]])
          else
            return(Spatstat.Options[choices])
	} else {
	   wrong <- called[!ischar]
	   offending <- unlist(lapply(wrong,
	   		function(x) { y <- x;
	     		short.deparse(substitute(y)) }))
	   offending <- paste(offending, collapse=",")
           stop(paste("Unrecognised mode of argument(s) [",
		offending,
	   "]: should be character string or name=value pair"))
    	}
    }
# spatstat.options(name=value, name2=value2,...)
    assignto <- names(called)
    if (is.null(assignto) || !all(nzchar(assignto)))
        stop("options must all be identified by name=value")
    recog <- assignto %in% names(.Spat.Stat.Opt.Table)
    if(!all(recog))
	stop(paste("Unrecognised option(s):", assignto[!recog]))
# validate new values
    for(i in seq_along(assignto)) {
      nama <- assignto[i]
      valo <- called[[i]]
      entry <- .Spat.Stat.Opt.Table[[nama]]
      ok <- entry$check(valo)
      if(!ok)
        stop(paste("Parameter", dQuote(nama), "should be",
                   entry$valid))
    }
# reassign
  changed <- Spatstat.Options[assignto]
  Spatstat.Options[assignto] <- called
  putSpatstatVariable("Spatstat.Options", Spatstat.Options)
  
# return 
    invisible(changed)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/ord.R"
#
#
#    ord.S
#
#    $Revision: 1.6 $	$Date: 2014/12/07 10:43:43 $
#
#    Ord process with user-supplied potential
#
#    Ord()  create an instance of the Ord process
#                 [an object of class 'interact']
#                 with user-supplied potential
#	
#
# -------------------------------------------------------------------
#	

Ord <- local({

  BlankOrd <- 
  list(
         name     = "Ord process with user-defined potential",
         creator  = "Ord",
         family    = "ord.family",
         pot      = NULL,
         par      = NULL,
         parnames = NULL,
         init     = NULL,
         update   = function(self, ...){
           do.call(Ord,
                   resolve.defaults(list(...),
                                    list(pot=self$pot, name=self$name)))
         } , 
         print = function(self) {
           cat("Potential function:\n")
           print(self$pot)
           invisible()
         },
       version=NULL
  )
  class(BlankOrd) <- "interact"

  Ord <- function(pot, name) {
    out <- instantiate.interact(BlankOrd)
    out$pot <- pot
    if(!missing(name)) out$name <- name
  }

  Ord <- intermaker(Ord, BlankOrd)
})


  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/ord.family.R"
#
#
#    ord.family.S
#
#    $Revision: 1.16 $	$Date: 2013/04/25 06:37:43 $
#
#    The Ord model (family of point process models)
#
#    ord.family:      object of class 'isf' defining Ord model structure
#	
#
# -------------------------------------------------------------------
#	

ord.family <-
  list(
         name  = "ord",
         print = function(self) {
                      cat("Ord model family\n")
         },
         eval  = function(X, U, EqualPairs, pot, pars, ...) {
  #
  # This auxiliary function is not meant to be called by the user.
  # It computes the distances between points,
  # evaluates the pair potential and applies edge corrections.
  #
  # Arguments:
  #   X           data point pattern                      'ppp' object
  #   U           points at which to evaluate potential   list(x,y) suffices
  #   EqualPairs  two-column matrix of indices i, j such that X[i] == U[j]
  #               (or NULL, meaning all comparisons are FALSE)
  #   pot         potential function                      function(d, p)
  #   pars        auxiliary parameters for pot            list(......)
  #   ...         IGNORED                             
  #
  # Value:
  #    matrix of values of the potential
  #    induced by the pattern X at each location given in U.
  #    The rows of this matrix correspond to the rows of U (the sample points);
  #    the k columns are the coordinates of the k-dimensional potential.
  #
  # Note:
  # The potential function 'pot' will be called as
  #    pot(M, pars)   where M is a vector of tile areas.
  # It must return a vector of the same length as M
  # or a matrix with number of rows equal to the length of M
  ##########################################################################

nX <- npoints(X)
nU <- length(U$x)       # number of data + dummy points

seqX <- seq_len(nX)
seqU <- seq_len(nU)

# determine which points in the combined list are data points
if(length(EqualPairs) > 0)           
  is.data <- seqU %in% EqualPairs[,2] 
else
  is.data <- rep.int(FALSE, nU)

#############################################################################
# First compute Dirichlet tessellation of data
# and its total potential (which could be vector-valued)
#############################################################################

marks(X) <- NULL
Wdata <- dirichlet.weights(X)   # sic - these are the tile areas.
Pdata <- pot(Wdata, pars)
summa <- function(P) {
  if(is.matrix(P))
    matrowsum(P)
  else if(is.vector(P) || length(dim(P))==1 )
    sum(P)
  else
    stop("Don't know how to take row sums of this object")
}
total.data.potential <- summa(Pdata)

# Initialise V

dimpot <- dim(Pdata)[-1]  # dimension of each value of the potential function
                          # (= numeric(0) if potential is a scalar)

dimV <- c(nU, dimpot)
if(length(dimV) == 1)
  dimV <- c(dimV, 1)

V <- array(0, dim=dimV)

rowV <- array(seqU, dim=dimV)

#################### Next, evaluate V for the data points.  ###############
# For each data point, compute Dirichlet tessellation
# of the data with this point removed.
# Compute difference of total potential.
#############################################################################


for(j in seq_len(nX)) {
        #  Dirichlet tessellation of data without point j
  Wminus <- dirichlet.weights(X[-j])
        #  regressor is the difference in total potential
  V[rowV == j] <- total.data.potential - summa(pot(Wminus, pars))
}


#################### Next, evaluate V for the dummy points   ################
# For each dummy point, compute Dirichlet tessellation
# of (data points together with this dummy point) only. 
# Take difference of total potential.
#############################################################################

for(j in seqU[!is.data]) {
  Xplus <- superimpose(X, list(x=U$x[j], y=U$y[j]), W=X$window)
  #  compute Dirichlet tessellation (of these points only!)
  Wplus <- dirichlet.weights(Xplus)
  #  regressor is difference in total potential
  V[rowV == j] <- summa(pot(Wplus, pars)) - total.data.potential
}

cat("dim(V) = \n")
print(dim(V))

return(V)

} ######### end of function $eval                            

) ######### end of list

class(ord.family) <- "isf"
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/ordthresh.R"
#
#
#    ordthresh.S
#
#    $Revision: 1.10 $	$Date: 2012/01/17 01:19:48 $
#
#    Ord process with threshold potential
#
#    OrdThresh()  create an instance of the Ord process
#                 [an object of class 'interact']
#                 with threshold potential
#	
#
# -------------------------------------------------------------------
#	

OrdThresh <- local({

  BlankOrdThresh <- 
    list(
      name     = "Ord process with threshold potential",
      creator  = "OrdThresh",
      family    = "ord.family",
      pot      = function(d, par) {
        (d <= par$r)
      },
      par      = list(r = NULL),
      parnames = "threshold distance",
      init     = function(self) {
        r <- self$par$r
        if(!is.numeric(r) || length(r) != 1 || r <= 0)
          stop("threshold distance r must be a positive number")
      },
      update = NULL,  # default OK
      print = NULL,    # default OK
      interpret =  function(coeffs, self) {
        loggamma <- as.numeric(coeffs[1])
        gamma <- exp(loggamma)
        return(list(param=list(gamma=gamma),
                    inames="interaction parameter gamma",
                    printable=dround(gamma)))
      },
      valid = function(coeffs, self) {
        loggamma <- as.numeric(coeffs[1])
        is.finite(loggamma)
      },
      project = function(coeffs, self) {
        if((self$valid)(coeffs, self)) return(NULL) else return(Poisson())
      },
      irange = function(...) {
        return(Inf)
      },
      version=NULL
      )
  class(BlankOrdThresh) <- "interact"

  OrdThresh <- function(r) { instantiate.interact(BlankOrdThresh, list(r=r)) }

  OrdThresh <- intermaker(OrdThresh, BlankOrdThresh)

  OrdThresh
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pairdistlpp.R"
#
# pairdistlpp.R
#
#  $Revision: 1.10 $ $Date: 2014/10/24 00:22:30 $
#
#
#  pairdist.lpp
#        Calculates the shortest-path distance between each pair of points
#        in a point pattern on a linear network.
#

pairdist.lpp <- function(X, ..., method="C") {
  stopifnot(inherits(X, "lpp"))
  stopifnot(method %in% c("C", "interpreted"))
  #
  L <- as.linnet(X)
  Y <- as.ppp(X)
  n <- npoints(Y)
  #
#  Lseg  <- L$lines
  Lvert <- L$vertices
  from  <- L$from
  to    <- L$to
  dpath <- L$dpath
  
  # nearest segment for each point
  pro <- coords(X, local=TRUE, spatial=FALSE, temporal=FALSE)$seg

  pairdistmat <- matrix(0,n,n)

  if(method == "interpreted") {
    # loop through all pairs of data points
    for (i in 1:(n-1)) {
      proi <- pro[i]
      Xi <- Y[i]
      nbi1 <- from[proi]
      nbi2 <- to[proi]
      vi1 <- Lvert[nbi1]
      vi2 <- Lvert[nbi2]   
      dXi1 <- crossdist(Xi, vi1)
      dXi2 <- crossdist(Xi, vi2)
      for (j in (i+1):n) {
        Xj <- Y[j]
        proj <- pro[j]
        if(proi == proj) {
          # points i and j lie on the same segment
          # use Euclidean distance
          d <- crossdist(Xi, Xj)
        } else {
          # shortest path from i to j passes through ends of segments
          nbj1 <- from[proj]
          nbj2 <- to[proj]
          vj1 <- Lvert[nbj1]
          vj2 <- Lvert[nbj2]
          # Calculate shortest of 4 possible paths from i to j
          d1Xj <- crossdist(vj1,Xj)
          d2Xj <- crossdist(vj2,Xj)
          d11 <- dXi1 + dpath[nbi1,nbj1] + d1Xj
          d12 <- dXi1 + dpath[nbi1,nbj2] + d2Xj
          d21 <- dXi2 + dpath[nbi2,nbj1] + d1Xj
          d22 <- dXi2 + dpath[nbi2,nbj2] + d2Xj
          d <- min(d11,d12,d21,d22)
        }
        # store result
        pairdistmat[i,j] <- pairdistmat[j,i] <- d
      }
    }
  } else {
    # C code
    # convert indices to start at 0
    from0 <- from - 1L
    to0   <- to - 1L
    segmap <- pro - 1L
    zz <- .C("linpairdist",
             np = as.integer(n),
             xp = as.double(Y$x),
             yp = as.double(Y$y),
             nv = as.integer(Lvert$n),
             xv = as.double(Lvert$x),
             yv = as.double(Lvert$y),
             ns = as.double(L$n),
             from = as.integer(from0),
             to = as.integer(to0),
             dpath = as.double(dpath),
             segmap = as.integer(segmap),
             answer = as.double(pairdistmat))
    pairdistmat <- matrix(zz$answer, n, n)
  }
  return(pairdistmat)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pairorient.R"
##
## pairorient.R
##
## point pair orientation distribution
##
## Function O_{r1,r2}(phi) defined in
## Stoyan & Stoyan (1994) equ (14.53) page 271
##
##     and its derivative estimated by kernel smoothing
##
##  $Revision: 1.9 $ $Date: 2014/12/05 06:59:53 $

pairorient <- function(X, r1, r2, ...,
                       cumulative=FALSE,
                       correction, ratio=FALSE,
                       unit=c("degree", "radian"),
                       domain=NULL) {
  stopifnot(is.ppp(X))
  check.1.real(r1)
  check.1.real(r2)
  stopifnot(r1 < r2)
  W <- Window(X)
  if(!is.null(domain))
    stopifnot(is.subset.owin(domain, W))
  
  unit <- match.arg(unit)
  switch(unit,
         degree = {
           FullCircle <- 360
           Convert <- 180/pi
         },
         radian = {
           FullCircle <- 2 * pi
           Convert <- 1
         })

  ## choose correction(s)
  correction.given <- !missing(correction) && !is.null(correction)
  if(!correction.given)
    correction <- c("border", "isotropic", "translate")
  correction <- pickoption("correction", correction,
                           c(none="none",
                             border="border",
                             bord.modif="bord.modif",
                             isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             good="good",
                             best="best"),
                           multi=TRUE)
#  best.wanted <- ("best" %in% correction)
  ## replace 'good' by the optimal choice for this size of dataset
  if("good" %in% correction)
    correction[correction == "good"] <- good.correction.K(X)
  ## retain only corrections that are implemented for the window
  correction <- implemented.for.K(correction, W$type, correction.given)

  
  ## Find close pairs in range [r1, r2]
  close <- as.data.frame(closepairs(X, r2))
  ok <- with(close, r1 <= d & d <= r2)
  if(!is.null(domain))
      ok <- ok & with(close, inside.owin(xi, yi, domain))
  if(!any(ok)) {
    warning(paste("There are no pairs of points in the distance range",
                  prange(c(r1,r2))))
    return(NULL)
  }
  close <- close[ok, , drop=FALSE]
  ANGLE <- with(close, atan2(dy, dx) * Convert) %% FullCircle

  ## initialise output object
  Nphi <- 512
  breaks <- make.even.breaks(bmax=FullCircle, npos=Nphi-1)
  phi <- breaks$r
  Odf <- data.frame(phi  = phi,
                    theo = (if(cumulative) phi else 1)/FullCircle)
  desc <- c("angle argument phi",
            "theoretical isotropic %s")
  Oletter <- if(cumulative) "O" else "o"
  Osymbol <- as.name(Oletter)
  OO <- ratfv(Odf, NULL, denom=nrow(close),
              argu="phi",
              ylab=substitute(fn[R1,R2](phi), list(R1=r1, R2=r2, fn=Osymbol)),
              valu="theo",
              fmla = . ~ phi,
              alim = c(0, FullCircle),
              c("phi",
                "{%s[%s]^{pois}}(phi)"),
              desc,
              fname=c(Oletter, paste0("list(", r1, ",", r2, ")")),
              yexp=substitute(fn[list(R1,R2)](phi),
                list(R1=r1,R2=r2,fn=Osymbol)))

  ## ^^^^^^^^^^^^^^^  Compute edge corrected estimates ^^^^^^^^^^^^^^^^

  nangles <- length(ANGLE)
  
  if(any(correction == "none")) {
    ## uncorrected! For demonstration purposes only!
    if(cumulative) {
      wh <- whist(ANGLE, breaks$val)  # no weights
      num.un <- cumsum(wh)
    } else {
      kd <- circdensity(ANGLE, ..., n=Nphi, unit=unit)
      num.un <- kd$y * nangles
    }
    den.un <- nangles
    ## uncorrected estimate 
    OO <- bind.ratfv(OO,
                     data.frame(un=num.un), den.un,
                    "{hat(%s)[%s]^{un}}(phi)",
                    "uncorrected estimate of %s",
                    "un",
                    ratio=ratio)
  }

  if(any(c("border", "bord.modif") %in% correction)) {
    ## border type corrections
    bX <- bdist.points(X)
    bI <- bX[close$i]
    if("border" %in% correction) {
      bok <- (bI > r2)
      ANGLEok <- ANGLE[bok]
      nok <- length(ANGLEok)
      if(cumulative) {
        wh <- whist(ANGLEok, breaks$val)
        num.bord <- cumsum(wh)
      } else {
        kd <- circdensity(ANGLEok, ..., n=Nphi, unit=unit)
        num.bord <- kd$y * nok
      }
      den.bord <- nok
      OO <- bind.ratfv(OO,
                       data.frame(border=num.bord),
                       den.bord,
                       "{hat(%s)[%s]^{bord}}(phi)",
                       "border-corrected estimate of %s",
                       "border",
                       ratio=ratio)
    }
    if("bord.modif" %in% correction) {
      ok <- (close$d < bI)
      nok <- sum(ok)
      inradius <- max(distmap(W, invert=TRUE))
      rrr <- range(r2, inradius)
      rr <- seq(rrr[1], rrr[2], length=256)
      Ar <- eroded.areas(W, rr)
      Arf <- approxfun(rr, Ar, rule=2)
      AI <- (Arf(bX))[close$i]
      edgewt <- ifelse(ok, pmin(area(W)/AI, 100), 0)
      if(cumulative) {
        wh <- whist(ANGLE, breaks$val, edgewt)
        num.bm <- cumsum(wh)/mean(edgewt)
      } else {
        w <- edgewt/sum(edgewt)
        kd <- circdensity(ANGLE, ..., weights=w, n=Nphi, unit=unit)
        num.bm <- kd$y * nok
      }
      den.bm <- nok
      OO <- bind.ratfv(OO,
                       data.frame(bordm=num.bm),
                       den.bm,
                       "{hat(%s)[%s]^{bordm}}(phi)",
                       "modified border-corrected estimate of %s",
                       "bordm",
                       ratio=ratio)
    }
  }
  if(any(correction == "translate")) {
    ## Ohser-Stoyan translation correction
    edgewt <- edge.Trans(dx=close$dx, dy=close$dy, W=W, paired=TRUE)
    if(cumulative) {
      wh <- whist(ANGLE, breaks$val, edgewt)
      num.trans <- cumsum(wh)/mean(edgewt)
    } else {
      w <- edgewt/sum(edgewt)
      kd <- circdensity(ANGLE, ..., weights=w, n=Nphi, unit=unit)
      num.trans <- kd$y * nangles
    }
    den.trans <- nangles
    OO <- bind.ratfv(OO,
                     data.frame(trans=num.trans),
                     den.trans,
                     "{hat(%s)[%s]^{trans}}(phi)",
                     "translation-corrected estimate of %s",
                     "trans",
                     ratio=ratio)
  }
  if(any(correction == "isotropic")) {
    ## Ripley isotropic correction
    XI <- ppp(close$xi, close$yi, window=W, check=FALSE)
    DIJ <- close$d
    edgewt <- edge.Ripley(XI, matrix(DIJ, ncol=1))
    if(cumulative) {
      wh <- whist(ANGLE, breaks$val, edgewt)
      num.iso <- cumsum(wh)/mean(edgewt)
    } else {
      w <- edgewt/sum(edgewt)
      kd <- circdensity(ANGLE, ..., weights=w, n=Nphi, unit=unit)
      num.iso <- kd$y * nangles
    }
    den.iso <- nangles
    OO <- bind.ratfv(OO,
                     data.frame(iso=num.iso),
                     den.iso,
                     "{hat(%s)[%s]^{iso}}(phi)",
                     "Ripley isotropic-corrected estimate of %s",
                     "iso",
                     ratio=ratio)
  }
  unitname(OO) <- switch(unit,
                         degree = c("degree", "degrees"),
                         radian = c("radian", "radians"))
  return(OO)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pairpiece.R"
#
#
#    pairpiece.S
#
#    $Revision: 1.21 $	$Date: 2013/04/25 06:37:43 $
#
#    A pairwise interaction process with piecewise constant potential
#
#    PairPiece()   create an instance of the process
#                 [an object of class 'interact']
#	
#
# -------------------------------------------------------------------
#	

PairPiece <- local({

  # .... auxiliary functions ........
  delP <- function(i, r) {
    r <- r[-i]
    nr <- length(r)
    if(nr == 0) return(Poisson())
    if(nr == 1) return(Strauss(r))
    return(PairPiece(r))
  }

  # ..... template ..........

  BlankPairPiece <- 
  list(
         name     = "Piecewise constant pairwise interaction process",
         creator  = "PairPiece",
         family   = "pairwise.family", # evaluated later
         pot      = function(d, par) {
                       r <- par$r
                       nr <- length(r)
                       out <- array(FALSE, dim=c(dim(d), nr))
                       out[,,1] <-  (d < r[1])
                       if(nr > 1) {
                         for(i in 2:nr) 
                           out[,,i] <- (d >= r[i-1]) & (d < r[i])
                       }
                       out
                     },
         par      = list(r = NULL), # filled in later
         parnames = "interaction thresholds",
         init     = function(self) {
                      r <- self$par$r
                      if(!is.numeric(r) || !all(r > 0))
                       stop("interaction thresholds r must be positive numbers")
                      if(length(r) > 1 && !all(diff(r) > 0))
                        stop("interaction thresholds r must be strictly increasing")
                    },
         update = NULL,  # default OK
         print = NULL,    # default OK
         interpret =  function(coeffs, self) {
           r <- self$par$r
           npiece <- length(r)
           # extract coefficients
           gammas <- exp(as.numeric(coeffs))
           # name them
           gn <- gammas
           names(gn) <- paste("[", c(0,r[-npiece]),",", r, ")", sep="")
           #
           return(list(param=list(gammas=gammas),
                       inames="interaction parameters gamma_i",
                       printable=dround(gn)))
         },
        valid = function(coeffs, self) {
           # interaction parameters gamma
           gamma <- (self$interpret)(coeffs, self)$param$gammas
           if(!all(is.finite(gamma))) return(FALSE)
           return(all(gamma <= 1) || gamma[1] == 0)
        },
        project = function(coeffs, self){
           # interaction parameters gamma
           gamma <- (self$interpret)(coeffs, self)$param$gammas
           # interaction thresholds r[i]
           r <- self$par$r
           # check for NA or Inf
           bad <- !is.finite(gamma)
           # gamma > 1 forbidden unless hard core
           ishard <- is.finite(gamma[1]) && (gamma[1] == 0)
           if(!ishard)
             bad <- bad | (gamma > 1)
           if(!any(bad))
             return(NULL)
           if(spatstat.options("project.fast") || sum(bad) == 1) {
             # remove smallest threshold with an unidentifiable parameter
             firstbad <- min(which(bad))
             return(delP(firstbad, r))
           } else {
             # consider all candidate submodels
             subs <- lapply(which(bad), delP, r=r)
             return(subs)
           }
        },
        irange = function(self, coeffs=NA, epsilon=0, ...) {
          r <- self$par$r
          if(all(is.na(coeffs)))
            return(max(r))
          gamma <- (self$interpret)(coeffs, self)$param$gammas
          gamma[is.na(gamma)] <- 1
          active <- (abs(log(gamma)) > epsilon)
          if(!any(active))
            return(0)
          else return(max(r[active]))
        },
       Mayer=function(coeffs, self) {
         # second Mayer cluster integral
         r     <- self$par$r
         gamma <- (self$interpret)(coeffs, self)$param$gammas
         # areas of annuli between r[i-1], r[i]
         areas <- pi * diff(c(0,r)^2)
         return(sum(areas * (1-gamma)))
       },
       version=NULL # filled in later
       )
  class(BlankPairPiece) <- "interact"

  PairPiece <- function(r) {
    instantiate.interact(BlankPairPiece, list(r=r))
  }

  PairPiece <- intermaker(PairPiece, BlankPairPiece)
  
  PairPiece
})

                   
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pairs.im.R"
#
#   pairs.im.R
#
#   $Revision: 1.7 $   $Date: 2014/08/04 05:55:43 $
#

pairs.listof <-
  pairs.im <- function(..., plot=TRUE) {
  argh <- list(...)
  cl <- match.call()
  ## unpack single argument which is a list of images
  if(length(argh) == 1) {
    arg1 <- argh[[1]]
    if(is.list(arg1) && all(unlist(lapply(arg1, is.im))))
      argh <- arg1
  }
  ## identify which arguments are images
  isim <- unlist(lapply(argh, is.im))
  nim <- sum(isim)
  if(nim == 0) 
    stop("No images provided")
  if(nim == 1) {
    ## one image: plot histogram
    h <- hist(..., plot=plot)
    return(invisible(h))
  }
  ## separate image arguments from others
  imlist <- argh[isim]
  rest   <- argh[!isim]
  ## determine image names for plotting
  imnames <- names(imlist)
  backupnames <- paste(cl)[c(FALSE, isim, FALSE)]
  if(length(backupnames) != nim)
    backupnames <- paste("V", seq_len(nim), sep="")
  if(length(imnames) != nim)
    imnames <- backupnames
  else if(any(needname <- !nzchar(imnames)))
    imnames[needname] <- backupnames[needname]
  ## extract pixel rasters and reconcile them
  imwins <- lapply(imlist, as.owin)
  names(imwins) <- NULL
  rasta    <- do.call("intersect.owin", imwins)
  ## extract image pixel values on common raster
  pixvals <- lapply(imlist, "[.im", i=rasta, raster=rasta, drop=TRUE)
  ## combine into data frame
  pixdf <- do.call("data.frame", pixvals)
  ## plot
  if(plot)
    do.call("pairs", resolve.defaults(list(x=pixdf),
                                      rest,
                                      list(labels=imnames, pch=".")))
  labels <- resolve.defaults(rest, list(labels=imnames))$labels
  colnames(pixdf) <- labels
  class(pixdf) <- c("plotpairsim", class(pixdf))
  return(invisible(pixdf))
}

plot.plotpairsim <- function(x, ...) {
  do.call("pairs.default",
          resolve.defaults(list(x=as.data.frame(x)),
                           list(...),
                           list(pch=".")))
  return(invisible(NULL))
}

print.plotpairsim <- function(x, ...) {
  cat("Object of class plotpairsim\n")
  cat(paste("contains pixel data for", commasep(sQuote(colnames(x))), "\n"))
  return(invisible(NULL))
}

panel.image <- function(x, y, ..., sigma=NULL) {
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  xx <- scaletointerval(x)
  yy <- scaletointerval(y)
  p <- ppp(xx, yy, window=square(1), check=FALSE)
  plot(density(p, sigma=sigma), add=TRUE, ...)
}

panel.contour <- function(x, y, ..., sigma=NULL) {
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  xx <- scaletointerval(x)
  yy <- scaletointerval(y)
  p <- ppp(xx, yy, window=square(1), check=FALSE)
  Z <- density(p, sigma=sigma)
  do.call("contour",
          resolve.defaults(list(x=Z, add=TRUE),
                           list(...),
                           list(drawlabels=FALSE)))
}

panel.histogram <- function(x, ...) {
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  do.call("rect",
          resolve.defaults(list(xleft   = breaks[-nB],
                                ybottom = 0,
                                xright  = breaks[-1],
                                ytop    = y),
                           list(...),
                           list(col="grey")))
}

  
  
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pairsat.family.R"
#
#
#    pairsat.family.S
#
#    $Revision: 1.42 $	$Date: 2013/09/26 03:47:38 $
#
#    The saturated pairwise interaction family of point process models
#
#    (an extension of Geyer's saturation process to all pairwise interactions)
#
#    pairsat.family:         object of class 'isf'
#                     defining saturated pairwise interaction
#	
#
# -------------------------------------------------------------------
#	

pairsat.family <-
  list(
         name  = "saturated pairwise",
         print = function(self) {
                      cat("Saturated pairwise interaction family\n")
         },
         eval  = function(X,U,EqualPairs,pairpot,potpars,correction,
                          ..., Reach=NULL,
                               precomputed=NULL, savecomputed=FALSE,
                               halfway=FALSE) {
  #
  # This is the eval function for the `pairsat' family.
  # 
  # This internal function is not meant to be called by the user.
  # It is called by mpl.prepare() during execution of ppm().
  #         
  # The eval functions perform all the manipulations that are common to
  # a given class of interactions. 
  #
  # For the `pairsat' family of pairwise-interaction processes,
  # this eval function computes the distances between points,
  # invokes 'pairpot' to evaluate the potential between each pair of points,
  # applies edge corrections, and then sums the pair potential terms
  # applying the saturation threshold.
  #
  # ARGUMENTS:
  #   All 'eval' functions have the following arguments 
  #   which are called in sequence (without formal names)
  #   by mpl.prepare():
  #       
  #   X           data point pattern                      'ppp' object
  #   U           points at which to evaluate potential   list(x,y) suffices
  #   EqualPairs  two-column matrix of indices i, j such that X[i] == U[j]
  #               (or NULL, meaning all comparisons are FALSE)
  #   pot         potential function 
  #   potpars     auxiliary parameters for pot            list(......)
  #   correction  edge correction type                    (string)
  #
  # VALUE:
  #    All `eval' functions must return a        
  #    matrix of values of the total potential
  #    induced by the pattern X at each location given in U.
  #    The rows of this matrix correspond to the rows of U (the sample points);
  #    the k columns are the coordinates of the k-dimensional potential.
  #         
  ########################################################################
  #
  # POTENTIAL:
  # The pair potential function 'pairpot' will be called as
  #    pairpot(M, potpars)   where M is a matrix of interpoint distances.
  # It must return a matrix with the same dimensions as M
  # or an array with its first two dimensions the same as the dimensions of M.
  #           
  # NOTE:
  #   Note the Geyer saturation threshold must be given in 'potpars$sat'

  ##########################################################################

           
# coercion should be unnecessary, but this is useful for debugging
X <- as.ppp(X)
U <- as.ppp(U, X$window)   # i.e. X$window is DEFAULT window

# saturation parameter(s)
saturate <- potpars$sat

# interaction distance of corresponding pairwise interaction
PairReach <- if(!is.null(Reach) && is.finite(Reach)) Reach/2 else NULL

if(is.null(saturate)) {
  # pairwise interaction 
  V <- pairwise.family$eval(X, U, EqualPairs,
                            pairpot, potpars, correction, ...,
                            Reach=PairReach,
                            precomputed=precomputed,
                            savecomputed=savecomputed)
  return(V)
}

# first ensure all data points are included in the quadrature points
nX <- npoints(X)
nU <- npoints(U)
Xseq  <- seq_len(nX)
if(length(EqualPairs) == 0) {
  # no data points currently included 
  missingdata <- rep.int(TRUE, nX)
} else {
  Xused <- EqualPairs[,1]
  missingdata <- !(Xseq %in% Xused)
}
somemissing <- any(missingdata)
if(somemissing) {
  # add the missing data points
  originalrows <- seq_len(nU)
  nmiss <- sum(missingdata)
  U <- superimpose(U, X[missingdata], W=X$window, check=FALSE)
  # correspondingly augment the list of equal pairs
  newXindex <- Xseq[missingdata]
  newUindex <- nU + seq_len(nmiss)
  EqualPairs <- rbind(EqualPairs, cbind(newXindex, newUindex))
  nU <- nU + nmiss
}

# compute the pair potentials POT and the unsaturated potential sums V

V <- pairwise.family$eval(X, U, EqualPairs, pairpot, potpars, correction,
                          ..., Reach=PairReach)
POT <- attr(V, "POT")

computed <- attr(V, "computed")   # could be NULL

#
# V is a matrix with rows = quadrature points,
#                    columns = coordinates of potential
# POT is an array with rows = data points
#                      columns = quadrature points
#                      planes = coordinates of potential

#################################################################
################## saturation part ##############################
#################################################################

# check dimensions and ensure 'saturate' is a vector
ns <- length(saturate)
np <- ncol(V)
if(ns == 1 && np > 1)
  saturate <- rep.int(saturate, np)
else if(ns != np)
  stop("Length of vector of saturation parameters is incompatible with the pair potential", call.=FALSE)

# replicate as a matrix and as an array
saturate2 <- array(saturate[slice.index(V, 2)], dim=dim(V))
saturate3 <- array(saturate[slice.index(POT, 3)], dim=dim(POT))
#
# (a) compute SATURATED potential sums
V.sat <- pmin.int(V, saturate2)

if(halfway)
  return(V.sat)
#
# (b) compute effect of addition/deletion of dummy/data point j
# on the UNSATURATED potential sum of each data point i
#
# Identify data points
is.data <- seq_len(npoints(U)) %in% EqualPairs[,2] # logical vector corresp. to rows of V

# Extract potential sums for data points only
V.data <- V[is.data, , drop=FALSE]

# replicate them so that V.dat.rep[i,j,k] = V.data[i, k]
V.dat.rep <- aperm(array(V.data, dim=c(dim(V.data), U$n)), c(1,3,2))

# make a logical array   col.is.data[i,j,k] = is.data[j]
col.is.data <- array(is.data[slice.index(POT, 2)], dim=dim(POT))

# compute value of unsaturated potential sum for each data point i
# obtained after addition/deletion of each dummy/data point j

V.after <- V.dat.rep + ifelseNegPos(col.is.data, POT)
#            The call to ifelseNegPos() is equivalent to
#                     ifelse(col.is.data, -POT, POT)
#
#
# (c) difference of SATURATED potential sums for each data point i
# before & after increment/decrement of each dummy/data point j
#
# saturated values after increment/decrement
V.after.sat <- array(pmin.int(saturate3, V.after), dim=dim(V.after))
# saturated values before
V.dat.rep.sat <- array(pmin.int(saturate3, V.dat.rep), dim=dim(V.dat.rep))
# difference
V.delta <- V.after.sat - V.dat.rep.sat
V.delta <- ifelseNegPos(col.is.data, V.delta)
#
# (d) Sum (c) over all data points i
V.delta.sum <- apply(V.delta, c(2,3), sum)
#
# (e) Result
V <- V.sat + V.delta.sum

##########################################
# remove rows corresponding to supplementary points
if(somemissing)
      V <- V[originalrows, , drop=FALSE]

### tack on the saved computations from pairwise.family$eval
if(savecomputed)
  attr(V, "computed") <- computed

return(V)

},     ######### end of function $eval                            
suffstat = function(model, X=NULL, callstring="pairsat.family$suffstat") {

# for saturated pairwise models only  (possibly nonstationary)
  verifyclass(model, "ppm")
  if(!identical(model$interaction$family$name,"saturated pairwise"))
    stop("Model is not a saturated pairwise interaction process") 

  if(is.null(X)) {
    X <- data.ppm(model)
    modelX <- model
  } else {
    verifyclass(X, "ppp")
    modelX <- update(model, X, method="mpl")
  }

  # find data points which do not contribute to pseudolikelihood
  mplsubset <- getglmdata(modelX)$.mpl.SUBSET
  mpldata   <- is.data(quad.ppm(modelX))
  contribute <- mplsubset[mpldata]
  
  Empty <- X[integer(0)]
  mom <- partialModelMatrix(X, Empty, model, "suffstat", halfway=TRUE)
  # halfway=TRUE is passed to pairsat.family$eval
  # and yields matrix of saturated potential sums 

  # take only those terms that contribute to the pseudolikelihood
  mom <- mom[contribute, , drop=FALSE]
  
  result <- apply(mom, 2, sum)
  return(result)
         

} ######### end of function $suffstat
)     ######### end of list

class(pairsat.family) <- "isf"
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pairwise.R"
#
#
#    pairwise.S
#
#    $Revision: 1.9 $	$Date: 2014/10/24 00:22:30 $
#
#    Pairwise()    create a user-defined pairwise interaction process
#                 [an object of class 'interact']
#	
# -------------------------------------------------------------------
#	

Pairwise <- function(pot, name = "user-defined pairwise interaction process",
                     par = NULL, parnames=NULL,
                     printfun) {

  fop <- names(formals(pot))
  if(!identical(all.equal(fop, c("d", "par")), TRUE)
     && !identical(all.equal(fop, c("d", "tx", "tu", "par")), TRUE))
    stop(paste("Formal arguments of pair potential function",
               sQuote("pot"),
               "must be either (d, par) or (d, tx, tu, par)"))

  if(!is.null(parnames)) {
    stopifnot(is.character(parnames))
    if(is.null(par) || length(par) != length(parnames))
      stop("par does not match parnames")
  }
  if(missing(printfun))
    printfun <- function(self) {
           cat("Potential function:\n")
           print(self$pot)
           if(!is.null(parnames <- self$parnames)) {
             for(i in 1:length(parnames)) {
               cat(paste(parnames[i], ":\t"))
               pari <- self$par[[i]]
               if(is.numeric(pari) && length(pari) == 1)
                 cat(pari, "\n")
               else 
                 print(pari)
             }
           }
         }

  out <- 
  list(
         name     = name,
         creator  = "Pairwise",
         family   = pairwise.family,
         pot      = pot,
         par      = par,
         parnames = parnames,
         init     = NULL,
         update   = function(self, ...){
           do.call(Pairwise,
                   resolve.defaults(list(...),
                                    list(pot=self$pot, name=self$name,
                                         par=self$par, parnames=self$parnames,
                                         printfun=self$print)))
         } , 
         print    = printfun,
         version  = versionstring.spatstat()
  )
  class(out) <- "interact"
  return(out)
}

Pairwise <- intermaker(Pairwise,
                       list(creator="Pairwise",
                            name="user-defined pairwise interaction process",
                            par=formals(Pairwise),
                            parnames=list("the potential",
                                "the name of the interaction",
                                "the list of parameters",
                                "a description of each parameter",
                                "an optional print function")))


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pairwise.family.R"
#
#
#    pairwise.family.S
#
#    $Revision: 1.60 $	$Date: 2014/12/03 02:44:08 $
#
#    The pairwise interaction family of point process models
#
#    pairwise.family:      object of class 'isf' defining pairwise interaction
#	
#
# -------------------------------------------------------------------
#	

pairwise.family <-
  list(
       name  = "pairwise",
       print = function(self) {
         cat("Pairwise interaction family\n")
       },
       plot = function(fint, ..., d=NULL, plotit=TRUE) {
         verifyclass(fint, "fii")
         inter <- fint$interaction
         unitz <- unitname(fint)
         if(is.null(inter) || is.null(inter$family)
            || inter$family$name != "pairwise")
           stop("Tried to plot the wrong kind of interaction")
         # get fitted coefficients of interaction terms
         # and set coefficients of offset terms to 1
         Vnames <- fint$Vnames
         IsOffset <- fint$IsOffset
         coeff <- rep.int(1, length(Vnames))
         names(coeff) <- Vnames
         coeff[!IsOffset] <- fint$coefs[Vnames[!IsOffset]]
         # 
         pairpot <- inter$pot
         potpars <- inter$par
         rmax <- reach(fint, epsilon=1e-3)
         xlim <- list(...)$xlim
         if(is.infinite(rmax)) {
           if(!is.null(xlim))
             rmax <- max(xlim)
           else {
             warning("Reach of interaction is infinite; need xlim to plot it")
             return(invisible(NULL))
           }
         }
         if(is.null(d)) {
           dmax <- 1.25 * rmax
           d <- seq(from=0, to=dmax, length.out=1024)
         } else {
           stopifnot(is.numeric(d) &&
                     all(is.finite(d)) &&
                     all(diff(d) > 0))
           dmax <- max(d)
         }
         if(is.null(xlim))
           xlim <- c(0, dmax)
         types <- potpars$types
         if(is.null(types)) {
           # compute potential function as `fv' object
           dd <- matrix(d, ncol=1)
           p <- pairpot(dd, potpars)
           if(length(dim(p))==2)
             p <- array(p, dim=c(dim(p),1), dimnames=NULL)
           if(dim(p)[3] != length(coeff))
             stop("Dimensions of potential do not match coefficient vector")
           for(k in seq_len(dim(p)[3])) 
             p[,,k] <- multiply.only.finite.entries( p[,,k] , coeff[k] )
           y <- exp(apply(p, c(1,2), sum))
           ylim <- range(0, 1.1, y, finite=TRUE)
           fun <- fv(data.frame(r=d, h=y, one=1),
                     "r", substitute(h(r), NULL), "h", cbind(h,one) ~ r,
                     xlim, c("r", "h(r)", "1"),
                     c("distance argument r",
                       "pairwise interaction term h(r)",
                       "reference value 1"),
                     unitname=unitz)
           if(plotit)
             do.call("plot.fv",
                     resolve.defaults(list(fun),
                                      list(...),
                                      list(ylim=ylim)))
           return(invisible(fun))
         } else{
           # compute each potential and store in `fasp' object
           if(!is.factor(types))
             types <- factor(types, levels=types)
           m <- length(types)
           nd <- length(d)
           dd <- matrix(rep.int(d, m), nrow=nd * m, ncol=m)
           tx <- rep.int(types, rep.int(nd, m))
           ty <- types
           p <- pairpot(dd, tx, ty, potpars)
           if(length(dim(p))==2)
             p <- array(p, dim=c(dim(p),1), dimnames=NULL)
           if(dim(p)[3] != length(coeff))
             stop("Dimensions of potential do not match coefficient vector")
           for(k in seq_len(dim(p)[3]))
             p[,,k] <- multiply.only.finite.entries( p[,,k] , coeff[k] )
           y <- exp(apply(p, c(1,2), sum))
           ylim <- range(0, 1.1, y, finite=TRUE)
           fns <- vector(m^2, mode="list")
           which <- matrix(, m, m)
           for(i in seq_len(m)) {
             for(j in seq_len(m)) {
               # relevant position in matrix
               ijpos <- i + (j-1) * m
               which[i,j] <- ijpos
               # extract values of potential
               yy <- y[tx == types[i], j]
               # make fv object
               fns[[ijpos]] <-
                   fv(data.frame(r=d, h=yy, one=1),
                      "r", substitute(h(r), NULL), "h", cbind(h,one) ~ r,
                      xlim, c("r", "h(r)", "1"),
                      c("distance argument r",
                        "pairwise interaction term h(r)",
                        "reference value 1"),
                      unitname=unitz)
               #
             }
           }
           funz <- fasp(fns, which=which,
                        formulae=list(cbind(h, one) ~ r),
                        title="Fitted pairwise interactions",
                        rowNames=paste(types), colNames=paste(types))
           if(plotit)
             do.call("plot.fasp",
                     resolve.defaults(list(funz),
                                      list(...),
                                      list(ylim=ylim)))
           return(invisible(funz))
         }
       },
       # end of function `plot'
       # ----------------------------------------------------
       eval  = function(X,U,EqualPairs,pairpot,potpars,correction,
           ..., Reach=NULL, precomputed=NULL, savecomputed=FALSE,
           pot.only=FALSE) {
  #
  # This is the eval function for the `pairwise' family.
  # 
  # This internal function is not meant to be called by the user.
  # It is called by mpl.prepare() during execution of ppm().
  #         
  # The eval functions perform all the manipulations that are common to
  # a given class of interactions. 
  #
  # For the `pairwise' family of pairwise-interaction processes,
  # this eval function computes the distances between points,
  # invokes 'pairpot' to evaluate the potential between each pair of points,
  # applies edge corrections, and then sums the pair potential terms.
  #
  # ARGUMENTS:
  #   All 'eval' functions have the following arguments 
  #   which are called in sequence (without formal names)
  #   by mpl.prepare():
  #       
  #   X           data point pattern                      'ppp' object
  #   U           points at which to evaluate potential   list(x,y) suffices
  #   EqualPairs  two-column matrix of indices i, j such that X[i] == U[j]
  #               (or NULL, meaning all comparisons are FALSE)
  #   pot         potential function 
  #   potpars     auxiliary parameters for pot            list(......)
  #   correction  edge correction type                    (string)
  #
  # VALUE:
  #    All `eval' functions must return a        
  #    matrix of values of the total potential
  #    induced by the pattern X at each location given in U.
  #    The rows of this matrix correspond to the rows of U (the sample points);
  #    the k columns are the coordinates of the k-dimensional potential.
  #
  ##########################################################################

  # POTENTIAL:
  #
  # The pair potential function 'pairpot' should be either
  #    pairpot(d, par)            [for potentials that don't depend on marks]
  # or
  #    pairpot(d, tx, tu, par)    [for potentials that do depend on mark]
  # where d is a matrix of interpoint distances,
  # tx is the vector of types for the data points,
  # tu is the vector of types for all quadrature points          
  # and
  #  par is a list of parameters for the potential.
  #         
  # It must return a matrix with the same dimensions as d
  # or an array with its first two dimensions the same as the dimensions of d.

fop <- names(formals(pairpot))
if(identical(all.equal(fop, c("d", "par")), TRUE))
  marx <- FALSE
else if(identical(all.equal(fop, c("d", "tx", "tu", "par")), TRUE))
  marx <- TRUE
else 
  stop("Formal arguments of pair potential function are not understood")

## edge correction argument

if(length(correction) > 1)
  stop("Only one edge correction allowed at a time!")

if(!any(correction == c("periodic", "border", "translate", "translation", "isotropic", "Ripley", "none")))
  stop(paste("Unrecognised edge correction", sQuote(correction)))

 no.correction <- 

#### Compute basic data

   # Decide whether to apply faster algorithm using 'closepairs'
   use.closepairs <-
     (correction %in% c("none", "border", "translate", "translation")) &&
     !is.null(Reach) && is.finite(Reach) &&
     is.null(precomputed) && !savecomputed 

if(!is.null(precomputed)) {
  # precomputed
  X <- precomputed$X
  U <- precomputed$U
  EqualPairs <- precomputed$E
  M <- precomputed$M
} else {
  U <- as.ppp(U, X$window)   # i.e. X$window is DEFAULT window
  if(!use.closepairs) 
    # Form the matrix of distances
    M <- crossdist(X, U, periodic=(correction=="periodic"))
}

nX <- npoints(X)
nU <- npoints(U)
dimM <- c(nX, nU)

# Evaluate the pairwise potential without edge correction

if(use.closepairs)
  POT <- evalPairPotential(X,U,EqualPairs,pairpot,potpars,Reach)
else if(!marx) 
  POT <- pairpot(M, potpars)
else
  POT <- pairpot(M, marks(X), marks(U), potpars)

# Determine whether each column of potential is an offset

  IsOffset <- attr(POT, "IsOffset")

# Check errors and special cases

if(!is.matrix(POT) && !is.array(POT)) {
  if(length(POT) == 0 && X$n ==  0) # empty pattern
    POT <- array(POT, dim=c(dimM,1))
  else
    stop("Pair potential did not return a matrix or array")
}

if(length(dim(POT)) == 1 || any(dim(POT)[1:2] != dimM)) {
        whinge <- paste0(
           "The pair potential function ",short.deparse(substitute(pairpot)),
           " must produce a matrix or array with its first two dimensions\n",
           "the same as the dimensions of its input.\n")
	stop(whinge)
}

# make it a 3D array
if(length(dim(POT))==2)
        POT <- array(POT, dim=c(dim(POT),1), dimnames=NULL)
                          
if(correction == "translate" || correction == "translation") {
        edgewt <- edge.Trans(X, U)
        # sanity check ("everybody knows there ain't no...")
        if(!is.matrix(edgewt))
          stop("internal error: edge.Trans() did not yield a matrix")
        if(nrow(edgewt) != X$n || ncol(edgewt) != length(U$x))
          stop("internal error: edge weights matrix returned by edge.Trans() has wrong dimensions")
        POT <- c(edgewt) * POT
} else if(correction == "isotropic" || correction == "Ripley") {
        # weights are required for contributions from QUADRATURE points
        edgewt <- t(edge.Ripley(U, t(M), X$window))
        if(!is.matrix(edgewt))
          stop("internal error: edge.Ripley() did not return a matrix")
        if(nrow(edgewt) != X$n || ncol(edgewt) != length(U$x))
          stop("internal error: edge weights matrix returned by edge.Ripley() has wrong dimensions")
        POT <- c(edgewt) * POT
}

# No pair potential term between a point and itself
if(length(EqualPairs) > 0) {
  nplanes <- dim(POT)[3]
  for(k in 1:nplanes)
    POT[cbind(EqualPairs, k)] <- 0
}

# Return just the pair potential?
if(pot.only)
  return(POT)

# Sum the pairwise potentials 

V <- apply(POT, c(2,3), sum)

# attach the original pair potentials
attr(V, "POT") <- POT

# attach the offset identifier
attr(V, "IsOffset") <- IsOffset

# pass computed information out the back door
if(savecomputed)
  attr(V, "computed") <- list(E=EqualPairs, M=M)
return(V)

},
######### end of function $eval
       suffstat = function(model, X=NULL, callstring="pairwise.family$suffstat") {
# for pairwise models only  (possibly nonstationary)
  verifyclass(model, "ppm")
  if(!identical(model$interaction$family$name,"pairwise"))
    stop("Model is not a pairwise interaction process")

  if(is.null(X)) {
    X <- data.ppm(model)
    modelX <- model
  } else {
    verifyclass(X, "ppp")
    modelX <- update(model, X, method="mpl")
  }

  # find data points which do not contribute to pseudolikelihood
  mplsubset <- getglmdata(modelX)$.mpl.SUBSET
  mpldata   <- is.data(quad.ppm(modelX))
  contribute <- mplsubset[mpldata]

  Xin  <- X[contribute]
  Xout <- X[!contribute]
  
  # partial model matrix arising from ordered pairs of data points
  # which both contribute to the pseudolikelihood
  Empty <- X[numeric(0)]
  momINxIN <- partialModelMatrix(Xin, Empty, model, "suffstat")

  # partial model matrix arising from ordered pairs of data points
  # the second of which does not contribute to the pseudolikelihood
  mom <- partialModelMatrix(Xout, Xin, model, "suffstat")
  indx <- Xout$n + seq_len(Xin$n)
  momINxOUT <- mom[indx, , drop=FALSE]

  # parameters
  order2  <- names(coef(model)) %in% model$internal$Vnames
  order1  <- !order2

  result <- 0 * coef(model)
  
  if(any(order1)) {
    # first order contributions can be determined from INxIN
    o1terms  <- momINxIN[ , order1, drop=FALSE]
    o1sum   <- colSums(o1terms)
    result[order1] <- o1sum
  }
  if(any(order2)) {
    # adjust for double counting of ordered pairs in INxIN but not INxOUT
    o2termsINxIN  <- momINxIN[, order2, drop=FALSE]
    o2termsINxOUT <- momINxOUT[, order2, drop=FALSE]
    o2sum   <- colSums(o2termsINxIN)/2 + colSums(o2termsINxOUT)
    result[order2] <- o2sum
  }

  return(result)
  },
######### end of function $suffstat
  delta2 = function(X, inte, correction, ...) {
  # Sufficient statistic for second order conditional intensity
  # for pairwise interaction processes
  # Equivalent to evaluating pair potential.
    X <- as.ppp(X)
    seqX <- seq_len(npoints(X))
    E <- cbind(seqX, seqX)
    R <- reach(inte)
    result <- pairwise.family$eval(X,X,E,
                                 inte$pot,inte$par,
                                 correction,
                                 pot.only=TRUE,
                                 Reach=R)
  }
######### end of function $delta2
)
######### end of list

class(pairwise.family) <- "isf"


# externally visible

evalPairPotential <- function(X, P, E, pairpot, potpars, R) {
  # Evaluate pair potential without edge correction weights
  nX <- npoints(X)
  nP <- npoints(P)
  stopifnot(is.function(pairpot))
  fop <- names(formals(pairpot))
  if(identical(all.equal(fop, c("d", "par")), TRUE)) {
    unmarked <- TRUE
  } else if(identical(all.equal(fop, c("d", "tx", "tu", "par")), TRUE)) {
    unmarked <- FALSE
  } else 
  stop("Formal arguments of pair potential function are not understood")
  # determine dimension of potential, etc
  fakePOT <- if(unmarked) pairpot(matrix(, 0, 0), potpars) else 
                          pairpot(matrix(, 0, 0),
                                  marks(X)[integer(0)],
                                  marks(P)[integer(0)],
                                  potpars)
  IsOffset <- attr(fakePOT, "IsOffset")
  fakePOT <- ensure3Darray(fakePOT)
  Vnames <- dimnames(fakePOT)[[3]]
  p <- dim(fakePOT)[3]
  # Identify close pairs X[i], P[j]
  cl <- crosspairs(X, P, R)
  I <- cl$i
  J <- cl$j
  D <- matrix(cl$d, ncol=1)
  # deal with empty cases
  if(nX == 0 || nP == 0 || length(I) == 0) {
    result <- array(0, dim=c(nX, nP, p), dimnames=list(NULL, NULL, Vnames))
    attr(result, "IsOffset") <- IsOffset
    return(result)
  }
  # evaluate potential for close pairs
  # POT is a 1-column matrix or array, with rows corresponding to close pairs
  if(unmarked) {
    # unmarked
    POT <- pairpot(D, potpars)
    IsOffset <- attr(POT, "IsOffset")
  } else {
    # marked
    marX <- marks(X)
    marP <- marks(P)
    if(!identical(levels(marX), levels(marP)))
      stop("Internal error: marks of X and P have different levels")
    types <- levels(marX)
    mI <- marX[I]
    mJ <- marP[J]
    POT <- NULL
    # split data by type of P[j]
    for(k in types) {
      relevant <- which(mJ == k)
      if(length(relevant) > 0) {
        fk <- factor(k, levels=types)
        POTk <- pairpot(D[relevant,  , drop=FALSE], mI[relevant], fk, potpars)
        POTk <- ensure3Darray(POTk)
        if(is.null(POT)) {
          # use first result of 'pairpot' to determine dimension
          POT <- array(, dim=c(length(I), 1, dim(POTk)[3]))
          # capture information about offsets, and names of interaction terms
          IsOffset <- attr(POTk, "IsOffset")
          Vnames <- dimnames(POTk)[[3]]
        }
        # insert values just computed
        POT[relevant, , ] <- POTk
      }
    }
  }
  POT <- ensure3Darray(POT)
  p <- dim(POT)[3]
  # create result array
  result <- array(0, dim=c(npoints(X), npoints(P), p),
                  dimnames=list(NULL, NULL, Vnames))
  # insert results
  II <- rep(I, p)
  JJ <- rep(J, p)
  KK <- rep(1:p, each=length(I))
  result[cbind(II,JJ,KK)] <- POT
  # finally identify identical pairs and set value to 0
  if(length(E) > 0) {
    E.rep <- apply(E, 2, rep, times=p)
    p.rep <- rep(1:p, each=nrow(E))
    result[cbind(E.rep, p.rep)] <- 0
  }
  attr(result, "IsOffset") <- IsOffset
  return(result)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/parres.R"
#
# parres.R
#
# code to plot transformation diagnostic
#
#   $Revision: 1.4 $  $Date: 2014/11/10 11:02:35 $
#

parres <- function(model, covariate, ...,
                   smooth.effect=FALSE, subregion=NULL,
                   bw="nrd0", adjust=1, from=NULL,to=NULL, n=512,
                   bw.input = c("points", "quad"),
                   bw.restrict = FALSE,
                   covname) {  

  modelname <- deparse(substitute(model))
  if(missing(covname)) 
    covname <- sensiblevarname(deparse(substitute(covariate)), "X")
  callstring <- paste(deparse(sys.call()), collapse = "")

  if(!is.null(subregion)) 
    stopifnot(is.owin(subregion))
  
  if(is.null(adjust)) adjust <- 1

  bw.input <- match.arg(bw.input)
  
  # validate model
  stopifnot(is.ppm(model))
  modelcall <- model$callstring
  if(is.null(modelcall))
    modelcall <- model$call
  if(is.null(getglmfit(model)))
    model <- update(model, forcefit=TRUE)
  
  # extract spatial locations
  Q <- quad.ppm(model)
#  datapoints <- Q$data
  quadpoints <- union.quad(Q)
  Z <- is.data(Q)
  wts <- w.quad(Q)
  nQ <- npoints(quadpoints)
  # fitted intensity
  lam <- fitted(model, type="trend")
  # subset of quadrature points used to fit model
  subQset <- getglmsubset(model)
  if(is.null(subQset)) subQset <- rep.int(TRUE, nQ)
  # restriction to subregion
  insubregion <- if(!is.null(subregion)) {
    inside.owin(quadpoints, w=subregion)
  } else rep.int(TRUE, nQ)

  ################################################################
  # Inverse lambda residuals

  rx <- residuals(model, type="inverse")
  resid <- with(rx, "increment")

  #################################################################
  # identify the covariate
  #
  if(length(covariate) == 0)
    stop("No covariate specified")

  covtype <- "unknown"

  if(!is.character(covariate)) {
    # Covariate is some kind of data, treated as external covariate
    covtype <- "external"
    beta <- 0
    covvalues <- evalCovariate(covariate, quadpoints)
  } else {
    # Argument is name of covariate
    covname <- covariate
    if(length(covname) > 1)
      stop("Must specify only one covariate")
    # 'original covariates'
    orig.covars <- variablesinformula(formula(model))
    # 'canonical covariates'
    canon.covars <- names(coef(model))
    # offsets
    offset.covars <- offsetsinformula(formula(model))
    # 
    if(covname %in% orig.covars) {
      # one of the original covariates
      covtype <- "original"
      covvalues <- evalCovariate(findCovariate(covname, model), quadpoints)
    } else if(covname %in% canon.covars) {
      # one of the canonical covariates
      covtype <- "canonical"
      mm <- model.matrix(model)
      covvalues <- mm[, covname]
      ## extract the corresponding coefficient
      beta <- coef(model)[[covname]]
    } else if(covname %in% offset.covars) {
      # an offset term only
      covtype <- "offset"
      mf <- model.frame(model, subset=rep.int(TRUE, n.quad(Q)))
      if(!(covname %in% colnames(mf)))
        stop(paste("Internal error: offset term", covname,
                   "not found in model frame"))
      covvalues <- mf[, covname]
      ## fixed coefficient (not an estimated parameter)
      beta <- 1
    } else{
      # must be an external covariate (i.e. not used in fitted model)
      covtype <- "external"
      beta <- 0
      covvalues <- evalCovariate(findCovariate(covname, model), quadpoints)
    }
  }
  # validate covvalues
  #
  if(is.null(covvalues))
    stop("Unable to extract covariate values")
  if(length(covvalues) != npoints(quadpoints))
    stop(paste("Internal error: number of covariate values =",
               length(covvalues), "!=", npoints(quadpoints),
               "= number of quadrature points"))
  vtype <- typeof(covvalues)
  switch(vtype,
         real=,
         double = { },
         integer = {
           warning("Covariate is integer-valued")
         },
         stop(paste("Cannot handle covariate of type", sQuote(vtype))))
  
  #################################################################
  # Compute covariate effect

  if(covtype != "original") {
    effect <- beta * covvalues
    mediator <- covtype
    effectfundata <- list(beta=beta)
    effectFun <- function(x) { (effectfundata$beta) * x }
    isoffset <- (covtype == "offset")
    names(isoffset) <- covname
  } else {
    ## `original' covariate (passed as argument to ppm)
    ## may determine one or more canonical covariates and/or offsets
    origcovdf <- getppmOriginalCovariates(model)[insubregion, , drop=FALSE]
    isconstant <- lapply(origcovdf,
                         function(z) { length(unique(z)) == 1 })
    ##
    ## Initialise
    termnames <- character(0)
    termbetas <- numeric(0)
    isoffset <- logical(0)
    mediator <- character(0)
    effect <- 0
    effectFun <- function(x) { effectFun.can(x) + effectFun.off(x) }
    effectFun.can <- effectFun.off <- function(x) { 0 * x }
    ## Identify relevant canonical covariates
    dmat <- model.depends(model)
    if(!(covname %in% colnames(dmat)))
      stop("Internal error: cannot match covariate names")
    othercov <- (colnames(dmat) != covname)
    relevant <- dmat[, covname]
    if(any(relevant)) {
      # original covariate determines one or more canonical covariates
      mediator <- "canonical"
      # check whether covariate is separable
      if(any(conflict <- dmat[relevant, othercov, drop=FALSE])) {
        ## identify entangled covariates
        entangled <- colnames(conflict)[apply(conflict, 2, any)]
        ## not problematic if constant
        ok <- unlist(isconstant[entangled])
        conflict[ , ok] <- FALSE
        ## re-test
        if(any(conflict)) {
          conflictterms <- apply(conflict, 1, any)
          conflictcovs  <- apply(conflict, 2, any)
          stop(paste("The covariate", sQuote(covname),
                     "cannot be separated from the",
                     ngettext(sum(conflictcovs), "covariate", "covariates"),
                     commasep(sQuote(colnames(conflict)[conflictcovs])),
                     "in the model",
                     ngettext(sum(conflictterms), "term", "terms"),
                     commasep(sQuote(rownames(conflict)[conflictterms]))
                     ))
        }
      }
      # 
      termnames <- rownames(dmat)[relevant]
      isoffset <- rep.int(FALSE, length(termnames))
      names(isoffset) <- termnames
      # Extract relevant canonical covariates
      mm <-  model.matrix(model)
      termvalues <- mm[, relevant, drop=FALSE]
      # extract corresponding coefficients
      termbetas <- coef(model)[relevant]
      # evaluate model effect
      effect <- as.numeric(termvalues %*% termbetas)
      # check length
      if(length(effect) != npoints(quadpoints))
        stop(paste("Internal error: number of values of fitted effect =",
                   length(effect), "!=", npoints(quadpoints),
                   "= number of quadrature points"))
      # Trap loglinear case
      if(length(termnames) == 1 && identical(termnames, covname)) {
        covtype <- "canonical"
        beta <- termbetas
      }
      # construct the corresponding function
      gd <- getglmdata(model)
      goodrow <- min(which(complete.cases(gd)))
      defaultdata <- gd[goodrow, , drop=FALSE]
      effectfundata.can <- list(covname=covname,
                            fmla = formula(model),
                            termbetas = termbetas,
                            defaultdata = defaultdata,
                            relevant = relevant,
                            termnames = termnames)
      effectFun.can <- function(x) {
        d <- effectfundata.can
        # replicate default data to correct length
        df <- as.data.frame(lapply(d$defaultdata, rep, length(x)))
        # overwrite value of covariate with new data
        df[,covname] <- x
        # construct model matrix 
        m <- model.matrix(d$fmla, df)
        # check it conforms to expected structure
        if(!identical(colnames(m)[d$relevant], d$termnames))
          stop("Internal error: mismatch in term names in effectFun")
        me <- m[, d$relevant, drop=FALSE]
        y <- me %*% as.matrix(d$termbetas, ncol=1) 
        return(y)
      }
    }
    if(!is.null(offmat <- attr(dmat, "offset")) &&
       any(relevant <- offmat[, covname])) {
      # covariate appears in a model offset term
      mediator <- c(mediator, "offset")
      # check whether covariate is separable
      if(any(conflict<- offmat[relevant, othercov, drop=FALSE])) {
        ## identify entangled covariates
        entangled <- colnames(conflict)[apply(conflict, 2, any)]
        ## not problematic if constant
        ok <- unlist(isconstant[entangled])
        conflict[ , ok] <- FALSE
        ## re-test
        if(any(conflict)) {
          conflictterms <- apply(conflict, 1, any)
          conflictcovs  <- apply(conflict, 2, any)
          stop(paste("The covariate", sQuote(covname),
                     "cannot be separated from the",
                     ngettext(sum(conflictcovs), "covariate", "covariates"),
                     commasep(sQuote(colnames(conflict)[conflictcovs])),
                     "in the model",
                     ngettext(sum(conflictterms), "term", "terms"),
                     commasep(sQuote(rownames(conflict)[conflictterms]))
                     ))
        }
      }
      # collect information about relevant offset 
      offnames <- rownames(offmat)[relevant]
      termnames <- c(termnames, offnames)
      noff <- length(offnames)
      termbetas <- c(termbetas, rep.int(1, noff))
      isoffset  <- c(isoffset, rep.int(TRUE, noff))
      names(termbetas) <- names(isoffset) <- termnames
      # extract values of relevant offset 
      mf <- model.frame(model, subset=rep.int(TRUE, n.quad(Q)))
      if(any(nbg <- !(offnames %in% colnames(mf))))
        stop(paste("Internal error:",
                   ngettext(sum(nbg), "offset term", "offset terms"),
                   offnames[nbg],
                   "not found in model frame"))
      effex <- mf[, offnames, drop=FALSE]
      effect <- effect + apply(effex, 1, sum)
      #
      # construct the corresponding function
      gd <- getglmdata(model)
      goodrow <- min(which(complete.cases(gd)))
      defaultdata <- gd[goodrow, , drop=FALSE]
      effectfundata.off <- list(covname=covname,
                                fmla = formula(model),
                                defaultdata = defaultdata,
                                offnames = offnames)
      effectFun.off <- function(x) {
        d <- effectfundata.off
        # replicate default data to correct length
        df <- as.data.frame(lapply(d$defaultdata, rep, length(x)))
        # overwrite value of covariate with new data
        df[,covname] <- x
        # construct model FRAME
        mf <- model.frame(d$fmla, df)
        # check it conforms to expected structure
        if(!all(d$offnames %in% colnames(mf))) 
          stop("Internal error: mismatch in term names in effectFun")
        moff <- mf[, d$offnames, drop=FALSE]
        y <- apply(moff, 1, sum)
        return(y)
      }
    }
    if(length(termnames) == 0) {
      # Sanity clause
      # (everyone knows there ain't no Sanity Clause...)
      warning(paste("Internal error: could not find any",
                    "canonical covariates or offset terms",
                    "that depended on the covariate", sQuote(covname)))
      # Assume it's an external covariate (i.e. not used in fitted model)
      covtype <- "external"
      beta <- 0
      effect <- beta * covvalues
      effectFun <- function(x) { 0 * x }
      isoffset <- FALSE
      names(isoffset) <- covname
    }
  }

  #### Canonical covariates and coefficients
  switch(covtype,
         original={
           cancovs <- termnames
           canbeta <- termbetas
         },
         offset = ,
         canonical={
           cancovs <- covname
           canbeta <- beta
         },
         external={
           cancovs <- canbeta <- NA
         })
  
  #################################################################
  # Validate covariate values

  # locations that must have finite values 
  operative <- if(bw.restrict) insubregion & subQset else subQset

  nbg.cov <- !is.finite(covvalues)
  if(any(offending <- nbg.cov & operative)) {
    warning(paste(sum(offending), "out of", length(offending),
                  "covariate values discarded because",
                  ngettext(sum(offending), "it is", "they are"),
                  "NA or infinite"))
  }

  nbg.eff <- !is.finite(effect)
  if(any(offending <- nbg.eff & operative)) {
    warning(paste(sum(offending), "out of", length(offending),
                  "values of fitted effect discarded because",
                  ngettext(sum(offending), "it is", "they are"),
                  "NA or infinite"))
  }
  
  #################################################################
  # Restrict data to 'operative' points
  #                            with finite values
  
  nbg <- nbg.cov | nbg.eff
  ok <- !nbg & operative
  
  Q           <- Q[ok]
  covvalues   <- covvalues[ok]
  quadpoints  <- quadpoints[ok]
  resid       <- resid[ok]
  lam         <- lam[ok]
  effect      <- effect[ok]
  insubregion <- insubregion[ok]
  Z           <- Z[ok]
  wts         <- wts[ok]

  ####################################################
  # assemble data for smoothing 
  x <- covvalues
  y <- resid/wts
  if(smooth.effect) y <- y + effect 
  w <- wts
  #
  if(makefrom <- is.null(from))
    from <- min(x)
  if(maketo <- is.null(to))
    to   <- max(x)

  ####################################################
  # determine smoothing bandwidth
  #     from 'operative' data

  switch(bw.input,
         quad = {
           # bandwidth selection from covariate values at all quadrature points
           numer <- unnormdensity(x, weights=w*y,
                                  bw=bw, adjust=adjust,
                                  n=n,from=from,to=to, ...)
           sigma <- numer$bw
         },
         points= {
           # bandwidth selection from covariate values at data points
           fake <- unnormdensity(x[Z], weights=1/lam[Z],
                                 bw=bw, adjust=adjust,
                                 n=n,from=from,to=to, ...)
           sigma <- fake$bw
           numer <- unnormdensity(x, weights=w*y,
                                  bw=sigma, adjust=1,
                                  n=n,from=from,to=to, ...)
         })


  ####################################################
  # Restrict data and recompute numerator if required

  if(!is.null(subregion) && !bw.restrict) {
    # Bandwidth was computed on all data
    # Restrict to subregion and recompute numerator
    x   <- x[insubregion]
    y   <- y[insubregion]
    w   <- w[insubregion]
    Z   <- Z[insubregion]
    lam <- lam[insubregion]
    if(makefrom) from <- min(x)
    if(maketo)     to <- max(x)
    numer <- unnormdensity(x, weights=w*y,
                           bw=sigma, adjust=1,
                           n=n,from=from,to=to, ...)
  }

  ####################################################
  # Compute denominator

  denom <- unnormdensity(x, weights=w,
                         bw=sigma, adjust=1,
                         n=n,from=from,to=to, ...)

  
  ####################################################
  # Determine recommended plot range

  xr <- range(x[Z], finite=TRUE)
  alim <- xr + 0.1 * diff(xr) * c(-1,1)
  alim <- intersect.ranges(alim, c(from, to))
  
  ####################################################
  # Compute terms 

  interpolate <- function(x,y) {
    if(inherits(x, "density") && missing(y))
      approxfun(x$x, x$y, rule=2)
    else 
      approxfun(x, y, rule=2)
  }
  numfun <- interpolate(numer)
  denfun <- interpolate(denom)
  xxx <- numer$x
  yyy <- numfun(xxx)/denfun(xxx)
  # variance estimation
  # smooth 1/lambda(u) with smaller bandwidth
  tau   <- sigma/sqrt(2)
  varnumer <- unnormdensity(x, weights=w/lam,
                            bw=tau, adjust=1,
                            n=n,from=from,to=to, ...)
  varnumfun <- interpolate(varnumer)
  varestxxx <- varnumfun(xxx)/(2 * sigma * sqrt(pi) * denfun(xxx)^2)
  sd <- sqrt(varestxxx)
  # alternative estimate of variance using data points only
  varXnumer <- unnormdensity(x[Z], weights=1/lam[Z]^2,
                             bw=tau, adjust=1,
                             n=n,from=from,to=to, ...)
  varXnumfun <- interpolate(varXnumer)
  varXestxxx <- varXnumfun(xxx)/(2 * sigma * sqrt(pi) * denfun(xxx)^2)
  sdX <- sqrt(varXestxxx)
  # fitted effect
  effxxx <- effectFun(xxx)
  
  # add fitted effect of covariate, if not added before smoothing
  if(!smooth.effect)
    yyy <- yyy + effxxx
  
  ####################################################
  # pack into fv object
  
  df <- data.frame(xxx=xxx,
                   h  =yyy,
                   varh=varestxxx,
                   hi=yyy+2*sd,
                   lo=yyy-2*sd,
                   hiX=yyy+2*sdX,
                   loX=yyy-2*sdX,
                   fit=effxxx)
  # remove any funny characters in name of covariate (e.g. if it is an offset)
  Covname <- make.names(covname)
  names(df)[1] <- Covname
  desc <- c(paste("covariate", sQuote(covname)),
            "Smoothed partial residual",
            "Variance",
            "Upper limit of pointwise 5%% significance band (integral)",
            "Lower limit of pointwise 5%% significance band (integral)",
            "Upper limit of pointwise 5%% significance band (sum)",
            "Lower limit of pointwise 5%% significance band (sum)",
            paste("Parametric fitted effect of", sQuote(covname)))
  rslt <- fv(df,
             argu=Covname,
             ylab=substitute(h(X), list(X=as.name(covname))),
             valu="h",
             fmla= as.formula(paste(". ~ ", Covname)),
             alim=alim,
             labl=c(covname,
               paste("%s", paren(covname), sep=""),
               paste("var", paren(covname), sep=""),
               paste("hi", paren(covname), sep=""),
               paste("lo", paren(covname), sep=""),
               paste("hiX", paren(covname), sep=""),
               paste("loX", paren(covname), sep=""),
               paste("fit", paren(covname), sep="")),
             desc=desc,
             fname="h",
             yexp=as.expression(substitute(hat(h)(X), list(X=covname))))
  attr(rslt, "dotnames") <- c("h", "hi", "lo", "fit")
  fvnames(rslt, ".s") <- c("hi", "lo")
  # add special class data
  class(rslt) <- c("parres", class(rslt))
  attr(rslt, "stuff") <- list(covname       = paste(covname, collapse=""),
                              covtype       = covtype,
                              mediator      = mediator,
                              cancovs       = cancovs,
                              canbeta       = canbeta,
                              isoffset      = isoffset,
                              modelname     = modelname,
                              modelcall     = modelcall,
                              callstring    = callstring,
                              sigma         = sigma,
                              smooth.effect = smooth.effect,
                              restricted    = !is.null(subregion),
                              bw.input      = bw.input)
  return(rslt)
}

print.parres <- function(x, ...) {
  cat("Transformation diagnostic (class parres)\n")
  s <- attr(x, "stuff")
  cat(paste("for the", s$covtype, "covariate", sQuote(s$covname),
            if(s$covtype != "external") "in" else "for",
            "the fitted model",
            if(nchar(s$modelcall) < 30) "" else "\n\t",
            s$modelcall, "\n"))
  switch(s$covtype,
         original={
           cancovs <- s$cancovs
           med <- s$mediator
           isoffset <- s$isoffset
           if(is.null(isoffset)) isoffset <- rep.int(FALSE, length(cancovs))
           ncc <- length(cancovs)
           noff <- sum(isoffset)
           nother <- sum(!isoffset)
           explain <-
             paste(ngettext(ncc, "Fitted effect:", "Fitted effect: sum of"),
                   if(noff == 0) {
                     paste(paste(med, collapse=" and "),
                           ngettext(ncc, "term", "terms"),
                           commasep(dQuote(cancovs)))
                   } else {
                     paste(paste(med[med != "offset"], collapse=" and "),
                           ngettext(nother, "term", "terms"),
                           commasep(dQuote(cancovs[!isoffset])),
                           "and offset",
                           ngettext(noff, "term", "terms"),
                           commasep(dQuote(cancovs[isoffset])))
                   })
           cat(paste(explain, "\n"))
         },
         external={
           cat("Note: effect estimate not justified by delta method\n")
         },
         offset={},
         canonical={})
  # earlier versions were equivalent to restricted=FALSE
  if(identical(s$restricted, TRUE))
    cat("\t--Diagnostic computed for a subregion--\n")
  cat(paste("Call:", s$callstring, "\n"))
  cat(paste("Actual smoothing bandwidth sigma =", signif(s$sigma,5), "\n"))
  # earlier versions were equivalent to smooth.effect=TRUE
  sme <- !identical(s$smooth.effect, FALSE)
  if(sme) {
    cat("Algorithm: smooth(effect + residual)\n\n")
  } else {
    cat("Algorithm: effect + smooth(residual)\n\n")
  }
  NextMethod("print")
}

plot.parres <- function(x, ...) {
  xname <- deparse(substitute(x))
  do.call("plot.fv", resolve.defaults(list(x), list(...),
                                      list(main=xname, shade=c("hi", "lo"))))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pcf.R"
#
#   pcf.R
#
#   $Revision: 1.52 $   $Date: 2014/11/10 11:06:53 $
#
#
#   calculate pair correlation function
#   from point pattern (pcf.ppp)
#   or from estimate of K or Kcross (pcf.fv)
#   or from fasp object
#
#
pcf <- function(X, ...) {
  UseMethod("pcf")
}

pcf.ppp <- function(X, ..., r=NULL,
                    kernel="epanechnikov", bw=NULL, stoyan=0.15,
                    correction=c("translate", "Ripley"),
                    divisor=c("r", "d"),
                    domain=NULL)
{
  verifyclass(X, "ppp")
#  r.override <- !is.null(r)

  win <- X$window
  areaW <- area(win)
  lambda <- X$n/areaW
  lambda2area <- areaW * lambda^2

  if(!is.null(domain)) {
    # estimate based on contributions from a subdomain
    domain <- as.owin(domain)
    if(!is.subset.owin(domain, win))
      stop(paste(dQuote("domain"),
                 "is not a subset of the window of X"))
    # trick pcfdot() into doing it
    indom <- factor(inside.owin(X$x, X$y, domain), levels=c(FALSE,TRUE))
    g <- pcfdot(X %mark% indom,
                i="TRUE",
                r=r,
                correction=correction, kernel=kernel, bw=bw, stoyan=stoyan,
                divisor=divisor,
                ...)
    # relabel and exit
    g <- rebadge.fv(g, quote(g(r)), "g")
    return(g)
  }

  correction.given <- !missing(correction)
  correction <- pickoption("correction", correction,
                           c(isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             best="best"),
                           multi=TRUE)

  correction <- implemented.for.K(correction, win$type, correction.given)

  divisor <- match.arg(divisor)
  
  # bandwidth
  if(is.null(bw) && kernel=="epanechnikov") {
    # Stoyan & Stoyan 1995, eq (15.16), page 285
    h <- stoyan /sqrt(lambda)
    hmax <- h
    # conversion to standard deviation
    bw <- h/sqrt(5)
  } else if(is.numeric(bw)) {
    # standard deviation of kernel specified
    # upper bound on half-width
    hmax <- 3 * bw
  } else {
    # data-dependent bandwidth selection: guess upper bound on half-width
    hmax <- 2 * stoyan /sqrt(lambda)
  }

  ########## r values ############################
  # handle arguments r and breaks 

  rmaxdefault <- rmax.rule("K", win, lambda)        
  breaks <- handle.r.b.args(r, NULL, win, rmaxdefault=rmaxdefault)
  if(!(breaks$even))
    stop("r values must be evenly spaced")
  # extract r values
  r <- breaks$r
  rmax <- breaks$max
  # recommended range of r values for plotting
  alim <- c(0, min(rmax, rmaxdefault))

  # arguments for 'density'
  denargs <- resolve.defaults(list(kernel=kernel, bw=bw),
                              list(...),
                              list(n=length(r), from=0, to=rmax))
  
  #################################################
  
  # compute pairwise distances
  
  close <- closepairs(X, rmax + hmax)
  dIJ <- close$d

  # initialise fv object
  
  df <- data.frame(r=r, theo=rep.int(1,length(r)))
  out <- fv(df, "r",
            quote(g(r)), "theo", ,
            alim,
            c("r","%s[Pois](r)"),
            c("distance argument r", "theoretical Poisson %s"),
            fname="g")

  ###### compute #######

  if(any(correction=="translate")) {
    # translation correction
    edgewt <- edge.Trans(dx=close$dx, dy=close$dy, W=win, paired=TRUE)
    gT <- sewpcf(dIJ, edgewt, denargs, lambda2area, divisor)$g
    out <- bind.fv(out,
                   data.frame(trans=gT),
                   "hat(%s)[Trans](r)",
                   "translation-corrected estimate of %s",
                   "trans")
  }
  if(any(correction=="isotropic")) {
    # Ripley isotropic correction
    XI <- ppp(close$xi, close$yi, window=win, check=FALSE)
    edgewt <- edge.Ripley(XI, matrix(dIJ, ncol=1))
    gR <- sewpcf(dIJ, edgewt, denargs, lambda2area, divisor)$g
    out <- bind.fv(out,
                   data.frame(iso=gR),
                   "hat(%s)[Ripley](r)",
                   "isotropic-corrected estimate of %s",
                   "iso")
  }
  
  # sanity check
  if(is.null(out)) {
    warning("Nothing computed - no edge corrections chosen")
    return(NULL)
  }
  
  # default is to display all corrections
  formula(out) <- . ~ r
  #
  unitname(out) <- unitname(X)
  return(out)
}

# Smoothing Estimate of Weighted Pair Correlation
# d = vector of relevant distances
# w = vector of edge correction weights (in normal use)
# denargs = arguments to density.default
# lambda2area = constant lambda^2 * areaW (in normal use)

sewpcf <- function(d, w, denargs, lambda2area, divisor=c("r","d")) {
  divisor <- match.arg(divisor)
  if(divisor == "d") {
    w <- w/d
    if(!all(good <- is.finite(w))) {
      nbad <- sum(!good)
      warning(paste(nbad, "infinite or NA",
                    ngettext(nbad, "contribution was", "contributions were"),
                    "deleted from pcf estimate"))
      d <- d[good]
      w <- w[good]
    }
  }
  wtot <- sum(w)
  kden <- do.call.matched("density.default",
                  append(list(x=d, weights=w/wtot), denargs))
  r <- kden$x
  y <- kden$y * wtot
  if(divisor == "r")
    y <- y/r
  g <- y/(2 * pi * lambda2area)
  return(data.frame(r=r,g=g))
}

#
#---------- OTHER METHODS FOR pcf --------------------
#

"pcf.fasp" <- function(X, ..., method="c") {
  verifyclass(X, "fasp")
  Y <- X
  Y$title <- paste("Array of pair correlation functions",
                   if(!is.null(X$dataname)) "for",
                   X$dataname)
  # go to work on each function
  for(i in seq_along(X$fns)) {
    Xi <- X$fns[[i]]
    PCFi <- pcf.fv(Xi, ..., method=method)
    Y$fns[[i]] <- PCFi
    if(is.fv(PCFi))
      Y$default.formula[[i]] <- formula(PCFi)
  }
  return(Y)
}


pcf.fv <- local({

  callmatched <- function(fun, argue) {
    formalnames <- names(formals(fun))
    formalnames <- formalnames[formalnames != "..."]
    do.call("fun", argue[names(argue) %in% formalnames])
  }

  pcf.fv <- function(X, ..., method="c") {
    verifyclass(X, "fv")
  
    # extract r and the recommended estimate of K
    r <- with(X, .x)
    K <- with(X, .y)
    alim <- attr(X, "alim")

    # remove NA's
    ok <- !is.na(K)
    K <- K[ok]
    r <- r[ok]
    switch(method,
           a = {
             ss <- callmatched(smooth.spline,
                               list(x=r, y=K, ...))
             dK <- predict(ss, r, deriv=1)$y
             g <- dK/(2 * pi * r)
           },
           b = {
             y <- K/(2 * pi * r)
             y[!is.finite(y)] <- 0
             ss <- callmatched(smooth.spline,
                               list(x=r, y=y, ...))
             dy <- predict(ss, r, deriv=1)$y
             g <- dy + y/r
           },
           c = {
             z <- K/(pi * r^2)
             z[!is.finite(z)] <- 1
             ss <- callmatched(smooth.spline,
                               list(x=r, y=z, ...))
             dz <- predict(ss, r, deriv=1)$y
             g <- (r/2) * dz + z
           },
           d = {
             z <- sqrt(K)
             z[!is.finite(z)] <- 0
             ss <- callmatched(smooth.spline,
                               list(x=r, y=z, ...))
             dz <- predict(ss, r, deriv=1)$y
             g <- z * dz/(pi * r)
           },
           stop(paste("unrecognised method", sQuote(method)))
           )

    # pack result into "fv" data frame
    Z <- fv(data.frame(r=r,
                       theo=rep.int(1, length(r)),
                       pcf=g),
            "r", substitute(g(r), NULL), "pcf", . ~ r, alim,
            c("r", "%s[pois](r)", "%s(r)"),
            c("distance argument r",
              "theoretical Poisson value of %s",
              "estimate of %s by numerical differentiation"),
            fname="g")
    unitname(Z) <- unitname(X)
    return(Z)
  }

  pcf.fv
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pcfinhom.R"
#
#   pcfinhom.R
#
#   $Revision: 1.16 $   $Date: 2014/11/10 11:03:53 $
#
#   inhomogeneous pair correlation function of point pattern 
#
#

pcfinhom <- function(X, lambda=NULL, ..., r=NULL,
                     kernel="epanechnikov", bw=NULL, stoyan=0.15,
                     correction=c("translate", "Ripley"),
                     divisor=c("r","d"),
                     renormalise=TRUE,
                     normpower=1,
                     reciplambda=NULL, 
                     sigma=NULL, varcov=NULL)
{
  verifyclass(X, "ppp")
#  r.override <- !is.null(r)

  win <- X$window
  areaW <- area(win)
  npts <- npoints(X)
  
  correction.given <- !missing(correction)
  correction <- pickoption("correction", correction,
                           c(isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             best="best"),
                           multi=TRUE)

  correction <- implemented.for.K(correction, win$type, correction.given)

  divisor <- match.arg(divisor)
  
  if(is.null(bw) && kernel=="epanechnikov") {
    # Stoyan & Stoyan 1995, eq (15.16), page 285
    h <- stoyan /sqrt(npts/areaW)
    hmax <- h
    # conversion to standard deviation
    bw <- h/sqrt(5)
  } else if(is.numeric(bw)) {
    # standard deviation of kernel specified
    # upper bound on half-width
    hmax <- 3 * bw
  } else {
    # data-dependent bandwidth selection: guess upper bound on half-width
    hmax <- 2 * stoyan /sqrt(npts/areaW)
  }


  ########## intensity values #########################

  dangerous <- c("lambda", "reciplambda")
  danger <- TRUE
  
  if(missing(lambda) && is.null(reciplambda)) {
    # No intensity data provided
    danger <- FALSE
    # Estimate density by leave-one-out kernel smoothing
    lambda <- density(X, ..., sigma=sigma, varcov=varcov,
                      at="points", leaveoneout=TRUE)
    lambda <- as.numeric(lambda)
    reciplambda <- 1/lambda
  } else if(!is.null(reciplambda)) {
    # 1/lambda values provided
    if(is.im(reciplambda)) 
      reciplambda <- safelookup(reciplambda, X)
    else if(is.function(reciplambda))
      reciplambda <- reciplambda(X$x, X$y)
    else if(is.numeric(reciplambda) && is.vector(as.numeric(reciplambda)))
      check.nvector(reciplambda, npts)
    else stop(paste(sQuote("reciplambda"),
                    "should be a vector, a pixel image, or a function"))
  } else {
    # lambda values provided
    if(is.im(lambda)) 
      lambda <- safelookup(lambda, X)
    else if(is.ppm(lambda))
      lambda <- predict(lambda, locations=X, type="trend")
    else if(is.function(lambda)) 
      lambda <- lambda(X$x, X$y)
    else if(is.numeric(lambda) && is.vector(as.numeric(lambda)))
      check.nvector(lambda, npts)
    else stop(paste(sQuote("lambda"),
                    "should be a vector, a pixel image, or a function"))
    # evaluate reciprocal
    reciplambda <- 1/lambda
  }
  
  # renormalise
  if(renormalise) {
    check.1.real(normpower)
    stopifnot(normpower %in% 1:2)
    renorm.factor <- (areaW/sum(reciplambda))^normpower
  } 
  
  ########## r values ############################
  # handle arguments r and breaks 

  rmaxdefault <- rmax.rule("K", win, lambda)        
  breaks <- handle.r.b.args(r, NULL, win, rmaxdefault=rmaxdefault)
  if(!(breaks$even))
    stop("r values must be evenly spaced")
  # extract r values
  r <- breaks$r
  rmax <- breaks$max
  # recommended range of r values for plotting
  alim <- c(0, min(rmax, rmaxdefault))

  ########## smoothing parameters for pcf ############################  
  # arguments for 'density'

  denargs <- resolve.defaults(list(kernel=kernel, bw=bw),
                              list(...),
                              list(n=length(r), from=0, to=rmax))
  
  #################################################
  
  # compute pairwise distances
  
  close <- closepairs(X, rmax+hmax)
  dIJ <- close$d
  I <- close$i
  J <- close$j
  XI <- ppp(close$xi, close$yi, window=win, check=FALSE)
  wIJ <- reciplambda[I] * reciplambda[J]

  # initialise fv object
  
  df <- data.frame(r=r, theo=rep.int(1,length(r)))
  out <- fv(df, "r",
            quote(g[inhom](r)), "theo", ,
            alim,
            c("r","{%s[%s]^{pois}}(r)"),
            c("distance argument r", "theoretical Poisson %s"),
            fname=c("g", "inhom"))

  ###### compute #######

  if(any(correction=="translate")) {
    # translation correction
    XJ <- ppp(close$xj, close$yj, window=win, check=FALSE)
    edgewt <- edge.Trans(XI, XJ, paired=TRUE)
    gT <- sewpcf(dIJ, edgewt * wIJ, denargs, areaW, divisor)$g
    if(renormalise) gT <- gT * renorm.factor
    out <- bind.fv(out,
                   data.frame(trans=gT),
                   "{hat(%s)[%s]^{Trans}}(r)",
                   "translation-corrected estimate of %s",
                   "trans")
  }
  if(any(correction=="isotropic")) {
    # Ripley isotropic correction
    edgewt <- edge.Ripley(XI, matrix(dIJ, ncol=1))
    gR <- sewpcf(dIJ, edgewt * wIJ, denargs, areaW, divisor)$g
    if(renormalise) gR <- gR * renorm.factor
    out <- bind.fv(out,
                   data.frame(iso=gR),
                   "{hat(%s)[%s]^{Ripley}}(r)",
                   "isotropic-corrected estimate of %s",
                   "iso")
  }
  
  # sanity check
  if(is.null(out)) {
    warning("Nothing computed - no edge corrections chosen")
    return(NULL)
  }
  
  # which corrections have been computed?
  nama2 <- names(out)
  corrxns <- rev(nama2[nama2 != "r"])

  # default is to display them all
  formula(out) <- deparse(as.formula(paste(
                       "cbind(",
                        paste(corrxns, collapse=","),
                        ") ~ r")))
  unitname(out) <- unitname(X)
  if(danger)
    attr(out, "dangerous") <- dangerous
  return(out)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pcfmulti.R"
#
#   pcfmulti.R
#
#   $Revision: 1.6 $   $Date: 2014/11/10 11:05:55 $
#
#   multitype pair correlation functions
#

pcfcross <- 
  function(X, i, j, ...,
         r=NULL, kernel="epanechnikov", bw=NULL, stoyan=0.15,
         correction = c("isotropic", "Ripley", "translate"),
         divisor=c("r","d"))
{
  verifyclass(X, "ppp")
  stopifnot(is.multitype(X))
  if(missing(correction))
    correction <- NULL
  divisor <- match.arg(divisor)
  ##
  marx <- marks(X)
  if(missing(i))
    i <- levels(marx)[1]
  if(missing(j))
    j <- levels(marx)[2]
  I <- (marx == i)
  J <- (marx == j)
  Iname <- paste("points with mark i =", i)
  Jname <- paste("points with mark j =", j)
  ##
  result <- pcfmulti(X, I, J, ...,
                     r=r, 
                     kernel=kernel, bw=bw, stoyan=stoyan,
                     correction=correction,
                     divisor=divisor,
                     Iname=Iname, Jname=Jname)
  ##
  iname <- make.parseable(paste(i))
  jname <- make.parseable(paste(j))
  result <-
    rebadge.fv(result,
               substitute(g[i,j](r),
                          list(i=iname,j=jname)),
               c("g", paste0("list", paren(paste(iname, jname, sep=",")))),
               new.yexp=substitute(g[list(i,j)](r),
                                   list(i=iname,j=jname)))
  return(result)
}

pcfdot <- 
function(X, i, ...,
         r=NULL, kernel="epanechnikov", bw=NULL, stoyan=0.15,
         correction = c("isotropic", "Ripley", "translate"),
         divisor=c("r", "d"))
{
  verifyclass(X, "ppp")
  stopifnot(is.multitype(X))
  if(missing(correction))
    correction <- NULL
  divisor <- match.arg(divisor)

  marx <- marks(X)
  if(missing(i))
    i <- levels(marx)[1]

  I <- (marx == i)
  J <- rep.int(TRUE, X$n)  # i.e. all points
  Iname <- paste("points with mark i =", i)
  Jname <- "points"
	
  result <- pcfmulti(X, I, J, ...,
                     r=r, kernel=kernel, bw=bw, stoyan=stoyan,
                     correction=correction,
                     divisor=divisor,
                     Iname=Iname, Jname=Jname)

  iname <- make.parseable(paste(i))
  result <-
    rebadge.fv(result,
               substitute(g[i ~ dot](r), list(i=iname)),
               c("g", paste0(iname, "~symbol(\"\\267\")")),
               new.yexp=substitute(g[i ~ symbol("\267")](r),
                 list(i=iname)))
  return(result)
}


pcfmulti <- function(X, I, J, ...,
                     r=NULL, 
                     kernel="epanechnikov", bw=NULL, stoyan=0.15,
                     correction=c("translate", "Ripley"),
                     divisor=c("r","d"),
                     Iname="points satisfying condition I",
                     Jname="points satisfying condition J")
{
  verifyclass(X, "ppp")
#  r.override <- !is.null(r)
  divisor <- match.arg(divisor)

  win <- X$window
  areaW <- area(win)
  npts <- npoints(X)
  
  correction.given <- !missing(correction) && !is.null(correction)
  if(is.null(correction))
    correction <- c("translate", "Ripley")
  correction <- pickoption("correction", correction,
                           c(isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             best="best"),
                           multi=TRUE)

  correction <- implemented.for.K(correction, win$type, correction.given)
  
  ## .......... indices I and J .............................
  
  I <- ppsubset(X, I)
  J <- ppsubset(X, J)
  if(is.null(I) || is.null(J))
    stop("I and J must be valid subset indices")

  nI <- sum(I)
  nJ <- sum(J)
  if(nI == 0) stop(paste("There are no", Iname))
  if(nJ == 0) stop(paste("There are no", Jname))

  XI <- X[I]
  XJ <- X[J]

#  lambdaI <- nI/areaW
  lambdaJ <- nJ/areaW
  nIJ <- sum(I & J)
  lambdaIJarea <- (nI * nJ - nIJ)/areaW
  
  ## ...........  kernel bandwidth and support .........................
  
  if(is.null(bw) && kernel=="epanechnikov") {
    # Stoyan & Stoyan 1995, eq (15.16), page 285
    h <- stoyan /sqrt(lambdaJ)
    hmax <- h
    # conversion to standard deviation
    bw <- h/sqrt(5)
  } else if(is.numeric(bw)) {
    # standard deviation of kernel specified
    # upper bound on half-width
    hmax <- 3 * bw
  } else {
    # data-dependent bandwidth selection: guess upper bound on half-width
    hmax <- 2 * stoyan /sqrt(lambdaJ)
  }


########## r values ############################
  # handle argument r 

  rmaxdefault <- rmax.rule("K", win, lambdaJ)
  breaks <- handle.r.b.args(r, NULL, win, rmaxdefault=rmaxdefault)
  if(!(breaks$even))
    stop("r values must be evenly spaced")
  # extract r values
  r <- breaks$r
  rmax <- breaks$max
  # recommended range of r values for plotting
  alim <- c(0, min(rmax, rmaxdefault))

  # initialise fv object
  
  df <- data.frame(r=r, theo=rep.int(1,length(r)))
  fname <- c("g", "list(I,J)")
  yexp <- quote(g[list(I,J)](r))
  out <- fv(df, "r",
            quote(g[I,J](r)), "theo", ,
            alim,
            c("r", makefvlabel(NULL, NULL, fname, "Pois")),
            c("distance argument r", "theoretical Poisson %s"),
            fname=fname,
            yexp=yexp)
  
  ########## smoothing parameters for pcf ############################  
  # arguments for 'density'

  denargs <- resolve.defaults(list(kernel=kernel, bw=bw),
                              list(...),
                              list(n=length(r), from=0, to=rmax))
  
  #################################################
  
  ## compute pairwise distances
  
  ## identify close pairs of points
  close <- crosspairs(XI, XJ, rmax+hmax)
  ## map (i,j) to original serial numbers in X
  orig <- seq_len(npts)
  imap <- orig[I]
  jmap <- orig[J]
  iX <- imap[close$i]
  jX <- jmap[close$j]
  ## eliminate any identical pairs
  if(nIJ > 0) {
    ok <- (iX != jX)
    if(!all(ok)) {
      close$i  <- close$i[ok]
      close$j  <- close$j[ok]
      close$xi <- close$xi[ok]
      close$yi <- close$yi[ok]
      close$xj <- close$xj[ok]
      close$yj <- close$yj[ok]
      close$dx <- close$dx[ok]
      close$dy <- close$dy[ok]
      close$d  <- close$d[ok]
    }
  }
  ## extract information for these pairs (relative to orderings of XI, XJ)
  dclose <- close$d
  icloseI  <- close$i
#  jcloseJ  <- close$j

  ###### compute #######

  if(any(correction=="translate")) {
    # translation correction
    edgewt <- edge.Trans(dx=close$dx, dy=close$dy, W=win, paired=TRUE)
    gT <- sewpcf(dclose, edgewt, denargs, lambdaIJarea, divisor)$g
    out <- bind.fv(out,
                   data.frame(trans=gT),
                   makefvlabel(NULL, "hat", fname, "Trans"),
                   "translation-corrected estimate of %s",
                   "trans")
  }
  if(any(correction=="isotropic")) {
    # Ripley isotropic correction
    edgewt <- edge.Ripley(XI[icloseI], matrix(dclose, ncol=1))
    gR <- sewpcf(dclose, edgewt, denargs, lambdaIJarea, divisor)$g
    out <- bind.fv(out,
                   data.frame(iso=gR),
                   makefvlabel(NULL, "hat", fname, "Ripley"),
                   "isotropic-corrected estimate of %s",
                   "iso")
  }
  
  ## sanity check
  if(is.null(out)) {
    warning("Nothing computed - no edge corrections chosen")
    return(NULL)
  }
  
  # which corrections have been computed?
  nama2 <- names(out)
  corrxns <- rev(nama2[nama2 != "r"])

  # default is to display them all
  formula(out) <- deparse(as.formula(paste(
                       "cbind(",
                        paste(corrxns, collapse=","),
                        ") ~ r")))
  unitname(out) <- unitname(X)
  return(out)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pcfmulti.inhom.R"
#
#   pcfmulti.inhom.R
#
#   $Revision: 1.13 $   $Date: 2014/10/24 00:22:30 $
#
#   inhomogeneous multitype pair correlation functions
#
#

pcfcross.inhom <- 
  function(X, i, j, lambdaI=NULL, lambdaJ=NULL, ...,
         r=NULL, breaks=NULL,
         kernel="epanechnikov", bw=NULL, stoyan=0.15,
         correction = c("isotropic", "Ripley", "translate"),
         sigma=NULL, varcov=NULL)
{
  verifyclass(X, "ppp")
  stopifnot(is.multitype(X))
  if(missing(correction))
    correction <- NULL
  marx <- marks(X)
  if(missing(i))
    i <- levels(marx)[1]
  if(missing(j))
    j <- levels(marx)[2]
  I <- (marx == i)
  J <- (marx == j)
  Iname <- paste("points with mark i =", i)
  Jname <- paste("points with mark j =", j)
  g <- pcfmulti.inhom(X, I, J, lambdaI, lambdaJ, ...,
                      r=r,breaks=breaks,
                      kernel=kernel, bw=bw, stoyan=stoyan,
                      correction=correction,
                      sigma=sigma, varcov=varcov,
                      Iname=Iname, Jname=Jname)
  iname <- make.parseable(paste(i))
  jname <- make.parseable(paste(j))
  result <-
    rebadge.fv(g,
               substitute(g[inhom,i,j](r),
                          list(i=iname,j=jname)),
               c("g", paste0("list", paren(paste("inhom", i, j, sep=",")))),
               new.yexp=substitute(g[list(inhom,i,j)](r),
                                   list(i=iname,j=jname)))
  attr(result, "dangerous") <- attr(g, "dangerous")
  return(result)
}

pcfdot.inhom <- 
function(X, i, lambdaI=NULL, lambdadot=NULL, ...,
         r=NULL, breaks=NULL,
         kernel="epanechnikov", bw=NULL, stoyan=0.15,
         correction = c("isotropic", "Ripley", "translate"),
         sigma=NULL, varcov=NULL)
{
  verifyclass(X, "ppp")
  stopifnot(is.multitype(X))
  if(missing(correction))
    correction <- NULL

  marx <- marks(X)
  if(missing(i))
    i <- levels(marx)[1]

  I <- (marx == i)
  J <- rep.int(TRUE, X$n)  # i.e. all points
  Iname <- paste("points with mark i =", i)
  Jname <- paste("points")
	
  g <- pcfmulti.inhom(X, I, J, lambdaI, lambdadot, ...,
                      r=r,breaks=breaks,
                      kernel=kernel, bw=bw, stoyan=stoyan,
                      correction=correction,
                      sigma=sigma, varcov=varcov,
                      Iname=Iname, Jname=Jname)
  iname <- make.parseable(paste(i))
  result <-
    rebadge.fv(g,
               substitute(g[inhom, i ~ dot](r), list(i=iname)),
               c("g", paste0("list(inhom,", iname, "~symbol(\"\\267\"))")),
               new.yexp=substitute(g[list(inhom, i ~ symbol("\267"))](r),
                 list(i=iname)))
  if(!is.null(dang <- attr(g, "dangerous"))) {
    dang[dang == "lambdaJ"] <- "lambdadot"
    dang[dang == "lambdaIJ"] <- "lambdaIdot"
    attr(result, "dangerous") <- dang
  }
  return(result)
}


pcfmulti.inhom <- function(X, I, J, lambdaI=NULL, lambdaJ=NULL, ...,
                           r=NULL, breaks=NULL, 
                           kernel="epanechnikov", bw=NULL, stoyan=0.15,
                           correction=c("translate", "Ripley"),
                           sigma=NULL, varcov=NULL,
                           Iname="points satisfying condition I",
                           Jname="points satisfying condition J")
{
  verifyclass(X, "ppp")
#  r.override <- !is.null(r)

  win <- X$window
  areaW <- area(win)
  npts <- npoints(X)
  
  correction.given <- !missing(correction) && !is.null(correction)
  if(is.null(correction))
    correction <- c("translate", "Ripley")
  correction <- pickoption("correction", correction,
                           c(isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             best="best"),
                           multi=TRUE)

  correction <- implemented.for.K(correction, win$type, correction.given)
  
  # bandwidth  
  if(is.null(bw) && kernel=="epanechnikov") {
    # Stoyan & Stoyan 1995, eq (15.16), page 285
    h <- stoyan /sqrt(npts/areaW)
    hmax <- h
    # conversion to standard deviation
    bw <- h/sqrt(5)
  } else if(is.numeric(bw)) {
    # standard deviation of kernel specified
    # upper bound on half-width
    hmax <- 3 * bw
  } else {
    # data-dependent bandwidth selection: guess upper bound on half-width
    hmax <- 2 * stoyan /sqrt(npts/areaW)
  }

  ##########  indices I and J  ########################
  
  if(!is.logical(I) || !is.logical(J))
    stop("I and J must be logical vectors")
  if(length(I) != npts || length(J) != npts)
    stop(paste("The length of I and J must equal",
               "the number of points in the pattern"))
	
  nI <- sum(I)
  nJ <- sum(J)
  if(nI == 0) stop(paste("There are no", Iname))
  if(nJ == 0) stop(paste("There are no", Jname))

  XI <- X[I]
  XJ <- X[J]
  
  ########## intensity values #########################

  dangerous <- c("lambdaI", "lambdaJ")
  dangerI <- dangerJ <- TRUE
  
  if(is.null(lambdaI)) {
      # Estimate density by leave-one-out kernel smoothing
    dangerI <- FALSE
    lambdaI <- density(XI, ..., sigma=sigma, varcov=varcov,
                      at="points", leaveoneout=TRUE)
  } else {
    # lambda values provided
    if(is.vector(lambdaI)) 
      check.nvector(lambdaI, nI)
    else if(is.im(lambdaI)) 
      lambdaI <- safelookup(lambdaI, XI)
    else if(is.function(lambdaI)) 
      lambdaI <- lambdaI(XI$x, XI$y)
    else stop(paste(sQuote("lambdaI"),
                    "should be a vector, a pixel image, or a function"))
  }

  if(is.null(lambdaJ)) {
      # Estimate density by leave-one-out kernel smoothing
    dangerJ <- FALSE
    lambdaJ <- density(XJ, ..., sigma=sigma, varcov=varcov,
                      at="points", leaveoneout=TRUE)
  } else {
    # lambda values provided
    if(is.vector(lambdaJ)) 
      check.nvector(lambdaJ, nJ)
    else if(is.im(lambdaJ)) 
      lambdaJ <- safelookup(lambdaJ, XJ)
    else if(is.function(lambdaJ)) 
      lambdaJ <- lambdaJ(XJ$x, XJ$y)
    else stop(paste(sQuote("lambdaJ"),
                    "should be a vector, a pixel image, or a function"))
  }

  danger <- dangerI || dangerJ
  
  ########## r values ############################
  # handle arguments r and breaks 

  rmaxdefault <- rmax.rule("K", win, npts/areaW)        
  breaks <- handle.r.b.args(r, breaks, win, rmaxdefault=rmaxdefault)
  if(!(breaks$even))
    stop("r values must be evenly spaced")
  # extract r values
  r <- breaks$r
  rmax <- breaks$max
  # recommended range of r values for plotting
  alim <- c(0, min(rmax, rmaxdefault))

  # initialise fv object
  
  df <- data.frame(r=r, theo=rep.int(1,length(r)))
  fname <- c("g", "list(inhom,I,J)")
  out <- fv(df, "r",
            quote(g[inhom,I,J](r)), "theo", ,
            alim,
            c("r", makefvlabel(NULL, NULL, fname, "pois")),            
            c("distance argument r", "theoretical Poisson %s"),
            fname=fname,
            yexp=quote(g[list(inhom,I,J)](r)))
  
  ########## smoothing parameters for pcf ############################  
  # arguments for 'density'

  denargs <- resolve.defaults(list(kernel=kernel, bw=bw),
                              list(...),
                              list(n=length(r), from=0, to=rmax))
  
  #################################################
  
  # compute pairwise distances
  
# identify close pairs of points
  close <- crosspairs(XI, XJ, rmax+hmax)
# map (i,j) to original serial numbers in X
  orig <- seq_len(npts)
  imap <- orig[I]
  jmap <- orig[J]
  iX <- imap[close$i]
  jX <- jmap[close$j]
# eliminate any identical pairs
  if(any(I & J)) {
    ok <- (iX != jX)
    if(!all(ok)) {
      close$i  <- close$i[ok]
      close$j  <- close$j[ok]
      close$xi <- close$xi[ok]
      close$yi <- close$yi[ok]
      close$xj <- close$xj[ok]
      close$yj <- close$yj[ok]
      close$dx <- close$dx[ok]
      close$dy <- close$dy[ok]
      close$d  <- close$d[ok]
    }
  }
# extract information for these pairs (relative to orderings of XI, XJ)
  dclose <- close$d
  icloseI  <- close$i
  jcloseJ  <- close$j

# Form weight for each pair
  weight <- 1/(lambdaI[icloseI] * lambdaJ[jcloseJ])

  ###### compute #######

  if(any(correction=="translate")) {
    # translation correction
    edgewt <- edge.Trans(XI[icloseI], XJ[jcloseJ], paired=TRUE)
    gT <- sewpcf(dclose, edgewt * weight, denargs, areaW)$g
    out <- bind.fv(out,
                   data.frame(trans=gT),
                   makefvlabel(NULL, "hat", fname, "Trans"),
                   "translation-corrected estimate of %s",
                   "trans")
  }
  if(any(correction=="isotropic")) {
    # Ripley isotropic correction
    edgewt <- edge.Ripley(XI[icloseI], matrix(dclose, ncol=1))
    gR <- sewpcf(dclose, edgewt * weight, denargs, areaW)$g
    out <- bind.fv(out,
                   data.frame(iso=gR),
                   makefvlabel(NULL, "hat", fname, "Ripley"),
                   "isotropic-corrected estimate of %s",
                   "iso")
  }
  
  # sanity check
  if(is.null(out)) {
    warning("Nothing computed - no edge corrections chosen")
    return(NULL)
  }
  
  # which corrections have been computed?
  nama2 <- names(out)
  corrxns <- rev(nama2[nama2 != "r"])

  # default is to display them all
  formula(out) <- deparse(as.formula(paste(
                       "cbind(",
                        paste(corrxns, collapse=","),
                        ") ~ r")))
  unitname(out) <- unitname(X)

  if(danger)
    attr(out, "dangerous") <- dangerous
  return(out)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/percy.R"
## percus.R
##
## Percus-Yevick style approximations to pcf and K
##
##  $Revision: 1.4 $ $Date: 2014/01/31 10:10:19 $

pcfmodel.ppm <- local({

  pcfmodel.ppm <- function(model, ...) {
    if(is.multitype(model))
      stop("Not yet implemented for multitype models")
    if(!is.stationary(model))
      stop("Model must be stationary")
    if(is.poisson(model)) return(function(r) rep(1, length(r)))
    inte <- as.interact(model)
    if(inte$family$name != "pairwise")
      stop("Only implemented for pairwise-interaction models")
    lambda <- intensity(model)
    beta <- exp(coef(model)[1])
    par <- inte$par
    pot <- inte$pot
    f <- fitin(model)
    Vcoefs <- f$coefs[f$Vnames]
    Mayer <- inte$Mayer
    G <- Mayer(Vcoefs, inte)
    irange <- reach(inte, epsilon=1e-6)
    G2fun <- inte$Percy
    testit <- resolve.1.default(list(testit=FALSE), list(...))
    if(testit || is.null(G2fun))
      G2fun <- pairwisePercy
    fun <- function(r) {
      pcfapprox(r, beta, lambda, pot, par, Vcoefs, G, G2fun, irange)
    }
    return(fun)
  }

  pcfapprox <- function(r, beta, lambda, pot, par, Vcoefs, G, G2fun, irange) {
    as.numeric((beta/lambda)^2 *
               exp(logpairpot(r, pot, par, Vcoefs)
                   - lambda * G2fun(r, Vcoefs, par, pot=pot,
                                    irange=irange, G=G)))
  }

  logpairpot <- function(r, pot, par, Vcoefs) {
    as.numeric(pot(matrix(r, ncol=1), par) %*% Vcoefs)
  }
  
  negpair <- function(x,y, pot, par, Vcoefs) {
    ## evaluate 1 - g(x,y)
    ## where g(x,y) is pair interaction between (0,0) and (x,y)
    1 - exp(logpairpot(sqrt(x^2+y^2), pot, par, Vcoefs))
  }
  
  pairwisePercy <- function(r, Vcoefs, par, ..., G, pot, irange, dimyx=256) {
    S <- max(max(r), irange)
    ng <- as.im(negpair, square(c(-S,S)),
                  pot=pot, par=par, Vcoefs=Vcoefs,
                  dimyx=dimyx)
    ng2 <- convolve.im(ng)
    rr <- seq(min(r), max(r), length=dimyx[1])
    yy <- ng2[list(x=rr, y=rep.int(0, dimyx[1]))]
    zz <- 2 * G - yy
    z <- approx(rr, zz, r)$y
    return(z)
  }

  pcfmodel.ppm
})

    

Kmodel.ppm <- local({
  
  Kmodel.ppm <- function(model, ...) {
    if(is.poisson(model)) return(function(r) { pi * r^2 })
    pc <- pcfmodel(model, ...)
    K <- function(r) pcf2K(r, pc)
    return(K)
  }

  pcf2K <- function(r, pc) {
    ## integrate the pair correlation function to obtain the K-function
    if(length(r) == 1) {
      ## definite integral
      spcfs <- function(s) { s * pc(s) }
      y <- 2 * pi * integrate(spcfs, lower=0, upper=r)$value
    } else {
      ## indefinite integral
      rr <- seq(0, max(r), length=1025)
      dr <- max(r)/(length(rr) - 1)
      ff <- 2 * pi * rr * pc(rr)
      yy <- dr * cumsum(ff)
      y <- approx(rr, yy, r)$y
    }
    return(y)
  }

  Kmodel.ppm
})
                    
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/periodify.R"
#
# periodify.R
#
# replicate a pattern periodically
#
#  $Revision: 1.3 $  $Date: 2011/04/17 05:52:50 $
#

periodify <- function(X, ...) {
  UseMethod("periodify")
}

periodify.ppp <- function(X, nx=1, ny=1, ...,
                          combine=TRUE, warn=TRUE, check=TRUE, 
                          ix=(-nx):nx, iy=(-ny):ny,
                          ixy=expand.grid(ix=ix,iy=iy)) {
  # sanity checks
  if(!missing(nx) || !missing(ny)) {
    if(is.null(nx)) nx <- 1
    if(is.null(ny)) ny <- 1
    if(length(nx) != 1 || length(ny) != 1)
      stop("nx and ny should be single integers")
    if(nx != round(nx) || ny != round(ny))
      stop("nx and ny should be integers")
  }
  force(ixy)
  W <- X$window
  isrect <- (W$type == "rectangle")
  if(warn && combine && !isrect)
    warning("X has a non-rectangular window")
  else 
   isrect <- isrect && all(diff(nx) == 1) && all(diff(ny) == 1)
  width <- diff(W$xrange)
  height <- diff(W$yrange)
  shifts <- cbind(ixy[,1] * width, ixy[,2] * height)
  Xshift <- list()
  for(i in 1:nrow(shifts))
    Xshift[[i]] <- shift(X, vec=as.numeric(shifts[i, ]))
  if(!combine)
    return(Xshift)
  Wnew <- if(isrect) {
    owin(range(range(W$xrange) + range(shifts[,1])),
         range(range(W$yrange) + range(shifts[,2])))
  } else NULL
  Z <- do.call(superimpose, append(Xshift, list(W=Wnew, check=check)))
  return(Z)
}

periodify.psp <- function(X, nx=1, ny=1, ...,
                          combine=TRUE, warn=TRUE, check=TRUE,
                          ix=(-nx):nx, iy=(-ny):ny,
                          ixy=expand.grid(ix=ix,iy=iy)) {
  # sanity checks
  if(!missing(nx) || !missing(ny)) {
    if(is.null(nx)) nx <- 1
    if(is.null(ny)) ny <- 1
    if(length(nx) != 1 || length(ny) != 1)
      stop("nx and ny should be single integers")
    if(nx != round(nx) || ny != round(ny))
      stop("nx and ny should be integers")
  }
  force(ixy)
  W <- X$window
  isrect <- (W$type == "rectangle")
  if(warn && combine && !isrect)
    warning("X has a non-rectangular window")
  else 
   isrect <- isrect && all(diff(nx) == 1) && all(diff(ny) == 1)
  width <- diff(W$xrange)
  height <- diff(W$yrange)
  shifts <- cbind(ixy[,1] * width, ixy[,2] * height)
  Xshift <- list()
  for(i in 1:nrow(shifts))
    Xshift[[i]] <- shift(X, vec=as.numeric(shifts[i, ]))
  if(!combine)
    return(Xshift)
  Wnew <- if(isrect) {
    owin(range(range(W$xrange) + range(shifts[,1])),
         range(range(W$yrange) + range(shifts[,2])))
  } else NULL
  Z <- do.call(superimpose, append(Xshift, list(W=Wnew, check=check)))
  return(Z)
}

periodify.owin <- function(X, nx=1, ny=1, ...,
                          combine=TRUE, warn=TRUE,
                          ix=(-nx):nx, iy=(-ny):ny,
                          ixy=expand.grid(ix=ix,iy=iy)) {
  # sanity checks
  if(!missing(nx) || !missing(ny)) {
    if(is.null(nx)) nx <- 1
    if(is.null(ny)) ny <- 1
    if(length(nx) != 1 || length(ny) != 1)
      stop("nx and ny should be single integers")
    if(nx != round(nx) || ny != round(ny))
      stop("nx and ny should be integers")
  }
  force(ixy)
  isrect <- (X$type == "rectangle")
  if(warn && combine && !isrect)
    warning("X is not rectangular")
  else 
    isrect <- isrect && all(diff(nx) == 1) && all(diff(ny) == 1)
  width <- diff(X$xrange)
  height <- diff(X$yrange)
  shifts <- cbind(ixy[,1] * width, ixy[,2] * height)
  if(combine) {
    if(isrect) {
      # result is a rectangle
      Y <-  owin(range(range(X$xrange) + range(shifts[,1])),
                    range(range(X$yrange) + range(shifts[,2])))
    } else {
      # result is another type of window
      for(i in 1:nrow(shifts)) {
        Xi <- shift(X, vec=as.numeric(shifts[i, ]))
        Y <- if(i == 1) Xi else union.owin(Y, Xi)
      }
    }
  } else {
    # result is a list
    Y <- list()
    for(i in 1:nrow(shifts))
      Y[[i]] <- shift(X, vec=as.numeric(shifts[i, ]))
  }
  return(Y)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/persp.im.R"
##
## persp.im.R
##
##  'persp' method for image objects
##      plus annotation
##  
##  $Revision: 1.6 $ $Date: 2014/11/10 11:08:30 $
##

persp.im <- local({

  persp.im <- function(x, ...,
                       colmap=NULL, colin=x, apron=FALSE, visible=FALSE) {
    xname <- deparse(substitute(x))
    xinfo <- summary(x)
    if(xinfo$type == "factor")
      stop("Perspective plot is inappropriate for factor-valued image")
    ## check whether 'col' was specified when 'colmap' was intended
    Col <- list(...)$col
    if(is.null(colmap) && !is.null(Col) && !is.matrix(Col) && length(Col) != 1)
      warning("Argument col is not a matrix. Did you mean colmap?")
    if(!missing(colin)) {
      ## separate image to determine colours
      verifyclass(colin, "im")
      if(!compatible(colin, x)) {
        ## resample 'colin' onto grid of 'x'
        colin <- as.im(colin, W=x)
      }
      if(is.null(colmap))
        colmap <- spatstat.options("image.colfun")(128)
    }
    pop <- spatstat.options("par.persp")
    ##
    if(is.function(colmap) && !inherits(colmap, "colourmap")) {
      ## coerce to a 'colourmap' if possible
      zlim <- resolve.1.default(list(zlim=range(colin, finite=TRUE)), list(...))
      if(names(formals(colmap))[1] == "n") {
        colval <- colmap(128)
        colmap <- colourmap(colval, range=zlim)
      } else {
        ## colour map determined by a rule (e.g. 'beachcolours')
        colmap <- invokeColourmapRule(colmap, colin,
                                      zlim=zlim, colargs=list(...))
        if(is.null(colmap))
          stop("Unrecognised syntax for colour function")
      }
    }
    ## colour map?
    if(is.null(colmap)) {
      colinfo <- list(col=NULL)
    } else if(inherits(colmap, "colourmap")) {
      ## colour map object
      ## apply colour function to image data
      colval <- eval.im(colmap(colin))
      colval <- t(as.matrix(colval))
      ## strip one row and column for input to persp.default
      colval <- colval[-1, -1]
      ## replace NA by arbitrary value
      isna <- is.na(colval)
      if(any(isna)) {
        stuff <- attr(colmap, "stuff")
        colvalues <- stuff$outputs
        colval[isna] <- colvalues[1]
      }
      ## pass colour matrix (and suppress lines)
      colinfo <- list(col=colval, border=NA)
    } else {
      ## interpret 'colmap' as colour map
      if(is.list(colmap) && all(c("breaks", "col") %in% names(colmap))) {
        breaks <- colmap$breaks
        colvalues <- colmap$col
      } else if(is.vector(colmap)) {
        colvalues <- colmap
        breaks <- quantile(colin,
                           seq(from=0,to=1,length.out=length(colvalues)+1))
        if(!all(ok <- !duplicated(breaks))) {
          breaks <- breaks[ok]
          colvalues <- colvalues[ok[-1]]
        }
      } else warning("Unrecognised format for colour map")
      ## apply colour map to image values
      colid <- cut.im(colin, breaks=breaks, include.lowest=TRUE)
      colval <- eval.im(colvalues[unclass(colid)])
      colval <- t(as.matrix(colval))
#      nr <- nrow(colval)
#      nc <- ncol(colval)
      ## strip one row and column for input to persp.default
      colval <- colval[-1, -1]
      colval[is.na(colval)] <- colvalues[1]
      ## pass colour matrix (and suppress lines)
      colinfo <- list(col=colval, border=NA)
    }

    if(apron) {
      ## add an 'apron'
      minx <- min(x)
      x <- na.handle.im(x, na.replace=minx)
      x <- padimage(x, minx)
      xinfo <- summary(x)
      if(is.matrix(colval <- colinfo$col)) {
        colval <- matrix(col2hex(colval), nrow(colval), ncol(colval))
        grijs <- col2hex("lightgrey")
        colval <- cbind(grijs, rbind(grijs, colval, grijs), grijs)
        colinfo$col <- colval
      }
    }

    if(spatstat.options("monochrome"))
      colinfo$col <- to.grey(colinfo$col)
  
    ## get reasonable z scale while fixing x:y aspect ratio
    if(xinfo$type %in% c("integer", "real")) {
      zrange <- xinfo$range
      if(diff(zrange) > 0) {
        xbox <- as.rectangle(x)
        zscale <- 0.5 * mean(diff(xbox$xrange), diff(xbox$yrange))/diff(zrange)
        zlim <- zrange
      } else {
        zscale <- NULL
        zlim <- c(0,2) * xinfo$mean
      }
    } else 
      zscale <- zlim <- NULL

    yargh <- resolve.defaults(list(x=x$xcol, y=x$yrow, z=t(x$v)),
                              list(...),
                              pop,
                              colinfo,
                              list(xlab="x", ylab="y", zlab=xname),
                              list(scale=FALSE, expand=zscale,
                                   zlim=zlim),
                              list(main=xname),
                              .StripNull=TRUE)

    jawab <- do.call.matched("persp", yargh, 
                             funargs=.Spatstat.persp.args)

    attr(jawab, "expand") <- yargh$expand
    
    if(visible)
      attr(jawab, "visible") <- perspvis(x, M=jawab)
    
    return(invisible(jawab))
  }

  diffit <- function(x) {
    y <- diff(x)
    return(c(y[1], y))
  }
  
  perspvis <- function(X, ..., M=NULL) {
    stopifnot(is.im(X))
    ## determine perspective matrix
    if(is.null(M))
      M <- persp(X, ...)
    ## project the coordinates
    ## onto (x,y) plane of plot and z axis pointing out of it
    xy <- rasterxy.im(X, drop=TRUE)
    z <- X[drop=TRUE]
    xyz <- cbind(xy, z)
    v <- cbind(xyz, 1) %*% M
    pxyz <- v[,1:3]/v[,4]
    px <- pxyz[,1]
    py <- pxyz[,2]
    pz <- pxyz[,3]
    ## determine greatest possible difference in 'depth' in one pixel step
    PZ <- as.matrix(X)
    ok <- !is.na(PZ)
    PZ[ok] <- pz
    maxslip <- max(abs(apply(PZ, 1, diff)), abs(apply(PZ, 2, diff)))
    ## determine which pixels are in front
    d <- ceiling(dim(X)/2)
    jx <- cut(px, breaks=d[2])
    iy <- cut(py, breaks=d[1])
    zmax <- tapply(pz, list(iy,jx), max)
    isvis <- infront <- (pz > zmax[cbind(iy,jx)] - 2 * maxslip)
    ##
    if(TRUE) {
      ## Additionally check whether unit normal to surface is pointing to viewer
      Xmat <- as.matrix(X)
      dzdx <- cbind(0, t(apply(Xmat, 1, diff)))/X$xstep
      dzdy <- rbind(0, apply(Xmat, 2, diff))/X$ystep
      dzdx <- as.vector(dzdx[ok])
      dzdy <- as.vector(dzdy[ok])
      ## unscaled normal is (-dzdx, -dzdy, 1)
      if(FALSE) {
        ## THIS DOESN'T WORK - not sure why.
        ## rescale so that length is half diameter of pixel
        fac <- sqrt(X$xstep^2 + X$ystep^2)/(2 * sqrt(dzdx^2+dzdy^2+1))
        ## add to spatial coordinates
        xyzplus <- xyz + fac * cbind(-dzdx, -dzdy, 1)
        ## transform
        vplus <- cbind(xyzplus, 1) %*% M
        pplus <- vplus[,1:3]/vplus[,4]
        ## determine whether normal is pointing toward viewer
        deltaz <- pplus[,3] - pz
        isvis <- infront & (deltaz > 0)
      } else {
        theta <- atan2(M[2,1],M[1,1]) + pi/2
        phi <-  - atan2(M[3,3], M[3,2])
        ## check agreement
        ## cat(paste("Guess: theta=", theta * 180/pi, "\n"))
        ## cat(paste("Guess: phi=", phi * 180/pi, "\n"))
        ## view vector
        viewer <- cos(phi) * c(cos(theta), sin(theta), 0)
                       + c(0, 0, sin(phi))
        ## inner product
        dotprod <- -dzdx * viewer[1] - dzdy * viewer[2] + viewer[3]
        isvis <- infront & (dotprod < 0)
      }
    }
    ## put into image
    Y <- eval.im(X > 0)
    Y[] <- isvis
    return(Y)
  }

  persp.im
})


.Spatstat.persp.args <- list("x", "y", "z",
                             "xlim", "ylim", "zlim",
                             "xlab", "ylab", "zlab",
                             "main", "sub",
                             "theta", "phi", "r", "d", "scale",
                             "expand", "col", "border",
                             "ltheta", "lphi", "shade", "box",
                             "axes", "nticks", "ticktype")

perspPoints <- function(x, y=NULL, ..., Z, M) {
  xy <- xy.coords(x, y)
  stopifnot(is.im(Z))
  X <- as.ppp(xy, W=Frame(Z))
  if(!is.matrix(M) && all(dim(M) == 4))
    stop("M should be a 4 x 4 matrix, returned from persp()")
  V <- attr(M, "visible")
  if(is.null(V)) {
    warning(paste("M does not contain visibility information;",
               "it should be recomputed by persp() with visible=TRUE"))
  } else {
    ## restrict to visible points
    X <- X[V[X]]
  }
  points(trans3d(X$x, X$y, Z[X], M), ...)
}

perspSegments <- local({
  perspSegments <- function(x0, y0=NULL, x1=NULL, y1=NULL, ..., Z, M) {
    stopifnot(is.im(Z))
    if(!is.matrix(M) && all(dim(M) == 4))
      stop("M should be a 4 x 4 matrix, returned from persp()")
    V <- attr(M, "visible")
    if(is.null(V))
      warning(paste("M does not contain visibility information;",
                 "it should be recomputed by persp() with visible=TRUE"))
    
    if(is.psp(X <- x0) && is.null(y0) && is.null(x1) && is.null(y1)) {
      eX <- X$ends
#      nX <- nrow(eX)
    } else {
#      nX <- length(x0)
      check.nvector(x0, naok=TRUE)
      check.nvector(y0, naok=TRUE)
      check.nvector(x1, naok=TRUE)
      check.nvector(y1, naok=TRUE)
      eX <- cbind(x0, y0, x1, y1)
    }
    if(is.null(V)) {
      Y <- eX
    } else {
      ## chop segments to length of single pixel
      eps <- with(Z, min(xstep,ystep))
      Y <- do.call(rbind, lapply(as.data.frame(t(eX)), chopsegment, eps=eps))
      ## determine which segments are visible
      ok <- V[list(x=Y[,1], y=Y[,2])] & V[list(x=Y[,3], y=Y[,4])]
      Y <- Y[ok, ,drop=FALSE]
    }
    if(nrow(Y) == 0) return(invisible(NULL))
    ## map to projected plane
    x0y0 <- trans3d(Y[,1], Y[,2], Z[list(x=Y[,1],y=Y[,2])], M)
    x1y1 <- trans3d(Y[,3], Y[,4], Z[list(x=Y[,3],y=Y[,4])], M)
    segments(x0y0$x, x0y0$y, x1y1$x, x1y1$y, ...)
  }

  chopsegment <- function(x, eps) {
    len2 <- (x[3] - x[1])^2 + (x[4] - x[2])^2
    if(len2 <= eps^2) return(x)
    n <- ceiling(sqrt(len2)/eps)
    b <- (1:n)/n
    a <- (0:(n-1))/n
    return(cbind(x[1] + a * (x[3]-x[1]),
                 x[2] + a * (x[4]-x[2]),
                 x[1] + b * (x[3]-x[1]),
                 x[2] + b * (x[4]-x[2])))
  }
      
  perspSegments
})

perspLines <- function(x, y=NULL, ..., Z, M) {
  xy <- xy.coords(x, y)
  n <- length(xy$x)
  perspSegments(x[-n], y[-n], x[-1], y[-1], Z=Z, M=M, ...)
}

perspContour <- function(Z, M, ...,
                         nlevels=10, levels=pretty(range(Z), nlevels)) {
  cl <- contourLines(x=Z$xcol,
                     y=Z$yrow,
                     z=t(Z$v),
                     nlevels=nlevels, levels=levels)
  for(i in seq_along(cl)) {
    cli <- cl[[i]]
    perspLines(cli$x, cli$y, ..., Z=Z, M=M)
  }
  invisible(NULL)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pickoption.R"
#
#  pickoption.R
#
#  $Revision: 1.5 $  $Date: 2013/04/25 06:37:43 $
#

pickoption <- function(what="option", key, keymap, ...,
                       exact=FALSE, list.on.err=TRUE, die=TRUE, multi=FALSE)
{
  keyname <- short.deparse(substitute(key))

  if(!is.character(key))
    stop(paste(keyname, "must be a character string",
               if(multi) "or strings" else NULL))
  if(length(key) == 0)
    stop(paste("Argument", sQuote(keyname), "has length zero"))
  key <- unique(key)
  if(!multi && length(key) > 1)
    stop(paste("Must specify only one", what, sQuote(keyname)))

  id <-
    if(exact)
      match(key, names(keymap), nomatch=NA)
    else
      pmatch(key, names(keymap), nomatch=NA)
  
  if(any(nbg <- is.na(id))) {
    # no match
    whinge <- paste("unrecognised", what,
                    paste(dQuote(key[nbg]), collapse=", "),
                    "in argument", sQuote(keyname))
    if(list.on.err) {
      cat(paste(whinge, "\n", "Options are:"),
          paste(dQuote(names(keymap)), collapse=","), "\n")
    }
    if(die) 
      stop(whinge, call.=FALSE)
    else
      return(NULL)
  }

  key <- keymap[id]
  names(key) <- NULL
  return(key)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pixellate.R"
#
#           pixellate.R
#
#           $Revision: 1.13 $    $Date: 2014/10/24 00:22:30 $
#
#     pixellate            convert an object to a pixel image
#
#     pixellate.ppp        convert a point pattern to a pixel image
#                          (pixel value = number of points in pixel)
#
#     pixellate.owin       convert a window to a pixel image
#                          (pixel value = area of intersection with pixel)
#

pixellate <- function(x, ...) {
  UseMethod("pixellate")
}

pixellate.ppp <- function(x, W=NULL, ..., weights=NULL, padzero=FALSE) {
  verifyclass(x, "ppp")

  if(!is.null(W))
    W <- as.mask(W)
  else {
    # determine W using as.mask
    W <- do.call.matched("as.mask",
                         resolve.defaults(list(...),
                                          list(w=x$window)))
  }
  insideW <- W$m
  dimW   <- W$dim
  xcolW <- W$xcol
  yrowW <- W$yrow
  xrangeW <- W$xrange
  yrangeW <- W$yrange
  unitsW <- unitname(W)
    
  # multiple columns of weights?
  if(is.data.frame(weights) || is.matrix(weights)) {
    k <- ncol(weights)
    stopifnot(nrow(weights) == npoints(x))
    weights <- if(k == 1) as.vector(weights) else as.data.frame(weights)
  } else {
    k <- 1
    if(length(weights) == 0) weights <- NULL else 
      stopifnot(length(weights) == npoints(x) || length(weights) == 1)
    if(length(weights) == 1)
      weights <- rep(weights, npoints(x))
  }

  # handle empty point pattern
  if(x$n == 0) {
    zeroimage <- as.im(as.double(0), W)
    if(padzero) # map NA to 0
      zeroimage <- na.handle.im(zeroimage, 0)
    result <- zeroimage
    if(k > 1) {
      result <- as.listof(rep(list(zeroimage), k))
      names(result) <- colnames(weights)
    }
    return(result)
  }

  # perform calculation
  pixels <- nearest.raster.point(x$x, x$y, W)
  nr <- dimW[1]
  nc <- dimW[2]
  rowfac <- factor(pixels$row, levels=1:nr)
  colfac <- factor(pixels$col, levels=1:nc)
  if(is.null(weights)) {
    ta <- table(row = rowfac, col = colfac)
  } else if(k == 1) {
    ta <- tapply(weights, list(row = rowfac, col=colfac), sum)
    ta[is.na(ta)] <- 0
  } else {
    ta <- list()
    for(j in 1:k) {
      taj <- tapply(weights[,j], list(row = rowfac, col=colfac), sum)
      taj[is.na(taj)] <- 0
      ta[[j]] <- taj
    }
  }

  # pack up as image(s)
  if(k == 1) {
    # single image
    # clip to window of data
    if(!padzero)
      ta[!insideW] <- NA
    out <- im(ta,
              xcol = xcolW, yrow = yrowW,
              xrange = xrangeW, yrange = yrangeW,
              unitname=unitsW)
  } else {
    # case k > 1
    # create template image to reduce overhead
    template <- im(ta[[1]],
                   xcol = xcolW, yrow = yrowW,
                   xrange = xrangeW, yrange = yrangeW,
                   unitname=unitsW)
    out <- list()
    for(j in 1:k) {
      taj <- ta[[j]]
      # clip to window of data
      if(!padzero) 
        taj[!insideW] <- NA
      # copy template and reassign pixel values
      outj <- template
      outj$v <- taj
      # store
      out[[j]] <- outj
    }
    out <- as.listof(out)
    names(out) <- names(weights)
  }
  return(out)
}

pixellate.owin <- function(x, W=NULL, ...) {
  stopifnot(is.owin(x))
  P <- as.polygonal(x)
  R <- as.rectangle(x)
  if(is.null(W)) 
    W <- R
  else if(!is.subset.owin(R, as.rectangle(W)))
    stop("W does not cover the domain of x")
  W <- as.mask(W, ...)
  #
  x0 <- W$xrange[1]
  y0 <- W$yrange[1]
  dx <- W$xstep
  dy <- W$ystep
  nx <- W$dim[2]
  ny <- W$dim[1]
  # set up output image (real-valued) and initialise to zero
  Z <- as.im(W, value=pi, na.replace=pi)
  Z <- eval.im(Z * 0)
  # process each component polygon  
  B <- P$bdry
  for(i in seq_along(B)) {
    PP <- B[[i]]
    # transform so that pixels become unit squares
    QQ <- affinexypolygon(PP, vec = c(-x0, -y0))
    RR <- affinexypolygon(QQ, mat = diag(1/c(dx, dy)))
    # 
    xx <- RR$x
    yy <- RR$y
    nn <- length(xx)
    # close polygon
    xx <- c(xx, xx[1])
    yy <- c(yy, yy[1])
    nn <- nn+1
    # call C routine
    zz <- .C("poly2imA",
             ncol=as.integer(nx),
             nrow=as.integer(ny),
             xpoly=as.double(xx),
             ypoly=as.double(yy),
             npoly=as.integer(nn),
             out=as.double(numeric(nx * ny)),
             status=as.integer(integer(1)))
    if(zz$status != 0)
      stop("Internal error")
    # increment output image
    Z$v <- Z$v + matrix(zz$out, ny, nx)
  }
  # revert to original scale
  pixelarea <- dx * dy
  Z <- eval.im(Z * pixelarea)
  return(Z)
}

    
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/plot.anylist.R"
##
##  plot.anylist.R
##
##  Plotting functions for 'solist', 'anylist', 'imlist'
##       and legacy class 'listof'
##
##  $Revision: 1.5 $ $Date: 2014/12/01 06:20:21 $
##

plot.anylist <- plot.solist <- plot.listof <-
  local({

  ## auxiliary functions
  extraplot <- function(nnn, x, ..., add=FALSE, extrargs=list(),
                        panel.args=NULL, plotcommand="plot") {
    argh <- list(...)
    if(is.ppp(x) && identical(plotcommand,"plot"))
      argh <- c(argh, list(multiplot=FALSE))
    if(!is.null(panel.args)) {
      xtra <- if(is.function(panel.args)) panel.args(nnn) else panel.args
      if(!is.list(xtra))
        stop(paste0("panel.args",
                    if(is.function(panel.args)) "(i)" else "",
                    " should be a list"))
      argh <- resolve.defaults(xtra, argh)
    }
    if(length(extrargs) > 0)
      argh <- resolve.defaults(argh, extrargs)
    ## some plot commands don't recognise 'add'
    if(add)
      argh <- append(argh, list(add=TRUE))
    do.call(plotcommand, append(list(x=x), argh))
  }

  exec.or.plot <- function(cmd, i, xi, ..., extrargs=list(), add=FALSE) {
    if(is.null(cmd)) return(NULL)
    argh <- resolve.defaults(list(...),
                             extrargs,
                             ## some plot commands don't recognise 'add' 
                             if(add) list(add=TRUE) else NULL)
    if(is.function(cmd)) 
      do.call(cmd, resolve.defaults(list(i, xi), argh))
    else
      do.call(plot, resolve.defaults(list(cmd), argh))
  }

  exec.or.plotshift <- function(cmd, i, xi, ..., vec=vec,
                                extrargs=list(), add=FALSE) {
    if(is.null(cmd)) return(NULL)
    argh <- resolve.defaults(list(...),
                             extrargs,
                             ## some plot commands don't recognise 'add' 
                             if(add) list(add=TRUE) else NULL)
    if(is.function(cmd)) {
      do.call(cmd, resolve.defaults(list(i, xi), argh))
    } else {
      cmd <- shift(cmd, vec)
      do.call(plot, resolve.defaults(list(cmd), argh))
    }
  }

  ## bounding box, including ribbon for images, legend for point patterns
  getplotbox <- function(x, ..., do.plot) {
    if(inherits(x, c("im", "ppp", "psp", "msr", "layered"))) {
      y <- plot(x, ..., do.plot=FALSE)      
      return(as.owin(y))
    }
    return(as.rectangle(x))
  }

  is.shiftable <- function(x) {
    if(is.null(x)) return(TRUE)
    if(is.function(x)) return(FALSE)
    y <- try(as.rectangle(x), silent=TRUE)
    return(!inherits(y, "try-error"))
  }

  plot.anylist <- function(x, ..., main, arrange=TRUE,
                            nrows=NULL, ncols=NULL,
                            main.panel=NULL,
                            mar.panel=c(2,1,1,2),
                            hsep = 0,
                            vsep = 0,
                            panel.begin=NULL,
                            panel.end=NULL,
                            panel.args=NULL,
                            plotcommand="plot",
                            adorn.left=NULL,
                            adorn.right=NULL,
                            adorn.top=NULL,
                            adorn.bottom=NULL,
                            adorn.size=0.2,
                            equal.scales=FALSE,
                            halign=FALSE, valign=FALSE) {
    xname <- short.deparse(substitute(x))

    isSo <- inherits(x, "solist")
    isIm <- inherits(x, "imlist") || (isSo && all(unlist(lapply(x, is.im))))
    
    ## `boomerang despatch'
    cl <- match.call()
    if(missing(plotcommand) && isIm) {
      cl[[1]] <- as.name("image.imlist")
      parenv <- sys.parent()
      return(eval(cl, envir=parenv))
    }

    if(isSo) {
      allfv <- somefv <- FALSE
    } else {
      isfv <- unlist(lapply(x, is.fv))
      allfv <- all(isfv)
      somefv <- any(isfv)
    }
    
    ## panel margins
    if(!missing(mar.panel)) {
      nm <- length(mar.panel)
      if(nm == 1) mar.panel <- rep(mar.panel, 4) else
      if(nm == 2) mar.panel <- rep(mar.panel, 2) else
      if(nm != 4) stop("mar.panel should have length 1, 2 or 4")
    } else if(somefv) {
      ## change default
      mar.panel <- 0.25+c(4,4,2,2)
    }
    
    n <- length(x)
    names(x) <- good.names(names(x), "Component_", 1:n)
    if(is.null(main.panel))
      main.panel <- names(x)
    else {
      stopifnot(is.character(main.panel) || is.expression(main.panel))
      nmp <- length(main.panel)
      if(nmp == 1)
        main.panel <- rep.int(main.panel, n)
      else if(nmp != n)
        stop("Incorrect length for main.panel")
    }

    if(allfv && equal.scales) {
      ## all entries are 'fv' objects: determine their plot limits
      fvlims <- lapply(x, plot, ..., limitsonly=TRUE)
      ## establish common x,y limits for all panels
      xlim <- range(unlist(lapply(fvlims, getElement, name="xlim")))
      ylim <- range(unlist(lapply(fvlims, getElement, name="ylim")))
      extrargs <- list(xlim=xlim, ylim=ylim)
    } else extrargs <- list()
    
    if(!arrange) {
      ## sequence of plots
      for(i in 1:n) {
        xi <- x[[i]]
        exec.or.plot(panel.begin, i, xi, main=main.panel[i],
                     extrargs=extrargs)
        extraplot(i, xi, ...,
                  add=!is.null(panel.begin),
                  main=main.panel[i],
                  panel.args=panel.args, extrargs=extrargs,
                  plotcommand=plotcommand)
        exec.or.plot(panel.end, i, xi, add=TRUE, extrargs=extrargs)
      }
      if(!is.null(adorn.left))
        warning("adorn.left was ignored because arrange=FALSE")
      if(!is.null(adorn.right))
        warning("adorn.right was ignored because arrange=FALSE")
      if(!is.null(adorn.top))
        warning("adorn.top was ignored because arrange=FALSE")
      if(!is.null(adorn.bottom))
        warning("adorn.bottom was ignored because arrange=FALSE")
      return(invisible(NULL))
    }

    ## ARRAY of plots
    ## decide whether to plot a main header
    main <- if(!missing(main) && !is.null(main)) main else xname
    if(!is.character(main)) {
      ## main title could be an expression
      nlines <- 1
      banner <- TRUE
    } else {
      ## main title is character string/vector, possibly ""
      banner <- any(nzchar(main))
      if(length(main) > 1)
        main <- paste(main, collapse="\n")
      nlines <- length(unlist(strsplit(main, "\n")))
    }
    ## determine arrangement of plots
    ## arrange like mfrow(nrows, ncols) plus a banner at the top
    if(is.null(nrows) && is.null(ncols)) {
      nrows <- as.integer(floor(sqrt(n)))
      ncols <- as.integer(ceiling(n/nrows))
    } else if(!is.null(nrows) && is.null(ncols))
      ncols <- as.integer(ceiling(n/nrows))
    else if(is.null(nrows) && !is.null(ncols))
      nrows <- as.integer(ceiling(n/ncols))
    else stopifnot(nrows * ncols >= length(x))
    nblank <- ncols * nrows - n
    if(allfv) {
      ## Function plots do not have physical 'size'
      sizes.known <- FALSE
    } else {
      ## Determine dimensions of objects
      ##     (including space for colour ribbons, if they are images)
      boxes <- try(lapply(x, getplotbox, ...), silent=TRUE)
      sizes.known <- !inherits(boxes, "try-error")
      if(equal.scales && !sizes.known) {
        warning("Ignored equal.scales=TRUE; scales could not be determined")
        equal.scales <- FALSE
      }
    }
    if(sizes.known) {
      ## determine size of each panel
      if(equal.scales) {
        ## do not rescale panels
        scaledboxes <- boxes
      } else {
        ## rescale panels
        sides <- lapply(boxes, sidelengths)
        bwidths <- unlist(lapply(sides, "[", 1))
        bheights <- unlist(lapply(sides, "[", 2))
        ## Force equal heights, unless there is only one column
        scales <- if(ncols > 1) 1/bheights else 1/bwidths
        scaledboxes <- vector(mode="list", length=n)
        for(i in 1:n)
          scaledboxes[[i]] <- scalardilate(boxes[[i]], scales[i])
      }
    }
    ## determine whether to display all objects in one enormous plot
    ## Precondition is that everything has a spatial bounding box
    single.plot <- equal.scales && sizes.known
    if(equal.scales && !single.plot && !allfv)
      warning("equal.scales=TRUE ignored ", "because bounding boxes ",
              "could not be determined", call.=FALSE)
    ## enforce alignment by expanding boxes
    if(halign) {
      if(!equal.scales)
        warning("halign=TRUE ignored because equal.scales=FALSE")
      ## x coordinates align in each column
      xr <- range(sapply(scaledboxes, getElement, name="xrange"))
      scaledboxes <- lapply(scaledboxes, "[[<-", i="xrange", value=xr)
    }
    if(valign) {
      if(!equal.scales)
        warning("valign=TRUE ignored because equal.scales=FALSE")
      ## y coordinates align in each column
      yr <- range(sapply(scaledboxes, getElement, name="yrange"))
      scaledboxes <- lapply(scaledboxes, "[[<-", i="yrange", value=yr)
    }
    ## set up layout
    mat <- matrix(c(seq_len(n), integer(nblank)),
                  byrow=TRUE, ncol=ncols, nrow=nrows)
    if(sizes.known) {
      boxsides <- lapply(scaledboxes, sidelengths)
      xwidths <- unlist(lapply(boxsides, "[", i=1))
      xheights <- unlist(lapply(boxsides, "[", i=2))
      heights <- apply(mat, 1, function(j,h) { max(h[j[j>0]]) }, h=xheights)
      widths <- apply(mat, 2, function(i,w) { max(w[i[i>0]]) }, w=xwidths)
    } else {
      heights <- rep.int(1, nrows)
      widths <- rep.int(1, ncols)
    }
    meanheight <- mean(heights)
    meanwidth  <- mean(widths)
    nall <- n
    ##
    if(single.plot) {
      ## .........  create a single plot ..................
      ## determine sizes
      ht <- max(heights)
      wd <- max(widths)
      marpar <- mar.panel * c(ht, wd, ht, wd)/6
      vsep <- vsep * ht/6
      hsep <- hsep * wd/6
      mainheight <- any(nzchar(main.panel)) * ht/5
      ewidths <- marpar[2] + widths + marpar[4]
      eheights <- marpar[1] + heights + marpar[3] + mainheight
      Width <- sum(ewidths) + hsep * (length(ewidths) - 1)
      Height <- sum(eheights) + vsep * (length(eheights) - 1)
      bigbox <- owin(c(0, Width), c(0, Height))
      ox <- marpar[2] + cumsum(c(0, ewidths + hsep))[1:ncols]
      oy <- marpar[1] + cumsum(c(0, rev(eheights) + vsep))[nrows:1]
      panelorigin <- as.matrix(expand.grid(x=ox, y=oy))
      ## initialise, with banner
      cex <- resolve.1.default(list(cex.title=1.5), list(...))/par('cex.main')
      plot(bigbox, type="n", main=main, cex.main=cex)
      ## plot individual objects
      for(i in 1:n) {
        ## determine shift vector that moves bottom left corner of spatial box
        ## to bottom left corner of target area on plot device
        vec <- panelorigin[i,] - with(scaledboxes[[i]], c(xrange[1], yrange[1]))
        ## shift panel contents
        xi <- x[[i]]
        xishift <- shift(xi, vec)
        ## let rip
        if(!is.null(panel.begin))
          exec.or.plotshift(panel.begin, i, xishift,
                            add=TRUE,
                            main=main.panel[i], show.all=TRUE,
                            extrargs=extrargs,
                            vec=vec)
        extraplot(i, xishift, ...,
                  add=TRUE, show.all=is.null(panel.begin),
                  main=main.panel[i],
                  extrargs=extrargs,
                  panel.args=panel.args, plotcommand=plotcommand)
        exec.or.plotshift(panel.end, i, xishift, add=TRUE,
                          extrargs=extrargs,
                          vec=vec)
      }
      return(invisible(NULL))
    }
    ## ................. multiple logical plots using 'layout' ..............
    ## adjust panel margins to accommodate desired extra separation
    mar.panel <- pmax(0, mar.panel + c(vsep, hsep, vsep, hsep)/2)
    ## check for adornment
    if(!is.null(adorn.left)) {
      ## add margin at left, of width adorn.size * meanwidth
      nall <- i.left <- n+1
      mat <- cbind(i.left, mat)
      widths <- c(adorn.size * meanwidth, widths)
    } 
    if(!is.null(adorn.right)) {
      ## add margin at right, of width adorn.size * meanwidth
      nall <- i.right <- nall+1
      mat <- cbind(mat, i.right)
      widths <- c(widths, adorn.size * meanwidth)
    } 
    if(!is.null(adorn.bottom)) {
      ## add margin at bottom, of height adorn.size * meanheight
      nall <- i.bottom <- nall+1
      mat <- rbind(mat, i.bottom)
      heights <- c(heights, adorn.size * meanheight)
    } 
    if(!is.null(adorn.top)) {
      ## add margin at top, of height adorn.size * meanheight
      nall <- i.top <- nall + 1
      mat <- rbind(i.top, mat)
      heights <- c(adorn.size * meanheight, heights)
    } 
    if(banner) {
      ## Increment existing panel numbers
      ## New panel 1 is the banner
      panels <- (mat > 0)
      mat[panels] <- mat[panels] + 1
      mat <- rbind(1, mat)
      heights <- c(0.1 * meanheight * (1 + nlines), heights)
    }
    ## declare layout
    layout(mat, heights=heights, widths=widths, respect=sizes.known)
    ## start output .....
    ## .... plot banner
    if(banner) {
      opa <- par(mar=rep.int(0,4), xpd=TRUE)
      plot(numeric(0),numeric(0),type="n",ann=FALSE,axes=FALSE,
           xlim=c(-1,1),ylim=c(-1,1))
      cex <- resolve.1.default(list(cex.title=1.5), list(...))/par('cex')
      text(0,0,main, cex=cex)
    }
    ## plot panels
    npa <- par(mar=mar.panel)
    if(!banner) opa <- npa
    for(i in 1:n) {
      xi <- x[[i]]
      exec.or.plot(panel.begin, i, xi, main=main.panel[i], extrargs=extrargs)
      extraplot(i, xi, ...,
                add = !is.null(panel.begin), 
                main = main.panel[i],
                extrargs=extrargs,
                panel.args=panel.args, plotcommand=plotcommand)
      exec.or.plot(panel.end, i, xi, add=TRUE, extrargs=extrargs)
    }
    ## adornments
    if(nall > n) {
      par(mar=rep.int(0,4), xpd=TRUE)
      if(!is.null(adorn.left))
        adorn.left()
      if(!is.null(adorn.right))
        adorn.right()
      if(!is.null(adorn.bottom))
        adorn.bottom()
      if(!is.null(adorn.top))
        adorn.top()
    }
    ## revert
    layout(1)
    par(opa)
    return(invisible(NULL))
  }

  plot.anylist
})


contour.imlist <- contour.listof <- function(x, ...) {
  xname <- short.deparse(substitute(x))
  do.call("plot.solist",
          resolve.defaults(list(x=x, plotcommand="contour"),
                           list(...),
                           list(main=xname)))
}

image.imlist <- plot.imlist <- image.listof <- local({

  image.imlist <- function(x, ..., equal.ribbon = FALSE, ribmar=NULL) {
    xname <- short.deparse(substitute(x))
    if(equal.ribbon &&
       !inherits(x, "imlist") &&
       !all(unlist(lapply(x, is.im)))) {
      warning("equal.ribbon is only implemented for objects of class 'im'")
      equal.ribbon <- FALSE
    }
    if(equal.ribbon) imagecommon(x, ..., xname=xname, ribmar=ribmar) else 
      do.call("plot.solist",
              resolve.defaults(list(x=x, plotcommand="image"),
                               list(...),
                               list(main=xname)))
  }

  imagecommon <- function(x, ...,
                          xname,
                          zlim=NULL,
                          ribbon=TRUE,
                          ribside=c("right", "left", "bottom", "top"),
                          ribsep=NULL, ribwid=0.5, ribn=1024,
                          ribscale=NULL, ribargs=list(),
                          ribmar = NULL, mar.panel = c(2,1,1,2)) {
    if(missing(xname))
      xname <- short.deparse(substitute(x))
    ribside <- match.arg(ribside)
    stopifnot(is.list(ribargs))
    if(!is.null(ribsep))
      warning("Argument ribsep is not yet implemented for image arrays")
    ## determine range of values
    if(is.null(zlim))
      zlim <- range(unlist(lapply(x, range)))
    ## determine common colour map
    imcolmap <- plot.im(x[[1]], do.plot=FALSE, zlim=zlim, ..., ribn=ribn)
    ## plot ribbon?
    if(!ribbon) {
      ribadorn <- list()
    } else {
      ## determine plot arguments for colour ribbon
      vertical <- (ribside %in% c("right", "left"))
      scaleinfo <- if(!is.null(ribscale)) list(labelmap=ribscale) else list()
      sidecode <- match(ribside, c("bottom", "left", "top", "right"))
      ribstuff <- c(list(x=imcolmap, main="", vertical=vertical),
                    ribargs,
                    scaleinfo,
                    list(side=sidecode))
      if (is.null(mar.panel)) 
        mar.panel <- c(2, 1, 1, 2)
      if (length(mar.panel) != 4) 
        mar.panel <- rep(mar.panel, 4)[1:4]
      if (is.null(ribmar)) {
        ribmar <- mar.panel/2
        newmar <- c(2, 0)
        switch(ribside,
               left   = { ribmar[c(2, 4)] <- newmar },
               right  = { ribmar[c(4, 2)] <- newmar },
               bottom = { ribmar[c(1, 3)] <- newmar },
               top    = { ribmar[c(3, 1)] <- newmar }
               )
      }
       ## function executed to plot colour ribbon
      do.ribbon <- function() {
        opa <- par(mar=ribmar)
        do.call("plot", ribstuff)
        par(opa)
      }
      ## encoded as 'adorn' argument
      ribadorn <- list(adorn=do.ribbon, adorn.size=ribwid)
      names(ribadorn)[1] <- paste("adorn", ribside, sep=".")
    }
    ##
    do.call("plot.solist",
            resolve.defaults(list(x=x, plotcommand="image"),
                             list(...),
                             list(mar.panel=mar.panel,
                                  main=xname,
                                  col=imcolmap, zlim=zlim,
                                  ribbon=FALSE),
                             ribadorn))
  }

  image.imlist
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/plot.fasp.R"
#
#   plot.fasp.R
#
#   $Revision: 1.28 $   $Date: 2014/12/29 03:11:28 $
#
plot.fasp <- function(x, formule=NULL, ..., subset=NULL,
                      title=NULL, banner=TRUE,
                      transpose=FALSE,
                      samex=FALSE, samey=FALSE,
                      mar.panel=NULL,
                      outerlabels=TRUE, cex.outerlabels=1.25,
                      legend=FALSE) {
  # plot dimensions
  which <- x$which
  if(transpose)
    which <- t(which)
  nrows  <- nrow(which)
  ncols  <- ncol(which)
  
# Determine the overall title of the plot
  if(banner) {
    if(!is.null(title)) overall <- title
    else if(!is.null(x$title)) overall <- x$title
    else {
      if(prod(dim(which)) > 1)
        overall <- "Array of diagnostic functions"
      else
        overall <- "Diagnostic function"
      if(is.null(x$dataname)) overall <- paste(overall,".",sep="")
      else overall <- paste(overall," for ",x$dataname,".",sep="")
    }
    if(length(overall) > 1)
      overall <- paste(overall, collapse="\n")
    nlines <-
      if(!is.character(overall)) 1 else length(unlist(strsplit(overall, "\n")))
  } 

# If no formula is given, look for a default formula in x:
  defaultplot <- is.null(formule)
  if(defaultplot && !is.null(x$default.formula))
    formule <- x$default.formula

  if(!is.null(formule)) {
    # ensure formulae are given as character strings.
    formule <- FormatFaspFormulae(formule, "formule")
    # Number of formulae should match number of functions.
    nf <- length(formule)
    nfun <- length(x$fns)
    if(nf == 1 && nfun > 1)
      formule <- rep.int(formule, nfun)
    else if(nf != nfun)
      stop(paste("Wrong number of entries in", sQuote("formule")))
  }
  
# Check on the length of the subset argument.
  ns <- length(subset)
  if(ns > 1) {
    if(ns != length(x$fns))
      stop("Wrong number of entries in subset argument.\n")
    msub <- TRUE
  } else msub <- FALSE

# compute common x, y axis limits for all plots ?
  xlim <- ylim <- NULL
  if(samex || samey) {
    cat("Computing limits\n")
    # call plot.fv to determine plot limits of each panel
    for(i in 1:nrows) {
      for(j in 1:ncols) {
        k <- which[i,j]
        if(!is.na(k)) {
          fun <- as.fv(x$fns[[k]])
          fmla <- if(!defaultplot) formule[k] else NULL
          sub <- if(msub) subset[[k]] else subset
          lims <- plot(fun, fmla, subset=sub, limitsonly=TRUE)
          # update the limits
          if(samex) xlim <- range(xlim, lims$xlim)
          if(samey) ylim <- range(ylim, lims$ylim)
        }
      }
    }
  } 

#############################################################  
# Set up the plot layout
  n <- nrows * ncols
# panels 1..n = plot panels
  codes <- matrix(seq_len(n), byrow=TRUE, ncol=ncols, nrow=nrows)
  heights <- rep.int(1, nrows)
  widths  <- rep.int(1, ncols)
# annotation as chosen
  if(outerlabels) {
    # column headings
    colhead.codes <- max(codes) + (1:ncols)
    colhead.height <- 0.2
    codes <- rbind(colhead.codes, codes)
    heights <- c(colhead.height, heights)
    # row headings
    rowhead.codes <- max(codes) + (1:nrows)
    rowhead.width <- 0.2
    codes <- cbind(c(0,rowhead.codes), codes)
    widths <- c(rowhead.width, widths)
  }
  if(banner) {
    # overall banner
    top.code <- max(codes) + 1
    top.height <- 0.1 * (1+nlines)
    codes <- rbind(top.code, codes)
    heights <- c(top.height, heights)
  }

# declare layout  
  layout(codes, widths=widths, heights=heights)

############################################################  
# Plot the function panels 
#
# determine annotation
  colNames <- colnames(which)
  rowNames <- rownames(which)
  nrc <- max(nrows, ncols)
  ann.def <- par("ann") && (nrc <= 3)
# determine margin around each panel
  if(is.null(mar.panel)) 
    mar.panel <- if(nrc > 3 && outerlabels) rep.int(1/nrc, 4) else par("mar")
  opa <- par(mar=mar.panel, xpd=TRUE)
#
# plot each function  
  for(i in 1:nrows) {
    for(j in 1:ncols) {
      k <- which[i,j]
      if(is.na(k)) plot(0,0,type='n',xlim=c(0,1),
                        ylim=c(0,1),axes=FALSE,xlab='',ylab='', ...)
      else {
        fun <- as.fv(x$fns[[k]])
        fmla <- if(!defaultplot) formule[k] else NULL
        sub <- if(msub) subset[[k]] else subset
        main <- if(outerlabels) "" else
                if(nrows == 1) colNames[j] else
                if(ncols == 1) rowNames[i] else 
                paren(paste(rowNames[i], colNames[j], sep=","))
        do.call("plot",
                resolve.defaults(list(x=fun, fmla=fmla, subset=sub),
                                 list(...),
                                 list(xlim=xlim, ylim=ylim,
                                      main=main, legend=legend),
                                 list(ann=ann.def, axes=ann.def,
                                      frame.plot=TRUE)))
      }
    }
  }
############################################################
#
# Annotation as selected
  if(outerlabels) {
    par(mar=rep.int(0,4), xpd=TRUE)
    # Plot the column headers
    for(j in 1:ncols) {
      plot(numeric(0),numeric(0),type="n",ann=FALSE,axes=FALSE,
           xlim=c(-1,1),ylim=c(-1,1))
      text(0,0,colNames[j], cex=cex.outerlabels)
    }
    # Plot the row labels
    for(i in 1:nrows) {
      plot(numeric(0),numeric(0),type="n",ann=FALSE,axes=FALSE,
           xlim=c(-1,1),ylim=c(-1,1))
      text(0,0,rowNames[i], srt=90, cex=cex.outerlabels)
    }
  }
  if(banner) {
    par(mar=rep.int(0,4), xpd=TRUE)
    # plot the banner
    plot(numeric(0),numeric(0),type="n",ann=FALSE,axes=FALSE,
         xlim=c(-1,1),ylim=c(-1,1))
    cex <- resolve.defaults(list(...), list(cex.title=2))$cex.title
    text(0,0, overall, cex=cex)
  }
  
  # revert
  layout(1)
  par(opa)
  return(invisible(NULL))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/plot.fv.R"
#
#       plot.fv.R   (was: conspire.S)
#
#  $Revision: 1.117 $    $Date: 2014/11/10 11:10:49 $
#
#

conspire <- function(...) {
  .Deprecated("plot.fv", package="spatstat")
  plot.fv(...)
}

plot.fv <- local({

  hasonlyone <- function(x, amongst) {
    sum(all.vars(parse(text=x)) %in% amongst) == 1
  }

  extendifvector <- function(a, n, nmore) {
    if(is.null(a)) return(a)
    if(length(a) == 1) return(a)
    return(c(a, rep(a[1], nmore)))
  }

  fixit <- function(a, n, a0, a00) {
    # 'a' is formal argument
    # 'a0' and 'a00' are default and fallback default
    # 'n' is number of values required
    if(is.null(a))
      a <- if(!is.null(a0)) a0 else a00
    if(length(a) == 1)
      return(rep.int(a, n))
    else if(length(a) != n)
      stop(paste("Length of", short.deparse(substitute(a)),
                 "does not match number of curves to be plotted"))
    else 
      return(a)
  }

  pow10 <- function(x) { 10^x }

  plot.fv <- function(x, fmla, ..., subset=NULL, lty=NULL, col=NULL, lwd=NULL,
                      xlim=NULL, ylim=NULL, xlab=NULL, ylab=NULL,
                      ylim.covers=NULL, legend=!add, legendpos="topleft",
                      legendavoid=missing(legendpos),
                      legendmath=TRUE, legendargs=list(),
                      shade=fvnames(x, ".s"), shadecol="grey", add=FALSE,
                      log="",
                      mathfont=c("italic", "plain", "bold", "bolditalic"), 
                      limitsonly=FALSE) {

    xname <-
      if(is.language(substitute(x))) short.deparse(substitute(x)) else ""

    force(legendavoid)
    if(is.null(legend))
      legend <- !add

    mathfont <- match.arg(mathfont)

    verifyclass(x, "fv")
    env.user <- parent.frame()

    indata <- as.data.frame(x)

    xlogscale <- (log %in% c("x", "xy", "yx"))
    ylogscale <- (log %in% c("y", "xy", "yx"))

    ## ---------------- determine plot formula ----------------
  
    defaultplot <- missing(fmla) || is.null(fmla)
    if(defaultplot) 
      fmla <- formula(x)

    ## This *is* the last possible moment, so...
    fmla <- as.formula(fmla, env=env.user)

    ## validate the variable names
    vars <- variablesinformula(fmla)
    reserved <- c(".", ".x", ".y", ".a", ".s")
    external <- !(vars %in% c(colnames(x), reserved))
    if(any(external)) {
      sought <- vars[external]
      found <- unlist(lapply(sought, exists, envir=env.user, mode="numeric"))
      if(any(!found)) {
        nnot <- sum(!found)
        stop(paste(ngettext(nnot, "Variable", "Variables"),
                   commasep(sQuote(sought[!found])),
                   ngettext(nnot, "was", "were"),
                   "not found"))
      } else {
        ## validate the found variables
        externvars <- lapply(sought, get, envir=env.user)
        isnum <- unlist(lapply(externvars, is.numeric))
        len <- unlist(lapply(externvars, length))
        ok <- isnum & (len == 1 | len == nrow(x))
        if(!all(ok)) {
          nnot <- sum(!ok)
          stop(paste(ngettext(nnot, "Variable", "Variables"),
                     commasep(sQuote(sought[!ok])),
                     ngettext(nnot, "is", "are"),
                     "not of the right format"))
        }
      }
    }
  
    ## Extract left hand side as given
#    lhs.original <- fmla[[2]]
    fmla.original <- fmla
  
    ## expand "."
    dotnames <- fvnames(x, ".")
    starnames <- fvnames(x, "*")
    umap <- fvexprmap(x)
    fmla <- eval(substitute(substitute(fom, um), list(fom=fmla, um=umap)))

    ## ------------------- extract data for plot ---------------------
  
    ## extract LHS and RHS of formula
    lhs <- fmla[[2]]
    rhs <- fmla[[3]]

    ## extract data 
    lhsdata <- eval(lhs, envir=indata)
    rhsdata <- eval(rhs, envir=indata)

    ## reformat
    if(is.vector(lhsdata)) {
      lhsdata <- matrix(lhsdata, ncol=1)
      lhsvars <- all.vars(as.expression(lhs))
      lhsvars <- lhsvars[lhsvars %in% names(x)]
      colnames(lhsdata) <-
        if(length(lhsvars) == 1) lhsvars else
        if(length(starnames) == 1 && (starnames %in% lhsvars)) starnames else 
        paste(short.deparse(lhs), collapse="")
    }
    ## check lhs names exist
    lnames <- colnames(lhsdata)
    nc <- ncol(lhsdata)
    lnames0 <- paste("V", seq_len(nc), sep="")
    if(length(lnames) != nc)
      colnames(lhsdata) <- lnames0
    else if(any(uhoh <- !nzchar(lnames)))
      colnames(lhsdata)[uhoh] <- lnames0[uhoh]
    lhs.names <- colnames(lhsdata)

    ## check whether each lhs column is associated with a single column of 'x'
    ## that is one of the alternative versions of the function.
    ##    This may be unreliable, as it depends on the
    ##    column names assigned to lhsdata by eval()
    one.star <- unlist(lapply(lhs.names, hasonlyone, amongst=fvnames(x, "*")))
    one.dot  <- unlist(lapply(lhs.names, hasonlyone, amongst=dotnames))
    explicit.lhs.names    <- ifelse(one.star, lhs.names, "")
    explicit.lhs.dotnames <- ifelse(one.star & one.dot, lhs.names, "")
  
    ## check rhs data
    if(is.matrix(rhsdata))
      stop("rhs of formula should yield a vector")
    rhsdata <- as.numeric(rhsdata)

    nplots <- ncol(lhsdata)
    allind <- 1:nplots
  
    ## ---------- extra plots may be implied by 'shade' -----------------
    extrashadevars <- NULL
  
    if(!is.null(shade)) {
      ## select columns by name or number
      names(allind) <- explicit.lhs.names
      shind <- try(allind[shade])
      if(inherits(shind, "try-error")) 
        stop(paste("The argument shade should be a valid subset index",
                   "for columns of x"), call.=FALSE)
      if(any(nbg <- is.na(shind))) {
        ## columns not included in formula: add them
        morelhs <- try(as.matrix(indata[ , shade[nbg], drop=FALSE]))
        if(inherits(morelhs, "try-error")) 
          stop(paste("The argument shade should be a valid subset index",
                     "for columns of x"), call.=FALSE)
        nmore <- ncol(morelhs)
        extrashadevars <- colnames(morelhs)
        if(defaultplot) {
          success <- TRUE
        } else if("." %in% variablesinformula(fmla.original)) {
          ## evaluate lhs of formula, expanding "." to shade names
          u <- if(length(extrashadevars) == 1) as.name(extrashadevars) else {
            as.call(lapply(c("cbind", extrashadevars), as.name))
          }
          ux <- as.name(fvnames(x, ".x"))
          uy <- as.name(fvnames(x, ".y"))
          foo <- eval(substitute(substitute(fom, list(.=u, .x=ux, .y=uy)),
                                 list(fom=fmla.original)))
          lhsnew <- foo[[2]]
          morelhs <- eval(lhsnew, envir=indata)
          success <- identical(colnames(morelhs), extrashadevars)
        } else if(is.name(lhs) && as.character(lhs) %in% names(indata)) {
          ## lhs is the name of a single column in x
          ## expand the LHS 
          explicit.lhs.names <- c(explicit.lhs.names, extrashadevars)
          ff <- paste("cbind",
                      paren(paste(explicit.lhs.names, collapse=", ")),
                      "~ 1")
          lhs <- lhs.of.formula(as.formula(ff))
          success <- TRUE
        } else if(length(explicit.lhs.dotnames) > 1) {
          ## lhs = cbind(...) where ... are dotnames
          cbound <- paste0("cbind",
                           paren(paste(explicit.lhs.dotnames, collapse=", ")))
          if(identical(deparse(lhs), cbound)) {
            success <- TRUE
            explicit.lhs.names <- union(explicit.lhs.names, extrashadevars)
            ff <- paste("cbind",
                        paren(paste(explicit.lhs.names, collapse=", ")),
                        "~ 1")
            lhs <- lhs.of.formula(as.formula(ff))
          } else success <- FALSE
        } else success <- FALSE
        if(success) {
          ## add these columns to the plotting data
          lhsdata <- cbind(lhsdata, morelhs)
          shind[nbg] <- nplots + seq_len(nmore)
          lty <- extendifvector(lty, nplots, nmore)
          col <- extendifvector(col, nplots, nmore)
          lwd <- extendifvector(lwd, nplots, nmore)
          nplots <- nplots + nmore
          ## update the names
          one.star <- unlist(lapply(explicit.lhs.names,
                                    hasonlyone, amongst=fvnames(x, "*")))
          one.dot  <- unlist(lapply(explicit.lhs.names,
                                    hasonlyone, amongst=dotnames))
          explicit.lhs.names    <- ifelse(one.star, explicit.lhs.names, "")
          explicit.lhs.dotnames <- ifelse(one.star & one.dot,
                                          explicit.lhs.names, "")
        } else {
          ## cannot add columns
          warning(paste("Shade",
                        ngettext(sum(nbg), "column", "columns"),
                        commasep(sQuote(shade[nbg])),
                        "were missing from the plot formula, and were omitted"))
          shade <- NULL
          extrashadevars <- NULL
        }
      }
    }

    ## -------------------- determine plotting limits ----------------------
  
    ## restrict data to subset if desired
    if(!is.null(subset)) {
      keep <- if(is.character(subset)) {
                eval(parse(text=subset), envir=indata)
              } else eval(subset, envir=indata)
      lhsdata <- lhsdata[keep, , drop=FALSE]
      rhsdata <- rhsdata[keep]
    }
  
    ## determine x and y limits and clip data to these limits
    if(is.null(xlim) && add) {
      ## x limits are determined by existing plot
      xlim <- par("usr")[1:2]
    }
    if(!is.null(xlim)) {
      ok <- !is.finite(rhsdata) | (xlim[1] <= rhsdata & rhsdata <= xlim[2])
      rhsdata <- rhsdata[ok]
      lhsdata <- lhsdata[ok, , drop=FALSE]
    } else {
      ## if we're using the default argument, use its recommended range
      if(rhs == fvnames(x, ".x")) {
        xlim <- attr(x, "alim") %orifnull% range(rhsdata, finite=TRUE)
        if(xlogscale && xlim[1] <= 0) 
          xlim[1] <- min(rhsdata[is.finite(rhsdata) & rhsdata > 0], na.rm=TRUE)
        ok <- !is.finite(rhsdata) | (rhsdata >= xlim[1] & rhsdata <= xlim[2])
        rhsdata <- rhsdata[ok]
        lhsdata <- lhsdata[ok, , drop=FALSE]
      } else { ## actual range of values to be plotted
        if(xlogscale) {
          ok <- is.finite(rhsdata) & (rhsdata > 0) & apply(lhsdata > 0, 1, any)
          xlim <- range(rhsdata[ok])
        } else {
          xlim <- range(rhsdata, na.rm=TRUE)
        }
      }
    }

    if(is.null(ylim)) {
      yok <- is.finite(lhsdata)
      if(ylogscale)
        yok <- yok & (lhsdata > 0)
      ylim <- range(lhsdata[yok],na.rm=TRUE)
    }
    if(!is.null(ylim.covers))
      ylim <- range(ylim, ylim.covers)

    ## return x, y limits only?
    if(limitsonly)
      return(list(xlim=xlim, ylim=ylim))
  
    ## -------------  work out how to label the plot --------------------

    ## extract plot labels, substituting function name
    labl <- fvlabels(x, expand=TRUE)
    ## create plot label map (key -> algebraic expression)
    map <- fvlabelmap(x) 

    ## ......... label for x axis ..................

    if(is.null(xlab)) {
      argname <- fvnames(x, ".x")
      if(as.character(fmla)[3] == argname) {
        ## The x axis variable is the default function argument.
        ArgString <- fvlabels(x, expand=TRUE)[[argname]]
        xexpr <- parse(text=ArgString)
        ## use specified font
        xexpr <- fontify(xexpr, mathfont)
        ## Add name of unit of length?
        ax <- summary(unitname(x))$axis
        if(is.null(ax)) {
          xlab <- xexpr
        } else {
          xlab <- expression(VAR ~ COMMENT)
          xlab[[1]][[2]] <- xexpr[[1]]
          xlab[[1]][[3]] <- ax
        }
      } else {
        ## map ident to label
        xlab <- eval(substitute(substitute(rh, mp), list(rh=rhs, mp=map)))
        ## use specified font
        xlab <- fontify(xlab, mathfont)
      }
    }
    if(is.language(xlab) && !is.expression(xlab))
      xlab <- as.expression(xlab)

    ## ......... label for y axis ...................

    leftside <- lhs
    if(ncol(lhsdata) > 1 || length(dotnames) == 1) {
      ## For labelling purposes only, simplify the LHS by 
      ## replacing 'cbind(.....)' by '.'
      ## even if not all columns are included.
      leftside <- paste(as.expression(leftside))
      eln <- explicit.lhs.dotnames
      eln <- eln[nzchar(eln)]
      cb <- if(length(eln) == 1) eln else {
        paste("cbind(",
              paste(eln, collapse=", "),
              ")", sep="")
      }
      compactleftside <- gsub(cb, ".", leftside, fixed=TRUE)
      ## Separately expand "." to cbind(.....)
      ## and ".x", ".y" to their real names
      dotdot <- c(dotnames, extrashadevars)
      cball <- if(length(dotdot) == 1) dotdot else {
        paste("cbind(",
              paste(dotdot, collapse=", "),
              ")", sep="")
      }
      expandleftside <- gsub(".x", fvnames(x, ".x"), leftside, fixed=TRUE)
      expandleftside <- gsub(".y", fvnames(x, ".y"), expandleftside, fixed=TRUE)
      expandleftside <- gsubdot(cball, expandleftside)
      ## convert back to language
      compactleftside <- parse(text=compactleftside)[[1]]
      expandleftside <- parse(text=expandleftside)[[1]]
    } else {
      compactleftside <- expandleftside <- leftside
    }

    ## construct label for y axis
    if(is.null(ylab)) {
      yl <- attr(x, "yexp")
      if(defaultplot && !is.null(yl)) {
        ylab <- yl
      } else {
        ## replace "." and short identifiers by plot labels
        ylab <- eval(substitute(substitute(le, mp),
                                list(le=compactleftside, mp=map)))
      }
    }
    if(is.language(ylab)) {
      ## use specified font
      ylab <- fontify(ylab, mathfont)
      ## ensure it's an expression
      if(!is.expression(ylab))
        ylab <- as.expression(ylab)
    }

    ## ------------------ start plotting ---------------------------

    ## create new plot
    if(!add)
      do.call("plot.default",
              resolve.defaults(list(xlim, ylim, type="n", log=log),
                               list(xlab=xlab, ylab=ylab),
                               list(...),
                               list(main=xname)))

    ## handle 'type' = "n" 
    giventype <- resolve.defaults(list(...), list(type=NA))$type
    if(identical(giventype, "n"))
      return(invisible(NULL))

    ## process lty, col, lwd arguments

    opt0 <- spatstat.options("par.fv")
  
    lty <- fixit(lty, nplots, opt0$lty, 1:nplots)
    col <- fixit(col, nplots, opt0$col, 1:nplots)
    lwd <- fixit(lwd, nplots, opt0$lwd, 1)

    ## convert to greyscale?
    if(spatstat.options("monochrome"))
      col <- to.grey(col)
    
    if(!is.null(shade)) {
      ## shade region between critical boundaries
      ## extract relevant columns for shaded bands
      shdata <- lhsdata[, shind]
      if(!is.matrix(shdata) || ncol(shdata) != 2) 
        stop("The argument shade should select two columns of x")
      ## truncate infinite values to plot limits
      if(any(isinf <- is.infinite(shdata))) {
        if(is.null(ylim)) {
          warning("Unable to truncate infinite values to the plot area")
        } else {
          shdata[isinf & (shdata == Inf)] <- ylim[2]
          shdata[isinf & (shdata == -Inf)] <- ylim[1]
        }
      }
      ## determine limits of shading
      shdata1 <- shdata[,1]
      shdata2 <- shdata[,2]
      ## plot grey polygon
      xpoly <- c(rhsdata, rev(rhsdata))
      ypoly <- c(shdata1, rev(shdata2)) 
      miss1 <- !is.finite(shdata1)
      miss2 <- !is.finite(shdata2)
      if(!any(broken <- (miss1 | miss2))) {
        ## single polygon
        polygon(xpoly, ypoly, border=shadecol, col=shadecol)
      } else {
        ## interrupted
        dat <- data.frame(rhsdata=rhsdata, shdata1=shdata1, shdata2=shdata2)
        serial <- cumsum(broken)
        lapply(split(dat, serial),
               function(z) {
                 with(z, {
                   xp <- c(rhsdata, rev(rhsdata))
                   yp <- c(shdata1, rev(shdata2))
                   polygon(xp, yp, border=shadecol, col=shadecol)
                 })
               })
        ## save for use in placing legend
        okp <- !c(broken, rev(broken))
        xpoly <- xpoly[okp]
        ypoly <- ypoly[okp]
      }
      ## overwrite graphical parameters
      lty[shind] <- 1
      ## try to preserve the same type of colour specification
      if(is.character(col) && is.character(shadecol)) {
        ## character representations 
        col[shind] <- shadecol
      } else if(is.numeric(col) && !is.na(sc <- paletteindex(shadecol))) {
        ## indices in colour palette
        col[shind] <- sc
      } else {
        ## convert colours to hexadecimal and edit relevant values
        col <- col2hex(col)
        col[shind] <- col2hex(shadecol)
      }
      ## remove these columns from further plotting
      allind <- allind[-shind]
      ## 
    } else xpoly <- ypoly <- numeric(0)
  
    ## ----------------- plot lines ------------------------------

    for(i in allind)
      lines(rhsdata, lhsdata[,i], lty=lty[i], col=col[i], lwd=lwd[i])

    if(nplots == 1)
      return(invisible(NULL))

    ## ---------------- determine legend -------------------------
    key <- colnames(lhsdata)
    mat <- match(key, names(x))
    keyok <- !is.na(mat)
    matok <- mat[keyok]
    legdesc <- rep.int("constructed variable", length(key))
    legdesc[keyok] <- attr(x, "desc")[matok]
    leglabl <- lnames0
    leglabl[keyok] <- labl[matok]
    ylab <- attr(x, "ylab")
    if(!is.null(ylab)) {
      if(is.language(ylab)) 
        ylab <- flat.deparse(ylab)
      legdesc <- sprintf(legdesc, ylab)
    }
    ## compute legend info
    legtxt <- key
    if(legendmath) {
      legtxt <- leglabl
      if(defaultplot) {
        ## try to convert individual labels to expressions
        fancy <- try(parse(text=leglabl), silent=TRUE)
        if(!inherits(fancy, "try-error"))
          legtxt <- fancy
      } else {
        ## try to navigate the parse tree
        fancy <- try(fvlegend(x, expandleftside), silent=TRUE)
        if(!inherits(fancy, "try-error"))
          legtxt <- fancy
      }
    }

    if(is.expression(legtxt) ||
       is.language(legtxt) ||
       all(sapply(legtxt, is.language)))
      legtxt <- fontify(legtxt, mathfont)

    ## --------------- handle legend plotting  -----------------------------
    
    if(identical(legend, TRUE)) {
      ## legend will be plotted
      ## Basic parameters of legend
      legendxpref <- if(identical(legendpos, "float")) NULL else legendpos
      optparfv <- spatstat.options("par.fv")$legendargs %orifnull% list()
      legendspec <- resolve.defaults(legendargs,
                                     list(lty=lty,
                                          col=col,
                                          lwd=lwd),
                                     optparfv,
                                     list(x=legendxpref,
                                          legend=legtxt,
                                          inset=0.05,
                                          y.intersp=if(legendmath) 1.3 else 1),
                                     .StripNull=TRUE)
      
      if(legendavoid || identical(legendpos, "float")) {
        ## Automatic determination of legend position
        ## Assemble data for all plot objects
        linedata <- list()
        xmap <- if(xlogscale) log10 else identity
        ymap <- if(ylogscale) log10 else identity
        inv.xmap <- if(xlogscale) pow10 else identity
        inv.ymap <- if(ylogscale) pow10 else identity 
        for(i in seq_along(allind)) 
          linedata[[i]] <- list(x=xmap(rhsdata), y=ymap(lhsdata[,i]))
        polydata <-
          if(length(xpoly) > 0) list(x=xmap(xpoly), y=ymap(ypoly)) else NULL
        objects <- assemble.plot.objects(xmap(xlim), ymap(ylim),
                                         lines=linedata, polygon=polydata)
        ## find best position to avoid them
        legendbest <- findbestlegendpos(objects, preference=legendpos,
                                      legendspec=legendspec)
        ## handle log scale
        if((xlogscale || ylogscale) &&
           checkfields(legendbest, c("x", "xjust", "yjust"))) {
          ## back-transform x, y coordinates
          legendbest$x$x <- inv.xmap(legendbest$x$x)
          legendbest$x$y <- inv.ymap(legendbest$x$y)
        }
      } else legendbest <- list()
    
      ##  ********** plot legend *************************
      if(!is.null(legend) && legend) 
        do.call("legend",
                resolve.defaults(legendargs,
                                 legendbest,
                                 legendspec,
                                 .StripNull=TRUE))
      
    }

    ## convert labels back to character
    labl <- paste.expr(legtxt)
    labl <- gsub(" ", "", labl)
    ## return legend info
    df <- data.frame(lty=lty, col=col, key=key, label=labl,
                     meaning=legdesc, row.names=key)
    return(df)
  }
  plot.fv

})



assemble.plot.objects <- function(xlim, ylim, ..., lines=NULL, polygon=NULL) {
  # Take data that would have been passed to the commands 'lines' and 'polygon'
  # and form corresponding geometrical objects.
  objects <- list()
  if(!is.null(lines)) {
    if(is.psp(lines)) {
      objects <- list(lines)
    } else {
      if(checkfields(lines, c("x", "y"))) {
        lines <- list(lines)
      } else if(!all(unlist(lapply(lines, checkfields, L=c("x", "y")))))
        stop("lines should be a psp object, a list(x,y) or a list of list(x,y)")
      W <- owin(xlim, ylim)
      for(i in seq_along(lines)) {
        lines.i <- lines[[i]]
        x.i <- lines.i$x
        y.i <- lines.i$y
        n <- length(x.i)
        if(length(y.i) != n)
          stop(paste(paste("In lines[[", i, "]]", sep=""),
                     "the vectors x and y have unequal length"))
        if(!all(ok <- (is.finite(x.i) & is.finite(y.i)))) {
          x.i <- x.i[ok]
          y.i <- y.i[ok]
          n <- sum(ok)
        }
        segs.i <- psp(x.i[-n], y.i[-n], x.i[-1], y.i[-1], W, check=FALSE)
        objects <- append(objects, list(segs.i))        
      }
    }
  }
  if(!is.null(polygon)) {
    # Add filled polygon
    pol <- polygon[c("x", "y")]
    ok <- with(pol, is.finite(x) & is.finite(y))
    if(!all(ok))
      pol <- with(pol, list(x=x[ok], y=y[ok]))
    if(Area.xypolygon(pol) < 0) pol <- lapply(pol, rev)
    P <- try(owin(poly=pol, xrange=xlim, yrange=ylim, check=FALSE))
    if(!inherits(P, "try-error"))
      objects <- append(objects, list(P))
  }
  return(objects)
}

findbestlegendpos <- local({
  # Given a list of geometrical objects, find the best position
  # to avoid them.
  thefunction <- function(objects, show=FALSE, aspect=1, bdryok=TRUE,
                          preference="float", verbose=FALSE,
                          legendspec=NULL) {
    # find bounding box
    W <- do.call("boundingbox", lapply(objects, as.rectangle))
    # convert to common box
    objects <- lapply(objects, rebound, rect=W)
    # comp
    # rescale x and y axes so that bounding box has aspect ratio 'aspect'
    aspectW <- with(W, diff(yrange)/diff(xrange))
    s <- aspect/aspectW
    mat <- diag(c(1, s))
    invmat <- diag(c(1, 1/s))
    scaled.objects <- lapply(objects, affine, mat=mat)
    scaledW <- affine(W, mat=mat)
    if(verbose) {
      cat("Scaled space:\n")
      print(scaledW)
    }
    # pixellate the scaled objects
    pix.scal.objects <- lapply(scaled.objects, asma)
    # apply distance transforms in scaled space
    D1 <- distmap(pix.scal.objects[[1]])
    Dlist <- lapply(pix.scal.objects, distmap, xy=list(x=D1$xcol, y=D1$yrow))
    # distance transform of superposition
    D <- im.apply(Dlist, min)
    if(!bdryok) {
      # include distance to boundary
      B <- attr(D1, "bdry")
      D <- eval.im(pmin.int(D, B))
    }
    if(show) {
      plot(affine(D, mat=invmat), add=TRUE)
      lapply(lapply(scaled.objects, affine, mat=invmat), plot, add=TRUE)
    }
    if(preference != "float") {
      # evaluate preferred location (check for collision)
      if(!is.null(legendspec)) {
        # pretend to plot the legend as specified
        legout <- do.call("legend", append(legendspec, list(plot=FALSE)))
        # determine bounding box
        legbox <- with(legout$rect, owin(c(left, left+w), c(top-h, top)))
        scaledlegbox <- affine(legbox, mat=mat)
        # check for collision 
        Dmin <- min(D[scaledlegbox])
        if(Dmin >= 0.02) {
          # no collision: stay at preferred location. Exit.
          return(list(x=preference))
        }
        # collision occurred! 
      } else {
        # no legend information.
        # Pretend legend is 15% of plot width and height
        xr <- scaledW$xrange
        yr <- scaledW$yrange
        testloc <- switch(preference,
                          topleft     = c(xr[1],yr[2]),
                          top         = c(mean(xr), yr[2]),
                          topright    = c(xr[2], yr[2]),
                          right       = c(xr[2], mean(yr)),
                          bottomright = c(xr[2], yr[1]),
                          bottom      = c(mean(xr), yr[1]),
                          bottomleft  = c(xr[1], yr[1]),
                          left        = c(xr[1], mean(yr)),
                          center      = c(mean(xr), mean(yr)),
                          NULL)
        if(!is.null(testloc)) {
          # look up distance value at preferred location
          val <- safelookup(D, list(x=testloc[1], y=testloc[2]))
          crit <- 0.15 * min(diff(xr), diff(yr))
          if(verbose)
            cat(paste("val=",val, ", crit=", crit, "\n"))
          if(val > crit) {
            # no collision: stay at preferred location. Exit.
            return(list(x=preference))
          }
        # collision occurred! 
        }
      }
      # collision occurred! 
    }
    # find location of max
    locmax <- which(D$v == max(D), arr.ind=TRUE)
    locmax <- unname(locmax[1,])
    pos <- list(x=D$xcol[locmax[2]], y=D$yrow[locmax[1]])
    pos <- affinexy(pos, mat=invmat)
    if(show) 
      points(pos)
    # determine justification of legend relative to this point
    # to avoid crossing edges of plot
    xrel <- (pos$x - W$xrange[1])/diff(W$xrange)
    yrel <- (pos$y - W$yrange[1])/diff(W$yrange)
    xjust <- if(xrel < 0.1) 0 else if(xrel > 0.9) 1 else 0.5 
    yjust <- if(yrel < 0.1) 0 else if(yrel > 0.9) 1 else 0.5
    #
    out <- list(x=pos, xjust=xjust, yjust=yjust)
    return(out)
  }

  asma <- function(z) { if(is.owin(z)) as.mask(z) else
                        if(is.psp(z)) as.mask.psp(z) else NULL }
  
  callit <- function(...) {
    rslt <- try(thefunction(...))
    if(!inherits(rslt, "try-error"))
      return(rslt)
    return(list())
  }
  callit
})
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/plot.im.R"
#
#   plot.im.R
#
#  $Revision: 1.103 $   $Date: 2014/10/17 10:21:42 $
#
#  Plotting code for pixel images
#
#  plot.im
#  image.im
#  contour.im
#
###########################################################################

plot.im <- local({

  ## auxiliary functions

  image.doit <- function(imagedata, ...,
                         extrargs=graphicsPars("image"), W) {
    aarg <- resolve.defaults(...)
    add      <- resolve.1.default(list(add=FALSE),     aarg)
    show.all <- resolve.1.default(list(show.all=!add), aarg)
    if(add && show.all) {
      ## set up the window space *with* the main title
      ## using the same code as plot.owin, for consistency
      do.call.matched("plot.owin",
                      resolve.defaults(list(x=W, type="n"), aarg), 
                      extrargs=graphicsPars("owin"))
    }
    do.call.matched("image.default",
                    append(imagedata, aarg),
                    extrargs=extrargs)
  }

  clamp <- function(x, v, tol=0.02 * diff(v)) {
    ok <- (x >= v[1] - tol) & (x <= v[2] + tol)
    x[ok]
  }
  
  cellbreaks <- function(x, dx) {
    nx <- length(x)
    seq(x[1] - dx/2, x[nx] + dx/2, length.out=nx+1)
  }

  log10orNA <- function(x) {
    y <- rep(NA_real_, length(x))
    ok <- !is.na(x) & (x > 0)
    y[ok] <- log10(x[ok])
    return(y)
  }
  
  # main function
  PlotIm <- function(x, ...,
                     main, 
                     add=FALSE, clipwin=NULL,
                     col=NULL, valuesAreColours=NULL, log=FALSE,
                     ribbon=show.all, show.all=!add,
                     ribside=c("right", "left", "bottom", "top"),
                     ribsep=0.15, ribwid=0.05, ribn=1024,
                     ribscale=1, ribargs=list(), colargs=list(),
                     useRaster=NULL,
                     do.plot=TRUE) {
    if(missing(main)) main <- short.deparse(substitute(x))
    verifyclass(x, "im")
    ribside <- match.arg(ribside)
    col.given <- !is.null(col)
    dotargs <- list(...)

    stopifnot(is.list(ribargs))
    user.ticks <- ribargs$at
    
    if(!is.null(clipwin)) {
      x <- x[as.rectangle(clipwin)]
      if(!is.rectangle(clipwin)) x <- x[clipwin, drop=FALSE]
    }

    zlim <- dotargs$zlim

    x <- repair.image.xycoords(x)

    xtype <- x$type
    xbox <- as.rectangle(x)
    
    do.log <- identical(log, TRUE)
    if(do.log && !(x$type %in% c("real", "integer")))
      stop(paste("Log transform is undefined for an image of type",
                 sQuote(xtype)))

    # determine whether pixel values are to be treated as colours
    if(!is.null(valuesAreColours)) {
      # argument given - validate
      stopifnot(is.logical(valuesAreColours))
      if(valuesAreColours) {
        # pixel values must be factor or character
        if(!xtype %in% c("factor", "character")) {
          warning(paste("Pixel values of type", sQuote(xtype),
                        "are not interpretable as colours"))
          valuesAreColours <- FALSE
        } else if(col.given) {
          # colour info provided: contradictory
          warning(paste("Pixel values are taken to be colour values,",
                        "because valuesAreColours=TRUE;", 
                        "the colour map (argument col) is ignored"),
                  call.=FALSE)
          col <- NULL
        }
        if(do.log) 
          warning(paste("Pixel values are taken to be colour values,",
                        "because valuesAreColours=TRUE;", 
                        "the argument log=TRUE is ignored"),
                  call.=FALSE)
      }
    } else if(col.given) {
      # argument 'col' controls colours
      valuesAreColours <- FALSE
    } else if(spatstat.options("monochrome")) {
      valuesAreColours <- FALSE
    } else {
      ## default : determine whether pixel values are colours
      strings <- switch(xtype,
                        character = { as.vector(x$v) },
                        factor    = { levels(x) },
                        { NULL })
      valuesAreColours <- is.character(strings) && 
      !inherits(try(col2rgb(strings), silent=TRUE), "try-error")
      if(valuesAreColours)
        cat("Interpreting pixel values as colours\n")
    }
    # 
    if(valuesAreColours) {
      # colour-valued images are plotted using the code for factor images
      # with the colour map equal to the levels of the factor
      switch(xtype,
             factor = {
               col <- levels(x)
             },
             character = {
               x <- eval.im(factor(x))
               xtype <- "factor"
               col <- levels(x)
             },
             {
               warning(paste("Pixel values of type", sQuote(xtype),
                             "are not interpretable as colours"))
             })
      # colours not suitable for ribbon
      ribbon <- FALSE
    } 
    
    # transform pixel values to log scale?
    if(do.log) {
      rx <- range(x, finite=TRUE)
      if(all(rx > 0)) {
        x <- eval.im(log10(x))
      } else {
        if(any(rx < 0)) 
          warning(paste("Negative pixel values",
                        "omitted from logarithmic colour map;",
                        "range of values =", prange(rx)),
                  call.=FALSE)
        if(!all(rx < 0))
          warning("Zero pixel values omitted from logarithmic colour map",
                  call.=FALSE)
        x <- eval.im(log10orNA(x))
      } 
      xtype <- x$type
      Log <- log10
      Exp <- function(x) { 10^x }
    } else {
      Log <- Exp <- function(x) { x }
    }
    
    imagebreaks <- NULL
#    ribbonvalues <- ribbonbreaks <- NULL
    ribbonvalues <- NULL

    ## NOW DETERMINE THE COLOUR MAP
    colfun <- colmap <- NULL
    if(valuesAreColours) {
      ## pixel values are colours; set of colours was determined earlier
      colmap <- colourmap(col=col, inputs=col)
    } else if(!col.given) {
      ## no colour information given: use default
      colfun <- spatstat.options("image.colfun")
    } else if(inherits(col, "colourmap")) {
      ## Bob's your uncle
      colmap <- col
    } else if(is.function(col)) {
      ## Some kind of function determining a colour map
      if(names(formals(col))[1] == "n") {
        ## function(n) -> colour values
        colfun <- col
      } else {
        ## colour map determined by a rule (e.g. 'beachcolours')
        colmap <- invokeColourmapRule(col, x, zlim=zlim, colargs=colargs)
        if(is.null(colmap))
          stop("Unrecognised syntax for colour function")
      }
    }

    switch(xtype,
           real    = {
             vrange <- range(x, finite=TRUE)
             vrange <- range(zlim, vrange)
             if(!is.null(colmap)) {
               # explicit colour map
               s <- summary(colmap)
               if(s$discrete)
                 stop("Discrete colour map is not applicable to real values")
               imagebreaks <- s$breaks
               vrange <- range(imagebreaks)
               col <- s$outputs
             } 
             trivial <- (diff(vrange) <= .Machine$double.eps)
             if(!trivial) {
               # ribbonvalues: domain of colour map (pixel values)
               # ribbonrange: (min, max) of pixel values in image
               # nominalrange: range of values shown on ribbon 
               # nominalmarks: values shown on ribbon at tick marks
               # ribbonticks: pixel values of tick marks 
               # ribbonlabels: text displayed at tick marks
               ribbonvalues <- seq(from=vrange[1], to=vrange[2],
                                   length.out=ribn)
               ribbonrange <- vrange
               nominalrange <- Log(ribscale * Exp(ribbonrange))
               nominalmarks <-
                 user.ticks %orifnull% axisTicks(nominalrange, log=do.log)
               ribbonticks <- Log(nominalmarks/ribscale)
               ribbonlabels <- paste(nominalmarks)
             }
           },
           integer = {
             values <- as.vector(x$v)
             values <- values[!is.na(values)]
             uv <- unique(values)
             vrange <- range(uv, finite=TRUE)
             vrange <- range(zlim, vrange)
             nvalues <- length(uv)
             trivial <- (nvalues < 2)
             if(!trivial){
               nominalrange <- Log(ribscale * Exp(vrange))
               if(!is.null(user.ticks)) {
                 nominalmarks <- user.ticks
               } else {
                 nominalmarks <- axisTicks(nominalrange, log=do.log)
                 nominalmarks <- nominalmarks[nominalmarks %% 1 == 0]
               }
               ribbonticks <- Log(nominalmarks/ribscale)
               ribbonlabels <- paste(nominalmarks)
               if(!do.log && identical(all.equal(ribbonticks,
                                                 vrange[1]:vrange[2]), TRUE)) {
                 # each possible pixel value will appear in ribbon
                 ribbonvalues <- vrange[1]:vrange[2]
                 imagebreaks <- c(ribbonvalues - 0.5, vrange[2] + 0.5)
                 ribbonrange <- range(imagebreaks)
                 ribbonticks <- ribbonvalues
                 ribbonlabels <- paste(ribbonticks * ribscale)
               } else {
                 # not all possible values will appear in ribbon
                 ribn <- min(ribn, diff(vrange)+1)
                 ribbonvalues <- seq(from=vrange[1], to=vrange[2],
                                     length.out=ribn)
                 ribbonrange <- vrange
               }
             }
             if(!is.null(colmap)) {
               # explicit colour map
               s <- summary(colmap)
               imagebreaks <-
                 if(!s$discrete) s$breaks else
                 c(s$inputs[1] - 0.5, s$inputs + 0.5)
               col <- s$outputs
             }
           },
           logical = {
             values <- as.integer(as.vector(x$v))
             values <- values[!is.na(values)]
             uv <- unique(values)
             trivial <- (length(uv) < 2)
             vrange <- c(0,1)
             imagebreaks <- c(-0.5, 0.5, 1.5)
             ribbonvalues <- c(0,1)
             ribbonrange <- range(imagebreaks)
#             ribbonbreaks <- imagebreaks
             ribbonticks <- user.ticks %orifnull% ribbonvalues
             ribbonlabels <- c("FALSE", "TRUE")
             if(!is.null(colmap)) 
               col <- colmap(c(FALSE,TRUE))
           },
           factor  = {
             lev <- levels(x)
             nvalues <- length(lev)
             trivial <- (nvalues < 2)
             # ensure all factor levels plotted separately
             fac <- factor(lev, levels=lev)
             intlev <- as.integer(fac)
             imagebreaks <- c(intlev - 0.5, max(intlev) + 0.5)
             ribbonvalues <- intlev
             ribbonrange <- range(imagebreaks)
#             ribbonbreaks <- imagebreaks
             ribbonticks <- user.ticks %orifnull% ribbonvalues
             ribbonlabels <- paste(lev)
             vrange <- range(intlev)
             if(!is.null(colmap) && !valuesAreColours) 
               col <- colmap(fac)
           },
           character  = {
             x <- eval.im(factor(x))
             lev <- levels(x)
             nvalues <- length(lev)
             trivial <- (nvalues < 2)
             # ensure all factor levels plotted separately
             fac <- factor(lev, levels=lev)
             intlev <- as.integer(fac)
             imagebreaks <- c(intlev - 0.5, max(intlev) + 0.5)
             ribbonvalues <- intlev
             ribbonrange <- range(imagebreaks)
#             ribbonbreaks <- imagebreaks
             ribbonticks <- user.ticks %orifnull% ribbonvalues
             ribbonlabels <- paste(lev)
             vrange <- range(intlev)
             if(!is.null(colmap)) 
               col <- colmap(fac)
           },
           stop(paste("Do not know how to plot image of type", sQuote(xtype)))
           )
  
    ## Compute colour values to be passed to image.default
    if(!is.null(colmap)) {
      ## Explicit colour map object
      colourinfo <- list(breaks=imagebreaks, col=col)
    } else if(!is.null(colfun)) {
      ## Function colfun(n)
      colourinfo <- if(is.null(imagebreaks)) list(col=colfun(256)) else
                    list(breaks=imagebreaks, col=colfun(length(imagebreaks)-1))
    } else if(col.given) {
      ## Colour values
      if(inherits(try(col2rgb(col), silent=TRUE), "try-error"))
        stop("Unable to interpret argument col as colour values")
      if(is.null(imagebreaks)) {
        colourinfo <- list(col=col)
      } else {
        nintervals <- length(imagebreaks) - 1
        colourinfo <- list(breaks=imagebreaks, col=col)
        if(length(col) != nintervals)
          stop(paste("Length of argument", dQuote("col"),
                     paren(paste(length(col))),
                     "does not match the number of distinct values",
                     paren(paste(nintervals))))
      }
    } else stop("Internal error: unable to determine colour values")

    if(spatstat.options("monochrome")) {
      ## transform to grey scale
      colourinfo$col <- to.grey(colourinfo$col)
    }
    
    # colour map to be returned (invisibly)
    i.col <- colourinfo$col
    i.bks <- colourinfo$breaks
    output.colmap <-
      if(is.null(i.col)) NULL else
      if(inherits(i.col, "colourmap")) i.col else
      if(valuesAreColours) colourmap(col=i.col, inputs=i.col) else
      switch(xtype,
             integer=,
             real= {
               if(!is.null(i.bks)) {
                 colourmap(col=i.col, breaks=i.bks)
               } else colourmap(col=i.col, range=vrange)
             },
             logical={
               colourmap(col=i.col, inputs=c(FALSE,TRUE))
             },
             character=,
             factor={
               colourmap(col=i.col, inputs=lev)
             },
             NULL)

    ##  ........ decide whether to use rasterImage .........
    
    ## get device capabilities
    ##      (this will start a graphics device if none is active)
    rasterable <- dev.capabilities()$rasterImage
    if(is.null(rasterable)) rasterable <- "no"
    ##
    can.use.raster <-
      switch(rasterable,
             yes=TRUE,
             no=FALSE,
             "non-missing"=!any(is.na(x$v)),
             FALSE)
    if(is.null(useRaster)) {
      useRaster <- can.use.raster
    } else if(useRaster && !can.use.raster) {
        whinge <- "useRaster=TRUE is not supported by the graphics device"
        if(rasterable == "non-missing")
          whinge <- paste(whinge, "for images with NA values")
        warning(whinge, call.=FALSE)
    } 
    
    ## ........ start plotting .................

    if(!identical(ribbon, TRUE) || trivial) {
      ## no ribbon wanted

      attr(output.colmap, "bbox") <- as.rectangle(x)
      if(!do.plot)
        return(output.colmap)

      ## plot image without ribbon
      image.doit(imagedata=list(x=cellbreaks(x$xcol, x$xstep),
                                y=cellbreaks(x$yrow, x$ystep),
                                z=t(x$v)),
                 W=xbox,
                 dotargs,
                 list(useRaster=useRaster, add=add, show.all=show.all),
                 colourinfo,
                 list(xlab = "", ylab = ""),
                 list(asp = 1, main = main, axes=FALSE))
##      if(add && show.all)
##        fakemaintitle(x, main, dotargs)
      return(invisible(output.colmap))
    }
    
    # determine plot region
    bb <- owin(x$xrange, x$yrange)
    Width <- diff(bb$xrange)
    Height <- diff(bb$yrange)
    Size <- max(Width, Height)
    switch(ribside,
           right={
             # ribbon to right of image
             bb.rib <- owin(bb$xrange[2] + c(ribsep, ribsep+ribwid) * Size,
                            bb$yrange)
             rib.iside <- 4
           },
           left={
             # ribbon to left of image
             bb.rib <- owin(bb$xrange[1] - c(ribsep+ribwid, ribsep) * Size,
                            bb$yrange)
             rib.iside <- 2
           },
           top={
             # ribbon above image
             bb.rib <- owin(bb$xrange,
                            bb$yrange[2] + c(ribsep, ribsep+ribwid) * Size)
             rib.iside <- 3
           },
           bottom={
             # ribbon below image
             bb.rib <- owin(bb$xrange,
                            bb$yrange[1] - c(ribsep+ribwid, ribsep) * Size)
             rib.iside <- 1
           })
    bb.all <- boundingbox(bb.rib, bb)

    attr(output.colmap, "bbox") <- bb.all
    if(!do.plot)
      return(output.colmap)

    pt <- prepareTitle(main)
    
    if(!add) {
      ## establish coordinate system
      do.call.plotfun("plot.owin",
                      resolve.defaults(list(x=bb.all,
                                            type="n",
                                            main=pt$blank),
                                       dotargs),
                      extrargs=graphicsPars("owin"))
    }
    if(show.all) {
      ## plot title centred over main image area 'bb'
      do.call.plotfun("plot.owin",
                      resolve.defaults(list(x=bb,
                                            type="n",
                                            main=main,
                                            add=TRUE,
                                            show.all=TRUE),
                                       dotargs),
                      extrargs=graphicsPars("owin"))
      main <- ""
    }
    # plot image
    image.doit(imagedata=list(x=cellbreaks(x$xcol, x$xstep),
                              y=cellbreaks(x$yrow, x$ystep),
                              z=t(x$v)),
               W=xbox,
               list(add=TRUE, show.all=show.all),
               dotargs,
               list(useRaster=useRaster),
               colourinfo,
               list(xlab = "", ylab = ""),
               list(asp = 1, main = main))

##    if(add && show.all)
##      fakemaintitle(bb.all, main, ...)
    
    # axes for image
    imax <- identical(dotargs$axes, TRUE)
    imbox <- !identical(dotargs$box, FALSE)
    if(imbox)
      rect(x$xrange[1], x$yrange[1], x$xrange[2], x$yrange[2])
    if(imax) {
      px <- pretty(bb$xrange)
      py <- pretty(bb$yrange)
      do.call.plotfun("axis",
                      resolve.defaults(
                                       list(side=1, at=px), 
                                       dotargs,
                                       list(pos=bb$yrange[1])),
                      extrargs=graphicsPars("axis"))
      do.call.plotfun("axis",
                      resolve.defaults(
                                       list(side=2, at=py), 
                                       dotargs,
                                       list(pos=bb$xrange[1])),
                      extrargs=graphicsPars("axis"))
    }
    # plot ribbon image containing the range of image values
    rib.npixel <- length(ribbonvalues) + 1
    switch(ribside,
           left=,
           right={
             # vertical ribbon
             rib.xcoords <- bb.rib$xrange
             rib.ycoords <- seq(from=bb.rib$yrange[1],
                                to=bb.rib$yrange[2],
                                length.out=rib.npixel)
             rib.z <- matrix(ribbonvalues, ncol=1)
             rib.useRaster <- useRaster
           },
           top=,
           bottom={
             # horizontal ribbon
             rib.ycoords <- bb.rib$yrange
             rib.xcoords <- seq(from=bb.rib$xrange[1],
                                to=bb.rib$xrange[2],
                                length.out=rib.npixel)
             rib.z <- matrix(ribbonvalues, nrow=1)
             # bug workaround
             rib.useRaster <- FALSE 
           })
    image.doit(imagedata=list(x=rib.xcoords,
                              y=rib.ycoords,
                              z=t(rib.z)),
               W=bb.rib,
               list(add=TRUE,
                    show.all=show.all),
               ribargs,
               list(useRaster=rib.useRaster),
               list(main="", sub=""),
               dotargs,
               colourinfo)
    # box around ribbon?
    resol <- resolve.defaults(ribargs, dotargs)
    if(!identical(resol$box, FALSE))
      plot(as.owin(bb.rib), add=TRUE)
    # scale axis for ribbon image
    ribaxis <- !(identical(resol$axes, FALSE) || identical(resol$ann, FALSE))
    if(ribaxis) {
      axisargs <- list(side=rib.iside, labels=ribbonlabels)
      switch(ribside,
             right={
               scal <- diff(bb.rib$yrange)/diff(ribbonrange)
               at <- bb.rib$yrange[1] + scal * (ribbonticks - ribbonrange[1])
               axisargs <- append(axisargs, list(at=at))
               posargs <- list(pos=bb.rib$xrange[2],
                               yaxp=c(bb.rib$yrange, length(ribbonticks)))
             },
             left={
               scal <- diff(bb.rib$yrange)/diff(ribbonrange)
               at <- bb.rib$yrange[1] + scal * (ribbonticks - ribbonrange[1])
               axisargs <- append(axisargs, list(at=at))
               posargs <- list(pos=bb.rib$xrange[1],
                               yaxp=c(bb.rib$yrange, length(ribbonticks)))
             },
             top={
               scal <- diff(bb.rib$xrange)/diff(ribbonrange)
               at <- bb.rib$xrange[1] + scal * (ribbonticks - ribbonrange[1])
               axisargs <- append(axisargs, list(at=at))
               posargs <- list(pos=bb.rib$yrange[2],
                               xaxp=c(bb.rib$xrange, length(ribbonticks)))
             },
             bottom={
               scal <- diff(bb.rib$xrange)/diff(ribbonrange)
               at <- bb.rib$xrange[1] + scal * (ribbonticks - ribbonrange[1])
               axisargs <- append(axisargs, list(at=at))
               posargs <- list(pos=bb.rib$yrange[1],
                               xaxp=c(bb.rib$xrange, length(ribbonticks)))
             })
      do.call.plotfun("axis",
                      resolve.defaults(ribargs,
                                       axisargs, dotargs,
                                       posargs),
                      extrargs=graphicsPars("axis"))
    }
    #
    return(invisible(output.colmap))
  }

  PlotIm
})

invokeColourmapRule <- function(colfun, x, ..., zlim=NULL, colargs=list()) {
  ## utility for handling special functions that generate colour maps
  ## either 
  ##        function(... range) -> colourmap
  ##        function(... inputs) -> colourmap
  stopifnot(is.im(x))
  stopifnot(is.function(colfun))
  colargnames <- names(formals(colfun))
  ## Convert it to a 'colourmap'
  colmap <- NULL
  xtype <- x$type
  if(xtype %in% c("real", "integer") && "range" %in% colargnames) {
    ## function(range) -> colourmap
    vrange <- range(range(x, finite=TRUE), zlim)
    cvals <- try(do.call.matched(colfun,
                                 append(list(range=vrange), colargs)),
                 silent=TRUE)
    if(!inherits(cvals, "try-error")) {
      colmap <- if(inherits(cvals, "colourmap")) cvals else
      if(is.character(cvals)) colourmap(cvals, range=vrange) else NULL
    }
  } else if(xtype != "real" && "inputs" %in% colargnames) {
    ## function(inputs) -> colourmap
    vpossible <- switch(xtype,
                        logical = c(FALSE, TRUE),
                        factor = levels(x),
                        unique(as.matrix(x)))
    if(!is.null(vpossible) && length(vpossible) < 256) {
      cvals <- try(do.call.matched(colfun,
                                   append(list(inputs=vpossible),
                                          colargs)),
                   silent=TRUE)
      if(!inherits(cvals, "try-error")) {
        colmap <- if(inherits(cvals, "colourmap")) cvals else
        if(is.character(cvals))
          colourmap(cvals, inputs=vpossible) else NULL
      }
    }
  }
  return(colmap)
}

########################################################################

image.im <- plot.im

######################################################################

contour.im <- function (x, ..., main, axes=FALSE, add=FALSE,
                        clipwin=NULL, show.all=!add, do.plot=TRUE)
{
  defaultmain <- deparse(substitute(x))
  ## return value
  z <- as.rectangle(x)
  attr(z, "bbox") <- z
  if(!do.plot) return(z)
  ## 
  sop <- spatstat.options("par.contour")
  if(missing(main)) 
    main <- resolve.1.default(list(main=defaultmain), sop)
  if(missing(add)) {
    force(add) ## use default in formal arguments, unless overridden
    add <- resolve.1.default(list(add=add), sop)
  }
  if(missing(axes)) {
    force(axes)
    axes <- resolve.1.default(list(axes=axes), sop)
  }
  if(!is.null(clipwin))
    x <- x[clipwin, drop=FALSE]
  if(show.all) {
    if(axes) # with axes
      do.call.plotfun("plot.default",
                      resolve.defaults(
                                       list(x = range(x$xcol),
                                            y = range(x$yrow),
                                            type = "n", add=add),
                                       list(...),
                                       list(asp = 1, xlab = "x",
                                            ylab = "y", main = main)))
    else { # box without axes
      rec <- owin(x$xrange, x$yrange)
      do.call.matched("plot.owin",
                      resolve.defaults(list(x=rec, add=add, show.all=TRUE),
                                       list(...),
                                       list(main=main)))
    }
  }
  do.call.plotfun("contour.default",
                  resolve.defaults(list(x=x$xcol, y=x$yrow, z=t(x$v)),
                                   list(add=TRUE),
                                   list(...)))
  return(invisible(z))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/plot.mppm.R"
#
# plot.mppm.R
#
#   $Revision: 1.1 $  $Date: 2007/03/26 01:31:40 $
#
#

plot.mppm <- function(x, ..., trend=TRUE, cif=FALSE, how="image") {
  xname <- deparse(substitute(x))
  if(length(how) > 1)
    stop(paste("Multiple plotting styles cannot be selected;",
               "argument", dQuote("how"), "must have length 1"))
  if(!missing(trend) && missing(cif))
    cif <- !trend
  else if(missing(trend) && !missing(cif))
    trend <- !cif
  else if(trend + cif != 1)
    stop(paste("Exactly one of", dQuote("trend"), "and", dQuote("cif"),
               "should be TRUE"))
  subs <- subfits(x)
  arglist <- resolve.defaults(list(x=subs,how=how, trend=trend, cif=cif),
                              list(...),
                              list(main=xname))
  do.call("plot", arglist)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/plot.owin.R"
#
#	plot.owin.S
#
#	The 'plot' method for observation windows (class "owin")
#
#	$Revision: 1.53 $	$Date: 2014/10/24 00:22:30 $
#
#
#

plot.owin <- function(x, main, add=FALSE, ..., box, edge=0.04,
                      type = c("w", "n"), show.all=!add,
                      hatch=FALSE,
                      hatchargs=list(), 
                      invert=FALSE, do.plot=TRUE)
{
#
# Function plot.owin.  A method for plot.
#
  if(missing(main))
    main <- short.deparse(substitute(x))

  W <- x
  verifyclass(W, "owin")
  if(!do.plot) 
    return(invisible(as.rectangle(W)))
  
  type <- match.arg(type)

  if(missing(box) || is.null(box)) {
    box <- is.mask(W) && show.all
  } else stopifnot(is.logical(box) && length(box) == 1)

####
  pt <- prepareTitle(main)
  main <- pt$main
  nlines <- pt$nlines
#########        
  xlim <- xr <- W$xrange
  ylim <- yr <- W$yrange

####################################################

  ## graphics parameters that can be overridden by user
  gparam <- resolve.defaults(list(...), par())
  ## character expansion factors
  ##     main title size = 'cex.main' * par(cex.main) * par(cex)
  ## user's graphics expansion factor (*multiplies* par)
  cex.main.user <- resolve.1.default(list(cex.main=1), list(...))
  ## size of main title as multiple of par('cex')
  cex.main.rela <- cex.main.user * par('cex.main') 
  ## absolute size
  cex.main.absol <- cex.main.rela * par('cex')
    
  if(!add) {
    # new plot
    # allow space for main title
    if(nlines > 0) {
      guesslinespace <- 0.1 * diff(yr) * cex.main.absol
      added <- (nlines + 1) * guesslinespace
      ylim[2] <- ylim[2] + added
    }
    # set up plot with equal scales
    do.call.plotfun("plot.default",
                    resolve.defaults(list(x=numeric(0), y=numeric(0),
                                          type="n"),
                                     list(...),
                                     list(xlim=xlim, ylim=ylim,
                                          ann=FALSE, axes=FALSE,
                                          asp=1.0,
                                          xaxs="i", yaxs="i")))
  }
  if(show.all) {
    ## add title in a reasonable place!
    if(nlines > 0) {
      mainheight <- sum(strheight(main, units="user", cex=cex.main.rela))
      gapheight <- (strheight("b\nb", units="user", cex=cex.main.rela)
                    - 2 * strheight("b", units="user", cex=cex.main.rela))
      if(nlines > 1 && !is.expression(main))
        main <- paste(main, collapse="\n")
      text(x=mean(xr), y=yr[2] + mainheight + 0.5 * gapheight, labels=main,
           cex=cex.main.rela,
           col=gparam$col.main,
           font=gparam$font.main)
    }
  }
  
# Draw surrounding box
  if(box)
    do.call.plotfun("segments",
                    resolve.defaults(
                                     list(x0=xr[c(1,2,2,1)],
                                          y0=yr[c(1,1,2,2)],
                                          x1=xr[c(2,2,1,1)],
                                          y1=yr[c(1,2,2,1)]),
                                     list(...)))
  
# If type = "n", do not plot the window.
    if(type == "n")
      return(invisible(as.rectangle(W)))

  
# Draw window

  switch(W$type,
         rectangle = {
           Wpoly <- as.polygonal(W)
           po <- Wpoly$bdry[[1]]
           do.call.plotfun("polygon",
                           resolve.defaults(list(x=po),
                                            list(...)),
                           extrargs="lwd")
           if(hatch)
             do.call("add.texture", append(list(W=W), hatchargs))
         },
         polygonal = {
           p <- W$bdry
           # Determine whether user wants to fill the interior
           col.poly <- resolve.defaults(list(...), list(col=NA))$col
           den.poly <- resolve.defaults(list(...), list(density=NULL))$density
           no.fill  <- is.null(den.poly) &&
                       (is.null(col.poly) || is.na(col.poly))
           # Determine whether we need to triangulate the interior.
           # If it is required to fill the interior,
           # this can be done directly using polygon() provided
           # there are no holes. Otherwise we must triangulate the interior.
           if(no.fill)
             triangulate <- FALSE
           else {
             # Determine whether there are any holes
             holes <- unlist(lapply(p, is.hole.xypolygon))
             triangulate <- any(holes)
           }

           if(!triangulate) {
             # No triangulation required;
             # simply plot the polygons
             for(i in seq_along(p))
               do.call.plotfun("polygon",
                               resolve.defaults(
                                                list(x=p[[i]]),
                                                list(...)),
                               extrargs="lwd")
           } else {
              # Try using polypath():
             lucy <- names(dev.cur())
             if(!(lucy %in% c("xfig","pictex","X11"))) {
               xx <- unlist(lapply(p, function(a) {c(NA, a$x)}))[-1]
               yy <- unlist(lapply(p, function(a) {c(NA, a$y)}))[-1]
               do.call.plotfun("polypath",
                               resolve.defaults(list(x=xx,y=yy),
                                                list(border=col.poly),
                                                list(...)))
             } else {
               # decompose window into simply-connected pieces
               broken <- try(break.holes(W))
               if(inherits(broken, "try-error")) {
                 warning("Unable to plot filled polygons")
               } else {
                 # Fill pieces with colour (and draw border in same colour)
                 pp <- broken$bdry
                 for(i in seq_len(length(pp)))
                   do.call.plotfun("polygon",
                                   resolve.defaults(list(x=pp[[i]],
                                                         border=col.poly),
                                                    list(...)))
               }
             }
             # Now draw polygon boundaries
             for(i in seq_along(p))
               do.call.plotfun("polygon",
                               resolve.defaults(
                                                list(x=p[[i]]),
                                                list(density=0, col=NA),
                                                list(...)),
                               extrargs="lwd")
           }
           if(hatch)
             do.call("add.texture", append(list(W=W), hatchargs))
         },
         mask = {
           # capture 'col' argument and ensure it's at least 2 values
           coldefault <- c(par("bg"), par("fg"))
           col <- resolve.defaults(
                                   list(...),
                                   spatstat.options("par.binary"),
                                   list(col=coldefault)
                                   )$col
           if(length(col) == 1) {
             col <- unique(c(par("bg"), col))
             if(length(col) == 1) 
               col <- c(par("fg"), col)
           }
           ## invert colours?
           if(invert)
             col <- rev(col)
           ## convert to greyscale?
           if(spatstat.options("monochrome"))
             col <- to.grey(col)
           
           do.call.matched("image.default",
                           resolve.defaults(
                           list(x=W$xcol, y=W$yrow, z=t(W$m), add=TRUE),
                           list(col=col),       
                           list(...),
                           spatstat.options("par.binary"),
                           list(zlim=c(FALSE, TRUE))))
           if(hatch)
             do.call("add.texture", append(list(W=W), hatchargs))
         },
         stop(paste("Don't know how to plot window of type", sQuote(W$type)))
         )
  return(invisible(as.rectangle(W)))
}

break.holes <- local({

  insect <- function(A, Box) {
    ## efficient version of intersect.owin which doesn't 'fix' the polygons
    a <- lapply(A$bdry, reverse.xypolygon)
    b <- lapply(as.polygonal(Box)$bdry, reverse.xypolygon)
    ab <- polyclip::polyclip(a, b, "intersection",
                             fillA="nonzero", fillB="nonzero")
    if(length(ab)==0)
      return(emptywindow(Box))
    # ensure correct polarity
    totarea <- sum(unlist(lapply(ab, Area.xypolygon)))
    if(totarea < 0)
      ab <- lapply(ab, reverse.xypolygon)
    AB <- owin(Box$xrange, Box$yrange,
               poly=ab, check=FALSE, strict=FALSE, fix=FALSE,
               unitname=unitname(A))
    return(AB)
  }

  break.holes <- function(x, splitby=NULL, depth=0, maxdepth=100) {
    if(is.null(splitby)) {
      ## first call: validate x
      stopifnot(is.owin(x))
      splitby <- "x"
    }
    if(depth > maxdepth)
      stop("Unable to divide window into simply-connected pieces")
    p <- x$bdry
    holes <- unlist(lapply(p, is.hole.xypolygon))
    if(!any(holes)) return(x)
    nholes <- sum(holes)
    maxdepth <- max(maxdepth, 4 * nholes)
    i <- min(which(holes))
    p.i <- p[[i]]
    b <- as.rectangle(x)
    xr <- b$xrange
    yr <- b$yrange
    switch(splitby,
           x = {
             xsplit <- mean(range(p.i$x))
             left <- c(xr[1], xsplit)
             right <- c(xsplit, xr[2])
             xleft <- insect(x, owin(left, yr))
             xright <- insect(x, owin(right, yr))
             ## recurse
             xleft <- break.holes(xleft, splitby="y",
                                  depth=depth+1, maxdepth=maxdepth)
             xright <- break.holes(xright, splitby="y",
                                  depth=depth+1, maxdepth=maxdepth)
             ## recombine (without fusing polygons again!)
             result <- owin(xr, yr, poly=c(xleft$bdry, xright$bdry),
                            check=FALSE, strict=FALSE, fix=FALSE)
           },
           y = {
             ysplit <- mean(range(p.i$y))
             lower <- c(yr[1], ysplit)
             upper <- c(ysplit, yr[2])
             xlower <- insect(x, owin(xr, lower))
             xupper <- insect(x, owin(xr, upper))
             ## recurse
             xlower <- break.holes(xlower, splitby="x",
                                   depth=depth+1, maxdepth=maxdepth)
             xupper <- break.holes(xupper, splitby="x",
                                   depth=depth+1, maxdepth=maxdepth)
             ## recombine (without fusing polygons again!)
             result <- owin(xr, yr, poly=c(xlower$bdry, xupper$bdry),
                            check=FALSE, strict=FALSE, fix=FALSE)
           })
    return(result)
  }

  break.holes
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/plot.plotppm.R"
#
# plot.plotppm.R
#
# engine of plot method for ppm
#
# $Revision: 1.15 $  $Date: 2014/10/14 07:46:06 $
#
#

plot.plotppm <- function(x,data=NULL,trend=TRUE,cif=TRUE,se=TRUE,
                         pause=interactive(),
                         how=c("persp","image","contour"), ...,
                         pppargs=list())
{
  verifyclass(x,"plotppm")
  
  # determine main plotting actions
  superimposed <- !is.null(data)
  if(!missing(trend) && (trend & is.null(x[["trend"]])))
    stop("No trend to plot.\n")
  trend <- trend & !is.null(x[["trend"]])
  if(!missing(cif) && (cif & is.null(x[["cif"]])))
    stop("No cif to plot.\n")
  cif <- cif & !is.null(x[["cif"]])
  if(!missing(se) && (se & is.null(x[["se"]])))
    stop("No SE to plot.\n")
  se <- se & !is.null(x[["se"]])
  surftypes <- c("trend", "cif", "se")[c(trend, cif, se)]

  # marked point process?
  mrkvals <- attr(x,"mrkvals")
  marked <- (length(mrkvals) > 1)
  if(marked)
    data.marks <- marks(data)
  if(marked & superimposed) {
    data.types <- levels(data.marks)
    if(any(sort(data.types) != sort(mrkvals)))
      stop(paste("Data marks are different from mark",
                 "values for argument x.\n"))
  }

  # plotting style
  howmat <- outer(how, c("persp", "image", "contour"), "==")
  howmatch <- apply(howmat, 1, any)
  if (any(!howmatch)) 
    stop(paste("unrecognised option", how[!howmatch]))

  # start plotting
  if(pause)
    oldpar <- par(ask = TRUE)
  on.exit(if(pause) par(oldpar))

  
  for(ttt in surftypes) {
    xs <- x[[ttt]]
    for (i in seq_along(mrkvals)) {
      level <- mrkvals[i]
      main <- paste(if(ttt == "se") "Estimated" else "Fitted",
                    ttt, 
                    if(marked) paste("\n mark =", level) else NULL)
      for (style in how) {
        switch(style,
               persp = {
                 do.call("persp",
                         resolve.defaults(list(xs[[i]]),
                                          list(...), 
                                          spatstat.options("par.persp"),
                                          list(xlab="x", zlab=ttt, main=main)))
               },
               image = {
                 do.call("image",
                         resolve.defaults(list(xs[[i]]),
                                          list(...),
                                          list(main=main)))
                 if(superimposed) {
                   X <- if(marked) data[data.marks == level] else data
                   do.call(plot.ppp, append(list(x=X, add=TRUE), pppargs))
                 }
               },
               contour = {
                 do.call("contour",
                         resolve.defaults(list(xs[[i]]),
                                          list(...),
                                          list(main=main)))
                 if(superimposed) {
                   X <- if(marked) data[data.marks == level] else data
                   do.call(plot.ppp, append(list(x=X, add=TRUE), pppargs))
                 }
               },
               {
                 stop(paste("Unrecognised plot style", style))
               })
      }
    }
  }
  return(invisible())
}

print.plotppm <- function(x, ...) {
  verifyclass(x, "plotppm")
  trend   <- x$trend
  cif     <- x$cif
  mrkvals <- attr(x, "mrkvals")
  ntypes  <- length(mrkvals)
  unmarked <- (ntypes == 1 )
  cat(paste("Object of class", sQuote("plotppm"), "\n"))
  if(unmarked)
    cat("Computed for an unmarked point process\n")
  else {
    cat("Computed for a marked point process, with mark values:\n")
    print(mrkvals)
  }
  cat("Contains the following components:\n")
  if(!is.null(trend)) {
    cat("\n$trend:\tFitted trend.\n")
    if(unmarked) {
      cat("A list containing 1 image\n")
      print(trend[[1]], ...)
    } else {
      cat(paste("A list of", ntypes, "images\n"))
      cat("Typical details:\n")
      print(trend[[1]], ...)
    }
  }
  if(!is.null(cif)) {
    cat("\n$cif:\tFitted conditional intensity.\n")
    if(unmarked) {
      cat("A list containing 1 image\n")
      print(cif[[1]], ...)
    } else {
      cat(paste("A list of", ntypes, "images\n"))
      cat("Typical details:\n")
      print(cif[[1]], ...)
    }
  }
  invisible(NULL)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/plot.ppm.R"
#
#    plot.ppm.S
#
#    $Revision: 2.10 $    $Date: 2014/12/12 11:45:52 $
#
#    plot.ppm()
#         Plot a point process model fitted by ppm().
#        
#
#
plot.ppm <- function(x, ngrid = c(40,40),
		     superimpose = TRUE,
                     trend=TRUE, cif=TRUE, se=TRUE, 
                     pause = interactive(),
                     how=c("persp","image", "contour"),
                     plot.it=TRUE,
                     locations=NULL, covariates=NULL, ...)
{
  model <- x
#       Plot a point process model fitted by ppm().
#
  verifyclass(model, "ppm")
#
#       find out what kind of model it is
#
  mod <- summary(model)
  stationary <- mod$stationary
  poisson    <- mod$poisson
  marked     <- mod$marked
  multitype  <- mod$multitype
  data       <- mod$entries$data
        
  if(marked) {
    if(!multitype)
      stop("Not implemented for general marked point processes")
    else
      mrkvals <- levels(marks(data))
  } else mrkvals <- 1
#  ntypes <- length(mrkvals)
        
#
#        Interpret options
#        -----------------
#        
#        Whether to plot trend, cif, se
        
  if(!trend && !cif && !se) {
    cat(paste("Nothing plotted;", sQuote("trend"), ",", sQuote("cif"),
              "and", sQuote("se"), "are all FALSE\n"))
    return(invisible(NULL))
  }
#        Suppress uninteresting plots
#        unless explicitly instructed otherwise
  if(missing(trend))
    trend <- !stationary
  if(missing(cif))
    cif <- !poisson
  if(missing(se))
    se <- poisson && !stationary 
  else if(se && !poisson) {
      warning(paste("standard error calculation",
                  "is only implemented for Poisson models"))
      se <- FALSE
  }
  if(!trend && !cif && !se) {
    cat("Nothing plotted -- all plots selected are flat surfaces.\n")
    return(invisible(NULL))
  }
#
#  style of plot: suppress pseudo-default
#  
    if(missing(how))
      how <- "image"
#
#
#        Do the prediction
#        ------------------

  out <- list()
  surftypes <- c("trend","cif","se")[c(trend,cif,se)]
  ng <- if(missing(ngrid) && !missing(locations)) NULL else ngrid

  for (ttt in surftypes) {
    p <- predict(model,
                 ngrid=ng, locations=locations, covariates=covariates,
                 type = ttt,
                 getoutofjail=TRUE)  # permit outdated usage type="se"
    if(is.im(p))
      p <- list(p)
    out[[ttt]] <- p
  }

#        Make it a plotppm object
#        ------------------------  
  
  class(out) <- "plotppm"
  attr(out, "mrkvals") <- mrkvals

#        Actually plot it if required
#        ----------------------------  
  if(plot.it) {
    if(!superimpose)
      data <- NULL
    plot(out,data=data,trend=trend,cif=cif,se=se,how=how,pause=pause, ...)
  }

  
  return(invisible(out)) 
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/plot.ppp.R"
#
#	plot.ppp.R
#
#	$Revision: 1.78 $	$Date: 2014/11/10 11:16:58 $
#
#
#--------------------------------------------------------------------------

plot.ppp <- local({

  ## determine symbol map for marks of points
  default.symap.points <- function(x, ..., 
                                  chars=NULL, cols=NULL, 
                                  maxsize=NULL, meansize=NULL, markscale=NULL) {
    marx <- marks(x)
    if(is.null(marx)) {
      ## null or constant map
      return(symbolmap(..., chars=chars, cols=cols))
    }
    if(!is.null(dim(marx)))
      stop("Internal error: multivariate marks in default.symap.points")

    argnames <- names(list(...))
    shapegiven <- "shape" %in% argnames
    chargiven <- (!is.null(chars)) || ("pch" %in% argnames)
    assumecircles <- !(shapegiven || chargiven)
    sizegiven <- ("size" %in% argnames) ||
                 (("cex" %in% argnames) && !shapegiven)
    
    if(inherits(marx, c("Date", "POSIXt"))) {
      ## ......... marks are dates or date/times .....................
      timerange <- range(marx, na.rm=TRUE)
      shapedefault <- if(!assumecircles) list() else list(shape="circles")
      if(sizegiven) {
        g <- do.call("symbolmap",
          resolve.defaults(list(range=timerange),
                           list(...),
                           shapedefault,
                           list(chars=chars, cols=cols)))
        return(g)
      }
      ## attempt to determine a scale for the marks 
      y <- scaletointerval(marx, 0, 1, timerange)
      y <- y[is.finite(y)]
      if(length(y) == 0) return(symbolmap(..., chars=chars, cols=cols))
      scal <- mark.scale.default(y, as.owin(x), 
                                 markscale=markscale, maxsize=maxsize,
                                 meansize=meansize, 
                                 characters=chargiven)
      if(is.na(scal)) return(symbolmap(..., chars=chars, cols=cols))
      ## scale determined
      sizefun <- function(x, scal=1) {
        (scal/2) * scaletointerval(x, 0, 1, timerange)
      }
      formals(sizefun)[[2]] <- scal  ## ensures value of 'scal' is printed
      ##
      g <- do.call("symbolmap",
                   resolve.defaults(list(range=timerange),
                                    list(...),
                                    shapedefault,
                                    list(size=sizefun)))
      return(g)
    }
    if(is.numeric(marx)) {
      ## ............. marks are numeric values ...................
      marx <- marx[is.finite(marx)]
      if(length(marx) == 0)
        return(symbolmap(..., chars=chars, cols=cols))
      markrange <- range(marx)
      ## 
      if(sizegiven) {
        g <- do.call("symbolmap",
          resolve.defaults(list(range=markrange),
                           list(...),
                           if(assumecircles) list(shape="circles") else list(),
                           list(chars=chars, cols=cols)))
        return(g)
      }
      ## attempt to determine a scale for the marks 
      if(all(markrange == 0))
        return(symbolmap(..., chars=chars, cols=cols))
      scal <- mark.scale.default(marx, as.owin(x), 
                                 markscale=markscale, maxsize=maxsize,
                                 meansize=meansize,
                                 characters=chargiven)
      if(is.na(scal)) return(symbolmap(..., chars=chars, cols=cols))
      ## scale determined
      if(markrange[1] >= 0) {
        ## all marks are nonnegative
        shapedefault <-
          if(!assumecircles) list() else list(shape="circles")
        cexfun <- function(x, scal=1) { scal * x }
        circfun <- function(x, scal=1) { scal * x/2 }
        formals(cexfun)[[2]] <- formals(circfun)[[2]] <- scal
        sizedefault <-
          if(sizegiven) list() else
          if(chargiven) list(cex=cexfun) else list(size=circfun)
      } else {
        ## some marks are negative
        shapedefault <-
          if(!assumecircles) list() else
          list(shape=function(x) { ifelse(x >= 0, "circles", "squares") })
        cexfun <- function(x, scal=1) { scal * abs(x) }
        circfun <- function(x, scal=1) { scal * ifelse(x >= 0, x/2, -x) }
        formals(cexfun)[[2]] <- formals(circfun)[[2]] <- scal
        sizedefault <-
          if(sizegiven) list() else
          if(chargiven) list(cex=cexfun) else list(size=circfun)
      }
      g <- do.call("symbolmap",
                   resolve.defaults(list(range=markrange),
                                    list(...),
                                    shapedefault,
                                    sizedefault,
                                    chars=chars, cols=cols))
      return(g)
    }
    ##  ...........  non-numeric marks .........................
    um <- if(is.factor(marx)) levels(marx) else sort(unique(marx))
    ntypes <- length(um)
    ## resolve parameters 'chars' and 'cols'
    chars <- default.charmap(ntypes, chars)
    if(!is.null(cols))
      cols <- rep.int(cols, ntypes)[1:ntypes]
    g <- symbolmap(inputs=um, ..., chars=chars, cols=cols)
    return(g)
  }
                                  
  default.charmap <- function(n, ch=NULL) {
    if(!is.null(ch))
      return(rep.int(ch, n)[1:n])
    if(n <= 25)
      return(1:n)
    ltr <- c(letters, LETTERS)
    if(n <= 52)
      return(ltr[1:n])
    ## wrapped sequence of letters
    warning("Too many types to display every type as a different character")
    return(ltr[1 + (0:(n - 1) %% 52)])
  }

  ## main function
  plot.ppp <-
    function(x, main, ..., clipwin=NULL,
             chars=NULL, cols=NULL, use.marks=TRUE,
             which.marks=NULL, add=FALSE, type=c("p", "n"), 
             legend=TRUE, leg.side=c("left", "bottom", "top", "right"),
             leg.args=list(),
             symap=NULL, maxsize=NULL, meansize=NULL, markscale=NULL, zap=0.01, 
             show.window=show.all, show.all=!add, do.plot=TRUE,
             multiplot=TRUE)
{
  if(missing(main))
    main <- short.deparse(substitute(x))

  type <- match.arg(type)

  if(!missing(maxsize) || !missing(markscale) || !missing(meansize))
    warn.once("circlescale",
              "Interpretation of arguments maxsize and markscale",
              "has changed (in spatstat version 1.37-0 and later).",
              "Size of a circle is now measured by its diameter.")
  
  if(!is.null(clipwin))
    x <- x[clipwin]
  
  ## sensible default position
  legend <- legend && show.all
  if(legend) {
    leg.side <- match.arg(leg.side)
    vertical <- (leg.side %in% c("left", "right"))
  }
  
#  if(type == "n" || npoints(x) == 0) {
#    ## plot the window only
#    xwindow <- x$window
#    if(do.plot) 
#      do.call("plot.owin",
#              resolve.defaults(list(xwindow),
#                               list(...),
#                               list(main=main, invert=TRUE, add=add,
#                                    type=if(show.window) "w" else "n")))
#    if(is.null(symap)) symap <- symbolmap()
#    attr(symap, "bbox") <- as.rectangle(xwindow)
#    return(invisible(symap))
#  }

  ## ................................................................
  ## Handle multiple columns of marks as separate plots
  ##  (unless add=TRUE or which.marks selects a single column
  ##   or multipage = FALSE)
  if(use.marks && is.data.frame(mx <- marks(x))) {
    implied.all <- is.null(which.marks)
    want.several <- implied.all || is.data.frame(mx <- mx[,which.marks])
    do.several <- want.several && !add && multiplot
    if(do.several) {
      ## generate one plot for each column of marks
      y <- as.listof(lapply(mx, function(z, P) setmarks(P,z), P=x))
      out <- do.call("plot",
                     resolve.defaults(list(x=y, main=main,
                                           show.window=show.window,
                                           do.plot=do.plot,
                                           type=type),
                                      list(...),
                                      list(equal.scales=TRUE), 
                                      list(legend=legend,
                                           leg.side=leg.side,
                                           leg.args=leg.args),
                                      list(chars=chars, cols=cols,
                                           maxsize=maxsize,
                                           meansize=meansize,
                                           markscale=markscale,
                                           zap=zap)))
      return(invisible(out))
    } 
    if(is.null(which.marks)) {
      which.marks <- 1
      if(do.plot) message("Plotting the first column of marks")
    }
  }
  
  ## ............... unmarked, or single column of marks ....................

  ## Determine symbol map and mark values to be used
  y <- x
  if(!is.marked(x, na.action="ignore") || !use.marks) {
    ## Marks are not mapped.
    marx <- NULL
    if(is.null(symap)) symap <- symbolmap(..., chars=chars, cols=cols)
  } else {
    ## Marked point pattern
    marx <- marks(y, dfok=TRUE)
    if(is.data.frame(marx)) {
      ## select column or take first colum
      marx <- marx[, which.marks]
      y <- setmarks(y, marx)
    }
    if(npoints(y) > 0) {
      ok <- complete.cases(as.data.frame(y))
      if(!any(ok)) {
        warning("All mark values are NA; plotting locations only.")
        if(is.null(symap)) symap <- symbolmap()
      } else if(any(!ok)) {
        warning(paste("Some marks are NA;",
                      "corresponding points are omitted."))
        x <- x[ok]
        y <- y[ok]
        marx <- marks(y)
      }
    }
    ## apply default symbol map
    if(is.null(symap))
      symap <- default.symap.points(y, chars=chars, cols=cols, 
                                    maxsize=maxsize, meansize=meansize,
                                    markscale=markscale,
                                    ...)
  }
#  gtype <- symbolmaptype(symap)

  ## Determine bounding box for main plot
  BB <- as.rectangle(x)
  sick <- inherits(x, "ppp") && !is.null(rejects <- attr(x, "rejects"))
  if(sick) {
    ## Get relevant parameters
    par.direct <- list(main=main, use.marks=use.marks,
                   maxsize=maxsize, meansize=meansize, markscale=markscale)
    par.rejects <- resolve.1.default(list(par.rejects=list(pch="+")),
                                     list(...))
    par.all <- resolve.defaults(par.rejects, par.direct)
    rw <- resolve.defaults(list(...), list(rejectwindow=NULL))$rejectwindow
    ## determine window for rejects
    rwin <-
      if(is.null(rw))
        rejects$window
      else if(is.logical(rw) && rw)
        rejects$window
      else if(inherits(rw, "owin"))
        rw
      else if(is.character(rw)) {
        switch(rw,
               box={boundingbox(rejects, x)},
               ripras={ripras(c(rejects$x, x$x), c(rejects$y, x$y))},
               stop(paste("Unrecognised option: rejectwindow=", rw)))
      } else stop("Unrecognised format for rejectwindow")
    if(is.null(rwin))
      stop("Selected window for rejects pattern is NULL")
    BB <- boundingbox(BB, as.rectangle(rwin))
  }

  ## Augment bounding box with space for legend, if appropriate
  legend <- legend && (symbolmaptype(symap) != "constant") 
  if(legend) {
    ## guess maximum size of symbols
    maxsize <- invoke.symbolmap(symap, marx,
                                corners(as.rectangle(x)),
                                add=add, do.plot=FALSE)
    sizeguess <- if(maxsize <= 0) NULL else (1.5 * maxsize)
    leg.args <- append(list(side=leg.side, vertical=vertical), leg.args)
    ## draw up layout
    legbox <- do.call.matched(plan.legend.layout,
                              append(list(B=BB, size = sizeguess,
                                          started=FALSE, map=symap),
                                     leg.args))
    ## bounding box for everything
    BB <- legbox$A
  }

  ## return now if not plotting
  attr(symap, "bbox") <- BB
  if(!do.plot)
    return(invisible(symap))
    
  ## ............. start plotting .......................
  pt <- prepareTitle(main)
  main <- pt$main
  nlines <- pt$nlines
  blankmain <- if(nlines == 0) "" else rep("  ", nlines)
  cex.main <- resolve.1.default(list(cex.main=1), list(...))
  plot(BB, type="n", add=add, main=blankmain, show.all=show.all,
       cex.main=cex.main)

  if(sick) {
    if(show.window) {
      ## plot windows
      if(!is.null(rw)) {
        ## plot window for rejects
        rwinpardefault <- list(lty=2,lwd=1,border=1)
        rwinpars <-
          resolve.defaults(par.rejects, rwinpardefault)[names(rwinpardefault)]
        do.call("plot.owin", append(list(rwin, add=TRUE), rwinpars))
      }
      ## plot window of main pattern
      do.call("plot.owin",
              resolve.defaults(list(x$window, add=TRUE),
                               list(...),
                               list(invert=TRUE)))
    }
    if(type != "n") {
      ## plot reject points
      do.call("plot.ppp", append(list(rejects, add=TRUE), par.all))
      warning(paste(rejects$n, "illegal points also plotted"))
    }
    ## the rest is added
    add <- TRUE
  }

  ## Now convert to bona fide point pattern
  x <- as.ppp(x)
  xwindow <- x$window

  ## Plot observation window (or at least the main title)
  do.call("plot.owin",
          resolve.defaults(list(x=xwindow,
                                add=TRUE,
                                main=main,
                                type=if(show.window) "w" else "n",
                                show.all=show.all),
                           list(...),
                           list(invert=TRUE)))
  # else if(show.all) fakemaintitle(as.rectangle(xwindow), main, ...)

  if(type != "n") {
    ## plot symbols ##
    invoke.symbolmap(symap, marx, x, add=TRUE)
  }
  
  ## add legend
  if(legend) {
    b <- legbox$b
    legendmap <- if(length(leg.args) == 0) symap else 
                 do.call("update", append(list(object=symap), leg.args))
    do.call("plot",
            append(list(x=legendmap, main="", add=TRUE,
                        xlim=b$xrange, ylim=b$yrange),
                   leg.args))
  }
  
  return(invisible(symap))
}

plot.ppp

})


mark.scale.default <- function(marx, w, markscale=NULL,
                               maxsize=NULL, meansize=NULL,
                               characters=FALSE) {
  ## establish values of markscale, maxsize, meansize
  ngiven <- (!is.null(markscale)) +
            (!is.null(maxsize)) +
            (!is.null(meansize))
  if(ngiven > 1)
     stop("Only one of the arguments markscale, maxsize, meansize",
          " should be given", call.=FALSE)
  if(ngiven == 0) {
    ## if ALL are absent, enforce the spatstat defaults
    ## (which could also be null)
    pop <- spatstat.options("par.points")
    markscale <- pop$markscale
    maxsize   <- pop$maxsize
    meansize <- pop$meansize
  }
  ## Now check whether markscale is fixed
  if(!is.null(markscale)) {
    stopifnot(markscale > 0)
    return(markscale)
  }
  # Usual case: markscale is to be determined from maximum/mean physical size
  if(is.null(maxsize) && is.null(meansize)) {
    ## compute default value of 'maxsize'
    ## guess appropriate max physical size of symbols
    bb <- as.rectangle(w)
    maxsize <- 1.4/sqrt(pi * length(marx)/area(bb))
    maxsize <- min(maxsize, diameter(bb) * 0.07)
    ## updated: maxsize now represents *diameter*
    maxsize <- 2 * maxsize
  } else {
    if(!is.null(maxsize)) stopifnot(maxsize > 0) else stopifnot(meansize > 0)
  }
  
  # Examine mark values
  absmarx <- abs(marx)
  maxabs <- max(absmarx)
  tiny <- (maxabs < 4 * .Machine$double.eps)
  if(tiny)
    return(NA)

  ## finally determine physical scale for symbols
  if(!is.null(maxsize)) {
    scal <- maxsize/maxabs
  } else {
    meanabs <- mean(absmarx)
    scal <- meansize/meanabs
  }
  if(!characters) return(scal)

  ## if using characters ('pch') we need to
  ## convert physical sizes to 'cex' values
  charsize <- max(sidelengths(as.rectangle(w)))/40
  return(scal/charsize)
}

fakemaintitle <- function(bb, main, ...) {
  ## Try to imitate effect of 'title(main=main)' above a specified box
  if(!any(nzchar(main))) return(invisible(NULL))
  bb <- as.rectangle(bb)
  x0 <- mean(bb$xrange)
  y0 <- bb$yrange[2] + length(main) * diff(bb$yrange)/12
  parnames <- c('cex.main', 'col.main', 'font.main')
  parlist <- par(parnames)
  parlist <- resolve.defaults(list(...), parlist)[parnames]
  names(parlist) <- c('cex', 'col', 'font')
  do.call.matched("text.default",
                  resolve.defaults(list(x=x0, y=y0, labels=main),
                                   parlist,    list(...)))
  return(invisible(NULL))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pointsonlines.R"
#
#   pointsonlines.R
#
# place points at regular intervals along line segments
#
#   $Revision: 1.7 $  $Date: 2014/11/10 11:21:02 $
#

pointsOnLines <- function(X, eps=NULL, np=1000, shortok=TRUE) {
  stopifnot(is.psp(X))
  len <- lengths.psp(X)
  nseg <- length(len)
  if(is.null(eps)) {
    stopifnot(is.numeric(np) && length(np) == 1)
    stopifnot(is.finite(np) && np > 0)
    eps <- sum(len)/np
  } else {
    stopifnot(is.numeric(eps) && length(eps) == 1)
    stopifnot(is.finite(eps) && eps > 0)
  }
  # initialise
  Xdf    <- as.data.frame(X)
  xmid <- with(Xdf, (x0+x1)/2)
  ymid <- with(Xdf, (y0+y1)/2)
  # handle very short segments
#  allsegs <- 1:nseg
  if(any(short <- (len <= eps)) && shortok) {
    # very short segments: use midpoints
    Z <- data.frame(x = xmid[short], y = ymid[short])
  } else Z <- data.frame(x=numeric(0), y=numeric(0))
  # handle other segments
  for(i in (1:nseg)[!short]) {
    # divide segment into pieces of length eps
    # with shorter bits at each end
    leni <- len[i]
    nwhole <- floor(leni/eps)
    if(leni/eps - nwhole < 0.5 && nwhole > 2)
      nwhole <- nwhole - 1
    rump <- (leni - nwhole * eps)/2
    brks <- c(0, rump + (0:nwhole) * eps, leni)
    nbrks <- length(brks)
    # points at middle of each piece
    ss <- (brks[-1] + brks[-nbrks])/2
    x <- with(Xdf, x0[i] + (ss/leni) * (x1[i]-x0[i]))
    y <- with(Xdf, y0[i] + (ss/leni) * (y1[i]-y0[i]))
    Z <- rbind(Z, data.frame(x=x, y=y))
  }
  Z <- as.ppp(Z, W=X$window)
  return(Z)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/poisson.R"
#
#
#    poisson.S
#
#    $Revision: 1.7 $	$Date: 2012/01/16 08:26:08 $
#
#    The Poisson process
#
#    Poisson()    create an object of class 'interact' describing
#                 the (null) interpoint interaction structure
#                 of the Poisson process.
#	
#
# -------------------------------------------------------------------
#	

Poisson <- local({

  BlankPoisson <- list(
    name     = "Poisson process",
    creator  = "Poisson",
    family   = NULL,
    pot      = NULL,
    par      = NULL,
    parnames = NULL,
    init     = function(...) { },
    update   = function(...) { },
    print    = function(self) {
      cat("Poisson process\n")
      invisible()
    },
    valid = function(...) { TRUE },
    project = function(...) NULL, 
    irange = function(...) { 0 },
    version=NULL
    )
  
  class(BlankPoisson) <- "interact"

  Poisson <- function() { BlankPoisson }

  Poisson <- intermaker(Poisson, BlankPoisson)

  Poisson
})
                 
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pp3.R"
#
#   pp3.R
#
#  class of three-dimensional point patterns in rectangular boxes
#
#  $Revision: 1.15 $  $Date: 2014/10/24 00:22:30 $
#

box3 <- function(xrange=c(0,1), yrange=xrange, zrange=yrange, unitname=NULL) {
  stopifnot(is.numeric(xrange) && length(xrange) == 2 && diff(xrange) > 0)
  stopifnot(is.numeric(yrange) && length(yrange) == 2 && diff(yrange) > 0)
  stopifnot(is.numeric(zrange) && length(zrange) == 2 && diff(zrange) > 0)
  out <- list(xrange=xrange, yrange=yrange, zrange=zrange,
              units=as.units(unitname))
  class(out) <- "box3"
  return(out)
}

as.box3 <- function(...) {
  a <- list(...)
  n <- length(a)
  if(n == 0)
    stop("No arguments given")
  if(n == 1) {
    a <- a[[1]]
    if(inherits(a, "box3"))
      return(a)
    if(inherits(a, "pp3"))
      return(a$domain)
    if(inherits(a, "boxx")){
      if(ncol(a$ranges)==3)
        return(box3(a$ranges[,1], a$ranges[,2], a$ranges[,3]))
      stop("Supplied boxx object does not have dimension three")
    }
    if(inherits(a, "ppx"))
      return(as.box3(a$domain))
    if(is.numeric(a)) {
      if(length(a) == 6)
        return(box3(a[1:2], a[3:4], a[5:6]))
      stop(paste("Don't know how to interpret", length(a), "numbers as a box"))
    }
    if(!is.list(a))
      stop("Don't know how to interpret data as a box")
  }
  return(do.call("box3", a))
}

print.box3 <- function(x, ...) {
  bracket <- function(z) paste("[",
                               paste(signif(z, 5), collapse=", "),
                               "]", sep="")
  v <- paste(unlist(lapply(x[1:3], bracket)), collapse=" x ")
  s <- summary(unitname(x))
  cat(paste("Box:", v, s$plural, s$explain, "\n"))
  invisible(NULL)
}

unitname.box3 <- function(x) { x$units }

"unitname<-.box3" <- function(x, value) {
  x$units <- as.units(value)
  return(x)
}

eroded.volumes <- function(x, r) { UseMethod("eroded.volumes") }

eroded.volumes.box3 <- function(x, r) {
  b <- as.box3(x)
  ax <- pmax.int(0, diff(b$xrange) - 2 * r)
  ay <- pmax.int(0, diff(b$yrange) - 2 * r)
  az <- pmax.int(0, diff(b$zrange) - 2 * r)
  ax * ay * az
}

shortside <- function(x) { UseMethod("shortside") }

shortside.box3 <- function(x) {
  min(sidelengths(x))
}

sidelengths <- function(x) { UseMethod("sidelengths") }

sidelengths.box3 <- function(x) {
  with(x, c(diff(xrange), diff(yrange), diff(zrange)))
}

bounding.box3 <- function(...) {
  wins <- list(...)
  boxes <- lapply(wins, as.box3)
  xr <- range(unlist(lapply(boxes, getElement, name="xrange")))
  yr <- range(unlist(lapply(boxes, getElement, name="yrange")))
  zr <- range(unlist(lapply(boxes, getElement, name="zrange")))
  box3(xr, yr, zr)
}

pp3 <- function(x, y, z, ...) {
  stopifnot(is.numeric(x))
  stopifnot(is.numeric(y))
  stopifnot(is.numeric(z)) 
  b <- as.box3(...)
  out <- ppx(data=data.frame(x=x,y=y,z=z), domain=b)
  class(out) <- c("pp3", class(out))
  return(out)
}

domain.pp3 <- function(X, ...) { X$domain }

is.pp3 <- function(x) { inherits(x, "pp3") }

npoints.pp3 <- function(x) { nrow(x$data) }

print.pp3 <- function(x, ...) {
  cat("Three-dimensional point pattern\n")
  sd <- summary(x$data)
  np <- sd$ncases
  cat(paste(np, ngettext(np, "point", "points"), "\n"))
  print(x$domain)
  invisible(NULL)
}

summary.pp3 <- function(object, ...) {
  sd <- summary(object$data)
  np <- sd$ncases
  dom <- object$domain
  v <- volume.box3(dom)
  u <- summary(unitname(dom))
  intens <- np/v
  out <-  list(np=np, sumdat=sd, dom=dom, v=v, u=u, intensity=intens)
  class(out) <- "summary.pp3"
  return(out)
}

print.summary.pp3 <- function(x, ...) {
  cat("Three-dimensional point pattern\n")
  cat(paste(x$np, ngettext(x$np, "point", "points"), "\n"))
  print(x$dom)
  u <- x$u
  v <- x$v
  cat(paste("Volume", v, "cubic",
            if(v == 1) u$singular else u$plural,
            u$explain, "\n"))
  cat(paste("Average intensity", x$intensity,
            "points per cubic", u$singular, u$explain,
            "\n"))
  invisible(NULL)
}

plot.pp3 <- function(x, ...) {
  xname <- short.deparse(substitute(x))
  if(!require("scatterplot3d"))
    stop("Package scatterplot3d is needed to plot 3D point patterns\n")
  coo <- coords(x)
  cnam <- names(coo)
  do.call("scatterplot3d",
          resolve.defaults(list(x=coo[,1],
                                y=coo[,2],
                                z=coo[,3]),
                           list(...),
                           list(main=xname),
                           list(xlab=cnam[1],
                                ylab=cnam[2],
                                zlab=cnam[3]),
                           list(xlim=x$domain$xrange,
                                ylim=x$domain$yrange,
                                zlim=x$domain$zrange)))
}

"[.pp3" <- function(x, i, ...) {
  answer <- NextMethod("[")
  if(is.ppx(answer))
    class(answer) <- c("pp3", class(answer))
  return(answer)
}
  
unitname.pp3 <- function(x) { unitname(x$domain) }

"unitname<-.pp3" <- function(x, value) {
  d <- x$domain
  unitname(d) <- value
  x$domain <- d
  return(x)
}

diameter.box3 <- function(x) {
  stopifnot(inherits(x, "box3"))
  with(x, sqrt(diff(xrange)^2+diff(yrange)^2+diff(zrange)^2))
}

volume <- function(x) { UseMethod("volume") }

volume.box3 <- function(x) {
  stopifnot(inherits(x, "box3"))
  with(x, prod(diff(xrange), diff(yrange), diff(zrange)))
}

runifpoint3 <- function(n, domain=box3(), nsim=1) {
  if(nsim > 1) {
    result <- vector(mode="list", length=nsim)
    for(i in 1:n) result[[i]] <- runifpoint3(n, domain)
    result <- as.solist(result)
    names(result) <- paste("Simulation", 1:n)
    return(result)
  }
  domain <- as.box3(domain)
  x <- with(domain, runif(n, min=xrange[1], max=xrange[2]))
  y <- with(domain, runif(n, min=yrange[1], max=yrange[2]))
  z <- with(domain, runif(n, min=zrange[1], max=zrange[2]))
  pp3(x,y,z,domain)
}

rpoispp3 <- function(lambda, domain=box3(), nsim=1) {
  if(nsim > 1) {
    result <- vector(mode="list", length=nsim)
    for(i in 1:n) result[[i]] <- rpoispp3(n, domain)
    result <- as.solist(result)
    names(result) <- paste("Simulation", 1:n)
    return(result)
  }
  domain <- as.box3(domain)
  v <- volume.box3(domain)
  if(!(is.numeric(lambda) && length(lambda) == 1))
    stop("lambda must be a single numeric value")
  n <- rpois(1, lambda * v)
  runifpoint3(n, domain=domain)
}



#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/ppm.R"
#
#	$Revision: 1.49 $	$Date: 2014/11/10 11:27:55 $
#
#    ppm()
#          Fit a point process model to a two-dimensional point pattern
#
#

ppm <- function(Q, ...) {
  UseMethod("ppm")
}


ppm.formula <- function(Q, interaction=NULL, ..., data=NULL, subset) {
  ## remember call
  callstring <- short.deparse(sys.call())
  cl <- match.call()

  ########### INTERPRET FORMULA ##############################
  
  if(!inherits(Q, "formula"))
    stop(paste("Argument 'Q' should be a formula"))
  formula <- Q
  
  ## check formula has LHS and RHS. Extract them
  if(length(formula) < 3)
    stop(paste("Formula must have a left hand side"))
  Yexpr <- formula[[2]]
  trend <- formula[c(1,3)]
  
  ## FIT #######################################
  thecall <- if(missing(subset)) {
    call("ppm", Q=Yexpr, trend=trend, data=data, interaction=interaction)
  } else {
    call("ppm", Q=Yexpr, trend=trend, data=data, interaction=interaction,
         subset=substitute(subset))
  }
  ncall <- length(thecall)
  argh <- list(...)
  nargh <- length(argh)
  if(nargh > 0) {
    thecall[ncall + 1:nargh] <- argh
    names(thecall)[ncall + 1:nargh] <- names(argh)
  }
  callenv <- parent.frame()
  if(!is.null(data)) callenv <- list2env(data, parent=callenv)
  result <- eval(thecall, envir=callenv)

  result$call <- cl
  result$callstring <- callstring
  result$callframe <- parent.frame()
  
  return(result)
}


ppm.quad <- ppm.ppp <- ppm.default <- 
function(Q,
         trend = ~1,
	 interaction = Poisson(),
         ..., 
         covariates = data,
         data = NULL,
         covfunargs = list(),
         subset,
	 correction="border",
	 rbord = reach(interaction),
         use.gam=FALSE,
         method = "mpl",
         forcefit=FALSE,
         project=FALSE,
         nd = NULL,
         eps = NULL,
         gcontrol=list(),
         nsim=100,
         nrmh=1e5,
         start=NULL,
         control=list(nrep=nrmh),
         verb=TRUE,
         callstring=NULL
) {
  Qname <- short.deparse(substitute(Q))

  subsetexpr <- if(!missing(subset)) substitute(subset) else NULL

  if(!(method %in% c("mpl", "ho", "logi")))
    stop(paste("Unrecognised fitting method", sQuote(method)))
  if(inherits(Q, "logiquad")){
    if(missing(method))
      method <- "logi"
    if(method != "logi")
      stop(paste("Only method =", sQuote("logi"),
                 "makes sense when Q is of type", sQuote("logiquad")))
  }
  cl <- match.call()
  if(is.null(callstring)) 
    callstring <- paste(short.deparse(sys.call()), collapse="")

  if(is.ppp(Q) && is.marked(Q) && !is.multitype(Q)) 
    stop(paste("ppm is not yet implemented for marked point patterns,",
               "other than multitype patterns."))
  if(!(is.ppp(Q) ||
       inherits(Q, "quad") ||
       checkfields(Q, c("data", "dummy")))) {
    stop("Argument Q must be a point pattern or a quadrature scheme")
  }
  X <- if(is.ppp(Q)) Q else Q$data

  ## Ensure interaction is fully defined  
  if(is.null(interaction)) 
    interaction <- Poisson()
  if(!is.null(ss <- interaction$selfstart)) {
    # invoke selfstart mechanism to fix all parameters
    interaction <- ss(X, interaction)
  }

  if(inherits(trend, "formula")) {
    ## handle "." in formula, representing all variables in 'data'
    if("." %in% variablesinformula(trend)) {
      if(is.null(covariates))
        stop("Cannot expand '.' since 'data' is not present", call.=FALSE)
      rhs <- paste(names(covariates), collapse=" + ")
      allmaineffects <- as.formula(paste("~", rhs))
      environment(allmaineffects) <- environment(trend)
      trend <- update(allmaineffects, trend)
    }
    ## expand polynom() in formula
    if(spatstat.options("expand.polynom"))
      trend <- expand.polynom(trend)
  }
  
  # validate choice of edge correction
  correction <- pickoption("correction", correction,
                           c(border="border",
                             periodic="periodic",
                             isotropic="isotropic",
                             Ripley="isotropic",
                             trans="translate",
                             translate="translate",
                             translation="translate",
                             none="none"))
  
  # validate rbord 
  if(correction == "border") {
    # rbord for border correction
    rbord.given <- !missing(rbord) && !is.null(rbord)
    if(is.null(rbord))
      rbord <- reach(interaction)
    infin <- is.infinite(rbord)
    too.large <- infin || (eroded.areas(as.owin(X), rbord) == 0)
    if(too.large) {
      whinge <-
        paste(if(rbord.given) "rbord" else "the reach of this interaction",
              if(infin) "is infinite or unknown;"
              else "is too large for this window;",
              "please specify",
              if(rbord.given) "a smaller value of",
              "rbord, or use a different edge correction")
      stop(whinge)
    }
  } else {
    # rbord must be numeric to satisfy mpl.engine
    if(is.null(rbord))
      rbord <- 0
  }

  if(method == "logi") {
    fitLOGI <- logi.engine(Q=Q, trend=trend,
                           interaction=interaction,
                           covariates=covariates,
                           covfunargs=covfunargs,
                           subsetexpr=subsetexpr,
                           correction=correction,
                           rbord=rbord,
                           use.gam=use.gam,
                           forcefit=forcefit,
                           nd = nd,
                           gcontrol=gcontrol,
                           callstring=callstring,
                           ...)
    fitLOGI$Qname <- Qname
    fitLOGI$call <- cl
    fitLOGI$callstring <- callstring
    fitLOGI$callframe <- parent.frame()
    if(project && !valid.ppm(fitLOGI))
      fitLOGI <- project.ppm(fitLOGI)
    return(fitLOGI)
  }
  
  # fit by maximum pseudolikelihood
  fitMPL <- mpl.engine(Q=Q, trend=trend,
                       interaction=interaction,
                       covariates=covariates,
                       covfunargs=covfunargs,
                       subsetexpr=subsetexpr,
                       correction=correction,
                       rbord=rbord,
                       use.gam=use.gam,
                       forcefit=forcefit,
                       nd = nd,
                       eps = eps, 
                       gcontrol=gcontrol,
                       callstring=callstring,
                       ...)
  fitMPL$Qname <- Qname

  if(!is.ppm(fitMPL)) {
    # internal use only - returns some other data
    return(fitMPL)
  }
  
  fitMPL$call <- cl
  fitMPL$callstring <- callstring
  fitMPL$callframe <- parent.frame()

  if(project && !valid.ppm(fitMPL))
    fitMPL <- project.ppm(fitMPL)
  
  if(method == "mpl" || is.poisson.ppm(fitMPL))
    return(fitMPL)

  fitHO <- ho.engine(fitMPL, nsim=nsim, nrmh=nrmh, start=start,
                     control=control, verb=verb)

  if(is.null(fitHO))
    return(fitMPL)
  
  if(project && !valid.ppm(fitHO))
    fitHO <- project.ppm(fitHO)
  
  return(fitHO)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/ppmclass.R"
#
#	ppmclass.R
#
#	Class 'ppm' representing fitted point process models.
#
#
#	$Revision: 2.116 $	$Date: 2014/12/31 01:54:00 $
#
#       An object of class 'ppm' contains the following:
#
#            $method           model-fitting method (currently "mpl")
#
#            $coef             vector of fitted regular parameters
#                              as given by coef(glm(....))
#
#            $trend            the trend formula
#                              or NULL 
#
#            $interaction      the interaction family 
#                              (an object of class 'interact') or NULL
#
#            $Q                the quadrature scheme used
#
#            $maxlogpl         the maximised value of log pseudolikelihood
#
#            $internal         list of internal calculation results
#
#            $correction       name of edge correction method used
#            $rbord            erosion distance for border correction (or NULL)
#
#            $the.call         the originating call to ppm()
#
#            $the.version      version of mpl() which yielded the fit
#
#
#------------------------------------------------------------------------

is.ppm <- function(x) { inherits(x, "ppm") }

print.ppm <-
function(x, ...,
         what=c("all", "model", "trend", "interaction", "se", "errors")) {

  verifyclass(x, "ppm")

  misswhat <- missing(what) 

  opts <- c("model", "trend", "interaction", "se", "errors")
  what <- match.arg(what, c("all", opts), several.ok=TRUE)
  if("all" %in% what) what <- opts

  np <- length(coef(x))
  terselevel <- spatstat.options("terse")
  digits <- getOption('digits')
  
  # If SE was explicitly requested, calculate it.
  # Otherwise, do it only if the model is Poisson (by default)
  do.SE <- force.no.SE <- force.SE <- FALSE
  if(np == 0) {
    force.no.SE <- TRUE
  } else if(!misswhat && ("se" %in% what)) {
    force.SE <- TRUE
  } else switch(spatstat.options("print.ppm.SE"),
                always = { force.SE <- TRUE }, 
                never  = { force.no.SE <- TRUE },
                poisson = {
                  do.SE <-
                    is.poisson(x) &&
                      !identical(x$fitter, "gam") &&
                        (!is.null(x$varcov) || x$method != "logi") &&
                          waxlyrical("extras", terselevel)
                })
  do.SE <- (do.SE || force.SE) && !force.no.SE

  s <- summary.ppm(x, quick=if(do.SE) FALSE else "no variances")
        
  notrend <-    s$no.trend
#  stationary <- s$stationary
  poisson <-    s$poisson
  markeddata <- s$marked
  multitype  <- s$multitype
        
#  markedpoisson <- poisson && markeddata
  csr <- poisson && notrend && !markeddata

  special <- csr && all(c("model", "trend") %in% what)
  if(special) {
    ## ---------- Trivial/special cases -----------------------
    splat("Stationary Poisson process")
    cat("Intensity:", signif(s$trend$value, digits), fill=TRUE)
  } else {
    ## ----------- Print model type -------------------
    if("model" %in% what) {
      splat(s$name)
      parbreak(terselevel)
        
      if(markeddata) mrk <- s$entries$marks
      if(multitype) {
        splat(paste("Possible marks:",
                    commasep(sQuote(levels(mrk)))))
        parbreak(terselevel)
      }
    }
    ## ----- trend --------------------------
    if("trend" %in% what) {
      if(!notrend) {
        splat("Log",
              if(poisson) "intensity: " else "trend: ",
              pasteFormula(s$trend$formula))
        parbreak(terselevel)
      }

      tv <- s$trend$value
      
      if(length(tv) == 0) 
        splat("[No trend coefficients]")
      else {
        thead <- paste0(s$trend$label, ":")
        if(is.list(tv)) {
          splat(thead)
          for(i in seq_along(tv))
            print(tv[[i]])
        } else if(is.numeric(tv) && length(tv) == 1) {
          ## single number: append to end of current line
          tvn <- names(tv)
          tveq <- if(is.null(tvn)) "\t" else paste(" ", tvn, "= ")
          splat(paste0(thead, tveq, signif(tv, digits)))
        } else {
          ## some other format 
          splat(thead)
          print(tv)
        }
      }
    }

    parbreak(terselevel)

    if(waxlyrical("extras", terselevel) &&
       !is.null(cfa <- s$covfunargs) && length(cfa) > 0) {
      cfafitter <- s$cfafitter
      if(is.null(cfafitter)) {
        cat("Covariate", "function", "arguments", "(covfunargs)",
            "provided:", fill=TRUE)
      } else {
        cat("Irregular", "parameters", "(covfunargs)",
            "fitted", "by", paste0(sQuote(cfafitter), ":"),
            fill=TRUE)
      }
      for(i in seq_along(cfa)) {
        cat(paste(names(cfa)[i], "= "))
        cfai <- cfa[[i]]
        if(is.numeric(cfai) && length(cfai) == 1) {
          cfai <- signif(cfai, digits)
          cat(paste(cfai, "\n"))
        } else print(cfai)
      }
    }
  }
  
  # ---- Interaction ----------------------------

  if("interaction" %in% what) {
    if(!poisson) {
      print(s$interaction, family=FALSE, banner=FALSE, 
            brief=!waxlyrical("extras"))
      parbreak(terselevel)
    }
  }
  
  # ----- parameter estimates with SE and 95% CI --------------------
  if(waxlyrical("extras", terselevel) && ("se" %in% what) && (np > 0)) {
    if(!is.null(cose <- s$coefs.SE.CI)) {
      print(cose, digits=digits)
    } else if(do.SE) {
      # standard error calculation failed
      splat("Standard errors unavailable; variance-covariance matrix is singular")
    } else if(!force.no.SE) {
      # standard error was voluntarily omitted
      if(waxlyrical('space', terselevel))
        splat("For standard errors, type coef(summary(x))\n")
    }
  }
  
  # ---- Warnings issued in mpl.prepare  ---------------------

  if(waxlyrical("errors", terselevel) && "errors" %in% what) {
    probs <- s$problems
    if(!is.null(probs) && is.list(probs) && (length(probs) > 0)) 
      lapply(probs,
             function(x) {
               if(is.list(x) && !is.null(p <- x$print))
                 splat(paste("Problem:\n", p, "\n\n"))
             })
    
    if(s$old)
      warning(paste("Model fitted by old spatstat version", s$version))
        
  # ---- Algorithm status ----------------------------

    fitter <- s$fitter
    converged <- s$converged
    if(!is.null(fitter) && fitter %in% c("glm", "gam") && !converged)
      splat("*** Fitting algorithm for", sQuote(fitter),
            "did not converge ***")
  }

  if(waxlyrical("extras", terselevel) && s$projected) {
    parbreak()
    splat("Fit was projected to obtain a valid point process model")
  }

  if(identical(s$valid, FALSE) && waxlyrical("errors", terselevel)) {
    parbreak()
    splat("***",
          "Model is not valid",
          "***\n***",
          "Interaction parameters are outside valid range",
          "***")
  } else if(is.na(s$valid) && waxlyrical("extras", terselevel)) {
    parbreak()
    splat("[Validity of model could not be checked]")
  }
  
  return(invisible(NULL))
}

quad.ppm <- function(object, drop=FALSE, clip=FALSE) {
  if(!is.ppm(object)) {
    if(inherits(object, "kppm")) object <- object$po else
    stop("object is not of class ppm or kppm")
  }
  Q <- object$Q
  if(is.null(Q))
    return(Q)
  if(drop || clip) {
    ok <- getglmsubset(object)
    if(!is.null(ok))
      Q <- Q[ok]
  }
  if(clip && object$correction == "border") {
    Wminus <- erosion(as.owin(object), object$rbord)
    Q <- Q[Wminus]
  }
  return(Q)
}

data.ppm <- function(object) { 
  verifyclass(object, "ppm")
  object$Q$data
}

dummy.ppm <- function(object, drop=FALSE) { 
  return(quad.ppm(object, drop=drop)$dummy)
}
  
# method for 'coef'
coef.ppm <- function(object, ...) {
  verifyclass(object, "ppm")
  object$coef
}


getglmfit <- function(object) {
  verifyclass(object, "ppm")
  glmfit <- object$internal$glmfit
  if(is.null(glmfit))
      return(NULL)
  if(object$method != "mpl")
    glmfit$coefficients <- object$coef
  return(glmfit)
}

getglmdata <- function(object, drop=FALSE) {
  verifyclass(object, "ppm")
  gd <- object$internal$glmdata
  if(!drop) return(gd)
  return(gd[getglmsubset(object), , drop=FALSE])
}

getglmsubset <- function(object) {
  gd <- object$internal$glmdata
  if(object$method=="logi")
    return(gd$.logi.ok)
  return(gd$.mpl.SUBSET)
}

getppmdatasubset <- function(object) {
  # Equivalent to getglmsubset(object)[is.data(quad.ppm(object))]
  # but also works for models fitted exactly, etc
  #
  if(object$method %in% c("mpl", "ho")) {
    sub <- getglmsubset(object)
    if(!is.null(sub)) {
      Z <- is.data(quad.ppm(object))
      return(sub[Z])
    }
  }
  X <- data.ppm(object)
  sub <- if(object$correction == "border") {
    (bdist.points(X) >= object$rbord)
  } else rep(TRUE, npoints(X))
  return(sub)
}


getppmOriginalCovariates <- function(object) {
  df <- as.data.frame(as.ppp(quad.ppm(object)))
  cova <- object$covariates
  if(length(cova) > 0) {
    df2 <- mpl.get.covariates(object$covariates,
                              union.quad(quad.ppm(object)),
                              "quadrature points",
                              object$covfunargs)
    df <- cbind(df, df2)
  } 
  return(df)
}
  
# ??? method for 'effects' ???

valid.ppm <- function(object, warn=TRUE) {
  verifyclass(object, "ppm")
  coeffs <- coef(object)
  # ensure all coefficients are fitted, and finite
  if(!all(is.finite(coeffs)))
    return(FALSE)
  # inspect interaction
  inte <- object$interaction
  if(is.null(inte))
    return(TRUE) # Poisson process
  # extract fitted interaction coefficients
  Vnames <- object$internal$Vnames
  IsOffset <- object$internal$IsOffset  
  Icoeffs <- coeffs[Vnames[!IsOffset]]
  # check interaction
  checker <- inte$valid
  if(is.null(checker) || !newstyle.coeff.handling(inte)) {
    if(warn) warning("Internal error: unable to check validity of model")
    return(NA)
  }
  answer <- checker(Icoeffs, inte)
  return(answer)
}

project.ppm <- local({
  tracemessage <- function(depth, ...) {
    if(depth == 0) return(NULL)
    spacer <- paste(rep.int("  ", depth), collapse="")
    marker <- ngettext(depth, "trace", paste("trace", depth))
    marker <- paren(marker, "[")
    splat(paste0(spacer, marker, " ", paste(...)))
  }
  leaving <- function(depth) {
    tracemessage(depth, ngettext(depth, "Returning.", "Exiting level."))
  }
  project.ppm <- function(object, ..., fatal=FALSE, trace=FALSE) {
    verifyclass(object, "ppm")
    fast <- spatstat.options("project.fast")
    # user specifies 'trace' as logical
    # but 'trace' can also be integer representing trace depth
    td <- as.integer(trace)
    trace <- (td > 0)
    tdnext <- if(trace) td+1 else 0
    if(valid.ppm(object)) {
      tracemessage(td, "Model is valid.")
      leaving(td)
      return(object)
    }
    # First ensure trend coefficients are all finite
    coeffs <- coef(object)
    # Which coefficients are trend coefficients
    coefnames  <- names(coeffs)
    internames <- object$internal$Vnames
    trendnames <- coefnames[!(coefnames %in% internames)]
    # Trend terms in trend formula
    trendterms <- attr(terms(object), "term.labels")
    # Mapping from coefficients to terms of GLM
    coef2term  <- attr(model.matrix(object), "assign")
    istrend <- (coef2term > 0) & (coefnames %in% trendnames)
    # Identify non-finite trend coefficients
    bad <- istrend & !is.finite(coeffs)
    if(!any(bad)) {
      tracemessage(td, "Trend terms are valid.")
    } else {
      nbad <- sum(bad)
      tracemessage(td,
                   "Non-finite ",
                   ngettext(nbad,
                            "coefficient for term ",
                            "coefficients for terms "),
                   commasep(sQuote(trendterms[coef2term[bad]])))
      if(fast) {
        # remove first illegal term
        firstbad <- min(which(bad))
        badterm <- trendterms[coef2term[firstbad]]
        # remove this term from model
        tracemessage(td, "Removing term ", sQuote(badterm))
        removebad <- as.formula(paste("~ . - ", badterm), env=object$callframe)
        newobject <- update(object, removebad)
        if(trace) {
          tracemessage(td, "Updated model:")
          print(newobject)
        }
        # recurse
        newobject <- project.ppm(newobject, fatal=fatal, trace=tdnext)
        # return
        leaving(td)
        return(newobject)
      } else {
        # consider all illegal terms
        bestobject <- NULL
        for(i in which(bad)) {
          badterm <- trendterms[coef2term[i]]
          # remove this term from model
          tracemessage(td, "Considering removing term ", sQuote(badterm))
          removebad <- as.formula(paste("~ . - ", badterm),
                                  env=object$callframe)
          object.i <- update(object, removebad)
          if(trace) {
            tracemessage(td, "Considering updated model:")
            print(object.i)
          }
          # recurse
          object.i <- project.ppm(object.i, fatal=fatal, trace=tdnext)
          # evaluate logPL
          logPL.i   <- logLik(object.i, warn=FALSE)
          tracemessage(td, "max log pseudolikelihood = ", logPL.i)
          # optimise
          if(is.null(bestobject) || (logLik(bestobject, warn=FALSE) < logPL.i))
            bestobject <- object.i
        }
        if(trace) {
          tracemessage(td, "Best submodel:")
          print(bestobject)
        }
        # return
        leaving(td)
        return(bestobject)
      }
    } 
    # Now handle interaction
    inte <- object$interaction
    if(is.null(inte)) {
      tracemessage(td, "No interaction to check.")
      leaving(td)
      return(object)
    }
    tracemessage(td, "Inspecting interaction terms.")
    proj <- inte$project
    if(is.null(proj)) {
      whinge <- "Internal error: interaction has no projection operator"
      if(fatal) stop(whinge) 
      warning(whinge)
      leaving(td)
      return(object)
    }
    # ensure the same edge correction is used!
    correction <- object$correction
    rbord      <- object$rbord
    # apply projection 
    coef.orig <- coeffs <- coef(object)
    Vnames   <- object$internal$Vnames
    Icoeffs  <- coeffs[Vnames]
    change <- proj(Icoeffs, inte)
    if(is.null(change)) {
      tracemessage(td, "Interaction does not need updating.")
      leaving(td)
      return(object)
    }
    tracemessage(td, "Interaction is not valid.")
    if(is.numeric(change)) {
      tracemessage(td, "Interaction coefficients updated without re-fitting.")
      # old style: 'project' returned a vector of updated coefficients
      Icoeffs <- change
      # tweak interaction coefficients
      object$coef[Vnames] <- Icoeffs
      # recompute fitted interaction
      object$fitin <- NULL
      object$fitin <- fitin(object)
    } else if(is.interact(change)) {
      # new style: 'project' returns an interaction
      if(trace) {
        tracemessage(td, "Interaction changed to:")
        print(change)
      }
      # refit the whole model 
      #      (using the same edge correction)
      #      (and the same quadrature scheme)
      newobject <- update(object, interaction=change,
                          correction=correction, rbord=rbord,
                          forcefit=TRUE,
                          envir=object$callframe)
      if(trace) {
        tracemessage(td, "Updated model:")
        print(newobject)
      }
      # recurse
      newobject <- project.ppm(newobject, fatal=fatal, trace=tdnext)
      object <- newobject
    } else if(is.list(change) && all(unlist(lapply(change, is.interact)))) {
      # new style: 'project' returns a list of candidate interactions
      nchange <- length(change)
      tracemessage(td, "Considering", nchange,
                   ngettext(nchange, "submodel", "submodels"))
      bestobject <- NULL
      for(i in seq_len(nchange)) {
        change.i <- change[[i]]
        if(trace) {
          tracemessage(td,
                       "Considering", ordinal(i), 
                       "candidate submodel, with interaction:")
          print(change.i)
        }
        # refit the whole model
        object.i <- update(object, interaction=change.i,
                           correction=correction, rbord=rbord,
                           forcefit=TRUE,
                           envir=object$callframe)
        if(trace) {
          tracemessage(td, "Considering", ordinal(i),
                       "candidate updated model:")
          print(object.i)
        }
        # recurse
        object.i <- project.ppm(object.i, fatal=fatal, trace=tdnext)
        # evaluate logPL
        logPL.i   <- logLik(object.i, warn=FALSE)
        tracemessage(td, "max log pseudolikelihood = ", logPL.i)
        # optimise
        if(is.null(bestobject) || (logLik(bestobject, warn=FALSE) < logPL.i))
          bestobject <- object.i
      }
      # end loop through submodels
      if(trace) {
        tracemessage(td, "Best submodel:")
        print(bestobject)
      }
      object <- bestobject
    } else stop("Internal error: unrecognised format of update")
    object$projected <- TRUE
    object$coef.orig  <- coef.orig
    leaving(td)
    return(object)
  }
  project.ppm
})

# more methods

logLik.ppm <- function(object, ..., new.coef=NULL, warn=TRUE) {
  if(!is.poisson.ppm(object) && warn) 
    warning(paste("log likelihood is not available for non-Poisson model;",
                  "log-pseudolikelihood returned"))
  ## degrees of freedom
  nip <- if(!inherits(object, "ippm")) 0 else
           length(attr(object$covfunargs, "free"))
  df <- length(coef(object)) + nip
  ##
  if(is.null(new.coef)) {
    ## extract from object
    ll <- object$maxlogpl
    attr(ll, "df") <- df
    class(ll) <- "logLik"
    return(ll)
  } 
  ## recompute for new parameter values
  method <- object$method
  if(method == "exact")
    method <- update(method, forcefit=TRUE)
  Q <- quad.ppm(object, drop=TRUE)
  Z <- is.data(Q)
  cif <- fitted(object, type="cif", new.coef=new.coef, drop=TRUE)
  cifdata <- cif[Z]
  switch(method,
         mpl=,
         exact=,
         ho = {
           w <- w.quad(Q)
           ll <- sum(log(cifdata[cifdata > 0])) - sum(w * cif)
         },
         logi={
           B <- getglmdata(object, drop=TRUE)$.logi.B
           p <- cif/(B+cif)
           ll <- sum(log(p/(1-p))[Z]) + sum(log(1-p)) + sum(log(B[Z]))
         },
         stop(paste("Internal error: unrecognised ppm method:",
                    dQuote(method)))
         )
  attr(ll, "df") <- df
  class(ll) <- "logLik"
  return(ll)
}

formula.ppm <- function(x, ...) {
  return(x$trend)
}

terms.ppm <- function(x, ...) {
  terms(x$terms, ...)
}

labels.ppm <- function(object, ...) {
  # extract fitted trend coefficients
  co <- coef(object)
  Vnames <- object$internal$Vnames
  is.trend <- !(names(co) %in% Vnames)
  # model terms
  tt <- terms(object)
  lab <- attr(tt, "term.labels")
  if(length(lab) == 0)
    return(character(0))
  # model matrix
  mm <- model.matrix(object)
  ass <- attr(mm, "assign")
  # 'ass' associates coefficients with model terms
  # except ass == 0 for the Intercept
  coef.ok <- is.finite(co)
  relevant <- (ass > 0) & is.trend
  okterms <- unique(ass[coef.ok & relevant])
  return(lab[okterms])
}

AIC.ppm <- function(object, ..., k=2, takeuchi=TRUE) {
  ll <- logLik(object, warn=FALSE)
  pen <- attr(ll, "df")
  if(takeuchi && !is.poisson(object)) {
    vv <- vcov(object, what="internals")
    logi <- (object$method == "logi")
    J  <- with(vv, if(!logi) Sigma else (Sigma1log+Sigma2log))
    H  <- with(vv, if(!logi) A1 else Slog)
    ## Takeuchi penalty = trace of J H^{-1} = trace of H^{-1} J
    JiH <- try(solve(H, J), silent=TRUE)
    if(!inherits(JiH, "try-error")) 
      pen <- sum(diag(JiH))
  } 
  return(- 2 * as.numeric(ll) + k * pen)
}

extractAIC.ppm <- function (fit, scale = 0, k = 2, ..., takeuchi=TRUE)
{
  edf <- length(coef(fit))
  aic <- AIC(fit, k=k, takeuchi=takeuchi)
  c(edf, aic)
}

#
# method for model.frame

model.frame.ppm <- function(formula, ...) {
  object <- formula
  gf <- getglmfit(object)
  if(is.null(gf)) {
    warning("Model re-fitted with forcefit=TRUE")
    object <- update(object, forcefit=TRUE)
    gf <- getglmfit(object)
  }
#  gd <- getglmdata(object)
#  model.frame(gf, data=gd, ...)
  model.frame(gf, ...)
}

#
# method for model.matrix

model.matrix.ppm <- function(object, data=model.frame(object),
                             ..., Q=NULL, keepNA=TRUE) {
  data.given <- !missing(data) && !is.null(data)
  if(!is.null(Q)) {
    if(data.given) stop("Arguments Q and data are incompatible")
    if(!inherits(Q, c("ppp", "quad")))
      stop("Q should be a point pattern or quadrature scheme")
    if(is.ppp(Q)) Q <- quad(Q, Q[FALSE])
    ## construct Berman-Turner frame
    needed <- c("trend", "interaction", "covariates", "correction", "rbord")
    bt <- do.call("bt.frame", append(list(Q), object[needed]))
    ## compute model matrix
    mf <- model.frame(bt$fmla, bt$glmdata, ...)
    mm <- model.matrix(bt$fmla, mf, ...)
    ## remove NA's ?
    if(!keepNA)
      mm <- mm[complete.cases(mm), ..., drop=FALSE]
    return(mm)
  }
  gf <- getglmfit(object)
  if(is.null(gf)) {
    warning("Model re-fitted with forcefit=TRUE")
    object <- update(object, forcefit=TRUE)
    gf <- getglmfit(object)
    if(is.null(gf))
      stop("internal error: unable to extract a glm fit")
  }
  
  if(data.given) {
    # new data. Must contain the Berman-Turner variables as well.
    bt <- list(.mpl.Y=1, .mpl.W=1, .mpl.SUBSET=TRUE)
    if(any(forgot <- !(names(bt) %in% names(data)))) 
      data <- do.call("cbind", append(list(data), bt[forgot]))
    mm <- model.matrix(gf, data=data, ...)
    return(mm)
  }

  if(!keepNA) {
    # extract model matrix of glm fit object
    # restricting to its 'subset' 
    mm <- model.matrix(gf, data=data, ...)
    return(mm)
  }
  
  # extract model matrix for all cases
  mm <- model.matrix(gf, data, ..., subset=NULL)
  cn <- colnames(mm)
  gd <- getglmdata(object, drop=FALSE)
  if(nrow(mm) != nrow(gd)) {
    # can occur if covariates include NA's or interaction is -Inf
    insubset <- getglmsubset(object)
    isna <- is.na(insubset) | !insubset
    if(sum(isna) + nrow(mm) == nrow(gd)) {
      # insert rows of NA's
      mmplus <- matrix( , nrow(gd), ncol(mm))
      mmplus[isna, ] <- NA
      mmplus[!isna, ] <- mm
      mm <- mmplus
    } else 
    stop("internal error: model matrix does not match glm data frame")
  }
  colnames(mm) <- cn
  return(mm)
}

model.images <- function(object, ...) {
  UseMethod("model.images")
}

model.images.ppm <- function(object, W=as.owin(object), ...) {
  X <- data.ppm(object)
  ## make a quadscheme with a dummy point at every pixel
  Q <- pixelquad(X, W)
  ## compute model matrix
  mm <- model.matrix(object, Q=Q)
  ## retain only the entries for dummy points (pixels)
  mm <- mm[!is.data(Q), , drop=FALSE]
  mm <- as.data.frame(mm)
  ## create template image
  Z <- as.im(attr(Q, "M"))
  ok <- !is.na(Z$v)
  ## make images
  imagenames <- colnames(mm)
  if(!is.multitype(object)) {
    result <- lapply(as.list(mm), replace, list=ok, x=Z)
    result <- as.listof(result)
    names(result) <- imagenames
  } else {
    marx <- marks(Q$dummy)
    mmsplit <- split(mm, marx)
    result <- vector(mode="list", length=length(mmsplit))
    for(i in seq_along(mmsplit))
      result[[i]] <- as.listof(lapply(as.list(mmsplit[[i]]),
                                      replace, list=ok, x=Z))
    names(result) <- names(mmsplit)
    result <- do.call(hyperframe, result)
    row.names(result) <- imagenames
  }
  return(result)
}

unitname.ppm <- function(x) {
  return(unitname(x$Q))
}

"unitname<-.ppm" <- function(x, value) {
  unitname(x$Q) <- value
  return(x)
}

nobs.ppm <- function(object, ...) { npoints(data.ppm(object)) }

as.interact.ppm <- function(object) {
 verifyclass(object, "ppm")
 inte <- object$interaction
 if(is.null(inte))
   inte <- Poisson()
 return(inte)
}

as.ppm <- function(object) {
  UseMethod("as.ppm")
}

as.ppm.ppm <- function(object) {
  object
}

## method for as.owin

as.owin.ppm <- function(W, ..., from=c("points", "covariates"), fatal=TRUE) {
  if(!verifyclass(W, "ppm", fatal=fatal))
    return(NULL)
  from <- match.arg(from)
  datawin <- as.owin(data.ppm(W))
  if(from == "points")
    return(datawin)
  covs <- W$covariates
  isim <- unlist(lapply(covs, is.im))
  if(!any(isim))
    return(datawin)
  cwins <- lapply(covs[isim], as.owin)
  covwin <- do.call("intersect.owin", unname(cwins))
  result <- intersect.owin(covwin, datawin)
  return(result)
}

domain.ppm <- Window.ppm <- function(X, ..., from=c("points", "covariates")) {
  from <- match.arg(from)
  as.owin(X, ..., from=from)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/ppp.R"
#
#	ppp.R
#
#	A class 'ppp' to define point patterns
#	observed in arbitrary windows in two dimensions.
#
#	$Revision: 4.100 $	$Date: 2014/11/11 01:26:40 $
#
#	A point pattern contains the following entries:	
#
#		$window:	an object of class 'owin'
#				defining the observation window
#
#		$n:	the number of points (for efficiency)
#	
#		$x:	
#		$y:	vectors of length n giving the Cartesian
#			coordinates of the points.
#
#	It may also contain the entry:	
#
#		$marks:	a vector of length n
#			whose entries are interpreted as the
#			'marks' attached to the corresponding points.	
#	
#--------------------------------------------------------------------------
ppp <- function(x, y, ..., window, marks, check=TRUE, drop=TRUE) {
  # Constructs an object of class 'ppp'
  #
  if(!missing(window))
    verifyclass(window, "owin")
  else
    window <- owin(...)

  if((missing(x) && missing(y)) || (length(x) == 0 && length(y) == 0))
    x <- y <- numeric(0)

  n <- length(x)
  if(length(y) != n)
    stop("coordinate vectors x and y are not of equal length")
  
  # validate x, y coordinates
  stopifnot(is.numeric(x))
  stopifnot(is.numeric(y))
  ok <- is.finite(x) & is.finite(y)
  if(any(!ok)) {
    nbg <- is.na(x) | is.na(y)
    if(any(nbg)) {
      howmany <- if(all(nbg)) "all" else paste(sum(nbg),  "out of", length(nbg))
      stop(paste(howmany, "coordinate values are NA or NaN"))
    }
    howmany <- if(!any(ok)) "all" else paste(sum(!ok),  "out of", length(ok))
    stop(paste(howmany, "coordinate values are infinite"))
  }

  names(x) <- NULL
  names(y) <- NULL
  
  # check (x,y) points lie inside window
  if(check && n > 0) {
    ok <- inside.owin(x, y, window)
    nout <- sum(!ok)
    if(nout > 0) {
      warning(paste(nout,
                    ngettext(nout, "point was", "points were"),
                    "rejected as lying outside the specified window"))
      rr <- ripras(x,y)
      bb <- boundingbox(x,y)
      bb <- boundingbox(rr, bb, window)
      rejectwindow <-
        if(!is.null(rr)) rebound.owin(rr, bb) else bb
      rejects <- ppp(x[!ok], y[!ok], window=rejectwindow, check=FALSE)
      # discard illegal points
      x <- x[ok]
      y <- y[ok]
      n <- length(x)
    }
  } else nout <- 0
  # initialise ppp object
  pp <- list(window=window, n=n, x=x, y=y)
  # coerce marks to appropriate format
  if(missing(marks))
    marks <- NULL
  if(is.hyperframe(marks)) 
    stop("Hyperframes of marks are not implemented for ppp objects; use ppx")
  if(is.matrix(marks)) 
    marks <- as.data.frame(marks)
  ## drop dimensions?
  if(drop && is.data.frame(marks)) {
    nc <- ncol(marks)
    if(nc == 0)
      marks <- NULL
    else if(nc == 1)
      marks <- marks[,,drop=TRUE]
  }
  # attach marks 
  if(is.null(marks)) {
    # no marks
    pp$markformat <- "none"
  } else if(is.data.frame(marks)) {
    # data frame of marks
    pp$markformat <- "dataframe"
    if(nout > 0) {
      marks <- marks[ok, ]
      marks(rejects) <- marks[!ok,]
    }
    if(nrow(marks) != n)
      stop("number of rows of marks != length of x and y")
    pp$marks <- marks
  } else {
    # should be a vector or factor
    # To recognise vector, strip attributes
    isspecial <- is.factor(marks) ||
                 inherits(marks, "POSIXt") || inherits(marks, "Date")
    if(!isspecial)
      attributes(marks) <- NULL
    if(!(is.vector(marks) || isspecial))
      stop("Format of marks not understood")
    # OK, it's a vector or factor
    pp$markformat <- "vector"
    if(nout > 0) {
      marks(rejects) <- marks[!ok]
      marks <- marks[ok]
    }
    if(length(marks) != n)
      stop("length of marks vector != length of x and y")
    names(marks) <- NULL
    pp$marks <- marks
  }
  class(pp) <- "ppp"
  if(check && anyDuplicated(pp))
    warning("data contain duplicated points")
  if(nout > 0) 
    attr(pp, "rejects") <- rejects
  pp
}

#
#--------------------------------------------------------------------------
#

is.ppp <- function(x) { inherits(x, "ppp") }

#
#--------------------------------------------------------------------------
#

as.ppp <- function(X, ..., fatal=TRUE) {
  UseMethod("as.ppp")
}

as.ppp.ppp <- function(X, ..., fatal=TRUE) {
  check <- resolve.defaults(list(...), list(check=FALSE))$check
  return(ppp(X$x, X$y, window=X$window, marks=X$marks, check=check))
}

as.ppp.quad <- function(X, ..., fatal=TRUE) {
  return(union.quad(X))
}

as.ppp.data.frame <- function(X, W = NULL, ..., fatal=TRUE) {
  check <- resolve.defaults(list(...), list(check=TRUE))$check
  if(ncol(X) < 2) 
    return(complaining("X must have at least two columns",
                       fatal, value=NULL))

  if(is.null(W))
    return(complaining("x,y coords given but no window specified",
                       fatal, value=NULL))

  # columns 1 and 2 are assumed to be coordinates
  # marks from other columns
  marx <- if(ncol(X) > 2) X[, -(1:2)] else NULL

  if(is.function(W))
    Z <- cobble.xy(X[,1], X[,2], W, fatal, marks=marx, check=check)
  else {
    win <- as.owin(W)
    Z <- ppp(X[,1], X[,2], window = win, marks=marx, check=check)
  }

  return(Z)
}
    
as.ppp.matrix <- function(X, W = NULL, ..., fatal=TRUE) {
  check <- resolve.defaults(list(...), list(check=TRUE))$check
  if(!verifyclass(X, "matrix", fatal=fatal)
     || !is.numeric(X))
    return(complaining("X must be a numeric matrix",
                       fatal, value=NULL))

  if(ncol(X) < 2)
    return(complaining("X must have at least two columns",
                       fatal, value=NULL))

  if(is.null(W))
    return(complaining("x,y coords given but no window specified",
                       fatal, value=NULL))
    
  if(is.function(W))
    Z <- cobble.xy(X[,1], X[,2], W, fatal)
  else {
    win <- as.owin(W)
    Z <- ppp(X[,1], X[,2], window = win, check=check)
  }

  # add marks from other columns
  if(ncol(X) > 2)
    marks(Z) <- X[, -(1:2)]

  return(Z)
}
    
as.ppp.default <- function(X, W=NULL, ..., fatal=TRUE) {
	# tries to coerce data X to a point pattern
	# X may be:
	#	1. a structure with entries x, y, xl, xu, yl, yu
	#	2. a structure with entries x, y, area where
        #                    'area' has entries xl, xu, yl, yu
	#	3. a structure with entries x, y
        #       4. a vector of length 2, interpreted as a single point.
	# The second argument W is coerced to an object of class 'owin' by the 
	# function "as.owin" in window.S
        # If X also has an entry X$marks
        # then this will be interpreted as the marks vector for the pattern.
	#
  check <- resolve.defaults(list(...), list(check=TRUE))$check
  if(checkfields(X, c("x", "y", "xl", "xu", "yl", "yu"))) {
		xrange <- c(X$xl, X$xu)
		yrange <- c(X$yl, X$yu)
		if(is.null(X$marks))
			Z <- ppp(X$x, X$y, xrange, yrange, check=check)
		else
			Z <- ppp(X$x, X$y, xrange, yrange, 
				marks=X$marks, check=check)
		return(Z)
        } else if(checkfields(X, c("x", "y", "area"))
                  && checkfields(X$area, c("xl", "xu", "yl", "yu"))) {
                win <- as.owin(X$area)
                if (is.null(X$marks))
                  Z <- ppp(X$x, X$y, window=win, check=check)
                else
                  Z <- ppp(X$x, X$y, window=win, marks = X$marks, check=check)
                return(Z)
	} else if(checkfields(X, c("x", "y"))) {
                if(is.function(W))
                  return(cobble.xy(X$x, X$y, W, fatal))
		if(is.null(W)) {
                  if(fatal)
                    stop("x,y coords given but no window specified")
                  else
                    return(NULL)
                }
		win <- as.owin(W)
		if(is.null(X$marks))
                  Z <- ppp(X$x, X$y, window=win, check=check)
                else
                  Z <- ppp(X$x, X$y, window=win, marks=X$marks, check=check)
                return(Z)
        } else if(is.vector(X) && length(X) == 2) {
                win <- as.owin(W)
                Z <- ppp(X[1], X[2], window=win, check=check)
                return(Z)
	} else {
          if(fatal)
            stop("Can't interpret X as a point pattern")
          else
            return(NULL)
        }
}

cobble.xy <- function(x, y, f=ripras, fatal=TRUE, ...) {
  if(!is.function(f))
    stop("f is not a function")
  w <- f(x,y)
  if(!is.owin(w)) {
    gripe <- "Supplied function f did not return an owin object"
    if(fatal)
      stop(gripe)
    else {
      warning(gripe)
      return(NULL)
    }
  }
  return(ppp(x, y, window=w, ...))
}
  

# --------------------------------------------------------------

"[.ppp" <-
  function(x, i, j, drop, ...) {

        verifyclass(x, "ppp")
        
        if(missing(i) && missing(j))
          return(x)

        if(!missing(i)) {
          if(inherits(i, "owin")) {
            # i is a window
            window <- i
            ok <- inside.owin(x$x, x$y, window)
            x <- ppp(x$x[ok], x$y[ok], window=window, #SIC
                     marks=marksubset(x$marks, ok),
                     check=FALSE)
          } else if(inherits(i, "im")) {
            # i is an image
            if(i$type != "logical")
              stop(paste("Subset operator X[i] undefined",
                         "when i is a pixel image",
                         "unless it has logical values"), call.=FALSE)
            # convert logical image to window
            e <- sys.frame(sys.nframe())
            window <- solutionset(i, e)
            ok <- inside.owin(x$x, x$y, window)
            x <- ppp(x$x[ok], x$y[ok], window=window, #SIC
                     marks=marksubset(x$marks, ok),
                     check=FALSE)
          } else {
            # assume i is a subset index
            nx <- x$n
            if(nx == 0)
              return(x)
            subset <- seq_len(nx)[i]
            if(any(is.na(subset)))
              stop("Index out of bounds in [.ppp", call.=FALSE)
            x <- ppp(x$x[subset], x$y[subset], window=x$window,
                     marks=marksubset(x$marks, subset),
                     check=FALSE)
          } 
        }

        if(!missing(j))
          x <- x[j]   # invokes code above

        return(x)
}


# ------------------------------------------------------------------
#
#
scanpp <- function(filename, window, header=TRUE, dir="", factor.marks = NULL, ...) {
  filename <- if(dir=="") filename else
              paste(dir, filename, sep=.Platform$file.sep)
  df <- read.table(filename, header=header, stringsAsFactors = is.null(factor.marks))
  if(header) {
    # check whether there are columns named 'x' and 'y'
    colnames <- dimnames(df)[[2]]
    xycolumns <- match(c("x", "y"), colnames, 0)
    named <- all(xycolumns > 0)
  } else {
    named <- FALSE
  }
  if(named) {
    x <- df$x
    y <- df$y
  } else {
    # assume x, y given in columns 1, 2 respectively
    x <- df[,1]
    y <- df[,2]
    xycolumns <- c(1,2)
  }
  if(ncol(df) == 2) 
      X <- ppp(x, y, window=window)
  else {
      # Catch old argument "multitype":
      dots <- list(...)
      multi <- charmatch(names(dots), "multitype")
      argindex <- which(!is.na(multi))
      if(length(argindex)>0){
          if(missing(factor.marks)){
              factor.marks <- dots[[argindex]]
              ignored <- ""
          } else{
              ignored <- paste(" and it is ignored since",
                               sQuote("factor.marks"),
                               "is also supplied.")
          }
          warning("It appears you have called scanpp with (something partially matching)",
                  " the deprecated argument ", sQuote("multitype"), ignored,
                  " Please change to the new syntax.")
      }
    marks <- df[ , -xycolumns]
    if(any(factor.marks)){
        # Find indices to convert to factors (recycling to obtain correct length)
        factorid <- (1:ncol(marks))[factor.marks]
        # Convert relevant columns to factors
        marks[,factorid] <- lapply(marks[,factorid,drop=FALSE], factor)
    }
    X <- ppp(x, y, window=window, marks = marks)
  }
  X
}

#-------------------------------------------------------------------

"markspace.integral" <-
  function(X) {
  verifyclass(X, "ppp")
  if(!is.marked(X, dfok=TRUE))
    return(1)
  if(is.multitype(X))
    return(length(levels(marks(X))))
  else
    stop("Don't know how to compute total mass of mark space")
}

#-------------------------------------------------------------------

print.ppp <- local({

  graceful <- function(prefix, strings) {
    shortblurb <- paste(prefix, paste(strings, collapse=", "), "\n")
    if(nchar(shortblurb) < options("width")[[1]]) {
      cat(shortblurb)
    } else {
      cat(paste(prefix,"\n"))
      print(strings, quote=FALSE)
    }
    return(invisible(NULL))
  }
    
  print.ppp <- function(x, ...) {
    verifyclass(x, "ppp")
    ism <- is.marked(x, dfok=TRUE)
    cat(paste0(if(ism) "marked " else NULL,
               "planar point pattern:"),
        x$n,
        ngettext(x$n, "point", "points"),
        fill=TRUE)
    if(ism) {
      mks <- marks(x, dfok=TRUE)
      if(is.data.frame(mks)) {
        ## data frame of marks
        graceful("Mark variables:", names(mks))
      } else {
        ## vector of marks
        if(is.factor(mks)) {
          graceful("Multitype, with levels =", levels(mks))
        } else {
          ## Numeric, or could be dates
          if(inherits(mks, "Date")) {
            cat("marks are dates,",
                "of class", sQuote("Date"),
                fill=TRUE)
          } else if(inherits(mks, "POSIXt")) {
            cat("marks are dates,",
                "of class", sQuote("POSIXt"),
                fill=TRUE)
          } else {
            cat(paste0("marks are", if(is.numeric(mks)) " numeric," else NULL),
                "of storage type ", sQuote(typeof(mks)),
                fill=TRUE)
          }
        }
      }
    }
    print(x$window)
    if(!is.null(rejects <- attr(x, "rejects"))) {
      nrejects <- rejects$n
      cat("***",
          nrejects,
          ngettext(nrejects, "illegal point", "illegal points"),
          "stored in",
          paste("attr(,", dQuote("rejects"), ")", sep=""),
          "***",
          fill=TRUE)
    }
    if(!is.null(info <- attr(x, "info")) && inherits(info, "rmhInfoList"))
      cat("\nPattern was generated by",
          "Metropolis-Hastings simulation.",
          fill=TRUE)
    return(invisible(NULL))
  }

  print.ppp
})


summary.ppp <- function(object, ..., checkdup=TRUE) {
  verifyclass(object, "ppp")
  result <- list()
  result$is.marked <- is.marked(object, dfok=TRUE)
  result$n <- object$n
  result$window <- summary(object$window)
  result$intensity <- result$n/result$window$area
  if(checkdup) {
    result$nduplicated <- sum(duplicated(object))
    result$rounding <- rounding(object)
  }
  if(result$is.marked) {
    mks <- marks(object, dfok=TRUE)
    if(result$multiple.marks <- is.data.frame(mks)) {
      result$marknames <- names(mks)
      result$is.numeric <- FALSE
      result$marktype <- "dataframe"
      result$is.multitype <- FALSE
    } else {
      result$is.numeric <- is.numeric(mks)
      result$marknames <- "marks"
      result$marktype <- typeof(mks)
      result$is.multitype <- is.multitype(object)
    }
    if(result$is.multitype) {
      tm <- as.vector(table(mks))
      tfp <- data.frame(frequency=tm,
                        proportion=tm/sum(tm),
                        intensity=tm/result$window$area,
                        row.names=levels(mks))
      result$marks <- tfp
    } else 
      result$marks <- summary(mks)
  }
  class(result) <- "summary.ppp"
  if(!is.null(rejects <- attr(object, "rejects"))) 
    result$rejects <- rejects$n
  if(!is.null(info <- attr(object, "info")) && inherits(info, "rmhInfoList"))
    result$rmhinfo <- info
  return(result)
}

print.summary.ppp <- function(x, ..., dp=3) {
  verifyclass(x, "summary.ppp")
  terselevel <- spatstat.options("terse")
  splat(if(x$is.marked) "Marked planar" else "Planar",
        "point pattern: ",
        x$n,
        "points")
  oneline <- resolve.defaults(list(...), list(oneline=FALSE))$oneline
  if(oneline) return(invisible(NULL))
  unitinfo <- summary(x$window$units)
  splat("Average intensity",
        signif(x$intensity,dp),
        "points per square",
        unitinfo$singular,
        unitinfo$explain)
  ndup <- x$nduplicated
  if(waxlyrical('extras', terselevel) && !is.null(ndup) && (ndup > 0)) {
    parbreak(terselevel)
    splat("*Pattern contains duplicated points*")
  }
  rndg <- x$rounding
  if(waxlyrical('gory', terselevel) && !is.null(rndg)) {
    cat("\n")
    if(rndg >= 1) {
      cat("Coordinates are", "given to",
          rndg,
          "decimal", ngettext(rndg, "place", "places"),
          fill=TRUE)
      if(rndg <= 3) {
        cat("i.e. rounded to", "the nearest", "multiple of",
            10^(-rndg), unitinfo$plural, unitinfo$explain,
            fill=TRUE)
      }
    } else if(rndg == 0) {
      cat("Coordinates are", "integers", fill=TRUE)
      cat("i.e. rounded to", "the nearest", unitinfo$singular,
          unitinfo$explain, 
          fill=TRUE)
    } else {
      cat("Coordinates are", "multiples of",
          10^(-rndg), unitinfo$plural, unitinfo$explain, 
          fill=TRUE)
    }
    parbreak(terselevel)
  }
  if(x$is.marked) {
    if(x$multiple.marks) {
      splat("Mark variables:", commasep(x$marknames, ", "))
      cat("Summary:\n")
      print(x$marks)
    } else if(x$is.multitype) {
      cat("Multitype:\n")
      print(signif(x$marks,dp))
    } else {
      splat("marks are ",
            if(x$is.numeric) "numeric, ",
            "of type ", sQuote(x$marktype),
            sep="")
      cat("Summary:\n")
      print(x$marks)
    }
    parbreak(terselevel)
  }
  if(waxlyrical('extras', terselevel))
    print(x$window)
  if(waxlyrical('errors', terselevel) && !is.null(nrejects <- x$rejects)) {
    parbreak(terselevel)
    splat("***",
          nrejects,
          ngettext(nrejects, "illegal point", "illegal points"),
          "stored in",
          paste("attr(,", dQuote("rejects"), ")", sep=""),
          "***")
  }
  if(waxlyrical('gory', terselevel) && !is.null(info <- x$rmhinfo)) {
    cat("\nPattern was generated by",
        "Metropolis-Hastings algorithm rmh",
        fill=TRUE)
    print(info)
  }
  return(invisible(x))
}

# ---------------------------------------------------------------

identify.ppp <- function(x, ...) {
  verifyclass(x, "ppp")
  id <- identify(x$x, x$y, ...)
  if(!is.marked(x)) return(id)
  marks <- as.data.frame(x)[id, -(1:2)]
  out <- cbind(data.frame(id=id), marks)
  row.names(out) <- NULL
  return(out)
}

rebound <- function(x, rect) {
  UseMethod("rebound")
}

rebound.ppp <- function(x, rect) {
  verifyclass(x, "ppp")
  x$window <- rebound.owin(x$window, rect)
  return(x)
}

as.data.frame.ppp <- function(x, row.names=NULL, ...) {
  df <- data.frame(x=x$x, y=x$y, row.names=row.names)
  marx <- marks(x, dfok=TRUE)
  if(is.null(marx))
    return(df)
  if(is.data.frame(marx))
    df <- cbind(df, marx)
  else
    df <- data.frame(df, marks=marx)
  return(df)
}

is.empty.ppp <- function(x) { return(x$n == 0) }

npoints <- function(x) {
  UseMethod("npoints")
}

nobjects <- function(x) {
  UseMethod("nobjects")
}

nobjects.ppp <- npoints.ppp <- function(x) { x$n }


domain.ppp <- Window.ppp <- function(X, ...) { as.owin(X) }

"Window<-.ppp" <- function(X, ..., value) {
  verifyclass(value, "owin")
  return(X[value])
}

"Frame<-.ppp" <- function(X, value) {
  Frame(Window(X)) <- value
  return(X)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pppmatch.R"
#
# pppmatch.R
#
# $Revision: 1.22 $  $Date: 2014/11/11 01:06:44 $
#
# Code by Dominic Schuhmacher
#
#
# -----------------------------------------------------------------
# The standard functions for the new class pppmatching
#
# Objects of class pppmatching consist of two point patterns pp1 and pp2,
# and either an adjacency matrix ((i,j)-th entry 1 if i-th point of pp1 and j-th
# point of pp2 are matched, 0 otherwise) for "full point matchings" or
# a "generalized adjacency matrix" (or flow matrix; positive values are
# no longer limited to 1, (i,j)-th entry gives the "flow" between
# the i-th point of pp1 and the j-th point of pp2) for "fractional matchings".
# Optional elements are the type
# of the matching, the cutoff value for distances in R^2, the order
# of averages taken, and the resulting distance for the matching.
# Currently recognized types are "spa" (subpattern assignment,
# where dummy points at maximal dist are introduced if cardinalities differ), 
# "ace" (assignment if cardinalities equal, where dist is maximal if cards differ),
# and "mat" (mass transfer, fractional matching that belongs to the
# Wasserstein distance obtained if point patterns are normalized to probability measures).
# -----------------------------------------------------------------

pppmatching <- function(X, Y, am, type = NULL, cutoff = NULL,
   q = NULL, mdist = NULL) {
   verifyclass(X, "ppp")
   verifyclass(Y, "ppp")
   n1 <- X$n
   n2 <- Y$n
   am <- as.matrix(am)
   if (length(am) == 0) {
      if (min(n1,n2) == 0) 
         am <- matrix(am, nrow=n1, ncol=n2)
      else
         stop("Adjacency matrix does not have the right dimensions")
   }
   if (dim(am)[1] != n1 || dim(am)[2] != n2)
      stop("Adjacency matrix does not have the right dimensions")
   am <- matrix(as.numeric(am), n1, n2)
   #am <- apply(am, c(1,2), as.numeric)
   res <- list("pp1" = X, "pp2" = Y, "matrix" = am, "type" = type, "cutoff" = cutoff, 
      "q" = q, "distance" = mdist)
   class(res) <- "pppmatching"
   res
}

# currently, for fractional matchings all the flows are plotted the same way
# irrespective of their weights
plot.pppmatching <- function(x, addmatch = NULL, main = NULL, ...) {
   if (is.null(main))
      main <- short.deparse(substitute(x))
   pp1 <- x$pp1
   pp2 <- x$pp2
   plot.owin(pp1$window, main = main, ...)
   here <- which((x$matrix > 0), arr.ind = TRUE)
   if (!is.null(addmatch)) {
      addhere <- which((addmatch > 0), arr.ind = TRUE)
      seg <- as.psp(from=pp1[addhere[,1]], to=pp2[addhere[,2]])
      plot(seg, add=TRUE, lty = 2, col="gray70")
   }
   if (length(here) > 0) {
     seg <- as.psp(from=pp1[here[,1]], to=pp2[here[,2]])
     plot(seg, add=TRUE, ...)
   }
   points(x$pp1, pch=20, col=2, ...)
   points(x$pp2, pch=20, col=4, ...)
   return(invisible(NULL))
}

print.pppmatching <- function(x, ...) {
   n1 <- x$pp1$n
   n2 <- x$pp2$n
   if (is.null(x$type) || is.null(x$q) || is.null(x$cutoff))
     cat("Generic matching of two planar point patterns \n")
   else
     cat(x$type, "-", x$q, " matching of two planar point patterns (cutoff = ",
       x$cutoff, ") \n", sep = "")
   cat("pp1:", n1, ngettext(n1, "point", "points"), "\n")
   cat("pp2:", n2, ngettext(n2, "point", "points"), "\n")
   print.owin(x$pp1$window)
   npair <- sum(x$matrix > 0)
   if (npair == 0)
     cat("matching is empty \n") 
   else {
     if (any(x$matrix != trunc(x$matrix)))
       cat("fractional matching,", npair, ngettext(npair, "flow", "flows"), "\n")
     else
       cat("point matching,", npair, ngettext(npair, "line", "lines"), "\n")
   }
   if (!is.null(x$distance))
     cat("distance:", x$distance, "\n") 
   return(invisible(NULL))
}

summary.pppmatching <- function(object, ...) {
   X <- object$pp1
   Y <- object$pp2
   n1 <- X$n
   n2 <- Y$n
   if (is.null(object$type) || is.null(object$q) || is.null(object$cutoff))
     cat("Generic matching of two planar point patterns \n")
   else
     cat(object$type, "-", object$q, " matching of two planar point patterns (cutoff = ",
       object$cutoff, ") \n", sep = "")
   cat("pp1:", n1, ngettext(n1, "point", "points"), "\n")
   cat("pp2:", n2, ngettext(n2, "point", "points"), "\n")
   print.owin(X$window)
   npair <- sum(object$matrix > 0)
   if (npair == 0)
     cat("matching is empty \n") 
   else {
     if (any(object$matrix != trunc(object$matrix))) {
       cat("fractional matching,", npair, ngettext(npair, "flow", "flows"), "\n")
     }
     else {
       cat("point matching,", npair, ngettext(npair, "line", "lines"), "\n")
       rowsum <- rowSums(object$matrix)
       colsum <- colSums(object$matrix)
       lt <- ifelse(min(rowsum) >= 1, TRUE, FALSE)
       ru <- ifelse(max(rowsum) <= 1, TRUE, FALSE)
       rt <- ifelse(min(colsum) >= 1, TRUE, FALSE)
       lu <- ifelse(max(colsum) <= 1, TRUE, FALSE)
       if (lt && ru && rt && lu)
         cat("matching is 1-1 \n")
       else if (any(lt, ru, rt, lu)) {
         cat("matching is",
                   ifelse(lt, " left-total", ""),
                   ifelse(lu, " left-unique", ""),
                   ifelse(rt, " right-total", ""),
                   ifelse(ru, " right-unique", ""),
                   "\n", sep="")
         }
     }
   }
   if (!is.null(object$distance))
     cat("distance:", object$distance, "\n") 
   return(invisible(NULL))
}


# -----------------------------------------------------------------
# matchingdist computes the distance associated with a certain kind of matching.
# Any of the arguments type, cutoff and order (if supplied) override the 
# the corresponding arguments in the matching.
# This function is useful for verifying the distance element of an
# object of class pppmatching as well as for comparing different
# (typically non-optimal) matchings.
# -----------------------------------------------------------------

matchingdist <- function(matching, type = NULL, cutoff = NULL, q = NULL) {
  verifyclass(matching, "pppmatching")
  if (is.null(type))
    if (is.null(matching$type))
      stop("Type of matching unknown. Distance cannot be computed")
    else
      type <- matching$type
  if (is.null(cutoff))
    if (is.null(matching$cutoff))
      stop("Cutoff value unknown. Distance cannot be computed")
    else
      cutoff <- matching$cutoff
  if (is.null(q))
    if (is.null(matching$q))
      stop("Order unknown. Distance cannot be computed")
    else
      q <- matching$q

  X <- matching$pp1
  Y <- matching$pp2
  n1 <- X$n
  n2 <- Y$n
  Lpexpect <- function(x, w, p) {
    f <- max(x)
      return(ifelse(f==0, 0, f * sum((x/f)^p * w)^(1/p)))
  }

  if (type == "spa") {
    n <- max(n1,n2) # divisor for Lpexpect
    if (n == 0)
      return(0)
    else if (min(n1,n2) == 0)
      return(cutoff)
    shortdim <- which.min(c(n1,n2))
    shortsum <- apply(matching$matrix, shortdim, sum)
    if (any(shortsum != 1))
      warning("matching does not attribute mass 1 to each point of point pattern with smaller cardinality")
#    dfix <- apply(crossdist(X,Y), c(1,2), function(x) { min(x,cutoff) })
    dfix <- pmin(crossdist(X,Y), cutoff)
    if (is.finite(q))
      resdist <- (Lpexpect(dfix, matching$matrix/n, q)^q + abs(n2-n1)/n * cutoff^q)^(1/q)
    else
      resdist <- ifelse(n1==n2, max(dfix[matching$matrix > 0]), cutoff)
  }
  else if (type == "ace") {
    n <- n1 # divisor for Lpexpect
    if (n1 != n2)
      return(cutoff)
    if (n == 0)
      return(0)
    rowsum <- rowSums(matching$matrix)
    colsum <- colSums(matching$matrix)
    if (any(c(rowsum, colsum) != 1))
      warning("matching is not 1-1")
#    dfix <- apply(crossdist(X,Y), c(1,2), function(x) { min(x,cutoff) })
    dfix <- pmin(crossdist(X,Y), cutoff)
    if (is.finite(q))
      resdist <- Lpexpect(dfix, matching$matrix/n, q)
    else
      resdist <- max(dfix[matching$matrix > 0])
  }
  else if (type == "mat") {
    n <- min(n1,n2) # divisor for Lpexpect
    if (min(n1,n2) == 0)
      return(NaN)
    shortdim <- which.min(c(n1,n2))
    shortsum <- apply(matching$matrix, shortdim, sum)
    if (any(shortsum != 1))
      warning("matching does not attribute mass 1 to each point of point pattern with smaller cardinality")
#    dfix <- apply(crossdist(X,Y), c(1,2), function(x) { min(x,cutoff) })
    dfix <- pmin(crossdist(X,Y), cutoff)
    if (is.finite(q))
      resdist <- Lpexpect(dfix, matching$matrix/n, q)
    else
      resdist <- max(dfix[matching$matrix > 0])
  }
  else 
    stop(paste("Unrecognised type", sQuote(type)))
  return(resdist)
}


# -----------------------------------------------------------------
# The main function for computation of distances and finding optimal
# matchings between point patterns: pppdist
# -----------------------------------------------------------------
#
# pppdist uses several helper functions not normally called by the user 
#
# The arguments of pppdist are 
#
# x and y of class ppp (the two point patterns for which we want to compute
#   a distance)
# The type of distance to be computed; any one of "spa" (default), "ace", "mat".
#   For details of this and the following two arguments see above (description
#   for class "pppmatching")
# cutoff and order q of the distance
# Set matching to TRUE if the full point matching (including distance)
#   should be returned; otherwise only the distance is returned
# If ccode is FALSE R code is used where available. This may be useful if q
#   is high (say above 10) and severe warning messages pop up. R can
#   (on most machines) deal with a higher number of significant digits per
#   number than C (at least with the code used below)
# precision should only be entered by advanced users. Empirically reasonable defaults
#   are used otherwise. As a rule of thumb, if ccode is TRUE, precision should
#   be the highest value that does not give an error (typically 9); if ccode
#   is FALSE, precision should be balanced (typically between 10 and 100) in
#   such a way that the sum of the  number of zeroes and pseudo-zeroes given in the
#   warning messages is minimal
# approximation: if q = Inf, by the distance of which order should 
#   the true distance be approximated. If approximation is Inf, brute force
#   computation is used, which is only practicable for point patterns with
#   very few points (see also the remarks just before the pppdist.prohorov
#   function below).  
# show.rprimal=TRUE shows at each stage of the algorithm what the current restricted
#   primal problem and its solution are (algorithm jumps between restricted primal
#   and dual problem until the solution to the restricted primal (a partial
#   matching of the point patterns) is a full matching)
# timelag gives the number of seconds of pause added each time a solution to
#   the current restricted primal is found (has only an effect if show.primal=TRUE) 
# -----------------------------------------------------------------

pppdist <- function(X, Y, type = "spa", cutoff = 1, q = 1, matching = TRUE,
  ccode = TRUE, auction = TRUE, precision = NULL, approximation = 10, show.rprimal = FALSE, timelag = 0) {

  verifyclass(X, "ppp")
  verifyclass(Y, "ppp")
  if (!ccode && type == "mat") {
    warning("R code is not available for type = ", dQuote("mat"), ". C code is
    used instead")
    ccode <- TRUE
  }
  if (!ccode && is.infinite(q) && is.infinite(approximation)) {
    warning("R code is not available for q = Inf and approximation = Inf. C code is
    used instead")
    ccode <- TRUE
  }
  if (ccode && is.infinite(q) && is.infinite(approximation) && type == "spa" && X$n != Y$n) {
    warning("approximation = Inf not available for type = ",
        dQuote("spa"), " and point patterns with differing cardinalities")
    approximation <- 10
  }
  if (is.infinite(q) && is.infinite(approximation) && type == "mat") {
    warning("approximation = Inf not available for type = ",
        dQuote("mat"))
    approximation <- 10
  }
  if (show.rprimal) {
    ccode <- FALSE
    auction <- FALSE
      if (type != "ace"){
        warning("show.rprimal = TRUE not available for type = ",
        dQuote(type), ". Type is changed to ", dQuote("ace"))
        type <- "ace"
    }
  }

  if (is.null(precision)) {
    if (ccode)
      precision <- trunc(log10(.Machine$integer.max))
    else {
      db <- .Machine$double.base
      minprec <- trunc(log10(.Machine$double.base^.Machine$double.digits))
      if (is.finite(q))
        precision <- min(max(minprec,2*q),(.Machine$double.max.exp-1)*log(db)/log(10))
      else
        precision <- min(max(minprec,2*approximation),(.Machine$double.max.exp-1)*log(db)/log(10))
      }
  }

  if (type == "spa") {
    if (X$n == 0 && Y$n == 0) {
      if (!matching)
        return(0)
      else {
        return(pppmatching(X, Y, matrix(0, nrow=0,ncol=0), type, cutoff, q, 0))
      }
    }
    n1 <- X$n
    n2 <- Y$n
    n <- max(n1,n2)
    dfix <- matrix(cutoff,n,n)
    if (min(n1,n2) > 0)
      dfix[1:n1,1:n2] <- crossdist(X,Y)
#    d <- dfix <- apply(dfix, c(1,2), function(x) { min(x,cutoff) })
    d <- dfix <- pmin(dfix,cutoff)
    if (is.infinite(q)) {
      if (n1 == n2 || matching)
        return(pppdist.prohorov(X, Y, n, d, type, cutoff, matching, ccode,
        auction, precision, approximation))
      else
        return(cutoff)
      # in the case n1 != n2 the distance is clear, and in a sense any
      # matching would be correct. We go here the extra mile and call
      # pppdist.prohorov in order to find (approximate) the matching
      # that is intuitively most interesting (i.e. the one that
      # pairs the points of the
      # smaller cardinality point pattern with the points of the larger
      # cardinality point pattern in such a way that the maximal pairing distance
      # is minimal (for q < Inf the q-th order pairing distance before the introduction
      # of dummy points is automatically minimal if it is minimal after the
      # introduction of dummy points)
      # which would be the case for the obtained pairing if q < Inf
    }
  }
  else if (type == "ace") {
    if (X$n != Y$n) {
      if (!matching)
        return(cutoff)
      else {
        return(pppmatching(X, Y, matrix(0, nrow=X$n, ncol=Y$n), type, cutoff, q, cutoff))
      }
    }
    if (X$n == 0) {
      if (!matching)
        return(0)
      else {
        return(pppmatching(X, Y, matrix(0, nrow=0,ncol=0), type, cutoff, q, 0))
      }
    }
    n <- n1 <- n2 <- X$n
    dfix <- crossdist(X,Y)
#    d <- dfix <- apply(dfix, c(1,2), function(x) { min(x,cutoff) })
    d <- dfix <- pmin(dfix, cutoff)
    if (is.infinite(q))
      return(pppdist.prohorov(X, Y, n, d, type, cutoff, matching, ccode,
      auction, precision, approximation))
  }
  else if (type == "mat") {
    if (!ccode)
      warning("R code is not available for type = ", dQuote("mat"), ". C code is used instead")
    if (auction)
      warning("Auction algorithm is not available for type = ", dQuote("mat"), ". Primal-dual algorithm is used instead")
    return(pppdist.mat(X, Y, cutoff, q, matching, precision, approximation))
  }
  else stop(paste("Unrecognised type", sQuote(type)))

  d <- d/max(d)
  d <- round((d^q)*(10^precision))
  nzeroes <- sum(d == 0 & dfix > 0)
  if(nzeroes > 0)
    warning(paste(nzeroes, ngettext(nzeroes, "zero", "zeroes"), "introduced, while rounding the q-th powers of distances"))
  if(ccode & any(d > .Machine$integer.max))
    stop("integer overflow, while rounding the q-th powers of distances")
  if(!ccode) {
    if (any(is.infinite(d)))
      stop("Inf obtained, while taking the q-th powers of distances")
    maxd <- max(d)
    npszeroes <- sum(maxd/d[d>0] >= .Machine$double.base^.Machine$double.digits)
    if (npszeroes > 0)
      warning(paste(npszeroes, ngettext(npszeroes, "pseudo-zero", "pseudo-zeroes"), "introduced, while taking the q-th powers of distances"))
      # a pseudo-zero is a value that is positive but contributes nothing to the
      # q-th order average because it is too small compared to the other values
  }

  Lpmean <- function(x, p) {
    f <- max(x)
    return(ifelse(f==0, 0, f * mean((x/f)^p)^(1/p)))
  }
    
  if (show.rprimal && type == "ace") {
    assig <- acedist.show(X, Y, n, d, timelag)
    am <- matrix(0, n, n)
    am[cbind(1:n, assig[1:n])] <- 1
  }
  else if (ccode) {
  	if (auction) {
  	  dupper <- max(d)/10	
  	  lasteps <- 1/(n+1)
  	  epsfac <- 10
      epsvec <- lasteps
      # Bertsekas: from dupper/2 to 1/(n+1) divide repeatedly by a constant
      while (lasteps < dupper) {
        lasteps <- lasteps*epsfac
        epsvec <- c(epsvec,lasteps)
      }
      epsvec <- rev(epsvec)[-1]
      neps <- length(epsvec)
      stopifnot(neps >= 1)
  	  d <- max(d)-d
  	  # auctionbf uses a "desire matrix"
  	  res <- .C("auctionbf",
                    as.integer(d),
                    as.integer(n),
                    pers_to_obj = as.integer(rep(-1,n)),
                    price = as.double(rep(0,n)),
                    profit = as.double(rep(0,n)),
                    as.integer(neps),
                    as.double(epsvec))
      am <- matrix(0, n, n)
      am[cbind(1:n,res$pers_to_obj+1)] <- 1
    }
    else {           
      res <- .C("dwpure",
             as.integer(d),
             as.integer(rep.int(1,n)),
             as.integer(rep.int(1,n)),
             as.integer(n),
             as.integer(n),
             flowmatrix = as.integer(integer(n^2)))
      am <- matrix(res$flowmatrix, n, n)
    }
  }
  else {
    assig <- acedist.noshow(X, Y, n, d)
    am <- matrix(0, n, n)
    am[cbind(1:n, assig[1:n])] <- 1
  }
  resdist <- Lpmean(dfix[am == 1], q)
  if (!matching)
    return(resdist)
  else {
    amsmall <- suppressWarnings(matrix(am[1:n1,1:n2], nrow=n1, ncol=n2))
    # previous line solves various problems associated with min(n1,n2) = 0 or = 1
    return(pppmatching(X, Y, amsmall, type, cutoff, q, resdist))
  }
}   

#
#
# ===========================================================
# ===========================================================
#                   Anything below:
#    Internal functions usually not to be called by user
# ===========================================================
# ===========================================================
#

#
#   Called if show.rprimal is true
#

acedist.show <- function(X, Y, n, d, timelag = 0) {
      plot(pppmatching(X, Y, matrix(0, n, n)))
      # initialization of dual variables
      u <- apply(d, 1, min)
      d <- d - u
      v <- apply(d, 2, min)
      d <- d - rep(v, each=n)
      # the main loop
      feasible <- FALSE
      while (!feasible) {
         rpsol <- maxflow(d)  # rpsol = restricted primal, solution
         am <- matrix(0, n, n)
         for (i in 1:n) {
            if (rpsol$assignment[i] > -1) am[i, rpsol$assignment[i]] <- TRUE
         }
         Sys.sleep(timelag)
         channelmat <- (d == 0 & !am)
         plot(pppmatching(X, Y, am), addmatch = channelmat)
         # if the solution of the restricted primal is not feasible for  
         # the original primal, update dual variables
         if (min(rpsol$assignment) == -1) {
            w1 <- which(rpsol$fi_rowlab > -1)
            w2 <- which(rpsol$fi_collab == -1)
            subtractor <- min(d[w1, w2])
            d[w1,] <- d[w1,] - subtractor
            d[,-w2] <- d[,-w2] + subtractor 
         }
         # otherwise break the loop
         else {
            feasible <- TRUE
         }   
      }
      return(rpsol$assignment)
}

#
#   R-version of hungarian algo without the pictures
#   useful if q is large
#

acedist.noshow <- function(X, Y, n, d) {
      # initialization of dual variables
      u <- apply(d, 1, min)
      d <- d - u
      v <- apply(d, 2, min)
      d <- d - rep(v, each=n)
      # the main loop
      feasible <- FALSE
      while (!feasible) {
         rpsol <- maxflow(d)  # rpsol = restricted primal, solution
# ~~~~~~~~~ deleted by AJB ~~~~~~~~~~~~~~~~~
#         am <- matrix(0, n, n)
#         for (i in 1:n) {
#            if (rpsol$assignment[i] > -1) am[i, rpsol$assignment[i]] <- TRUE
#         }
#         channelmat <- (d == 0 & !am)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~         
         # if the solution of the restricted primal is not feasible for  
         # the original primal, update dual variables
         if (min(rpsol$assignment) == -1) {
            w1 <- which(rpsol$fi_rowlab > -1)
            w2 <- which(rpsol$fi_collab == -1)
            subtractor <- min(d[w1, w2])
            d[w1,] <- d[w1,] - subtractor
            d[,-w2] <- d[,-w2] + subtractor 
         }
         # otherwise break the loop
         else {
            feasible <- TRUE
         }   
      }
      return(rpsol$assignment)
}

#  
# Solution of restricted primal
# 

maxflow <- function(costm) {
  stopifnot(is.matrix(costm))
  stopifnot(nrow(costm) == ncol(costm))
  if(!all(apply(costm == 0, 1, any)))
    stop("Each row of the cost matrix must contain a zero")
  
  m <- dim(costm)[1]   # cost matrix is square m * m
  assignment <- rep.int(-1, m)   # -1 means no pp2-point assigned to i-th pp1-point
   # initial assignment or rowlabel <- source label (= 0) where not possible
   for (i in 1:m) {
      j <- match(0, costm[i,])
      if (!(j %in% assignment))
         assignment[i] <- j
   }
   newlabelfound <- TRUE
   while (newlabelfound) {
     rowlab <- rep.int(-1, m)   # -1 means no label given, 0 stands for source label
     collab <- rep.int(-1, m)
     rowlab <- ifelse(assignment == -1, 0, rowlab)
     # column and row labeling procedure until either breakthrough occurs
     # (which means that there is a better point assignment, i.e. one that
     # creates more point pairs than the current one (flow can be increased))
     # or no more labeling is possible
     breakthrough <- -1
     while (newlabelfound && breakthrough == -1) { 
         newlabelfound <- FALSE
         for (i in 1:m) {
            if (rowlab[i] != -1) {
               for (j in 1:m) {
                  if (costm[i,j] == 0 && collab[j] == -1) {
                     collab[j] <- i
                     newlabelfound <- TRUE
                     if (!(j %in% assignment) && breakthrough == -1)
                        breakthrough <- j
                  }
               }
            }
         }
         for (j in 1:m) {
            if (collab[j] != -1) {
               for (i in 1:m) {
                  if (assignment[i] == j && rowlab[i] == -1) {
                     rowlab[i] <- j
                     newlabelfound <- TRUE
                  }
               }
            }
         }
      }
      # if the while-loop was left due to breakthrough,
      # reassign points (i.e. redirect flow) and restart labeling procedure
      if (breakthrough != -1) {
         l <- breakthrough
         while (l != 0) {
            k <- collab[l]
            assignment[k] <- l
            l <- rowlab[k] 
         }
      }
   }
   # the outermost while-loop is left, no more labels can be given; hence
   # the maximal number of points are paired given the current restriction
   # (flow is maximal given the current graph)
   return(list("assignment"=assignment, "fi_rowlab"=rowlab, "fi_collab"=collab))  
}

# 
# Prohorov distance computation/approximation (called if q = Inf in pppdist
#   and type = "spa" or "ace")
# Exact brute force computation of distance if approximation = Inf,
#   scales very badly, should not be used for cardinality n larger than 10-12
# Approximation by order q distance gives often (if the warning messages 
#   are not too extreme) the right matching and therefore the exact Prohorov distance,
#   but in very rare cases the result can be very wrong. However, it is always
#   an exact upper bound of the Prohorov distance (since based on *a* pairing
#   as opposed to optimal pairing.
#

pppdist.prohorov <- function(X, Y, n, dfix, type, cutoff = 1, matching = TRUE,
  ccode = TRUE, auction = TRUE, precision = 9, approximation = 10) {
  n1 <- X$n
  n2 <- Y$n
  d <- dfix/max(dfix)
  if (is.finite(approximation)) {
      warning(paste("distance with parameter q = Inf is approximated by distance with parameter q =", approximation))
    d <- round((d^approximation)*(10^precision)) 
    nzeroes <- sum(d == 0 & dfix > 0)
    if (nzeroes > 0)
      warning(paste(nzeroes, ngettext(nzeroes, "zero", "zeroes"), "introduced, while rounding distances"))
    if (ccode) {
      if (any(d > .Machine$integer.max))
        stop("integer overflow, while rounding the q-th powers of distances")
      if (auction) {
      	dupper <- max(d)/10
  	    lasteps <- 1/(n+1)
  	    epsfac <- 10
        epsvec <- lasteps
        # Bertsekas: from dupper/2 to 1/(n+1) divide repeatedly by a constant
        while (lasteps < dupper) {
          lasteps <- lasteps*epsfac
          epsvec <- c(epsvec,lasteps)
        }
        epsvec <- rev(epsvec)[-1]
        neps <- length(epsvec)
        stopifnot(neps >= 1)
  	    d <- max(d)-d
  	    # auctionbf uses a "desire matrix"
  	    res <- .C("auctionbf",
                      as.integer(d),
                      as.integer(n),
                      pers_to_obj = as.integer(rep(-1,n)),
                      price = as.double(rep(0,n)),
                      profit = as.double(rep(0,n)),
                      as.integer(neps),
                      as.double(epsvec))
        am <- matrix(0, n, n)
        am[cbind(1:n,res$pers_to_obj+1)] <- 1
      }
      else {           
        res <- .C("dwpure",
                 as.integer(d),
                 as.integer(rep.int(1,n)),
                 as.integer(rep.int(1,n)),
                 as.integer(n),
                 as.integer(n),
                 flowmatrix = as.integer(integer(n^2)))
        am <- matrix(res$flowmatrix, n, n)
      }
    }
    else {
      if (any(is.infinite(d)))
        stop("Inf obtained, while taking the q-th powers of distances")
      maxd <- max(d)
      npszeroes <- sum(maxd/d[d>0] >= .Machine$double.base^.Machine$double.digits)
      if (npszeroes > 0)
        warning(paste(npszeroes, ngettext(npszeroes, "pseudo-zero", "pseudo-zeroes"), "introduced, while taking the q-th powers of distances"))
      assig <- acedist.noshow(X, Y, n, d)
      am <- matrix(0, n, n)
      am[cbind(1:n, assig[1:n])] <- 1
    }
  }
  else {
    d <- round(d*(10^precision))
    nzeroes <- sum(d == 0 & dfix > 0)
    if (nzeroes > 0)
      warning(paste(nzeroes, ngettext(nzeroes, "zero", "zeroes"), "introduced, while rounding distances"))
    if (any(d > .Machine$integer.max))
      stop("integer overflow, while rounding the q-th powers of distances")
    res <- .C("dinfty_R",
             as.integer(d),
             as.integer(n),
             assignment = as.integer(rep.int(-1,n)))
    assig <- res$assignment
    am <- matrix(0, n, n)
    am[cbind(1:n, assig[1:n])] <- 1
  }
  if (n1 == n2)
    resdist <- max(dfix[am == 1])
  else
    resdist <- cutoff
  if (!matching)
    return(resdist)
  else {
    amsmall <- suppressWarnings(matrix(am[1:n1,1:n2], nrow=n1, ncol=n2))
    # previous line solves various problems associated with min(n1,n2) = 0 or = 1
    return(pppmatching(X, Y, amsmall, type, cutoff, Inf, resdist))
  }
}   

# 
# Computation of "pure Wasserstein distance" for any q (called if type="mat"
#   in pppdist, no matter if q finite or not).
# If q = Inf, approximation using ccode is enforced
# (approximation == Inf is not allowed here).
#

pppdist.mat <- function(X, Y, cutoff = 1, q = 1, matching = TRUE, precision = 9,
  approximation = 10) {
  n1 <- X$n
  n2 <- Y$n
  n <- min(n1,n2)
  if (n == 0) {
    if (!matching)
      return(NaN)
    else
      return(pppmatching(X, Y, matrix(0, nrow=0,ncol=0), "mat", cutoff, q, NaN))
  }

  dfix <- crossdist(X,Y)
#  d <- dfix <- apply(dfix, c(1,2), function(x) { min(x,cutoff) })
  d <- dfix <- pmin(dfix, cutoff)
  d <- d/max(d)
  if (is.infinite(q)) {
    if (is.infinite(approximation))
      stop("approximation = Inf")
    warning(paste("distance with parameter q = Inf is approximated by distance with parameter q =", approximation))
    d <- round((d^approximation)*(10^precision)) 
    nzeroes <- sum(d == 0 & dfix > 0)
    if (nzeroes > 0)
      warning(paste(nzeroes, "zeroes introduced, while rounding distances"))
    if (any(d > .Machine$integer.max))
      stop("integer overflow, while rounding the q-th powers of distances")
    gcd <- greatest.common.divisor(n1,n2)
    mass1 <- n2/gcd
    mass2 <- n1/gcd

    res <- .C("dwpure",
             as.integer(d),
             as.integer(rep.int(mass1,n1)),
             as.integer(rep.int(mass2,n2)),
             as.integer(n1),
             as.integer(n2),
             flowmatrix = as.integer(integer(n1*n2)))
    am <- matrix(res$flowmatrix/(max(n1,n2)/gcd), n1, n2)
    resdist <- max(dfix[am > 0])
  }
  else {
    d <- round((d^q)*(10^precision))
    nzeroes <- sum(d == 0 & dfix > 0)
    if(nzeroes > 0)
      warning(paste(nzeroes, ngettext(nzeroes, "zero", "zeroes"), "introduced, while rounding the q-th powers of distances"))
    if(any(d > .Machine$integer.max))
      stop("integer overflow, while rounding the q-th powers of distances")
    gcd <- greatest.common.divisor(n1,n2)
    mass1 <- n2/gcd
    mass2 <- n1/gcd

    Lpexpect <- function(x, w, p) {
      f <- max(x)
      return(ifelse(f==0, 0, f * sum((x/f)^p * w)^(1/p)))
    }

    res <- .C("dwpure",
             as.integer(d),
             as.integer(rep.int(mass1,n1)),
             as.integer(rep.int(mass2,n2)),
             as.integer(n1),
             as.integer(n2),
             flowmatrix = as.integer(integer(n1*n2)))
    am <- matrix(res$flowmatrix/(max(n1,n2)/gcd), n1, n2)
    # our "adjacency matrix" in this case is standardized to have
    # rowsum 1 if n1 <= n2 and colsum 1 if n1 >= n2
    resdist <- Lpexpect(dfix, am/n, q)
  }
  if (!matching)
    return(resdist)
  else {
   amsmall <- suppressWarnings(matrix(am[1:n1,1:n2], nrow=n1, ncol=n2))
   # previous line solves various problems associated with min(n1,n2) = 0 or = 1
   return(pppmatching(X, Y, amsmall, "mat", cutoff, q, resdist))
  }
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/ppx.R"
#
#   ppx.R
#
#  class of general point patterns in any dimension
#
#  $Revision: 1.44 $  $Date: 2014/11/11 01:25:08 $
#

ppx <- local({
  
  ctype.table <- c("spatial", "temporal", "local", "mark")
  ctype.real  <- c(TRUE,      TRUE,       FALSE,   FALSE)

  ppx <- function(data, domain=NULL, coord.type=NULL, simplify=FALSE) {
    data <- as.hyperframe(data)
    # columns suitable for spatial coordinates
    suitable <- with(unclass(data),
                     vtype == "dfcolumn" &
                     (vclass == "numeric" | vclass == "integer"))
    if(is.null(coord.type)) {
      # assume all suitable columns of data are spatial coordinates
      # and all other columns are marks.
      ctype <- ifelse(suitable, "spatial", "mark")
    } else {
      stopifnot(is.character(coord.type))
      stopifnot(length(coord.type) == ncol(data))
      ctypeid <- pmatch(coord.type, ctype.table, duplicates.ok=TRUE)
      # validate
      if(any(uhoh <- is.na(ctypeid)))
        stop(paste("Unrecognised coordinate",
                   ngettext(sum(uhoh), "type", "types"),
                   commasep(sQuote(coord.type[uhoh]))))
      if(any(uhoh <- (!suitable & ctype.real[ctypeid]))) {
        nuh <- sum(uhoh)
        stop(paste(ngettext(nuh, "Coordinate", "Coordinates"),
                   commasep(sQuote(names(data)[uhoh])),
                   ngettext(nuh, "does not", "do not"),
                   "contain real numbers"))
      }
      ctype <- ctype.table[ctypeid]
    }
    ctype <- factor(ctype, levels=ctype.table)
    #
    if(simplify && all(ctype == "spatial")) {
       # attempt to reduce to ppp or pp3
      d <- length(ctype)
      if(d == 2) {
        ow <- try(as.owin(domain), silent=TRUE)
        if(!inherits(ow, "try-error")) {
          X <- try(as.ppp(as.data.frame(data), W=ow))
          if(!inherits(X, "try-error"))
            return(X)
        }
      } else if(d == 3) {
        bx <- try(as.box3(domain), silent=TRUE)
        if(!inherits(bx, "try-error")) {
          m <- as.matrix(as.data.frame(data))
          X <- try(pp3(m[,1], m[,2], m[,3], bx))
          if(!inherits(X, "try-error"))
            return(X)
        }
      }
    }
    out <- list(data=data, ctype=ctype, domain=domain)
    class(out) <- "ppx"
    return(out)
  }

  ppx
})


is.ppx <- function(x) { inherits(x, "ppx") }

nobjects.ppx <- npoints.ppx <- function(x) { nrow(x$data) }

print.ppx <- function(x, ...) {
  cat("Multidimensional point pattern\n")
  sd <- summary(x$data)
  np <- sd$ncases
  nama <- sd$col.names
  cat(paste(np, ngettext(np, "point", "points"), "\n"))
  if(any(iscoord <- (x$ctype == "spatial")))
    cat(paste(sum(iscoord), "-dimensional space coordinates ",
              paren(paste(nama[iscoord], collapse=",")), "\n", sep=""))
  if(any(istime <- (x$ctype == "temporal")))
    cat(paste(sum(istime), "-dimensional time coordinates ",
              paren(paste(nama[istime], collapse=",")), "\n", sep=""))
  if(any(islocal <- (x$ctype == "local"))) 
    cat(paste(sum(islocal), ngettext(sum(islocal), "column", "columns"),
              "of local coordinates:",
              commasep(sQuote(nama[islocal])), "\n"))
  if(any(ismark <- (x$ctype == "mark"))) 
    cat(paste(sum(ismark), ngettext(sum(ismark), "column", "columns"),
              "of marks:",
              commasep(sQuote(nama[ismark])), "\n"))
  if(!is.null(x$domain)) {
    cat("Domain:\n\t")
    print(x$domain)
  }
  invisible(NULL)
}

summary.ppx <- function(object, ...) { print(object, ...) }

plot.ppx <- function(x, ...) {
  xname <- short.deparse(substitute(x))
  coo <- coords(x, local=FALSE)
  dom <- x$domain
  m <- ncol(coo)
  if(m == 1) {
    coo <- coo[,1]
    ran <- diff(range(coo))
    ylim <- c(-1,1) * ran/20
    do.call("plot.default",
            resolve.defaults(list(coo, numeric(length(coo))),
                             list(...),
                             list(asp=1, ylim=ylim,
                                  axes=FALSE, xlab="", ylab="")))
    axis(1, pos=ylim[1])
  } else if(m == 2) {
    if(is.null(dom)) {
      # plot x, y coordinates only
      nama <- names(coo)
      do.call.matched("plot.default",
                      resolve.defaults(list(x=coo[,1], y=coo[,2], asp=1),
                                       list(...),
                                       list(main=xname),
                                       list(xlab=nama[1], ylab=nama[2])))
    } else {
      add <- resolve.defaults(list(...), list(add=FALSE))$add
      if(!add) {
        # plot domain, whatever it is
        do.call("plot", resolve.defaults(list(dom),
                                       list(...),
                                       list(main=xname)))
      }
      # convert to ppp
      x2 <- ppp(coo[,1], coo[,2], window=as.owin(dom),
                marks=as.data.frame(marks(x)), check=FALSE)
      # invoke plot.ppp
      return(do.call("plot", resolve.defaults(list(x2),
                                              list(add=TRUE),
                                              list(...))))
    }
  } else if(m == 3) {
    # convert to pp3
    if(is.null(dom))
      dom <- box3(range(coo[,1]), range(coo[,2]), range(coo[,3]))
    x3 <- pp3(coo[,1], coo[,2], coo[,3], dom)
    # invoke plot.pp3
    nama <- names(coo)
    do.call("plot",
            resolve.defaults(list(x3),
                             list(...),
                             list(main=xname),
                             list(xlab=nama[1], ylab=nama[2], zlab=nama[3])))
  } else stop(paste("Don't know how to plot a general point pattern in",
               ncol(coo), "dimensions"))
  return(invisible(NULL))
}

"[.ppx" <- function (x, i, ...) {
  da <- x$data
  daij <- da[i, , drop=FALSE]
  out <- list(data=daij, ctype=x$ctype, domain=x$domain)
  class(out) <- "ppx"
  return(out)
}

domain <- function(X, ...) { UseMethod("domain") }

domain.ppx <- function(X, ...) { X$domain }

coords <- function(x, ...) {
  UseMethod("coords")
}

coords.ppx <- function(x, ..., spatial=TRUE, temporal=TRUE, local=TRUE) {
  ctype <- x$ctype
  chosen <- (ctype == "spatial" & spatial) |
            (ctype == "temporal" & temporal) | 
            (ctype == "local" & local) 
  as.data.frame(x$data[, chosen])
}

coords.ppp <- function(x, ...) { data.frame(x=x$x,y=x$y) }

"coords<-" <- function(x, ..., value) {
  UseMethod("coords<-")
}

"coords<-.ppp" <- function(x, ..., value) {
  win <- x$window
  if(is.null(value)) {
    # empty pattern
    return(ppp(window=win))
  }
  value <- as.data.frame(value)
  if(ncol(value) != 2)
    stop("Expecting a 2-column matrix or data frame, or two vectors")
  result <- as.ppp(value, win)
  marks(result) <- marks(x)
  return(result)
}

"coords<-.ppx" <- function(x, ..., spatial=TRUE, temporal=TRUE, local=TRUE, value) {
  ctype <- x$ctype
  chosen <- (ctype == "spatial" & spatial) |
            (ctype == "temporal" & temporal) | 
            (ctype == "local" & local) 
  x$data[, chosen] <- value
  return(x)
}

as.hyperframe.ppx <- function(x, ...) { x$data }

as.data.frame.ppx <- function(x, ...) { as.data.frame(x$data, ...) } 

as.matrix.ppx <- function(x, ...) { as.matrix(as.data.frame(x, ...)) }

marks.ppx <- function(x, ..., drop=TRUE) {
  ctype <- x$ctype
  chosen <- (ctype == "mark")
  if(!any(chosen)) return(NULL)
  x$data[, chosen, drop=drop]
}

"marks<-.ppx" <- function(x, ..., value) {
  ctype <- x$ctype
  retain <- (ctype != "mark")
  coorddata <- x$data[, retain, drop=TRUE]
  if(is.null(value)) {
    newdata <- coorddata
    newctype <- ctype[retain]
  } else {
    if(is.matrix(value) && nrow(value) == nrow(x$data)) {
      # assume matrix is to be treated as data frame
      value <- as.data.frame(value)
    }
    if(!is.data.frame(value) && !is.hyperframe(value)) 
      value <- hyperframe(marks=value)
    if(is.hyperframe(value) || is.hyperframe(coorddata)) {
      value <- as.hyperframe(value)
      coorddata <- as.hyperframe(coorddata)
    }
    if(ncol(value) == 0) {
      newdata <- coorddata
      newctype <- ctype[retain]
    } else {
      newdata <- cbind(coorddata, value)
      newctype <- factor(c(as.character(ctype[retain]),
                           rep.int("mark", ncol(value))),
                         levels=levels(ctype))
    }
  }
  out <- list(data=newdata, ctype=newctype, domain=x$domain)
  class(out) <- "ppx"
  return(out)
}

unmark.ppx <- function(X) {
  marks(X) <- NULL
  return(X)
}

markformat.ppx <- function(x) {
  mf <- x$markformat
  if(is.null(mf)) 
    mf <- markformat(marks(x))
  return(mf)
}

boxx <- function(..., unitname=NULL) {
  if(length(list(...)) == 0)
    stop("No data")
  ranges <- data.frame(...)
  nama <- names(list(...))
  if(is.null(nama) || !all(nzchar(nama)))
    names(ranges) <- paste("x", 1:ncol(ranges),sep="")
  if(nrow(ranges) != 2)
    stop("Data should be vectors of length 2")
  if(any(unlist(lapply(ranges, diff)) <= 0))
    stop("Illegal range: Second element <= first element")
  out <- list(ranges=ranges, units=as.units(unitname))
  class(out) <- "boxx"
  return(out)
}

print.boxx <- function(x, ...) {
  m <- ncol(x$ranges)
  cat(paste(m, "-dimensional box:\n", sep=""))
  bracket <- function(z) paste("[",
                               paste(signif(z, 5), collapse=", "),
                               "]", sep="")
  v <- paste(unlist(lapply(x$ranges, bracket)), collapse=" x ")
  s <- summary(unitname(x))
  cat(paste(v, s$plural, s$explain, "\n"))
  invisible(NULL)
}

unitname.boxx <- function(x) { x$units }

"unitname<-.boxx" <- function(x, value) {
  x$units <- as.units(value)
  return(x)
}

unitname.ppx <- function(x) { unitname(x$domain) }

"unitname<-.ppx" <- function(x, value) {
  d <- x$domain
  unitname(d) <- value
  x$domain <- d
  return(x)
}

as.owin.boxx <- function(W, ..., fatal=TRUE) {
  ra <- W$ranges
  if(length(ra) == 2) return(owin(ra[[1]], ra[[2]]))
  if(fatal) stop(paste("Cannot interpret box of dimension",
                       length(ra), "as a window"))
  return(NULL)
}

sidelengths.boxx <- function(x) {
  stopifnot(inherits(x, "boxx"))
  y <- unlist(lapply(x$ranges, diff))
  return(y)
}
  
volume.boxx <- function(x) {
  prod(sidelengths(x))
}

diameter.boxx <- function(x) {
  d <- sqrt(sum(sidelengths(x)^2))
  return(d)
}

shortside.boxx <- function(x) {
  return(min(sidelengths(x)))
}

eroded.volumes.boxx <- function(x, r) {
  len <- sidelengths(x)
  ero <- sapply(as.list(len), function(z, r) { pmax.int(0, z - 2 * r)}, r=r)
  apply(ero, 1, prod)
}

runifpointx <- function(n, domain, nsim=1) {
  if(nsim > 1) {
    result <- vector(mode="list", length=nsim)
    for(i in 1:n) result[[i]] <- runifpointx(n, domain)
    result <- as.solist(result)
    names(result) <- paste("Simulation", 1:n)
    return(result)
  }
  stopifnot(inherits(domain, "boxx"))
  coo <- lapply(domain$ranges,
                function(ra, n) { runif(n, min=ra[1], max=ra[2]) },
                n=n)
  df <- do.call("data.frame", coo)
  ppx(df, domain)
}

rpoisppx <- function(lambda, domain, nsim=1) {
  if(nsim > 1) {
    result <- vector(mode="list", length=nsim)
    for(i in 1:n) result[[i]] <- rpoisppx(lambda, domain)
    result <- as.solist(result)
    names(result) <- paste("Simulation", 1:n)
    return(result)
  }
  stopifnot(inherits(domain, "boxx"))
  vol <- volume.boxx(domain)
  stopifnot(is.numeric(lambda) && length(lambda) == 1 && lambda >= 0)
  n <- rpois(1, lambda * vol)
  runifpointx(n, domain)
}

unique.ppx <- function(x, ..., warn=FALSE) {
  dup <- duplicated(x, ...)
  if(!any(dup)) return(x)
  if(warn) warning(paste(sum(dup), "duplicated points were removed"),
                   call.=FALSE)
  y <- x[!dup]
  return(y)
}

duplicated.ppx <- function(x, ...) {
  dup <- duplicated(as.data.frame(x), ...)
  return(dup)
}

anyDuplicated.ppx <- function(x, ...) {
  anyDuplicated(as.data.frame(x), ...)
}


multiplicity.ppx <- function(x) {
  mul <- multiplicity(as.data.frame(x))
  return(mul)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/predict.ppm.R"
#
#    predict.ppm.S
#
#	$Revision: 1.89 $	$Date: 2014/12/31 04:06:17 $
#
#    predict.ppm()
#	   From fitted model obtained by ppm(),	
#	   evaluate the fitted trend or conditional intensity 
#	   at a grid/list of other locations 
#
#
# -------------------------------------------------------------------

predict.ppm <- local({
  ##
  ##  extract undocumented/outdated arguments, and trap others
  ##
  xtract <- function(..., newdata=NULL, sumobj=NULL, E=NULL, total=NULL,
                     getoutofjail=FALSE) {
    if(!is.null(newdata))
      warning(paste("The use of the argument", sQuote("newdata"),
                    "is out-of-date. See help(predict.ppm)"))
    if(!is.null(total)) 
      message(paste("The use of the argument", sQuote("total"),
                    "is out-of-date. See help(predict.ppm)"))
    trap.extra.arguments(..., .Context="In predict.ppm")
    return(list(sumobj=sumobj, E=E, total=total, getoutofjail=getoutofjail))
  }
  ##
  ## confidence/prediction intervals for number of points
  predconfPois <- function(region, object, level,
                           what=c("estimate", "se",
                             "confidence", "prediction")) {
    what <- match.arg(what)
    stopifnot(0 < level && level < 1)
    lam <- predict(object, window=region)
    mu.hat <- integral.im(lam)
    if(what == "estimate") return(mu.hat)
    mo <- model.images(object, W=as.owin(lam))
    ZL <- unlist(lapply(mo,
                        function(z, w) integral.im(eval.im(z * w)),
                        w = lam))
    ZL <- matrix(ZL, nrow=1)
    var.muhat <- as.numeric(ZL %*% vcov(object) %*% t(ZL))
    sd.muhat <- sqrt(var.muhat)
    if(what == "se") return(sd.muhat)
    alpha2 <- (1-level)/2
    pp <- sort(c(alpha2, 1-alpha2))
    out <- switch(what,
                  confidence = mu.hat + qnorm(pp) * sd.muhat,
                  prediction = qmixpois(pp, mu.hat, sd.muhat, I))
    names(out) <- paste0(signif(100 * pp, 3), "%")
    out
  }

  typeaccept <- c("trend", "cif", "lambda", "intensity", "count", "se", "SE")
  typeuse    <- c("trend", "cif", "cif",    "intensity", "count", "se", "se")
  typepublic <- c("trend", "cif", "intensity", "count")
  
  predict.ppm <- function(object, window=NULL, ngrid=NULL, locations=NULL,
                          covariates=NULL,
                          type=c("trend", "cif", "intensity", "count"),
                          se=FALSE,
                          interval=c("none", "confidence", "prediction"),
                          level = 0.95,
                          X=data.ppm(object),
                          correction,
                          ..., new.coef=NULL, check=TRUE, repair=TRUE) {
    interval <- match.arg(interval)
    ## extract undocumented arguments 
    xarg <- xtract(...)
    sumobj <- xarg$sumobj
    E      <- xarg$E
    total  <- xarg$total
    getoutofjail <- xarg$getoutofjail
    ## match 'type' argument including 'legacy' options
    seonly <- FALSE
    if(misstype <- missing(type)) type <- type[1] else {
      if(length(type) > 1) stop("Argument 'type' should be a single value")
      mt <- pmatch(type, typeaccept)
      if(is.na(mt)) stop("Argument 'type' should be one of",
                         commasep(sQuote(typepublic), " or "))
      type <- typeuse[mt]
      if(type == "se") {
        if(!getoutofjail)
          message(paste("Outdated syntax:",
                        "type='se' should be replaced by se=TRUE;",
                        "then the standard error is predict(...)$se"))
        type <- "trend"
        se <- TRUE
        seonly <- TRUE
      }
    } 
    if(!is.null(total)) {
      message("Outdated argument 'total': use 'window' and set type='count'")
      type <- "count" 
      if(!is.logical(total))
        window <- if(is.tess(total)) total else as.owin(total)
    }
    ##
    model <- object
    verifyclass(model, "ppm")
    ##  
    if(check && damaged.ppm(object)) {
      if(!repair)
        stop("object format corrupted; try update(object, use.internal=TRUE)")
      message("object format corrupted; repairing it.")
      object <- update(object, use.internal=TRUE)
    }

    if(missing(correction) || is.null(correction))
      correction <- object$correction
  
    fitcoef <- coef(object)
    if(!is.null(new.coef)) {
      ## validate coefs
      if(length(new.coef) != length(fitcoef))
        stop(paste("Argument new.coef has wrong length",
                   length(new.coef), ": should be", length(fitcoef)))
      coeffs <- new.coef
    } else {
      coeffs <- fitcoef
    }

    ##       find out what kind of model it is
    if(is.null(sumobj))
      sumobj <- summary(model, quick="entries")  # undocumented hack!
#    stationary  <- sumobj$stationary
    poisson     <- sumobj$poisson
    marked      <- sumobj$marked
    multitype   <- sumobj$multitype
    notrend     <- sumobj$no.trend
    changedcoef <- sumobj$changedcoef || !is.null(new.coef)
    trivial     <- poisson && notrend
  
    need.covariates <- sumobj$uses.covars
    covnames.needed <- sumobj$covars.used

    if(sumobj$antiquated)
      warning("The model was fitted by an out-of-date version of spatstat")  

    ##       determine mark space
    if(marked) {
      if(!multitype)
        stop("Prediction not yet implemented for general marked point processes")
      else 
        types <- levels(marks(sumobj$entries$data))
    }

    ## For Poisson models cif=intensity=trend
    if(poisson && type %in% c("cif", "intensity"))
      type <- "trend"

    ## ............. trap un-implemented cases ...................
    
    ## Standard errors not yet available for cif, intensity
    if(se && type %in% c("cif", "intensity"))
      stop(paste("Standard error for", type, "is not yet implemented"),
           call.=FALSE)

    ## Intervals are only available for unmarked Poisson models
    if(type == "count" && interval != "none" && (marked || !poisson)) {
      stop(paste0(interval, " intervals for counts are only implemented for",
                  if(marked) " unmarked" else "",
                  if(!poisson) " Poisson",
                  " models"),
           call.=FALSE)
    }

    if(interval == "prediction" && type != "count")
      stop("Prediction intervals are only available for type='count'",
           call.=FALSE)
    
    if(interval == "confidence" && type %in% c("intensity", "cif")) 
      stop(paste("Confidence intervals are not yet available for", type),
           call.=FALSE)

    estimatename <- if(interval == "none") "estimate" else interval
    
    ## ............. start computing .............................
    
    ## Total count in a region
    
    if(type == "count") {
      ## point or interval estimate, optionally with SE
      if(is.null(window)) {
        ## domain of the original data
        if(!seonly) est <- predconfPois(NULL, model, level, estimatename)
        if(se) sem <- predconfPois(NULL, model, level, "se")
      } else if(is.tess(window)) {
        ## quadrats
        tilz <- tiles(window)
        if(!seonly) {
          est <- unlist(lapply(tilz, predconfPois,
                               object=model, level=level, what=estimatename))
          if(interval != "none") # reshape
            est <- matrix(unlist(est), byrow=TRUE, ncol=2,
                          dimnames=list(names(est), names(est[[1]])))
        }
        if(se) sem <- unlist(lapply(tilz, predconfPois,
                                    object=model, level=level, what="se"))
      } else {
        ## window
        if(!seonly) est <- predconfPois(window, model, level, estimatename)
        if(se) sem <- predconfPois(window, model, level, "se")
      }
      if(!se) return(est)
      if(seonly) return(sem)
      result <- list(est, sem)
      names(result) <- c(estimatename, "se")
      return(result)
    }

    ## .....   Predict a spatial function .......
    
    if(interval != "none") {
      ## Prepare for confidence interval 
      alpha2 <- (1-level)/2
      pp <- sort(c(alpha2, 1-alpha2))
      ci.names <- paste0(signif(100 * pp, 3), "%")
      ci.q <- qnorm(pp)
    }
    
    ##      determine what kind of output is required:
    ##      (arguments present)    (output)  
    ##         window, ngrid    ->   image
    ##         locations (mask) ->   image
    ##         locations (image) ->   image
    ##         locations (rectangle) ->  treat locations as 'window'
    ##         locations (polygonal) ->  treat locations as 'window'
    ##         locations (other) ->  data frame
    ##

    if(is.im(locations))
      locations <- as.owin(locations)
    
    if(is.null(window) && is.owin(locations) && !is.mask(locations)) {
      window <- locations
      locations <- NULL
    }
  
    if(!is.null(ngrid) && !is.null(locations))
      stop(paste("Only one of",
                 sQuote("ngrid"), "and", sQuote("locations"),
                 "should be specified"))

    if(is.null(ngrid) && is.null(locations)) 
      ## use regular grid
      ngrid <- rev(spatstat.options("npixel"))
    
    want.image <- is.null(locations) || is.mask(locations)
    make.grid <- !is.null(ngrid)

    ## ##############   Determine prediction points  #####################

    if(!want.image) {
      ## (A) list of (x,y) coordinates given by `locations'
      xpredict <- locations$x
      ypredict <- locations$y
      if(is.null(xpredict) || is.null(ypredict)) {
        xy <- xy.coords(locations)
        xpredict <- xy$x
        xpredict <- xy$y
      }
      if(is.null(xpredict) || is.null(ypredict))
        stop(paste("Don't know how to extract x,y coordinates from",
                   sQuote("locations")))
      ## marks if required
      if(marked) {
        ## extract marks from data frame `locations'
        mpredict <- locations$marks 
        if(is.null(mpredict))
          stop(paste("The argument", sQuote("locations"),
                     "does not contain a column of marks",
                     "(required since the fitted model",
                     "is a marked point process)"))
        if(is.factor(mpredict)) {
          ## verify mark levels match those in model
          if(!identical(all.equal(levels(mpredict), types), TRUE)) {
            if(all(levels(mpredict) %in% types))
              mpredict <- factor(mpredict, levels=types)
            else 
              stop(paste("The marks in", sQuote("locations"),
                         "do not have the same levels as",
                         "the marks in the model"))
          }
        } else {
          ## coerce to factor if possible
          if(all(mpredict %in% types))
            mpredict <- factor(mpredict, levels=types)
          else
            stop(paste("The marks in", sQuote("locations"),
                       "do not have the same values as the marks in the model"))
        }
      }
    } else {
      ## (B) pixel grid of points
      if(!make.grid) 
        ##    (B)(i) The grid is given in `locations'
        masque <- locations
      else {
        ##    (B)(ii) We have to make the grid ourselves  
        ##    Validate ngrid
        if(!is.null(ngrid)) {
          if(!is.numeric(ngrid))
            stop("ngrid should be a numeric vector")
          ngrid <- ensure2vector(ngrid)
        }
        if(is.null(window))
          window <- sumobj$entries$data$window
        masque <- as.mask(window, dimyx=ngrid)
      }
      ## Hack -----------------------------------------------
      ## gam with lo() will not allow extrapolation beyond the range of x,y
      ## values actually used for the fit. Check this:
      tums <- termsinformula(model$trend)
      if(any(
             tums == "lo(x)" |
             tums == "lo(y)" |
             tums == "lo(x,y)" |
             tums == "lo(y,x)")
         ) {
        ## determine range of x,y used for fit
        gg <- model$internal$glmdata
        gxr <- range(gg$x[gg$SUBSET])
        gyr <- range(gg$y[gg$SUBSET])
        ## trim window to this range
        masque <- intersect.owin(masque, owin(gxr, gyr))
      }
      ## ------------------------------------ End Hack
      ##
      ## Finally, determine x and y vectors for grid
      rxy <- rasterxy.mask(masque, drop=TRUE)
      xpredict <- rxy$x
      ypredict <- rxy$y 
    }

    ## ################  CREATE DATA FRAME  ##########################
    ##                           ... to be passed to predict.glm()  
    ##
    ## First the x, y coordinates
  
    if(!marked) 
      newdata <- data.frame(x=xpredict, y=ypredict)
    else if(!want.image) 
      newdata <- data.frame(x=xpredict, y=ypredict, marks=mpredict)
    else {
      ## replicate
      nt <- length(types)
      np <- length(xpredict)
      xpredict <- rep.int(xpredict,nt)
      ypredict <- rep.int(ypredict,nt)
      mpredict <- rep.int(types, rep.int(np, nt))
      mpredict <- factor(mpredict, levels=types)
      newdata <- data.frame(x = xpredict,
                            y = ypredict,
                            marks=mpredict)
    }

    ## ## Next the external covariates, if any
    ##
    if(need.covariates) {
      if(is.null(covariates)) {
        ## Extract covariates from fitted model object
        ## They have to be images.
        oldcov <- model$covariates
        if(is.null(oldcov))
          stop("External covariates are required, and are not available")
        if(is.data.frame(oldcov))
          stop(paste("External covariates are required.",
                     "Prediction is not possible at new locations"))
        covariates <- oldcov
      }
      ## restrict to covariates actually required for formula
      covariates <- if(is.data.frame(covariates)) {
        covariates[,covnames.needed, drop=FALSE]
      } else covariates[covnames.needed]
      covfunargs <- model$covfunargs
      covariates.df <-
        mpl.get.covariates(covariates,
                           list(x=xpredict, y=ypredict),
                           "prediction points",
                           covfunargs)
      newdata <- cbind(newdata, covariates.df)
    }

    ## ###### Set up prediction variables ################################
    ##
    ## Provide SUBSET variable
    ##
    if(is.null(newdata$SUBSET))
      newdata$SUBSET <- rep.int(TRUE, nrow(newdata))
    ##
    ## Dig out information used in Berman-Turner device 
    ##        Vnames:     the names for the ``interaction variables''
    ##        glmdata:    the data frame used for the glm fit
    ##        glmfit:     the fitted glm object
    ##

    if(!trivial) {
      Vnames <- model$internal$Vnames
      glmdata <- getglmdata(model)
      glmfit <- getglmfit(model)
      if(object$method=="logi")
        newdata$.logi.B <- rep(glmdata$.logi.B[1], nrow(newdata))
    }
  
    ## ##########  COMPUTE PREDICTION ##############################
    ##
    ##   Compute the predicted value z[i] for each row of 'newdata'
    ##   Store in a vector z and reshape it later
    ##
    ##
    ## #############################################################

    needSE <- se || (interval != "none")
    
    if(trivial) {
      ## ###########  UNIFORM POISSON PROCESS #####################

      lambda <- exp(coeffs[[1]])
      if(needSE) {
        npts <- nobs(model)
        se.lambda <- lambda/sqrt(npts)
      }
      switch(interval,
             none = {
               z <- rep.int(lambda, nrow(newdata))
             },
             confidence = {
               z <- matrix(lambda + se.lambda * ci.q, 
                           byrow=TRUE,
                           nrow=nrow(newdata), ncol=2,
                           dimnames=list(NULL, ci.names))
             },
             stop("Internal error: unreached"))

      if(se) 
        zse <- rep.int(se.lambda, nrow(newdata))
    
      ## ##############################################################
    } else if((type %in% c("trend", "intensity")) || poisson) {
      ##
      ## ##########  COMPUTE TREND ###################################
      ##	
      ##   set explanatory variables to zero
      ##	
      zeroes <- numeric(nrow(newdata))    
      for(vn in Vnames)    
        newdata[[vn]] <- zeroes
      ##
      ##   predict trend
      ##
      z <- lambda <- GLMpredict(glmfit, newdata, coeffs, 
                                changecoef=changedcoef)
      ##
      if(type == "intensity") 
        z <- PoisSaddleApp(z, fitin(model))
      
      ##
      if(needSE) {
        ## extract variance-covariance matrix of parameters
        vc <- vcov(model)
        ## compute model matrix
        fmla <- formula(model)
        mf <- model.frame(fmla, newdata, ..., na.action=na.pass)
        mm <- model.matrix(fmla, mf, ..., na.action=na.pass)
        if(nrow(mm) != nrow(newdata))
          stop("Internal error: row mismatch in SE calculation")
        ## compute relative variance = diagonal of quadratic form
        vv <- quadform(mm, vc)
        ## standard error
        SE <- lambda * sqrt(vv)
        if(se) 
          zse <- SE
        if(interval == "confidence") {
          z <- lambda + outer(SE, ci.q, "*")
          colnames(z) <- ci.names
        } 
      } 
      
      ## ############################################################  
    } else if(type == "cif" || type =="lambda") {
      ## ####### COMPUTE FITTED CONDITIONAL INTENSITY ################
      ##
      ## set up arguments
      inter <- model$interaction
      if(!missing(X)) stopifnot(is.ppp(X))
      W <- as.owin(data.ppm(model))
      U <- ppp(newdata$x, y=newdata$y, window=W, check=FALSE)
      if(marked) 
        marks(U) <- newdata$marks
      ## determine which prediction points are data points
      if(is.null(E))
        E <- equalpairs(U, X, marked)
    
      ## evaluate interaction
      Vnew <- evalInteraction(X, U, E, inter, correction=correction,
                              check=check)

      ## Negative infinite values signify cif = zero
      cif.equals.zero <- matrowany(Vnew == -Inf)
    
      ## Insert the potential into the relevant column(s) of `newdata'
      if(ncol(Vnew) == 1) {
        ## Potential is real valued (Vnew is a column vector)
        ## Assign values to a column of the same name in newdata
        newdata[[Vnames]] <- as.vector(Vnew)
      ##
      } else if(is.null(dimnames(Vnew)[[2]])) {
        ## Potential is vector-valued (Vnew is a matrix)
        ## with unnamed components.
        ## Assign the components, in order of their appearance,
        ## to the columns of newdata labelled Vnames[1], Vnames[2],... 
        for(i in seq_along(Vnames))
          newdata[[Vnames[i] ]] <- Vnew[,i]
        ##
      } else {
        ## Potential is vector-valued (Vnew is a matrix)
        ## with named components.
        ## Match variables by name
        for(vn in Vnames)    
          newdata[[vn]] <- Vnew[,vn]
        ##
      }
      ## invoke predict.glm or compute prediction
      z <- GLMpredict(glmfit, newdata, coeffs, 
                      changecoef=changedcoef)
    
      ## reset to zero if potential was zero
      if(any(cif.equals.zero))
        z[cif.equals.zero] <- 0
    
      ## ###############################################################    
    } else
    stop(paste("Unrecognised type", sQuote(type)))

    ## ###############################################################
    ##
    ## reshape the result
    ##
    if(!want.image) {
      if(!se) {
        out <- as.vector(z)
      } else if(seonly) {
        out <- as.vector(zse)
      } else {
        out <- list(as.vector(z), as.vector(zse))
        names(out) <- c(estimatename, "se")
      }
    }
    else {
      ## make an image of the right shape and value
      imago <- as.im(masque, value=1.0)
      if(!marked && interval=="none") {
        ## single image
        if(!se) {
          out <- imago
          ## set entries
          out[] <- z
        } else if(seonly) {
          out <- imago
          out[] <- zse
        } else {
          est <- std <- imago
          est[] <- z
          std[] <- zse
          out <- list(est, std)
          names(out) <- c(estimatename, "se")
        }
      } else if(interval != "none") {
        ## list of 2 images for CI
        if(!seonly) {
          hi <- lo <- imago
          hi[] <- z[,1]
          lo[] <- z[,2]
          est <- listof(hi, lo)
          names(est) <- ci.names
        }
        if(se) {
          std <- imago
          std[] <- zse
        }
        if(!se) {
          out <- est
        } else if(seonly) {
          out <- std
        } else {
          out <- list(est, std)
          names(out) <- c(estimatename, "se")
        }
      } else {
        ## list of images, one for each level of marks
        out <- list()
        for(i in seq_along(types)) {
          outi <- imago
          ## set entries
          outi[] <- z[newdata$marks == types[i]]
          out[[i]] <- outi
        }
        out <- as.listof(out)
        names(out) <- as.character(types)
      }
    }
    ##  
    ##  FINISHED
    ##  
    return(out)
  }

  predict.ppm
})



####################################################################
#
# compute pointwise uncertainty of fitted intensity
#
model.se.image <- function(fit, W=as.owin(fit), ..., what="sd") {
  if(!is.poisson.ppm(fit))
    stop("Only implemented for Poisson point process models", call.=FALSE)
  what <- pickoption("option", what,
                     c(sd="sd", var="var", cv="cv", CV="cv", ce="ce", CE="ce"))
  W <- as.mask(as.owin(W))
  # variance-covariance matrix of coefficients
  vc <- vcov(fit)
  np <- dim(vc)[1]
  # extract sufficient statistic for each coefficient
  mm <- model.images(fit, W, ...)
  # compute fitted intensity 
  lam <- predict(fit, locations=W)
  # initialise resulting image
  U <- as.im(W)
  U[] <- 0
  # compute pointwise matrix product, assuming vc is symmetric
  for(i in 1:np) {
    Si <- mm[[i]]
    aii <- vc[i,i]
    U <- eval.im(U + aii * Si^2)
    if(i > 1) {
      for(j in 1:(i-1)) {
        Sj <- mm[[j]]
        aij <- vc[i,j]
        twoaij <- 2 * aij
        U <- eval.im(U + twoaij * Si * Sj)
      }
    }
  }
  # the matrix product is the relative variance (CV)
  if(what=="cv")
    return(U)
  # relative sd
  if(what=="ce") {
    U <- eval.im(sqrt(U))
    return(U)
  }
  # multiply by squared intensity to obtain variance
  U <- eval.im(U * lam^2)
  # variance
  if(what=="var")
    return(U)
  # compute SD and return
  U <- eval.im(sqrt(U))
  return(U)
}

GLMpredict <- function(fit, data, coefs, changecoef=TRUE) {
  ok <- is.finite(coefs)
  if(!changecoef && all(ok)) {
    answer <- predict(fit, newdata=data, type="response")
  } else {
    # do it by hand
    fmla <- formula(fit)
    data$.mpl.Y <- 1
    fram <- model.frame(fmla, data=data)
    # linear predictor
    mm <- model.matrix(fmla, data=fram)
    if(all(ok)) {
      eta <- as.vector(mm %*% coefs)
    } else {
      #' ensure 0 * anything = 0
      eta <- as.vector(mm[ , ok, drop=FALSE] %*% coefs[ok])
      for(j in which(!ok)) {
        mmj <- mm[, j]
        nonzero <- is.na(mmj) | (mmj != 0)
        if(any(nonzero))
          eta[nonzero] <- eta[nonzero] + mmj[nonzero] * coefs[j]
      }
    }
    # offset
    mo <- model.offset(fram)
    if(!is.null(mo)) {
      if(is.matrix(mo))
        mo <- apply(mo, 1, sum)
      eta <- mo + eta
    }
    # response
    linkinv <- family(fit)$linkinv
    answer <- linkinv(eta)
  }
  # Convert from fitted logistic prob. to lambda for logistic fit
  if(family(fit)$family=="binomial")
    answer <- fit$data$.logi.B[1] * answer/(1-answer)
  return(answer)
}

# An 'equalpairs' matrix E is needed in the ppm class
# to determine which quadrature points and data points are identical
# (not just which quadrature points are data points).
# It is a two-column matrix specifying all the identical pairs.
# The first column gives the index of a data point (in the data pattern X)
# and the second column gives the corresponding index in U.

# The following function determines the equal pair information
# from the coordinates (and marks) of U and X alone;
# it should be used only if we can't figure out this information otherwise.

equalpairs <- function(U, X, marked=FALSE) {
  nn <- nncross(U, X)
  coincides <- (nn$dist == 0)
  Xind <- nn$which[coincides]
  Uind <- which(coincides)
  if(marked) {
    samemarks <- (marks(X)[Xind] == marks(U)[Uind])
    Xind <- Xind[samemarks]
    Uind <- Uind[samemarks]
  }
  return(cbind(Xind, Uind))
}

  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/predictmppm.R"
#
#    predictmppm.R
#
#	$Revision: 1.8 $	$Date: 2014/12/27 11:46:56 $
#
#
# -------------------------------------------------------------------

predict.mppm <-
function(object, ..., newdata=NULL, type=c("trend", "cif"),
                      ngrid=40, locations=NULL, verbose=FALSE) {
#
#	'object' is the output of mppm()
#
  model <- object
  verifyclass(model, "mppm")
#
#  
#       'type'  
  type <- pickoption("type", type, c(trend="trend",
                                     lambda="cif",
                                     cif="cif"), multi=TRUE)
  want.trend <- "trend" %in% type
  want.cif   <- "cif"   %in% type
  selfcheck <- resolve.defaults(list(...), list(selfcheck=FALSE))$selfcheck
#
#
  if(verbose)
    cat("Inspecting arguments...")
#
#       'newdata'
  use.olddata <- is.null(newdata)
  if(use.olddata) {
    newdata <- model$data
    newdataname <- "Original data"
  } else {
    stopifnot(is.data.frame(newdata) || is.hyperframe(newdata))
    newdataname <- sQuote("newdata")
  }
#
#
#    Locations for prediction
  if(is.hyperframe(locations)) 
    locations <- locations[,1,drop=TRUE]
  if(is.list(locations))
    cls <- unique(sapply(locations, class))

  loctype <-
    if(is.null(locations)) "null" else
    if(is.data.frame(locations))  "data.frame" else
    if(is.list(locations)) {
      if(any(c("ppp", "quad") %in% cls)) "points"
      else if("owin" %in% cls) {
        if(all(sapply(locations, function(w) { w$type == "mask"})))
          "mask"
        else
          "window"
      } else "unknown"
    } else "unknown"

  need.grid <- switch(loctype,
                      null      =TRUE,
                      data.frame=FALSE,
                      points    =FALSE,
                      mask      =FALSE,
                      window    =TRUE,
                      unknown   =stop("Unrecognised format for locations"))
  make.image <- need.grid || (loctype == "mask")
#  
  locationvars <- c("x", "y", "id")
#  
#
  if(verbose)
    cat("done.\nDetermining locations for prediction...")
  if(need.grid) {
    # prediction on a grid is required
    if(is.data.frame(newdata))
      stop(paste("Cannot predict model on a grid;", newdataname,
                 "are a data frame"))
  } else {
    # prediction at  `locations' is required
    if(is.hyperframe(newdata)) {
      # check consistency between locations and newdata
      nloc <- length(locations)
      nnew <- summary(newdata)$ncases
      if(nloc != nnew)
        stop(paste("Length of argument", sQuote("locations"), paren(nloc),
                   "does not match number of rows in",
                   newdataname, paren(nnew)))
    } else {
      # newdata is a data frame
      if(!is.data.frame(locations)) 
        stop(paste(newdataname,
                   "is a data frame; locations must be a data frame"))
      else {
        stopifnot(nrow(locations) == nrow(newdata))
        dup <- names(newdata) %in% names(locations)
        if(any(dup))
          for(nam in names(newdata)[dup])
            if(!all.equal(newdata[,nam], locations[,nam]))
              stop(paste("The data frames newdata and locations",
                         "both have a column called", sQuote(nam),
                         "but the entries differ"))
        nbg <- !(locationvars %in% c(names(newdata),names(locations)))
        if(any(nbg))
          stop(paste(ngettext(sum(nbg), "Variable", "Variables"),
                     commasep(locationvars[nbg]),
                     "not provided"))
        # merge the two data frames
        newdata <- cbind(newdata[,!dup], locations)
        locations <- NULL
      }
    }
  }
  if(verbose)
    cat("done.\n Constructing data for prediction...")
#  
#
# extract fitted glm/gam/glmm object
  FIT <- model$Fit$FIT
# extract names of interaction variables
  Vnamelist <- model$Fit$Vnamelist
  vnames <- unlist(Vnamelist)
#
#  
# newdata is data frame
  if(is.data.frame(newdata)) {
    if(verbose)
      cat("(data frame)...")
    if(need.grid)
      stop("Cannot predict model on a grid; newdata is a data frame")
    # use newdata as covariates
    nbg <- !(locationvars %in% names(newdata))
    if(any(nbg))
      stop(paste(ngettext(sum(nbg), "variable", "variables"),
                 commasep(locationvars[nbg]),
                 "not provided"))
    # create output data frame
    answer <- as.data.frame(matrix(, nrow=nrow(newdata), ncol=0),
                            row.names=row.names(newdata))
    if(want.trend) {
      # add interaction components, set to zero (if any)
      if(length(vnames) > 0)
        newdata[, vnames] <- 0
      # compute fitted values
      answer$trend <- predict(FIT, newdata=newdata, type="response")
    }
    if(want.cif) {
      warning("Not yet implemented (computation of cif in data frame case)")
      # split data frame by 'id'
      # compute interaction components using existing point patterns
      # compute fitted values
    }
    return(answer)
  }
  
# newdata is a hyperframe
  if(verbose)
    cat("(hyperframe)...")
  sumry <- summary(newdata)
  npat.new <- sumry$ncases
  # name of response point pattern in model
  Yname <- model$Info$Yname
  #
  # Determine response point patterns if known.
  # Extract from newdata if available
  # Otherwise from the original data if appropriate
  if(verbose)
    cat("(responses)...")
  Y <- if(Yname %in% sumry$col.names) 
    newdata[, Yname, drop=TRUE, strip=FALSE]
  else if(npat.new == model$npat)
    data[, Yname, drop=TRUE, strip=FALSE]
  else NULL
  #
  if(want.cif && is.null(Y))
    stop(paste("Cannot compute cif:",
               "newdata does not contain column", dQuote(Yname),
               "of response point patterns"))
  #
  # Determine windows for prediction 
  if(verbose)
    cat("(windows)...")
  Wins <- if(!need.grid)
    lapply(locations, as.owin, fatal=FALSE)
  else if(!is.null(Y))
    lapply(Y, as.owin, fatal=FALSE)
  else NULL
  if(is.null(Wins) || any(sapply(Wins, is.null)))
    stop("Cannot determine windows where predictions should be made")
  #
  #
  if(is.null(Y)) {
    # only want trend; empty patterns will do
    emptypattern <- function(w) {
      ppp(numeric(0), numeric(0), window=w)
    }
    Y <- lapply(Wins, emptypattern)
  }
    
  # ensure Y contains data points only 
  if(inherits(Y[[1]], "quad"))
    Y <- lapply(Y, function(z) { z$data })

  # Determine locations for prediction
  if(need.grid) {
    # Generate grids of dummy locations 
    if(verbose)
      cat("(grids)...")
    gridsample <- function(W, ngrid) {
      masque <- as.mask(W, dimyx=ngrid)
      xx <- raster.x(masque)
      yy <- raster.y(masque)
      xpredict <- xx[masque$m]
      ypredict <- yy[masque$m]
      Dummy <- ppp(xpredict, ypredict, window=W)
      Image <- as.im(masque)
      return(list(D=Dummy, I=Image))
    }
    Gridded <- lapply(Wins, gridsample, ngrid=ngrid)
    Dummies   <- lapply(Gridded, function(z) { z$D })
    Templates <- lapply(Gridded, function(z) { z$I })
  } else {
    # locations are given somehow
    if(verbose)
      cat("(locations)...")
    if(loctype == "points")
      Dummies <- locations
    else if(loctype == "mask") {
      punctify <- function(M) { 
        xx <- raster.x(M)
        yy <- raster.y(M)
        xpredict <- xx[M$m]
        ypredict <- yy[M$m]
        return(ppp(xpredict, ypredict, window=M))
      }
      Dummies <- lapply(locations, punctify)
      Templates <- lapply(locations, as.im)
    } else
       stop("Internal error: illegal loctype")
  }
  
  # Pack into quadschemes
  if(verbose)
    cat("(quadschemes)...")
  Quads <- list()
  for(i in seq(npat.new)) 
    Quads[[i]] <- quad(data=Y[[i]], dummy=Dummies[[i]])
  # Insert quadschemes into newdata
  newdata[, Yname] <- Quads
  
  # Determine interactions to be used
  if(verbose)
    cat("(interactions)...")
  interactions <- model$Inter$interaction
  ninter <- if(is.hyperframe(interactions)) nrow(interactions) else 1
  nnew <- nrow(newdata)
  if(ninter != nnew && ninter != 1) {
    if(!all(model$Inter$constant))
      stop(paste("Number of rows of newdata", paren(nnew),
                 "does not match number of interactions in model",
                 paren(ninter)))
    interactions <- interactions[1, ]
  }

  # compute the Berman-Turner frame
  if(verbose)
    cat("done.\nStarting prediction...(Berman-Turner frame)...")
  moadf <- mppm(formula     = model$formula,
                data        = newdata,
                interaction = interactions,
                iformula    = model$iformula,
                use.gam     = model$Fit$use.gam,
                correction  = model$Info$correction,
                rbord       = model$Info$rbord,
                backdoor    = TRUE)
  # compute fitted values
  if(verbose)
    cat("(glm prediction)...")
  values <- moadf[, c("x", "y", "id")]
  if(want.cif)
    values$cif <- predict(FIT, newdata=moadf, type="response")
  if(want.trend) {
    if(length(vnames) == 0) 
      # Poisson model: trend = cif 
      values$trend <-
        if(want.cif) values$cif else 
    predict(FIT, newdata=moadf, type="response")
    else {
      # zero the interaction components
      moadf[, vnames] <- 0
      # compute fitted values
      values$trend <- predict(FIT, newdata=moadf, type="response")
    }
  }
  if(verbose)
    cat("done.\nReshaping results...")
  #
  # Reshape results
  # separate answers for each image
  values <- split(values, values$id)
  # 
  Trends <- list()
  Lambdas <- list()
  if(!make.image) {
    if(verbose)
      cat("(marked point patterns)...")
    # values become marks attached to locations
    for(i in seq(npat.new)) {
      Val <- values[[i]]
      Loc <- Dummies[[i]]
      isdum <- !is.data(Quads[[i]])
      if(selfcheck)
        if(length(isdum) != length(Val$trend))
          stop("Internal error: mismatch between data frame and locations")
      if(want.trend)
        Trends[[i]] <- Loc %mark% (Val$trend[isdum])
      if(want.cif)
        Lambdas[[i]] <- Loc %mark% (Val$cif[isdum])
    }
  } else {
    if(verbose)
      cat("(pixel images)...")
    # assign values to pixel images
    for(i in seq(npat.new)) {
      values.i <- values[[i]]
      Q.i <- Quads[[i]]
      values.i <- values.i[!is.data(Q.i), ]
      Template.i <- Templates[[i]]
      ok.i <- !is.na(Template.i$v)
      if(sum(ok.i) != nrow(values.i))
        stop("Internal error: mismatch between data frame and image")
      if(selfcheck) {
        dx <- rasterx.im(Template.i)[ok.i] - values.i$x
        dy <- rastery.im(Template.i)[ok.i] - values.i$y
        cat(paste("i=", i, "range(dx) =", paste(range(dx), collapse=", "),
                  "range(dy) =", paste(range(dy), collapse=", "), "\n"))
      }
      if(want.trend) {
        Trend.i <- Template.i
        Trend.i$v[ok.i] <- values.i$trend
        Trends[[i]] <- Trend.i
      }
      if(want.cif) {
        Lambda.i <- Template.i
        Lambda.i$v[ok.i] <- values.i$cif
        Lambdas[[i]] <- Lambda.i
      }
    }
  }
  if(verbose)
    cat("done.\n")
  # answer is a hyperframe
  Answer <- hyperframe(id=factor(levels(moadf$id)),
                       row.names=sumry$row.names)
  if(want.trend)
    Answer$trend <- Trends
  if(want.cif)
    Answer$cif <- Lambdas
  return(Answer)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/primefactors.R"
#
#  primefactors.R
#
#  $Revision: 1.5 $   $Date: 2014/10/24 00:22:30 $
#

primesbelow <- local({

  # all primes below 1000
  p1000 <- c(
   2,   3,   5,   7,  11,  13,  17,  19,  23,
  29,  31,  37,  41,  43,  47,  53,  59,  61,
  67,  71,  73,  79,  83,  89,  97, 101, 103,
 107, 109, 113, 127, 131, 137, 139, 149, 151,
 157, 163, 167, 173, 179, 181, 191, 193, 197,
 199, 211, 223, 227, 229, 233, 239, 241, 251,
 257, 263, 269, 271, 277, 281, 283, 293, 307,
 311, 313, 317, 331, 337, 347, 349, 353, 359,
 367, 373, 379, 383, 389, 397, 401, 409, 419,
 421, 431, 433, 439, 443, 449, 457, 461, 463,
 467, 479, 487, 491, 499, 503, 509, 521, 523,
 541, 547, 557, 563, 569, 571, 577, 587, 593,
 599, 601, 607, 613, 617, 619, 631, 641, 643,
 647, 653, 659, 661, 673, 677, 683, 691, 701,
 709, 719, 727, 733, 739, 743, 751, 757, 761,
 769, 773, 787, 797, 809, 811, 821, 823, 827,
 829, 839, 853, 857, 859, 863, 877, 881, 883,
 887, 907, 911, 919, 929, 937, 941, 947, 953,
 967, 971, 977, 983, 991, 997)

  primesbelow <- function(nmax) {
    if(nmax <= 1000) return(p1000[p1000 <=  nmax])
    eratosthenes(nmax, c(p1000, 1001:nmax))
  }
  primesbelow
})

eratosthenes <- function(nmax, startset=2:nmax) {
  # The Sieve of Eratosthenes
  if(nmax < 2) return(numeric(0))
  numbers <- startset
  prime <- startset[1]
  repeat{
    retain <-  (numbers <= prime) | (numbers %% prime != 0)
    numbers <- numbers[retain]
    remaining <- (numbers > prime)
    if(!any(remaining))
      break
    prime <- min(numbers[remaining])
  }
  return(numbers)
}
  
primefactors <- function(n, prmax) {
  if(missing(prmax)) prmax <- floor(sqrt(n))
  primes <- primesbelow(prmax)
  divides.n <- (n %% primes == 0)
  if(!any(divides.n)) 
    return(n)
  else {
    divisors <- primes[divides.n]
    prmax <- max(divisors)
    m <- n/prod(divisors)
    if(m == 1) return(divisors)
    else {
      mfactors <- primefactors(m, prmax=prmax)
      return(sort(c(divisors, mfactors)))
    }
  }
}

is.prime <- function(n) { length(primefactors(n)) == 1 }

least.common.multiple <- function(n, m) {
  nf <- primefactors(n)
  mf <- primefactors(m)
  p <- sort(unique(c(nf,mf)))
  nfac <- table(factor(nf, levels=p))
  mfac <- table(factor(mf, levels=p))
  prod(p^pmax.int(nfac,mfac))
}

greatest.common.divisor <- function(n, m) {
  nf <- primefactors(n)
  mf <- primefactors(m)
  p <- sort(unique(c(nf,mf)))
  nfac <- table(factor(nf, levels=p))
  mfac <- table(factor(mf, levels=p))
  prod(p^pmin.int(nfac,mfac))
}
  
divisors <- function(n) {
  p <- primefactors(n)

  up <- sort(unique(p))
  k <- table(factor(p, levels=up))

  rest <- function(kk, uu) {
    powers <- uu[1]^(0:(kk[1]))
    if(length(uu) == 1)
      return(powers)
    rr <- rest(kk[-1], uu[-1])
    products <- as.vector(outer(powers, rr, "*"))
    return(sort(unique(products)))
    }

  return(rest(k, up))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/profilepl.R"
#
# profilepl.R
#
#  $Revision: 1.31 $  $Date: 2014/12/17 05:01:35 $
#
#  computes profile log pseudolikelihood
#

profilepl <- local({

  ## Determine edge correction
  ## with partial matching, avoiding collisions with
  ## other arguments to ppm that have similar names.
  getppmcorrection <- function(..., correction = "border",
           covariates = NULL, covfunargs = NULL, control = NULL) {
    return(correction)
  }
  isSingleNA <- function(x) { length(x) == 1 && is.na(x) }
  
  profilepl <- function(s, f, ..., aic=FALSE, rbord=NULL, verbose=TRUE) {
    callenv <- parent.frame()
    s <- as.data.frame(s)
    n <- nrow(s)
    fname <- paste(short.deparse(substitute(f)), collapse="")
    stopifnot(is.function(f))
    ## validate 's'
    parms <- names(s)
    fargs <- names(formals(f))
    if(!all(fargs %in% parms)) {
      bad <- !(fargs %in% parms)
      forgiven <- sapply(formals(f)[bad], isSingleNA)
      if(!all(forgiven)) {
        slecht <- fargs[bad[!forgiven]]
        nsl <- length(slecht)
        stop(paste(ngettext(nsl, "Argument", "Arguments"),
                   commasep(sQuote(slecht)),
                   ngettext(nsl, "is", "are"),
                   "not provided in the data frame s"))
      }
    }
    ## extra columns in 's' are assumed to be parameters of covariate functions
    is.farg <- parms %in% fargs
    pass.cfa <- any(!is.farg)
    got.cfa <- "covfunargs" %in% names(list(...))
    if(pass.cfa && got.cfa)
      stop("Some columns in s are superfluous")
    ##
    criterion <- numeric(n)
    ## make a fake call
    pseudocall <- match.call()
    pseudocall[[1]] <- as.symbol("ppm")
    namcal <- names(pseudocall)
    ## remove arguments 's' and 'verbose'
    retain <- !(namcal %in% c("s", "verbose"))
    pseudocall <- pseudocall[retain]
    namcal <- namcal[retain]
    ## place 'f' argument third 
    np <- length(pseudocall)
    fpos <- (1:np)[namcal == "f"]
    indices <- (1:np)[-fpos]
    if(length(indices) < 3) {
      indices <- c(indices, fpos)
    } else {
      indices <- c(indices[1:3], fpos, indices[-(1:3)])
    }
    pseudocall <- pseudocall[indices]
    namcal <- names(pseudocall)
    namcal[namcal=="f"] <- "interaction"
    names(pseudocall) <- namcal
    ## get correction
    correction <- getppmcorrection(...)
    if(correction == "border") {
      ## determine border correction distance
      if(is.null(rbord)) {
        ## compute rbord = max reach of interactions
        if(verbose) message("(computing rbord)")
        for(i in 1:n) {
          fi <- do.call("f", as.list(s[i, is.farg, drop=FALSE]))
          if(!inherits(fi, "interact"))
            stop(paste("f did not yield an object of class",
                       sQuote("interact")))
          re <- reach(fi)
          if(is.null(rbord))
            rbord <- re
          else if(rbord < re)
            rbord <- re
        }
      }
    } 
    ## determine whether computations can be saved
    if(pass.cfa || got.cfa) {
      savecomp <- FALSE
    } else {
      Q <- do.call("ppm",
                   append(list(...), list(rbord=rbord, justQ=TRUE)),
                   envir=callenv)
      savecomp <- !oversize.quad(Q)
    }
    ## go
    if(verbose) message(paste("Comparing", n, "models..."))
    for(i in 1:n) {
      if(verbose)
        progressreport(i, n)
      fi <- do.call(f, as.list(s[i, is.farg, drop=FALSE]))
      if(!inherits(fi, "interact"))
        stop(paste("f did not yield an object of class", sQuote("interact")))
      if(pass.cfa)
        cfai <- list(covfunargs=as.list(s[i, !is.farg, drop=FALSE])) 
      ## fit model
      if(i == 1) {
        ## fit from scratch
        arg1 <- list(interaction=fi, ...,
                     rbord=rbord, savecomputed=savecomp,
                     warn.illegal=FALSE,
                     callstring="",
                     skip.border=TRUE)
        if(pass.cfa) arg1 <- append(arg1, cfai)
        fiti <- do.call("ppm", arg1, envir=callenv)
        ## save intermediate computations (pairwise distances, etc)
        precomp <- fiti$internal$computed
        savedargs <- list(...,
                          rbord=rbord, precomputed=precomp,
                          warn.illegal=FALSE,
                          callstring="",
                          skip.border=TRUE)
      } else {
        ## use precomputed data
        argi <- append(savedargs, list(interaction=fi))
        if(pass.cfa) argi <- append(argi, cfai)
        fiti <- do.call("ppm", argi, envir=callenv)
      }
      ## save log PL for each fit
      criterion[i] <-
          if(aic) -AIC(fiti) else as.numeric(logLik(fiti, warn=FALSE))
      ## save fitted coefficients for each fit
      co <- coef(fiti)
      if(i == 1) {
        allcoef <- data.frame(matrix(co, nrow=1))
        names(allcoef) <- names(co)
      } else
        allcoef <- rbind(allcoef, co)
    }
    if(verbose) message("Fitting optimal model...")
    opti <- which.max(criterion)
    optint <- do.call(f, as.list(s[opti, is.farg, drop=FALSE]))
    optarg <- list(interaction=optint, ..., rbord=rbord)
    if(pass.cfa) {
      optcfa <- as.list(s[opti, !is.farg, drop=FALSE])
      attr(optcfa, "fitter") <- "profilepl"
      optarg <- append(optarg, list(covfunargs=optcfa))
    }
    optfit <- do.call("ppm", optarg, envir=callenv)
    if(verbose) message("done.")
    critname <- if(aic) "-AIC" else
                if(is.poisson(optfit)) "log L" else
                if(optfit$method == "logi") "log CL" else "log PL"
    result <- list(param=s,
                   prof=criterion,
                   critname=critname,
                   iopt=opti,
                   fit=optfit,
                   rbord=rbord,
                   fname=fname,
                   allcoef=allcoef,
                   otherstuff=list(...),
                   pseudocall=pseudocall)
    class(result) <- c("profilepl", class(result))
    return(result)
  }

  profilepl
})

##
##   print method
##

print.profilepl <- function(x, ...) {
  head1 <- "Profile log pseudolikelihood"
  head2 <- "for model: "
  psc <- paste(unlist(strsplitretain(format(x$pseudocall))),
               collapse=" ")
  if(nchar(psc) + nchar(head2) + 1 <= getOption('width')) {
    splat(head1)
    splat(head2, psc)
  } else {
    splat(head1, head2)
    splat(psc)
  }
  nparm <- ncol(x$param)
  if(waxlyrical('extras')) {
    splat("fitted with rbord =", x$rbord)
    splat("Interaction:", x$fname)
    splat("Irregular",
          ngettext(nparm, "parameter:", "parameters:\n"),
          paste(names(x$param),
                "in",
                unlist(lapply(lapply(as.list(x$param), range), prange)),
                collapse="\n"))
  }
  popt <- x$param[x$iopt,, drop=FALSE]
  splat("Optimum",
        ngettext(nparm, "value", "values"),
        "of irregular",
        ngettext(nparm, "parameter: ", "parameters:\n"),
        commasep(paste(names(popt), "=", popt)))
  invisible(NULL)
}

##
##   summary method
##

summary.profilepl <- function(object, ...) {
  print(object)
  cat("\n\nOptimal model:\n")
  print(object$fit)
}

as.ppm.profilepl <- function(object) {
  object$fit
}


##
##  plot method 
##

plot.profilepl <- local({

  plot.profilepl <- function(x, ..., add=FALSE, main=NULL,
                             tag=TRUE, coeff=NULL, xvariable=NULL,
                             col=1, lty=1, lwd=1,
                             col.opt="green", lty.opt=3, lwd.opt=1) {
    para <- x$param
    ## graphics arguments may be expressions involving parameters
    if(ncol(para) > 1) {
      col <- eval(substitute(col), para)
      lwd <- eval(substitute(lwd), para)
      lty <- eval(substitute(lty), para)
      px <- cbind(para, col, lwd, lty, stringsAsFactors=FALSE)
      col <- px$col
      lwd <- px$lwd
      lty <- px$lty
    }
    ## strip any column that is entirely NA
    nacol <- sapply(para, function(z) all(!is.finite(z)))
    para <- para[, !nacol, drop=FALSE]
    ## 
    npara <- ncol(para)
    ## main header
    if(is.null(main))
      main <- short.deparse(x$pseudocall)
    ## x variable for plot
    if(is.null(xvariable)) {
      xvalues <- para[,1]
      xname <- names(para)[1]
    } else {
      stopifnot(is.character(xvariable))
      if(!(xvariable %in% names(para)))
        stop("There is no irregular parameter named", sQuote(xvariable))
      xvalues <- para[[xvariable]]
      xname <- xvariable
    }
    ## y variable for plot                  
    if(is.null(coeff)) {
      yvalues <- x$prof
      ylab <- x$critname %orifnull% "log PL"
    } else {
      stopifnot(is.character(coeff))
      allcoef <- x$allcoef
      if(!(coeff %in% names(allcoef)))
        stop(paste("There is no coefficient named", sQuote(coeff),
                   "in the fitted model"))
      yvalues <- allcoef[[coeff]]
      ylab <- paste("coefficient:", coeff)
    }
    ## start plot
    if(!add)
      do.call.matched("plot.default",
                      resolve.defaults(list(x=range(xvalues), y=range(yvalues)),
                                       list(type="n", main=main),
                                       list(...),
                                       list(ylab=ylab, xlab=xname)),
                      extrargs=graphicsPars("plot"))

    linepars <- graphicsPars("lines")
  
    if(npara == 1) {
      ## single curve
      do.call.matched(lines.default,
                      resolve.defaults(list(x=xvalues, y=yvalues, ...),
                                       spatstat.options("par.fv")),
                      extrargs=linepars)
    } else {
      ## multiple curves
      other <- para[, -1, drop=FALSE]
      tapply(1:nrow(para),
             as.list(other),
             plotslice, 
             xvalues=xvalues, yvalues=yvalues, other=other,
             tag=tag, ...,
             col=col, lwd=lwd, lty=lty,
             lineargs=linepars)
    }

    
    ## show optimal value
    do.call.matched(abline,
                    resolve.defaults(list(v = xvalues[x$iopt]),
                                     list(...),
                                     list(lty=lty.opt, lwd=lwd.opt,
                                          col=col.opt)),
                    extrargs=linepars)
    return(invisible(NULL))
  }

  plotslice <- function(z, xvalues, yvalues, other, tag=TRUE, ...,
                        lty=1, col=1, lwd=1, lineargs) {
    fz <- xvalues[z]
    pz <- yvalues[z]
    n <- length(xvalues)
    if(length(lty) == n) lty <- unique(lty[z])[1]
    if(length(col) == n) col <- unique(col[z])[1]
    if(length(lwd) == n) lwd <- unique(lwd[z])[1]
    do.call.matched(lines.default,
                    resolve.defaults(list(x=fz, y=pz,
                                          col=col, lwd=lwd, lty=lty),
                                     list(...)),
                    extrargs=lineargs)
    if(tag) {
      oz <- other[z, , drop=FALSE]
      uniques <- apply(oz, 2, unique)
      labels <- paste(names(uniques), "=", uniques, sep="")
      label <- paste(labels, sep=",")
      ii <- which.max(pz)
      do.call.matched(text.default,
                      list(x=fz[ii], y=pz[ii], labels=label,
                           col=col, ...))
    }
    return(NULL)
  }

  plot.profilepl
})


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/progress.R"
#
#   progress.R
#
#   $Revision: 1.7 $  $Date: 2014/10/12 00:16:58 $
#
#   progress plots (envelope representations)
#

dclf.progress <- function(X, ..., nrank=1)
  mctest.progress(X, ..., expo=2, nrank=nrank)

mad.progress <- function(X, ..., nrank=1)
  mctest.progress(X, ..., expo=Inf, nrank=nrank)

mctest.progress <- local({

  ordstat <- function(z, k) { sort(z, decreasing=TRUE, na.last=TRUE)[k] }
  
  silentmax <- function(z) {
    if(all(is.nan(z))) NaN else max(z[is.finite(z)])
  }

  mctest.progress <- function(X, fun=Lest, ..., expo=1, nrank=1) {
    check.1.real(expo)
    explain.ifnot(expo >= 0)
    if((nrank %% 1) != 0)
      stop("nrank must be an integer")
    if(missing(fun) && inherits(X, "envelope"))
      fun <- NULL
    Z <- envelopeProgressData(X, fun=fun, ..., expo=expo)
    R       <- Z$R
    devdata <- Z$devdata
    devsim  <- Z$devsim
    nsim    <- ncol(devsim)
    critval <- if(nrank == 1) apply(devsim, 1, silentmax) else
    apply(devsim, 1, ordstat, k=nrank)
    alpha   <- nrank/(nsim + 1)
    alphastring <- paste(100 * alpha, "%%", sep="")
    # create fv object
    fname  <- if(is.infinite(expo)) "mad" else
              if(expo == 2) "T" else paste("D[",expo,"]", sep="")
    ylab <- if(is.infinite(expo)) quote(mad(R)) else
            if(expo == 2) quote(T(R)) else
            eval(substitute(quote(D[p](R)), list(p=expo)))
    df <- data.frame(R=R, obs=devdata, crit=critval, zero=0)
    p <- fv(df,
            argu="R", ylab=ylab, valu="obs", fmla = . ~ R, 
            desc = c("Interval endpoint R",
              "observed value of test statistic %s",
              paste("Monte Carlo", alphastring, "critical value for %s"),
              "zero"),
            labl=c("R", "%s(R)", "%s[crit](R)", "0"),
            unitname = unitname(X), fname = fname)
    fvnames(p, ".") <- c("obs", "crit")
    fvnames(p, ".s") <- c("zero", "crit")
    return(p)
  }

  mctest.progress
})


# Do not call this function.
# Performs underlying computations

envelopeProgressData <- function(X, fun=Lest, ..., expo=1,
                                normalize=FALSE, deflate=FALSE) {
  # compute or extract simulated functions
  X <- envelope(X, fun=fun, ..., savefuns=TRUE)
  Y <- attr(X, "simfuns")
  # extract values
  R   <- with(X, .x)
  obs <- with(X, .y)
  reference <- if("theo" %in% names(X)) with(X, theo) else with(X, mmean)
  sim <- as.matrix(as.data.frame(Y))[, -1]
  nsim <- ncol(sim)

  if(is.infinite(expo)) {
    # MAD
    devdata <- cummax(abs(obs-reference))
    devsim <- apply(abs(sim-reference), 2, cummax)
    testname <- "Maximum absolute deviation test"
  } else {
    dR <- c(0, diff(R))
    a <- (nsim/(nsim - 1))^expo
    devdata <- a * cumsum(dR * abs(obs - reference)^expo)
    devsim <- a * apply(dR * abs(sim - reference)^expo, 2, cumsum)
    if(normalize) {
      devdata <- devdata/R
      devsim <- sweep(devsim, 1, R, "/")
    }
    if(deflate) {
      devdata <- devdata^(1/expo)
      devsim <- devsim^(1/expo)
    }
    testname <- if(expo == 2) "Diggle-Cressie-Loosmore-Ford test" else
                if(expo == 1) "Integral absolute deviation test" else
                paste("Integrated", ordinal(expo), "Power Deviation test")
  }
  result <- list(R=R, devdata=devdata, devsim=devsim, testname=testname)
  return(result)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/psp.R"
#
#  psp.R
#
#  $Revision: 1.78 $ $Date: 2014/11/19 07:19:42 $
#
# Class "psp" of planar line segment patterns
#
#
#################################################
# creator
#################################################
psp <- function(x0, y0, x1, y1, window, marks=NULL,
                check=spatstat.options("checksegments")) {
  stopifnot(is.numeric(x0))
  stopifnot(is.numeric(y0))
  stopifnot(is.numeric(x1))
  stopifnot(is.numeric(y1))
  stopifnot(is.vector(x0))
  stopifnot(is.vector(y0))
  stopifnot(is.vector(x1))
  stopifnot(is.vector(y1))
  stopifnot(length(x0) == length(y0))
  stopifnot(length(x1) == length(y1))
  stopifnot(length(x0) == length(x1))
  ends <- data.frame(x0=x0,y0=y0,x1=x1,y1=y1)
  if(!missing(window))
    verifyclass(window,"owin")
  if(check) {
    ok <- inside.owin(x0,y0, window) & inside.owin(x1,y1,window)
    if((nerr <- sum(!ok)) > 0)
      stop(paste(nerr, ngettext(nerr, "segment does not", "segments do not"),
                 "lie entirely inside the window.\n"), call.=FALSE)
  }
  out <- list(ends=ends,
              window=window,
              n = nrow(ends))

# add marks if any
  if(!is.null(marks)) {
    if(is.matrix(marks))
      marks <- as.data.frame(marks)
    if(is.data.frame(marks)) {
      omf <- "dataframe"
      nmarks <- nrow(marks)
      rownames(marks) <- seq_len(nmarks)
      whinge <- "The number of rows of marks"
    } else {
      omf <- "vector"
      names(marks) <- NULL
      nmarks <- length(marks)
      whinge <- "The length of the marks vector"
    }
    if(nmarks != out$n) stop(paste(whinge, "!= length of x and y.\n"))
    out$marks <- marks
    out$markformat <- omf
  } else {
    out$markformat <- "none"
  }

  class(out) <- c("psp", class(out))
  return(out)
}

######################################################
#  conversion
######################################################

is.psp <- function(x) { inherits(x, "psp") }

as.psp <- function(x, ..., from=NULL, to=NULL) {
  # special case: two point patterns
  if(is.null(from) != is.null(to))
    stop(paste("If one of", sQuote("from"), "and", sQuote("to"),
               "is specified, then both must be specified.\n"))
  if(!is.null(from) && !is.null(to)) {
    verifyclass(from, "ppp")
    verifyclass(to, "ppp")
    if(from$n != to$n)
      stop(paste("The point patterns", sQuote("from"), "and", sQuote("to"),
                 "have different numbers of points.\n"))
    uni <- union.owin(from$window, to$window)
    Y <- do.call("psp",
                 resolve.defaults(list(from$x, from$y, to$x, to$y),
                                  list(...),
                                  list(window=uni)))
    return(Y)
  }
  UseMethod("as.psp")
}

as.psp.psp <- function(x, ..., check=FALSE, fatal=TRUE) {
  if(!verifyclass(x, "psp", fatal=fatal))
    return(NULL)
  ends <- x$ends
  psp(ends$x0, ends$y0, ends$x1, ends$y1, window=x$window,
      marks=x$marks, check=check)
}

as.psp.data.frame <- function(x, ..., window=NULL, marks=NULL,
                              check=spatstat.options("checksegments"), fatal=TRUE) {
  window <- suppressWarnings(as.owin(window,fatal=FALSE))
  if(!is.owin(window)) {
    if(fatal) stop("Cannot interpret \"window\" as an object of class owin.\n")
    return(NULL)
  }

  if(checkfields(x,"marks")) {
    if(is.null(marks)) marks <- x$marks
    else warning(paste("Column named \"marks\" ignored;\n",
                       "argument named \"marks\" has precedence.\n",sep=""))
    x$marks <- NULL
  }

  if(checkfields(x, c("x0", "y0", "x1", "y1"))) {
    out <- psp(x$x0, x$y0, x$x1, x$y1, window=window,
               check=check)
    x <- x[-match(c("x0","y0","x1","y1"),names(x))]
  }
  else if(checkfields(x, c("xmid", "ymid", "length", "angle"))) {
    rr <- x$length/2
    dx <- cos(x$angle) * rr
    dy <- sin(x$angle) * rr
    bb <- boundingbox(window)
    rmax <- max(rr)
    bigbox <- owin(bb$xrange + c(-1,1) * rmax, bb$yrange + c(-1,1) * rmax)
    pattern <- psp(x$xmid - dx, x$ymid - dy, x$xmid + dx, x$ymid + dy,
                   window=bigbox,check=FALSE)
    out <- pattern[window]
    x <- x[-match(c("xmid","ymid","length","angle"),names(x))]
  }
  else if(ncol(x) >= 4) {
    out <- psp(x[,1], x[,2], x[,3], x[,4], window=window,
               check=check)
    x <- x[-(1:4)]
  }
  else if(fatal)
    stop("Unable to interpret x as a line segment pattern.", call.=FALSE)
  else out <- NULL

  if(!is.null(out)) {
    if(is.null(marks) & ncol(x) > 0) marks <- x
    if(is.null(marks)) {
       out$markformat <- "none"
    } else {
       out$marks <- marks
       out$markformat <- if(is.data.frame(marks)) "dataframe" else "vector"
       out <- as.psp(out,check=FALSE)
    }
  }
  return(out)
}

as.psp.matrix <- function(x, ..., window=NULL, marks=NULL,
                          check=spatstat.options("checksegments"), fatal=TRUE) {
   x <- as.data.frame(x)
   as.psp(x,...,window=window,marks=marks,check=check,fatal=fatal)
}

as.psp.default <- function(x, ..., window=NULL, marks=NULL,
                           check=spatstat.options("checksegments"), fatal=TRUE) {
  if(checkfields(x,"marks")) {
	if(is.null(marks)) marks <- x$marks
	else warning(paste("Component of \"x\" named \"marks\" ignored;\n",
                             "argument named \"marks\" has precedence.\n",sep=""))
  }
  if(checkfields(x, c("x0", "y0", "x1", "y1")))
    return(psp(x$x0, x$y0, x$x1, x$y1, window=window, marks=marks,
               check=check))
  else if(checkfields(x, c("xmid", "ymid", "length", "angle"))) {
    rr <- x$length/2
    dx <- cos(x$angle) * rr
    dy <- sin(x$angle) * rr
    window <- as.owin(window)
    bb <- boundingbox(window)
    rmax <- max(rr)
    bigbox <- owin(bb$xrange + c(-1,1) * rmax, bb$yrange + c(-1,1) * rmax)
    pattern <- psp(x$x - dx, x$y - dy, x$x + dx, x$y + dy,
                   window=bigbox, marks=marks, check=FALSE)
    clipped <- pattern[window]
    return(clipped)
  }
  else if(fatal)
    stop("Unable to interpret x as a line segment pattern")
  return(NULL)
}

as.psp.owin <- function(x, ..., window=NULL,
                        check=spatstat.options("checksegments"), fatal=TRUE) {
  .Deprecated("edges", package="spatstat")
  edges(x, ..., window=window, check=check)
}

edges <- function(x, ...,
                  window=NULL, check=FALSE) {
  x <- as.owin(x)
  if(is.null(window)) window <- as.rectangle(x)
  x <- as.polygonal(x)
  x0 <- y0 <- x1 <- y1 <- numeric(0)
  bdry <- x$bdry
  for(i in seq_along(bdry)) {
    po <- bdry[[i]]
    ni <- length(po$x)
    nxt <- c(2:ni, 1)
    x0 <- c(x0, po$x)
    y0 <- c(y0, po$y)
    x1 <- c(x1, po$x[nxt])
    y1 <- c(y1, po$y[nxt])
  }
  out <- psp(x0, y0, x1, y1,  window=window, check=check)
  return(out)
}


#################

as.data.frame.psp <- function(x, row.names=NULL, ...) {
  df <- as.data.frame(x$ends, row.names=row.names)
  if(is.marked(x))
    df <- cbind(df, if(x$markformat=="dataframe") marks(x)
                    else data.frame(marks=marks(x)))
  return(df)
}

#######  manipulation ##########################

append.psp <- function(A,B) {
  verifyclass(A, "psp")
  verifyclass(B, "psp")
  stopifnot(identical(A$window, B$window))
  marks <- marks(A) %mapp% marks(B)
  ends <- rbind(A$ends, B$ends)
  out  <- as.psp(ends,window=A$window,marks=marks,check=FALSE)
  return(out)
}

rebound.psp <- function(x, rect) {
  verifyclass(x, "psp")
  x$window <- rebound.owin(x$window, rect)
  return(x)
}


#################################################
#  marks
#################################################

is.marked.psp <- function(X, ...) {
  marx <- marks(X, ...)
  return(!is.null(marx))
}

marks.psp <- function(x, ..., dfok = TRUE) {
  # data frames of marks are as of 19/March 2011 implemented for psp
    ma <- x$marks
    if ((is.data.frame(ma) || is.matrix(ma)) && !dfok) 
        stop("Sorry, not implemented when the marks are a data frame.\n")
    return(ma)
}

"marks<-.psp" <- function(x, ..., value) {
  stopifnot(is.psp(x))
  if(is.null(value)) {
    return(unmark(x))
  }
  m <- value
  if(!(is.vector(m) || is.factor(m) || is.data.frame(m) || is.matrix(m)))
    stop("Incorrect format for marks")

    if (is.hyperframe(m)) 
        stop("Hyperframes of marks are not supported in psp objects.\n")
    nseg <- nsegments(x)
    if (!is.data.frame(m) && !is.matrix(m)) {
        if (length(m) == 1) 
            m <- rep.int(m, nseg)
        else if (nseg == 0) 
            m <- rep.int(m, 0)
        else if (length(m) != nseg) 
            stop("Number of marks != number of line segments.\n")
        marx <- m
    }
    else {
        m <- as.data.frame(m)
        if (ncol(m) == 0) {
            marx <- NULL
        }
        else {
            if (nrow(m) == nseg) {
                marx <- m
            }
            else {
                if (nrow(m) == 1 || nseg == 0) {
                  marx <- as.data.frame(lapply(as.list(m),function(x,k) {
                    rep.int(x, k)}, k = nseg))
                }
                else stop("Number of rows of data frame != number of points.\n")
            }
        }
    }
    Y <- as.psp(x$ends, window = x$window, marks = marx, check = FALSE)
    return(Y)
}

markformat.psp <- function(x) {
    mf <- x$markformat
    if(is.null(mf)) 
      mf <- markformat(marks(x))
    return(mf)
}

unmark.psp <- function(X) {
  X$marks <- NULL
  X$markformat <- "none"
  return(X)
}

#################################################
#  plot and print methods
#################################################

plot.psp <- function(x, ..., main, add=FALSE, show.all=!add, which.marks=1,
                     ribbon=show.all, ribsep=0.15, ribwid=0.05, ribn=1024,
                     do.plot=TRUE) {
  if(missing(main) || is.null(main))
    main <- short.deparse(substitute(x))
  verifyclass(x, "psp")
  #
  n <- nsegments(x)
  marx <- marks(x)
  #
  use.colour <- !is.null(marx) && (n != 0)
  do.ribbon <- identical(ribbon, TRUE) && use.colour 
  ##
  ## ....   initialise plot; draw observation window  ......
  owinpars <- setdiff(graphicsPars("owin"), "col")
  if(!do.ribbon) {
    ## window of x only
    bb.all <- as.rectangle(as.owin(x))
    if(do.plot && show.all)
      do.call.plotfun("plot.owin", 
                      resolve.defaults(list(x=x$window, main=main,
                                            add=add, show.all=show.all),
                                       list(...)),
                      extrargs=owinpars)
  } else {
    ## enlarged window with room for colour ribbon
    ## x at left, ribbon at right
    bb <- as.rectangle(as.owin(x))
    xwidth <- diff(bb$xrange)
    xheight <- diff(bb$yrange)
    xsize <- max(xwidth, xheight)
    bb.rib <- owin(bb$xrange[2] + c(ribsep, ribsep+ribwid) * xsize,
                   bb$yrange)
    bb.all <- boundingbox(bb.rib, bb)
    if(do.plot) {
      pt <- prepareTitle(main)
      ## establish coordinate system
      if(!add)
      do.call.plotfun("plot.owin",
                      resolve.defaults(list(x=bb.all,
                                            type="n",
                                            main=pt$blank),
                                       list(...)),
                      extrargs=owinpars)
      ## now plot window of x
      ## with title centred on this window
      if(show.all) {
        do.call.plotfun("plot.owin", 
                        resolve.defaults(list(x=x$window,
                                              add=TRUE,
                                              main=main,
                                              show.all=TRUE),
                                         list(...)),
                        extrargs=owinpars)
        ## title done. 
        main <- ""
      }
    }
  }

  # plot segments
  if(n == 0) {
    result <- symbolmap()
    attr(result, "bbox") <- bb.all
    return(invisible(result))
  }
  
  # determine colours if any
  if(!use.colour) {
    # black
    col <- colmap <- NULL
  } else {
    # multicoloured 
    marx <- as.data.frame(marx)[, which.marks]
    if(is.character(marx) || length(unique(marx)) == 1)
      marx <- factor(marx)
    if(is.factor(marx)) {
      lev <- levels(marx)
      colmap <- colourmap(col=rainbow(length(lev)), inputs=factor(lev))
    } else {
      if(!all(is.finite(marx)))
        warning("Some mark values are infinite or NaN or NA")
      colmap <- colourmap(col=rainbow(ribn), range=range(marx, finite=TRUE))
    }
    col <- colmap(marx)
  }

  ## convert to greyscale?
  if(spatstat.options("monochrome")) {
    col <- to.grey(col)
    colmap <- to.grey(colmap)
  }

  if(do.plot) {
    ## plot segments
    do.call.plotfun("segments",
                    resolve.defaults(as.list(x$ends),
                                     list(...),
                                     list(col=col),
                                     .StripNull=TRUE),
                    extrargs=names(par()))
    ## plot ribbon
    if(do.ribbon) 
      plot(colmap, vertical=TRUE, add=TRUE,
           xlim=bb.rib$xrange, ylim=bb.rib$yrange)
  }
  
  # return colour map
  result <- colmap %orifnull% colourmap()
  attr(result, "bbox") <- bb.all
  return(invisible(result))
}

print.psp <- function(x, ...) {
  verifyclass(x, "psp")
  n <- x$n
  ism <- is.marked(x, dfok = TRUE)
  splat(if(ism) "marked" else NULL,
        "planar line segment pattern:",
        n, ngettext(n, "line segment", "line segments"))
  if(ism) {
    mks <- marks(x, dfok = TRUE)
    if(is.data.frame(mks)) {
      splat("Mark variables: ",
            paste(names(mks), collapse = ", "))
    } else {
      if(is.factor(mks)) {
        splat("multitype, with levels =",
              paste(levels(mks), collapse = "\t"))
      } else {
        splat("marks are",
              if(is.numeric(mks)) "numeric," else NULL,
              "of type", sQuote(typeof(mks)))
      }
    }
  }
  print(x$window)
  return(invisible(NULL))
}

unitname.psp <- function(x) {
  return(unitname(x$window))
}

"unitname<-.psp" <- function(x, value) {
  w <- x$window
  unitname(w) <- value
  x$window <- w
  return(x)
}

####################################################
#    summary information
####################################################

endpoints.psp <- function(x, which="both") {
  verifyclass(x, "psp")
  ends <- x$ends
  n <- x$n
  switch(which,
         both={
           first <- second <- rep.int(TRUE, n)
         },
         first={
           first <- rep.int(TRUE, n)
           second <- rep.int(FALSE, n)
         },
         second={
           first <- rep.int(FALSE, n)
           second <- rep.int(TRUE, n)
         },
         left={
           first <- (ends$x0 < ends$x1)
           second <- !first
         },
         right={
           first <- (ends$x0 > ends$x1)
           second <- !first
         },
         lower={
           first <- (ends$y0 < ends$y1)
           second <- !first
         },
         upper={
           first <- (ends$y0 > ends$y1)
           second <- !first
         },
         stop(paste("Unrecognised option: which=", sQuote(which)))
         )
  ok <- rbind(first, second)
  xmat <- rbind(ends$x0, ends$x1)
  ymat <- rbind(ends$y0, ends$y1)
  idmat <- col(ok)
  xx <- as.vector(xmat[ok])
  yy <- as.vector(ymat[ok])
  id <- as.vector(idmat[ok])
  result <- ppp(xx, yy, window=x$window, check=FALSE)
  attr(result, "id") <- id
  return(result)
}

midpoints.psp <- function(x) {
  verifyclass(x, "psp")
  xm <- eval(expression((x0+x1)/2), envir=x$ends)
  ym <- eval(expression((y0+y1)/2), envir=x$ends)
  win <- x$window
  ok <- inside.owin(xm, ym, win)
  if(any(!ok)) {
    warning(paste("Some segment midpoints lie outside the original window;",
                  "window replaced by bounding box"))
    win <- boundingbox(win)
  }
  ppp(x=xm, y=ym, window=win, check=FALSE)
}

lengths.psp <- function(x) {
  verifyclass(x, "psp")
  eval(expression(sqrt((x1-x0)^2 + (y1-y0)^2)), envir=x$ends)
}

angles.psp <- function(x, directed=FALSE) {
  verifyclass(x, "psp")
  a <- eval(expression(atan2(y1-y0, x1-x0)), envir=x$ends)
  if(!directed) 
    a <- a %% pi
  return(a)
}

summary.psp <- function(object, ...) {
  verifyclass(object, "psp")
  len <- lengths.psp(object)
  out <- list(n = object$n,
              len = summary(len),
              totlen = sum(len),
              ang= summary(angles.psp(object)),
              w = summary.owin(object$window),
              marks=if(is.null(object$marks)) NULL else summary(object$marks),
              unitinfo=summary(unitname(object)))
  class(out) <- c("summary.psp", class(out))
  return(out)
}

print.summary.psp <- function(x, ...) {
  cat(paste(x$n, "line segments\n"))
  cat("Lengths:\n")
  print(x$len)
  unitblurb <- paste(x$unitinfo$plural, x$unitinfo$explain)
  cat(paste("Total length:", x$totlen, unitblurb, "\n"))
  cat(paste("Length per unit area:", x$totlen/x$w$area, "\n"))
  cat("Angles (radians):\n")
  print(x$ang)
  print(x$w)
  if(!is.null(x$marks)) {
    cat("Marks:\n")
    print(x$marks)
  }
  return(invisible(NULL))
}

  
########################################################
#  subsets
########################################################

"[.psp" <-
  function(x, i, j, drop, ...) {

    verifyclass(x, "psp")
    
    if(missing(i) && missing(j))
      return(x)
        
    if(!missing(i)) {
      style <- if(inherits(i, "owin")) "window" else "index"
      switch(style,
             window={
               x <- clip.psp(x, window=i, check=FALSE)
             },
             index={
               enz <- x$ends[i, ]
               win <- x$window
               marx <- marksubset(x$marks, i, markformat(x))
               x <- with(enz, psp(x0, y0, x1, y1, window=win, marks=marx,
                                  check=FALSE))
             })
    }

    if(!missing(j))
      x <- x[j] # invokes code above
    
    return(x)
 }
  


####################################################
# affine transformations
####################################################

affine.psp <- function(X,  mat=diag(c(1,1)), vec=c(0,0), ...) {
  verifyclass(X, "psp")
  W <- affine.owin(X$window, mat=mat, vec=vec, ...)
  E <- X$ends
  ends0 <- affinexy(list(x=E$x0,y=E$y0), mat=mat, vec=vec)
  ends1 <- affinexy(list(x=E$x1,y=E$y1), mat=mat, vec=vec)
  psp(ends0$x, ends0$y, ends1$x, ends1$y, window=W, marks=marks(X, dfok=TRUE),
      check=FALSE)
}

shift.psp <- function(X, vec=c(0,0), ..., origin=NULL) {
  verifyclass(X, "psp")
  if(!is.null(origin)) {
    stopifnot(is.character(origin))
    if(!missing(vec))
      warning("Argument vec ignored; argument origin has precedence.\n")
    origin <- pickoption("origin", origin, c(centroid="centroid",
                                             midpoint="midpoint",
                                             bottomleft="bottomleft"))
    W <- as.owin(X)
    locn <- switch(origin,
                   centroid={ unlist(centroid.owin(W)) },
                   midpoint={ c(mean(W$xrange), mean(W$yrange)) },
                   bottomleft={ c(W$xrange[1], W$yrange[1]) })
    return(shift(X, -locn))
  }
  # perform shift
  W <- shift.owin(X$window, vec=vec, ...)
  E <- X$ends
  ends0 <- shiftxy(list(x=E$x0,y=E$y0), vec=vec, ...)
  ends1 <- shiftxy(list(x=E$x1,y=E$y1), vec=vec, ...)
  Y <- psp(ends0$x, ends0$y, ends1$x, ends1$y,
           window=W, marks=marks(X, dfok=TRUE),
           check=FALSE)
  # tack on shift vector
  attr(Y, "lastshift") <- vec
  return(Y)
}

rotate.psp <- function(X, angle=pi/2, ..., centre=NULL) {
  verifyclass(X, "psp")
  if(!is.null(centre)) {
    X <- shift(X, origin=centre)
    negorigin <- getlastshift(X)
  } else negorigin <- NULL
  W <- rotate.owin(X$window, angle=angle, ...)
  E <- X$ends
  ends0 <- rotxy(list(x=E$x0,y=E$y0), angle=angle)
  ends1 <- rotxy(list(x=E$x1,y=E$y1), angle=angle)
  Y <- psp(ends0$x, ends0$y, ends1$x, ends1$y,
           window=W, marks=marks(X, dfok=TRUE),
           check=FALSE)
  if(!is.null(negorigin))
    Y <- shift(Y, -negorigin)
  return(Y)
}

is.empty.psp <- function(x) { return(x$n == 0) } 

identify.psp <- function(x, ..., labels=seq_len(nsegments(x)), n=nsegments(x), plot=TRUE) {
  Y <- x
  W <- as.owin(Y)
  mids <- midpoints.psp(Y)
  if(!(is.numeric(n) && (length(n) == 1) && (n %% 1 == 0) && (n >= 0)))
    stop("n should be a single integer")
  out <- integer(0)
  while(length(out) < n) {
    xy <- locator(1)
    # check for interrupt exit
    if(length(xy$x) == 0)
      return(out)
    # find nearest segment
    X <- ppp(xy$x, xy$y, window=W)
    ident <- project2segment(X, Y)$mapXY
    # add to list
    if(ident %in% out) {
      cat(paste("Segment", ident, "already selected\n"))
    } else {
      if(plot) {
        # Display
        mi <- mids[ident]
        li <- labels[ident]
        text(mi$x, mi$y, labels=li)
      }
      out <- c(out, ident)
    }
  }
  # exit if max n reached
  return(out)
}

nsegments <- function(x) {
	UseMethod("nsegments")
}

nobjects.psp <- nsegments.psp <- function(x) {
   x$n
}

as.ppp.psp <- function (X, ..., fatal=TRUE) 
{
  Y <- endpoints.psp(X, which="both")
  m  <- marks(X)
  marks(Y) <- markappend(m, m)
  return(Y)
}

domain.psp <- Window.psp <- function(X, ...) { as.owin(X) }

"Window<-.psp" <- function(X, ..., value) {
  verifyclass(value, "owin")
  X[value]
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/psp2pix.R"
#
# psp2pix.R
#
#  $Revision: 1.7 $  $Date: 2014/10/24 00:22:30 $
#
#

as.mask.psp <- function(x, W=NULL, ...) {
  L <- as.psp(x)
  if(is.null(W))
    W <- as.owin(L)
  else
    W <- as.owin(W)
  W <- as.mask(W, ...)

  ends <- L$ends
  nseg <- nrow(ends)
  
  if(nseg == 0) {
    # empty
    W$m[] <- FALSE
    return(W)
  }
    
  x0 <- (ends$x0 - W$xrange[1])/W$xstep
  x1 <- (ends$x1 - W$xrange[1])/W$xstep
  y0 <- (ends$y0 - W$yrange[1])/W$ystep
  y1 <- (ends$y1 - W$yrange[1])/W$ystep
  nr <- W$dim[1]
  nc <- W$dim[2]
  zz <- .C("seg2pixI",
           ns=as.integer(nseg),
           x0=as.double(x0),
           y0=as.double(y0),
           x1=as.double(x1),
           y1=as.double(y1),
           nx=as.integer(nc),
           ny=as.integer(nr),
           out=as.integer(integer(nr * nc)))
  mm <- matrix(zz$out, nr, nc)
  # intersect with existing window
  W$m <- W$m & mm
  W
}


pixellate.psp <- function(x, W=NULL, ..., weights=NULL) {
  L <- as.psp(x)
  if(is.null(W))
    W <- as.owin(L)
  else
    W <- as.owin(W)
  W <- as.mask(W, ...)

  Z <- as.im(W)

  ends <- L$ends
  nseg <- nrow(ends)

  if(nseg == 0) {
    # empty
    Z$v[] <- 0
    return(Z)
  }
  
  if(is.null(weights))
    weights <- rep.int(1, nseg)
  else {
    if(!is.numeric(weights)) stop("weights must be numeric")
    if(any(is.na(weights))) stop("weights must not be NA")
    if(!all(is.finite(weights))) stop("weights must not be infinite")
    if(length(weights) == 1)
      weights <- rep.int(weights, nseg)
    else if(length(weights) != nseg)
      stop(paste("weights vector has length", length(weights),
                 "but there are", nseg, "line segments"))
  }
      
  x0 <- (ends$x0 - Z$xrange[1])/Z$xstep
  x1 <- (ends$x1 - Z$xrange[1])/Z$xstep
  y0 <- (ends$y0 - Z$yrange[1])/Z$ystep
  y1 <- (ends$y1 - Z$yrange[1])/Z$ystep
  nr <- Z$dim[1]
  nc <- Z$dim[2]
  zz <- .C("seg2pixL",
           ns=as.integer(nseg),
           x0=as.double(x0),
           y0=as.double(y0),
           x1=as.double(x1),
           y1=as.double(y1),
           weights=as.double(weights),
           pixwidth=as.double(Z$xstep),
           pixheight=as.double(Z$ystep),
           nx=as.integer(nc),
           ny=as.integer(nr),
           out=as.double(numeric(nr * nc)))
  mm <- matrix(zz$out, nr, nc)
  mm[is.na(Z$v)] <- NA
  # intersect with existing window
  Z$v <- mm
  Z
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/pspcross.R"
#
#    pspcross.R
#
#    Intersections of line segments
#    
#    $Revision: 1.13 $   $Date: 2014/10/24 00:22:30 $
#
#
crossing.psp <- function(A,B,fatal=TRUE) {
  verifyclass(A, "psp")
  verifyclass(B, "psp")
  
  # first check for intersection of windows
  ABW <- intersect.owin(A$window, B$window, fatal=fatal)
  if(is.null(ABW)) 
    return(NULL)
  
  eps <- .Machine$double.eps

  na <- A$n
  eA <- A$ends
  x0a <- eA$x0
  y0a <- eA$y0
  dxa <- eA$x1 - eA$x0
  dya <- eA$y1 - eA$y0

  nb <- B$n
  eB <- B$ends
  x0b <- eB$x0
  y0b <- eB$y0
  dxb <- eB$x1 - eB$x0
  dyb <- eB$y1 - eB$y0

  useCall <- spatstat.options("crossing.psp.useCall")
  if(!useCall) {
    # old C routine
    out <- .C("xysegint",
              na=as.integer(na),
              x0a=as.double(x0a),
              y0a=as.double(y0a),
              dxa=as.double(dxa),
              dya=as.double(dya), 
              nb=as.integer(nb),
              x0b=as.double(x0b),
              y0b=as.double(y0b),
              dxb=as.double(dxb),
              dyb=as.double(dyb), 
              eps=as.double(eps),
              xx=as.double(numeric(na * nb)),
              yy=as.double(numeric(na * nb)),
              ta=as.double(numeric(na * nb)),
              tb=as.double(numeric(na * nb)),
              ok=as.integer(integer(na * nb)))
    
    ok <- (matrix(out$ok, na, nb) != 0)
    xx <- matrix(out$xx, na, nb)
    yy <- matrix(out$yy, na, nb)
    xx <- as.vector(xx[ok])
    yy <- as.vector(yy[ok])
  } else {
    # new
    storage.mode(x0a) <- storage.mode(y0a) <- "double"
    storage.mode(dxa) <- storage.mode(dya) <- "double"
    storage.mode(x0b) <- storage.mode(y0b) <- "double"
    storage.mode(dxb) <- storage.mode(dyb) <- "double"
    storage.mode(eps) <- "double"
    out <- .Call("Cxysegint",
                 x0a, 
                 y0a, 
                 dxa, 
                 dya, 
                 x0b, 
                 y0b, 
                 dxb, 
                 dyb, 
    	         eps)
#                 PACKAGE="spatstat")
    xx <- out[[5]]
    yy <- out[[6]]
  }
  result <- ppp(xx, yy, window=ABW, check=FALSE)
  return(result)
}

test.crossing.psp <- function(A,B) {
  # return logical matrix specifying whether A[i] and B[j] cross
  verifyclass(A, "psp")
  verifyclass(B, "psp")
  eps <- .Machine$double.eps

  na <- A$n
  eA <- A$ends
  x0a <- eA$x0
  y0a <- eA$y0
  dxa <- eA$x1 - eA$x0
  dya <- eA$y1 - eA$y0

  nb <- B$n
  eB <- B$ends
  x0b <- eB$x0
  y0b <- eB$y0
  dxb <- eB$x1 - eB$x0
  dyb <- eB$y1 - eB$y0

  out <- .C("xysi",
            na=as.integer(na),
            x0a=as.double(x0a),
            y0a=as.double(y0a),
            dxa=as.double(dxa),
            dya=as.double(dya), 
            nb=as.integer(nb),
            x0b=as.double(x0b),
            y0b=as.double(y0b),
            dxb=as.double(dxb),
            dyb=as.double(dyb), 
            eps=as.double(eps),
            ok=as.integer(integer(na * nb)))

  hit <- (matrix(out$ok, na, nb) != 0)
  return(hit)
}

anycrossing.psp <- function(A,B) {
  # equivalent to: any(test.crossing.psp(A,B))
  # Test whether two psp objects have at least one crossing point
  verifyclass(A, "psp")
  verifyclass(B, "psp")
  eps <- .Machine$double.eps

  na <- A$n
  eA <- A$ends
  x0a <- eA$x0
  y0a <- eA$y0
  dxa <- eA$x1 - eA$x0
  dya <- eA$y1 - eA$y0

  nb <- B$n
  eB <- B$ends
  x0b <- eB$x0
  y0b <- eB$y0
  dxb <- eB$x1 - eB$x0
  dyb <- eB$y1 - eB$y0

  out <- .C("xysiANY",
            na=as.integer(na),
            x0a=as.double(x0a),
            y0a=as.double(y0a),
            dxa=as.double(dxa),
            dya=as.double(dya), 
            nb=as.integer(nb),
            x0b=as.double(x0b),
            y0b=as.double(y0b),
            dxb=as.double(dxb),
            dyb=as.double(dyb), 
            eps=as.double(eps),
            ok=as.integer(integer(1)))
  hit <- (out$ok != 0)
  return(hit)
}

selfcrossing.psp <- function(A) {
  verifyclass(A, "psp")
  eps <- .Machine$double.eps

  n <- A$n
  eA <- A$ends
  x0 <- eA$x0
  y0 <- eA$y0
  dx <- eA$x1 - eA$x0
  dy <- eA$y1 - eA$y0

  useCall <- spatstat.options("selfcrossing.psp.useCall")
  if(!useCall) {
    # old C routine
    out <- .C("xysegXint",
              n=as.integer(n),
              x0=as.double(x0),
              y0=as.double(y0),
              dx=as.double(dx),
              dy=as.double(dy), 
              eps=as.double(eps),
              xx=as.double(numeric(n^2)),
              yy=as.double(numeric(n^2)),
              ti=as.double(numeric(n^2)),
              tj=as.double(numeric(n^2)),
              ok=as.integer(integer(n^2)))

    ok <- (matrix(out$ok, n, n) != 0)
    xx <- matrix(out$xx, n, n)
    yy <- matrix(out$yy, n, n)
    xx <- as.vector(xx[ok])
    yy <- as.vector(yy[ok])
  } else {
    # new
    storage.mode(x0) <- storage.mode(y0) <- "double"
    storage.mode(dx) <- storage.mode(dy) <- "double"
    storage.mode(eps) <- "double"
    out <- .Call("CxysegXint",
                 x0, 
                 y0, 
                 dx, 
                 dy, 
    	         eps)
#                 PACKAGE="spatstat")
    xx <- out[[5]]
    yy <- out[[6]]
  }
  result <- ppp(xx, yy, window=A$window, check=FALSE)
  return(result)
}


test.selfcrossing.psp <- function(A) {
  verifyclass(A, "psp")
  eps <- .Machine$double.eps

  n <- A$n
  eA <- A$ends
  x0 <- eA$x0
  y0 <- eA$y0
  dx <- eA$x1 - eA$x0
  dy <- eA$y1 - eA$y0

  out <- .C("xysxi",
            na=as.integer(n),
            x0=as.double(x0),
            y0=as.double(y0),
            dx=as.double(dx),
            dy=as.double(dy), 
            eps=as.double(eps),
            ok=as.integer(integer(n*n)))
  hit <- (matrix(out$ok, n, n) != 0)
  return(hit)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/psst.R"
#
#	psst.R
#
#	Computes the GNZ contrast of delta-f for any function f
#
#	$Revision: 1.8 $	$Date: 2014/11/11 02:30:45 $
#
################################################################################
#

psst <- function(object, fun, r=NULL, breaks=NULL, ...,
                 model=NULL,
                 trend=~1, interaction=Poisson(),
                 rbord=reach(interaction),
                 truecoef=NULL, hi.res=NULL,
                 funargs=list(correction="best"),
                 verbose=TRUE) {
  if(inherits(object, "ppm")) {
    fit <- object
  } else if(is.ppp(object) || inherits(object, "quad")) {
    if(is.ppp(object)) object <- quadscheme(object, ...)
    if(!is.null(model)) {
      fit <- update(model, Q=object, forcefit=TRUE)
    } else {
      fit <- ppm(object, trend=trend, interaction=interaction, rbord=rbord,
                 forcefit=TRUE)
    }
  } else 
    stop("object should be a fitted point process model or a point pattern")

#  rfixed <- !is.null(r) || !is.null(breaks)
  
  # Extract data and quadrature points
  Q <- quad.ppm(fit, drop=FALSE)
  X <- data.ppm(fit)
  U <- union.quad(Q)
  Z <- is.data(Q) # indicator data/dummy
#  E <- equalsfun.quad(Q)
  WQ <- w.quad(Q)  # quadrature weights

  # integrals will be restricted to quadrature points
  # that were actually used in the fit
#  USED <- getglmsubset(fit)
  if(fit$correction == "border") {
    rbord <- fit$rbord
    b <- bdist.points(U)
    USED <- (b > rbord)
  } else USED <- rep.int(TRUE, U$n)
  
  # basic statistics
  Win <- Window(X)
  npts <- npoints(X)
  areaW <- area(Win)
  lambda <- npts/areaW

  # adjustments to account for restricted domain of pseudolikelihood
#  if(any(!USED) && spatstat.options("eroded.intensity")) {
#    XUSED <- USED[Z]
#    npts.used <- sum(Z & USED)
#    area.used <- sum(WQ[USED])
#    lambda.used <- npts.used/area.used
#  } else {
#    XUSED <- rep.int(TRUE, npts)
#    npts.used <- npts
#    area.used <- areaW
#    lambda.used <- lambda
#  }
  
  #  determine breakpoints for r values
  rmaxdefault <- rmax.rule("G", Win, lambda)
  breaks <- handle.r.b.args(r, breaks, Win, rmaxdefault=rmaxdefault)
  rvals <- breaks$r
  rmax  <- breaks$max
  
  # residuals
  resid <- residuals(fit, type="raw",drop=FALSE,
                    new.coef=truecoef, quad=hi.res)
  rescts <- with(resid, "continuous")
  # absolute weight for continuous integrals
  wc   <- -rescts

  # initialise fv object
  df <- data.frame(r=rvals, theo=0)
  desc <- c("distance argument r", "value 0 corresponding to perfect fit")
  ans <- fv(df, "r", substitute(bold(R)~Delta~S(r), NULL),
            "theo", . ~ r,
            alim=c(0, rmax), c("r","%s[theo](r)"), desc,
            fname="bold(R)~Delta~S")

  # evaluate fun(X) for data
  fX <- do.call(fun, append(list(X, r=rvals), funargs))
  fXunits <- unitname(fX)
  # Extract 'best' estimate only
  fX <- with(fX, .y)
  zero <- numeric(length(fX))
  # sum over all quadrature points
  iused <- seq(U$n)[USED]
  nused <- length(iused)
  if(verbose) cat(paste("\nProcessing", nused, "quadrature points..."))
  # running sums & integrals
  sumX <- zero
  integ <- integ2 <- zero
  # template for X \cup {u}
  uX <- superimpose(U[1], X, W=Win, check=FALSE)
  Ux <- U$x
  Uy <- U$y
  # 
  for(j in seq(nused)) {
    i <- iused[j]
    wi <- wc[i]
    if(Z[i]) {
      # data point
      fXi <- do.call(fun, append(list(X[-i], r=rvals), funargs))
      fXi <- with(fXi, .y)
      deltaf <- fX - fXi
      sumX <- sumX + deltaf
    } else {
      # dummy point
      uX$x[1] <- Ux[i]
      uX$y[1] <- Uy[i]
      fuX <- do.call(fun, append(list(uX, r=rvals), funargs))
      fuX <- with(fuX, .y)
      deltaf <- fuX - fX
    }
    integ <- integ + wi * deltaf
    integ2 <- integ2 + wi * deltaf^2
    # 
    if(j %% 500 == 0) {
      cat("[garbage ")
      gc()
      cat("collected]")
    }
    if(verbose) progressreport(j, nused)
  }

  sdv <- sqrt(integ2)
  res <- sumX - integ
  ans <- bind.fv(ans,
                 data.frame(dat=sumX,
                            com=integ,
                            var=integ2,
                            sd=sdv,
                            hi=2*sdv,
                            lo=-2*sdv,
                            res=res,
                            stdres=res/sdv),
                 c("Sigma~Delta~S(r)",
                   "bold(C)~Delta~S(r)",
                   "bold(C)^2~Delta~S(r)",
                   "sqrt(bold(C)^2~Delta~S(r))",
                   "%s[hi](r)",
                   "%s[lo](r)",
                   "bold(R)~Delta~S(r)",
                   "bold(T)~Delta~S(r)"),
               c("data pseudosum (contribution to %s)",
                 "model compensator (contribution to %s)",
                 "pseudovariance of %s",
                 "sqrt(pseudovariance) of %s",
                 "upper 2 sigma critical band for %s",
                 "lower 2 sigma critical band for %s",
                 "pseudoresidual function %s",
                 "standardised pseudoresidual function %s"),
               "res")

  fvnames(ans,".") <- c("res", "hi", "lo", "theo")
  unitname(ans) <- fXunits
  # 
  return(ans)
}

npfun <- function(X, ..., r) {
  npts <- npoints(X)
  # initialise fv object
  df <- data.frame(r=r, theo=0, npoint=npts)
  desc <- c("distance argument r",
            "value 0",
            "value equal to number of points")
  ans <- fv(df, "r", substitute(npoints(r), NULL),
            "npoint", . ~ r,
            alim=c(0, max(r)), c("r","%s[theo](r)", "%s[obs](r)"),
            desc, fname="npoints")
  unitname(ans) <- unitname(X)
  return(ans)
}

nndcumfun <- function(X, ..., r) {
  nn <- nndist(X)
  bk <- breakpts.from.r(r)
#  nn <- nn[nn <= bdist.points(X)]
  h <- whist(nn, bk$val)
  # initialise fv object
  df <- data.frame(r=r, theo=0, obs=h)
  desc <- c("distance argument r",
            "value 0",
            "observed count")
  ans <- fv(df, "r", substitute(nndcount(r), NULL),
            "obs", . ~ r,
            alim=c(0, max(r)), c("r","%s[theo](r)", "%s[obs](r)"),
            desc, fname="nndcount")
  unitname(ans) <- unitname(X)
  return(ans)
}

  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/psstA.R"
#
#	psstA.R
#
#	Pseudoscore residual for unnormalised F (area-interaction)
#
#	$Revision: 1.7 $	$Date: 2014/11/11 02:31:44 $
#
################################################################################
#

psstA <- function(object, r=NULL, breaks=NULL, ...,
                  model=NULL,
                  trend=~1, interaction=Poisson(),
                  rbord=reach(interaction), ppmcorrection="border",
                  correction="all",
                  truecoef=NULL, hi.res=NULL,
                  nr=spatstat.options("psstA.nr"),
                  ngrid=spatstat.options("psstA.ngrid")) {
  if(inherits(object, "ppm")) 
    fit <- object
  else if(inherits(object, "ppp") || inherits(object, "quad")) {
    # convert to quadscheme
    if(inherits(object, "ppp"))
      object <- quadscheme(object, ...)
    # fit model
    if(!is.null(model))
      fit <- update(model, Q=object, forcefit=TRUE)
    else if(ppmcorrection == "border")
      fit <- ppm(object,
                 trend=trend, interaction=interaction,
                 rbord=rbord, forcefit=TRUE)
    else
      fit <- ppm(object,
                 trend=trend, interaction=interaction,
                 correction=ppmcorrection, forcefit=TRUE)
  } else 
    stop("object should be a fitted point process model or a point pattern")

  rfixed <- !is.null(r) || !is.null(breaks)
  
  # Extract data and quadrature points
  Q <- quad.ppm(fit, drop=FALSE)
  X <- data.ppm(fit)
  U <- union.quad(Q)
  Z <- is.data(Q) # indicator data/dummy
#  E <- equalsfun.quad(Q)
#  WQ <- w.quad(Q)  # quadrature weights

  # integrals will be restricted to quadrature points
  # that were actually used in the fit
#  USED <- getglmsubset(fit)
  if(fit$correction == "border") {
    rbord <- fit$rbord
    b <- bdist.points(U)
    USED <- (b > rbord)
    bX <- bdist.points(X)
    USEDX <- (bX > rbord)
  } else {
    USED <- rep.int(TRUE, U$n)
    USEDX <- rep.int(TRUE, X$n)
  }
  
  # basic statistics
  Win <- Window(X)
  npts <- npoints(X)
  areaW <- area(Win)
  lambda <- npts/areaW

  #  determine breakpoints for r values
  rmaxdefault <- rmax.rule("F", Win, lambda)
  if(rfixed) 
    breaks <- handle.r.b.args(r, breaks, Win, rmaxdefault=rmaxdefault)
  else {
    # create fairly coarse 'r' values
    r <- seq(0, rmaxdefault, length=nr)
    breaks <- breakpts.from.r(r)
  }
  rvals <- breaks$r
  rmax  <- breaks$max
  
  # residuals
  res <- residuals(fit, type="raw", drop=FALSE,
                    new.coef=truecoef, quad=hi.res)
  # 
  rescts <- with(res, "continuous")
  # absolute weight for continuous integrals
  wc   <- -rescts

  # initialise fv object
  df <- data.frame(r=rvals, theo=0)
  desc <- c("distance argument r", "value 0 corresponding to perfect fit")
  ans <- fv(df, "r", substitute(bold(R)~Delta~V[A](r), NULL),
            "theo", . ~ r,
            alim=c(0, rmax), c("r","%s[theo](r)"), desc,
            fname="bold(R)~Delta~V[A]")

  #
  # for efficiency, compute the largest value of distance transform
  Dmax <- 0
  for(i in 1:npts) {
    Di <- distmap(X[-i])
    Dimax <- summary(Di)$max
    Dmax <- max(Dmax, Dimax)
  }
  Rmax <- min(max(rvals), Dmax * 1.1)
  nontrivial <- (rvals <= Rmax)
  trivialzeroes <- numeric(sum(!nontrivial))
  
  # pseudosum
  Ax <- areaLoss.grid(X, rvals[nontrivial], subset=USEDX, ngrid=ngrid)
  C1 <- apply(Ax, 2, sum)
  C1 <- c(C1, trivialzeroes)
  # pseudocompensator
  OK <- USED & !Z
  Au <- areaGain.grid(U[OK], X, rvals[nontrivial], W=Win, ngrid=ngrid)
  lamu <- matrix(wc[OK], nrow=nrow(Au), ncol=ncol(Au))
  C2 <- apply(lamu * Au, 2, sum)
  C2 <- c(C2, trivialzeroes)
  # pseudoscore residual
  Ctot <- C1 - C2
  # tack on
  ans <- bind.fv(ans,
                 data.frame(dat=C1,
                            com=C2,
                            res=Ctot),
                 c("Sigma~Delta~V[A](r)", "bold(C)~Delta~V[A](r)", "%s(r)"),
                 c("data pseudosum (contribution to %s)",
                   "model pseudocompensator (contribution to %s)",
                   "pseudoscore residual %s"),
               "res")
  #
  # pseudovariance
  #        (skipped if called by envelope() etc)
  #
  if(correction == "all") {
    lamX <- matrix(wc[USED & Z], nrow=nrow(Ax), ncol=ncol(Ax))
    Var <- apply(lamu * Au^2, 2, sum) + apply(lamX * Ax^2, 2, sum)
    Var <- c(Var, trivialzeroes)
    # two-sigma limits
    TwoSig <- 2 * sqrt(Var)
    # tack on
    ans <- bind.fv(ans,
                   data.frame(var=Var,
                              up=TwoSig,
                              lo=-TwoSig),
                 c("bold(C)^2~Delta~V[A](r)",
                   "%s[up](r)", "%s[lo](r)"),
                 c("pseudovariance of %s",
                   "upper 2sigma critical limit for %s",
                   "lower 2sigma critical limit for %s"),
               "res")
    fvnames(ans, ".") <- c("res", "up", "lo", "theo")
  }
  unitname(ans) <- unitname(fit)
  # 
  return(ans)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/psstG.R"
#
#	psstG.R
#
#	Pseudoscore residual for unnormalised G (saturation process)
#
#	$Revision: 1.7 $	$Date: 2014/11/11 02:33:16 $
#
################################################################################
#

psstG <- function(object, r=NULL, breaks=NULL, ...,
                  model=NULL, 
                  trend=~1, interaction=Poisson(),
                  rbord=reach(interaction),
                  truecoef=NULL, hi.res=NULL) {
  if(inherits(object, "ppm")) 
    fit <- object
  else if(inherits(object, "ppp") || inherits(object, "quad")) {
    # convert to quadscheme
    if(inherits(object, "ppp"))
      object <- quadscheme(object, ...)
    # fit model
    if(!is.null(model))
      fit <- update(model, Q=object, forcefit=TRUE)
    else 
      fit <- ppm(object,
                 trend=trend, interaction=interaction,
                 rbord=rbord, forcefit=TRUE)
  } else 
    stop("object should be a fitted point process model or a point pattern")

#  rfixed <- !is.null(r) || !is.null(breaks)
  
  # Extract data and quadrature points
  Q <- quad.ppm(fit, drop=FALSE)
  X <- data.ppm(fit)
  U <- union.quad(Q)
  Z <- is.data(Q) # indicator data/dummy
  E <- equalsfun.quad(Q)
  WQ <- w.quad(Q)  # quadrature weights

  # integrals will be restricted to quadrature points
  # that were actually used in the fit
#  USED <- getglmsubset(fit)
  if(fit$correction == "border") {
    rbord <- fit$rbord
    b <- bdist.points(U)
    USED <- (b > rbord)
  } else USED <- rep.int(TRUE, U$n)
  
  # basic statistics
  Win <- Window(X)
  npts <- npoints(X)
  areaW <- area(Win)
  lambda <- npts/areaW

  # adjustments to account for restricted domain of pseudolikelihood
#  if(any(!USED)) {
#    npts.used <- sum(Z & USED)
#    area.used <- sum(WQ[USED])
#    lambda.used <- npts.used/area.used
#  } else {
#    npts.used <- npts
#    area.used <- areaW
#    lambda.used <- lambda
#  }
  
  #  determine breakpoints for r values
  rmaxdefault <- rmax.rule("G", Win, lambda)
  breaks <- handle.r.b.args(r, breaks, Win, rmaxdefault=rmaxdefault)
  rvals <- breaks$r
  rmax  <- breaks$max
  
  # residuals
  res <- residuals(fit, type="raw",drop=FALSE,
                    new.coef=truecoef, quad=hi.res)
  resval <- with(res, "increment")
  rescts <- with(res, "continuous")
  # absolute weight for continuous integrals
  wc   <- -rescts

  # initialise fv object
  df <- data.frame(r=rvals, theo=0)
  desc <- c("distance argument r", "value 0 corresponding to perfect fit")
  ans <- fv(df, "r", substitute(bold(R)~Delta~V[S](r), NULL),
            "theo", . ~ r,
            alim=c(0, rmax), c("r","%s[theo](r)"), desc,
            fname="bold(R)~Delta~V[S]")

  # First phase: .................................................
  # nearest neighbours (quadrature point to data point)
  nn <- nncross(U, X, seq(U$n), seq(X$n)) # excludes identical pairs
  dIJ <- nn$dist
  I <- seq(U$n)
  J <- nn$which
  DD <- (I <= X$n)  # TRUE for data points
  wcIJ <- wc
  okI <- USED[I]

  # histogram of nndist for data points only (without edge correction)
  Bsum <- cumsum(whist(dIJ[DD & okI], breaks$val))
  # weighted histogram of nncross (without edge correction)
  Bint <- cumsum(whist(dIJ[okI], breaks$val, wcIJ[okI]))
  # residual
  Bres <- Bsum - Bint
  # tack on 
  
  ans <- bind.fv(ans,
                 data.frame(dat1=Bsum,
                            com1=Bint,
                            res1=Bres),
                 c("%s[dat1](r)",
                   "%s[com1](r)",
                   "%s[res1](r)"),
                 c("phase 1 pseudosum (contribution to %s)",
                   "phase 1 pseudocompensator (contribution to %s)",
                   "phase 1 pseudoresidual (contribution to %s)"))
  
  # Second phase: ................................................
  # close pairs (quadrature point to data point)
  close <- crosspairs(U, X, rmax)
  dIJ <- close$d
  I   <- close$i
  J   <- close$j
#  UI <- U[I]
#  XJ <- X[J]
  EIJ <- E(I, J) # TRUE if points are identical, U[I[k]] == X[J[k]] 
  ZI <- Z[I]     # TRUE if U[I[k]] is a data point
  DD <- ZI & !EIJ  # TRUE for pairs of distinct data points only
#  nDD <- sum(DD)
  okI <- USED[I]
  
  # residual weights
#  wIJ <- ifelseXY(EIJ, rescts[I], resval[I])
  # absolute weight for continuous integrals
  wc   <- -rescts
  wcIJ <- -rescts[I]
  
  # nearest and second-nearest neighbour distances in X
  nn1 <- nndist(X)
  nn2 <- nndist(X, k=2)
  nn1J <- nn1[J]
  nn2J <- nn2[J]
  
  # weird use of the reduced sample estimator
  # data sum:
  RSX <- Kount(dIJ[DD & okI], nn2J[DD & okI], nn2J[ZI & okI], breaks)
  Csum <- RSX$numerator
  # integral:
  if(spatstat.options("psstG.remove.zeroes"))
    okE <- okI & !EIJ
  else
    okE <- okI
  RSD <- Kwtsum(dIJ[okE], nn1J[okE], wcIJ[okE],
                  nn1, rep.int(1, length(nn1)), breaks)
  Cint <- RSD$numerator
  #
  Cres <- Bres + Csum - Cint
  # tack on 
  ans <- bind.fv(ans,
                 data.frame(dat2=Csum,
                            com2=Cint,
                            res2=Cres,
                            dat=Bsum+Csum,
                            com=Bint+Cint,
                            res=Bres+Cres),
                 c("%s[dat2](r)",
                   "%s[com2](r)",
                   "%s[res2](r)",
                   "Sigma~Delta~V[S](r)",
                   "bold(C)~Delta~V[S](r)",
                   "bold(R)~Delta~V[S](r)"),
                 c("phase 2 pseudosum (contribution to %s)",
                   "phase 2 pseudocompensator (contribution to %s)",
                   "phase 2 pseudoresidual (contribution to %s)",
                   "pseudosum (contribution to %s)",
                   "pseudocompensator (contribution to %s)",
                   "pseudoresidual function %s"),
                 "res")
  # restrict choice of curves in default plot
  fvnames(ans, ".") <- c("dat", "com", "res", "theo")
  # 
  return(ans)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/qqplotppm.R"
#
#    QQ plot of smoothed residual field against model
#
#  qqplot.ppm()       QQ plot (including simulation)
#
#  $Revision: 1.24 $   $Date: 2013/04/25 06:37:43 $
#

qqplot.ppm <-
  function(fit, nsim=100, expr=NULL, ..., type="raw", style="mean",
           fast=TRUE, verbose=TRUE, plot.it=TRUE,
           dimyx=NULL, nrep=if(fast) 5e4 else 1e5,
           control=update(default.rmhcontrol(fit), nrep=nrep),
           saveall=FALSE,
           monochrome=FALSE,
           limcol=if(monochrome) "black" else "red",
           maxerr=max(100, ceiling(nsim/10)),
           check=TRUE, repair=TRUE)
{
  verifyclass(fit, "ppm")

  if(check && damaged.ppm(fit)) {
    if(!repair)
      stop("object format corrupted; try update(fit, use.internal=TRUE)")
    message("object format corrupted; repairing it.")
    fit <- update(fit, use.internal=TRUE)
  }
  
  if(fast) {
    oldnpixel <- spatstat.options("npixel")
    if(is.null(dimyx)) 
      dimyx <- pmin(40, rev(oldnpixel))
    spatstat.options(npixel=rev(dimyx))
  } 
    
  ################   How to evaluate residuals ##########################
  
  # Quantiles of the residual field will be computed.
  residualfield <- function(fit, ...) {
    d <- diagnose.ppm(fit, which="smooth",
                      plot.it=FALSE, compute.cts=FALSE, compute.sd=FALSE,
                      check=FALSE, ...)
    return(d$smooth$Z$v)
  }

  # Data values
  dat <- residualfield(fit, type=type, ..., dimyx=dimyx)

  # How to refit the model properly!
  refit <- function(fit, pattern) {
    update.ppm(fit, Q=pattern, use.internal=TRUE)
  }
  
  ##################  How to perform simulations?  #######################

  simulate.from.fit <- is.null(expr)

  how.simulating <- if(simulate.from.fit)
    "simulating from fitted model" else paste("evaluating", sQuote("expr"))  

  if(!simulate.from.fit) {
     # 'expr' will be evaluated 'nsim' times
    if(!is.expression(expr))
      stop(paste("Argument", sQuote("expr"), "should be an expression"))
  } else{
    # We will simulate from the fitted model 'nsim' times
    # and refit the model to these simulations

    # prepare rmh arguments
    rcontrol <- rmhcontrol(control)
    rmodel   <- rmhmodel(fit, control=rcontrol, project=FALSE, verbose=verbose)
    rstart   <- rmhstart(n.start=data.ppm(fit)$n)
    # pre-digest arguments
    rmhinfolist <- rmh(rmodel, rstart, rcontrol, preponly=TRUE, verbose=FALSE)
    
    # expression to be evaluated each time
    expr <- expression(
        refit(fit, 
              rmhEngine(rmhinfolist, verbose=FALSE)))
  }

  ######  Perform simulations
  if(verbose) cat(paste("Simulating", nsim, "realisations... "))
  simul.sizes <- numeric(nsim)
  i <- 0
  ierr <- 0
  repeat {
    # protect from randomly-generated crashes in gam
    ei <- try(eval(expr),silent=!verbose)
    if(inherits(ei, "try-error")) {
      # error encountered in evaluating 'expr'
      ierr <- ierr + 1
      if(ierr > maxerr) 
        stop(paste("Exceeded maximum of", maxerr,
                   "failures in", how.simulating,
                   "after generating only", i, "realisations"))
      else break
    } else {
      # simulation successful
      i <- i + 1
      fiti <-
      if(simulate.from.fit)
        ei
      else if(is.ppm(ei))
        ei
      else if(is.ppp(ei))
        refit(fit, ei)
      else
        stop("result of eval(expr) is not a ppm or ppp object")
      # diagnostic info
      simul.sizes[i] <- data.ppm(fiti)$n
      # compute residual field
      resi <- residualfield(fiti, type=type, ..., dimyx=dimyx)
      if(i == 1)
        sim <- array(, dim=c(dim(resi), nsim))
      sim[,,i] <- resi
      if(verbose) 
        progressreport(i, nsim)
      if(i >= nsim)
        break
    }
  }

  ###### Report diagnostics
  if(ierr > 0)
    cat(paste("\n\n**Alert:",
              ierr, "failures occurred in", how.simulating, "\n\n"))
  nempty <- sum(simul.sizes == 0)
  if(nempty > 0)
    cat(paste("\n\n**Alert:",
              nempty, "out of", nsim,
              "simulated patterns were empty.\n\n"))
  else
    cat(paste("\nDiagnostic info:\n",
              "simulated patterns contained an average of",
              mean(simul.sizes), "points.\n"))
  if(nempty == nsim)
    warning("All simulated patterns were empty")
  ############ Plot them
  switch(style,
         classical = {
           rr <- range(c(dat,sim))
           result <- qqplot(sim, dat, xlim=rr, ylim=rr, asp=1.0,
                            xlab="Quantiles of simulation",
                            ylab="Quantiles of data",plot.it=plot.it)
           title(sub=paste("Residuals:", type))
           abline(0,1, lty=2)
           result <- append(result,
                            list(data=dat,
                                 sim=sim,
                                 xlim=rr,
                                 ylim=rr,
                                 xlab="Quantiles of simulation",
                                 ylab="Quantiles of data",
                                 rtype=type,
                                 nsim=nsim,
                                 fit=fit,
                                 expr=
                                 if(simulate.from.fit) NULL else deparse(expr),
                                 simulate.from.fit=simulate.from.fit
                                 )
                            )
         },
         mean = {
           # compute quantiles corresponding to probabilities p[i]
           # separately in each realisation.
           if(verbose) cat("Calculating quantiles...")
           if(fast) {
             p <- ppoints(min(100,length(dat)), 3/8)
             qsim <- apply(sim, 3, quantile, probs=p, na.rm=TRUE)
           } else {
             qsim <- apply(sim, 3, sort, na.last=TRUE)
           }
           if(verbose) cat("averaging...")
           # sample mean of each quantile
           meanq <- apply(qsim, 1, mean, na.rm=TRUE)
           # et cetera
           varq <- apply(qsim, 1, var, na.rm=TRUE)
           sdq <- sqrt(varq)
           q.025 <- apply(qsim, 1, quantile, probs=0.025, na.rm=TRUE)
           q.975 <- apply(qsim, 1, quantile, probs=0.975, na.rm=TRUE)
  
           rr <- range(c(meanq,dat), na.rm=TRUE)

           dats <- if(fast) quantile(dat, probs=p, na.rm=TRUE) else sort(dat, na.last=TRUE)

           if(verbose) cat("..Done.\n")
           if(plot.it) {
           	plot(meanq, dats,
                     xlab="Mean quantile of simulations", ylab="data quantile",
                     xlim=rr, ylim=rr, asp=1.0)
                abline(0,1)
                lines(meanq, q.025, lty=2, col=limcol)
                lines(meanq, q.975, lty=2, col=limcol)
                title(sub=paste("Residuals:", type))
           }
           result <- list(x=meanq, y=dats, sdq=sdq,
                          q.025=q.025, q.975=q.975,
                          data=dat, sim=sim,
                          xlim=rr, ylim=rr,
                          xlab="Mean quantile of simulations",
                          ylab="data quantile",
                          rtype=type,
                          nsim=nsim,
                          fit=fit,
                          expr=if(simulate.from.fit) NULL else deparse(expr),
                          simulate.from.fit=simulate.from.fit)
         },
         stop(paste("Unrecognised option for", sQuote("style")))
       )

  # Throw out baggage if not wanted         
  if(!saveall) {
    result$fit <- summary(fit, quick=TRUE)
    result$sim <- NULL
  }
         
  # reset npixel
  if(fast)
    spatstat.options(npixel=oldnpixel)
  #
  class(result) <- c("qqppm", class(result))
  return(invisible(result))
}

plot.qqppm <- function(x, ..., limits=TRUE, monochrome=FALSE,
                               limcol=if(monochrome) "black" else "red") {
  stopifnot(inherits(x, "qqppm"))
  default.type <- if(length(x$x) > 150) "l" else "p"
  myplot <- function(object,
                     xlab = object$xlab, ylab = object$ylab,
                     xlim = object$xlim, ylim = object$ylim,
                     asp = 1,
                     type = default.type,
                     ..., limits=TRUE) {
    plot(object$x, object$y, xlab = xlab, ylab = ylab,
         xlim = xlim, ylim = ylim, asp = asp, type = type, ...)
    abline(0, 1)
    
    if(limits) {
      if(!is.null(object$q.025))
        lines(object$x, object$q.025, lty = 2, col=limcol)
      if(!is.null(object$q.975))
        lines(object$x, object$q.975, lty = 2, col=limcol)
    }
    title(sub=paste("Residuals:", object$rtype))
  }
  myplot(x, ..., limits=limits)
  return(invisible(x))
}

  
print.qqppm <- function(x, ...) {
  stopifnot(inherits(x, "qqppm"))
  cat(paste("Q-Q plot of point process residuals ",
            "of type", sQuote(x$rtype), "\n",
            "based on ", x$nsim, " simulations\n",
            sep=""))
  if(x$simulate.from.fit) {
    fit  <- x$fit
    sumfit <- if(is.ppm(fit)) summary(fit, quick=TRUE)
              else if(inherits(fit, "summary.ppm")) fit
              else list(name="(unrecognised format)")
    cat(paste("\nSimulations from fitted model:",
              sumfit$name, "\n"))
  } else {
    cat("Simulations obtained by evaluating the following expression:\n")
    print(x$expr)
  } 
  invisible(NULL)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/quadclass.R"
#
#	quadclass.S
#
#	Class 'quad' to define quadrature schemes
#	in (rectangular) windows in two dimensions.
#
#	$Revision: 4.24 $	$Date: 2014/10/24 00:22:30 $
#
# An object of class 'quad' contains the following entries:
#
#	$data:	an object of class 'ppp'
#		defining the OBSERVATION window, 
#		giving the locations (& marks) of the data points.
#
#	$dummy:	object of class 'ppp'
#		defining the QUADRATURE window, 
#		giving the locations (& marks) of the dummy points.
#	
#	$w: 	vector giving the nonnegative weights for the
#		data and dummy points (data first, followed by dummy)
#
#		w may also have an attribute attr(w, "zeroes")
#               equivalent to (w == 0). If this is absent
#               then all points are known to have positive weights.
#
#       $param:
#               parameters that were used to compute the weights
#               and possibly to create the dummy points (see below).
#              
#       The combined (data+dummy) vectors of x, y coordinates of the points, 
#       and their weights, are extracted using standard functions 
#       x.quad(), y.quad(), w.quad() etc.
#
# ----------------------------------------------------------------------
#  Note about parameters:
#
#       If the quadrature scheme was created by quadscheme(),
#       then $param contains
#
#           $param$weight
#                list containing the values of all parameters
#                actually used to compute the weights.
#
#           $param$dummy
#                list containing the values of all parameters
#                actually used to construct the dummy pattern
#                via default.dummy();
#                or NULL if the dummy pattern was provided externally
#
#           $param$sourceid
#                vector mapping the quadrature points to the
#                original data and dummy points.
#
#   If you constructed the quadrature scheme manually, this
#   structure may not be present.
#
#-------------------------------------------------------------

quad <- function(data, dummy, w, param=NULL) {
  
  data <- as.ppp(data)
  dummy <- as.ppp(dummy)

  n <- data$n + dummy$n
	
  if(missing(w))
    w <- rep.int(1, n)
  else {
    w <- as.vector(w)
    if(length(w) != n)
      stop("length of weights vector w is not equal to total number of points")
  }

  if(is.null(attr(w, "zeroes")) && any( w == 0))
	attr(w, "zeroes") <- (w == 0)

  Q <- list(data=data, dummy=dummy, w=w, param=param)
  class(Q) <- "quad"

  invisible(Q)
}

# ------------------ extractor functions ----------------------

x.quad <- function(Q) {
  verifyclass(Q, "quad")
  c(Q$data$x, Q$dummy$x)
}

y.quad <- function(Q) {
  verifyclass(Q, "quad")
  c(Q$data$y, Q$dummy$y)
}

w.quad <- function(Q) {
  verifyclass(Q, "quad")
  Q$w
}

param.quad <- function(Q) {
  verifyclass(Q, "quad")
  Q$param
}
 
n.quad <- function(Q) {
  verifyclass(Q, "quad")
  Q$data$n + Q$dummy$n
}

marks.quad <- function(x, dfok=FALSE, ...) {
  verifyclass(x, "quad")
  dat <- x$data
  dum <- x$dummy
  if(dfok) warning("ignored dfok = TRUE; not implemented")
  mdat <- marks(dat, dfok=FALSE, ...)
  mdum <- marks(dum, dfok=FALSE, ...)
  if(is.null(mdat) && is.null(mdum))
    return(NULL)
  if(is.null(mdat))
    mdat <- rep.int(NA_integer_, dat$n)
  if(is.null(mdum))
    mdum <- rep.int(NA_integer_, dum$n)
  if(is.factor(mdat) && is.factor(mdum)) {
    mall <- cat.factor(mdat, mdum)
  } else mall <- c(mdat, mdum)
  return(mall)
}

is.marked.quad <- function(X, na.action="warn", ...) {
  marx <- marks(X, ...)
  if(is.null(marx))
    return(FALSE)
  if(any(is.na(marx)))
    switch(na.action,
           warn = {
             warning(paste("some mark values are NA in the point pattern",
                           short.deparse(substitute(X))))
           },
           fatal = {
             return(FALSE)
           },
           ignore = {}
           )
  return(TRUE)
}

is.multitype.quad <- function(X, na.action="warn", ...) {
  marx <- marks(X, ...)
  if(is.null(marx))
    return(FALSE)
  if(any(is.na(marx)))
    switch(na.action,
           warn = {
             warning(paste("some mark values are NA in the point pattern",
                           short.deparse(substitute(X))))
           },
           fatal = {
             return(FALSE)
           },
           ignore = {}
           )
  return(!is.data.frame(marx) && is.factor(marx))
}

is.data <- function(Q) {
  verifyclass(Q, "quad")
  return(c(rep.int(TRUE, Q$data$n),
	   rep.int(FALSE, Q$dummy$n)))
}

equals.quad <- function(Q) {
    # return matrix E such that E[i,j] = (X[i] == U[j])
    # where X = Q$data and U = union.quad(Q)
    n <- Q$data$n
    m <- Q$dummy$n
    E <- matrix(FALSE, nrow=n, ncol=n+m)
    diag(E) <- TRUE
    E
}

equalsfun.quad <- function(Q) {
  stopifnot(inherits(Q, "quad"))
  return(function(i,j) { i == j })
}

equalpairs.quad <- function(Q) {
  # return two-column matrix E such that
  #     X[E[i,1]] == U[E[i,2]] for all i
  # where X = Q$data and U = union.quad(Q)
  n <- Q$data$n
  return(matrix(rep.int(seq_len(n),2), ncol=2))
}
      
union.quad <- function(Q) {
  verifyclass(Q, "quad")
  ppp(x= c(Q$data$x, Q$dummy$x),
      y= c(Q$data$y, Q$dummy$y),
      window=Q$dummy$window,
      marks=marks.quad(Q),
      check=FALSE)
}
	
#
#   Plot a quadrature scheme
#
#
plot.quad <- function(x, ..., main, add=FALSE, dum=list(), tiles=FALSE) {
  if(missing(main) || is.null(main)) 
    main <- short.deparse(substitute(x))
  verifyclass(x, "quad")
  data <- x$data
  dummy <- x$dummy
  # determine plot parameters for dummy points
  dum <- resolve.defaults(dum, list(pch=".", add=TRUE))
  tt <- NULL
  if(tiles) {
    # show tiles that determined the weights
    wp <- x$param$weight
    tt <- NULL
    if(is.null(wp) || is.null(wp$method)) {
      warning("Tile information is not available")
    } else {
      switch(wp$method,
             grid = {
               ntile <- wp$ntile
               tt <- quadrats(as.owin(x), ntile[1], ntile[2])
             },
             dirichlet = {
               U <- union.quad(x)
               if(wp$exact) {
                 tt <- dirichlet(U)
               } else {
                 win <- as.mask(as.owin(U))
                 tileid <- image(exactdt(U)$i,
                                 win$xcol, win$yrow, win$xrange, win$yrange)
                 tt <- tess(image=tileid[win, drop=FALSE])
               }
             },
             warning("Unrecognised 'method' for tile weights")
             )
    }
  }
  pixeltiles <- !is.null(tt) && tt$type == "image"
  tileargs <- resolve.defaults(list(x=tt, main=main, add=add),
                               list(...),
                               if(!pixeltiles) list(col="grey") else NULL)
  if(!is.marked(data)) {
    if(!is.null(tt)) {
      do.call("plot", tileargs)
      add <- TRUE
    }
    plot(data, main=main, add=add, ...)
    do.call("plot", append(list(x=dummy), dum))
  } else if(is.multitype(data) && !add) {
    oldpar <- par(ask = interactive() &&
                  (.Device %in% c("X11", "GTK", "windows", "Macintosh")))
    on.exit(par(oldpar))
    data.marks <- marks(data)
    dummy.marks <- marks(dummy)
    types <- levels(data.marks)
    for(k in types) {
      add <- FALSE
      if(!is.null(tt)) {
        do.call("plot", tileargs)
        add <- TRUE
      }
      maink <- paste(main, "\n mark = ", k, sep="")
      plot(unmark(data[data.marks == k]), main=maink, add=add, ...)
      do.call("plot", append(list(x=unmark(dummy[dummy.marks == k])),
                             dum))
    }
  } else {
    if(!is.null(tt)) {
      do.call("plot", tileargs)
      add <- TRUE
    }
    plot(data, ..., main=main, add=add)
    do.call("plot", append(list(x=dummy), dum))
  }
  invisible(NULL)
}

# subset operator

"[.quad" <- function(x, ...) {
  U <- union.quad(x)
  Z <- is.data(x)
  w <- w.quad(x)
  # determine serial numbers of points to be included
  V <- U %mark% seq_len(U$n)
  i <- marks(V[...])
  # extract corresponding subsets of vectors
  Z <- Z[i]
  w <- w[i]
  # take subset of points, using any type of subset index
  U <- U[...]
  # stick together
  quad(U[Z], U[!Z], w)
}

domain.quad <- Window.quad <- function(X, ...) { as.owin(X) }

"Window<-.quad" <- function(X, ..., value) {
  verifyclass(value, "owin")
  return(X[value])
}

unitname.quad <- function(x) {
  return(unitname(x$data))
}

"unitname<-.quad" <- function(x, value) {
  unitname(x$data) <- value
  unitname(x$dummy) <- value
  return(x)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/quadratcount.R"
#
#  quadratcount.R
#
#  $Revision: 1.48 $  $Date: 2014/11/11 02:34:24 $
#

quadratcount <- function(X, ...) {
  UseMethod("quadratcount")
}

quadratcount.splitppp <- function(X, ...) {
  as.listof(lapply(X, quadratcount, ...))
}

quadratcount.ppp <- function(X, nx=5, ny=nx, ...,
                             xbreaks=NULL, ybreaks=NULL,
                             tess=NULL)  {
  verifyclass(X, "ppp")
  W <- X$window

  if(is.null(tess)) {
    # rectangular boundaries 
    if(!is.numeric(nx))
      stop("nx should be numeric")
    # start with rectangular tessellation
    tess <- quadrats(as.rectangle(W),
                     nx=nx, ny=ny, xbreaks=xbreaks, ybreaks=ybreaks)
    # fast code for counting points in rectangular grid
    Xcount <- rectquadrat.countEngine(X$x, X$y, tess$xgrid, tess$ygrid)
    #
    if(W$type != "rectangle") {
      # intersections of rectangles with window including empty intersections
      tess <- quadrats(X,
                       nx=nx, ny=ny, xbreaks=xbreaks, ybreaks=ybreaks,
                       keepempty=TRUE)
      # now delete the empty quadrats and the corresponding counts
      nonempty <- !unlist(lapply(tiles(tess), is.empty))
      if(!any(nonempty))
        stop("All tiles are empty")
      if(!all(nonempty)) {
#        ntiles <- sum(nonempty)
        tess   <- tess[nonempty]
        Xcount <- t(Xcount)[nonempty]
        # matrices and tables are in row-major order,
        # tiles in a rectangular tessellation are in column-major order
        Xcount <- array(Xcount,
                        dimnames=list(tile=tilenames(tess)))
        class(Xcount) <- "table"
      }
    }
  } else {
    # user-supplied tessellation
    if(!inherits(tess, "tess"))
      stop("The argument tess should be a tessellation", call.=FALSE)
    if(tess$type == "rect") {
      # fast code for counting points in rectangular grid
      Xcount <- rectquadrat.countEngine(X$x, X$y, tess$xgrid, tess$ygrid)
    } else {
      # quadrats are another type of tessellation
      Y <- cut(X, tess)
      if(any(is.na(marks(Y))))
        warning("Tessellation does not contain all the points of X")
      Xcount <- table(tile=marks(Y))
    }
  }
  attr(Xcount, "tess") <- tess
  class(Xcount) <- c("quadratcount", class(Xcount))
  return(Xcount)
}

plot.quadratcount <- function(x, ...,
                              add=FALSE, entries=as.vector(t(as.table(x))),
                              dx=0, dy=0, show.tiles=TRUE,
                              textargs = list()) {
  xname <- short.deparse(substitute(x))
  tess <- attr(x, "tess")
  # add=FALSE, show.tiles=TRUE  => plot tiles + numbers
  # add=FALSE, show.tiles=FALSE => plot window (add=FALSE) + numbers
  # add=TRUE,  show.tiles=TRUE  => plot tiles  (add=TRUE) + numbers
  # add=TRUE,  show.tiles=FALSE => plot numbers
  if(show.tiles || !add) {
    context <- if(show.tiles) tess else as.owin(tess)
    do.call("plot",
            resolve.defaults(list(context, add=add),
                             list(...),
                             list(main=xname),
                             .StripNull=TRUE))
  }
  if(!is.null(entries)) {
    labels <- paste(as.vector(entries))
    til <- tiles(tess)
    incircles <- lapply(til, incircle)
    x0 <- unlist(lapply(incircles, function(z) { z$x }))
    y0 <- unlist(lapply(incircles, function(z) { z$y }))
    ra <- unlist(lapply(incircles, function(z) { z$r }))
    do.call.matched("text.default",
                    resolve.defaults(list(x=x0 + dx * ra, y = y0 + dy * ra),
                                     list(labels=labels),
                                     textargs, 
                                     list(...)))
  }
  return(invisible(NULL))
}

rectquadrat.breaks <- function(xr, yr, nx=5, ny=nx, xbreaks=NULL, ybreaks=NULL) {
  if(is.null(xbreaks))
    xbreaks <- seq(from=xr[1], to=xr[2], length.out=nx+1)
  else if(min(xbreaks) > xr[1] || max(xbreaks) < xr[2])
    stop("xbreaks do not span the range of x coordinates in the window")
  if(is.null(ybreaks))
    ybreaks <- seq(from=yr[1], to=yr[2], length.out=ny+1)
  else if(min(ybreaks) > yr[1] || max(ybreaks) < yr[2])
    stop("ybreaks do not span the range of y coordinates in the window")
  return(list(xbreaks=xbreaks, ybreaks=ybreaks))
}

rectquadrat.countEngine <- function(x, y, xbreaks, ybreaks, weights) {
  if(length(x) > 0) {
    # check validity of breaks
    if(min(x) < min(xbreaks) || max(x) > max(xbreaks))
      stop("xbreaks do not span the actual range of x coordinates in data")
    if(min(y) < min(ybreaks) || max(y) > max(ybreaks))
      stop("ybreaks do not span the actual range of y coordinates in data")
  }
  xg <- cut(x, breaks=xbreaks, include.lowest=TRUE)
  yg <- cut(y, breaks=ybreaks, include.lowest=TRUE)
  if(missing(weights)) 
    sumz <- table(list(y=yg, x=xg))
  else {
    sumz <- tapply(weights, list(y=yg, x=xg), sum)
    if(any(nbg <- is.na(sumz)))
      sumz[nbg] <- 0
  }
  # reverse order of y 
  sumz <- sumz[rev(seq_len(nrow(sumz))), ]
  sumz <- as.table(sumz)
  #
  attr(sumz, "xbreaks") <- xbreaks
  attr(sumz, "ybreaks") <- ybreaks
  return(sumz)
}

quadrats <- function(X, nx=5, ny=nx, xbreaks = NULL, ybreaks = NULL,
                     keepempty=FALSE) {
  W <- as.owin(X)
  xr <- W$xrange
  yr <- W$yrange
  b <- rectquadrat.breaks(xr, yr, nx, ny, xbreaks, ybreaks)
  # rectangular tiles
  Z <- tess(xgrid=b$xbreaks, ygrid=b$ybreaks)
  if(W$type != "rectangle") {
    # intersect rectangular tiles with window W
    if(!keepempty) {
      Z <- intersect.tess(Z, W)
    } else {
      til <- tiles(Z)
      for(i in seq_along(til))
        til[[i]] <- intersect.owin(til[[i]], W)
      Z <- tess(tiles=til, window=W, keepempty=TRUE)
    }
  }
  return(Z)
}

as.tess.quadratcount <- function(X) {
  return(attr(X, "tess"))
}

as.owin.quadratcount <- function(W, ..., fatal=TRUE) {
  return(as.owin(as.tess(W), ..., fatal=fatal))
}

domain.quadratcount <- Window.quadratcount <- function(X, ...) { as.owin(X) }

intensity.quadratcount <- function(X, ..., image=FALSE) {
  Y <- as.tess(X)
  a <- tile.areas(Y)
  ## in the rectangular case, tiles are indexed in column-major order
  if(Y$type == "rect" && length(dim(X)) > 1) 
    a <- matrix(a, byrow=TRUE, nrow(X), ncol(X))
  lambda <- X/a
  if(!image) {
    trap.extra.arguments(...)
    class(lambda) <- "table"
    attr(lambda, "tess") <- NULL
    return(lambda)
  }
  ## again to handle rectangular case
  lambda <- as.vector(t(lambda))
  tileid <- as.im(Y, ...)
  result <- eval.im(lambda[tileid])
  return(result)
}

## The shift method is undocumented.
## It is only needed in plot.listof

shift.quadratcount <- function(X, ...) {
  attr(X, "tess") <- te <- shift(attr(X, "tess"), ...)
  attr(X, "lastshift") <- getlastshift(te)
  return(X)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/quadratmtest.R"
#
#   method for 'quadrat.test' for class mppm
#
#   $Revision: 1.7 $   $Date: 2012/09/06 03:50:17 $
#
quadrat.test.mppm <- function(X, ...) {
  Xname <- short.deparse(substitute(X))
  if(!is.poisson.mppm(X))
    stop("Model is not a Poisson point process")
  
  subs <- subfits(X)
  tests <- lapply(subs, quadrat.test.ppm, ..., fitname=Xname)
  class(tests) <- c("listof", class(tests))

  df.est <- length(coef(X))
  return(pool.quadrattest(tests, Xname=Xname, df.est=df.est))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/quadratresample.R"
#
# quadratresample.R
#
# resample a point pattern by resampling quadrats
#
# $Revision: 1.5 $  $Date: 2010/11/25 02:58:49 $
#

quadratresample <- function(X, nx, ny=nx, ...,
                            replace=FALSE, nsamples=1,
                            verbose=(nsamples > 1)) {
  stopifnot(is.ppp(X))
  if(X$window$type != "rectangle")
    stop("Resampling is only implemented for rectangular windows")
  # create tessellation
  A <- quadrats(X, nx=nx, ny=ny)
  # split data over tessellation
  B <- split(X, A)
  nq <- length(B)
  # determine bottom left corner of each tile
  V <- lapply(B, function(z) { w <- z$window;
                               c(w$xrange[1], w$yrange[1]) })
  out <- list()
  if(verbose)
    cat("Generating resampled patterns...")
  for(i in 1:nsamples) {
    # resample tiles
    ind <- sample(1:nq, nq, replace=replace)
    Xresampled <- X
    Bresampled <- B
    for(j in 1:nq) {
      k <- ind[j]
      Bresampled[[j]] <- shift(B[[k]], unlist(V[[j]]) - unlist(V[[k]]))
    }
    split(Xresampled, A) <- Bresampled
    out[[i]] <- Xresampled
    if(verbose)
      progressreport(i, nsamples)
  }
  if(nsamples == 1)
    return(out[[1]])
  return(as.listof(out))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/quadrattest.R"
#
#   quadrattest.R
#
#   $Revision: 1.49 $  $Date: 2014/11/11 10:34:41 $
#

quadrat.test <- function(X, ...) {
   UseMethod("quadrat.test")
}

quadrat.test.ppp <-
  function(X, nx=5, ny=nx,
           alternative = c("two.sided", "regular", "clustered"),
           method = c("Chisq", "MonteCarlo"),
           conditional=TRUE, CR=1,
           ...,
           xbreaks=NULL, ybreaks=NULL,
           tess=NULL, nsim=1999)
{
   Xname <- short.deparse(substitute(X))
   method <- match.arg(method)
   alternative <- match.arg(alternative)
   do.call("quadrat.testEngine",
          resolve.defaults(list(X, nx=nx, ny=ny,
                                alternative=alternative,
                                method=method,
                                conditional=conditional,
                                CR=CR,
                                xbreaks=xbreaks, ybreaks=ybreaks,
                                tess=tess,
                                nsim=nsim),
                           list(...), 
                           list(Xname=Xname, fitname="CSR")))
}

quadrat.test.splitppp <- function(X, ..., df=NULL, df.est=NULL, Xname=NULL)
{
  if(is.null(Xname))
    Xname <- short.deparse(substitute(X))
  pool.quadrattest(lapply(X, quadrat.test.ppp, ...),
                   df=df, df.est=df.est, Xname=Xname)
}

quadrat.test.ppm <-
  function(X, nx=5, ny=nx,
           alternative = c("two.sided", "regular", "clustered"),      
           method=c("Chisq", "MonteCarlo"),
           conditional=TRUE, CR=1, ...,
           xbreaks=NULL, ybreaks=NULL,
           tess=NULL, nsim=1999)
{
   fitname <- short.deparse(substitute(X))
   dataname <- paste("data from", fitname)
   method <- match.arg(method)
   alternative <- match.arg(alternative)
   if(!is.poisson.ppm(X))
    stop("Test is only defined for Poisson point process models")
   if(is.marked(X))
    stop("Sorry, not yet implemented for marked point process models")
   do.call("quadrat.testEngine",
          resolve.defaults(list(data.ppm(X), nx=nx, ny=ny,
                                alternative=alternative,
                                method=method,
                                conditional=conditional, CR=CR,
                                xbreaks=xbreaks, ybreaks=ybreaks,
                                tess=tess,
                                nsim=nsim, 
                                fit=X),
                           list(...),
                           list(Xname=dataname, fitname=fitname)))
}

quadrat.test.quadratcount <-
  function(X,
           alternative = c("two.sided", "regular", "clustered"),
           method=c("Chisq", "MonteCarlo"),
           conditional=TRUE, CR=1,
           ...,
           nsim=1999) {
   trap.extra.arguments(...)
   method <- match.arg(method)
   alternative <- match.arg(alternative)
   quadrat.testEngine(Xcount=X,
                      alternative=alternative,
                      method=method, conditional=conditional, CR=CR, nsim=nsim)
}

quadrat.testEngine <- function(X, nx, ny,
                               alternative = c("two.sided",
                                                "regular", "clustered"),
                               method=c("Chisq", "MonteCarlo"),
                               conditional=TRUE, CR=1, ...,
                               nsim=1999,
                               Xcount=NULL,
                               xbreaks=NULL, ybreaks=NULL, tess=NULL,
                               fit=NULL, Xname=NULL, fitname=NULL) {
  trap.extra.arguments(...)
  method <- match.arg(method)
  alternative <- match.arg(alternative)
  if(method == "MonteCarlo") {
    check.1.real(nsim)
    explain.ifnot(nsim > 0)
  }
  if(is.null(Xcount))
    Xcount <- quadratcount(X, nx=nx, ny=ny, xbreaks=xbreaks, ybreaks=ybreaks,
                           tess=tess)
  tess <- attr(Xcount, "tess")
  testname <- switch(method,
                     Chisq = "Chi-squared test",
                     MonteCarlo = paste(
                       if(conditional) "Conditional" else "Unconditional",
                       "Monte Carlo test")
                     )
  # determine expected values under model
  if(is.null(fit)) {
    nullname <- "CSR"
    if(tess$type == "rect") 
      areas <- outer(diff(tess$xgrid), diff(tess$ygrid), "*")
    else 
      areas <- unlist(lapply(tiles(tess), area))
    fitmeans <- sum(Xcount) * areas/sum(areas)
    df <- switch(method,
                 Chisq      = length(fitmeans) - 1,
                 MonteCarlo = NULL)
  } else {
    if(!is.ppm(fit))
      stop("fit should be a ppm object")
    if(!is.poisson.ppm(fit))
      stop("Quadrat test only supported for Poisson point process models")
    if(is.marked(fit))
      stop("Sorry, not yet implemented for marked point process models")
    nullname <- paste("fitted Poisson model", sQuote(fitname))
    Q <- quad.ppm(fit, drop=TRUE)
    ww <- w.quad(Q)
    lambda <- fitted(fit, drop=TRUE)
    masses <- lambda * ww
    # sum weights of quadrature points in each tile 
    if(tess$type == "rect") {
      xx <- x.quad(Q)
      yy <- y.quad(Q)
      xbreaks <- tess$xgrid
      ybreaks <- tess$ygrid
      fitmeans <- rectquadrat.countEngine(xx, yy, xbreaks, ybreaks,
                                          weights=masses)
      fitmeans <- as.vector(t(fitmeans))
    } else {
      U <- as.ppp(Q)
      V <- marks(cut(U, tess), dfok=FALSE)
      fitmeans <- tapply(masses, list(tile=V), sum)
      fitmeans[is.na(fitmeans)] <- 0
    }
    switch(method,
           Chisq = {
             df <- length(fitmeans) - length(coef(fit))
             if(df < 1)
               stop(paste("Not enough quadrats: degrees of freedom df =", df))
           },
           MonteCarlo = {
             df <- NA
           })
  }
  OBS <- as.vector(t(as.table(Xcount)))
  EXP <- as.vector(fitmeans)
  testname <- paste(testname, "of", nullname, "using quadrat counts")

  testname <- c(testname, CressieReadName(CR))

  result <- X2testEngine(OBS, EXP,
                         method=method, df=df, nsim=nsim,
                         conditional=conditional, CR=CR,
                         alternative=alternative,
                         testname=testname, dataname=Xname)

  class(result) <- c("quadrattest", class(result))
  attr(result, "quadratcount") <- Xcount
  return(result)
}

CressieReadStatistic <- function(OBS, EXP, lambda=1) {
  y <- if(lambda == 1) sum((OBS - EXP)^2/EXP) else
       if(lambda == 0) 2 * sum(OBS * log(OBS/EXP)) else
       if(lambda == -1) 2 * sum(EXP * log(EXP/OBS)) else
       (2/(lambda * (lambda + 1))) * sum(OBS * ((OBS/EXP)^lambda - 1))
  names(y) <- CressieReadSymbol(lambda)
  return(y)
}

CressieReadSymbol <- function(lambda) {
  if(lambda == 1) "X2" else
  if(lambda == 0) "G2" else
  if(lambda == -1/2) "T2" else
  if(lambda == -1) "GM2" else
  if(lambda == -2) "NM2" else "CR"
}

CressieReadName <- function(lambda) {
  if(lambda == 1) "Pearson X2 statistic" else
  if(lambda == 0) "likelihood ratio test statistic G2" else
  if(lambda == -1/2) "Freeman-Tukey statistic T2" else
  if(lambda == -1) "modified likelihood ratio test statistic GM2" else
  if(lambda == -2) "Neyman modified X2 statistic NM2" else
  paste("Cressie-Read statistic",
        paren(paste("lambda =",
                    if(abs(lambda - 2/3) < 1e-7) "2/3" else lambda)
              )
        )
}

X2testEngine <- function(OBS, EXP, ...,
                         method=c("Chisq", "MonteCarlo"),
                         CR=1,
                         df=NULL, nsim=NULL, 
                         conditional, alternative, testname, dataname) {
  method <- match.arg(method)
  if(method == "Chisq" & any(EXP < 5)) 
    warning(paste("Some expected counts are small;",
                  "chi^2 approximation may be inaccurate"),
            call.=FALSE)
  X2 <- CressieReadStatistic(OBS, EXP, CR)
  # conduct test
  switch(method,
         Chisq = {
           if(!is.null(df))
             names(df) <- "df"
           pup <- pchisq(X2, df, lower.tail=FALSE)
           plo <- pchisq(X2, df, lower.tail=TRUE)
           PVAL <- switch(alternative,
                          regular   = plo,
                          clustered = pup,
                          two.sided = 2 * min(pup, plo))
         },
         MonteCarlo = {
           nsim <- as.integer(nsim)
           if(conditional) {
             npts <- sum(OBS)
             p <- EXP/sum(EXP)
             SIM <- rmultinom(n=nsim,size=npts,prob=p)
           } else {
             ne <- length(EXP)
             SIM  <- matrix(rpois(nsim*ne,EXP),nrow=ne)
           }
           simstats <- apply(SIM, 2, CressieReadStatistic, EXP=EXP)
           if(anyDuplicated(simstats))
             simstats <- jitter(simstats)
           phi <- (1 + sum(simstats >= X2))/(1+nsim)
           plo <- (1 + sum(simstats <= X2))/(1+nsim)
           PVAL <- switch(alternative,
                          clustered = phi,
                          regular   = plo,
                          two.sided = 2 * min(phi,plo))
         })
    result <- structure(list(statistic = X2,
                             parameter = df,
                             p.value = PVAL,
                             method = testname,
                             data.name = dataname,
                             alternative = alternative,
                             observed = OBS,
                             expected = EXP,
                             residuals = (OBS - EXP)/sqrt(EXP),
                             CR = CR,
                             method.key = method),
                        class = "htest")
  return(result)
}
                         
print.quadrattest <- function(x, ...) {
   NextMethod("print")
   if(is.atomicQtest(x)) {
     cat("Quadrats: ")
   } else {
     cat("Pooled test\nQuadrats of component tests:\n")
   }
   do.call("print",
           resolve.defaults(list(x=as.tess(x)),
                            list(...),
                            list(brief=TRUE)))
   return(invisible(NULL))
}

plot.quadrattest <- local({

  plot.quadrattest <- function(x, ..., textargs=list()) {
    xname <- short.deparse(substitute(x))

    if(!is.atomicQtest(x)) {
      # pooled test - plot the original tests
      tests <- extractAtomicQtests(x)
      do.call("plot",
              resolve.defaults(list(x=tests),
                               list(...),
                               list(main=xname)))
      return(invisible(NULL))
    }
    Xcount <- attr(x, "quadratcount")

    # plot tessellation
    tess  <- as.tess(Xcount)
    do.call("plot.tess",
            resolve.defaults(list(tess),
                             list(...),
                             list(main=xname)))
    # compute locations for text
    til <- tiles(tess)
    ok <- unlist(lapply(til, function(x) { !is.null(x) && area(x) > 0 }))
    incircles <- lapply(til[ok], incircle)
    x0 <- unlist(lapply(incircles, function(z) { z$x }))
    y0 <- unlist(lapply(incircles, function(z) { z$y }))
    ra <- unlist(lapply(incircles, function(z) { z$r }))
    # plot observed counts
    cos30 <- sqrt(2)/2
    sin30 <- 1/2
    f <- 0.4
    dotext(-f * cos30, f * sin30,
           as.vector(t(as.table(Xcount)))[ok],
           x0, y0, ra, textargs, 
           adj=c(1,0), ...)
    # plot expected counts
    dotext(f * cos30, f * sin30,
           round(x$expected,1)[ok],
           x0, y0, ra, textargs,
           adj=c(0,0), ...)
    # plot Pearson residuals
    dotext(0, -f,  signif(x$residuals,2)[ok],
           x0, y0, ra, textargs,
           ...)
    return(invisible(NULL))
  }
 
  dotext <- function(dx, dy, values, x0, y0, ra, textargs, ...) {
    do.call.matched("text.default",
                    resolve.defaults(list(x=x0 + dx * ra, y = y0 + dy * ra),
                                     list(labels=paste(as.vector(values))),
                                     textargs, 
                                     list(...)))
  }

  plot.quadrattest
})

########  pooling multiple quadrat tests into a quadrat test

pool.quadrattest <- function(...,
                             df=NULL, df.est=NULL, nsim=1999, Xname=NULL,
                             CR=NULL) {
  argh <- list(...)
  if(!is.null(df) + !is.null(df.est))
    stop("Arguments df and df.est are incompatible")
  
  if(all(unlist(lapply(argh, inherits, what="quadrattest")))) {
    # Each argument is a quadrattest object
    tests <- argh
  } else if(length(argh) == 1 &&
            is.list(arg1 <- argh[[1]]) &&
            all(unlist(lapply(arg1, inherits, "quadrattest")))) {
    # There is just one argument, which is a list of quadrattests
    tests <- arg1
  } else stop("Each entry in the list must be a quadrat test")

  # data from all cells in all tests
  OBS <- unlist(lapply(tests, getElement, name="observed"))
  EXP <- unlist(lapply(tests, getElement, name="expected"))
  # RES <- unlist(lapply(tests, getElement, name="residuals"))
  # STA <- unlist(lapply(tests, getElement, name="statistic"))

  # information about each test
  Mkey <- unlist(lapply(tests, getElement, name="method.key"))
  Testname <- lapply(tests, getElement, name="method")
  Alternative <- unlist(lapply(tests, getElement, name="alternative"))
  Conditional <- unlist(lapply(tests, getElement, name="conditional"))
  
  # name of data
  if(is.null(Xname)) {
    Nam <-  unlist(lapply(tests, getElement, name="data.name"))
    Xname <- commasep(sQuote(Nam))
  }

  # name of test
  testname    <- unique(Testname)
  method.key <- unique(Mkey)
  if(length(testname) > 1)
    stop(paste("Cannot combine different types of tests:",
               commasep(sQuote(method.key))))
  testname <- testname[[1]]

  # alternative hypothesis
  alternative <- unique(Alternative)
  if(length(alternative) > 1)
    stop(paste("Cannot combine tests with different alternatives:",
               commasep(sQuote(alternative))))

  # conditional tests
  conditional <- any(Conditional)
  if(conditional)
    stop("Sorry, not implemented for conditional tests")

  # Cressie-Read exponent
  if(is.null(CR)) {
    CR <- unlist(lapply(tests, getElement, name="CR"))
    CR <- unique(CR)
    if(length(CR) > 1) {
      warning("Tests used different values of CR; assuming CR=1")
      CR <- 1
    }
  }
                 
  if(method.key == "Chisq") {
    # determine degrees of freedom
    if(is.null(df)) {
      if(!is.null(df.est)) {
        # total number of observations minus number of fitted parameters
        df <- length(OBS) - df.est
      } else {
        # total degrees of freedom of tests
        # implicitly assumes independence of tests
        PAR <- unlist(lapply(tests, getElement, name="parameter"))
        df <- sum(PAR)
      }
    }
    # validate df
    if(df < 1)
      stop(paste("Degrees of freedom = ", df))
    names(df) <- "df"
  }
    
  # perform test
  result <- X2testEngine(OBS, EXP,
                         method=method.key, df=df, nsim=nsim,
                         conditional=conditional, CR=CR,
                         alternative=alternative,
                         testname=testname, dataname=Xname)
  # add info
  class(result) <- c("quadrattest", class(result))
  attr(result, "tests") <- as.listof(tests)
  # there is no quadratcount attribute 
  return(result)
}

is.atomicQtest <- function(x) {
  inherits(x, "quadrattest") && is.null(attr(x, "tests"))
}

extractAtomicQtests <- function(x) {
  if(is.atomicQtest(x))
    return(list(x))
  stopifnot(inherits(x, "quadrattest"))
  tests <- attr(x, "tests")
  y <- lapply(tests, extractAtomicQtests)
  z <- do.call("c", y)
  return(as.listof(z))
}

as.tess.quadrattest <- function(X) {
  if(is.atomicQtest(X)) {
    Y <- attr(X, "quadratcount")
    return(as.tess(Y))
  }
  tests <- extractAtomicQtests(X)
  return(as.listof(lapply(tests, as.tess.quadrattest)))
}

as.owin.quadrattest <- function(W, ..., fatal=TRUE) {
  if(is.atomicQtest(W))
    return(as.owin(as.tess(W), ..., fatal=fatal))    
  gezeur <- paste("Cannot convert quadrat test result to a window;",
                  "it contains data for several windows")
  if(fatal) stop(gezeur) else warning(gezeur)
  return(NULL)
}

domain.quadrattest <- Window.quadrattest <- function(X, ...) { as.owin(X) }

## The shift method is undocumented.
## It is only needed in plot.listof

shift.quadrattest <- function(X, ...) {
  if(is.atomicQtest(X)) {
    attr(X, "quadratcount") <- qc <- shift(attr(X, "quadratcount"), ...)
    attr(X, "lastshift") <- getlastshift(qc)
  } else {
    tests <- extractAtomicQtests(X)
    attr(X, "tests") <- te <- lapply(tests, shift, ...)
    attr(X, "lastshift") <- getlastshift(te[[1]])
  }
  return(X)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/quadscheme.R"
#
#
#      quadscheme.S
#
#      $Revision: 4.33 $    $Date: 2014/11/22 02:19:30 $
#
#      quadscheme()    generate a quadrature scheme from 
#		       data and dummy point patterns.
#
#      quadscheme.spatial()    case where both patterns are unmarked
#
#      quadscheme.replicated() case where data are multitype
#
#
#---------------------------------------------------------------------

quadscheme <- function(data, dummy, method="grid", ...) {
        #
	# generate a quadrature scheme from data and dummy patterns.
	#
	# Other arguments control how the quadrature weights are computed
        #

  data <- as.ppp(data)

  if(missing(dummy)) {
    # create dummy points
    dummy <- default.dummy(data, method=method, ...)
    # extract full set of parameters used to create dummy points
    dp <- attr(dummy, "dummy.parameters")
    # extract recommended parameters for computing weights
    wp <- attr(dummy, "weight.parameters")
  } else {
    # user-supplied dummy points
    if(!is.ppp(dummy)) {
      # convert to ppp object
      dummy <- as.ppp(dummy, data$window, check=FALSE)
      # confine dummy points to data window 
      dummy <- dummy[data$window]
      wp <- dp <- list()
    } else {
      # if it's already a ppp, it may have been created by default.dummy
     dp <- attr(dummy, "dummy.parameters")
     wp <- attr(dummy, "weight.parameters")     
   }
  }
  # arguments supplied directly to quadscheme()
  # override any arguments passed as attributes
  wp <- resolve.defaults(list(method=method), list(...), wp)
  
  mX <- is.marked(data)
  mD <- is.marked(dummy)

  if(!mX && !mD)
    Q <- do.call("quadscheme.spatial",
                 append(list(data, dummy, check=FALSE), wp))
  else if(mX && !mD)
    Q <- do.call("quadscheme.replicated",
                 append(list(data, dummy, check=FALSE), wp))
  else if(!mX && mD)
    stop("dummy points are marked but data are unmarked")
  else
    stop("marked data and marked dummy points -- sorry, this case is not implemented")

  # record parameters used to make dummy points
  Q$param$dummy <- dp

  return(Q)
}

quadscheme.spatial <-
  function(data, dummy, method="grid", ...) {
        #
	# generate a quadrature scheme from data and dummy patterns.
	#
	# The 'method' may be "grid" or "dirichlet"
	#
	# '...' are passed to gridweights() or dirichlet.weights()
        #
        # quadscheme.spatial:
        #       for unmarked point patterns.
        #
        #       weights are determined only by spatial locations
        #       (i.e. weight computations ignore any marks)
	#
        # No two points should have the same spatial location
        # 

    check <- resolve.defaults(list(...), list(check=TRUE))$check
    
    data <- as.ppp(data, check=check)
    dummy <- as.ppp(dummy, data$window, check=check)
    # note data$window is the DEFAULT quadrature window
    # applicable when 'dummy' does not contain a window

    if(is.marked(data, dfok=TRUE))
      warning("marks in data pattern - ignored")
    if(is.marked(dummy, dfok=TRUE))
      warning("marks in dummy pattern - ignored")
    
    both <- as.ppp(concatxy(data, dummy), dummy$window, check=check)
    switch(method,
           grid={
             w <- gridweights(both, window= dummy$window, ...)
           },
           dirichlet = {
             w <- dirichlet.weights(both, window=dummy$window, ...)
           },
           { 
             stop(paste("unrecognised method", sQuote(method)))
           }
           )
    # parameters actually used to make weights
    wp <- attr(w, "weight.parameters")
    param <- list(weight = wp, dummy = NULL)
    
    Q <- quad(data, dummy, w, param)
    return(Q)
  }

"quadscheme.replicated" <-
  function(data, dummy, method="grid", ...) {
    ##
    ## generate a quadrature scheme from data and dummy patterns.
    ##
    ## The 'method' may be "grid" or "dirichlet"
    ##
    ## '...' are passed to gridweights() or dirichlet.weights()
    ##
    ## quadscheme.replicated:
    ##       for multitype point patterns.
    ##
    ## No two points in 'data'+'dummy' should have the same spatial location

    check <- resolve.defaults(list(...), list(check=TRUE))$check

    data <- as.ppp(data, check=check)
    dummy <- as.ppp(dummy, data$window, check=check)
		## note data$window is the DEFAULT quadrature window
		## unless otherwise specified in 'dummy'
    ndata <- data$n
    ndummy <- dummy$n

    if(!is.marked(data))
      stop("data pattern does not have marks")
    if(is.marked(dummy, dfok=TRUE) && npoints(dummy) > 0)
      warning("dummy points have marks --- ignored")

    ## first, ignore marks and compute spatial weights
    P <- quadscheme.spatial(unmark(data), dummy, method, ...)
    W <- w.quad(P)
    iz <- is.data(P)
    Wdat <- W[iz]
    Wdum <- W[!iz]

    ## find the set of all possible marks

    if(!is.multitype(data))
      stop("data pattern is not multitype")
    data.marks <- marks(data)
    markset <- levels(data.marks)
    nmarks <- length(markset)
    
    ## replicate dummy points, one copy for each possible mark
    ## -> dummy x {1,..,K}
        
    dumdum <- cartesian(dummy, markset)
    Wdumdum <- rep.int(Wdum, nmarks)
    Idumdum <- rep.int(ndata + seq_len(ndummy), nmarks)
        
    ## also make dummy marked points at same locations as data points
    ## but with different marks

    dumdat <- cartesian(unmark(data), markset)
    Wdumdat <- rep.int(Wdat, nmarks)
    Mdumdat <- marks(dumdat)
    Idumdat <- rep.int(1:ndata, nmarks)
        
    Mrepdat <- rep.int(data.marks, nmarks)

    ok <- (Mdumdat != Mrepdat)
    dumdat <- dumdat[ok,]
    Wdumdat <- Wdumdat[ok]
    Idumdat <- Idumdat[ok]

    ## combine the two dummy patterns
    dumb <- superimpose(dumdum, dumdat, W=dummy$window, check=FALSE)
    Wdumb <- c(Wdumdum, Wdumdat)
    Idumb <- c(Idumdum, Idumdat)
    
    ## record the quadrature parameters
    param <- list(weight = P$param$weight,
                  dummy = NULL,
                  sourceid=c(1:ndata, Idumb))

    ## wrap up
    Q <- quad(data, dumb, c(Wdat, Wdumb), param)
    return(Q)
}


"cartesian" <-
function(pp, markset, fac=TRUE) {
  ## given an unmarked point pattern 'pp'
  ## and a finite set of marks,
  ## create the marked point pattern which is
  ## the Cartesian product, consisting of all pairs (u,k)
  ## where u is a point of 'pp' and k is a mark in 'markset'
  nmarks <- length(markset)
  result <- ppp(rep.int(pp$x, nmarks),
                rep.int(pp$y, nmarks),
                window=pp$window,
                check=FALSE)
  marx <- rep.int(markset, rep.int(pp$n, nmarks))
  if(fac)
    marx <- factor(marx, levels=markset)
  marks(result) <- marx
  return(result)
}


validate.quad <- function(Q, fatal=FALSE, repair=TRUE, announce=FALSE) {
  X <- Q$data
  D <- Q$dummy
  mX <- is.marked(X)
  mD <- is.marked(D)
  nbg <- function(whinge, fatal=FALSE, announce=FALSE) {
    if(fatal)
      stop(whinge, call.=FALSE)
    else {
      if(announce)
        warning(whinge, call.=FALSE)
      return(FALSE)
    }
  }
  if(mX != mD) {
    whinge <-
      if(mX)
        "data points are marked, but dummy points are not"
      else
        "dummy points are marked, but data points are not"
    return(nbg(whinge, fatal, announce))
  }
  if(!mX)
    return(TRUE)
  # marked points 
  fX <- is.factor(Xmarx <- marks(X))
  fD <- is.factor(Dmarx <- marks(D))
  if(fX != fD) {
    whinge <-
      if(fX)
        "data points are multitype, but dummy points are not"
      else
        "dummy points are multitype, but data points are not"
    return(nbg(whinge, fatal, announce))
  }
  if(!fX)
    return(TRUE)
  # multitype points
  lX <- levels(Xmarx)
  lD <- levels(Dmarx)
  if(length(lX) != length(lD) || any(lX != lD)) {
    whinge <- "data and dummy points have different sets of possible marks"
    return(nbg(whinge, fatal, announce))
  }
  return(TRUE)
}

  

pixelquad <- function(X, W=as.owin(X)) {
  ## make a quadscheme with a dummy point at every pixel
  verifyclass(X, "ppp")
  
  ## convert window to mask if not already one
  W <- as.owin(W)
  M <- as.mask(W)
  MM <- M$m
  pixelarea <- M$xstep * M$ystep
  
  ## create pixel coordinates and corresponding row, column indices
  rxy <- rasterxy.mask(M, drop=TRUE)
  xx <- rxy$x
  yy <- rxy$y
  cc <- as.vector(col(MM)[MM])
  rr <- as.vector(row(MM)[MM])
  Nr <- M$dim[1]
  Nc <- M$dim[2]
  
  ## dummy point pattern
  dum <- ppp(xx, yy, window=W, check=FALSE)
  
  ## discretise data points
  ij <- nearest.raster.point(X$x, X$y, M)
  ijrow <- ij$row
  ijcol <- ij$col


  if(!is.marked(X)) {
    ## tabulate pixel locations of data points
    Xtab <- table(row=factor(ijrow, levels=1:Nr),
                  col=factor(ijcol, levels=1:Nc))
    ## every pixel contains exactly one dummy point,
    ## so the total count of quadrature points in each pixel is:
    Qtab <- Xtab + 1
    ## compute counting weights for data points
    wdat <- 1/Qtab[cbind(ijrow, ijcol)]
    ## compute counting weights for dummy points
    wdum <- 1/Qtab[cbind(rr, cc)]
  } else {
    marx <- marks(X)
    ## tabulate pixel locations and marks of data points
    Xtab <- table(row=factor(ijrow, levels=1:Nr),
                  col=factor(ijcol, levels=1:Nc),
                  mark=marx)
    ## replicate dummy points (pixel centres) for each mark
    dum <- cartesian(dum, levels(marx))
    ## every marked pixel contains exactly one dummy point,
    ## so the total count of quadrature points in each marked pixel is:
    Qtab <- Xtab + 1
    ## compute counting weights for data points
    wdat <- 1/Qtab[cbind(ijrow, ijcol, as.integer(marx))]
    ## compute counting weights for dummy points
    nm <- length(levels(marx))
    wdum <- 1/Qtab[cbind(rep.int(rr, nm),
                         rep.int(cc, nm),
                         rep(1:nm, each=length(rr)))]
  }
  ## create quadrature scheme
  wboth <- pixelarea * c(wdat, wdum)
  Q <- quad(X, dum, wboth)
  
  attr(Q, "M") <- M
  return(Q)
}

  
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/quasirandom.R"
##
##     quasirandom.R
##
##  Quasi-random sequence generators
##
##  $Revision: 1.5 $   $Date: 2014/10/24 00:22:30 $
##

vdCorput <- function(n, base) {
  stopifnot(is.prime(base))
  z <- .C("Corput",
          base=as.integer(base),
          n=as.integer(n),
          result=as.double(numeric(n)))
  return(z$result)
}

Halton <- function(n, bases=c(2,3), raw=FALSE, simplify=TRUE) {
  d <- length(bases)
  if(d==2 && !raw && simplify)
    return(ppp(vdCorput(n, bases[1]),
               vdCorput(n, bases[2]),
               window=owin(), check=FALSE))
  z <- matrix(, nrow=n, ncol=d)
  for(j in 1:d)
    z[,j] <- vdCorput(n, bases[j])
  if(raw || d < 2) return(z)
  b <- do.call(boxx, rep(list(c(0,1)), d))
  return(ppx(z, b, simplify=simplify))
}

Hammersley <- function(n, bases=2, raw=FALSE, simplify=TRUE) {
  d <- length(bases) + 1
  z <- cbind(Halton(n, bases, raw=TRUE), (1:n)/n)
  dimnames(z) <- NULL
  if(raw || d < 2) return(z)
  b <- do.call(boxx, rep(list(c(0,1)), d))
  return(ppx(z, b, simplify=simplify))
}

rQuasi <- function(n, W, type=c("Halton", "Hammersley"), ...) {
  R <- as.rectangle(W)
  type <- match.arg(type)
  X <- switch(type,
              Halton=Halton(n, ...),
              Hammersley=Hammersley(n, ...))
  Y <- ppp(R$xrange[1] + diff(R$xrange) * X$x,
           R$yrange[1] + diff(R$yrange) * X$y,
           window=R, check=FALSE)
  if(!is.rectangle(W))
    Y <- Y[W]
  return(Y)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rLGCP.R"
#
#   rLGCP.R
#
#   simulation of log-Gaussian Cox process
#
#   original code by Abdollah Jalilian
#
#  $Revision: 1.10 $    $Date: 2014/08/27 09:50:07 $
#

rLGCP <- function(model="exp", mu = 0, param = NULL, ...,
                  win=NULL, saveLambda=TRUE)
{
  if(!missing(mu)) {
    if (!(is.numeric(mu) || is.function(mu) || is.im(mu))) 
      stop(paste(sQuote("mu"), "must be a constant, a function or an image"))
    if (is.numeric(mu) && !(length(mu) == 1)) 
      stop(paste(sQuote("mu"), "must be a single number"))
  }
  if(!require(RandomFields))
    stop("Simulation of log-Gaussian Cox process requires the package RandomFields")
  win.given <- !is.null(win)
  mu.image <- is.im(mu)
  win <- if(win.given) as.owin(win) else if(mu.image) as.owin(mu) else owin()
  
  if(win.given && mu.image && !is.subset.owin(win, as.owin(mu)))
    stop(paste("The spatial domain of the pixel image", sQuote("mu"),
               "does not cover the simulation window", sQuote("win")))

  ## convert win to a mask
  dc <- do.call.matched(as.mask, append(list(w=win), list(...)), sieve=TRUE)
  w  <- dc$result
  dotargs <- dc$otherargs
  
  xcol <- w$xcol
  yrow <- w$yrow
  dim <- w$dim
  xy <- expand.grid(x=xcol, y=yrow)
  xx <- xy$x
  yy <- xy$y

  muxy <- if(is.numeric(mu)) mu else
          if (is.function(mu)) mu(xx,yy) else
          lookup.im(mu, xx, yy, naok=TRUE, strict=TRUE)
  muxy[is.na(muxy)] <- -Inf

  ## check for outdated usage
  plist <- as.list(param)
  if(!all(nzchar(names(plist))))
    stop("Outdated syntax of argument 'param' to rLGCP", call.=FALSE)
  
  ## get the 'model generator'
  modelname <- if(model == "exponential") "exp" else model
  modgen <- mget(paste0("RM", modelname), inherits=TRUE,
                 ifnotfound=list(NULL))[[1]]
  if(is.null(modgen) || !inherits(modgen, "RMmodelgenerator"))
    stop(paste("Model", sQuote(modelname), "is not recognised"))
  ## now create a RandomFields 'model' object
  rfmodel <- do.call(modgen, append(plist, dotargs))
  
  ## generate zero-mean Gaussian random field
  spc <- RandomFields::RFoptions()$general$spConform
  if(spc) RandomFields::RFoptions(spConform=FALSE)
  z <- RandomFields::RFsimulate(rfmodel, xcol, yrow, grid = TRUE)
  if(spc) RandomFields::RFoptions(spConform=TRUE)

  ## convert to log-Gaussian image
  logLambda <- muxy + z
  Lambda <- matrix(exp(logLambda), nrow=dim[1], ncol=dim[2], byrow=TRUE)
  Lambda <- as.im(Lambda, W=w)
  # generate Poisson points
  X <- rpoispp(Lambda)[win]
  # 
  if(saveLambda)
    attr(X, "Lambda") <- Lambda
  
  return(X)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rPerfect.R"
#
#  Perfect Simulation 
#
#  $Revision: 1.17 $ $Date: 2014/11/17 05:04:59 $
#
#  rStrauss
#  rHardcore
#  rStraussHard
#  rDiggleGratton
#  rDGS

rStrauss <- function(beta, gamma=1, R=0, W=owin(), expand=TRUE, nsim=1) {

  if(!missing(W)) 
    verifyclass(W, "owin")

  check.1.real(beta)
  check.1.real(gamma)
  check.1.real(R)

  check.finite(beta)
  check.finite(gamma)
  check.finite(R)
  
  stopifnot(beta > 0)
  stopifnot(gamma >= 0)
  stopifnot(gamma <= 1)
  stopifnot(R >= 0)

  runif(1)

  Wsim <- expandwinPerfect(W, expand, rmhexpand(distance=2*R))
  xrange <- Wsim$xrange
  yrange <- Wsim$yrange

  result <- vector(mode="list", length=nsim)

  for(i in 1:nsim) {
    storage.mode(beta) <- storage.mode(gamma) <- storage.mode(R) <- "double"
    storage.mode(xrange) <- storage.mode(yrange) <- "double"
  
    z <- .Call("PerfectStrauss",
               beta,
               gamma,
               R,
               xrange,
               yrange)

    X <- z[[1]]
    Y <- z[[2]]
    nout <- z[[3]]
    times <- c(start=z[[4]], end=z[[5]])
    
    if(nout<0)
      stop("internal error: copying failed in PerfectStrauss")

    seqn <- seq_len(nout)
    P <- ppp(X[seqn], Y[seqn], window=Wsim, check=FALSE)
    if(attr(Wsim, "changed"))
      P <- P[W]
    attr(P, "times") <- times

    if(nsim == 1) return(P)
    
    result[[i]] <- P
  }
  result <- as.solist(result)
  names(result) <- paste("Simulation", 1:nsim)
  return(result)
}

#  Perfect Simulation of Hardcore process

rHardcore <- function(beta, R=0, W=owin(), expand=TRUE, nsim=1) {
  if(!missing(W)) 
    verifyclass(W, "owin")

  check.1.real(beta)
  check.1.real(R)

  check.finite(beta)
  check.finite(R)

  stopifnot(beta > 0)
  stopifnot(R    >= 0)

  runif(1)

  Wsim <- expandwinPerfect(W, expand, rmhexpand(distance=2*R))
  xrange <- Wsim$xrange
  yrange <- Wsim$yrange

  result <- vector(mode="list", length=nsim)

  for(i in 1:nsim) {
    storage.mode(beta) <- storage.mode(R) <- "double"
    storage.mode(xrange) <- storage.mode(yrange) <- "double"
  
    z <- .Call("PerfectHardcore",
               beta,
               R,
               xrange,
               yrange)

    X <- z[[1]]
    Y <- z[[2]]
    nout <- z[[3]]
    
    if(nout<0)
      stop("internal error: copying failed in PerfectHardcore")

    seqn <- seq_len(nout)
    P <- ppp(X[seqn], Y[seqn], window=Wsim, check=FALSE)
    if(attr(Wsim, "changed"))
      P <- P[W]

    if(nsim == 1) return(P)
    result[[i]] <- P
  }
  result <- as.solist(result)
  names(result) <- paste("Simulation", 1:nsim)
  return(result)
}

#
#  Perfect simulation of hybrid Strauss-Hardcore
#        provided gamma <= 1
#

rStraussHard <- function(beta, gamma=1, R=0, H=0, W=owin(), expand=TRUE, nsim=1) {
  if(!missing(W)) 
    verifyclass(W, "owin")

  check.1.real(beta)
  check.1.real(gamma)
  check.1.real(R)
  check.1.real(H)

  check.finite(beta)
  check.finite(gamma)
  check.finite(R)
  check.finite(H)
  
  stopifnot(beta > 0)
  stopifnot(gamma >= 0)
  if(gamma > 1)
    stop("Sorry, perfect simulation is only implemented for gamma <= 1")
  stopifnot(R >= 0)
  stopifnot(H >= 0)
  stopifnot(H <= R)

  runif(1)

  Wsim <- expandwinPerfect(W, expand, rmhexpand(distance=2*R))
  xrange <- Wsim$xrange
  yrange <- Wsim$yrange

  result <- vector(mode="list", length=nsim)

  for(i in 1:nsim) {
    storage.mode(beta) <- storage.mode(gamma) <-
      storage.mode(R) <- storage.mode(H) <- "double"
    storage.mode(xrange) <- storage.mode(yrange) <- "double"
  
    z <- .Call("PerfectStraussHard",
               beta,
               gamma,
               R,
               H,
               xrange,
               yrange)

    X <- z[[1]]
    Y <- z[[2]]
    nout <- z[[3]]

    if(nout<0)
      stop("internal error: copying failed in PerfectStraussHard")

    seqn <- seq_len(nout)
    P <- ppp(X[seqn], Y[seqn], window=Wsim, check=FALSE)
    if(attr(Wsim, "changed"))
      P <- P[W]

    if(nsim == 1) return(P)
    result[[i]] <- P
  }
  result <- as.solist(result)
  names(result) <- paste("Simulation", 1:nsim)
  return(result)
}

#
#  Perfect Simulation of Diggle-Gratton process
#

rDiggleGratton <- function(beta, delta, rho, kappa=1, W=owin(),
                           expand=TRUE, nsim=1) {
  if(!missing(W)) 
    verifyclass(W, "owin")

  check.1.real(beta)
  check.1.real(delta)
  check.1.real(rho)
  check.1.real(kappa)

  check.finite(beta)
  check.finite(delta)
  check.finite(rho)
  check.finite(kappa)

  stopifnot(beta > 0)
  stopifnot(delta >= 0)
  stopifnot(rho   >= 0)
  stopifnot(delta <= rho)
  stopifnot(kappa >= 0)

  runif(1)

  Wsim <- expandwinPerfect(W, expand, rmhexpand(distance=2*rho))
  xrange <- Wsim$xrange
  yrange <- Wsim$yrange

  result <- vector(mode="list", length=nsim)

  for(i in 1:nsim) {
    storage.mode(beta) <- "double"
    storage.mode(delta) <- storage.mode(rho) <- storage.mode(kappa) <- "double"
    storage.mode(xrange) <- storage.mode(yrange) <- "double"
  
    z <- .Call("PerfectDiggleGratton",
               beta,
               delta,
               rho,
               kappa,
               xrange,
               yrange)

    X <- z[[1]]
    Y <- z[[2]]
    nout <- z[[3]]

    if(nout<0)
      stop("internal error: copying failed in PerfectDiggleGratton")

    seqn <- seq_len(nout)
    P <- ppp(X[seqn], Y[seqn], window=Wsim, check=FALSE)
    if(attr(Wsim, "changed"))
      P <- P[W]

    if(nsim == 1) return(P)
    result[[i]] <- P
  }
  result <- as.solist(result)
  names(result) <- paste("Simulation", 1:nsim)
  return(result)
}


#
#  Perfect Simulation of Diggle-Gates-Stibbard process
#

rDGS <- function(beta, rho, W=owin(), expand=TRUE, nsim=1) {
  if(!missing(W)) 
    verifyclass(W, "owin")

  check.1.real(beta)
  check.1.real(rho)

  check.finite(beta)
  check.finite(rho)

  stopifnot(beta > 0)
  stopifnot(rho  >= 0)

  runif(1)

  Wsim <- expandwinPerfect(W, expand, rmhexpand(distance=2*rho))
  xrange <- Wsim$xrange
  yrange <- Wsim$yrange

  result <- vector(mode="list", length=nsim)

  for(i in 1:nsim) {
    storage.mode(beta) <- "double"
    storage.mode(rho) <- "double"
    storage.mode(xrange) <- storage.mode(yrange) <- "double"
  
    z <- .Call("PerfectDGS",
               beta,
               rho,
               xrange,
               yrange)

    X <- z[[1]]
    Y <- z[[2]]
    nout <- z[[3]]
    
    if(nout<0)
      stop("internal error: copying failed in PerfectDGS")
    
    seqn <- seq_len(nout)
    P <- ppp(X[seqn], Y[seqn], window=Wsim, check=FALSE)
    if(attr(Wsim, "changed"))
      P <- P[W]

    if(nsim == 1) return(P)
    result[[i]] <- P
  }
  result <- as.solist(result)
  names(result) <- paste("Simulation", 1:nsim)
  return(result)
}


## .......  utilities .................................

expandwinPerfect <- function(W, expand, amount) {
  ## expand 'W' if expand=TRUE according to default 'amount'
  ## or expand 'W' using rmhexpand(expand)
  if(!is.logical(expand)) {
    amount <- rmhexpand(expand)
    expand <- TRUE
  }
  changed <- FALSE
  if(expand) {
    W <- expand.owin(W, amount)
    changed <- TRUE
  }
  if(!is.rectangle(W)) {
    W <- as.rectangle(W)
    changed <- TRUE
    warning(paste("Simulation will be performed in the containing rectangle",
                  "and clipped to the original window."),
            call.=FALSE)
  }
  attr(W, "changed") <- changed
  return(W)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/random.R"
##
##    random.R
##
##    Functions for generating random point patterns
##
##    $Revision: 4.71 $   $Date: 2014/11/27 03:25:32 $
##
##
##    runifpoint()      n i.i.d. uniform random points ("binomial process")
##
##    runifpoispp()     uniform Poisson point process
##
##    rpoispp()         general Poisson point process (thinning method)
##
##    rpoint()          n independent random points (rejection/pixel list)
##
##    rMaternI()        Mat'ern model I 
##    rMaternII()       Mat'ern model II
##    rSSI()            Simple Sequential Inhibition process
##
##    rthin()           independent random thinning
##    rjitter()         random perturbation
##
##    Examples:
##          u01 <- owin(0:1,0:1)
##          plot(runifpoispp(100, u01))
##          X <- rpoispp(function(x,y) {100 * (1-x/2)}, 100, u01)
##          X <- rpoispp(function(x,y) {ifelse(x < 0.5, 100, 20)}, 100)
##          plot(X)
##          plot(rMaternI(100, 0.02))
##          plot(rMaternII(100, 0.05))
##

runifrect <- function(n, win=owin(c(0,1),c(0,1)), nsim=1)
{
  ## no checking
  xr <- win$xrange
  yr <- win$yrange
  if(nsim == 1) {
    x <- runif(n, min=xr[1], max=xr[2])
    y <- runif(n, min=yr[1], max=yr[2])
    return(ppp(x, y, window=win, check=FALSE))
  } 
  result <- vector(mode="list", length=nsim)
  for(isim in 1:nsim) {
    x <- runif(n, min=xr[1], max=xr[2])
    y <- runif(n, min=yr[1], max=yr[2])
    result[[isim]] <- ppp(x, y, window=win, check=FALSE)
  }
  return(as.solist(result))
}

runifdisc <- function(n, radius=1, centre=c(0,0), ..., nsim=1)
{
  ## i.i.d. uniform points in the disc of radius r and centre (x,y)
  disque <- disc(centre=centre, radius=radius, ...)
  if(nsim == 1) {
    theta <- runif(n, min=0, max= 2 * pi)
    s <- sqrt(runif(n, min=0, max=radius^2))
    return(ppp(centre[1] + s * cos(theta),
               centre[2] + s * sin(theta),
               window=disque, check=FALSE))
  }
  result <- vector(mode="list", length=nsim)
  for(isim in 1:nsim) {
    theta <- runif(n, min=0, max= 2 * pi)
    s <- sqrt(runif(n, min=0, max=radius^2))
    result[[isim]] <- ppp(centre[1] + s * cos(theta),
                          centre[2] + s * sin(theta),
                          window=disque, check=FALSE)
  }
  return(as.solist(result))
}


runifpoint <- function(n, win=owin(c(0,1),c(0,1)),
                       giveup=1000, warn=TRUE, ..., nsim=1)
{
  win <- as.owin(win)
    
  check.1.integer(n)
  stopifnot(n >= 0)

  if(n == 0) {
    emp <- ppp(numeric(0), numeric(0), window=win)
    if(nsim == 1) return(emp)
    result <- rep(list(emp), nsim)
    names(result) <- paste("Simulation", 1:nsim)
    return(as.solist(result))
  }

  if(warn) {
    nhuge <- spatstat.options("huge.npoints")
    if(n > nhuge)
      warning(paste("Attempting to generate", n, "random points"))
  }

  switch(win$type,
         rectangle = {
           return(runifrect(n, win, nsim=nsim))
         },
         mask = {
           dx <- win$xstep
           dy <- win$ystep
           ## extract pixel coordinates and probabilities
           rxy <- rasterxy.mask(win, drop=TRUE)
           xpix <- rxy$x
           ypix <- rxy$y
           ## make a list of nsim point patterns
           result <- vector(mode="list", length=nsim)
           for(isim in 1:nsim) {
             ## select pixels with equal probability
             id <- sample(seq_along(xpix), n, replace=TRUE)
             ## extract pixel centres and randomise within pixels
             x <- xpix[id] + runif(n, min= -dx/2, max=dx/2)
             y <- ypix[id] + runif(n, min= -dy/2, max=dy/2)
             result[[isim]] <- ppp(x, y, window=win, check=FALSE)
           }
         },
         polygonal={
           ## make a list of nsim point patterns
           result <- vector(mode="list", length=nsim)
           for(isim in 1:nsim) {
             ## rejection method
             ## initialise empty pattern
             x <- numeric(0)
             y <- numeric(0)
             X <- ppp(x, y, window=win)
             ##
             ## rectangle in which trial points will be generated
             box <- boundingbox(win)
             ## 
             ntries <- 0
             repeat {
               ntries <- ntries + 1
               ## generate trial points in batches of n
               qq <- runifrect(n, box) 
               ## retain those which are inside 'win'
               qq <- qq[win]
               ## add them to result
               X <- superimpose(X, qq, W=win, check=FALSE)
               ## if we have enough points, exit
               if(X$n > n) {
                 result[[isim]] <- X[1:n]
                 break
               } else if(X$n == n) {
                 result[[isim]] <- X
                 break
               } else if(ntries >= giveup) {
                 ## otherwise get bored eventually
                 stop(paste("Gave up after", giveup * n, "trials,",
                            X$n, "points accepted"))
               }
             }
           }
         },
         stop("Unrecognised window type")
         )
  
  ## list of point patterns produced.
  if(nsim == 1)
    return(result[[1]])
  names(result) <- paste("Simulation", 1:nsim)
  return(as.solist(result))
}

runifpoispp <- function(lambda, win = owin(c(0,1),c(0,1)), ..., nsim=1) {
  win <- as.owin(win)
  if(!is.numeric(lambda) || length(lambda) > 1 ||
     !is.finite(lambda) || lambda < 0)
    stop("Intensity lambda must be a single finite number >= 0")

  if(lambda == 0) {
    ## return empty pattern
    emp <- ppp(numeric(0), numeric(0), window=win)
    if(nsim == 1) return(emp)
    result <- rep(list(emp), nsim)
    names(result) <- paste("Simulation", 1:nsim)
    return(as.solist(result))
  }

  ## will generate Poisson process in enclosing rectangle and trim it
  box <- boundingbox(win)
  mean <- lambda * area(box)

  if(nsim == 1) {
    n <- rpois(1, mean)
    X <- runifpoint(n, box)
    ## trim to window
    if(win$type != "rectangle")
      X <- X[win]  
    return(X)
  }
  result <- vector(mode="list", length=nsim)
  for(isim in 1:nsim) {
    n <- rpois(1, mean)
    X <- runifpoint(n, box)
    ## trim to window
    if(win$type != "rectangle")
      X <- X[win]
    result[[isim]] <- X
  }
  names(result) <- paste("Simulation", 1:nsim)
  return(as.solist(result))
}

rpoint <- function(n, f, fmax=NULL,
                   win=unit.square(), ..., giveup=1000,verbose=FALSE,
                   nsim=1) {
  
  if(missing(f) || (is.numeric(f) && length(f) == 1))
    ## uniform distribution
    return(runifpoint(n, win, giveup, nsim=nsim))
  
  ## non-uniform distribution....
  if(!is.function(f) && !is.im(f))
    stop(paste(sQuote("f"),
               "must be either a function or an",
               sQuote("im"), "object"))
  
  if(is.im(f)) {
    ## ------------ PIXEL IMAGE ---------------------
    wf <- as.owin(f)
    if(n == 0) {
      ## return empty pattern(s)
      emp <- ppp(numeric(0), numeric(0), window=wf)
      if(nsim == 1) return(emp)
      result <- rep(list(emp), nsim)
      names(result) <- paste("Simulation", 1:nsim)
      return(as.solist(result))
    }
    w <- as.mask(wf)
    M <- w$m
    dx <- w$xstep
    dy <- w$ystep
    ## extract pixel coordinates and probabilities
    rxy <- rasterxy.mask(w, drop=TRUE)
    xpix <- rxy$x
    ypix <- rxy$y
    ppix <- as.vector(f$v[M]) ## not normalised - OK
    ##
    if(nsim == 1) {
      ## select pixels
      id <- sample(length(xpix), n, replace=TRUE, prob=ppix)
      ## extract pixel centres and randomise within pixels
      x <- xpix[id] + runif(n, min= -dx/2, max=dx/2)
      y <- ypix[id] + runif(n, min= -dy/2, max=dy/2)
      return(ppp(x, y, window=wf, check=FALSE))
    }
    result <- vector(mode="list", length=nsim)
    for(isim in 1:nsim) {
      ## select pixels
      id <- sample(length(xpix), n, replace=TRUE, prob=ppix)
      ## extract pixel centres and randomise within pixels
      x <- xpix[id] + runif(n, min= -dx/2, max=dx/2)
      y <- ypix[id] + runif(n, min= -dy/2, max=dy/2)
      result[[isim]] <- ppp(x, y, window=wf, check=FALSE)
    }
    names(result) <- paste("Simulation", 1:nsim)
    return(as.solist(result))
  }

  ## ------------ FUNCTION  ---------------------  
  ## Establish parameters for rejection method

  verifyclass(win, "owin")

  if(n == 0) {
    ## return empty pattern(s)
    emp <- ppp(numeric(0), numeric(0), window=win)
    if(nsim == 1) return(emp)
    result <- rep(list(emp), nsim)
    names(result) <- paste("Simulation", 1:nsim)
    return(as.solist(result))
  }
  
  if(is.null(fmax)) {
    ## compute approx maximum value of f
    imag <- as.im(f, win, ...)
    summ <- summary(imag)
    fmax <- summ$max + 0.05 * diff(summ$range)
  }
  irregular <- (win$type != "rectangle")
  box <- boundingbox(win)

  result <- vector(mode="list", length=nsim)
  for(isim in 1:nsim) {

    ## initialise empty pattern
    X <- ppp(numeric(0), numeric(0), window=win)
  
    pbar <- 1
    nremaining <- n
    totngen <- 0
    
    ## generate uniform random points in batches
    ## and apply the rejection method.
    ## Collect any points that are retained in X

    ntries <- 0
    repeat{
      ntries <- ntries + 1
      ## proposal points
      ngen <- nremaining/pbar + 10
      totngen <- totngen + ngen
      prop <- runifrect(ngen, box)
      if(irregular)
        prop <- prop[win]
      if(prop$n > 0) {
        fvalues <- f(prop$x, prop$y, ...)
        paccept <- fvalues/fmax
        u <- runif(prop$n)
        ## accepted points
        Y <- prop[u < paccept]
        if(Y$n > 0) {
          ## add to X
          X <- superimpose(X, Y, W=win, check=FALSE)
          nX <- X$n
          pbar <- nX/totngen
          nremaining <- n - nX
          if(nremaining <= 0) {
            ## we have enough!
            if(verbose)
              splat("acceptance rate = ", round(100 * pbar, 2), "%")
            result[[isim]] <- if(nX == n) X else X[1:n]
            break
          }
        }
      }
      if(ntries > giveup)
        stop(paste("Gave up after",giveup * n,"trials with",
                   X$n, "points accepted"))
    }
  }
  if(nsim == 1) return(result[[1]])
  names(result) <- paste("Simulation", 1:nsim)
  return(as.solist(result))
}

rpoispp <- function(lambda, lmax=NULL, win = owin(), ...,
                    nsim=1) {
  ## arguments:
  ##     lambda  intensity: constant, function(x,y,...) or image
  ##     lmax     maximum possible value of lambda(x,y,...)
  ##     win     default observation window (of class 'owin')
  ##   ...       arguments passed to lambda(x, y, ...)
  ##     nsim    number of replicate simulations
  
  if(!(is.numeric(lambda) || is.function(lambda) || is.im(lambda)))
    stop(paste(sQuote("lambda"),
               "must be a constant, a function or an image"))
  if(is.numeric(lambda) && !(length(lambda) == 1 && lambda >= 0))
    stop(paste(sQuote("lambda"),
               "must be a single, nonnegative number"))
  if(!is.null(lmax)) {
    if(!is.numeric(lmax))
      stop("lmax should be a number")
    if(length(lmax) > 1)
      stop("lmax should be a single number")
  }
  
  win <- if(is.im(lambda))
    rescue.rectangle(as.owin(lambda))
  else
    as.owin(win)
    
  if(is.numeric(lambda)) 
    ## uniform Poisson
    return(runifpoispp(lambda, win, nsim=nsim))

  ## inhomogeneous Poisson
  ## perform thinning of uniform Poisson

  if(is.null(lmax)) {
    imag <- as.im(lambda, win, ...)
    summ <- summary(imag)
    lmax <- summ$max + 0.05 * diff(summ$range)
  } 

  if(is.function(lambda)) {
    ## function lambda
    if(nsim == 1) {
      X <- runifpoispp(lmax, win)  ## includes sanity checks on `lmax'
      if(X$n == 0) return(X)
      prob <- lambda(X$x, X$y, ...)/lmax
      u <- runif(X$n)
      retain <- (u <= prob)
      X <- X[retain, ]
      return(X)
    }
    result <- runifpoispp(lmax, win, nsim=nsim)
    for(isim in 1:nsim) {
      X <- result[[isim]]
      if(X$n > 0) {
        prob <- lambda(X$x, X$y, ...)/lmax
        u <- runif(X$n)
        retain <- (u <= prob)
        result[[isim]] <- X[retain, ]
      }
    }
    return(as.solist(result))
  }

  if(is.im(lambda)) {
    ## image lambda
    if(nsim == 1) {
      X <- runifpoispp(lmax, win)
      if(X$n == 0) return(X)
      prob <- lambda[X]/lmax
      u <- runif(X$n)
      retain <- (u <= prob)
      X <- X[retain, ]
      return(X)
    }
    result <- runifpoispp(lmax, win, nsim=nsim)
    for(isim in 1:nsim) {
      X <- result[[isim]]
      if(X$n > 0) {
        prob <- lambda[X]/lmax
        u <- runif(X$n)
        retain <- (u <= prob)
        result[[isim]] <- X[retain, ]
      }
    }
    return(as.solist(result))
  }
  stop(paste(sQuote("lambda"), "must be a constant, a function or an image"))
}
    
rMaternI <- function(kappa, r, win = owin(c(0,1),c(0,1)), stationary=TRUE,
                     ..., nsim=1)
{
  win <- as.owin(win)
  stopifnot(is.numeric(r) && length(r) == 1)
  if(stationary) {
    ## generate in a larger window
    bigbox <- grow.rectangle(as.rectangle(win), r)
    X <- rpoispp(kappa, win=bigbox, nsim=nsim)
  } else {
    X <- rpoispp(kappa, win=win, nsim=nsim)
  }
  result <- if(nsim == 1) list(X) else X
  for(isim in 1:nsim) {
    Y <- result[[isim]]
    if(npoints(Y) > 1) {
      d <- nndist(Y)
      Y <- Y[d > r]
    }
    if(stationary)
      Y <- Y[win]
    result[[isim]] <- Y
  }
  if(nsim == 1) return(result[[1]])
  return(as.solist(result))
}
    
rMaternII <- function(kappa, r, win = owin(c(0,1),c(0,1)), stationary=TRUE,
                      ..., nsim=1)
{
  win <- as.owin(win)
  stopifnot(is.numeric(r) && length(r) == 1)
  if(stationary) {
    bigbox <- grow.rectangle(as.rectangle(win), r)
    X <- rpoispp(kappa, win=bigbox, nsim=nsim)
  } else {
    X <- rpoispp(kappa, win=win, nsim=nsim)
  }
  result <- if(nsim == 1) list(X) else X
  for(isim in 1:nsim) {
    Y <- result[[isim]]
    nY <- npoints(Y)
    if(nY > 1) {
      ## matrix of squared pairwise distances
      d2 <- pairdist(Y, squared=TRUE)
      close <- (d2 <= r^2)
      ## random order 1:n
      age <- sample(seq_len(nY), nY, replace=FALSE)
      earlier <- outer(age, age, ">")
      conflict <- close & earlier
      ## delete <- apply(conflict, 1, any)
      delete <- matrowany(conflict)
      Y <- Y[!delete]
    }
    if(stationary)
      Y <- Y[win]
    result[[isim]] <- Y
  }
  if(nsim == 1) return(result[[1]])
  return(as.solist(result))
}
  
rSSI <- function(r, n=Inf, win = square(1), 
                 giveup = 1000, x.init=NULL, ..., nsim=1)
{
  win.given <- !missing(win) && !is.null(win)
  stopifnot(is.numeric(r) && length(r) == 1 && r >= 0)
  stopifnot(is.numeric(n) && length(n) == 1 && n >= 0)
  ##
  if(nsim > 1) {
    result <- vector(mode="list", length=nsim)
    for(isim in 1:nsim)
      result[[isim]] <- rSSI(r=r, n=n, win=if(win.given) win else NULL,
                             giveup=giveup, x.init=x.init)
    names(result) <- paste("Simulation", 1:nsim)
    return(as.solist(result))
  }
  ## Simple Sequential Inhibition process
  ## fixed number of points
  ## Naive implementation, proposals are uniform
  if(is.null(x.init)) {
    ## start with empty pattern in specified window
    win <- as.owin(win)
    x.init <- ppp(numeric(0),numeric(0), window=win)
  } else {
    ## start with specified pattern
    stopifnot(is.ppp(x.init))
    if(!win.given) {
      win <- as.owin(x.init)
    } else {
      ## check compatibility of windows
      if(!identical(win, as.owin(x.init)))
        warning(paste("Argument", sQuote("win"),
                      "is not the same as the window of", sQuote("x.init")))
      x.init.new <- x.init[win]
      if(npoints(x.init.new) == 0)
        stop(paste("No points of x.init lie inside the specified window",
                   sQuote("win")))
      nlost <- npoints(x.init) - npoints(x.init.new)
      if(nlost > 0) 
        warning(paste(nlost, "out of",
                      npoints(x.init), "points of the pattern x.init",
                      "lay outside the specified window",
                      sQuote("win")))
      x.init <- x.init.new
    }
    if(n < npoints(x.init))
      stop(paste("x.init contains", npoints(x.init), "points",
                 "but a pattern containing only n =", n, "points", 
                 "is required"))
    if(n == npoints(x.init)) {
      warning(paste("Initial state x.init already contains", n, "points;",
                    "no further points were added"))
      return(x.init)
    }
  }
  X <- x.init
  r2 <- r^2
  if(!is.infinite(n) && (n * pi * r2/4  > area(win)))
    warning(paste("Window is too small to fit", n, "points",
               "at minimum separation", r))
  ntries <- 0
  while(ntries < giveup) {
    ntries <- ntries + 1
    qq <- runifpoint(1, win)
    x <- qq$x[1]
    y <- qq$y[1]
    if(X$n == 0 || all(((x - X$x)^2 + (y - X$y)^2) > r2))
      X <- superimpose(X, qq, W=win, check=FALSE)
    if(X$n >= n)
      return(X)
  }
  if(!is.infinite(n))
    warning(paste("Gave up after", giveup,
                  "attempts with only", X$n, "points placed out of", n))
  return(X)
}

rPoissonCluster <-
  function(kappa, rmax, rcluster, win = owin(c(0,1),c(0,1)), ...,
           lmax=NULL, nsim=1)
{
  ## Generic Poisson cluster process
  ## Implementation for bounded cluster radius
  ##
  ## 'rcluster' is a function(x,y) that takes the coordinates
  ## (x,y) of the parent point and generates a list(x,y) of offspring
  ##
  ## "..." are arguments to be passed to 'rcluster()'
  ##

  win <- as.owin(win)
  
  ## Generate parents in dilated window
  frame <- boundingbox(win)
  dilated <- owin(frame$xrange + c(-rmax, rmax),
                  frame$yrange + c(-rmax, rmax))
  if(is.im(kappa) && !is.subset.owin(dilated, as.owin(kappa)))
    stop(paste("The window in which the image",
               sQuote("kappa"),
               "is defined\n",
               "is not large enough to contain the dilation of the window",
               sQuote("win")))
  parentlist <- rpoispp(kappa, lmax=lmax, win=dilated, nsim=nsim)
  if(nsim == 1) parentlist <- list(parentlist)

  resultlist <- vector(mode="list", length=nsim)
  for(isim in 1:nsim) {
    parents <- parentlist[[isim]]
    result <- NULL
    ## generate clusters
    np <- parents$n
    if(np > 0) {
      xparent <- parents$x
      yparent <- parents$y
      for(i in seq_len(np)) {
        ## generate random offspring of i-th parent point
        cluster <- rcluster(xparent[i], yparent[i], ...)
        if(!inherits(cluster, "ppp"))
          cluster <- ppp(cluster$x, cluster$y, window=frame, check=FALSE)
        ## skip if cluster is empty
        if(cluster$n > 0) {
          ## trim to window
          cluster <- cluster[win]
          if(is.null(result)) {
            ## initialise offspring pattern and offspring-to-parent map
            result <- cluster
            parentid <- rep.int(1, cluster$n)
          } else {
            ## add to pattern
            result <- superimpose(result, cluster, W=win, check=FALSE)
            ## update offspring-to-parent map
            parentid <- c(parentid, rep.int(i, cluster$n))
          }
        }
      }
    } else {
      ## no parents - empty pattern
      result <- ppp(numeric(0), numeric(0), window=win)
      parentid <- integer(0)
    }

    attr(result, "parents") <- parents
    attr(result, "parentid") <- parentid

    resultlist[[isim]] <- result
  }

  if(nsim == 1) return(resultlist[[1]])

  names(resultlist) <- paste("Simulation", 1:nsim)
  return(as.solist(resultlist))
}  

rGaussPoisson <- local({
  
  rGaussPoisson <- function(kappa, r, p2, win=owin(c(0,1), c(0,1)),
                            ..., nsim=1) {
    ## Gauss-Poisson process
    result <- rPoissonCluster(kappa, 1.05 * r, oneortwo,
                              win, radius=r/2, p2=p2, nsim=nsim)
    return(result)
  }

  oneortwo <- function(x0, y0, radius, p2) {
    if(runif(1) > p2) 
      ## one point
      return(list(x=x0, y=y0))
    ## two points
    theta <- runif(1, min=0, max=2*pi)
    return(list(x=x0+c(-1,1)*radius*cos(theta),
                y=y0+c(-1,1)*radius*sin(theta)))
  }

  rGaussPoisson
})

  
rstrat <- function(win=square(1), nx, ny=nx, k=1, nsim=1) {
  win <- as.owin(win)
  stopifnot(nx >= 1 && ny >= 1)
  stopifnot(k >= 1)
  if(nsim == 1) {
    xy <- stratrand(win, nx, ny, k)
    Xbox <- ppp(xy$x, xy$y, win$xrange, win$yrange, check=FALSE)
    X <- Xbox[win]
    return(X)
  }
  result <- vector(mode="list", length=nsim)
  for(isim in 1:nsim) {
    xy <- stratrand(win, nx, ny, k)
    Xbox <- ppp(xy$x, xy$y, win$xrange, win$yrange, check=FALSE)
    result[[isim]] <- Xbox[win]
  }
  names(result) <- paste("Simulation", 1:nsim)
  return(as.solist(result))
}

xy.grid <- function(xr, yr, nx, ny, dx, dy) {
  nx.given <- !is.null(nx)
  ny.given <- !is.null(ny)
  dx.given <- !is.null(dx)
  dy.given <- !is.null(dy)
  if(nx.given && dx.given)
    stop("Do not give both nx and dx")    
  if(nx.given) {
    stopifnot(nx >= 1)
    x0 <- seq(from=xr[1], to=xr[2], length.out=nx+1)
    dx <- diff(xr)/nx
  } else if(dx.given) {
    stopifnot(dx > 0)
    x0 <- seq(from=xr[1], to=xr[2], by=dx)
    nx <- length(x0)
  } else stop("Need either nx or dx")
  ## determine y grid
  if(ny.given && dy.given)
    stop("Do not give both ny and dy")    
  if(ny.given) {
    stopifnot(ny >= 1)
    y0 <- seq(from=yr[1], to=yr[2], length.out=ny+1)
    dy <- diff(yr)/ny
  } else {
    if(is.null(dy)) dy <- dx
    stopifnot(dy > 0)
    y0 <- seq(from=yr[1], to=yr[2], by=dy)
    ny <- length(y0)
  }
  return(list(x0=x0, y0=y0, nx=nx, ny=ny, dx=dx, dy=dy))
}
  
rsyst <- function(win=square(1), nx=NULL, ny=nx, ..., dx=NULL, dy=dx, nsim=1) {
  win <- as.owin(win)
  xr <- win$xrange
  yr <- win$yrange
  ## determine grid coordinates 
  if(missing(ny)) ny <- NULL
  if(missing(dy)) dy <- NULL
  g <- xy.grid(xr, yr, nx, ny, dx, dy)
  x0 <- g$x0
  y0 <- g$y0
  dx <- g$dx
  dy <- g$dy
  ## assemble grid and randomise location
  xy0 <- expand.grid(x=x0, y=y0)
  if(nsim == 1) {
    x <- xy0$x + runif(1, min = 0, max = dx)
    y <- xy0$y + runif(1, min = 0, max = dy)
    Xbox <- ppp(x, y, xr, yr, check=FALSE)
    ## trim to window
    X <- Xbox[win]
    return(X)
  }
  result <- vector(mode="list", length=nsim)
  for(isim in 1:nsim) {
    x <- xy0$x + runif(1, min = 0, max = dx)
    y <- xy0$y + runif(1, min = 0, max = dy)
    Xbox <- ppp(x, y, xr, yr, check=FALSE)
    ## trim to window
    result[[isim]] <- Xbox[win]
  }
  names(result) <- paste("Simulation", 1:nsim)
  return(as.solist(result))
}

rcellnumber <- function(n, N=10) {
  if(!missing(N)) {
    if(round(N) != N) stop("N must be an integer")
    stopifnot(is.finite(N))
    stopifnot(N > 1)
  }
  u <- runif(n, min=0, max=1)
  p0 <- 1/N
  pN <- 1/(N * (N-1))
  k <- ifelse(u < p0, 0, ifelse(u < (1 - pN), 1, N))
  return(k)
}

rcell <- function(win=square(1), nx=NULL, ny=nx, ...,
                  dx=NULL, dy=dx, N=10, nsim=1) {
  win <- as.owin(win)
  xr <- win$xrange
  yr <- win$yrange
  ## determine grid coordinates 
  if(missing(ny)) ny <- NULL
  if(missing(dy)) dy <- NULL
  g <- xy.grid(xr, yr, nx, ny, dx, dy)
  nx <- g$nx
  ny <- g$ny
  x0 <- g$x0
  y0 <- g$y0
  dx <- g$dx
  dy <- g$dy
  ## generate pattern(s)
  result <- vector(mode="list", length=nsim)
  for(isim in 1:nsim) {
    x <- numeric(0)
    y <- numeric(0)
    for(ix in seq_len(nx))
      for(iy in seq_len(ny)) {
        nij <- rcellnumber(1, N)
        x <- c(x, x0[ix] + runif(nij, min=0, max=dx))
        y <- c(y, y0[iy] + runif(nij, min=0, max=dy))
      }
    Xbox <- ppp(x, y, xr, yr, check=FALSE)
    result[[isim]] <- Xbox[win]
  }
  if(nsim == 1) return(result[[1]])
  names(result) <- paste("Simulation", 1:nsim)
  return(as.solist(result))
}


rthin <- function(X, P, ..., nsim=1) {
  verifyclass(X, "ppp")

  nX <- npoints(X)
  if(nX == 0) {
    if(nsim == 1) return(X)
    result <- rep(list(X), nsim)
    names(result) <- paste("Simulation", 1:nsim)
    return(as.solist(result))
  }

  if(is.numeric(P)) {
    ## vector of retention probabilities
    pX <- P
    if(length(pX) != nX) {
      if(length(pX) == 1)
        pX <- rep.int(pX, nX)
      else 
        stop("Length of vector P does not match number of points of X")
    }
    if(any(is.na(pX)))
      stop("P contains NA's")
  } else if(is.function(P)) {
    ## function - evaluate it at points of X
    pX <- P(X$x, X$y, ...)
    if(length(pX) != nX)
      stop("Function P returned a vector of incorrect length")
    if(!is.numeric(pX))
      stop("Function P returned non-numeric values")
    if(any(is.na(pX)))
      stop("Function P returned some NA values")
  } else if(is.im(P)) {
    ## image - look it up
    if(!(P$type %in% c("integer", "real")))
      stop("Values of image P should be numeric")
    pX <- P[X, drop=FALSE]
    if(any(is.na(pX)))
      stop("some points of X lie outside the domain of image P")
  } else
  stop("Unrecognised format for P")

  if(min(pX) < 0) stop("some probabilities are negative")
  if(max(pX) > 1) stop("some probabilities are greater than 1")

  if(nsim == 1) {
    retain <- (runif(length(pX)) < pX)
    Y <- X[retain]
    ## also handle offspring-to-parent map if present
    if(!is.null(parentid <- attr(X, "parentid")))
      attr(Y, "parentid") <- parentid[retain]
    return(Y)
  }
  result <- vector(mode="list", length=nsim)
  for(isim in 1:nsim) {
    retain <- (runif(length(pX)) < pX)
    Y <- X[retain]
    ## also handle offspring-to-parent map if present
    if(!is.null(parentid <- attr(X, "parentid")))
      attr(Y, "parentid") <- parentid[retain]
    result[[isim]] <- Y
  }
  names(result) <- paste("Simulation", 1:nsim)
  return(as.solist(result))
}


## rjitter

rjitter <- function(X, radius, retry=TRUE, giveup=10000, ..., nsim=1) {
  verifyclass(X, "ppp")
  if(missing(radius) || is.null(radius))
    radius <- bw.stoyan(X)
  if(nsim > 1) {
    result <- vector(mode="list", length=nsim)
    for(isim in 1:nsim)
      result[[isim]] <- rjitter(X, radius=radius,
                                retry=retry, giveup=giveup, ...)
    names(result) <- paste("Simulation", 1:nsim)
    return(as.solist(result))
  }
  nX <- npoints(X)
  if(nX == 0) return(X)
  W <- X$window
  if(!retry) {
    ## points outside window are lost
    D <- runifdisc(nX, radius=radius)
    xnew <- X$x + D$x
    ynew <- X$y + D$y
    ok <- inside.owin(xnew, ynew, W)
    return(ppp(xnew[ok], ynew[ok], window=W))
  }
  ## retry = TRUE: condition on points being inside window
  undone <- rep.int(TRUE, nX)
  while(any(undone)) {
    giveup <- giveup - 1
    if(giveup <= 0)
      return(X)
    Y <- X[undone]
    D <- runifdisc(Y$n, radius=radius)
    xnew <- Y$x + D$x
    ynew <- Y$y + D$y
    ok <- inside.owin(xnew, ynew, W)
    if(any(ok)) {
      changed <- seq_len(nX)[undone][ok]
      X$x[changed] <- xnew[ok]
      X$y[changed] <- ynew[ok]
      undone[changed] <- FALSE
    }
  }
  return(X)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/randomNS.R"
##
##   randomNS.R
##
##   simulating from Neyman-Scott processes
##
##   $Revision: 1.13 $  $Date: 2014/11/17 08:44:46 $
##
##    Original code for rCauchy and rVarGamma by Abdollah Jalilian
##    Other code and modifications by Adrian Baddeley
##    Bug fixes by Abdollah, Adrian, and Rolf Turner

rNeymanScott <- 
  function(kappa, rmax, rcluster, win = owin(c(0,1),c(0,1)), ...,
           lmax=NULL, nsim=1)
{
  ## Generic Neyman-Scott process
  ## Implementation for bounded cluster radius
  ##
  ## 'rcluster' may be
  ##
  ##     (1) a function(x,y, ...) that takes the coordinates
  ##         (x,y) of the parent point and generates a list(x,y) of offspring
  ##
  if(is.function(rcluster))
    return(rPoissonCluster(kappa, rmax, rcluster, win, ...,
                           lmax=lmax, nsim=nsim))

  ##     (2) a list(mu, f) where mu is a numeric value, function, or pixel image
  ##         and f is a function(n, ...) generating n i.i.d. offspring at 0,0
  
  if(!(is.list(rcluster) && length(rcluster) == 2))
    stop("rcluster should be either a function, or a list of two elements")
  win <- as.owin(win)
  mu <- rcluster[[1]]
  rdisplace <- rcluster[[2]]
  if(is.numeric(mu)) {
    ## homogeneous
    if(!(length(mu) == 1 && mu >= 0))
      stop("rcluster[[1]] should be a single nonnegative number")
    mumax <- mu
  } else if (is.im(mu) || is.function(mu)) {
      ## inhomogeneous
    if(is.function(mu)) mu <- as.im(mu, W=win)
    mumax <- max(mu)
  } else stop("rcluster[[1]] should be a number, a function or a pixel image")  
  if(!is.function(rdisplace))
    stop("rcluster[[2]] should be a function")

  ## Generate parents in dilated window
  frame <- boundingbox(win)
  dilated <- grow.rectangle(frame, rmax)
  if(is.im(kappa) && !is.subset.owin(dilated, as.owin(kappa)))
    stop(paste("The window in which the image",
               sQuote("kappa"),
               "is defined\n",
               "is not large enough to contain the dilation of the window",
               sQuote("win")))
  parentlist <- rpoispp(kappa, lmax=lmax, win=dilated, nsim=nsim)
  if(nsim == 1) parentlist <- list(parentlist)

  resultlist <- vector(mode="list", length=nsim)
  for(i in 1:nsim) {
    parents <- parentlist[[i]]
    
    np <- npoints(parents)
    ## generate cluster sizes
    if(np == 0) {
      ## no parents - empty pattern
      result <- ppp(numeric(0), numeric(0), window=win)
      parentid <- integer(0)
    } else {
      csize <- rpois(np, mumax)
      noff <- sum(csize)
      xparent <- parents$x
      yparent <- parents$y
      x0 <- rep.int(xparent, csize)
      y0 <- rep.int(yparent, csize)
      ## invoke random generator
      dd <- rdisplace(noff, ...)
      mm <- if(is.ppp(dd)) marks(dd) else NULL
      ## validate
      xy <- xy.coords(dd)
      dx <- xy$x
      dy <- xy$y
      if(!(length(dx) == noff))
        stop("rcluster returned the wrong number of points")
      ## create offspring and offspring-to-parent map
      xoff <- x0 + dx
      yoff <- y0 + dy
      parentid <- rep.int(1:np, csize)
      ## trim to window
      retain <- inside.owin(xoff, yoff, win)
      if(is.im(mu))
        retain[retain] <- inside.owin(xoff[retain], yoff[retain], as.owin(mu))
      xoff <- xoff[retain]
      yoff <- yoff[retain]
      parentid <- parentid[retain]
      if(!is.null(mm)) mm <- marksubset(mm, retain)
      ## done
      result <- ppp(xoff, yoff, window=win, check=FALSE, marks=mm)
    }

    attr(result, "parents") <- parents
    attr(result, "parentid") <- parentid

    if(is.im(mu)) {
      ## inhomogeneously modulated clusters a la Waagepetersen
      P <- eval.im(mu/mumax)
      result <- rthin(result, P)
    }

    resultlist[[i]] <- result
  }

  if(nsim == 1) return(resultlist[[1]])
  names(resultlist) <- paste("Simulation", 1:nsim)
  return(resultlist)
}  

rMatClust <- local({
  
  ## like runifdisc but returns only the coordinates
  rundisk <- function(n, radius) {
    R <- radius * sqrt(runif(n, min=0, max=1))
    Theta <- runif(n, min=0, max=2*pi)
    cbind(R * cos(Theta), R * sin(Theta))
  }

  rMatClust <- 
  function(kappa, r, mu, win = owin(c(0,1),c(0,1)), nsim=1) {
    ## Matern Cluster Process with Poisson (mu) offspring distribution
    stopifnot(is.numeric(r) && length(r) == 1 && r > 0)
    result <- rNeymanScott(kappa, r, list(mu, rundisk), win, radius=r,
                           nsim=nsim)  
    return(result)
  }

  rMatClust
})

                  
rThomas <- local({

  ## random displacements
  gaus <- function(n, sigma) {
    matrix(rnorm(2 * n, mean=0, sd=sigma), ncol=2)
  }

  ## main function
  rThomas <-
    function(kappa, sigma, mu, win = owin(c(0,1),c(0,1)), nsim=1) {
      ## Thomas process with Poisson(mu) number of offspring
      ## at isotropic Normal(0,sigma^2) displacements from parent
      ##
      stopifnot(is.numeric(sigma) && length(sigma) == 1 && sigma > 0)

      result <- rNeymanScott(kappa, 4 * sigma, list(mu, gaus),
                             win, sigma=sigma,
                             nsim=nsim)  
      return(result)
    }
  rThomas
})


## ================================================
## Neyman-Scott process with Cauchy kernel function
## ================================================

## omega: scale parameter of Cauchy kernel function
## eta: scale parameter of Cauchy pair correlation function
## eta = 2 * omega

rCauchy <- local({

  ## simulate mixture of normals with inverse-gamma distributed variance
  rnmix.invgam <- function(n = 1, rate) {
    V <- matrix(rnorm(2 * n, 0, 1), nrow = n, ncol = 2)
    s <- 1/rgamma(n, shape=1/2, rate=rate)
    return(sqrt(s) * V)
  }

  ## threshold the kernel function in polar coordinate
  kernthresh <- function(r, eta, eps) {
    4 * (r/eta^2)/((1 + (2 * r/eta)^2)^(3/2)) - eps
  }
  
  ## main function
  rCauchy <- function (kappa, omega, mu, win = owin(), eps = 0.001, nsim=1) {

    ## omega: scale parameter of Cauchy kernel function
    ## eta: scale parameter of Cauchy pair correlation function
    eta     <- 2 * omega
    
    ## determine the maximum radius of clusters
    rmax <- uniroot(kernthresh,
                    lower = eta/2, upper = 5 * diameter(as.rectangle(win)),
                    eta = eta, eps = eps)$root
    ## simulate
    result <- rNeymanScott(kappa, rmax,
                           list(mu, rnmix.invgam),
                           win, rate = eta^2/8, nsim=nsim)
    ## correction from Abdollah: the rate is beta = omega^2 / 2 = eta^2 / 8.
    return(result)
  }

  rCauchy })

##    
## =================================================================
## Neyman-Scott process with Variance Gamma (Bessel) kernel function
## =================================================================

## nu.ker: smoothness parameter of Variance Gamma kernel function
## omega: scale parameter of kernel function
## nu.pcf: smoothness parameter of Variance Gamma pair correlation function
## eta: scale parameter of Variance Gamma pair correlation function
## nu.pcf = 2 * nu.ker + 1    and    eta = omega

rVarGamma <- local({
  
  ## simulates mixture of isotropic Normal points in 2D with gamma variances
  rnmix.gamma <- function(n = 1, shape, rate) {
    V <- matrix(rnorm(2 * n, 0, 1), nrow = n, ncol = 2)
    s <- rgamma(n, shape=shape, rate=rate)
    return(sqrt(s) * V)
  }

  ## kernel function in polar coordinates
  kernfun.old <- function(r, nu.ker, omega, eps) {
    numer <- ((r/omega)^(nu.ker+1)) * besselK(r/omega, nu.ker)
    denom <- (2^nu.ker) * omega * gamma(nu.ker + 1)
    numer/denom - eps
  }
  kernfun <- function(r, nu.ker, omega, eps) {
    numer <- ((r/omega)^(nu.ker + 1)) * besselK(r/omega, nu.ker)
    denom <- pi * (2^(nu.ker+1)) * omega^2 * gamma(nu.ker + 1)
    numer/denom - eps
  }
  
  ## main function
  rVarGamma <- function (kappa, nu.ker=NULL, omega, mu, win = owin(),
                         eps = 0.001, nu.pcf=NULL, nsim=1) {
    ## nu.ker: smoothness parameter of Variance Gamma kernel function
    ## omega: scale parameter of kernel function

    nu.ker <- resolve.vargamma.shape(nu.ker=nu.ker, nu.pcf=nu.pcf)$nu.ker
    
    ## determine the maximum radius of clusters
    rmax <- uniroot(kernfun,
                    lower = omega, upper = 5 * diameter(as.rectangle(win)),
                    nu.ker = nu.ker, omega=omega, eps=eps)$root
    ## simulate
    result <- rNeymanScott(kappa, rmax,
                           list(mu, rnmix.gamma), win,
##                          WAS:  shape = 2 * (nu.ker + 1)
                           shape = nu.ker + 1,
                           rate = 1/(2 * omega^2),
                           nsim=nsim)
    return(result)
  }

  rVarGamma })

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/randomlpp.R"
#
#  random.R
#
#  Random point pattern generators for a linear network
#
#  $Revision: 1.3 $   $Date: 2012/10/20 06:56:01 $
#

rpoislpp <- function(lambda, L, ..., nsim=1) {
  verifyclass(L, "linnet")
  result <- vector(mode="list", length=nsim)
  for(i in 1:nsim) {
    X <- datagen.rpoisppOnLines(lambda, as.psp(L), ...)
    Y <- lpp(X, L)
    if(nsim == 1) return(Y)
    result[[i]] <- Y
  }
  Y <- as.solist(Y)
  names(Y) <- paste("Simulation", 1:nsim)
  return(Y)
}

runiflpp <- function(n, L, nsim=1) {
  verifyclass(L, "linnet")
  result <- vector(mode="list", length=nsim)
  for(i in 1:nsim) {
    X <- datagen.runifpointOnLines(n, as.psp(L))
    Y <- lpp(X, L)
    if(nsim == 1) return(Y)
    result[[i]] <- Y
  }
  Y <- as.solist(Y)
  names(Y) <- paste("Simulation", 1:nsim)
  return(Y)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/randommk.R"
#
#
#   randommk.R
#
#   Random generators for MULTITYPE point processes
#
#   $Revision: 1.33 $   $Date: 2014/11/17 04:11:18 $
#
#   rmpoispp()   random marked Poisson pp
#   rmpoint()    n independent random marked points
#   rmpoint.I.allim()  ... internal
#   rpoint.multi()   temporary wrapper 
#
rmpoispp <- local({

  ## Argument checking
  is.numvector <- function(x) {is.numeric(x) && is.vector(x)}
  is.constant <- function(x) {is.numvector(x) && length(x) == 1}
  checkone <- function(x) {
    if(is.constant(x)) {
      if(x >= 0) return(TRUE) else stop("Intensity is negative!")
    }
    return(is.function(x) || is.im(x))
  }

  ## Ensure that m can be passed as a single value to function(x,y,m,...)
  slice.fun <- function(x,y,fun,mvalue, ...) {
    m <- if(length(mvalue) == 1) rep.int(mvalue, length(x)) else mvalue
    result <- fun(x,y,m, ...)
    return(result)
  }

  ## Main function
  rmpoispp <- 
    function(lambda, lmax=NULL, win = owin(c(0,1),c(0,1)),
             types, ..., nsim=1) {
      ## arguments:
      ##     lambda  intensity:
      ##                constant, function(x,y,m,...), image,
      ##                vector, list of function(x,y,...) or list of images
      ##
      ##     lmax     maximum possible value of lambda
      ##                constant, vector, or list
      ##
      ##     win     default observation window (of class 'owin')
      ##
      ##     types    possible types for multitype pattern
      ##    
      ##     ...     extra arguments passed to lambda()
      ##

      if(missing(types)) types <- NULL

      if(nsim > 1) {
        result <- vector(mode="list", length=nsim)
        for(i in 1:nsim)
          result[[i]] <- rmpoispp(lambda, lmax, win, types, ...)
        names(result) <- paste("Simulation", 1:nsim)
        return(as.solist(result))
      }
      
      ## Validate arguments
      single.arg <- checkone(lambda)
      vector.arg <- !single.arg && is.numvector(lambda) 
      list.arg <- !single.arg && is.list(lambda)
      if(! (single.arg || vector.arg || list.arg))
        stop(paste("argument", sQuote("lambda"), "not understood"))
    
      if(list.arg && !all(unlist(lapply(lambda, checkone))))
        stop(paste("Each entry in the list",
                   sQuote("lambda"),
                   "must be either a constant, a function or an image"))
      if(vector.arg && any(lambda < 0))
        stop(paste("Some entries in the vector",
                   sQuote("lambda"), "are negative"))

      ## Determine & validate the set of possible types
      if(is.null(types)) {
        if(single.arg)
          stop(paste(sQuote("types"), "must be given explicitly when",
                     sQuote("lambda"), "is a constant, a function or an image"))
        else
          types <- seq_along(lambda)
      } 

      ntypes <- length(types)
      if(!single.arg && (length(lambda) != ntypes))
        stop(paste("The lengths of", sQuote("lambda"),
                   "and", sQuote("types"), "do not match"))

      factortype <- factor(types, levels=types)

      ## Validate `lmax'
      if(! (is.null(lmax) || is.numvector(lmax) || is.list(lmax) ))
        stop(paste(sQuote("lmax"),
                   "should be a constant, a vector, a list or NULL"))
       
      ## coerce lmax to a vector, to save confusion
      if(is.null(lmax))
        maxes <- rep(NULL, ntypes)
      else if(is.numvector(lmax) && length(lmax) == 1)
        maxes <- rep.int(lmax, ntypes)
      else if(length(lmax) != ntypes)
        stop(paste("The length of",
                   sQuote("lmax"),
                   "does not match the number of possible types"))
      else if(is.list(lmax))
        maxes <- unlist(lmax)
      else maxes <- lmax

      ## coerce lambda to a list, to save confusion
      lam <- if(single.arg) lapply(1:ntypes, function(x, y){y}, y=lambda)
              else if(vector.arg) as.list(lambda) else lambda

      ## Simulate
      for(i in 1:ntypes) {
        if(single.arg && is.function(lambda)) {
          ## call f(x,y,m, ...)
          Y <- rpoispp(slice.fun, lmax=maxes[i], win=win,
                       fun=lambda, mvalue=types[i], ...)
        } else {
          ## call f(x,y, ...) or use other formats
          Y <- rpoispp(lam[[i]], lmax=maxes[i], win=win, ...)
        }
        Y <- Y %mark% factortype[i]
        X <- if(i == 1) Y else superimpose(X, Y, W=X$window, check=FALSE)
      }

      ## Randomly permute, just in case the order is important
      permu <- sample(X$n)
      return(X[permu])
    }

  rmpoispp
})

## ------------------------------------------------------------------------

rmpoint <- local({

  ## argument validation
  is.numvector <- function(x) {is.numeric(x) && is.vector(x)}
  is.constant <- function(x) {is.numvector(x) && length(x) == 1}
  checkone <- function(x) {
    if(is.constant(x)) {
      if(x >= 0) return(TRUE) else stop("Intensity is negative!")
    }
    return(is.function(x) || is.im(x))
  }

  # integration..
  integratexy <- function(f, win, ...) {
    imag <- as.im(f, W=win, ...)
    integral.im(imag)
  }
  ## create a counterpart of f(x,y,m) that works when m is a single value
  funwithfixedmark <- function(xx, yy, ..., m, fun) {
    mm <- rep.int(m, length(xx))
    fun(xx, yy, mm, ...)
  }
  integratewithfixedmark <- function(m, fun, win, ...) {
    integratexy(funwithfixedmark, win=win, m=m, fun=fun, ...)
  }

  # Main function
  rmpoint <- function(n, f=1, fmax=NULL, 
                      win = unit.square(), 
                      types, ptypes, ...,
                      giveup = 1000, verbose = FALSE,
                      nsim = 1) {
    if(!is.numeric(n))
      stop("n must be a scalar or vector")
    if(any(ceiling(n) != floor(n)))
      stop("n must be an integer or integers")
    if(any(n < 0))
      stop("n must be non-negative")
    if(missing(types)) types <- NULL
    if(missing(ptypes)) ptypes <- NULL

    if(nsim > 1) {
      result <- vector(mode="list", length=nsim)
      for(i in 1:nsim)
        result[[i]] <- rmpoint(n, f, fmax, win, types, ptypes, ...,
                               giveup=giveup, verbose=verbose)
      names(result) <- paste("Simulation", 1:nsim)
      return(as.solist(result))
    }
      
    if(sum(n) == 0) {
      nopoints <- ppp(x=numeric(0), y=numeric(0), window=win, check=FALSE)
      if(!is.null(types)) {
        nomarks <- factor(types[numeric(0)], levels=types)
        npoints <- nopoints %mark% nomarks
      }
      return(nopoints)
    }         
    #############
  
    Model <- if(length(n) == 1) {
      if(is.null(ptypes)) "I" else "II"
    } else "III"
  
    ##############  Validate f argument
    single.arg <- checkone(f)
    vector.arg <- !single.arg && is.numvector(f) 
    list.arg <- !single.arg && is.list(f)
    if(! (single.arg || vector.arg || list.arg))
      stop(paste("argument", sQuote("f"), "not understood"))
    
    if(list.arg && !all(unlist(lapply(f, checkone))))
      stop(paste("Each entry in the list", sQuote("f"),
                 "must be either a constant, a function or an image"))
    if(vector.arg && any(f < 0))
      stop(paste("Some entries in the vector",
                 sQuote("f"), "are negative"))
    
    ## cases where it's known that all types of points 
    ## have the same conditional density of location (x,y)
    const.density <- vector.arg ||
                     (list.arg && all(unlist(lapply(f, is.constant))))
    same.density <- const.density || (single.arg && !is.function(f))

    ################   Determine & validate the set of possible types
    if(is.null(types)) {
      if(single.arg && length(n) == 1)
        stop(paste(sQuote("types"), "must be given explicitly when",
                   sQuote("f"),
                   "is a single number, a function or an image and",
                   sQuote("n"), "is a single number"))
      else if(single.arg) {
        types <- seq_len(n)
      } else {
        types <- seq_along(f)
      }
    }

    ntypes <- length(types)
    if(!single.arg && (length(f) != ntypes))
      stop(paste("The lengths of",
                 sQuote("f"), "and", sQuote("types"),
                 "do not match"))
    if(length(n) > 1 && ntypes != length(n))
      stop(paste("The lengths of",
                 sQuote("n"), "and", sQuote("types"),
                 "do not match"))

    factortype <- factor(types, levels=types)
  
    #######################  Validate `fmax'
    if(! (is.null(fmax) || is.numvector(fmax) || is.list(fmax) ))
      stop(paste(sQuote("fmax"),
                 "should be a constant, a vector, a list or NULL"))
       
    ## coerce fmax to a vector, to save confusion
    if(is.null(fmax))
      maxes <- rep(NULL, ntypes)
    else if(is.constant(fmax))
      maxes <- rep.int(fmax, ntypes)
    else if(length(fmax) != ntypes)
      stop(paste("The length of", sQuote("fmax"),
                 "does not match the number of possible types"))
    else if(is.list(fmax))
      maxes <- unlist(fmax)
    else maxes <- fmax

    ## coerce f to a list, to save confusion
    flist <- if(single.arg) lapply(1:ntypes, function(i, f){f}, f=f)
    else if(vector.arg) as.list(f) else f

    #################### START ##################################

    ## special algorithm for Model I when all f[[i]] are images

    if(Model == "I" && !same.density && all(unlist(lapply(flist, is.im))))
      return(rmpoint.I.allim(n, flist, types))

    ## otherwise, first select types, then locations given types
  
    if(Model == "I") {
      ## Compute approximate marginal distribution of type
      if(vector.arg)
        ptypes <- f/sum(f)
      else if(list.arg) {
        fintegrals <- unlist(lapply(flist, integratexy, win=win, ...))
        ptypes <- fintegrals/sum(fintegrals)
      } else {
        ## single argument
        if(is.constant(f)) {
          ptypes <- rep.int(1/ntypes, ntypes)
        } else {
          ## f is a function (x,y,m)
          ## convert to images and integrate
          fintegrals <- unlist(lapply(types,
                                      integratewithfixedmark,
                                      win=win, fun=f, ...))
          ## normalise
          ptypes <- fintegrals/sum(fintegrals)
        }
      }
    }

    ## Generate marks 

    if(Model == "I" || Model == "II") {
      ## i.i.d.: n marks with distribution 'ptypes'
      marques <- sample(factortype, n, prob=ptypes, replace=TRUE)
      nn <- table(marques)
    } else {
      ## multinomial: fixed number n[i] of types[i]
      repmarks <- factor(rep.int(types, n), levels=types)
      marques <- sample(repmarks)
      nn <- n
    }
    ntot <- sum(nn)

    ##############  SIMULATE !!!  #########################

    ## If all types have the same conditional density of location,
    ## generate the locations using rpoint, and return.
    if(same.density) {
      X <- rpoint(ntot, flist[[1]], maxes[[1]], win=win, ...,
                  giveup=giveup, verbose=verbose)
      X <- X %mark% marques
      return(X)
    }
    ## Otherwise invoke rpoint() for each type separately
    X <- ppp(numeric(ntot), numeric(ntot), window=win, marks=marques,
              check=FALSE)

    for(i in 1:ntypes) {
      if(verbose) cat(paste("Type", i, "\n"))
      if(single.arg && is.function(f)) {
        ## want to call f(x,y,m, ...)
        Y <- rpoint(nn[i], funwithfixedmark, fmax=maxes[i], win=win,
                    ..., m=factortype[i], fun=f, giveup=giveup, verbose=verbose)
      } else {
        ## call f(x,y, ...) or use other formats
        Y <- rpoint(nn[i], flist[[i]], fmax=maxes[i], win=win,
                    ..., giveup=giveup, verbose=verbose)
      }
      Y <- Y %mark% factortype[i]
      X[marques == factortype[i]] <- Y
    }
      return(X)
  }

  rmpoint
})

rmpoint.I.allim <- local({

  ## Extract pixel coordinates and probabilities
  get.stuff <- function(imag) {
    w <- as.mask(as.owin(imag))
    dx <- w$xstep
    dy <- w$ystep
    rxy <- rasterxy.mask(w, drop=TRUE)
    xpix <- rxy$x
    ypix <- rxy$y
    ppix <- as.vector(imag$v[w$m]) ## not normalised - OK
    npix <- length(xpix)
    return(list(xpix=xpix, ypix=ypix, ppix=ppix,
                dx=rep.int(dx,npix), dy=rep.int(dy, npix),
                npix=npix))
  }

  rmpoint.I.allim <- function(n, f, types) {
    ## Internal use only!
    ## Generates random marked points (Model I *only*)
    ## when all f[[i]] are pixel images.
    ##
    stuff <- lapply(f, get.stuff)
    ## Concatenate into loooong vectors
    xpix <- unlist(lapply(stuff, getElement, name="xpix"))
    ypix <- unlist(lapply(stuff, getElement, name="ypix"))
    ppix <- unlist(lapply(stuff, getElement, name="ppix"))
    dx   <- unlist(lapply(stuff, getElement, name="dx"))
    dy   <- unlist(lapply(stuff, getElement, name="dy"))
    ## replicate types
    numpix <- unlist(lapply(stuff, getElement, name="npix"))
    tpix <- rep.int(seq_along(types), numpix)
    ##
    ## sample pixels from union of all images
    ##
    npix <- sum(numpix)
    id <- sample(npix, n, replace=TRUE, prob=ppix)
    ## get pixel centre coordinates and randomise within pixel
    x <- xpix[id] + (runif(n) - 1/2) * dx[id]
    y <- ypix[id] + (runif(n) - 1/2) * dy[id]
    ## compute types
    marx <- factor(types[tpix[id]],levels=types)
    ## et voila!
    return(ppp(x, y, window=as.owin(f[[1]]), marks=marx, check=FALSE))
  }

  rmpoint.I.allim
})

##
##     wrapper for Rolf's function
##
rpoint.multi <- function (n, f, fmax=NULL, marks = NULL,
                          win = unit.square(),
                          giveup = 1000, verbose = FALSE,
                          warn=TRUE, nsim=1) {
  if(nsim > 1) {
    result <- vector(mode="list", length=nsim)
    for(i in 1:nsim)
      result[[i]] <- rpoint.multi(n, f, fmax, marks, win, giveup, verbose)
    names(result) <- paste("Simulation", 1:nsim)
    return(as.solist(result))
  }
  
  no.marks <- is.null(marks) ||
               (is.factor(marks) && length(levels(marks)) == 1)
  if(warn) {
    nhuge <- spatstat.options("huge.npoints")
    if(n > nhuge)
      warning(paste("Attempting to generate", n, "random points"))
  }
  ## unmarked case
  if (no.marks) {
    if(is.function(f))
      return(rpoint(n, f, fmax, win, giveup=giveup, verbose=verbose))
    else
      return(rpoint(n, f, fmax, giveup=giveup, verbose=verbose))
  }
  ## multitype case
  if(length(marks) != n)
    stop("length of marks vector != n")
  if(!is.factor(marks))
    stop("marks should be a factor")
  types <- levels(marks)
  types <- factor(types, levels=types)
  ## generate required number of points of each type
  nums <- table(marks)
  X <- rmpoint(nums, f, fmax, win=win, types=types,
               giveup=giveup, verbose=verbose)
  if(any(table(marks(X)) != nums))
    stop("Internal error: output of rmpoint illegal")
  ## reorder them to correspond to the desired 'marks' vector
  Y <- X
  Xmarks <- marks(X)
  for(ty in types) {
    to   <- (marks == ty)
    from <- (Xmarks == ty)
    if(sum(to) != sum(from))
      stop(paste("Internal error: mismatch for mark =", ty))
    if(any(to)) {
      Y$x[to] <- X$x[from]
      Y$y[to] <- X$y[from]
      Y$marks[to] <- ty
    }
  }
  return(Y)
}


  
  

    
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/randomonlines.R"
#
# randomOnLines.R
#
# $Revision: 1.8 $  $Date: 2014/11/17 04:40:14 $
#
# Generate random points on specified lines
#

runifpointOnLines <- function(n, L, nsim=1) {
  if(!is.numeric(n) || any(n < 0) || any(n %% 1 != 0))
    stop("n should be a nonnegative integer or integers")
  if(!is.psp(L))
    L <- as.psp(L)
  W <- as.owin(L)
  result <- vector(mode="list", length=nsim)
  for(i in 1:nsim) {
    X <- datagen.runifpointOnLines(n, L)
    Y <- ppp(X$x, X$y, marks=X$marks, window=W, check=FALSE)
    result[[i]] <- Y
  }
  if(nsim == 1) return(result[[1]])
  names(result) <- paste("Simulation", 1:nsim)
  return(as.solist(result))
}

datagen.runifpointOnLines <- function(n, L) {
  stopifnot(is.psp(L))
  m <- length(n)
  ismarked <- (m > 1)
  if(m == 0 || (m == 1 && n == 0))
    return(data.frame(x=numeric(0),
                      y=numeric(0),
                      seg=integer(0),
                      tp=numeric(0)))
  # extract segment information
  len <- lengths.psp(L)
  sumlen <- sum(len)
  cumlen <- cumsum(len)
  cum0len <- c(0, cumlen)
  Ldf <- as.data.frame(L)
  x0 <- with(Ldf, x0)
  y0 <- with(Ldf, y0)
  dx <- with(Ldf, x1-x0)
  dy <- with(Ldf, y1-y0)
  # determine mark space
  if(ismarked) {
    markvalues <- names(n)
    if(sum(nzchar(markvalues)) < m)
      markvalues <- paste(1:m)
  }
  # initialise output data.frame
  out <- data.frame(x=numeric(0), y=numeric(0), seg=integer(0), tp=numeric(0))
  if(ismarked) 
    out <- cbind(out, data.frame(marks=character(0)))
  # generate points of each mark in turn
  for(j in 1:m) {
    if(n[[j]] > 0) {
      # generate random positions
      uu <- runif(n[[j]], min=0, max=sumlen)
      # identify segment for each point
      kk <- findInterval(uu, cum0len, rightmost.closed=TRUE, all.inside=TRUE)
      # parametric position along segment
      tt <- (uu - cum0len[kk])/len[kk]
      tt[!is.finite(tt)] <- 0
      # convert to (x,y)
      x <- x0[kk] + tt * dx[kk]
      y <- y0[kk] + tt * dy[kk]
      # assemble result
      if(!ismarked) {
        out <- data.frame(x=x, y=y, seg=kk, tp=tt)
      } else {
        outj <- data.frame(x=x, y=y, seg=kk, tp=tt, marks=markvalues[j])
        out <- rbind(out, outj)
      }
    }
  }
  if(ismarked) out$marks <- factor(out$marks, levels=markvalues)
  return(out)
}

runifpoisppOnLines <- function(lambda, L, nsim=1) {
  if(!is.numeric(lambda) || !all(is.finite(lambda) && (lambda >= 0)))
    stop("lambda should be a finite, nonnegative number or numbers")
  if(!is.psp(L))
    L <- as.psp(L)
  W <- as.owin(L)
  result <- vector(mode="list", length=nsim)
  for(i in 1:nsim) {
    X <- datagen.runifpoisppOnLines(lambda, L)
    Y <- ppp(X$x, X$y, marks=X$marks, window=W, check=FALSE)
    result[[i]] <- Y
  }
  if(nsim == 1) return(result[[1]])
  names(result) <- paste("Simulation", 1:nsim)
  return(as.solist(result))
}

datagen.runifpoisppOnLines <- function(lambda, L) {
  stopifnot(is.psp(L))
  mu <- lambda * sum(lengths.psp(L))
  n <- rpois(rep.int(1, length(mu)), mu)
  if(length(n) > 1)
    names(n) <- names(lambda)
  df <- datagen.runifpointOnLines(n, L)
  return(df)
}

rpoisppOnLines <- function(lambda, L, lmax=NULL, ..., nsim=1) {
  if(!is.psp(L))
    L <- as.psp(L)
  W <- as.owin(L)
  result <- vector(mode="list", length=nsim)
  for(i in 1:nsim) {
    X <- datagen.rpoisppOnLines(lambda, L, lmax=lmax, ...)
    Y <- ppp(X$x, X$y, marks=X$marks, window=W, check=FALSE)
    result[[i]] <- Y
  }
  if(nsim == 1) return(result[[1]])
  names(result) <- paste("Simulation", 1:nsim)
  return(as.solist(result))
}

datagen.rpoisppOnLines <- function(lambda, L, lmax=NULL, ..., check=TRUE)  {
  stopifnot(is.psp(L))
  if(is.numeric(lambda)) 
    return(datagen.runifpoisppOnLines(lambda, L))
  # ensure lambda is a list
  if(is.function(lambda) || is.im(lambda))
    lambda <- list(lambda)
  m <- length(lambda)
  # determine type of argument
  argtype <-
    if(all(unlist(lapply(lambda, is.im)))) "im" else
    if(all(unlist(lapply(lambda, is.function)))) "function" else
    stop(paste(sQuote("lambda"),
               "must be a numeric vector, a function, an image,",
               "a list of functions, or a list of images"))
  # check values of lambda
  if(argtype == "im") {
    for(j in seq_len(m)) {
      lamj <- lambda[[j]]
      if(!(lamj$type %in% c("real", "integer")))
        stop("lambda must be numeric-valued or integer-valued")
      lrange <- range(lamj)
      if(any(is.infinite(lrange)))
        stop("Infinite pixel values not permitted")
      if(lrange[1] < 0)
        stop("Negative pixel values not permitted")
    }
  }
  # determine uniform bound
  if(!is.null(lmax)) {
    stopifnot(is.numeric(lmax))
    if(length(lmax) != m) {
      if(length(lmax) == 1) {
        lmax <- rep.int(lmax, m)
      } else stop("Length of lmax does not match length of lambda")
    }
  } else {
    # compute lmax
    lmax <- numeric(m)
    for(j in seq_len(m)) {
      lamj <- lambda[[j]]
      if(is.function(lamj)) {
        X <- pointsOnLines(L, np=10000)
        lambdaX <- lamj(X$x, X$y, ...)
        lmax[j] <- max(lambdaX, na.rm=TRUE)
      } else if(is.im(lamj)) 
        lmax[j] <- max(lamj)
    }
    if(!all(is.finite(lmax)))
      stop("Infinite values of lambda obtained")
    if(any(lmax < 0))
      stop("Negative upper bound for lambda obtained")
    names(lmax) <- names(lambda)
  } 
  # Lewis-Shedler (rejection) method
  Y <- datagen.runifpoisppOnLines(lmax, L)
  n <- nrow(Y)
  if(n == 0)
    return(Y)
  # evaluate lambda at each simulated point
  if(m == 1) {
    lambda <- lambda[[1]]
    markindex <- 1
    if(is.function(lambda)) 
      lambdaY <- lambda(Y$x, Y$y, ...)
    else
      lambdaY <- safelookup(lambda, as.ppp(Y, W=as.owin(L)))
  } else {
    lambdaY <- numeric(n)
    markindex <- as.integer(Y$marks)
    for(j in seq_len(m)) {
      lamj <- lambda[[j]]
      jrows <- (markindex == j)
      Yj <- Y[jrows, , drop=FALSE]
      if(is.function(lamj)) 
        lambdaY[jrows] <- lamj(Yj$x, Yj$y, ...)
      else
        lambdaY[jrows] <- safelookup(lamj, as.ppp(Yj, W=as.owin(L)))
    }
  }
  lambdaY[is.na(lambdaY)] <- 0
  # accept/reject
  pY <- lambdaY/lmax[markindex]
  if(check) {
    if(any(pY < 0))
      warning("Negative values of lambda obtained")
    if(any(pY > 1))
      warning("lmax is not an upper bound for lambda")
  }
  retain <- (runif(n) < pY)
  Y <- Y[retain, , drop=FALSE]
  return(Y)
}

      
  
  
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/randomseg.R"
#
# randomseg.R
#
# $Revision: 1.9 $ $Date: 2014/02/22 02:43:07 $
#

rpoisline <- function(lambda, win=owin()) {
  win <- as.owin(win)
  # determine circumcircle
  xr <- win$xrange
  yr <- win$yrange
  xmid <- mean(xr)
  ymid <- mean(yr)
  width <- diff(xr)
  height <- diff(yr)
  rmax <- sqrt(width^2 + height^2)/2
  boundbox <- owin(xmid + c(-1,1) * rmax, ymid + c(-1,1) * rmax)
  # generate poisson lines through circumcircle
  n <- rpois(1, lambda * 2 * pi * rmax)
  if(n == 0)
    return(psp(numeric(0), numeric(0), numeric(0), numeric(0),
               window=win))
  theta <- runif(n, max= 2 * pi)
  p <- runif(n, max=rmax)
  # compute intersection points with circle
  q <- sqrt(rmax^2 - p^2)
  co <- cos(theta)
  si <- sin(theta)
  X <- psp(x0= xmid + p * co + q * si,
           y0= ymid + p * si - q * co,
           x1= xmid + p * co - q * si,
           y1= ymid + p * si + q * co,
           window=boundbox, check=FALSE)
  # clip to window
  X <- X[win]
  return(X)
}

rlinegrid <- function(angle=45, spacing=0.1, win=owin()) {
  win <- as.owin(win)
  # determine circumcircle
  width <- diff(win$xrange)
  height <- diff(win$yrange)
  rmax <- sqrt(width^2 + height^2)/2
  xmid <- mean(win$xrange)
  ymid <- mean(win$yrange)
  # generate randomly-displaced grid of lines through circumcircle
  u <- runif(1, min=0, max=spacing) - rmax
  if(u >= rmax)   
    return(psp(numeric(0), numeric(0), numeric(0), numeric(0),
               window=win, check=FALSE))
  p <- seq(from=u, to=rmax, by=spacing)
  # compute intersection points with circle
  q <- sqrt(rmax^2 - p^2)
  theta <- pi * ((angle - 90)/180)
  co <- cos(theta)
  si <- sin(theta)
  X <- psp(x0= xmid + p * co + q * si,
           y0= ymid + p * si - q * co,
           x1= xmid + p * co - q * si,
           y1= ymid + p * si + q * co,
           window=owin(xmid+c(-1,1)*rmax, ymid+c(-1,1)*rmax), check=FALSE)
  # clip to window
  X <- X[win]
  return(X)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/randomtess.R"
#
# randomtess.R
#
# Random tessellations
#
# $Revision: 1.6 $  $Date: 2011/05/18 09:00:01 $
#

# Poisson line tessellation

rpoislinetess <- function(lambda, win=owin()) {
  win <- as.owin(win)
  if(win$type == "mask")
    stop("Not implemented for masks")
  # determine circumcircle
  xr <- win$xrange
  yr <- win$yrange
  xmid <- mean(xr)
  ymid <- mean(yr)
  width <- diff(xr)
  height <- diff(yr)
  rmax <- sqrt(width^2 + height^2)/2
  boundbox <- owin(xmid + c(-1,1) * rmax, ymid + c(-1,1) * rmax)
  # generate poisson lines through circumcircle
  n <- rpois(1, lambda * 2 * pi * rmax)
  if(n == 0)
    return(tess(tiles=list(win)))
  theta <- runif(n, max= 2 * pi)
  p <- runif(n, max=rmax)
  Y <- infline(p=p, theta=theta)
  # form the induced tessellation in bounding box
  Z <- chop.tess(boundbox, Y)
  # clip to window
  Z <- intersect.tess(Z, win)
  return(Z)
}

rMosaicSet <- function(X, p=0.5) {
  stopifnot(is.tess(X))
  Y <- tiles(X)
  Y <- Y[runif(length(Y)) < p]
  if(length(Y) == 0)
    return(NULL)
  Z <- NULL
  for(i in seq_along(Y))
    Z <- union.owin(Z, Y[[i]])
  return(Z)
}

rMosaicField <- function(X,
                    rgen=function(n) { sample(0:1, n, replace=TRUE)},
                    ..., 
                    rgenargs=NULL ) {
  stopifnot(is.tess(X))
  Y <- as.im(X, ...)
  ntiles <- length(levels(Y))
  values <- do.call(rgen, append(list(ntiles),rgenargs))
  Z <- eval.im(values[as.integer(Y)])
  return(Z)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rat.R"
#
#    rat.R
#
#   Ratio objects
#
#   Numerator and denominator are stored as attributes
#
#   $Revision: 1.5 $   $Date: 2014/10/24 00:22:30 $
#

rat <- function(ratio, numerator, denominator, check=TRUE) {
  if(check) {
    stopifnot(compatible(numerator, denominator))
    stopifnot(compatible(ratio, denominator))
  }
  attr(ratio, "numerator") <- numerator
  attr(ratio, "denominator") <- denominator
  class(ratio) <- c("rat", class(ratio))
  return(ratio)
}

print.rat <- function(x, ...) {
  NextMethod("print")
  cat("[Contains ratio information]\n")
  return(invisible(NULL))
}

compatible.rat <- function(A, B, ...) {
  NextMethod("compatible")
}

pool.rat <- function(...) {
  argh <- list(...)
  n <- narg <- length(argh)
  if(narg == 0) return(NULL)
  if(narg == 1) return(argh[[1]])
  #
  israt <- unlist(lapply(argh, inherits, what="rat"))
  if(any(bad <- !israt)) {
    nbad <- sum(bad)
    stop(paste(ngettext(nbad, "Argument", "Arguments"),
               commasep(which(bad)),
               ngettext(nbad, "does not", "do not"),
               "contain ratio (numerator/denominator) information"))
  }
  isfv <- unlist(lapply(argh, is.fv))
  if(!all(isfv))
    stop("All arguments must be fv objects")
  # extract
  template <- vanilla.fv(argh[[1]])
  Y <- lapply(argh, attr, which="numerator")
  X <- lapply(argh, attr, which="denominator")
  templateX <- vanilla.fv(X[[1]])
  templateY <- vanilla.fv(Y[[1]])
  # sum
  Add <- function(A,B){ force(A); force(B); eval.fv(A+B) }
  sumX <- Reduce(Add, X)
  sumY <- Reduce(Add, Y)
  attributes(sumX) <- attributes(templateX)
  attributes(sumY) <- attributes(templateY)
  # ratio-of-sums
  Ratio <- eval.fv(sumY/sumX)
  # variance calculation
  meanX <- eval.fv(sumX/n)
  meanY <- eval.fv(sumY/n)
  Square <- function(A) { force(A); eval.fv(A^2) }
  sumX2 <- Reduce(Add, lapply(X, Square))
  sumY2 <- Reduce(Add, lapply(Y, Square))
  varX   <- eval.fv((sumX2 - n * meanX^2)/(n-1))
  varY   <- eval.fv((sumY2 - n * meanY^2)/(n-1))
  Mul <- function(A,B){ force(A); force(B); eval.fv(A*B) }
  XY <- Map(Mul, X, Y)
  sumXY <- Reduce(Add, XY)
  covXY <- eval.fv((sumXY - n * meanX * meanY)/(n-1))
  # variance by delta method
  relvar <- eval.fv(pmax.int(0, varY/meanY^2 + varX/meanX^2
                            - 2 * covXY/(meanX * meanY)))
  Variance <- eval.fv(Ratio^2 * relvar/n)
  # two sigma CI
  hiCI <- eval.fv(Ratio + 2 * sqrt(Variance))
  loCI <- eval.fv(Ratio - 2 * sqrt(Variance))
  # relabel
  attributes(Ratio) <- attributes(Variance) <- attributes(template)
  Ratio <- prefixfv(Ratio,
                    tagprefix="pool",
                    descprefix="pooled ",
                    lablprefix="")
  Variance <- prefixfv(Variance,
                    tagprefix="var",
                    descprefix="delta-method variance estimate of ",
                    lablprefix="bold(var)~")
  attributes(hiCI) <- attributes(loCI) <-  attributes(template)
  hiCI <- prefixfv(hiCI,
                   tagprefix="hi",
                    descprefix="upper limit of two-sigma CI based on ",
                    lablprefix="bold(hi)~")
  loCI <- prefixfv(loCI,
                   tagprefix="lo",
                   descprefix="lower limit of two-sigma CI based on ",
                   lablprefix="bold(lo)~")
  #
  result <- Reduce(bind.fv, list(Ratio, Variance, hiCI, loCI))
  return(result)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/reach.R"
#
#   reach.R
#
#  $Revision: 1.8 $   $Date: 2007/10/24 09:41:15 $
#

reach <- function(x, ...) {
  UseMethod("reach")
}

reach.interact <- function(x, ...) {
  verifyclass(x, "interact")
  irange <- x$irange
  if(is.null(irange))
    return(Inf)
  if(!is.function(irange))
    stop("Internal error - x$irange is not a function")
  ir <- irange(x)
  if(is.na(ir))
    ir <- Inf
  return(ir)
}

reach.ppm <- function(x, ..., epsilon=0) {
  verifyclass(x, "ppm")
  
  # Poisson case
  if(is.poisson.ppm(x))
    return(0)

  # extract info
  inte <- x$interaction
  coeffs <- coef(x)

  if(newstyle.coeff.handling(inte)) {
    # extract only interaction coefficients
    Vnames <- x$internal$Vnames
    coeffs <- coeffs[Vnames]
  } 
  
  # apply 'irange' function
  irange <- inte$irange
  if(is.null(irange))
    return(Inf)
  ir <- irange(inte, coeffs, epsilon=epsilon)

  if(is.na(ir))
    ir <- Inf

  return(ir)
}



#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/reduceformula.R"
#
#  reduceformula.R
#
#  $Revision: 1.3 $   $Date: 2007/04/02 06:28:17 $
#
# delete variable from formula 
#
#......................................................
#

reduceformula <- function(fmla, deletevar, verbose=FALSE) {
  # removes the variable `deletevar' from the formula `fmla'
  # returns a simplified formula, or NULL if it can't simplify.
  stopifnot(inherits(fmla, "formula"))
  stopifnot(is.character(deletevar) && length(deletevar) == 1)
  if(!(deletevar %in% all.vars(as.expression(fmla)))) {
    if(verbose)
      message(paste("The formula does not involve", dQuote(deletevar),
                    "and is therefore unchanged"))
    return(fmla)
  }
  lhs <- if(length(fmla) < 3) NULL else fmla[[2]]
  # create terms object
  tt <- attributes(terms(fmla))
  formula.has.intercept <- (tt$intercept == 1)
  # extract all variables appearing in the model
  vars <- as.list(tt$variables)[-1]
  nvars <- length(vars)
  varstrings <- sapply(vars, function(x) paste(as.expression(x)))
  # identify any offsets
  offs <- tt$offset
  v.is.offset <- if(!is.null(offs)) (1:nvars) %in% offs else rep(FALSE, nvars)
  # remove the response
  repo <- tt$response
  if(repo != 0) {
    vars <- vars[-repo]
    varstrings <- varstrings[-repo]
    v.is.offset <- v.is.offset[-repo]
  }
  # a term may be a variable name
#  v.is.name <- sapply(vars, is.name)
  # a term may be an expression like sin(x), poly(x,y,degree=2)
  v.args <- lapply(vars, function(x) all.vars(as.expression(x)))
  v.has.delete <- sapply(v.args,
                         function(x,d) { d %in% x },
                         d=deletevar)
  v.has.other <- sapply(v.args,
                        function(x,d) { !all(x == d) },
                        d=deletevar)
  v.is.mixed <- v.has.delete & v.has.other
  # we can't handle mixed terms like sin(x-d), poly(x,d)
  # where d is to be deleted. Handling these would require
  # knowledge about the functions sin and poly.
  if(any(v.is.mixed)) {
    nmixed <- sum(v.is.mixed)
    if(verbose)
      message(paste("Don't know how to reduce the",
              ngettext(nmixed, "term", "terms"),
              paste(dQuote(varstrings[v.is.mixed]), collapse=",")))
    return(NULL)
  }
  # OK. We have identified all first order terms to be deleted.
  condemned.names <- varstrings[v.has.delete]
  # Determine the terms of all orders that include these first order terms
  # (1) terms with model coefficients
  fax <- tt$factors
  if(prod(dim(fax)) == 0)
    retained.terms <- character(0)
  else {
    # Rows are first order terms 
    condemned.row <- rownames(fax) %in% condemned.names
    # Columns are the terms of all orders
    allterms <- colnames(fax)
    # Find all columns containing a 1 in a row that is to be deleted
    if(any(condemned.row)) {
      condemned.column <- apply(fax[condemned.row, , drop=FALSE] != 0, 2, any)
      retained.terms <- allterms[!condemned.column]
    } else retained.terms <- allterms
  }
  # (2) offsets if any
  if(any(v.is.offset))
    retained.terms <- c(retained.terms,
                        varstrings[v.is.offset & !v.has.delete])
  # (3) intercept forced?
  if(length(retained.terms) == 0)
    retained.terms <- "1"
  
  # OK. Cut-and-paste
  f <- paste(lhs, "~", paste(retained.terms, collapse=" + "))
  return(as.formula(f))
} 

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/relrisk.R"
#
#    relrisk.R
#
#   Estimation of relative risk
#
#  $Revision: 1.29 $  $Date: 2014/12/30 11:01:15 $
#

relrisk <- function(X, ...) UseMethod("relrisk")
                                      
relrisk.ppp <- local({

  relrisk.ppp <- function(X, sigma=NULL, ..., varcov=NULL, at="pixels",
                      relative=FALSE, se=FALSE,
                      casecontrol=TRUE, control=1, case) {
    stopifnot(is.ppp(X))
    stopifnot(is.multitype(X))
    control.given <- !missing(control)
    case.given <- !missing(case)
    if(!relative && (control.given || case.given)) {
      aa <- c("control", "case")[c(control.given, case.given)]
      nn <- length(aa)
      warning(paste(ngettext(nn, "Argument", "Arguments"),
                    paste(sQuote(aa), collapse=" and "),
                    ngettext(nn, "was", "were"),
                    "ignored, because relative=FALSE"))
    }
    npts <- npoints(X)
    Y <- split(X)
    uX <- unmark(X)
    types <- names(Y)
    ntypes <- length(Y)
    if(ntypes == 1)
      stop("Data contains only one type of points")
    marx <- marks(X)
    imarks <- as.integer(marx)
    lev <- levels(marx)
    ## trap arguments
    dotargs <- list(...)
    isbwarg <- names(dotargs) %in% c("method", "nh", "hmin", "hmax", "warn")
    bwargs <- dotargs[isbwarg]
    dargs  <- dotargs[!isbwarg]
    ## using edge corrections?
    edge   <- resolve.1.default(list(edge=TRUE), list(...))
    diggle <- resolve.1.default(list(diggle=FALSE), list(...))
    ## bandwidth
    if(is.null(sigma) && is.null(varcov)) 
      sigma <- do.call(bw.relrisk, append(list(X), bwargs))
    SmoothPars <- append(list(sigma=sigma, varcov=varcov, at=at), dargs)
    if(se) {
      ## determine other bandwidth for variance estimation
      if(is.null(varcov)) {
        varconst <- 1/(4 * pi * prod(sigma))
        VarPars <- append(list(sigma=sigma/sqrt(2), at=at), dargs)
      } else {
        varconst <- 1/(4 * pi * sqrt(det(varcov)))
        VarPars <- append(list(varcov=varcov/2, at=at), dargs)
      }
      if(edge) {
        ## evaluate edge correction weights
        edgeim <- second.moment.calc(uX, sigma, what="edge", ...,
                                     varcov=varcov)
        if(diggle || at == "points") {
          edgeX <- safelookup(edgeim, uX, warn=FALSE)
          diggleX <- 1/edgeX
          diggleX[!is.finite(diggleX)] <- 0
        }
        edgeim <- edgeim[Window(X), drop=FALSE]
      }
    }
    ## .........................................
    ## compute intensity estimates for each type
    ## .........................................
    switch(at,
           pixels = {
             ## intensity estimates of each type
             Deach <- do.call(density.splitppp,
                              append(list(x=Y), SmoothPars))
             ## compute intensity estimate for unmarked pattern
             Dall <- Reduce("+", Deach)
             ## variance terms
             if(se) {
               if(!edge) {
                 ## no edge correction
                 Veach <- do.call(density.splitppp,
                                  append(list(x=Y), VarPars))
               } else if(!diggle) {
                 ## edge correction e(u)
                 Veach <- do.call(density.splitppp,
                                  append(list(x=Y), VarPars))
                 Veach <- lapply(Veach, "/", e2=edgeim)
               } else {
                 ## Diggle edge correction e(x_i)
                 Veach <- mapply(density.ppp,
                                 x=Y,
                                 weights=split(diggleX, marx),
                                 MoreArgs=VarPars,
                                 SIMPLIFY=FALSE)
               }
               Veach <- lapply(Veach, "*", varconst)
               Vall <- Reduce("+", Veach)
             }
           },
           points = {
             ## intensity estimates of each type **at each data point**
             ## dummy variable matrix
             dumm <- matrix(0, npts, ntypes)
             dumm[cbind(seq_len(npts), imarks)] <- 1
             colnames(dumm) <- lev
             Deach <- do.call(density.ppp,
                              append(list(x=uX, weights=dumm),
                                     SmoothPars))
             ## compute intensity estimate for unmarked pattern
             Dall <- rowSums(Deach)
             ## variance terms
             if(se) {
               if(!edge) {
                 ## no edge correction
                 Veach <- do.call(density.ppp,
                                  append(list(x=uX, weights=dumm),
                                         VarPars))
               } else if(!diggle) {
                 ## edge correction e(u)
                 Veach <- do.call(density.ppp,
                                  append(list(x=uX, weights=dumm),
                                         VarPars))
                 Veach <- Veach * diggleX
               } else {
                 ## Diggle edge correction e(x_i)
                 Veach <- do.call(density.ppp,
                                  append(list(x=uX, weights=dumm * diggleX),
                                         VarPars))
               }
               Veach <- Veach * varconst
               Vall <- rowSums(Veach)
             }
           })
    ## .........................................
    ## compute probabilities/risks
    ## .........................................
    if(ntypes == 2 && casecontrol) {
      if(control.given || !case.given) {
        stopifnot(length(control) == 1)
        if(is.numeric(control)) {
          icontrol <- control <- as.integer(control)
          stopifnot(control %in% 1:2)
        } else if(is.character(control)) {
          icontrol <- match(control, levels(marks(X)))
          if(is.na(icontrol)) stop(paste("No points have mark =", control))
        } else
          stop(paste("Unrecognised format for argument", sQuote("control")))
        if(!case.given)
          icase <- 3 - icontrol
      }
      if(case.given) {
        stopifnot(length(case) == 1)
        if(is.numeric(case)) {
          icase <- case <- as.integer(case)
          stopifnot(case %in% 1:2)
        } else if(is.character(case)) {
          icase <- match(case, levels(marks(X)))
          if(is.na(icase)) stop(paste("No points have mark =", case))
        } else stop(paste("Unrecognised format for argument", sQuote("case")))
        if(!control.given) 
          icontrol <- 3 - icase
      }
      ## compute ......
      switch(at,
             pixels = {
               ## compute probability of case
               pcase <- Deach[[icase]]/Dall
               ## correct small numerical errors
               pcase <- clamp01(pcase)
               ## trap NaN values
               nbg <- badvalues(pcase)
               if(any(nbg)) {
                 ## apply l'Hopital's rule:
                 ##     p(case) = 1{nearest neighbour is case}
                 distcase <- distmap(Y[[icase]], xy=pcase)
                 distcontrol <- distmap(Y[[icontrol]], xy=pcase)
                 closecase <- eval.im(as.integer(distcase < distcontrol))
                 pcase[nbg] <- closecase[nbg]
               }
               if(!relative) {
                 if(!se) {
                   result <- pcase
                 } else {
                   Vcase <- Veach[[icase]]
                   NUM <- eval.im(Vcase * (1-2*pcase) + Vall * pcase^2)
                   SE <- eval.im(sqrt(pmax(NUM, 0))/Dall)
                   result <- list(estimate=pcase, SE=SE)
                 }
               } else {
                 rcase <- eval.im(ifelse(pcase < 1, pcase/(1-pcase), NA))
                 if(!se) {
                   result <- rcase
                 } else {
                   Vcase <- Veach[[icase]]
                   Vctrl <- Veach[[icontrol]]
                   Dctrl <- Deach[[icontrol]]
                   NUM <- eval.im(Vcase + Vctrl * rcase^2)
                   SE <- eval.im(sqrt(pmax(NUM, 0))/Dctrl)
                   result <- list(estimate=rcase, SE=SE)
                 }
               }
             },
             points={
               ## compute probability of case
               pcase <- Deach[,icase]/Dall
               ## correct small numerical errors
               pcase <- clamp01(pcase)
               ## trap NaN values
               if(any(nbg <- badvalues(pcase))) {
                 ## apply l'Hopital's rule
                 nntype <- imarks[nnwhich(X)]
                 pcase[nbg] <- as.integer(nntype[nbg] == icase)
               }
               if(!relative) {
                 if(!se) {
                   result <- pcase
                 } else {
                   NUM <- Veach[,icase] * (1-2*pcase) + Vall * pcase^2
                   SE <- sqrt(pmax(NUM, 0))/Dall
                   result <- list(estimate=pcase, SE=SE)
                 }
               } else {
                 rcase <- ifelse(pcase < 1, pcase/(1-pcase), NA)
                 if(!se) {
                   result <- rcase
                 } else {
                   NUM <- Veach[,icase] + Veach[,icontrol] * rcase^2
                   SE <- sqrt(pmax(NUM, 0))/Deach[,icontrol]
                   result <- list(estimate=rcase, SE=SE)
                 }
               }
             })
    } else {
      ## several types
      if(relative) {
        ## need 'control' type
        stopifnot(length(control) == 1)
        if(is.numeric(control)) {
          icontrol <- control <- as.integer(control)
          stopifnot(control %in% 1:ntypes)
        } else if(is.character(control)) {
          icontrol <- match(control, levels(marks(X)))
          if(is.na(icontrol)) stop(paste("No points have mark =", control))
        } else
          stop(paste("Unrecognised format for argument", sQuote("control")))
      }
      switch(at,
             pixels={
               probs <- as.listof(lapply(Deach, "/", e2=Dall))
               ## correct small numerical errors
               probs <- as.listof(lapply(probs, clamp01))
               ## trap NaN values
               nbg <- lapply(probs, badvalues)
               nbg <- Reduce("|", nbg)
               if(any(nbg)) {
                 ## apply l'Hopital's rule
                 distX <- distmap(X, xy=Dall)
                 whichnn <- attr(distX, "index")
                 typenn <- eval.im(imarks[whichnn])
                 typennsub <- as.matrix(typenn)[nbg]
                 for(k in seq_along(result)) 
                   probs[[k]][nbg] <- (typennsub == k)
               }
               if(!relative) {
                 if(!se) {
                   result <- probs
                 } else {
                   SE <- list()
                   for(i in 1:ntypes) {
                     NUM <- (Veach[[i]] * (1 - 2 * probs[[i]])
                             + Vall * probs[[i]]^2)
                     SE[[i]] <- eval.im(sqrt(pmax(NUM, 0))/Dall)
                   }
                   SE <- as.listof(SE)
                   names(SE) <- types
                   result <- list(estimate=probs, SE=SE)
                 }
               } else {
                 risks <- as.listof(lapply(probs,
                                           function(z, d) {
                                             eval.im(ifelse(d > 0, z/d, NA))
                                           },
                                           d = probs[[icontrol]]))
                 if(!se) {
                   result <- risks
                 } else {
                   Vctrl <- Veach[[icontrol]]
                   Dctrl <- Deach[[icontrol]]
                   SE <- list()
                   for(i in 1:ntypes) {
                     NUM <- Veach[[i]] + Vctrl * risks[[i]]^2
                     SE[[i]] <- eval.im(sqrt(pmax(NUM, 0))/Dctrl)
                   }
                   SE <- as.listof(SE)
                   names(SE) <- types
                   result <- list(estimate=risks, SE=SE)
                   
                 }
               }
             },
             points = {
               probs <- Deach/Dall
               ## correct small numerical errors
               probs <- clamp01(probs)
               ## trap NaN values
               bad <- badvalues(probs)
               badrow <- apply(bad, 1, any)
               if(any(badrow)) {
                 ## apply l'Hopital's rule
                 typenn <- imarks[nnwhich(X)]
                 probs[badrow, ] <- (typenn == col(result))[badrow, ]
               }
               if(!relative) {
                 if(!se) {
                   result <- probs
                 } else {
                   NUM <- Veach * (1-2*probs) + Vall * probs^2
                   SE <- sqrt(pmax(NUM, 0))/Dall
                   result <- list(estimate=probs, SE=SE)
                }
               } else {
                 risks <- probs/probs[,icontrol]
                 if(!se) {
                   result <- risks
                 } else {
                   NUM <- Veach + Veach[,icontrol] * risks^2
                   NUM[,icontrol] <- 0
                   SE <- sqrt(pmax(NUM, 0))/Deach[,icontrol]
                   result <- list(estimate=risks, SE=SE)
                 }
               }
            })
    }
    attr(result, "sigma") <- sigma
    attr(result, "varcov") <- varcov
    return(result)
  }

  clamp01 <- function(x) {
    if(is.im(x)) return(eval.im(pmin(pmax(x, 0), 1)))
    return(pmin(pmax(x, 0), 1))
  }

  badvalues <- function(x) {
    if(is.im(x)) x <- as.matrix(x)
    return(!(is.finite(x) | is.na(x)))
  }

  reciprocal <- function(x) 1/x
  
  relrisk.ppp
})


bw.stoyan <- function(X, co=0.15) {
  ## Stoyan's rule of thumb
  stopifnot(is.ppp(X))
  n <- npoints(X)
  W <- Window(X)
  a <- area(W)
  stoyan <- co/sqrt(5 * n/a)
  return(stoyan)
}


bw.relrisk <- function(X, method="likelihood",
                       nh=spatstat.options("n.bandwidth"),
                       hmin=NULL, hmax=NULL, warn=TRUE) {
  stopifnot(is.ppp(X))
  stopifnot(is.multitype(X))
  ## rearrange in ascending order of x-coordinate (for C code)
  X <- X[fave.order(X$x)]
  ##
  Y <- split(X)
  ntypes <- length(Y)
  if(ntypes == 1)
    stop("Data contains only one type of points")
  marx <- marks(X)
  method <- pickoption("method", method,
                       c(likelihood="likelihood",
                         leastsquares="leastsquares",
                         ls="leastsquares",
                         LS="leastsquares",
                         weightedleastsquares="weightedleastsquares",
                         wls="weightedleastsquares",
                         WLS="weightedleastsquares"))
  ## 
  if(method != "likelihood") {
    ## dummy variables for each type
    imarks <- as.integer(marx)
    if(ntypes == 2) {
      ## 1 = control, 2 = case
      indic <- (imarks == 2)
      y01   <- as.integer(indic)
    } else {
      indic <- matrix(FALSE, n, ntypes)
      indic[cbind(seq_len(n), imarks)] <- TRUE
      y01  <- indic * 1
    }
    X01 <- X %mark% y01
  }
  ## cross-validated bandwidth selection
  ## determine a range of bandwidth values
  n <- npoints(X)
  if(is.null(hmin) || is.null(hmax)) {
    W <- Window(X)
    a <- area(W)
    d <- diameter(as.rectangle(W))
    ## Stoyan's rule of thumb applied to the least and most common types
    mcount <- table(marx)
    nmin <- max(1, min(mcount))
    nmax <- max(1, max(mcount))
    stoyan.low <- 0.15/sqrt(nmax/a)
    stoyan.high <- 0.15/sqrt(nmin/a)
    if(is.null(hmin)) 
      hmin <- max(minnndist(unique(X)), stoyan.low/5)
    if(is.null(hmax)) {
      hmax <- min(d/4, stoyan.high * 20)
      hmax <- max(hmax, hmin * 2)
    }
  } else stopifnot(hmin < hmax)
  ##
  h <- exp(seq(from=log(hmin), to=log(hmax), length.out=nh))
  cv <- numeric(nh)
  ## 
  ## compute cross-validation criterion
  switch(method,
         likelihood={
           methodname <- "Likelihood"
           ## for efficiency, only compute the estimate of p_j(x_i)
           ## when j = m_i = mark of x_i.
           Dthis <- numeric(n)
           for(i in seq_len(nh)) {
             Dall <- density.ppp(X, sigma=h[i], at="points", edge=FALSE,
                                 sorted=TRUE)
             Deach <- density.splitppp(Y, sigma=h[i], at="points", edge=FALSE,
                                       sorted=TRUE)
             split(Dthis, marx) <- Deach
             pthis <- Dthis/Dall
             cv[i] <- -mean(log(pthis))
           }
         },
         leastsquares={
           methodname <- "Least Squares"
           for(i in seq_len(nh)) {
             phat <- Smooth(X01, sigma=h[i], at="points", leaveoneout=TRUE,
                            sorted=TRUE)
             cv[i] <- mean((y01 - phat)^2)
           }
         },
         weightedleastsquares={
           methodname <- "Weighted Least Squares"
           ## need initial value of h from least squares
           h0 <- bw.relrisk(X, "leastsquares", nh=ceiling(nh/4))
           phat0 <- Smooth(X01, sigma=h0, at="points", leaveoneout=TRUE,
                           sorted=TRUE)
           var0 <- phat0 * (1-phat0)
           var0 <- pmax.int(var0, 1e-6)
           for(i in seq_len(nh)) {
             phat <- Smooth(X01, sigma=h[i], at="points", leaveoneout=TRUE,
                            sorted=TRUE)
             cv[i] <- mean((y01 - phat)^2/var0)
           }
         })
  ## optimize
  iopt <- which.min(cv)
  ##
  if(warn && (iopt == nh || iopt == 1)) 
    warning(paste("Cross-validation criterion was minimised at",
                  if(iopt == 1) "left-hand" else "right-hand",
                  "end of interval",
                  "[", signif(hmin, 3), ",", signif(hmax, 3), "];",
                  "use arguments hmin, hmax to specify a wider interval"))
  ##    
  result <- bw.optim(cv, h, iopt,
                     hname="sigma", 
                     creator="bw.relrisk",
                     criterion=paste(methodname, "Cross-Validation"))
  return(result)
}

which.max.im <- function(x) {
  .Deprecated("im.apply", "spatstat",
              "which.max.im(x) is deprecated: use im.apply(x, which.max)")
  ans <- im.apply(x, which.max)
  return(ans)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/relrisk.ppm.R"
##
##  relrisk.ppm.R
##
##  $Revision: 1.3 $ $Date: 2014/11/22 03:51:17 $
##

relrisk.ppm <- local({

  relrisk.ppm <- function(X, ..., at=c("pixels", "points"),
                          relative=FALSE, se=FALSE, 
                          casecontrol=TRUE, control=1, case,
                          ngrid=NULL, window=NULL) {
    stopifnot(is.ppm(X))
    stopifnot(is.multitype(X))
    control.given <- !missing(control)
    case.given <- !missing(case)
    at <- match.arg(at)
    if(!relative && (control.given || case.given)) {
      aa <- c("control", "case")[c(control.given, case.given)]
      nn <- length(aa)
      warning(paste(ngettext(nn, "Argument", "Arguments"),
                    paste(sQuote(aa), collapse=" and "),
                    ngettext(nn, "was", "were"),
                    "ignored, because relative=FALSE"))
    }
    model <- X
    Y <- data.ppm(model)
    types <- levels(marks(Y))
    nm <- ntypes <- length(types)
    np <- length(coef(model))
    ## compute probabilities or risks
    if(ntypes == 2 && casecontrol) {
      if(control.given || !case.given) {
        stopifnot(length(control) == 1)
        if(is.numeric(control)) {
          icontrol <- control <- as.integer(control)
          stopifnot(control %in% 1:2)
        } else if(is.character(control)) {
          icontrol <- match(control, types)
          if(is.na(icontrol)) stop(paste("No points have mark =", control))
        } else
          stop(paste("Unrecognised format for argument", sQuote("control")))
        if(!case.given)
          icase <- 3 - icontrol
      }
      if(case.given) {
        stopifnot(length(case) == 1)
        if(is.numeric(case)) {
          icase <- case <- as.integer(case)
          stopifnot(case %in% 1:2)
        } else if(is.character(case)) {
          icase <- match(case, types)
          if(is.na(icase)) stop(paste("No points have mark =", case))
        } else stop(paste("Unrecognised format for argument", sQuote("case")))
        if(!control.given) 
          icontrol <- 3 - icase
      }
      switch(at,
             pixels= {
               ## estimate is a single image
               ## compute images of intensities of each mark
               lambda.each <- predict(model, ngrid=ngrid, window=window)
               if(!relative) {
                 ## compute probabilities..
                 ## total intensity (image)
                 lambda.all <- Reduce("+", lambda.each)
                 if(!se) {
                   result <- lambda.each[[icase]]/lambda.all
                   result <- killglitches(result)
                 } else {
                   probs <- lapply(lambda.each, "/", e2=lambda.all)
                   probs <- as.listof(lapply(probs, killglitches))
                   estimate <- probs[[icase]]
                   SE <- SEprobPixels(model, probs)[[icase]]
                   SE <- killglitches(SE)
                   result <- list(estimate=estimate, SE=SE)
                 }
               } else {
                 ## relative risks
                 lambda.ctrl <- lambda.each[[icontrol]]
                 if(!se) {
                   result <- lambda.each[[icase]]/lambda.ctrl
                   result <- killglitches(result)
                 } else {
                   risks <- lapply(lambda.each, "/", e2=lambda.ctrl)
                   risks <- as.listof(lapply(risks, killglitches))
                   estimate <- risks[[icase]]
                   SE <- SErelriskPixels(model, risks, icontrol)[[icase]]
                   SE <- killglitches(SE)
                   result <- list(estimate=estimate, SE=SE)
                 }
               }
             },
             points={
               ## compute intensities of each type
               Ycase <- unmark(Y) %mark% factor(types[icase], levels=types)
               Yctrl <- unmark(Y) %mark% factor(types[icontrol], levels=types)
               lambda.case <- predict(model, locations=Ycase)
               lambda.ctrl <- predict(model, locations=Yctrl)
               if(!relative) {
                 ## compute probabilities
                 ## total intensity
                 lambda.all  <- lambda.case + lambda.ctrl
                 prob.case <- lambda.case/lambda.all
                 if(!se) {
                   result <- prob.case
                 } else {
                   probs <- matrix(, length(prob.case), 2)
                   probs[,icase] <- prob.case
                   probs[,icontrol] <- 1 - prob.case
                   SE <- SEprobPoints(model, probs)[,icase]
                   result <- list(estimate=prob.case, SE=SE)
                 }
               } else {
                 ## compute relative risks
                 risk.case <- lambda.case/lambda.ctrl
                 if(!se) {
                   result <- risk.case
                 } else {
                   risks <- matrix(, length(risk.case), 2)
                   risks[,icase] <- risk.case
                   risks[,icontrol] <- 1
                   SE <- SErelriskPoints(model, risks, icontrol)[,icase]
                   result <- list(estimate=risk.case, SE=SE)
                 }
               }
             })
    } else {
      ## several types
      if(relative) {
        ## need 'control' type
        stopifnot(length(control) == 1)
        if(is.numeric(control)) {
          icontrol <- control <- as.integer(control)
          stopifnot(control %in% 1:ntypes)
        } else if(is.character(control)) {
          icontrol <- match(control, types)
          if(is.na(icontrol)) stop(paste("No points have mark =", control))
        } else
          stop(paste("Unrecognised format for argument", sQuote("control")))
      }
      switch(at,
             pixels={
               ## estimate is a list of images
               ## Compute images of intensities of each type
               lambda.each <- predict(model, ngrid=ngrid, window=window)
               if(!relative) {
                 ## compute probabilities...
                 ## image of total intensity
                 lambda.all <- Reduce("+", lambda.each)
                 probs <- lapply(lambda.each, "/", e2=lambda.all)
                 probs <- as.listof(lapply(probs, killglitches))
                 if(!se) {
                   result <- probs
                 } else {
                   SE <- SEprobPixels(model, probs)
                   SE <- as.listof(lapply(SE, killglitches))
                   result <- list(estimate=probs, SE=SE)
                 }
               } else {
                 ## compute relative risks
                 risks <- lapply(lambda.each, "/",
                                 e2=lambda.each[[icontrol]])
                 risks <- as.listof(lapply(risks, killglitches))
                 if(!se) {
                   result <- risks
                 } else {
                   SE <- SErelriskPixels(model, risks, icontrol)
                   SE <- as.listof(lapply(SE, killglitches))
                   result <- list(estimate=risks, SE=SE)
                 }
               }
             },
             points = {
               ## matrix of intensities of each type at each point
               ## rows=locations, cols=types
               lambda.each <- sapply(types,
                                     predictfortype, 
                                     loc=unmark(Y), model=model, types=types)
               if(!relative) {
                 ## compute probabilities
                 lambda.all <- rowSums(lambda.each)
                 probs <- lambda.each/lambda.all
                 if(!se) {
                   result <- probs
                 } else {
                   SE <- SEprobPoints(model, probs)
                   result <- list(estimate=probs, SE=SE)
                 }
               } else {
                 ## compute relative risks
                 risks <- lambda.each/lambda.each[,icontrol]
                 if(!se) {
                   result <- risks
                 } else {
                   SE <- SErelriskPoints(model, risks, icontrol)
                   result <- list(estimate=risks, SE=SE)
                 }
               }
            })
    }
    return(result)
  }

  modmats <- function(model) {
    # model matrices for data locations for each possible mark
    QM <- quad.ppm(model)
    Y <- QM$data
    QR <- quadscheme.replicated(Y, unmark(Y[FALSE]))
    sourceid <- QR$param$sourceid
    ## canonical covariates 
    mm <- model.matrix(model, Q=QR)
    ## mm is a matrix with one column for canonical covariate
    ## and one row for each marked point in QR.
    mm <- cbind(data.frame(".s"=sourceid, ".m"=marks(QR)), mm)
    ## Split by marks 
    ss <- split(mm, mm$.m)
    ## Reorganise into compatible matrices
    zz <- lapply(ss, reorg)
    return(zz)
  }
  
  reorg <- function(x) {
      z <- x
      rownames(z) <- NULL
      z[x$.s, ] <- z
      return(z[,-(1:2), drop=FALSE])
  }

  SErelriskPoints <- function(model, riskvalues, icontrol) {
    ## riskvalues is a matrix with rows=data locations, cols=types
    types <- colnames(riskvalues)
    ntypes <- length(types)
    ## 
    S.um <- modmats(model)
    S.um <- lapply(S.um, as.matrix)
    ## S.um is a list of matrices, one for each possible type,
    ## each matrix having one row per data location 
    dS.um <- lapply(S.um, "-", e2=S.um[[icontrol]])
    R.um <- mapply("*",
                   dS.um,
                   as.list(as.data.frame(riskvalues)),
                   SIMPLIFY=FALSE)
    ## likewise R.um is a list of matrices
    ##
    vc <- vcov(model)
    VAR <- lapply(R.um, quadform, v=vc)
    VAR <- do.call(cbind, VAR)
    SE <- sqrt(VAR)
    colnames(SE) <- types
    return(SE)
  }

  SErelriskPixels <- function(model, riskvalues, icontrol) {
    ## riskvalues is an imlist
    types <- names(riskvalues)
    ntypes <- length(types)
    ## canonical covariates
    S.um <- model.images(model)
    ## S.um is a hyperframe with one column for each mark value
    ## and one row for each canonical covariate
    dS.um <- lapply(S.um, 
                    function(z, z0) mapply("-", e1=z, e2=z0, SIMPLIFY=FALSE),
                    z0=S.um[,icontrol,drop=TRUE])
    R.um <- mapply(function(a, b) as.listof(lapply(a, "*", e2=b)),
                   a=dS.um,
                   b=riskvalues,
                   SIMPLIFY=FALSE)
    VAR <- vector(mode="list", length=ntypes)
    ntypes <- length(types)
    vc <- vcov(model)
    ncoef <- nrow(vc)
    for(type in 1:ntypes) {
      v <- 0
      Rum <- R.um[[type]]
      for(i in 1:ncoef) {
        for(j in 1:ncoef) {
          v <- v + Rum[[i]] * vc[i,j] * Rum[[j]]
        }
      }
      VAR[[type]] <- v
    }
    names(VAR) <- types
    VAR <- as.listof(VAR)
    SE <- as.listof(lapply(VAR, sqrt))
    return(SE)
  }

  SEprobPixels <- function(model, probvalues) {
    ## probvalues is an imlist
    types <- names(probvalues)
    ntypes <- length(types)
    ## canonical covariates
    S.um <- model.images(model)
    ## S.um is a hyperframe with one column for each mark value
    ## and one row for each canonical covariate
    ncoef <- length(coef(model))
    Sbar.u <- vector(mode="list", length=ncoef)
    for(k in 1:ncoef)
      Sbar.u[[k]] <- Reduce("+",
                            mapply("*", e1=S.um[k,,drop=TRUE], e2=probvalues,
                                   SIMPLIFY=FALSE))
    ## Sbar.u is a list of images, one for each canonical covariate
    Sdif.um <- lapply(as.list(S.um), 
                      function(z, zbar) mapply("-", e1=z, e2=zbar, SIMPLIFY=FALSE),
                      zbar=Sbar.u)
    ## Sdif.um is a list of lists of images.
    ##   List of length ntypes,
    ##   each entry being an imlist of length ncoef
    P.um <- mapply(function(a, b) as.listof(lapply(a, "*", e2=b)),
                   Sdif.um, 
                   probvalues, 
                   SIMPLIFY=FALSE)
    ## P.um is same format as Sdif.um
    vc <- vcov(model)
    ncoef <- nrow(vc)
    VAR <- vector(mode="list", length=ntypes)
    for(m in 1:ntypes) {
      v <- 0
      Pum <- P.um[[m]]
      for(i in 1:ncoef) {
        for(j in 1:ncoef) {
          v <- v + Pum[[i]] * vc[i,j] * Pum[[j]]
        }
      }
      VAR[[m]] <- v
    }
    names(VAR) <- types
    VAR <- as.listof(VAR)
    SE <- as.listof(lapply(VAR, sqrt))
  }
  
  SEprobPoints <- function(model, probvalues) {
    ## probvalues is a matrix with row=location and column=type
    types <- colnames(probvalues)
    ntypes <- length(types)
    ## canonical covariates
    S.um <- modmats(model)
    S.um <- lapply(S.um, as.matrix)
    ## S.um is a list of matrices, one for each possible type,
    ## each matrix having rows=locations and cols=covariates
    ## Weight each matrix by its mark probabilities
    SW <- mapply("*",
                 e1=S.um,
                 e2=as.list(as.data.frame(probvalues)),
                 SIMPLIFY=FALSE)
    ## average them
    Sbar.u <- Reduce("+", SW)
    ## Sbar.u is a matrix with rows=locations and cols=covariates
    Sdif.um <- lapply(S.um, "-", e2=Sbar.u)
    ## Sdif.um is a list of matrices like S.um
    P.um <- mapply("*",
                   e1=Sdif.um, 
                   e2=as.list(as.data.frame(probvalues)),
                   SIMPLIFY=FALSE)
    ## P.um likewise
    vc <- vcov(model)
    VAR <- lapply(P.um, quadform, v=vc)
    VAR <- do.call(cbind, VAR)
    SE <- sqrt(VAR)
    colnames(SE) <- types
    return(SE)
  }
  
  predictfortype <- function(type, model, types, loc) {
    predict(model, locations=loc %mark% factor(type, levels=types))
  }

  killglitches <- function(z, eps=.Machine$double.eps) {
    ra <- range(z, finite=TRUE)
    if(max(abs(ra)) < eps) {
      z[] <- 0
      return(z)
    }
    if(diff(ra) < eps) 
      z[] <- mean(z, na.rm=TRUE)
    return(z)
  }

  relrisk.ppm
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/replace.ppp.R"
#
# replace.ppp.R
#


"[<-.ppp" <-
  function(x, i, j, value) {
    verifyclass(x, "ppp")
    verifyclass(value, "ppp")
    
    if(missing(i) && missing(j))
      return(value)

    if(missing(i)) {
      message("The use of argument j in [<-.ppp is deprecated; use argument i")
      # invoke code below
      x[j] <- value
      return(x)
    }

    xmf <- markformat(x)
    vmf <- markformat(value)
    if(xmf != vmf) {
      if(xmf == "none")
        stop("Replacement points are marked, but x is not marked")
      else if(vmf == "none")
        stop("Replacement points have no marks, but x is marked")
      else
        stop("Format of marks in replacement is incompatible with original")
    }
    
    if(inherits(i, "owin")) {
      win <- i
      vok <- inside.owin(value$x, value$y, win)
      if(!all(vok)) {
        warning("Replacement points outside the specified window were deleted")
        value <- value[vok]
      }
      # convert to vector index
      i <- inside.owin(x$x, x$y, win)
    }
    if(!is.vector(i))
      stop("Unrecognised format for subset index i")
    
    # vector index
    # determine index subset
    n <- x$n
    SUB <- seq_len(n)[i]
    # anything to replace?
    if(length(SUB) == 0)
      return(x)
    # sanity checks
    if(any(is.na(SUB)))
      stop("Invalid subset: the resulting subscripts include NAs")
    # exact replacement of this subset?
    if(value$n == length(SUB)) {
      x$x[SUB] <- value$x
      x$y[SUB] <- value$y
      switch(xmf,
             none={},
             list=,
             vector={ x$marks[SUB] <- value$marks },
             dataframe={ x$marks[SUB,] <- value$marks })
    } else 
      x <- superimpose(x[-SUB], value, W=x$window)

    if(!missing(j)) {
      warning("The use of argument j in [<-.ppp is deprecated; use argument i")
      # invoke code above
      x[j] <- value
    }
      
    return(x)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rescale.R"
#
#
#   rescale.R
#
#   $Revision: 1.6 $ $Date: 2014/10/24 00:22:30 $
#
#

rescale <- function(X, s, unitname) {
  UseMethod("rescale")
}

rescale.ppp <- function(X, s, unitname) {
  if(missing(unitname)) unitname <- NULL
  if(missing(s) || is.null(s)) s <- 1/unitname(X)$multiplier
  Y <- affine.ppp(X, mat=diag(c(1/s,1/s)))
  unitname(Y) <- rescale(unitname(X), s, unitname)
  return(Y)
}

rescale.owin <- function(X, s, unitname) {
  if(missing(unitname)) unitname <- NULL
  if(missing(s) || is.null(s)) s <- 1/unitname(X)$multiplier
  Y <- affine.owin(X, mat=diag(c(1/s,1/s)))
  unitname(Y) <- rescale(unitname(X), s, unitname)
  return(Y)
}

rescale.im <- function(X, s, unitname) {
  if(missing(unitname)) unitname <- NULL
  if(missing(s) || is.null(s)) s <- 1/unitname(X)$multiplier
  Y <- X
  Y$xrange <- X$xrange/s
  Y$yrange <- X$yrange/s
  Y$xstep  <- X$xstep/s
  Y$ystep  <- X$ystep/s
  Y$xcol   <- X$xcol/s
  Y$yrow   <- X$yrow/s
  unitname(Y) <- rescale(unitname(X), s, unitname)
  return(Y)
}

rescale.psp <- function(X, s, unitname) {
  if(missing(unitname)) unitname <- NULL
  if(missing(s) || is.null(s)) s <- 1/unitname(X)$multiplier
  Y <- affine.psp(X, mat=diag(c(1/s,1/s)))
  unitname(Y) <- rescale(unitname(X), s, unitname)
  return(Y)
}
  
rescale.units <- function(X, s, unitname) {
  if(!missing(unitname) && !is.null(unitname)) return(as.units(unitname))
  if(summary(X)$vanilla)
    return(X)
  if(missing(s)) {
    X$multiplier <- 1
  } else {
    if(!is.numeric(s) || length(s) != 1 || s <= 0)
      stop("s should be a positive number")
    X$multiplier <- s * X$multiplier
  }
  return(X)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rescue.rectangle.R"
#
#    rescue.rectangle.R
# 
#    $Revision: 1.6 $   $Date: 2008/06/15 14:53:11 $
#
rescue.rectangle <- function(W) {
  verifyclass(W, "owin")

  if(W$type == "mask" && all(W$m))
     return(owin(W$xrange, W$yrange, unitname=unitname(W)))

  if(W$type == "polygonal" && length(W$bdry) == 1) {
    x <- W$bdry[[1]]$x
    y <- W$bdry[[1]]$y
    if(length(x) == 4 && length(y) == 4) {
      # could be a rectangle
      veryunique <- function(z) {
        uz <- sort(unique(z))
        epsilon <- 2 * .Machine$double.eps * diff(range(uz))
        close <- (diff(uz) <= epsilon)
        uz <- uz[c(TRUE, !close)]
        return(uz)
      }
      ux <- veryunique(x)
      uy <- veryunique(y)
      if(length(ux) == 2 && length(uy) == 2)
        return(owin(ux,uy, unitname=unitname(W)))
    }
  }
  
  return(W)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/resid4plot.R"
#
#
#   Residual plots:
#         resid4plot       four panels with matching coordinates
#         resid1plot       one or more unrelated individual plots 
#         resid1panel      one panel of resid1plot
#
#   $Revision: 1.27 $    $Date: 2014/10/24 00:22:30 $
#
#

resid4plot <- local({
  
  do.clean <- function(fun, ..., 
                       pch, chars, cols, etch, size,
                       maxsize, meansize, markscale, symap, zap,
                       legend, leg.side, leg.args) {
    ## avoid passing arguments of plot.ppp to image()
    do.call(fun, list(...))
  }

  do.lines <- function(x, y, defaulty=1, ...) {
    do.call("lines",
            resolve.defaults(list(x, y),
                             list(...),
                             list(lty=defaulty)))
  }

  resid4plot <-
    function(RES,
             plot.neg=c("image", "discrete", "contour", "imagecontour"),
             plot.smooth=c("imagecontour", "image", "contour", "persp"),
             spacing=0.1, srange=NULL, monochrome=FALSE, main=NULL,
             ...)
{
  plot.neg <- match.arg(plot.neg)
  clip     <- RES$clip
  Yclip    <- RES$Yclip
  Z        <- RES$smooth$Z
  W        <- RES$W
  Wclip    <- Yclip$window
  type     <- RES$type
  typename <- RES$typename
  Ydens    <- RES$Ydens[Wclip, drop=FALSE]
  Ymass    <- RES$Ymass[Wclip]
  # set up 2 x 2 plot with space
  wide <- diff(W$xrange)
  high <- diff(W$yrange)
  space <- spacing * max(wide,high)
  width <- wide + space + wide
  height <- high + space + high
  outerspace <- 3 * space
  plot(c(0, width) + outerspace * c(-1,1),
       c(0, height) + outerspace * c(-1,1),
       type="n", asp=1.0, axes=FALSE, xlab="", ylab="")
  # determine colour map for background
  if(is.null(srange)) {
    Yrange <- if(!is.null(Ydens)) summary(Ydens)$range else NULL
    Zrange <- if(!is.null(Z)) summary(Z)$range else NULL
    srange <- range(c(0, Yrange, Zrange), na.rm=TRUE)
  } else {
    stopifnot(is.numeric(srange) && length(srange) == 2)
    stopifnot(all(is.finite(srange)))
  }
  backcols <- beachcolours(srange, if(type=="eem") 1 else 0, monochrome)
                      
  # ------ plot residuals/marks (in top left panel) ------------
  Xlowleft <- c(W$xrange[1],W$yrange[1])
  vec <- c(0, high) + c(0, space) - Xlowleft
  # shift the original window
  Ws <- shift(W, vec)
  # shift the residuals 
  Ys <- shift(Yclip,vec)

  # determine whether pre-plotting the window(s) is redundant
  redundant <- 
    (plot.neg == "image") && (type != "eem") && (Yclip$window$type == "mask")

  # pre-plot the window(s)
  if(!redundant) {
    if(!clip) 
      do.clean(plot, Ys$window, add=TRUE, ...)
    else
      do.clean(ploterodewin, Ws, Ys$window, add=TRUE, ...)
  }

  ## adjust position of legend associated with eroded window
  sep <- if(clip) Wclip$yrange[1] - W$yrange[1] else NULL
  
  ## decide whether mark scale should be shown
  showscale <- (type != "raw")
  
  switch(plot.neg,
         discrete={
           neg <- (Ys$marks < 0)
           ## plot negative masses of discretised measure as squares
           if(any(c("maxsize","meansize","markscale") %in% names(list(...)))) {
             plot(Ys[neg], add=TRUE, legend=FALSE, ...)
           } else {
             hackmax <- 0.5 * sqrt(area(Wclip)/Yclip$n)
             plot(Ys[neg], add=TRUE, legend=FALSE, maxsize=hackmax, ...)
           }
           ## plot positive masses at atoms
           plot(Ys[!neg], add=TRUE,
                leg.side="left", leg.args=list(sep=sep),
                show.all=TRUE, main="",
                ...)
         },
         contour = {
           Yds <- shift(Ydens, vec)
           Yms <- shift(Ymass, vec)
           do.clean(contour, Yds, add=TRUE, ...)
           do.call("plot",
                   resolve.defaults(list(x=Yms, add=TRUE),
                                    list(...), 
                                    list(use.marks=showscale,
                                         leg.side="left", show.all=TRUE,
                                         main="", leg.args=list(sep=sep))))
         },
         imagecontour=,
         image={
           Yds <- shift(Ydens, vec)
           Yms <- shift(Ymass, vec)
           if(redundant)
             do.clean(ploterodeimage,
                      Ws, Yds, rangeZ=srange, colsZ=backcols,
                      ...)
           else if(type != "eem")
             do.clean(image,
                      Yds, add=TRUE, ribbon=FALSE,
                      col=backcols, zlim=srange,
                      ...)
           if(plot.neg == "imagecontour")
             do.clean(contour, Yds, add=TRUE, ...)
           ## plot positive masses at atoms
           do.call("plot",
                   resolve.defaults(list(x=Yms, add=TRUE),
                                    list(...),
                                    list(use.marks=showscale,
                                         leg.side="left", show.all=TRUE,
                                         main="", leg.args=list(sep=sep))))
         }
         )
  # --------- plot smoothed surface (in bottom right panel) ------------
  vec <- c(wide, 0) + c(space, 0) - Xlowleft
  Zs <- shift.im(Z, vec)
  switch(plot.smooth,
         image={
           do.clean(image,
                    Zs, add=TRUE, col=backcols,
                    zlim=srange, ribbon=FALSE,
                    ...)
         },
         contour={
           do.clean(contour, Zs, add=TRUE, ...)
         },
         persp={ warning("persp not available in 4-panel plot") },
         imagecontour={
             do.clean(image,
                      Zs, add=TRUE, col=backcols, zlim=srange, ribbon=FALSE,
                      ...)
             do.clean(contour, Zs, add=TRUE, ...)
           }
         )
  lines(Zs$xrange[c(1,2,2,1,1)], Zs$yrange[c(1,1,2,2,1)])
  # -------------- lurking variable plots -----------------------
  # --------- lurking variable plot for x coordinate ------------------
  #           (cumulative or marginal)
  #           in bottom left panel
  if(!is.null(RES$xmargin)) {
    a <- RES$xmargin
    observedV <-    a$xZ
    observedX <-    a$x
    theoreticalV <- a$ExZ
    theoreticalX <- a$x
    theoreticalSD <- NULL
    ylabel <- paste("marginal of", typename)
  } else if(!is.null(RES$xcumul)) {
    a <- RES$xcumul
    observedX <- a$empirical$covariate
    observedV <- a$empirical$value
    theoreticalX <- a$theoretical$covariate
    theoreticalV <- a$theoretical$mean
    theoreticalSD <- a$theoretical$sd
    theoreticalHI <- a$theoretical$upper
    theoreticalLO <- a$theoretical$lower
    ylabel <- paste("cumulative sum of", typename)
  }
  # pretty axis marks
  pX <- pretty(theoreticalX)
  rV <- range(0, observedV, theoreticalV, theoreticalHI, theoreticalLO)
  if(!is.null(theoreticalSD))
    rV <- range(rV,
                theoreticalV+2*theoreticalSD,
                theoreticalV-2*theoreticalSD)
  pV <- pretty(rV)
  # rescale smoothed values
  rr <- range(c(0, observedV, theoreticalV, pV))
  yscale <- function(y) { high * (y - rr[1])/diff(rr) }
  xscale <- function(x) { x - W$xrange[1] }
  if(!is.null(theoreticalHI)) 
    do.call.matched(polygon,
                    resolve.defaults(
                      list(x=xscale(c(theoreticalX, rev(theoreticalX))),
                           y=yscale(c(theoreticalHI, rev(theoreticalLO)))),
                      list(...),
                      list(col="grey", border=NA)))
  do.clean(do.lines, xscale(observedX), yscale(observedV), 1, ...)
  do.clean(do.lines, xscale(theoreticalX), yscale(theoreticalV), 2, ...)
  if(!is.null(theoreticalSD)) {
    do.clean(do.lines,
             xscale(theoreticalX),
             yscale(theoreticalV + 2 * theoreticalSD),
             3, ...)
    do.clean(do.lines,
             xscale(theoreticalX),
             yscale(theoreticalV - 2 * theoreticalSD),
             3, ...)
  }
  axis(side=1, pos=0, at=xscale(pX), labels=pX)
  text(xscale(mean(theoreticalX)), - outerspace, "x coordinate")
  axis(side=2, pos=0, at=yscale(pV), labels=pV)
  text(-outerspace, yscale(mean(pV)), ylabel, srt=90)
  
  # --------- lurking variable plot for y coordinate ------------------
  #           (cumulative or marginal)
  #           in top right panel
  if(!is.null(RES$ymargin)) {
    a <- RES$ymargin
    observedV <-    a$yZ
    observedY <-    a$y
    theoreticalV <- a$EyZ
    theoreticalY <- a$y
    theoreticalSD <- NULL
    ylabel <- paste("marginal of", typename)
  } else if(!is.null(RES$ycumul)) {
    a <- RES$ycumul
    observedV <- a$empirical$value
    observedY <- a$empirical$covariate
    theoreticalY <- a$theoretical$covariate
    theoreticalV <- a$theoretical$mean
    theoreticalSD <- a$theoretical$sd
    theoreticalHI <- a$theoretical$upper
    theoreticalLO <- a$theoretical$lower
    ylabel <- paste("cumulative sum of", typename)
  }
  # pretty axis marks
  pY <- pretty(theoreticalY)
  rV <- range(0, observedV, theoreticalV, theoreticalHI, theoreticalLO)
  if(!is.null(theoreticalSD))
    rV <- range(rV,
                theoreticalV+2*theoreticalSD,
                theoreticalV-2*theoreticalSD)
  pV <- pretty(rV)
  # rescale smoothed values
  rr <- range(c(0, observedV, theoreticalV, pV))
  yscale <- function(y) { y - W$yrange[1] + high + space}
  xscale <- function(x) { wide + space + wide * (rr[2] - x)/diff(rr) }
  if(!is.null(theoreticalHI)) 
    do.call.matched(polygon,
                    resolve.defaults(
                      list(x=xscale(c(theoreticalHI, rev(theoreticalLO))),
                           y=yscale(c(theoreticalY,  rev(theoreticalY)))),
                      list(...),
                      list(col="grey", border=NA)))
  do.clean(do.lines, xscale(observedV), yscale(observedY), 1, ...)
  do.clean(do.lines, xscale(theoreticalV), yscale(theoreticalY), 2, ...)
  if(!is.null(theoreticalSD)) {
    do.clean(do.lines,
             xscale(theoreticalV+2*theoreticalSD),
             yscale(theoreticalY),
             3, ...)
    do.clean(do.lines,
             xscale(theoreticalV-2*theoreticalSD),
             yscale(theoreticalY),
             3, ...)
  }
  axis(side=4, pos=width, at=yscale(pY), labels=pY)
  text(width + outerspace, yscale(mean(theoreticalY)), "y coordinate", srt=90)
  axis(side=3, pos=height, at=xscale(pV), labels=pV)
  text(xscale(mean(pV)), height + outerspace, ylabel)
  #
  if(!is.null(main))
    title(main=main)
  invisible(NULL)
}

  resid4plot
})

#
#
#   Residual plot: single panel(s)
#
#

resid1plot <-
  function(RES, opt,
           plot.neg=c("image", "discrete", "contour", "imagecontour"),
           plot.smooth=c("imagecontour", "image", "contour", "persp"),
           srange=NULL, monochrome=FALSE, main=NULL,
           add=FALSE, show.all=!add, do.plot=TRUE, 
           ...) {
    if(!any(unlist(opt[c("all", "marks", "smooth",
                         "xmargin", "ymargin", "xcumul", "ycumul")])))
      return(invisible(NULL))
    if(!add && do.plot) {
      ## determine size of plot area by calling again with do.plot=FALSE
      cl <- match.call()
      cl$do.plot <- FALSE
      b <- eval(cl, parent.frame())
      bb <- as.owin(b, fatal=FALSE)
      if(is.owin(bb)) {
        ## initialise plot area
        plot(bb, type="n", main="")
        force(show.all)
        add <- TRUE
      }
    }
    ## extract info
    clip  <- RES$clip
    Y     <- RES$Y
    Yclip <- RES$Yclip
    Z     <- RES$smooth$Z
    W     <- RES$W
    Wclip <- Yclip$window
    type  <- RES$type
    Ydens <- RES$Ydens[Wclip, drop=FALSE]
    Ymass <- RES$Ymass[Wclip]
    ## determine colour map
    if(opt$all || opt$marks || opt$smooth) {
      if(is.null(srange)) {
        Yrange <- if(!is.null(Ydens)) summary(Ydens)$range else NULL
        Zrange <- if(!is.null(Z)) summary(Z)$range else NULL
        srange <- range(c(0, Yrange, Zrange), na.rm=TRUE)
      }
      backcols <- beachcolours(srange, if(type=="eem") 1 else 0, monochrome)
    }
    ## determine main heading
    if(is.null(main)) {
      prefix <- if(opt$marks) NULL else
      if(opt$smooth) "Smoothed" else
      if(opt$xcumul) "Lurking variable plot for x coordinate\n" else 
      if(opt$ycumul) "Lurking variable plot for y coordinate\n" else
      if(opt$xmargin) "Lurking variable plot for x coordinate\n" else
      if(opt$ymargin) "Lurking variable plot for y coordinate\n" else NULL
      main <- paste(prefix, RES$typename)
    }
    ## ------------- residuals ---------------------------------
    if(opt$marks) {
      ## determine whether pre-plotting the window(s) is redundant
      redundant <- (plot.neg == "image") &&
                   (type != "eem") && (Yclip$window$type == "mask")
      ## pre-plot the window(s)
      if(redundant && !add) {
        z <- plot(as.rectangle(W), box=FALSE, main="",
                  do.plot=do.plot, ...)
      } else {
        if(!clip) 
          z <- plot(W, main="",
               add=add, show.all=show.all, do.plot=do.plot, ...)
        else
          z <- ploterodewin(W, Wclip, main="",
                       add=add, show.all=show.all, do.plot=do.plot, ...)
      }
      bb <- as.owin(z)

      switch(plot.neg,
             discrete={
               neg <- (Y$marks < 0)
               ## plot negative masses of discretised measure as squares
               if(any(c("maxsize", "markscale") %in% names(list(...)))) {
                 z <- plot(Y[neg], add=TRUE,
                          show.all=show.all, do.plot=do.plot, ...)
               } else {
                 hackmax <- 0.5 * sqrt(area(Wclip)/Yclip$n)
                 z <- plot(Y[neg], add=TRUE, maxsize=hackmax,
                           show.all=show.all, do.plot=do.plot, ...)
               }
               ## plot positive masses at atoms
               zp <- plot(Y[!neg], add=TRUE,
                          show.all=show.all, do.plot=do.plot, ...)
               bb <- boundingbox(bb, z, zp)
           },
           contour = {
             z <- contour(Ydens, add=TRUE, do.plot=do.plot, ...)
             bb <- boundingbox(bb, z)
           },
           imagecontour=,
           image={
             if(redundant) {
               z <- ploterodeimage(W, Ydens, rangeZ=srange, colsZ=backcols,
                                   add=add, show.all=show.all, main="", 
                                   do.plot=do.plot, ...)
             } else if(type != "eem") {
               z <- image(Ydens, col=backcols, zlim=srange, ribbon=FALSE,
                          add=TRUE, show.all=show.all, do.plot=do.plot,
                          main="", ...)
             }
             bb <- boundingbox(bb, z)
             if(plot.neg == "imagecontour") {
               z <- contour(Ydens, add=TRUE,
                            show.all=show.all, do.plot=do.plot, ...)
               bb <- boundingbox(bb, z)
             }
             ## decide whether mark scale should be shown
             showscale <- (type != "raw")
             ## plot positive masses at atoms
             z <- do.call("plot",
                          resolve.defaults(list(x=Ymass, add=TRUE),
                                           list(...),
                                           list(use.marks=showscale,
                                                do.plot=do.plot)))
             bb <- boundingbox(bb, z)
           }
           )
    if(do.plot && show.all) title(main=main)
  }
  # -------------  smooth -------------------------------------
  if(opt$smooth) {
    if(!clip) {
      switch(plot.smooth,
           image={
             z <- image(Z, main="", axes=FALSE, xlab="", ylab="",
                        col=backcols, zlim=srange, ribbon=FALSE,
                        do.plot=do.plot, add=add, show.all=show.all, ...)
             bb <- as.owin(z)
           },
           contour={
             z <- contour(Z, main="", axes=FALSE, xlab="", ylab="",
                        do.plot=do.plot, add=add, show.all=show.all, ...)
             bb <- as.owin(z)
           },
           persp={
             if(do.plot)
               persp(Z, main="", axes=FALSE, xlab="", ylab="", ...)
             bb <- NULL
           },
           imagecontour={
             z <- image(Z, main="", axes=FALSE, xlab="", ylab="",
                        col=backcols, zlim=srange, ribbon=FALSE,
                        do.plot=do.plot, add=add, show.all=show.all, ...)
             contour(Z, add=TRUE, do.plot=do.plot, ...)
             bb <- as.owin(z)
           }
             )
      if(do.plot && show.all) title(main=main)             
    } else {
      switch(plot.smooth,
             image={
               plot(as.rectangle(W), box=FALSE, main=main,
                    do.plot=do.plot, ...)
               z <- ploterodeimage(W, Z, colsZ=backcols, rangeZ=srange,
                                   do.plot=do.plot, ...)
               bb <- boundingbox(as.rectangle(W), z)
             },
             contour={
               plot(W, main=main,
                    do.plot=do.plot, add=add, show.all=show.all, ...)
               z <- contour(Z, add=TRUE,
                            show.all=show.all, do.plot=do.plot, ...)
               bb <- as.owin(z)
             },
             persp={
               if(do.plot) 
                 persp(Z, main=main, axes=FALSE, xlab="", ylab="", ...)
               bb <- NULL
             },
             imagecontour={
               plot(as.rectangle(W), box=FALSE, main=main,
                    do.plot=do.plot, ...)
               z <- ploterodeimage(W, Z, colsZ=backcols, rangeZ=srange,
                                   do.plot=do.plot, ...)
               contour(Z, add=TRUE, do.plot=do.plot, ...)
               bb <- as.owin(z)
             }
             )
    }
  }

  # ------------  cumulative x -----------------------------------------
  if(opt$xcumul) {
    a <- RES$xcumul
    obs <- a$empirical
    theo <- a$theoretical
    resid1panel(obs$covariate, obs$value,
               theo$covariate, theo$mean, theo$sd,
               "x coordinate", "cumulative mark", main=main,
                ...,
                do.plot=do.plot)
    bb <- NULL
  }
  
  # ------------  cumulative y -----------------------------------------
  if(opt$ycumul) {
    a <- RES$ycumul
    obs <- a$empirical
    theo <- a$theoretical
    resid1panel(obs$covariate, obs$value,
               theo$covariate, theo$mean, theo$sd,
               "y coordinate", "cumulative mark", main=main,
                ...,
                do.plot=do.plot)
    bb <- NULL
  }
  ## ------------  x margin -----------------------------------------
  if(opt$xmargin) {
    a <- RES$xmargin
    resid1panel(a$x, a$xZ, a$x, a$ExZ, NULL,
               "x coordinate", "marginal of residuals", main=main,
                ...,
                do.plot=do.plot)
    bb <- NULL
  }
  # ------------  y margin -----------------------------------------
  if(opt$ymargin) {
    a <- RES$ymargin
    resid1panel(a$y, a$yZ, a$y, a$EyZ, NULL,
               "y coordinate", "marginal of residuals", main=main,
                ...,
                do.plot=do.plot)
    bb <- NULL
  }

  attr(bb, "bbox") <- bb  
  return(invisible(bb))
}


resid1panel <- function(observedX, observedV,
                        theoreticalX, theoreticalV, theoreticalSD, xlab, ylab,
                        ..., do.plot=TRUE)
{
  if(!do.plot) return(NULL)
  ## work out plot range
  rX <- range(observedX, theoreticalX)
  rV <- range(c(0, observedV, theoreticalV))
  if(!is.null(theoreticalSD))
    rV <- range(c(rV, theoreticalV + 2*theoreticalSD,
                  theoreticalV - 2*theoreticalSD))
  ## argument handling
  do.lines <-
    function(x, y, defaulty=1, ...) {
      do.call("lines",
              resolve.defaults(list(x, y),
                               list(...),
                               list(lty=defaulty)))
    }
  ## start plot
  plot(rX, rV, type="n", xlab=xlab, ylab=ylab, ...)
  do.lines(observedX, observedV, 1, ...)
  do.lines(theoreticalX, theoreticalV, 2, ...)
  if(!is.null(theoreticalSD)) {
    do.lines(theoreticalX, theoreticalV + 2 * theoreticalSD, 3, ...)
    do.lines(theoreticalX, theoreticalV - 2 * theoreticalSD, 3, ...)
  }
}

#
#
ploterodewin <- function(W1, W2, col.edge=grey(0.75), col.inside=rgb(1,0,0),
                         do.plot=TRUE, ...) {
  ## internal use only
  ## W2 is assumed to be an erosion of W1
  switch(W1$type,
         rectangle={
           z <- plot(W1, ..., do.plot=do.plot)
           plot(W2, add=TRUE, lty=2, do.plot=do.plot)
         },
         polygonal={
           z <- plot(W1, ..., do.plot=do.plot)
           plot(W2, add=TRUE, lty=2, do.plot=do.plot)
         },
         mask={
           Z <- as.im(W1)
           x <- as.vector(rasterx.mask(W1))
           y <- as.vector(rastery.mask(W1))
           ok <- inside.owin(x, y, W2)
           Z$v[ok] <- 2
           z <- plot(Z, ..., col=c(col.edge, col.inside),
                     add=TRUE, ribbon=FALSE, do.plot=do.plot)
         }
         )
  return(z)
}

ploterodeimage <- function(W, Z, ..., Wcol=grey(0.75), rangeZ, colsZ,
                           do.plot=TRUE) {
  # Internal use only
  # Image Z is assumed to live on a subset of mask W
  # colsZ are the colours for the values in the range 'rangeZ'

  if(W$type != "mask" && do.plot) {
    plot(W, add=TRUE)
    W <- as.mask(W)
  }
  
  # Extend the colour map to include an extra colour for pixels in W
  # (1) Add the desired colour of W to the colour map
  pseudocols <- c(Wcol, colsZ)
  # (2) Breakpoints
  bks <- seq(from=rangeZ[1], to=rangeZ[2], length=length(colsZ)+1)
  dZ <- diff(bks)[1]
  pseudobreaks <- c(rangeZ[1] - dZ, bks)
  # (3) Determine a fake value for pixels in W
  Wvalue <- rangeZ[1] - dZ/2

  # Create composite image on W grid
  # (with W-pixels initialised to Wvalue)
  X <- as.im(Wvalue, W)
  # Look up Z-values of W-pixels
  xx <- as.vector(rasterx.mask(W))
  yy <- as.vector(rastery.mask(W))
  Zvalues <- lookup.im(Z, xx, yy, naok = TRUE, strict=FALSE)
  # Overwrite pixels in Z
  inZ <- !is.na(Zvalues)
  X$v[inZ] <- Zvalues[inZ]

  z <- image(X, ..., add=TRUE, ribbon=FALSE, 
             col=pseudocols, breaks=pseudobreaks,
             do.plot=do.plot)
  out <- list(X, pseudocols, pseudobreaks)
  attr(out, "bbox") <- as.owin(z)
  return(out)
}


  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/residppm.R"
#
#  residppm.R
#
# computes residuals for fitted point process model
#
#
# $Revision: 1.20 $ $Date: 2014/03/05 08:13:13 $
#

residuals.ppm <- function(object, type="raw", ..., check=TRUE, drop=FALSE,
                 fittedvalues = fitted.ppm(object, check=check, drop=drop),
                          new.coef=NULL, quad=NULL) {
  
  verifyclass(object, "ppm")
  trap.extra.arguments(..., .Context="In residuals.ppm")
  
  type <- pickoption("type", type,
                     c(inverse="inverse",
                       raw="raw",
                       pearson="pearson",
                       Pearson="pearson",
                       score="score"))
  typenames <- c(inverse="inverse-lambda residuals",
                 raw="raw residuals",
                 pearson="Pearson residuals",
                 score="score residuals")
  typename <- typenames[[type]]

  given.fitted <- !missing(fittedvalues) && !is.null(fittedvalues)

  # ................. determine fitted values .................
  
  if(is.null(new.coef) && is.null(quad)) {
    # use 'object' without modification
    # validate 'object'
    if(check && missing(fittedvalues) && damaged.ppm(object)) 
      stop("object format corrupted; try update(object, use.internal=TRUE)")
  } else {
    # determine a new set of model coefficients
    if(!is.null(new.coef)) {
      # use specified model parameters
      modelcoef <- new.coef
    } else {
      # estimate model parameters using a (presumably) denser set of dummy pts
      # Determine new quadrature scheme
      if(inherits(quad, "quad")) 
        hi.res.quad <- quad
      else if(is.ppp(quad))
        hi.res.quad <- quadscheme(data=data.ppm(object), dummy=quad)
      else {
        # assume 'quad' is a list of arguments to 'quadscheme'
        hi.res.quad <- do.call("quadscheme",
                               append(list(data.ppm(object)),
                                      quad))
      }
      # refit the model with new quadscheme
      hi.res.fit <- update(object, hi.res.quad)
      modelcoef <- coef(hi.res.fit)
    }
    # now compute fitted values using new coefficients
    if(!given.fitted) 
      fittedvalues <- fitted(object, drop=drop, new.coef=modelcoef)
  }

  # ..................... compute residuals .....................

  # Extract quadrature points and weights
  Q <- quad.ppm(object, drop=drop, clip=drop)
#  U <- union.quad(Q) # quadrature points
  Z <- is.data(Q) # indicator data/dummy
#  W <- w.quad(Q) # quadrature weights

  # Compute fitted conditional intensity at quadrature points
  lambda <- fittedvalues

  # indicator is 1 if lambda > 0
  # (adjusted for numerical behaviour of predict.glm)
  indicator <- (lambda > .Machine$double.eps)

  if(type == "score") {
    # need the covariates
    X <- model.matrix(object)
    if(drop) {
      gs <- getglmsubset(object)
      ok <- !is.na(gs) & gs
      X <- X[ok,]
    }
  }
      
  # Evaluate residual measure components

  discrete <- switch(type,
                     raw     = rep.int(1, sum(Z)), 
                     inverse = 1/lambda[Z],
                     pearson = 1/sqrt(lambda[Z]),
                     score   = X[Z, ]
                     )

  density <- switch(type,
                    raw     = -lambda,
                    inverse = -indicator,
                    pearson = -indicator * sqrt(lambda),
                    score   = -lambda * X)

  # Residual measure (return value)
  res <- msr(Q, discrete, density)

  # name the residuals
  attr(res, "type") <- type
  attr(res, "typename") <- typename

  return(res)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/residuals.mppm.R"
#
#  residuals.mppm.R
#
# computes residuals for fitted multiple point process model
#
#
#  $Revision: 1.4 $ $Date: 2013/11/11 14:47:19 $
#

residuals.mppm <- function(object, type="raw", ..., 
                          fittedvalues = fitted.mppm(object)) {
  
  verifyclass(object, "mppm")
  userfitted <- !missing(fittedvalues)
  type <- pickoption("type", type,
                     c(inverse="inverse",
                       raw="raw",
                       pearson="pearson",
                       Pearson="pearson"))
  typenames <- c(inverse="inverse-lambda residuals",
                 raw="raw residuals",
                 pearson="Pearson residuals")
  typename <- typenames[[type]]
  
  # Extract quadrature points and weights
  Q <- quad.mppm(object)
#  U <- lapply(Q, union.quad) # quadrature point patterns
  Z <- unlist(lapply(Q, is.data)) # indicator data/dummy
  W <- unlist(lapply(Q, w.quad)) # quadrature weights
  # total number of quadrature points
  nquadrature <- length(W)
  # number of quadrature points in each pattern
  nU <- unlist(lapply(Q, n.quad))
  # number of rows of hyperframe
  npat <- object$npat
  # attribution of each quadrature point
  id <- factor(rep(1:npat, nU), levels=1:npat)
  
  # Compute fitted conditional intensity at quadrature points

  if(!is.list(fittedvalues) || length(fittedvalues) != npat)
    stop(paste(sQuote("fittedvalues"), "should be a list of length",
               npat, "containing vectors of fitted values"))
  
  lambda <- unlist(fittedvalues)

  # consistency check
  if(length(lambda) != nquadrature)
    stop(paste(if(!userfitted) "internal error:" else NULL,
               "number of fitted values", paren(length(lambda)),
               "does not match number of quadrature points",
               paren(nquadrature)))

  # indicator is 1 if lambda > 0
  # (adjusted for numerical behaviour of predict.glm)
  indicator <- (lambda > .Machine$double.eps)

  # Evaluate residual measure components
  discrete <- ifelse(Z,
                     switch(type,
                            raw     = 1,
                            inverse = 1/lambda,
                            pearson = 1/sqrt(lambda)
                            ),
                     0)

  density <- switch(type,
                    raw     = -lambda,
                    inverse = -indicator,
                    pearson = -indicator * sqrt(lambda))

  atoms <- as.logical(Z)
  
  # All components
  resdf <- data.frame(discrete=discrete,
                      density=density,
                      atoms=atoms)

  # Split residual data according to point pattern affiliation
  splitres <- split(resdf, id)
  # Associate with quadrature scheme
  reshf <- hyperframe(R=splitres, Q=Q)
  # Convert to signed measures
  answer <- with(reshf, msr(Q, R$discrete[R$atoms], R$density))
  # tag
  answer <- lapply(answer, "attr<-", which="type", value=type)
  answer <- lapply(answer, "attr<-", which="typename", value=typename)
  return(as.listof(answer))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/resolve.defaults.R"
#
#   resolve.defaults.R
#
#  $Revision: 1.22 $ $Date: 2014/12/14 01:50:04 $
#
# Resolve conflicts between several sets of defaults
# Usage:
#     resolve.defaults(list1, list2, list3, .......)
# where the earlier lists have priority 
#

resolve.defaults <- function(..., .MatchNull=TRUE, .StripNull=FALSE) {
  # Each argument is a list. Append them.
  argue <- c(...)
  # is NULL a possible value?
  if(!.MatchNull) {
    isnul <- unlist(lapply(argue, is.null))
    argue <- argue[!isnul]
  }
  if(!is.null(nam <- names(argue))) {
    named <- nzchar(nam)
    arg.unnamed <- argue[!named]
    arg.named <-   argue[named]
    if(any(discard <- duplicated(names(arg.named)))) 
      arg.named <- arg.named[!discard]
    argue <- append(arg.unnamed, arg.named)
  }
  # should NULL become a missing argument?
  if(.StripNull) {
    isnull <- sapply(argue, is.null)
    argue <- argue[!isnull]
  }
  return(argue)
}

do.call.without <- function(fun, ..., avoid) {
  argh <- list(...)
  nama <- names(argh)
  if(!is.null(nama))
    argh <- argh[!(nama %in% avoid)]
  do.call(fun, argh)
}

do.call.matched <- function(fun, arglist, funargs,
                            extrargs=NULL,
                            matchfirst=FALSE,
                            sieve=FALSE,
                            skipargs=NULL) {
  if(!is.function(fun) && !is.character(fun))
    stop("Internal error: wrong argument type in do.call.matched")
  if(is.character(fun)) {
    fname <- fun
    fun <- get(fname, mode="function")
    if(!is.function(fun))
      stop(paste("internal error: function", sQuote(fname), "not found",
                 sep=""))
  }
  ## determine list of argument names to be matched
  if(missing(funargs))
    funargs <- names(formals(fun))
  funargs <- c(funargs, extrargs)
  funargs <- setdiff(funargs, skipargs)
  ## identify which arguments in the call actually match a formal argument
  givenargs <- names(arglist)
  matched <- givenargs %in% funargs
  # deem the first argument to be matched?
  if(matchfirst && !nzchar(givenargs[1]))
    matched[1] <- TRUE
  # apply 'fun' to matched arguments
  out <- do.call(fun, arglist[matched])
  # retain un-matched arguments?
  if(sieve)
    out <- list(result=out, otherargs=arglist[!matched])
  return(out)
}

## This function traps the colour arguments
## and converts to greyscale if required.

do.call.plotfun <- function(fun, arglist, ...) {
  if(spatstat.options("monochrome")) {
    keys <- names(arglist)
    if(!is.null(keys)) {
      cols <- nzchar(keys) & ((keys %in% c("border", "col", "fg", "bg")) |
                              (substr(keys, 1, 4) == "col."))
      if(any(cols))
        arglist[cols] <- lapply(arglist[cols], to.grey)
    }
  }
  do.call.matched(fun, arglist, ...)
}


resolve.1.default <- function(.A, ...) {
  if(is.character(.A)) {
    ## .A is the name of the parameter to be returned
    Aname <- .A
    res <- resolve.defaults(...)
  } else if(is.list(.A) && length(.A) == 1) {
    ## .A is a list giving the name and default value of the parameter
    Aname <- names(.A)
    res <- resolve.defaults(..., .A)
  } else stop("Unrecognised format for .A")
  hit <- (names(res) == Aname)
  if(!any(hit)) return(NULL)
  return(res[[min(which(hit))]])
}

# extract all the arguments that match '...' rather than a named argument

passthrough <- function(.Fun, ..., .Fname=NULL) {
  if(is.null(.Fname))
    .Fname <- deparse(substitute(.Fun))
  # make a fake call to the named function using the arguments provided
  cl <- eval(substitute(call(.Fname, ...)))
  # match the call to the function 
  mc <- match.call(.Fun, cl)
  # extract the arguments
  mcargs <- as.list(mc)[-1]
  # figure out which ones are actually formal arguments of the function
  nam <- names(formals(.Fun))
  nam <- setdiff(nam, "...")
  known <- names(mcargs) %in% nam
  # return the *other* arguments
  return(mcargs[!known])
}

graphicsPars <- local({
  ## recognised additional arguments to image.default(), axis() etc
    PlotArgs <- c(
        "main", "asp", "sub", "axes", "ann",
        "cex", "font", 
        "cex.axis", "cex.lab", "cex.main", "cex.sub",
        "col.axis", "col.lab", "col.main", "col.sub",
        "font.axis", "font.lab", "font.main", "font.sub")
    
  TheTable <- 
    list(plot = PlotArgs,
         image = c(
           "main", "asp", "sub", "axes", "ann",
           "box", 
           "cex", "font", 
           "cex.axis", "cex.lab", "cex.main", "cex.sub",
           "col.axis", "col.lab", "col.main", "col.sub",
           "font.axis", "font.lab", "font.main", "font.sub"),
         axis = c(
           "cex", 
           "cex.axis", "cex.lab",
           "col.axis", "col.lab",
           "font.axis", "font.lab",
           "mgp", "xaxp", "yaxp", "tck", "tcl", "las", "fg", "xpd"),
         owin = c(
           "sub",
           "cex", "font", "col",
           "border", "box", 
           "cex.main", "cex.sub",
           "col.main", "col.sub",
           "font.main", "font.sub",
           "xaxs", "yaxs"),
         lines = c("lwd", "lty", "col", "lend", "ljoin", "lmitre"),
         symbols = c(PlotArgs, "fg", "bg")
         )

    TheTable$ppp <- unique(c(TheTable$owin,
                             TheTable$symbols,
                             "pch", "cex", "lty", "lwd",
                             "etch"))

  graphicsPars <- function(key) {
    n <- pmatch(key, names(TheTable))
    if(is.na(n)) return(NULL)
    return(TheTable[[n]])
  }

  graphicsPars
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rho2hat.R"
#
#   rho2hat.R
#
#   Relative risk for pairs of covariate values
#
#   $Revision: 1.19 $   $Date: 2014/11/11 02:43:31 $
#

rho2hat <- function(object, cov1, cov2, ..., method=c("ratio", "reweight")) {
  cov1name <- short.deparse(substitute(cov1))
  cov2name <- short.deparse(substitute(cov2))
  callstring <- short.deparse(sys.call())
  method <- match.arg(method)
  # validate model
  if(is.ppp(object) || inherits(object, "quad")) {
    model <- ppm(object, ~1, forcefit=TRUE)
    reference <- "area"
    modelcall <- NULL
  } else if(is.ppm(object)) {
    model <- object
    reference <- "model"
    modelcall <- model$call
    if(is.null(getglmfit(model)))
      model <- update(model, forcefit=TRUE)
  } else stop("object should be a point pattern or a point process model")

  # interpret string "x" or "y" as a coordinate function
  getxyfun <- function(s) {
    switch(s,
           x = { function(x,y) { x } },
           y = { function(x,y) { y } },
           stop(paste("Unrecognised covariate name", sQuote(s))))
  }
  if(is.character(cov1) && length(cov1) == 1) {
    cov1name <- cov1
    cov1 <- getxyfun(cov1name)
  }
  if(is.character(cov2) && length(cov2) == 1) {
    cov2name <- cov2
    cov2 <- getxyfun(cov2name)
  }
  if(   (cov1name == "x" && cov2name == "y")
     || (cov1name == "y" && cov2name == "x")) {
    # spatial relative risk
    isxy <- TRUE
    needflip <- (cov1name == "y" && cov2name == "x")
    X <- data.ppm(model)
    if(needflip) X <- flipxy(X)
    switch(method,
           ratio = {
             # ratio of smoothed intensity estimates
             den <- density(X, ...)
             sigma <- attr(den, "sigma")
             varcov <- attr(den, "varcov")
             W <- as.owin(den)
             rslt <- switch(reference,
                            area = { den },
                            model = {
                              lam <- predict(model, locations=W)
                              if(needflip) lam <- flipxy(lam)
                              lam <- blur(lam, sigma=sigma, varcov=varcov,
                                          normalise=TRUE)
                              eval.im(den/lam)
                            })
           },
           reweight = {
             # smoothed point pattern with weights = 1/reference
             W <- do.call.matched("as.mask",
                                  append(list(w=as.owin(X)), list(...)))
             gstarX <- switch(reference,
                              area = {
                                rep.int(area(W), npoints(X))
                              },
                              model = {
                                lam <- predict(model, locations=W)
                                if(needflip) lam <- flipxy(lam)
                                lam[X]
                              })
             rslt <- density(X, ..., weights=1/gstarX)
             sigma <- attr(rslt, "sigma")
             varcov <- attr(rslt, "varcov")
           })
    Z12points <- X
    r1 <- W$xrange
    r2 <- W$yrange
  } else {
    # general case
    isxy <- FALSE
    # harmonise covariates 
    if(is.function(cov1) && is.im(cov2)) {
      cov1 <- as.im(cov1, W=cov2)
    } else if(is.im(cov1) && is.function(cov2)) {
      cov2 <- as.im(cov2, W=cov1)
    }
    # evaluate each covariate at data points and at pixels
    stuff1 <- evalCovar(model, cov1)
    stuff2 <- evalCovar(model, cov2)
    # unpack
    values1 <- stuff1$values
    values2 <- stuff2$values
    # covariate values at each data point
    Z1X      <- values1$ZX
    Z2X      <- values2$ZX
    # covariate values at each pixel
    Z1values <- values1$Zvalues
    Z2values <- values2$Zvalues
    # model intensity
    lambda  <- values1$lambda
    # ranges of each covariate
    r1 <- range(Z1X, Z1values, finite=TRUE)
    r2 <- range(Z2X, Z2values, finite=TRUE)
    scal <- function(x, r) { (x - r[1])/diff(r) }
    # scatterplot coordinates
    Z12points <- ppp(scal(Z1X, r1), scal(Z2X, r2), c(0,1), c(0,1))
    Z12pixels <- ppp(scal(Z1values, r1), scal(Z2values, r2), c(0,1), c(0,1))
    # normalising constants
#    nX   <- length(Z1X)
    npixel <- length(lambda)
    areaW <- area(Window(model))
    pixelarea <- areaW/npixel
    baseline <- if(reference == "area") rep.int(1, npixel) else lambda
    wts <- baseline * pixelarea
    switch(method,
           ratio = {
             # estimate intensities
             fhat <- density(Z12points, ...)
             sigma <- attr(fhat, "sigma")
             varcov <- attr(fhat, "varcov")
             ghat <- do.call("density.ppp",
                             resolve.defaults(list(Z12pixels, weights=wts),
                                              list(...),
                                              list(sigma=sigma,
                                                   varcov=varcov)))
             # compute ratio of smoothed densities
             rslt <- eval.im(fhat/ghat)
           },
           reweight = {
             # compute smoothed intensity with weight = 1/reference
             ghat <- density(Z12pixels, weights=wts, ...)
             rslt <- density(Z12points, weights=1/ghat[Z12points], ...)
             sigma <- attr(rslt, "sigma")
             varcov <- attr(rslt, "varcov")
           })
  }
  # add scale and label info
  attr(rslt, "stuff") <- list(isxy=isxy,
                              cov1name=cov1name,
                              cov2name=cov2name,
                              r1=r1,
                              r2=r2,
                              reference=reference,
                              modelcall=modelcall,
                              callstring=callstring,
                              Z12points=Z12points,
                              sigma=sigma,
                              varcov=varcov)
  class(rslt) <- c("rho2hat", class(rslt))
  rslt
}

plot.rho2hat <- function(x, ..., do.points=FALSE) {
  xname <- short.deparse(substitute(x))
  s <- attr(x, "stuff")
  # resolve "..." arguments
  rd <- resolve.defaults(list(...),
                         list(add=FALSE, axes=!s$isxy,
                              xlab=s$cov1name, ylab=s$cov2name))
  # plot image
  plotparams <- graphicsPars("plot")
  do.call.matched("plot.im",
                  resolve.defaults(list(x=x, axes=FALSE),
                                   list(...), list(main=xname)),
                  extrargs=c(plotparams, "add", "zlim", "breaks"))
  # add axes 
  if(rd$axes) {
    axisparams <- graphicsPars("axis")
    Axis <- function(..., extrargs=axisparams) {
      do.call.matched("axis", resolve.defaults(list(...)), extrargs=extrargs)
    }
    if(s$isxy) {
      # for (x,y) plots the image is at the correct physical scale
      xr <- x$xrange
      yr <- x$yrange
      spak <- 0.05 * max(diff(xr), diff(yr))
      Axis(side=1, ..., at=pretty(xr), pos=yr[1] - spak)
      Axis(side=2, ..., at=pretty(yr), pos=xr[1] - spak)
    } else {
      # for other plots the image was scaled to the unit square
      rx <- s$r1
      ry <- s$r2
      px <- pretty(rx)
      py <- pretty(ry)
      Axis(side=1, labels=px, at=(px - rx[1])/diff(rx), ...)
      Axis(side=2, labels=py, at=(py - ry[1])/diff(ry), ...)
    }
    title(xlab=rd$xlab)
    title(ylab=rd$ylab)
  }
  if(do.points) {
    do.call.matched("plot.ppp",
                    resolve.defaults(list(x=s$Z12points, add=TRUE),
                                     list(...)),
                    extrargs=c("pch", "col", "cols", "bg", "cex", "lwd", "lty"))
  }
  invisible(NULL)
}

print.rho2hat <- function(x, ...) {
  s <- attr(x, "stuff")
  cat("Scatterplot intensity estimate (class rho2hat)\n")
  cat(paste("for the covariates", s$cov1name, "and", s$cov2name, "\n"))
  switch(s$reference,
         area=cat("Function values are absolute intensities\n"),
         model={
           cat("Function values are relative to fitted model\n")
           print(s$modelcall)
         })
  cat(paste("Call:", s$callstring, "\n"))
  if(s$isxy) {
    cat("Obtained by spatial smoothing of original data\n")
    cat("Smoothing parameters used by density.ppp:\n")
  } else {
    cat("Obtained by transforming to the unit square and smoothing\n")
    cat("Smoothing parameters (on unit square) used by density.ppp:\n")
  }
  if(!is.null(s$sigma)) cat(paste("\tsigma = ", signif(s$sigma, 5), "\n"))
  if(!is.null(s$varcov)) { cat("\tvarcov =\n") ; print(s$varcov) }
  cat("Intensity values:\n")
  NextMethod("print")
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rhohat.R"
#
#  rhohat.R
#
#  $Revision: 1.61 $  $Date: 2014/11/10 11:18:05 $
#
#  Non-parametric estimation of a transformation rho(z) determining
#  the intensity function lambda(u) of a point process in terms of a
#  spatial covariate Z(u) through lambda(u) = rho(Z(u)).
#  More generally allows offsets etc.

rhohat <- function(object, covariate, ...) {
  UseMethod("rhohat")
}

rhohat.ppp <- rhohat.quad <- 
  function(object, covariate, ...,
           baseline=NULL, weights=NULL,
           method=c("ratio", "reweight", "transform"),
           horvitz=FALSE,
           smoother=c("kernel", "local"),
           dimyx=NULL, eps=NULL,
           n=512, bw="nrd0", adjust=1, from=NULL, to=NULL, 
           bwref=bw, covname, confidence=0.95) {
  callstring <- short.deparse(sys.call())
  smoother <- match.arg(smoother)
  method <- match.arg(method)
  if(missing(covname)) 
    covname <- sensiblevarname(short.deparse(substitute(covariate)), "X")
  if(is.null(adjust))
    adjust <- 1
  # validate model
  if(is.null(baseline)) {
    model <- ppm(object ~1)
    reference <- "Lebesgue"
  } else {
    model <- ppm(object ~ offset(log(baseline)))
    reference <- "baseline"
  } 
  modelcall <- NULL

  if(is.character(covariate) && length(covariate) == 1) {
    covname <- covariate
    switch(covname,
           x={
             covariate <- function(x,y) { x }
           }, 
           y={
             covariate <- function(x,y) { y }
           },
           stop("Unrecognised covariate name")
         )
    covunits <- unitname(data.ppm(model))
  } else {
    covunits <- NULL
  }

  areaW <- area(Window(data.ppm(model)))
  
  rhohatEngine(model, covariate, reference, areaW, ...,
               weights=weights,
               method=method,
               horvitz=horvitz,
               smoother=smoother,
               resolution=list(dimyx=dimyx, eps=eps),
               n=n, bw=bw, adjust=adjust, from=from, to=to,
               bwref=bwref, covname=covname, covunits=covunits,
               confidence=confidence,
               modelcall=modelcall, callstring=callstring)
}

rhohat.ppm <- function(object, covariate, ...,
                       weights=NULL,
                       method=c("ratio", "reweight", "transform"),
                       horvitz=FALSE,
                       smoother=c("kernel", "local"),
                       dimyx=NULL, eps=NULL,
                       n=512, bw="nrd0", adjust=1, from=NULL, to=NULL, 
                       bwref=bw, covname, confidence=0.95) {
  callstring <- short.deparse(sys.call())
  smoother <- match.arg(smoother)
  method <- match.arg(method)
  if(missing(covname)) 
    covname <- sensiblevarname(short.deparse(substitute(covariate)), "X")
  if(is.null(adjust))
    adjust <- 1

  if("baseline" %in% names(list(...)))
    warning("Argument 'baseline' ignored: not available for rhohat.ppm")

  ## validate model
  model <- object
  reference <- "model"
  modelcall <- model$call

  if(is.character(covariate) && length(covariate) == 1) {
    covname <- covariate
    switch(covname,
           x={
             covariate <- function(x,y) { x }
           }, 
           y={
             covariate <- function(x,y) { y }
           },
           stop("Unrecognised covariate name")
         )
    covunits <- unitname(data.ppm(model))
  } else {
    covunits <- NULL
  }

  areaW <- area(Window(data.ppm(model)))
  
  rhohatEngine(model, covariate, reference, areaW, ...,
               weights=weights,
               method=method,
               horvitz=horvitz,
               smoother=smoother,
               resolution=list(dimyx=dimyx, eps=eps),
               n=n, bw=bw, adjust=adjust, from=from, to=to,
               bwref=bwref, covname=covname, covunits=covunits,
               confidence=confidence,
               modelcall=modelcall, callstring=callstring)
}

rhohat.lpp <- rhohat.lppm <- 
  function(object, covariate, ...,
           weights=NULL,
           method=c("ratio", "reweight", "transform"),
           horvitz=FALSE,
           smoother=c("kernel", "local"),
           nd=1000, eps=NULL,
           n=512, bw="nrd0", adjust=1, from=NULL, to=NULL, 
           bwref=bw, covname, confidence=0.95) {
  callstring <- short.deparse(sys.call())
  smoother <- match.arg(smoother)
  method <- match.arg(method)
  if(missing(covname)) 
    covname <- sensiblevarname(short.deparse(substitute(covariate)), "X")
  if(is.null(adjust))
    adjust <- 1
  # validate model
  if(is.lpp(object)) {
    X <- object
    model <- lppm(object, ~1)
    reference <- "Lebesgue"
    modelcall <- NULL
  } else if(inherits(object, "lppm")) {
    model <- object
    X <- model$X
    reference <- "model"
    modelcall <- model$call
  } else stop("object should be of class lpp or lppm")
  
  if("baseline" %in% names(list(...)))
    warning("Argument 'baseline' ignored: not available for ",
            if(is.lpp(object)) "rhohat.lpp" else "rhohat.lppm")

  if(is.character(covariate) && length(covariate) == 1) {
    covname <- covariate
    switch(covname,
           x={
             covariate <- function(x,y) { x }
           }, 
           y={
             covariate <- function(x,y) { y }
           },
           stop("Unrecognised covariate name")
         )
    covunits <- unitname(X)
  } else {
    covunits <- NULL
  }

  totlen <- sum(lengths.psp(as.psp(as.linnet(X))))
  
  rhohatEngine(model, covariate, reference, totlen, ...,
               weights=weights,
               method=method,
               horvitz=horvitz,
               smoother=smoother,
               resolution=list(nd=nd, eps=eps),
               n=n, bw=bw, adjust=adjust, from=from, to=to,
               bwref=bwref, covname=covname, covunits=covunits,
               confidence=confidence,
               modelcall=modelcall, callstring=callstring)
}

rhohatEngine <- function(model, covariate,
                         reference=c("Lebesgue", "model", "baseline"),
                         volume,
                         ...,
                         weights=NULL,
                         method=c("ratio", "reweight", "transform"),
                         horvitz=FALSE,
                         smoother=c("kernel", "local"),
                         resolution=list(), 
                         n=512, bw="nrd0", adjust=1, from=NULL, to=NULL, 
                         bwref=bw, covname, covunits=NULL, confidence=0.95,
                         modelcall=NULL, callstring="rhohat") {
  reference <- match.arg(reference)
  # evaluate the covariate at data points and at pixels
  stuff <- do.call("evalCovar",
                   append(list(model, covariate), resolution))
  # unpack
#  info   <- stuff$info
  values <- stuff$values
  # values at each data point
  ZX      <- values$ZX
  lambdaX <- if(horvitz) fitted(model, dataonly=TRUE) else NULL
  # values at each pixel
  Zimage  <- values$Zimage
  Zvalues <- values$Zvalues
  lambda  <- values$lambda
  ## weights
  if(!is.null(weights)) {
    X <- data.ppm(model)
    if(is.im(weights)) 
      weights <- safelookup(weights, X)
    else if(is.function(weights))
      weights <- weights(X$x, X$y)
    else if(is.numeric(weights) && is.vector(as.numeric(weights))) 
      check.nvector(weights, npoints(X))
    else stop(paste(sQuote("weights"),
                    "should be a vector, a pixel image, or a function"))
  }
  # normalising constants
  denom <- volume * (if(reference == "Lebesgue" || horvitz) 1 else mean(lambda))
  # info 
  savestuff <- list(reference  = reference,
                    horvitz    = horvitz,
                    Zimage     = Zimage)
  # calculate rho-hat
  result <- rhohatCalc(ZX, Zvalues, lambda, denom,
                       ...,
                       weights=weights,
                       lambdaX=lambdaX,
                       method=method,
                       horvitz=horvitz,
                       smoother=smoother,
                       n=n, bw=bw, adjust=adjust, from=from, to=to,
                       bwref=bwref, covname=covname, confidence=confidence,
                       covunits=covunits,
                       modelcall=modelcall, callstring=callstring,
                       savestuff=savestuff)
  return(result)
}


# basic calculation of rhohat from covariate values

rhohatCalc <- local({
  
  interpolate <- function(x,y) {
    if(inherits(x, "density") && missing(y))
      approxfun(x$x, x$y, rule=2)
    else 
      approxfun(x, y, rule=2)
  }

  ## note: this function normalises the weights, like density.default
  LocfitRaw <- function(x, ..., weights=NULL) {
    if(is.null(weights)) weights <- 1
    do.call.matched("locfit.raw", append(list(x=x, weights=weights), list(...)))
  }

  varlog <- function(obj,xx) {
    ## variance of log f-hat
    stopifnot(inherits(obj, "locfit"))
    if(!identical(obj$trans, exp))
      stop("internal error: locfit object does not have log link")
    ## the following call should have band="local" but that produces NaN's
    pred <- predict(obj, newdata=xx,
                    se.fit=TRUE, what="coef")
    se <- pred$se.fit
    return(se^2)
  }

  rhohatCalc <- function(ZX, Zvalues, lambda, denom, ...,
                         weights=NULL, lambdaX=NULL,
                         method=c("ratio", "reweight", "transform"),
                         horvitz=FALSE, 
                         smoother=c("kernel", "local"),
                         n=512, bw="nrd0", adjust=1, from=NULL, to=NULL, 
                         bwref=bw, covname, confidence=0.95,
                         covunits = NULL, modelcall=NULL, callstring=NULL,
                         savestuff=list()) {
    method <- match.arg(method)
    smoother <- match.arg(smoother)
    ## check availability of locfit package
    if(smoother == "local" && !require(locfit, quietly=TRUE)) {
      warning(paste("In", paste(dQuote(callstring), ":", sep=""),
                    "package", sQuote("locfit"), "is not available;",
                    "unable to perform local likelihood smoothing;",
                    "using kernel smoothing instead"),
              call.=FALSE)
      smoother <- "kernel"
    }
    ## validate
    stopifnot(is.numeric(ZX))
    stopifnot(is.numeric(Zvalues))
    stopifnot(is.numeric(lambda))
    stopifnot(length(lambda) == length(Zvalues))
    stopifnot(all(is.finite(lambda))) 
    check.1.real(denom)
    ## 
    if(horvitz) {
      ## data points will be weighted by reciprocal of model intensity
      weights <- (weights %orifnull% 1)/lambdaX
    }
    ## normalising constants
    nX   <- if(is.null(weights)) length(ZX) else sum(weights)
    kappahat <- nX/denom
    ## limits
    Zrange <- range(ZX, Zvalues)
    if(is.null(from)) from <- Zrange[1] 
    if(is.null(to))   to   <- Zrange[2]
    if(from > Zrange[1] || to < Zrange[2])
      stop("Interval [from, to] = ", prange(c(from,to)), 
           "does not contain the range of data values =", prange(Zrange))
    ## critical constant for CI's
    crit <- qnorm((1+confidence)/2)
    percentage <- paste(round(100 * confidence), "%%", sep="")
    CIblurb <- paste("pointwise", percentage, "confidence interval")
    ## estimate densities   
    if(smoother == "kernel") {
      ## ............... kernel smoothing ......................
      ## reference density (normalised) for calculation
      ghat <- density(Zvalues,weights=if(horvitz) NULL else lambda/sum(lambda),
                      bw=bwref,adjust=adjust,n=n,from=from,to=to, ...)
      xxx <- ghat$x
      ghatfun <- interpolate(ghat)
      ## relative density
      switch(method,
             ratio={
               ## compute ratio of smoothed densities
               fhat <- unnormdensity(ZX,weights=weights,
                                     bw=bw,adjust=adjust,
                                     n=n,from=from, to=to, ...)
               fhatfun <- interpolate(fhat)
               Ghat.xxx <- denom * ghatfun(xxx)
               yyy <- fhatfun(xxx)/Ghat.xxx
               ## compute variance approximation
               sigma <- fhat$bw
               weights2 <- if(is.null(weights)) NULL else weights^2
               fstar <- unnormdensity(ZX,weights=weights2,
                                      bw=bw,adjust=adjust/sqrt(2),
                                      n=n,from=from, to=to, ...)
               fstarfun <- interpolate(fstar)
               const <- 1/(2 * sigma * sqrt(pi))
               vvv  <- const * fstarfun(xxx)/Ghat.xxx^2
             },
             reweight={
               ## weight Z values by reciprocal of reference
               wt <- (weights %orifnull% 1)/(denom * ghatfun(ZX))
               rhat <- unnormdensity(ZX, weights=wt, bw=bw,adjust=adjust,
                                     n=n,from=from, to=to, ...)
               rhatfun <- interpolate(rhat)
               yyy <- rhatfun(xxx)
               ## compute variance approximation
               sigma <- rhat$bw
               rongstar <- unnormdensity(ZX, weights=wt^2,
                                         bw=bw,adjust=adjust/sqrt(2),
                                         n=n,from=from, to=to, ...)
               rongstarfun <- interpolate(rongstar)
               const <- 1/(2 * sigma * sqrt(pi))
               vvv  <- const * rongstarfun(xxx)
             },
             transform={
               ## probability integral transform
               Gfun <- interpolate(ghat$x, cumsum(ghat$y)/sum(ghat$y))
               GZX <- Gfun(ZX)
               ## smooth density on [0,1]
               qhat <- unnormdensity(GZX,weights=weights,
                                     bw=bw,adjust=adjust,
                                     n=n, from=0, to=1, ...)
               qhatfun <- interpolate(qhat)
               ## edge effect correction
               one <- density(seq(from=0,to=1,length.out=512),
                              bw=qhat$bw, adjust=1,
                              n=n,from=0, to=1, ...)
               onefun <- interpolate(one)
               ## apply to transformed values
               Gxxx <- Gfun(xxx)
               Dxxx <- denom * onefun(Gxxx)
               yyy <- qhatfun(Gxxx)/Dxxx
               ## compute variance approximation
               sigma <- qhat$bw
               weights2 <- if(is.null(weights)) NULL else weights^2
               qstar <- unnormdensity(GZX,weights=weights2,
                                      bw=bw,adjust=adjust/sqrt(2),
                                      n=n,from=0, to=1, ...)
               qstarfun <- interpolate(qstar)
               const <- 1/(2 * sigma * sqrt(pi))
               vvv  <- const * qstarfun(Gxxx)/Dxxx^2
             })
      vvvname <- "Variance of estimator"
      vvvlabel <- paste("bold(Var)~hat(%s)", paren(covname), sep="")
      sd <- sqrt(vvv)
      hi <- yyy + crit * sd
      lo <- yyy - crit * sd
    } else {
      ## .................. local likelihood smoothing .......................
      xlim <- c(from, to)
      xxx <- seq(from, to, length=n)
      ## reference density
      ghat <- LocfitRaw(Zvalues,
                        weights=if(horvitz) NULL else lambda,
                        xlim=xlim, ...)
      ggg <- predict(ghat, xxx)
      ## relative density
      switch(method,
             ratio={
               ## compute ratio of smoothed densities
               fhat <- LocfitRaw(ZX, weights=weights, xlim=xlim, ...)
               fff <- predict(fhat, xxx)
               yyy <- kappahat * fff/ggg
               ## compute approximation to variance of log rho-hat
               varlogN <- 1/nX
               vvv <- varlog(fhat, xxx) + varlogN
             },
             reweight={
               ## weight Z values by reciprocal of reference
               wt <- (weights %orifnull% 1)/(denom * predict(ghat,ZX))
               sumwt <- sum(wt)
               rhat <- LocfitRaw(ZX, weights=wt, xlim=xlim, ...)
               rrr <- predict(rhat, xxx)
               yyy <- sumwt * rrr
               ## compute approximation to variance of log rho-hat
               varsumwt <- mean(yyy /(denom * ggg)) * diff(xlim)
               varlogsumwt <- varsumwt/sumwt^2
               vvv <- varlog(rhat, xxx) + varlogsumwt
             },
             transform={
               ## probability integral transform
               Gfun <- approxfun(xxx, cumsum(ggg)/sum(ggg), rule=2)
               GZX <- Gfun(ZX)
               ## smooth density on [0,1], end effect corrected
               qhat <- LocfitRaw(GZX, weights=weights, xlim=c(0,1), ...)
               ## apply to transformed values
               Gxxx <- Gfun(xxx)
               qqq <- predict(qhat, Gxxx)
               yyy <- kappahat * qqq
               ## compute approximation to variance of log rho-hat
               varlogN <- 1/nX
               vvv <- varlog(qhat, Gxxx) + varlogN
             })
      vvvname <- "Variance of log of estimator"
      vvvlabel <- paste("bold(Var)~log(hat(%s)", paren(covname), ")", sep="")
      sss <- exp(crit * sqrt(vvv))
      hi <- yyy * sss
      lo <- yyy / sss
    }
    ## pack into fv object
    df <- data.frame(xxx=xxx, rho=yyy, var=vvv, hi=hi, lo=lo)
    names(df)[1] <- covname
    desc <- c(paste("covariate", covname),
              "Estimated intensity",
              vvvname,
              paste("Upper limit of", CIblurb),
              paste("Lower limit of", CIblurb))
    rslt <- fv(df,
               argu=covname,
               ylab=substitute(rho(X), list(X=as.name(covname))),
               valu="rho",
               fmla= as.formula(paste(". ~ ", covname)),
               alim=range(ZX),
               labl=c(covname,
                 paste("hat(%s)", paren(covname), sep=""),
                 vvvlabel,
                 paste("%s[hi]", paren(covname), sep=""),
                 paste("%s[lo]", paren(covname), sep="")),
               desc=desc,
               unitname=covunits,
               fname="rho",
               yexp=substitute(rho(X), list(X=as.name(covname))))
    attr(rslt, "dotnames") <- c("rho", "hi", "lo")
    ## pack up
    class(rslt) <- c("rhohat", class(rslt))
    ## add info
    stuff <- 
      list(modelcall  = modelcall, 
           callstring = callstring,
           sigma      = switch(smoother, kernel=sigma, local=NULL),
           covname    = paste(covname, collapse=""),
           ZX         = ZX,
           lambda     = lambda,
           method     = method,
           smoother   = smoother)
    attr(rslt, "stuff") <- append(stuff, savestuff)
    return(rslt)
  }
  
  rhohatCalc
})

## ........... end of 'rhohatCalc' .................................


print.rhohat <- function(x, ...) {
  s <- attr(x, "stuff")
  splat("Intensity function estimate (class rhohat)",
        "for the covariate", s$covname)
  switch(s$reference,
         Lebesgue=splat("Function values are absolute intensities"),
         baseline=splat("Function values are relative to baseline"),
         model={
           splat("Function values are relative to fitted model")
           print(s$modelcall)
         })
  cat("Estimation method: ")
  switch(s$method,
         ratio={
           splat("ratio of fixed-bandwidth kernel smoothers")
         },
         reweight={
           splat("fixed-bandwidth kernel smoother of weighted data")
         },
         transform={
           splat("probability integral transform,",
                 "edge-corrected fixed bandwidth kernel smoothing",
                 "on [0,1]")
         },
         cat("UNKNOWN\n"))
  if(identical(s$horvitz, TRUE))
    splat("\twith Horvitz-Thompson weight")
  cat("Smoother: ")
  switch(s$smoother,
         kernel={
           splat("Kernel density estimator")
           splat("Actual smoothing bandwidth sigma = ",
                 signif(s$sigma,5))
         },
         local ={ splat("Local likelihood density estimator") }
         )
  splat("Call:", s$callstring)

  NextMethod("print")
}

plot.rhohat <- function(x, ..., do.rug=TRUE) {
  xname <- short.deparse(substitute(x))
  s <- attr(x, "stuff")
  covname <- s$covname
  asked.rug <- !missing(do.rug) && identical(rug, TRUE)
  out <- do.call("plot.fv",
                 resolve.defaults(list(x=x), list(...),
                                  list(main=xname, shade=c("hi", "lo"))))
  if(identical(list(...)$limitsonly, TRUE))
    return(out)
  if(do.rug) {
    rugx <- ZX <- s$ZX
    # check whether it's the default plot
    argh <- list(...)
    isfo <- unlist(lapply(argh, inherits, what="formula"))
    if(any(isfo)) {
      # a plot formula was given; inspect RHS
      fmla <- argh[[min(which(isfo))]]
      rhs <- rhs.of.formula(fmla)
      vars <- variablesinformula(rhs)
      vars <- vars[vars %in% c(colnames(x), ".x", ".y")]
      if(length(vars) == 1 && vars %in% c(covname, ".x")) {
        # expression in terms of covariate
        rhstr <- as.character(rhs)[2]
        dat <- list(ZX)
        names(dat) <- vars[1]
        rugx <- as.numeric(eval(parse(text=rhstr), dat))
      } else {
        if(asked.rug) warning("Unable to add rug plot")
        rugx <- NULL
      }
    } 
    if(!is.null(rugx)) {
      # restrict to x limits, if given
      if(!is.null(xlim <- list(...)$xlim))
        rugx <- rugx[rugx >= xlim[1] & rugx <= xlim[2]]
      # finally plot the rug
      if(length(rugx) > 0)
        rug(rugx)
    }
  }
  invisible(NULL)
}

predict.rhohat <- function(object, ..., relative=FALSE) {
  if(length(list(...)) > 0)
    warning("Additional arguments ignored in predict.rhohat")
  # extract info
  s <- attr(object, "stuff")
  reference <- s$reference
  # convert to (linearly interpolated) function 
  x <- with(object, .x)
  y <- with(object, .y)
  rho <- approxfun(x, y, rule=2)
  # extract image of covariate
  Z <- s$Zimage
  # apply rho to Z
  Y <- eval.im(rho(Z))
  # adjust to reference baseline
  if(reference != "Lebesgue" && !relative) {
    lambda <- s$lambda
    Y <- eval.im(Y * lambda)
  }
  return(Y)
}

as.function.rhohat <- function(x, ..., value=".y", extrapolate=TRUE) {
  NextMethod("as.function")
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/ripras.R"
#
#	ripras.S	Ripley-Rasson estimator of domain
#
#
#	$Revision: 1.14 $	$Date: 2014/10/24 00:22:30 $
#
#
#
#
#-------------------------------------
bounding.box.xy <- function(x, y=NULL) {
  xy <- xy.coords(x,y)
  if(length(xy$x) == 0)
    return(NULL)
  owin(range(xy$x), range(xy$y), check=FALSE)
}

convexhull.xy <- function(x, y=NULL) {
  xy <- xy.coords(x, y)
  x <- xy$x
  y <- xy$y
  if(length(x) < 3)
    return(NULL)
  h <- rev(chull(x, y))  # must be anticlockwise
  if(length(h) < 3)
    return(NULL)
  w <- owin(poly=list(x=x[h], y=y[h]), check=FALSE)
  return(w)
}

ripras <- function(x, y=NULL, shape="convex", f) {
  xy <- xy.coords(x, y)
  n <- length(xy$x)
  w <- switch(shape,
              convex = convexhull.xy(xy),
              rectangle = boundingbox(xy),
              stop(paste("Unrecognised option: shape=", dQuote(shape))))
  if(is.null(w))
    return(NULL)
  # expansion factor
  if(!missing(f))
    stopifnot(is.numeric(f) && length(f) == 1 && f >= 1)
  else switch(shape,
              convex = {
                # number of vertices
                m <- summary(w)$nvertices
                f <- if(m < n) 1/sqrt(1 - m/n) else 2
              },
              rectangle = {
                f <- (n+1)/(n-1)
              })
  # centroid
  ce <- unlist(centroid.owin(w))
  # shift centroid to origin
  W <- shift(w, -ce)
  # rescale
  W <- affine(W, mat=diag(c(f,f)))
  # shift origin to centroid
  W <- shift(W, ce)
  return(W)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rknn.R"
#
#   rknn.R
#
#   Distribution of distance to k-th nearest point in d dimensions
#   (Poisson process of intensity lambda)
#
#   $Revision: 1.2 $  $Date: 2009/12/31 01:33:44 $
#

dknn <- function(x, k=1, d=2, lambda=1) {
  validposint(k, "dknn")
  validposint(d, "dknn")
  alpha.d <- (2 * pi^(d/2))/(d * gamma(d/2.))
  y <- dgamma(x^d, shape=k, rate=lambda * alpha.d)
  y <- y * d * x^(d-1)
  return(y)
}

pknn <- function(q, k=1, d=2, lambda=1) {
  validposint(k, "pknn")
  validposint(d, "pknn")
  alpha.d <- (2 * pi^(d/2))/(d * gamma(d/2.))
  p <- pgamma(q^d, shape=k, rate=lambda * alpha.d)
  return(p)
}

qknn <- function(p, k=1, d=2, lambda=1) {
  validposint(k, "qknn")
  validposint(d, "qknn")
  alpha.d <- (2 * pi^(d/2))/(d * gamma(d/2.))
  y <- qgamma(p, shape=k, rate=lambda * alpha.d)
  z <- y^(1/d)
  return(z)
}

rknn <- function(n, k=1, d=2, lambda=1) {
  validposint(k, "rknn")
  validposint(d, "rknn")
  alpha.d <- (2 * pi^(d/2))/(d * gamma(d/2.))  
  y <- rgamma(n, shape=k, rate=lambda * alpha.d)
  x <- y^(1/d)
  return(x)
}

  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rlabel.R"
#
#   rlabel.R
#
#   random (re)labelling
#
#   $Revision: 1.7 $   $Date: 2013/02/27 01:01:20 $
#
#
rlabel <- function(X, labels=marks(X), permute=TRUE) {
  stopifnot(is.ppp(X) || is.lpp(X) || is.pp3(X) || is.ppx(X))
  if(is.null(labels))
    stop("labels not given and marks not present")
  npts <- npoints(X)
  if(is.vector(labels) || is.factor(labels)) {
    nlabels <- length(labels)
    if(permute && (nlabels != npts))
      stop("length of labels vector does not match number of points")
    Y <- X %mark% sample(labels, npts, replace=!permute)
  } else if(is.data.frame(labels) || is.hyperframe(labels)) {
    nlabels <- nrow(labels)
    if(permute && (nlabels != npts))
      stop("number of rows of data frame does not match number of points")      
    Y <- X %mark% labels[sample(1:nlabels, npts, replace=!permute), ]
  } else stop("Format of labels argument is not understood")
  return(Y)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rmh.R"
#
# generic rmh

rmh <- function(model, ...){
     UseMethod("rmh")
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rmh.default.R"
#
# $Id: rmh.default.R,v 1.99 2014/12/27 15:30:57 adrian Exp adrian $
#
rmh.default <- function(model,start=NULL,
                        control=default.rmhcontrol(model),
                        ..., verbose=TRUE, snoop=FALSE) {
#
# Function rmh.  To simulate realizations of 2-dimensional point
# patterns, given the conditional intensity function of the 
# underlying process, via the Metropolis-Hastings algorithm.
#
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
#
#     V A L I D A T E
#
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
  
  if(verbose)
    cat("Checking arguments..")

# validate arguments and fill in the defaults

  model <- rmhmodel(model)
  start <- rmhstart(start)
  if(is.null(control)) {
    control <- default.rmhcontrol(model)
  } else {
    control <- rmhcontrol(control)
  }
  # override 
  if(length(list(...)) > 0)
    control <- update(control, ...)

  control <- rmhResolveControl(control, model)
  
  # retain "..." arguments unrecognised by rmhcontrol
  # These are assumed to be arguments of functions defining the trend
  argh <- list(...)
  known <- names(argh) %in% names(formals(rmhcontrol.default))
  f.args <- argh[!known]

#### Multitype models
  
# Decide whether the model is multitype; if so, find the types.

  types <- rmhResolveTypes(model, start, control)
  ntypes <- length(types)
  mtype <- (ntypes > 1)

# If the model is multitype, check that the model parameters agree with types
# and digest them
  
  if(mtype && !is.null(model$check)) {
    model <- rmhmodel(model, types=types)
  } else {
    model$types <- types
  }
  
######## Check for illegal combinations of model, start and control  ########

  # No expansion can be done if we are using x.start

  if(start$given == "x") {
    if(control$expand$force.exp)
      stop("Cannot expand window when using x.start.\n", call.=FALSE)
    control$expand <- .no.expansion
  }

# Warn about a silly value of fixall:
  if(control$fixall & ntypes==1) {
    warning("control$fixall applies only to multitype processes. Ignored. \n")
    control$fixall <- FALSE
    if(control$fixing == "n.each.type")
      control$fixing <- "n.total"
  }

  
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
#
#     M O D E L   P A R A M E T E R S
#
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

#######  Determine windows  ################################

  if(verbose)
    cat("determining simulation windows...")
  
# these may be NULL  
  w.model <- model$w
  x.start <- start$x.start
  trend <- model$trend
  trendy <- !is.null(trend)

  singletrend <- trendy && (is.im(trend) ||
                            is.function(trend) ||
                            (is.numeric(trend) && length(trend) == 1))
  trendlist <- if(singletrend) list(trend) else trend
  
# window implied by trend image, if any
  
  w.trend <- 
    if(is.im(trend))
      as.owin(trend)
    else if(is.list(trend) && any(ok <- unlist(lapply(trend, is.im))))
      as.owin((trend[ok])[[1]])
    else NULL

##  Clipping window (for final result)
  
  w.clip <-
    if(!is.null(w.model))
      w.model
    else if(!will.expand(control$expand)) {
      if(start$given == "x" && is.ppp(x.start))
        x.start$window
      else if(is.owin(w.trend))
        w.trend
    } else NULL

  if(!is.owin(w.clip))
    stop("Unable to determine window for pattern")

  
##  Simulation window 

  xpn <- rmhResolveExpansion(w.clip, control, trendlist, "trend")
  w.sim <- xpn$wsim
  expanded <- xpn$expanded

## Check the fine print   

  if(expanded) {

    if(control$fixing != "none")
      stop(paste("If we're conditioning on the number of points,",
                 "we cannot clip the result to another window.\n"))

    if(!is.subset.owin(w.clip, w.sim))
      stop("Expanded simulation window does not contain model window")
  }


#######  Trend  ################################
  
# Check that the expanded window fits inside the window
# upon which the trend(s) live if there are trends and
# if any trend is given by an image.

  if(expanded && !is.null(trend)) {
    trends <- if(is.im(trend)) list(trend) else trend
    images <- unlist(lapply(trends, is.im))
    if(any(images)) {
      iwindows <- lapply(trends[images], as.owin)
      nimages <- length(iwindows)
      misfit <- !unlist(lapply(iwindows,
                               function(x,w) { is.subset.owin(w,x) },
                               w = w.sim))
      nmisfit <- sum(misfit)
      if(nmisfit > 1) 
        stop(paste("Expanded simulation window is not contained in",
                   "several of the trend windows.\n",
                   "Bailing out.\n"))
      else if(nmisfit == 1) {
        warning(paste("Expanded simulation window is not contained in",
                      if(nimages == 1) "the trend window.\n"
                      else "one of the trend windows.\n",
                      "Expanding to this trend window (only).\n"))
        w.sim <- iwindows[[which(misfit)]]
      }
    }
  }

# Extract the 'beta' parameters

  if(length(model$cif) == 1) {
    # single interaction
    beta <- model$C.beta
    betalist <- list(beta)
  } else {
    # hybrid
    betalist <- model$C.betalist
    # multiply beta vectors for each component
    beta <- Reduce("*", betalist)
  }
  
##### .................. CONDITIONAL SIMULATION ...................

#####  
#||   Determine windows for conditional simulation
#||
#||      w.state  = window for the full configuration
#||  
#||      w.sim    = window for the 'free' (random) points
#||

  w.state <- w.sim
  
  condtype <- control$condtype
  x.cond   <- control$x.cond
#  n.cond   <- control$n.cond

  switch(condtype,
         none={
           w.cond <- NULL
         },
         window={
           # conditioning on the realisation inside a subwindow
           w.cond <- as.owin(x.cond)
           # subtract from w.sim
           w.sim <- setminus.owin(w.state, w.cond)
           if(is.empty(w.sim))
             stop(paste("Conditional simulation is undefined;",
                        "the conditioning window",
                        sQuote("as.owin(control$x.cond)"),
                        "covers the entire simulation window"))
         },
         Palm={
           # Palm conditioning
           w.cond <- NULL
         })

#####  
#||   Convert conditioning points to appropriate format


  x.condpp <- switch(condtype,
                        none=NULL,
                        window=x.cond,
                        Palm=as.ppp(x.cond, w.state))

# validate  
  if(!is.null(x.condpp)) {
    if(mtype) {
      if(!is.marked(x.condpp))
        stop("Model is multitype, but x.cond is unmarked")
      if(!identical(all.equal(types, levels(marks(x.condpp))), TRUE))
        stop("Types of points in x.cond do not match types in model")
    }
  }
  

#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
#
#     S T A R T I N G      S T A T E
#
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

###################### Starting state data ############################

# whether the initial state should be thinned
  
  thin <- (start$given != "x") && (control$fixing == "none")
  
# There must now be a starting state.
  
  if(start$given == "none") {
    # For conditional simulation, the starting state must be given
    if(condtype != "none")
      stop("No starting state given")
    # Determine integral of beta * trend over data window.
    # This is the expected number of points in the reference Poisson process.
    area.w.clip <- area(w.clip)
    if(trendy) {
      tsummaries <- summarise.trend(trend, w=w.clip, a=area.w.clip)
      En <- beta * unlist(lapply(tsummaries, function(x) { x$integral }))
    } else {
      En <- beta * area.w.clip
    }
    # Fix n.start equal to this integral
    n.start <- if(spatstat.options("scalable")) round(En) else ceiling(En)
    start <- rmhstart(n.start=n.start)
  }
  
# In the case of conditional simulation, the start data determine
# the 'free' points (i.e. excluding x.cond) in the initial state.

  switch(start$given,
         none={
           stop("No starting state given")
         },
         x = {
           # x.start was given
           # coerce it to a ppp object
           if(!is.ppp(x.start))
             x.start <- as.ppp(x.start, w.state)
           if(condtype == "window") {
             # clip to simulation window
             xs <- x.start[w.sim]
             nlost <- x.start$n - xs$n
             if(nlost > 0) 
               warning(paste(nlost,
                             ngettext(nlost, "point","points"),
                             "of x.start",
                             ngettext(nlost, "was", "were"),
                             "removed because",
                             ngettext(nlost, "it", "they"),
                             "fell in the window of x.cond"))
             x.start <- xs
           }
           npts.free <- x.start$n
         },
         n = {
           # n.start was given
           n.start <- start$n.start
           # Adjust the number of points in the starting state in accordance
           # with the expansion that has occurred.  
           if(expanded) {
	     holnum <- if(spatstat.options("scalable")) round else ceiling
             n.start <- holnum(n.start * area(w.sim)/area(w.clip))
           }
           #
           npts.free <- sum(n.start) # The ``sum()'' is redundant if n.start
                                # is scalar; no harm, but.
         },
         stop("Internal error: start$given unrecognized"))

#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
#
#     C O N T R O L    P A R A M E T E R S
#
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

###################  Periodic boundary conditions #########################

  periodic <- control$periodic
  
  if(is.null(periodic)) {
    # undecided. Use default rule
    control$periodic <- periodic <- expanded && is.rectangle(w.state)
  } else if(periodic && !is.rectangle(w.state)) {
    # if periodic is TRUE we have to be simulating in a rectangular window.
    stop("Need rectangular window for periodic simulation.\n")
  }

# parameter passed to C:  
  period <-
    if(periodic)
      c(diff(w.state$xrange), diff(w.state$yrange))
    else
      c(-1,-1)



#### vector of proposal probabilities 

  if(!mtype) 
    ptypes <- 1
  else {
    ptypes <- control$ptypes
    if(is.null(ptypes)) {
      # default proposal probabilities
      ptypes <- if(start$given == "x" && (nx <- npoints(x.start)) > 0) {
        table(marks(x.start, dfok=FALSE))/nx
      } else rep.int(1/ntypes, ntypes)
    } else {
      # Validate ptypes
      if(length(ptypes) != ntypes | sum(ptypes) != 1)
        stop("Argument ptypes is mis-specified.\n")
    }
  } 


  
########################################################################
#  Normalising constant for proposal density
# 
# Integral of trend over the expanded window (or area of window):
# Iota == Integral Of Trend (or) Area.

  area.w.sim <- area(w.sim)
  if(trendy) {
    if(verbose)
      cat("Evaluating trend integral...")
    tsummaries <- summarise.trend(trend, w=w.sim, a=area.w.sim)
    nbg  <- unlist(lapply(tsummaries, function(x) { x$min < 0 }))
    if(any(nbg))
      stop("Trend has negative values")
    iota <- unlist(lapply(tsummaries, function(x) { x$integral }))
    tmax <- unlist(lapply(tsummaries, function(x) { x$max }))
  } else {
    iota <- area.w.sim
    tmax <- NULL
  }

  
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
#
#     A.S. EMPTY PROCESS
#
#         for conditional simulation, 'empty' means there are no 'free' points
#  
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

  a.s.empty <- FALSE
  
#
#  Empty pattern, simulated conditional on n
#  
  if(npts.free == 0 && control$fixing != "none") {
    a.s.empty <- TRUE
    if(verbose) {
      mess <- paste("Initial pattern has 0 random points,",
                    "and simulation is conditional on the number of points -")
      if(condtype == "none")
        warning(paste(mess, "returning an empty pattern\n"))
      else
        warning(paste(mess, "returning a pattern with no random points\n"))
    }
  }

#
#  If beta = 0, the process is almost surely empty
#
  
  if(all(beta < .Machine$double.eps)) {
    if(control$fixing == "none" && condtype == "none") {
      # return empty pattern
      if(verbose)
        warning("beta = 0 implies an empty pattern\n")
      a.s.empty <- TRUE
    } else 
      stop("beta = 0 implies an empty pattern, but we are simulating conditional on a nonzero number of points")
  }

#
# If we're conditioning on the contents of a subwindow,
# and the subwindow covers the clipping region,
# the result is deterministic.  

  if(condtype == "window" && is.subset.owin(w.clip, w.cond)) {
    a.s.empty <- TRUE
    warning(paste("Model window is a subset of conditioning window:",
              "result is deterministic\n"))
  }    

#
#  
  if(a.s.empty) {
    # create empty pattern, to be returned
    if(!is.null(x.condpp)) 
      empty <- x.condpp[w.clip]
    else {
      empty <- ppp(numeric(0), numeric(0), window=w.clip)
      if(mtype) {
        vide <- factor(types[integer(0)], levels=types)
        empty <- empty %mark% vide
      }
    }
  }

#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
#
#     PACK UP
#
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

######### Store decisions

  Model <- model
  Start <- start
  Control <- control

  Model$w <- w.clip
  Model$types <- types
  
  Control$expand <- if(expanded) rmhexpand(w.state) else .no.expansion

  Control$internal <- list(w.sim=w.sim,
                           w.state=w.state,
                           x.condpp=x.condpp,
                           ptypes=ptypes,
                           period=period,
                           thin=thin)

  Model$internal <- list(a.s.empty=a.s.empty,
                         empty=if(a.s.empty) empty else NULL,
                         mtype=mtype,
                         trendy=trendy,
                         betalist=betalist,
                         beta=beta,
                         iota=iota,
                         tmax=tmax)

  Start$internal <- list(npts.free=npts.free)

  InfoList <- list(model=Model, start=Start, control=Control)
  class(InfoList) <- c("rmhInfoList", class(InfoList))

  # go
  do.call("rmhEngine",
          append(list(InfoList,
                      verbose=verbose, snoop=snoop, kitchensink=TRUE),
                 f.args))
}

print.rmhInfoList <- function(x, ...) {
  cat("\nPre-digested Metropolis-Hastings algorithm parameters (rmhInfoList)\n")
  print(as.listof(x))
}

#---------------  rmhEngine -------------------------------------------
#
# This is the interface to the C code.
#
# InfoList is a list of pre-digested, validated arguments
# obtained from rmh.default.
#
# This function is called by rmh.default to generate one simulated
# realisation of the model.
# It's called repeatedly by ho.engine and qqplot.ppm to generate multiple
# realisations (saving time by not repeating the argument checking
# in rmh.default).

# arguments:  
# kitchensink: whether to tack InfoList on to the return value as an attribute
# preponly: whether to just return InfoList without simulating
#
#   rmh.default digests arguments and calls rmhEngine with kitchensink=T
#
#   qqplot.ppm first gets InfoList by calling rmh.default with preponly=T
#              (which digests the model arguments and calls rmhEngine
#               with preponly=T, returning InfoList),
#              then repeatedly calls rmhEngine(InfoList) to simulate.
#
# -------------------------------------------------------

rmhEngine <- function(InfoList, ...,
                       verbose=FALSE, kitchensink=FALSE,
                       preponly=FALSE, snoop=FALSE) {
# Internal Use Only!
# This is the interface to the C code.

  if(!inherits(InfoList, "rmhInfoList"))
    stop("data not in correct format for internal function rmhEngine")

  
  if(preponly)
    return(InfoList)

  model <- InfoList$model
  start <- InfoList$start
  control <- InfoList$control

  w.sim <- control$internal$w.sim
  w.state <- control$internal$w.state
  w.clip <- model$w

  condtype <- control$condtype
  x.condpp <- control$internal$x.condpp

  types <- model$types
  ntypes <- length(types)
  
  ptypes <- control$internal$ptypes
  period <- control$internal$period

  mtype <- model$internal$mtype

  trend <- model$trend
  trendy <- model$internal$trendy
#  betalist <- model$internal$betalist
  beta <- model$internal$beta
  iota <- model$internal$iota
  tmax <- model$internal$tmax

  npts.free <- start$internal$npts.free

  n.start <- start$n.start
  x.start <- start$x.start

  
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
#
#     E M P T Y   P A T T E R N
#
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

  if(model$internal$a.s.empty) {
    if(verbose) cat("\n")
    empty <- model$internal$empty
    attr(empty, "info") <- InfoList
    return(empty)
  }
  
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
#
#     S I M U L A T I O N     
#
#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

#############################################
####  
####  Random number seed: initialisation & capture
####  
#############################################  
  
  if(!exists(".Random.seed"))
    runif(1)

  saved.seed <- .Random.seed
  

#############################################
####  
####  Poisson case
####  
#############################################  
  
  if(is.poisson.rmhmodel(model)) {
    if(verbose) cat("\n")
    intensity <- if(!trendy) beta else model$trend
    Xsim <-
      switch(control$fixing,
             none= {
               # Poisson process 
               if(!mtype)
                 rpoispp(intensity, win=w.sim, ...)
               else
                 rmpoispp(intensity, win=w.sim, types=types)
             },
             n.total = {
               # Binomial/multinomial process with fixed total number of points
               if(!mtype) 
                 rpoint(npts.free, intensity, win=w.sim, verbose=verbose)
               else
                 rmpoint(npts.free, intensity, win=w.sim, types=types,
                         verbose=verbose)
             },
             n.each.type = {
               # Multinomial process with fixed number of points of each type
               npts.each <-
                 switch(start$given,
                        n = n.start,
                        x = as.integer(table(marks(x.start, dfok=FALSE))),
  stop("No starting state given; can't condition on fixed number of points"))
               rmpoint(npts.each, intensity, win=w.sim, types=types,
                       verbose=verbose)
             },
             stop("Internal error: control$fixing unrecognised")
             )
    # if conditioning, add fixed points
    if(condtype != "none")
      Xsim <- superimpose(Xsim, x.condpp, W=w.state)
    # clip result to output window
    Xclip <- Xsim[w.clip]
    attr(Xclip, "info") <- InfoList
    return(Xclip)
  }

  
########################################################################  
#      M e t r o p o l i s  H a s t i n g s    s i m u l a t i o n
########################################################################

  if(verbose)
    cat("Starting simulation.\nInitial state...")
  

#### Build starting state

  npts.cond  <- if(condtype != "none") x.condpp$n else 0
#  npts.total <- npts.free + npts.cond

#### FIRST generate the 'free' points
  
#### First the marks, if any.
#### The marks must be integers 0 to (ntypes-1) for passing to C

  Ctypes <- if(mtype) 0:(ntypes-1) else 0
  
  Cmarks <-
    if(!mtype)
      0
    else
      switch(start$given,
             n = {
               # n.start given
               if(control$fixing=="n.each.type")
                 rep.int(Ctypes,n.start)
               else
                 sample(Ctypes,npts.free,TRUE,ptypes)
             },
             x = {
               # x.start given
               as.integer(marks(x.start, dfok=FALSE))-1
             },
             stop("internal error: start$given unrecognised")
             )
#
# Then the x, y coordinates
#
  switch(start$given,
         x = {
           x <- x.start$x
           y <- x.start$y
         },
         n = {
           xy <-
             if(!trendy)
               runifpoint(npts.free, w.sim, ...)
             else
               rpoint.multi(npts.free, trend, tmax,
                      factor(Cmarks,levels=Ctypes), w.sim, ...)
           x <- xy$x
           y <- xy$y
         })

## APPEND the free points AFTER the conditioning points

  if(condtype != "none") {
    x <- c(x.condpp$x, x)
    y <- c(x.condpp$y, y)
    if(mtype)
      Cmarks <- c(as.integer(marks(x.condpp))-1, Cmarks)
  }

# decide whether to activate visual debugger
  if(snoop) {
    Xinit <- ppp(x, y, window=w.sim)
    if(mtype)
      marks(Xinit) <- Cmarks + 1
    if(verbose) cat("\nCreating debugger environment..")
    snoopenv <- rmhSnoopEnv(Xinit=Xinit, Wclip=w.clip, R=reach(model))
    if(verbose) cat("Done.\n")
  } else snoopenv <- "none"

  
#######################################################################
#  Set up C call
######################################################################    

# Determine the name of the cif used in the C code

  C.id <- model$C.id
  ncif <- length(C.id)
  
# Get the parameters in C-ese
    
  ipar <- model$C.ipar
  iparlist <- if(ncif == 1) list(ipar) else model$C.iparlist
  iparlen <- unlist(lapply(iparlist, length))

  beta <- model$internal$beta
  
# Absorb the constants or vectors `iota' and 'ptypes' into the beta parameters
  beta <- (iota/ptypes) * beta
  
# Algorithm control parameters

  p       <- control$p
  q       <- control$q
  nrep    <- control$nrep
#  fixcode <- control$fixcode
#  fixing  <- control$fixing
  fixall  <- control$fixall
  nverb   <- control$nverb
  saving  <- control$saving
  nsave   <- control$nsave
  nburn   <- control$nburn
  track   <- control$track
  thin    <- control$internal$thin
  
  if(verbose)
    cat("Proposal points...")
           
# If the pattern is multitype, generate the mark proposals (0 to ntypes-1)
  Cmprop <- if(mtype) sample(Ctypes,nrep,TRUE,prob=ptypes) else 0
		
# Generate the ``proposal points'' in the expanded window.
  xy <-
    if(trendy)
      rpoint.multi(nrep,trend,tmax,
                   factor(Cmprop, levels=Ctypes),
                   w.sim, ..., warn=FALSE)
    else
      runifpoint(nrep, w.sim, warn=FALSE)
  xprop <- xy$x
  yprop <- xy$y

  if(verbose)
    cat("Start simulation.\n")

  storage.mode(ncif)   <- "integer"
  storage.mode(C.id)   <- "character"
  storage.mode(beta)    <- "double"
  storage.mode(ipar)    <- "double"
  storage.mode(iparlen) <- "integer"
  storage.mode(period) <- "double"
  storage.mode(xprop)  <- storage.mode(yprop) <- "double"
  storage.mode(Cmprop) <- "integer"
  storage.mode(ntypes) <- "integer"
  storage.mode(nrep)   <- "integer"
  storage.mode(p) <- storage.mode(q) <- "double"
  storage.mode(nverb)  <- "integer"
  storage.mode(x) <- storage.mode(y) <- "double"
  storage.mode(Cmarks) <- "integer"
  storage.mode(fixall) <- "integer"
  storage.mode(npts.cond) <- "integer"
  storage.mode(track) <- "integer"
  storage.mode(thin) <- "integer"

  if(!saving) {
    # ////////// Single block /////////////////////////////////
    nrep0 <- 0
    storage.mode(nrep0)  <- "integer"
    # Call the Metropolis-Hastings C code:
    out <- .Call("xmethas",
                 ncif,
                 C.id,
                 beta,
                 ipar,
                 iparlen,
                 period,
                 xprop, yprop, Cmprop,
                 ntypes,
                 nrep,
                 p, q,
                 nverb,
                 nrep0,
                 x, y, Cmarks,
                 npts.cond,
                 fixall,
                 track,
                 thin,
                 snoopenv)
#                 PACKAGE="spatstat")
  
    # Extract the point pattern returned from C
    X <- ppp(x=out[[1]], y=out[[2]], window=w.state, check=FALSE)
    if(mtype) {
      # convert integer marks from C to R
      marx <- factor(out[[3]], levels=0:(ntypes-1))
      # then restore original type levels
      levels(marx) <- types
      # glue to points
      marks(X) <- marx
    }

    # Now clip the pattern to the ``clipping'' window:
    if(!control$expand$force.noexp)
      X <- X[w.clip]

    # Extract transition history:
    if(track) {
      usedout <- if(mtype) 3 else 2
      proptype <- factor(out[[usedout+1]], levels=1:3,
                         labels=c("Birth", "Death", "Shift"))
      accepted <- as.logical(out[[usedout+2]])
      History <- data.frame(proposaltype=proptype, accepted=accepted)
      if(length(out) >= usedout + 4) {
        # history includes numerator & denominator of Hastings ratio
        numerator <- as.double(out[[usedout + 3]])
        denominator <- as.double(out[[usedout + 4]])
        History <- cbind(History,
                         data.frame(numerator=numerator,
                                    denominator=denominator))
      }
    }
  } else {
    # ////////// Multiple blocks /////////////////////////////////
    # determine length of each block of simulations
    nblocks <- as.integer(1 + ceiling((nrep - nburn)/nsave))
    block <- c(nburn, rep.int(nsave, nblocks-1))
    block[nblocks] <- block[nblocks] - (sum(block)-nrep)
    block <- block[block >= 1]
    nblocks <- length(block)
    blockend <- cumsum(block)
    # set up list to contain the saved point patterns
    Xlist <- vector(mode="list", length=nblocks)
    # Call the Metropolis-Hastings C code repeatedly:
    xprev <- x
    yprev <- y
    Cmarksprev <- Cmarks
    #
    thinFALSE <- as.integer(FALSE)
    storage.mode(thinFALSE) <- "integer"
    # ................ loop .........................
    for(I in 1:nblocks) {
      # number of iterations for this block
      nrepI <- block[I]
      storage.mode(nrepI) <- "integer"
      # number of previous iterations
      nrep0 <- if(I == 1) 0 else blockend[I-1]
      storage.mode(nrep0)  <- "integer"
      # proposals
      seqI <- 1:nrepI
      xpropI <- xprop[seqI]
      ypropI <- yprop[seqI]
      CmpropI <- Cmprop[seqI]
      storage.mode(xpropI) <- storage.mode(ypropI) <- "double"
      storage.mode(CmpropI) <- "integer"
      # no thinning in subsequent blocks
      if(I > 1) thin <- thinFALSE
      # call
      out <- .Call("xmethas",
                   ncif,
                   C.id,
                   beta,
                   ipar,
                   iparlen,
                   period,
                   xpropI, ypropI, CmpropI,
                   ntypes,
                   nrepI,
                   p, q,
                   nverb,
                   nrep0,
                   xprev, yprev, Cmarksprev,
                   npts.cond,
                   fixall,
                   track,
                   thin,
                   snoopenv)
#                   PACKAGE="spatstat")
      # Extract the point pattern returned from C
      X <- ppp(x=out[[1]], y=out[[2]], window=w.state, check=FALSE)
      if(mtype) {
        # convert integer marks from C to R
        marx <- factor(out[[3]], levels=0:(ntypes-1))
        # then restore original type levels
        levels(marx) <- types
        # glue to points
        marks(X) <- marx
      }
      
      # Now clip the pattern to the ``clipping'' window:
      if(!control$expand$force.noexp)
        X <- X[w.clip]

      # commit to list
      Xlist[[I]] <- X
      
      # Extract transition history:
      if(track) {
        usedout <- if(mtype) 3 else 2
        proptype <- factor(out[[usedout+1]], levels=1:3,
                           labels=c("Birth", "Death", "Shift"))
        accepted <- as.logical(out[[usedout+2]])
        HistoryI <- data.frame(proposaltype=proptype, accepted=accepted)
        if(length(out) >= usedout + 4) {
          # history includes numerator & denominator of Hastings ratio
          numerator <- as.double(out[[usedout + 3]])
          denominator <- as.double(out[[usedout + 4]])
          HistoryI <- cbind(HistoryI,
                            data.frame(numerator=numerator,
                                       denominator=denominator))
        }
        # concatenate with histories of previous blocks
        History <- if(I == 1) HistoryI else rbind(History, HistoryI)
      }

      # update 'previous state'
      xprev <- out[[1]]
      yprev <- out[[2]]
      Cmarksprev <- if(!mtype) 0 else out[[3]]
      storage.mode(xprev) <- storage.mode(yprev) <- "double"
      storage.mode(Cmarksprev) <- "integer"

      # discard used proposals
      xprop <- xprop[-seqI]
      yprop <- yprop[-seqI]
      Cmprop <- Cmprop[-seqI]
    }
    # .............. end loop ...............................
    
    # Result of simulation is final state 'X'
    # Tack on the list of intermediate states
    names(Xlist) <- paste("Iteration", as.integer(blockend), sep="_")
    attr(X, "saved") <- as.listof(Xlist)
  }

# Append to the result information about how it was generated.
  if(kitchensink) {
    attr(X, "info") <- InfoList
    attr(X, "seed") <- saved.seed
  }
  if(track)
    attr(X, "history") <- History
  
  return(X)
}


# helper function

summarise.trend <- local({
  # main function
  summarise.trend <- function(trend, w, a=area(w)) {
    tlist <- if(is.function(trend) || is.im(trend)) list(trend) else trend
    return(lapply(tlist, summarise1, w=w, a=a))
  }
  # 
  summarise1 <-  function(x, w, a) {
    if(is.numeric(x)) {
      mini <- maxi <- x
      integ <- a*x
    } else {
      Z  <- as.im(x, w)[w, drop=FALSE]
      ran <- range(Z)
      mini <- ran[1]
      maxi <- ran[2]
      integ <- integral.im(Z)
    }
    return(list(min=mini, max=maxi, integral=integ))
  }
  summarise.trend
})
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rmh.ppm.R"
#
# simulation of FITTED model
#
#  $Revision: 1.30 $ $Date: 2014/12/09 09:14:35 $
#
#
rmh.ppm <- function(model, start = NULL,
                    control = default.rmhcontrol(model),
                    ...,
                    w = NULL, project=TRUE, verbose=TRUE,
                    new.coef=NULL) {
  verifyclass(model, "ppm")
  argh <- list(...)

  if(is.null(control)) {
    control <- default.rmhcontrol(model)
  } else {
    control <- rmhcontrol(control)
  }

  # override 
  if(length(list(...)) > 0)
    control <- update(control, ...)
  
  # convert fitted model object to list of parameters for rmh.default
  X <- rmhmodel(model, w=w, verbose=verbose, project=project, control=control,
                new.coef=new.coef)

  # set initial state

  if(is.null(start)) {
    datapattern <- data.ppm(model)
    start <- rmhstart(n.start=datapattern$n)
  }
  
  # call rmh.default 
  # passing only arguments unrecognised by rmhcontrol
  known <- names(argh) %in% names(formals(rmhcontrol.default))
  fargs <- argh[!known]

  Y <- do.call("rmh.default",
               append(list(model=X, start=start, control=control,
                           verbose=verbose),
                      fargs))
  return(Y)
}

simulate.ppm <- function(object, nsim=1, ...,
                         singlerun=FALSE,
                         start = NULL,
                         control = default.rmhcontrol(object),
                         project=TRUE,
                         new.coef=NULL,
                         verbose=FALSE,
                         progress=(nsim > 1)) {
  verifyclass(object, "ppm")
  argh <- list(...)
  if(nsim == 0) return(list())

  starttime = proc.time()
  
  # set up control parameters
  if(missing(control) || is.null(control)) {
    rcontr <- default.rmhcontrol(object)
  } else {
    rcontr <- rmhcontrol(control)
  }
  if(singlerun) {
    # allow nsave, nburn to determine nrep
    nsave <- resolve.1.default("nsave", list(...), as.list(rcontr),
                               .MatchNull=FALSE)
    nburn <- resolve.1.default("nburn", list(...), as.list(rcontr),
                               list(nburn=nsave),
                               .MatchNull=FALSE)
    if(!is.null(nsave)) {
      nrep <- nburn + (nsim-1) * nsave
      rcontr <- update(rcontr, nrep=nrep, nsave=nsave, nburn=nburn)
    } 
  }
  # other overrides
  if(length(list(...)) > 0)
    rcontr <- update(rcontr, ...)

  # Set up model parameters for rmh
  rmodel <- rmhmodel(object, verbose=FALSE, project=TRUE, control=rcontr,
                     new.coef=new.coef)
  if(is.null(start)) {
    datapattern <- data.ppm(object)
    start <- rmhstart(n.start=datapattern$n)
  }
  rstart <- rmhstart(start)

  #########
  
  if(singlerun && nsim > 1) {
    # //////////////////////////////////////////////////
    # execute one long run and save every k-th iteration
    if(is.null(rcontr$nsave)) {
      # determine spacing between subsamples
      if(!is.null(rcontr$nburn)) {
        nsave <- max(1, with(rcontr, floor((nrep - nburn)/(nsim-1))))
      } else {
        # assume nburn = 2 * nsave
        nsave <- max(1, with(rcontr, floor(nrep/(nsim+1))))
        nburn <- 2 * nsave
      }
      rcontr <- update(rcontr, nsave=nsave, nburn=nburn)
    }
    # check nrep is enough
    nrepmin <- with(rcontr, nburn + (nsim-1) * nsave)
    if(rcontr$nrep < nrepmin)
      rcontr <- update(rcontr, nrep=nrepmin)
    # OK, run it
    if(progress) {
      cat(paste("Generating", nsim, "simulated patterns in a single run ... ")) 
      flush.console()
    }
    Y <- rmh(rmodel, rstart, rcontr, verbose=verbose)
    if(progress)
      cat("Done.\n")
    # extract sampled states
    out <- attr(Y, "saved")
    if(length(out) != nsim)
      stop(paste("Internal error: wrong number of simulations generated:",
                 length(out), "!=", nsim))
  } else {
    # //////////////////////////////////////////////////
    # execute 'nsim' independent runs
    out <- list()
    # pre-digest arguments
    rmhinfolist <- rmh(rmodel, rstart, rcontr, preponly=TRUE, verbose=verbose)
    # go
    if(nsim > 0) {
      if(progress) {
        cat(paste("Generating", nsim, "simulated", 
                  ngettext(nsim, "pattern", "patterns"),
                  "..."))
        flush.console()
      }
      # call rmh
      # passing only arguments unrecognised by rmhcontrol
      known <- names(argh) %in% names(formals(rmhcontrol.default))
      fargs <- argh[!known]
      rmhargs <- append(list(InfoList=rmhinfolist, verbose=verbose), fargs)
      for(i in 1:nsim) {
        out[[i]] <- do.call("rmhEngine", rmhargs)
        if(progress) progressreport(i, nsim)
      }
    }
  }
  out <- as.listof(out)
  if(nsim > 0)
    names(out) <- paste("Simulation", 1:nsim)
  out <- timed(out, starttime=starttime)
  return(out)
}  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rmhResolveTypes.R"
#
#
#   rmhResolveTypes.R
#
#   $Revision: 1.9 $   $Date: 2009/10/31 01:52:54 $
#
#
rmhResolveTypes <- function(model, start, control) {

# Decide whether a multitype point process is to be simulated.
# If so, determine the vector of types.

  verifyclass(model, "rmhmodel")
  verifyclass(start, "rmhstart")
  verifyclass(control, "rmhcontrol")

# Different ways of specifying types directly

  types.model <- model$types
  types.start <- if(start$given=="x" && is.marked(x.start <- start$x.start))
                     levels(marks(x.start, dfok=FALSE)) else NULL
  
# Check for inconsistencies  
  if(!is.null(types.model) && !is.null(types.start))
    if(!identical(all.equal(types.model, types.start), TRUE))
      stop("marks in start$x.start do not match model$types")
  
  types.given <- if(!is.null(types.model)) types.model else types.start
  types.given.source <-
    if(!is.null(types.model)) "model$types" else "marks of x.start"
  
# Different ways of implying the number of types
  
  ntypes.beta <- length(model$par[["beta"]])
  ntypes.ptypes <- length(control$ptypes)
  ntypes.nstart <- if(start$given == "n") length(start$n.start) else 0
  mot <- model$trend
  ntypes.trend <-  if(is.null(mot)) 0 else
                   if(is.im(mot)) 1 else
                   if(is.list(mot) &&
                      all(unlist(lapply(mot, is.im))))
                     length(mot) else 0
  
# Check for inconsistencies in implied number of types (only for numbers > 1)

  nty <- c(ntypes.beta, ntypes.ptypes, ntypes.nstart, ntypes.trend)
  nam <- c("model$par$beta", "control$ptypes", "start$n.start", "model$trend")
  implied <- (nty > 1)
  if(!any(implied))
    ntypes.implied <- 1
  else {
    if(length(unique(nty[implied])) > 1)
      stop(paste("Mismatch in numbers of types implied by",
                 commasep(sQuote(nam[implied]))))
    ntypes.implied <- unique(nty[implied])
    ntypes.implied.source <- (nam[implied])[1]
  } 

# Check consistency between types.given and ntypes.implied 

  if(!is.null(types.given) && ntypes.implied > 1)
    if(length(types.given) != ntypes.implied)
      stop(paste("Mismatch between number of types in",
                 types.given.source,
                 "and length of",
                 ntypes.implied.source))

# Finally determine the types
  
  if(model$multitype.interact) {
    # There MUST be a types vector
    types <- if(!is.null(types.given)) types.given
             else if(ntypes.implied > 1) 1:ntypes.implied
             else stop("Cannot determine types for multitype process")
  } else {
    types <- if(!is.null(types.given)) types.given
             else if(ntypes.implied > 1) 1:ntypes.implied
             else 1
  }

  ntypes <- length(types)
  
# If we are conditioning on the number of points of each type,
# make sure the starting state is appropriate

  if(control$fixing == "n.each.type") {
    if(start$given == "n" && ntypes.nstart != ntypes)
      stop("Length of start$n.start not equal to number of types.\n")
    else if(start$given == "x" && length(types.given) != ntypes) 
      stop("Marks of start$x.start do not match number of types.\n")
  }
  
  return(types)
}

  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rmhcontrol.R"
#
#
#   rmhcontrol.R
#
#   $Revision: 1.25 $  $Date: 2014/10/24 00:22:30 $
#
#

rmhcontrol <- function(...) {
  UseMethod("rmhcontrol")
}

rmhcontrol.rmhcontrol <- function(...) {
  argz <- list(...)
  if(length(argz) == 1)
    return(argz[[1]])
  stop("Arguments not understood")
}

rmhcontrol.list <- function(...) {
  argz <- list(...)
  nama <- names(argz)
  if(length(argz) == 1 && !any(nzchar(nama)))
    do.call("rmhcontrol.default", argz[[1]])
  else
    do.call.matched("rmhcontrol.default", argz)
}

rmhcontrol.default <- function(..., p=0.9, q=0.5, nrep=5e5,
                        expand=NULL, periodic=NULL, ptypes=NULL,
                        x.cond=NULL, fixall=FALSE, nverb=0,
                        nsave=NULL, nburn=nsave, track=FALSE)
{
  argh <- list(...)
  nargh <- length(argh)
  if(nargh > 0) {
    # allow rmhcontrol(NULL), otherwise flag an error
    if(!(nargh == 1 && is.null(argh[[1]])))
      stop(paste("Unrecognised arguments to rmhcontrol;",
                 "valid arguments are listed in help(rmhcontrol.default)"))
  }
  # impose default values
  if(missing(p)) p <- spatstat.options("rmh.p")
  if(missing(q)) q <- spatstat.options("rmh.q")
  if(missing(nrep)) nrep <- spatstat.options("rmh.nrep")
  # validate arguments
  if(!is.numeric(p) || length(p) != 1
     || p < 0 || p > 1)
    stop("p should be a number in [0,1]")
  if(!is.numeric(q) || length(q) != 1
     || q < 0 || q > 1)
    stop("q should be a number in [0,1]")
  if(!is.numeric(nrep) || length(nrep) != 1
     || nrep < 1)
    stop("nrep should be an integer >= 1")
  nrep <- as.integer(nrep)
  if(!is.numeric(nverb) || length(nverb) != 1
     || nverb < 0 || nverb > nrep)
    stop("nverb should be an integer <= nrep")
  nverb <- as.integer(nverb)
  if(!is.logical(fixall) || length(fixall) != 1)
    stop("fixall should be a logical value")
  if(!is.null(periodic) && (!is.logical(periodic) || length(periodic) != 1))
    stop(paste(sQuote("periodic"), "should be a logical value or NULL"))
  if(saving <- !is.null(nsave)) {
    if(!is.numeric(nsave) || length(nsave) != 1
       || nsave < 0 || nsave >= nrep)
      stop("nsave should be an integer < nrep")
    if(is.null(nburn)) nburn <- min(nsave, nrep-nsave)
    if(!is.null(nburn)) stopifnot(nburn + nsave <= nrep)
  }
  stopifnot(is.logical(track))

#################################################################
# Conditioning on point configuration
#
# condtype = "none": no conditioning
# condtype = "Palm": conditioning on the presence of specified points
# condtype = "window": conditioning on the configuration in a subwindow
#
  if(is.null(x.cond)) {
    condtype <- "none"
    n.cond <- NULL
  } else if(is.ppp(x.cond)) {
    condtype <- "window"
    n.cond <- x.cond$n
  } else if(is.data.frame(x.cond)) {
    if(ncol(x.cond) %in% c(2,3)) {
      condtype <- "Palm"
      n.cond <- nrow(x.cond)
    } else stop("Wrong number of columns in data frame x.cond")
  } else if(is.list(x.cond)) {
    if(length(x.cond) %in% c(2,3)) {
      x.cond <- as.data.frame(x.cond)
      condtype <- "Palm"
      n.cond <- nrow(x.cond)
    } else stop("Wrong number of components in list x.cond")
  } else stop("Unrecognised format for x.cond")

  if(condtype == "Palm" && n.cond == 0) {
    warning(paste("Ignored empty configuration x.cond;",
                  "conditional (Palm) simulation given an empty point pattern",
                  "is equivalent to unconditional simulation"))
    condtype <- "none"
    x.cond <- NULL
    n.cond <- NULL
  }
    
#################################################################
# Fixing the number of points?
#  
# fixcode = 1 <--> no conditioning
# fixcode = 2 <--> conditioning on n = number of points
# fixcode = 3 <--> conditioning on the number of points of each type.

  fixcode    <- 2 - (p<1) + fixall - fixall*(p<1)
  fixing <- switch(fixcode, "none", "n.total", "n.each.type")
  
# Warn about silly combination
  if(fixall && p < 1)
	warning("fixall = TRUE conflicts with p < 1. Ignored.\n")

###############################################################  
# `expand' determines expansion of the simulation window

  expand <- rmhexpand(expand)

# No expansion is permitted if we are conditioning on the
# number of points
  
  if(fixing != "none") {
    if(expand$force.exp)
      stop(paste("When conditioning on the number of points,",
                 "no expansion may be done.\n"), call.=FALSE)
    # no expansion
    expand <- .no.expansion
  }

###################################################################
# return augmented list  
  out <- list(p=p, q=q, 
              nrep=nrep, nverb=nverb,
              expand=expand, 
              periodic=periodic, 
              ptypes=ptypes,
              fixall=fixall,
              fixcode=fixcode,
              fixing=fixing,
              condtype=condtype,
              x.cond=x.cond,
              saving=saving, nsave=nsave, nburn=nburn,
              track=track)
  class(out) <- c("rmhcontrol", class(out))
  return(out)
}

print.rmhcontrol <- function(x, ...) {
  verifyclass(x, "rmhcontrol")

  cat("Metropolis-Hastings algorithm control parameters\n")
  cat(paste("Probability of shift proposal: p =", x$p, "\n"))
  if(x$fixing == "none") {
    cat(paste("Conditional probability of death proposal: q =", x$q, "\n"))
    if(!is.null(x$ptypes)) {
      cat("Birth proposal probabilities for each type of point:\n")
      print(x$ptypes)
    }
  }
  switch(x$fixing,
         none={},
         n.total=cat("The total number of points is fixed\n"),
         n.each.type=cat("The number of points of each type is fixed\n"))
  switch(x$condtype,
         none={},
         window={
           cat(paste("Conditional simulation given the",
                     "configuration in a subwindow\n"))
           print(x$x.cond$window)
         },
         Palm={
           cat("Conditional simulation of Palm type\n")
         })
  cat(paste("Number of M-H iterations: nrep =", x$nrep, "\n"))
  if(x$saving) 
    cat(paste("Save point pattern every", x$nsave, "iterations",
              "after a burn-in of", x$nburn, "iterations\n"))
  cat(paste("Track proposal type and acceptance/rejection?",
            if(x$track) "yes" else "no", "\n"))
  if(x$nverb > 0)
    cat(paste("Progress report every nverb=", x$nverb, "iterations\n"))
  else
    cat("No progress reports (nverb = 0).\n")

  # invoke print.rmhexpand
  print(x$expand)

  cat("Periodic edge correction? ")
  if(is.null(x$periodic)) cat("Not yet determined.\n") else 
  if(x$periodic) cat("Yes.\n") else cat("No.\n")
  #
  return(invisible(NULL))
}

default.rmhcontrol <- function(model) {
  # set default for 'expand'
  return(rmhcontrol(expand=default.expand(model)))
}

update.rmhcontrol <- function(object, ...) {
  do.call.matched("rmhcontrol.default",
                  resolve.defaults(list(...), as.list(object),
                                   .StripNull=TRUE))
}

rmhResolveControl <- function(control, model) {
  # adjust control information once the model is known
  stopifnot(inherits(control, "rmhcontrol"))
  # change *default* expansion rule to something appropriate for model
  # (applies only if expansion rule is undecided)
  control$expand <- change.default.expand(control$expand, default.expand(model))
  return(control)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rmhexpand.R"
#
#   rmhexpand.R
#
#   Rules/data for expanding the simulation window in rmh
#
#   $Revision: 1.7 $  $Date: 2014/10/24 00:22:30 $
#

# Establish names and rules for each type of expansion

RmhExpandRule <- local({

  .RmhExpandTable <-
  list(area=list(descrip ="Area expansion factor",
                 minval = 1,
                 expands = function(x) { unname(x) > 1 }),
       length=list(descrip ="Length expansion factor",
                   minval = 1,
                   expands = function(x) { unname(x) > 1 }),
       distance=list(descrip="Expansion buffer distance",
                     minval = 0,
                     expands = function(x) { unname(x) > 0 }))
  
  RmhExpandRule <- function(nama) {
    if(length(nama) == 0) nama <- "area"
    if(length(nama) > 1)
      stop("Internal error: too many names in RmhExpandRule", call.=FALSE)
    if(!(nama %in% names(.RmhExpandTable)))
      stop(paste("Internal error: unrecognised expansion type",
                 sQuote(nama)),
           call.=FALSE)
    return(.RmhExpandTable[[nama]])
  }
  RmhExpandRule
})
  
                        
rmhexpand <- function(x=NULL, ..., area=NULL, length=NULL, distance=NULL) {
  trap.extra.arguments(..., .Context="In rmhexpand")
  # check for incompatibility
  n <- (!is.null(x)) + (!is.null(area)) +
       (!is.null(length)) + (!is.null(distance))
  if(n > 1) stop("Only one argument should be given")
  # absorb other arguments into 'x'
  if(is.null(x) && n > 0) {
      if(!is.null(area)) x <- c(area=area)
      if(!is.null(length)) x <- c(length=length)
      if(!is.null(distance)) x <- c(distance=distance)
  }
  if(is.null(x)) {
    # No expansion rule supplied.
    # Use spatstat default, indicating that the user did not choose it.
    force.exp <- force.noexp <- FALSE
    x <- spatstat.options("expand")
    x <- rmhexpand(x)$expand
  } else {
    # process x
    if(inherits(x, "rmhexpand"))
      return(x)
    if(is.owin(x)) {
      force.exp <- TRUE
      force.noexp <- FALSE
    } else {
      # expecting c(name=value) or list(name=value)
      if(is.list(x))
        x <- unlist(x)
      if(!is.numeric(x))
        stop(paste("Expansion argument must be either",
                   "a number, a window, or NULL.\n"))
      # x is numeric
      check.1.real(x, "In rmhexpand(x)")
      explain.ifnot(is.finite(x), "In rmhexpand(x)")
      # an unlabelled numeric value is interpreted as an area expansion factor
      if(!any(nzchar(names(x))))
        names(x) <- "area"
      # validate
      rule <- RmhExpandRule(names(x))
      if(x < rule$minval) {
        warning(paste(rule$descrip, "<", rule$minval,
                      "has been reset to", rule$minval),
                call.=FALSE)
        x[] <- rule$minval
      }
      force.exp <- rule$expands(x)
      force.noexp <- !force.exp
    }
  }
  result <- list(expand=x, force.exp=force.exp, force.noexp=force.noexp)
  class(result) <- "rmhexpand"
  return(result)
}

.no.expansion <- list(expand=c(area=1), force.exp=FALSE, force.noexp=TRUE)
class(.no.expansion) <- "rmhexpand"

print.rmhexpand <- function(x, ..., prefix=TRUE) {
  if(prefix) cat("Expand the simulation window? ")
  if(x$force.noexp) {
    cat("No.\n")
  } else {
    if(x$force.exp) cat("Yes:\n") else cat("Not determined. Default is:\n")

    y <- x$expand
    if(is.null(y)) {
      print(rmhexpand(spatstat.options("expand")), prefix=FALSE)
    } else if(is.numeric(y)) {
      descrip <- RmhExpandRule(names(y))$descrip
      cat(paste("\t", descrip, unname(y), "\n"))
    } else {
      print(y)
    }
  }
  return(invisible(NULL))
}

summary.rmhexpand <- function(object, ...) {
  decided <- with(object, force.exp || force.noexp)
  ex <- object$expand
  if(is.null(ex))
    ex <- rmhexpand(spatstat.options("expand"))$expand
  if(is.owin(ex)) {
    willexpand <- TRUE
    descrip <- "Window"
  } else if(is.numeric(ex)) {
    rule <- RmhExpandRule(names(ex))
    descrip    <- rule$descrip
    willexpand <- if(object$force.exp) TRUE else
                  if(object$force.noexp) FALSE else
                  (unname(ex) > rule$minval)
  } else stop("Internal error: unrecognised format in summary.rmhexpand",
              call.=FALSE)
              
  out <- list(rule.decided=decided,
              window.decided=decided && is.owin(ex), 
              expand=ex,
              descrip=descrip,
              willexpand=willexpand)
  class(out) <- "summary.rmhexpand"
  return(out)
}

print.summary.rmhexpand <- function(x, ...) {
  cat("Expansion rule\n")
  ex <- x$expand
  if(x$window.decided) {
    cat("Window is decided.\n")
    print(ex)
  } else {
    if(x$rule.decided) {
      cat("Rule is decided.\n")
    } else {
      cat("Rule is not decided.\nDefault is:\n")
    }
    if(!x$willexpand) {
      cat("No expansion\n")
    } else {
      if(is.numeric(ex)) cat(paste(x$descrip, ex, "\n")) else print(ex)
    }
  }
  return(invisible(NULL))
}

expand.owin <- function(W, ...) {
  ex <- list(...)
  if(length(ex) > 1) stop("Too many arguments")
  # get an rmhexpand object
  if(inherits(ex[[1]], "rmhexpand")) {
    ex <- ex[[1]]
  } else ex <- do.call("rmhexpand", ex)
  f <- ex$expand
  if(is.null(f)) return(W)
  if(is.owin(f)) return(f)
  if(!is.numeric(f)) stop("Format not understood")
  switch(names(f),
         area = {
           if(f == 1)
             return(W)
           bb <- boundingbox(W)
           xr <- bb$xrange
           yr <- bb$yrange
           fff <- (sqrt(f) - 1)/2
           Wexp <- grow.rectangle(bb, fff * diff(xr), fff * diff(yr))
         },
         length = {
           if(f == 1)
             return(W)
           bb <- boundingbox(W)
           xr <- bb$xrange
           yr <- bb$yrange
           fff <- (f - 1)/2
           Wexp <- grow.rectangle(bb, fff * diff(xr), fff * diff(yr))
         },
         distance = {
           if(f == 0)
             return(W)
           Wexp <- if(is.rectangle(W)) grow.rectangle(W, f) else dilation(W, f)
         },
         stop("Internal error: unrecognised type")
         )
  return(Wexp)
}

will.expand <- function(x) {
  stopifnot(inherits(x, "rmhexpand"))
  if(x$force.exp) return(TRUE)
  if(x$force.noexp) return(FALSE)
  return(summary(x)$willexpand)
}

is.expandable <- function(x) { UseMethod("is.expandable") }

change.default.expand <- function(x, newdefault) {
  stopifnot(inherits(x, "rmhexpand"))
  decided <- with(x, force.exp || force.noexp)
  if(!decided)
    x$expand <- rmhexpand(newdefault)$expand
  return(x)
}

  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rmhmodel.R"
#
#
#   rmhmodel.R
#
#   $Revision: 1.63 $  $Date: 2014/12/27 06:21:03 $
#
#

rmhmodel <- function(...) {
  UseMethod("rmhmodel")
}


rmhmodel.rmhmodel <- function(model, ...) {
  # Check for outdated internal format
  # C.par was replaced by C.beta and C.ipar in spatstat 1.22-3 
  if(outdated <- !is.null(model$C.par))
    warning("Outdated internal format of rmhmodel object; rebuilding it")
  if(outdated || (length(list(...)) > 0))
    model <- rmhmodel.list(unclass(model), ...)
  return(model)
}

rmhmodel.list <- function(model, ...) {
  argnames <- c("cif","par","w","trend","types")
  ok <- argnames %in% names(model)
  do.call("rmhmodel.default",
          resolve.defaults(list(...), model[argnames[ok]]))
}

rmhmodel.default <- function(...,
                             cif=NULL, par=NULL, w=NULL, trend=NULL, types=NULL)
{
  extractsecret <- function(..., stopinvalid=TRUE) {
    if(length(list(...)) > 0)
      stop(paste("rmhmodel.default: syntax should be",
                 "rmhmodel(cif, par, w, trend, types)",
                 "with arguments given by name if they are present"),
           call.=FALSE)
    return(list(stopinvalid=stopinvalid))
  }
  stopinvalid <- extractsecret(...)$stopinvalid
  
  # Validate parameters
  if(is.null(cif)) stop("cif is missing or NULL")
  if(is.null(par)) stop("par is missing or NULL")

  if(!is.null(w))
    w <- as.owin(w)
  
  if(!is.character(cif))
    stop("cif should be a character string")

  betamultiplier <- 1

  Ncif <- length(cif)
  if(Ncif > 1) {
    # hybrid
    # check for Poisson components
    ispois <- (cif == 'poisson')
    if(any(ispois)) {
      # validate Poisson components
      Npois <- sum(ispois)
      poismodels <- vector(mode="list", length=Npois)
      parpois <- par[ispois]
      for(i in 1:Npois)
        poismodels[[i]] <- rmhmodel(cif='poisson', par=parpois[[i]],
                                    w=w, trend=NULL, types=types,
                                    stopinvalid=FALSE)
      # consolidate Poisson intensity parameters
      poisbetalist <- lapply(poismodels, function(x){x$C.beta})
      poisbeta <- Reduce("*", poisbetalist)
      if(all(ispois)) {
        # model collapses to a Poisson process
        cif <- 'poisson'
        Ncif <- 1
        par <- list(beta=poisbeta)
        betamultiplier <- 1
      } else {
        # remove Poisson components
        cif <- cif[!ispois]
        Ncif <- sum(!ispois)
        par <- par[!ispois]
        if(Ncif == 1) # revert to single-cif format
          par <- par[[1]]
        # absorb beta parameters 
        betamultiplier <- poisbeta
      }
    }
  }
  
  if(Ncif > 1) {
    # genuine hybrid 
    models <- vector(mode="list", length=Ncif)
    check <- vector(mode="list", length=Ncif)
    for(i in 1:Ncif) 
      models[[i]] <- rmhmodel(cif=cif[i], par=par[[i]],
                              w=w, trend=NULL, types=types,
                              stopinvalid=FALSE)
    C.id  <- unlist(lapply(models, function(x){x$C.id}))
    C.betalist <- lapply(models, function(x){x$C.beta})
    C.iparlist <- lapply(models, function(x){x$C.ipar})
    # absorb beta multiplier into beta parameter of first component
    C.betalist[[1]] <- C.betalist[[1]] * betamultiplier
    # concatenate for use in C
    C.beta     <- unlist(C.betalist)
    C.ipar     <- unlist(C.iparlist)
    check <- lapply(models, function(x){x$check})
    maxr <- max(unlist(lapply(models, function(x){x$reach})))
    ismulti <- unlist(lapply(models, function(x){x$multitype.interact}))
    multi <- any(ismulti)
    # determine whether model exists
    integ <- unlist(lapply(models, function(x) { x$integrable }))
    stabi <- unlist(lapply(models, function(x) { x$stabilising }))
    integrable <- all(integ) || any(stabi)
    stabilising <- any(stabi)
    # string explanations of conditions for validity
    integ.ex <- unlist(lapply(models, function(x){ x$explainvalid$integrable }))
    stabi.ex <- unlist(lapply(models, function(x){ x$explainvalid$stabilising}))
    stabi.oper <- !(stabi.ex %in% c("TRUE", "FALSE"))
    integ.oper <- !(integ.ex %in% c("TRUE", "FALSE"))
    compnames <- if(!anyDuplicated(C.id)) paste("cif", sQuote(C.id)) else 
         paste("component", 1:Ncif, paren(sQuote(C.id)))
    if(!integrable && stopinvalid) {
      # model is not integrable: explain why
      ifail <- !integ & integ.oper
      ireason <- paste(compnames[ifail], "should satisfy",
                       paren(integ.ex[ifail], "{"))
      ireason <- verbalogic(ireason, "and")
      if(sum(ifail) <= 1) {
        # There's only one offending cif, so stability is redundant
        sreason <- "FALSE"
      } else {
        sfail <- !stabi & stabi.oper
        sreason <- paste(compnames[sfail], "should satisfy",
                         paren(stabi.ex[sfail], "{"))
        sreason <- verbalogic(sreason, "or")
      }
      reason <- verbalogic(c(ireason, sreason), "or")
      stop(paste("rmhmodel: hybrid model is not integrable; ", reason),
           call.=FALSE)
    } else {
      # construct strings summarising conditions for validity
      if(!any(integ.oper))
        ireason <- as.character(integrable)
      else {
        ireason <- paste(compnames[integ.oper], "should satisfy",
                         paren(integ.ex[integ.oper], "{"))
        ireason <- verbalogic(ireason, "and")
      }
      if(!any(stabi.oper))
        sreason <- as.character(stabilising)
      else {
        sreason <- paste(compnames[stabi.oper], "should satisfy",
                         paren(stabi.ex[stabi.oper], "{"))
        sreason <- verbalogic(sreason, "or")
      }
      ireason <- verbalogic(c(ireason, sreason), "or")
      explainvalid <- list(integrable=ireason,
                           stabilising=sreason)
    }

    out <- list(cif=cif,
                par=par,
                w=w,
                trend=trend,
                types=types,
                C.id=C.id,
                C.beta=C.beta,
                C.ipar=C.ipar,
                C.betalist=C.betalist,
                C.iparlist=C.iparlist,
                check=check,
                multitype.interact=multi,
                integrable=integrable,
                stabilising=stabilising,
                explainvalid=explainvalid,
                reach=maxr)
    class(out) <- c("rmhmodel", class(out))
    return(out)
  }

  # non-hybrid
  
  # Check that this is a recognised model
  # and look up the rules for this model
  rules <- spatstatRmhInfo(cif)
  
  # Map the name of the cif from R to C
  #      (the names are normally identical in R and C,
  #      except "poisson" -> NA)
  C.id <- rules$C.id
  
  # Check that the C name is recognised in C 
  if(!is.na(C.id)) {
    z <- .C("knownCif",
            cifname=as.character(C.id),
            answer=as.integer(0))
#            PACKAGE="spatstat")
    ok <- as.logical(z$answer)
    if(!ok)
      stop(paste("Internal error: the cif", sQuote(C.id),
                 "is not recognised in the C code"))
  }

  # Validate the model parameters and reformat them 
  check <- rules$parhandler
  checkedpar <-
    if(!rules$multitype)
      check(par)
    else if(!is.null(types))
      check(par, types)
    else 
      # types vector not given - defer checking
      NULL

  if(!is.null(checkedpar)) {
    stopifnot(is.list(checkedpar))
    stopifnot(!is.null(names(checkedpar)) && all(nzchar(names(checkedpar))))
    stopifnot(names(checkedpar)[[1]] == "beta")
    C.beta  <- unlist(checkedpar[[1]])
    C.beta <- C.beta * betamultiplier
    C.ipar <- as.numeric(unlist(checkedpar[-1]))
  } else {
    C.beta <- C.ipar <- NULL
  }
  
  # Determine whether model is integrable
  integrable <- rules$validity(par, "integrable")
  explainvalid  <- rules$explainvalid

  if(!integrable && stopinvalid) 
    stop(paste("rmhmodel: the model is not integrable; it should satisfy",
               explainvalid$integrable),
         call.=FALSE)
  
  # Determine whether cif is stabilising
  # (i.e. any hybrid including this cif will be integrable)
  stabilising <- rules$validity(par, "stabilising")

  # Calculate reach of model
  mreach <- rules$reach(par)

  
###################################################################
# return augmented list  
  out <- list(cif=cif,
              par=par,
              w=w,
              trend=trend,
              types=types,
              C.id=C.id,
              C.beta=C.beta,
              C.ipar=C.ipar,
              check= if(is.null(C.ipar)) check else NULL,
              multitype.interact=rules$multitype,
              integrable=integrable,
              stabilising=stabilising,
              explainvalid=explainvalid,
              reach=mreach
              )
  class(out) <- c("rmhmodel", class(out))
  return(out)
}

print.rmhmodel <- function(x, ...) {
  verifyclass(x, "rmhmodel")

  cat("Metropolis-Hastings algorithm, model parameters\n")

  Ncif <- length(x$cif)
  cat(paste("Conditional intensity:",
            if(Ncif == 1) "cif=" else "hybrid of cifs",
            commasep(sQuote(x$cif)), "\n"))
  
  if(!is.null(x$types)) {
    if(length(x$types) == 1)
      cat("Univariate process.\n")
    else {
      cat("Multitype process with types =\n")
      print(x$types)
      if(!x$multitype.interact)
        cat("Interaction does not depend on type\n")
    }
  } else if(x$multitype.interact) 
    cat("Multitype process, types not yet specified.\n")
  
  cat("Numerical parameters: par =\n")
  print(x$par)
  if(is.null(x$C.ipar))
    cat("Parameters have not yet been checked for compatibility with types.\n")
  if(is.owin(x$w)) print(x$w) else cat("Window: not specified.\n")
  cat("Trend: ")
  if(!is.null(x$trend)) print(x$trend) else cat("none.\n")
  if(!is.null(x$integrable) && !x$integrable) {
    cat("\n*Warning: model is not integrable and cannot be simulated*\n")
  }
  invisible(NULL)
}

reach.rmhmodel <- function(x, ...) {
  if(length(list(...)) == 0)
    return(x$reach)
  # reach must be recomputed 
  cif <- x$cif
  Ncif <- length(cif)
  pars <- if(Ncif == 1) list(x$par) else x$par
  maxr <- 0
  for(i in seq_len(Ncif)) {
    cif.i <- cif[i]
    par.i <- pars[[i]]
    rules <- spatstatRmhInfo(cif.i)
    rchfun  <- rules$reach
    if(!is.function(rchfun))
      stop(paste("Internal error: reach is unknown for cif=", sQuote(cif.i)),
           call.=FALSE)
    r.i <- rchfun(par.i, ...)
    maxr <- max(maxr, r.i, na.rm=TRUE)
  }
  return(maxr)
}

is.poisson.rmhmodel <- function(x) {
  verifyclass(x, "rmhmodel")
  identical(x$cif, 'poisson')
}

is.stationary.rmhmodel <- function(x) {
  verifyclass(x, "rmhmodel")
  tren <- x$trend
  return(is.null(tren) || is.numeric(tren))
}

as.owin.rmhmodel <- function(W, ..., fatal=FALSE) {
  # W is the rmhmodel object. It contains a window w
  ans <- W$w
  if(is.owin(ans)) return(ans)
  if(fatal) stop("rmhmodel object does not contain a window")
  return(NULL)
}

domain.rmhmodel <- Window.rmhmodel <- function(X, ...) { as.owin(X) }

is.expandable.rmhmodel <- function(x) {
  tren <- x$tren
  ok <- function(z) { is.null(z) || is.numeric(z) || is.function(z) }
  return(if(!is.list(tren)) ok(tren) else all(unlist(lapply(tren, ok))))
}

  
#####  Table of rules for handling rmh models ##################

spatstatRmhInfo <- function(cifname) {
  rules <- .Spatstat.RmhTable[[cifname]]
  if(is.null(rules))
    stop(paste("Unrecognised cif:", sQuote(cifname)), call.=FALSE)
  return(rules)
}
  
.Spatstat.RmhTable <-
  list(
#
# 0. Poisson (special case)
#
       'poisson'=
       list(
            C.id=NA,
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the Poisson process"
              with(par, forbidNA(beta, ctxt))
              par <- check.named.list(par, "beta", ctxt)
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              return(par)
            },
            validity=function(par, kind) {
              switch(kind,
                     integrable=TRUE,
                     stabilising=FALSE)
            },
            explainvalid=list(integrable="TRUE",stabilising="FALSE"),
            reach = function(par, ...) { return(0) },
            hardcore = function(par, ...) { return(0) }
            ),
#       
# 1. Strauss.
#       
       'strauss'=
       list(
            C.id="strauss",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the strauss cif"
              par <- check.named.list(par, c("beta","gamma","r"), ctxt)
              # treat r=NA as absence of interaction
              par <- within(par, if(is.na(r)) { r <- 0; gamma <- 1 })
              with(par, check.finite(beta, ctxt))
              with(par, check.finite(gamma, ctxt))
              with(par, check.finite(r, ctxt))
              with(par, check.1.real(gamma, ctxt))
              with(par, check.1.real(r,     ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              with(par, explain.ifnot(gamma >= 0, ctxt))
              with(par, explain.ifnot(r >= 0, ctxt))
              return(par)
            },
            validity=function(par, kind) {
              gamma <- par$gamma
              switch(kind,
                     integrable=(gamma <= 1),
                     stabilising=(gamma == 0)
                     )
            },
            explainvalid=list(
              integrable="gamma <= 1",
              stabilising="gamma == 0"),
            reach = function(par, ...) {
              r <- par[["r"]]
              g <- par[["gamma"]]
              return(if(g == 1) 0 else r)
            },
            hardcore = function(par, ..., epsilon=0) {
              r <- par[["r"]]
              g <- par[["gamma"]]
              return(if(g <= epsilon) r else 0)
            }
            ),
#       
# 2. Strauss with hardcore.
#       
       'straush' =
       list(
            C.id="straush",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the straush cif"
              par <- check.named.list(par, c("beta","gamma","r","hc"), ctxt)
              # treat hc=NA as absence of hard core
              par <- within(par, if(is.na(hc)) { hc <- 0 } )
              # treat r=NA as absence of interaction
              par <- within(par, if(is.na(r)) { r <- hc; gamma <- 1 } )
              with(par, check.finite(beta, ctxt))
              with(par, check.finite(gamma, ctxt))
              with(par, check.finite(r, ctxt))
              with(par, check.finite(hc, ctxt))
              with(par, check.1.real(gamma, ctxt))
              with(par, check.1.real(r,     ctxt))
              with(par, check.1.real(hc,     ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              with(par, explain.ifnot(gamma >= 0, ctxt))
              with(par, explain.ifnot(r >= 0, ctxt))
              with(par, explain.ifnot(hc >= 0, ctxt))
              with(par, explain.ifnot(hc <= r, ctxt))
              return(par)
            },
            validity=function(par, kind) {
              hc <- par$hc
              gamma <- par$gamma
              switch(kind,
                     integrable=(hc > 0 || gamma <= 1),
                     stabilising=(hc > 0)
                   )
            },
            explainvalid=list(
              integrable="hc > 0 or gamma <= 1",
              stabilising="hc > 0"),
            reach = function(par, ...) {
              h <- par[["hc"]]
              r <- par[["r"]]
              g <- par[["gamma"]]
              return(if(g == 1) h else r)
            },
            hardcore = function(par, ..., epsilon=0) {
              h <- par[["hc"]]
              r <- par[["r"]]
              g <- par[["gamma"]]
              return(if(g <= epsilon) r else h)
            }
            ),
#       
# 3. Softcore.
#
       'sftcr' =
       list(
            C.id="sftcr",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the sftcr cif"
              par <- check.named.list(par, c("beta","sigma","kappa"), ctxt)
              with(par, check.finite(beta, ctxt))
              with(par, check.finite(sigma, ctxt))
              with(par, check.finite(kappa, ctxt))
              with(par, check.1.real(sigma, ctxt))
              with(par, check.1.real(kappa, ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              with(par, explain.ifnot(sigma >= 0, ctxt))
              with(par, explain.ifnot(kappa >= 0 && kappa <= 1, ctxt))
              return(par)
            },
            validity=function(par, kind) {
              switch(kind,
                     integrable=TRUE,
                     stabilising=FALSE)
            },
            explainvalid=list(integrable="TRUE",stabilising="FALSE"),
            reach = function(par, ..., epsilon=0) {
              if(epsilon==0)
                return(Inf)
              kappa <- par[["kappa"]]
              sigma <- par[["sigma"]]
              return(sigma/(epsilon^(kappa/2)))
            },
            hardcore = function(par, ..., epsilon=0) {
              if(epsilon==0)
                return(0)
              kappa <- par[["kappa"]]
              sigma <- par[["sigma"]]
              return(sigma/((-log(epsilon))^(kappa/2)))
            }
            ),
#       
# 4. Multitype Strauss.
#       
       'straussm' =
       list(
            C.id="straussm",
            multitype=TRUE,
            parhandler=function(par, types) {
              ctxt <- "For the straussm cif"
              par <- check.named.list(par, c("beta","gamma","radii"), ctxt)

              beta <- par$beta
              gamma <- par$gamma
              r <- par$radii
              ntypes <- length(types)

              check.finite(beta, ctxt)
              check.nvector(beta, ntypes, TRUE, "types")

              MultiPair.checkmatrix(gamma, ntypes, "par$gamma")
	      gamma[is.na(gamma)] <- 1
              check.finite(gamma, ctxt)

              MultiPair.checkmatrix(r, ntypes, "par$radii")
              if(any(nar <- is.na(r))) {
                r[nar] <- 0
                gamma[nar] <- 1
              }
              check.finite(r, ctxt)

              explain.ifnot(all(beta >= 0), ctxt)
              explain.ifnot(all(gamma >= 0), ctxt)
              explain.ifnot(all(r >= 0), ctxt)

              par <- list(beta=beta, gamma=gamma, r=r)
              return(par)
            }, 
            validity=function(par, kind) {
              gamma <- par$gamma
              radii <- par$radii
              dg <- diag(gamma)
              dr <- diag(radii)
              hard <-!is.na(dg) & (dg == 0) & !is.na(dr) & (dr > 0)
              operative <- !is.na(gamma) & !is.na(radii) & (radii > 0)
              switch(kind,
                     stabilising=all(hard),
                     integrable=all(hard) || all(gamma[operative] <= 1))
            },
            explainvalid=list(
              integrable=paste(
                "gamma[i,j] <= 1 for all i and j,",
                "or gamma[i,i] = 0 for all i"),
              stabilising="gamma[i,i] = 0 for all i"),
            reach = function(par, ...) {
              r <- par$radii
              g <- par$gamma
              operative <- ! (is.na(r) | (g == 1))
              return(max(0, r[operative]))
            },
            hardcore = function(par, ..., epsilon=0) {
              r <- par$radii
              g <- par$gamma
              return(max(0, r[!is.na(r) & g <= epsilon]))
            }
            ),
#       
# 5. Multitype Strauss with hardcore.
#       
       'straushm' = 
       list(
            C.id="straushm",
            multitype=TRUE,
            parhandler=function(par, types) {
              ctxt="For the straushm cif"
              par <- check.named.list(par,
                                      c("beta","gamma","iradii","hradii"),
                                      ctxt)

              beta <- par$beta
              gamma <- par$gamma
              iradii <- par$iradii
              hradii <- par$hradii
              ntypes <- length(types)

              check.nvector(beta, ntypes, TRUE, "types")
              check.finite(beta, ctxt)
              
              MultiPair.checkmatrix(gamma, ntypes, "par$gamma")
              gamma[is.na(gamma)] <- 1
              check.finite(gamma, ctxt)

              MultiPair.checkmatrix(iradii, ntypes, "par$iradii")
              if(any(nar <- is.na(iradii))) {
                iradii[nar] <- 0
                gamma[nar] <- 1
              }
              check.finite(iradii, ctxt)

              MultiPair.checkmatrix(hradii, ntypes, "par$hradii")
              hradii[is.na(hradii)] <- 0
              check.finite(hradii, ctxt)

              explain.ifnot(all(beta >= 0), ctxt)
              explain.ifnot(all(gamma >= 0), ctxt)
              explain.ifnot(all(iradii >= 0), ctxt)
              explain.ifnot(all(hradii >= 0), ctxt)
              explain.ifnot(all(iradii >= hradii), ctxt)

              par <- list(beta=beta,gamma=gamma,iradii=iradii,hradii=hradii)
              return(par)
            },
            validity=function(par, kind) {
              gamma <- par$gamma
              iradii <- par$iradii
              hradii <- par$hradii
              dh <- diag(hradii)
              dg <- diag(gamma)
              dr <- diag(iradii)
              hhard <- !is.na(dh) & (dh > 0)
              ihard <- !is.na(dr) & (dr > 0) & !is.na(dg) & (dg == 0)
              hard <- hhard | ihard
              operative <- !is.na(gamma) & !is.na(iradii) & (iradii > 0)
              switch(kind,
                     stabilising=all(hard),
                     integrable={
                       all(hard) || all(gamma[operative] <= 1)
                     })
            },
            explainvalid=list(
              integrable=paste(
                "hradii[i,i] > 0 or gamma[i,i] = 0 for all i, or",
                "gamma[i,j] <= 1 for all i and j"),
              stabilising="hradii[i,i] > 0 or gamma[i,i] = 0 for all i"),
            reach=function(par, ...) {
              r <- par$iradii
              h <- par$hradii
              g <- par$gamma
              roperative <- ! (is.na(r) | (g == 1))
              hoperative <- ! is.na(h)
              return(max(0, r[roperative], h[hoperative]))
            },
            hardcore = function(par, ..., epsilon=0) {
              r <- par$radii
              h <- par$hradii
              g <- par$gamma
              return(max(h[!is.na(h)],
                         r[!is.na(r) & g <= epsilon]))
            }
            ),
#       
# 6. Diggle-Gates-Stibbard interaction
#    (function number 1 from Diggle, Gates, and Stibbard)
       
       'dgs' = 
       list(
            C.id="dgs",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the dgs cif"
              par <- check.named.list(par, c("beta","rho"), ctxt)
              with(par, check.finite(beta, ctxt))
              with(par, check.finite(rho, ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              with(par, check.1.real(rho, ctxt))
              with(par, explain.ifnot(rho >= 0, ctxt))
              return(par)
            },
            validity=function(par, kind) {
              switch(kind,
                     integrable=TRUE,
                     stabilising=FALSE)
            },
            explainvalid=list(integrable="TRUE", stabilising="FALSE"),
            reach=function(par, ...) {
              return(par[["rho"]])
            },
            hardcore=function(par, ..., epsilon=0) {
              if(epsilon == 0) return(0)
              return(par[["rho"]] * (2/pi) * asin(sqrt(epsilon)))
            }
            ),
#
# 7. Diggle-Gratton interaction 
#    (function number 2 from Diggle, Gates, and Stibbard).

       'diggra' =
       list(
            C.id="diggra",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the diggra cif"
              par <- check.named.list(par, c("beta","kappa","delta","rho"),
                                      ctxt)
              with(par, check.finite(beta, ctxt))
              with(par, check.finite(kappa, ctxt))
              with(par, check.finite(delta, ctxt))
              with(par, check.finite(rho, ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              with(par, check.1.real(kappa, ctxt))
              with(par, check.1.real(delta, ctxt))
              with(par, check.1.real(rho,   ctxt))
              with(par, explain.ifnot(kappa >= 0, ctxt))              
              with(par, explain.ifnot(delta >= 0, ctxt))              
              with(par, explain.ifnot(rho >= 0, ctxt))              
              with(par, explain.ifnot(delta < rho, ctxt))              
              return(par)
            },
            validity=function(par, kind) {
              switch(kind,
                     integrable=TRUE,
                     stabilising=FALSE)
            },
            explainvalid=list(integrable="TRUE",stabilising="FALSE"),
            reach=function(par, ...) {
              return(par[["rho"]])
            },
            hardcore=function(par, ..., epsilon=0) {
              return(par[["delta"]])
            }
            ),
#       
# 8. Geyer saturation model
#       
       'geyer' = 
       list(
            C.id="geyer",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the geyer cif"
              par <- check.named.list(par, c("beta","gamma","r","sat"), ctxt)
              with(par, check.1.real(gamma, ctxt))
              with(par, check.1.real(r,     ctxt))
              with(par, check.1.real(sat,   ctxt))
              par <- within(par, sat <- min(sat, .Machine$integer.max-100))
              par <- within(par, if(is.na(gamma)) { r <- 0; gamma <- 1 })
              with(par, check.finite(beta, ctxt))
              with(par, check.finite(gamma, ctxt))
              with(par, check.finite(r, ctxt))
              with(par, check.finite(sat, ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              return(par)
            },
            validity=function(par, kind) {
              switch(kind,
                     integrable=TRUE,
                     stabilising=FALSE)
            },
            explainvalid=list(integrable="TRUE", stabilising="FALSE"),
            reach = function(par, ...) {
              r <- par[["r"]]
              g <- par[["gamma"]]
              return(if(g == 1) 0 else 2 * r)
            },
            hardcore = function(par, ..., epsilon=0) {
              r <- par[["r"]]
              g <- par[["gamma"]]
              return(if(g <= epsilon) r else 0)
            }
            ),
#       
# 9. The ``lookup'' device.  This permits simulating, at least
# approximately, ANY pairwise interaction function model
# with isotropic pair interaction (i.e. depending only on distance).
# The pair interaction function is provided as a vector of
# distances and corresponding function values which are used
# as a ``lookup table'' by the C code.
#
       'lookup' = 
       list(
            C.id="lookup",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the lookup cif"
              par <- check.named.list(par, c("beta","h"), ctxt, "r")
              with(par, check.finite(beta, ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              beta   <- par[["beta"]]
              h.init <- par[["h"]]
              r      <- par[["r"]]
              if(is.null(r)) {
		if(!is.stepfun(h.init))
                  stop(paste("For cif=lookup, if component r of",
                             "par is absent then component h must",
                             "be a stepfun object."))
		if(!is.cadlag(h.init))
                  stop(paste("The lookup pairwise interaction step",
			     "function must be right continuous,\n",
			     "i.e. built using the default values of the",
                             sQuote("f"), "and", sQuote("right"),
                             "arguments for stepfun."))
		r     <- knots(h.init)
		h0    <- get("yleft",envir=environment(h.init))
		h     <- h.init(r)
		nlook <- length(r)
		if(!identical(all.equal(h[nlook],1),TRUE))
                  stop(paste("The lookup interaction step function",
                             "must be equal to 1 for", dQuote("large"),
                             "distances."))
		if(r[1] <= 0)
                  stop(paste("The first jump point (knot) of the lookup",
                             "interaction step function must be",
                             "strictly positive."))
		h <- c(h0,h)
              } else {
		h     <- h.init
		nlook <- length(r)
		if(length(h) != nlook)
                  stop("Mismatch of lengths of h and r lookup vectors.")
		if(any(is.na(r)))
                  stop("Missing values not allowed in r lookup vector.")
		if(is.unsorted(r))
                  stop("The r lookup vector must be in increasing order.")
		if(r[1] <= 0)
                  stop(paste("The first entry of the lookup vector r",
                             "should be strictly positive."))
		h <- c(h,1)
              }
              if(any(h < 0))
		stop(paste("Negative values in the lookup",
                           "pairwise interaction function."))
              if(h[1] > 0 & any(h > 1))
		stop(paste("Lookup pairwise interaction function does",
                           "not define a valid point process."))
              rmax   <- r[nlook]
              r <- c(0,r)
              nlook <- nlook+1
              deltar <- mean(diff(r))
              if(identical(all.equal(diff(r),rep.int(deltar,nlook-1)),TRUE)) {
		par <- list(beta=beta,nlook=nlook,
                            equisp=1,
                            deltar=deltar,rmax=rmax, h=h)
              } else {
		par <- list(beta=beta,nlook=nlook,
                            equisp=0,
                            deltar=deltar,rmax=rmax, h=h,
                            r=r)
              }
              return(par) 
            },
            validity=function(par, kind) {
              h <- par$h
              if(is.stepfun(h))
                h <- eval(expression(c(yleft,y)),envir=environment(h))
              switch(kind,
                     integrable={
                       (h[1] == 0) || all(h <= 1)
                     },
                     stabilising={ h[1] == 0 })
            },
            explainvalid=list(
              integrable="h[1] == 0 or h[i] <= 1 for all i",
              stabilising="h[1] == 0"),
            reach = function(par, ...) {
              r <- par[["r"]]
              h <- par[["h"]]
              if(is.null(r)) 
                r <- knots(h)
              return(max(r))
            },
            hardcore = function(par, ..., epsilon=0) {
              r <- par[["r"]]
              h <- par[["h"]]
              if(is.null(r)) 
                r <- knots(h)
              return(max(0, r[h <= epsilon]))
            }
            ),
#       
# 10. Area interaction
#       
       'areaint'=
       list(
            C.id="areaint",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the areaint cif"
              par <- check.named.list(par, c("beta","eta","r"), ctxt)
              par <- within(par, if(is.na(r)) { r <- 0 })
              with(par, check.finite(beta, ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              with(par, check.1.real(eta, ctxt))
              with(par, check.1.real(r,   ctxt))
              with(par, check.finite(eta, ctxt))
              with(par, check.finite(r,   ctxt))
              with(par, explain.ifnot(eta >= 0, ctxt))
              with(par, explain.ifnot(r >= 0,   ctxt))
              return(par)
            },
            validity=function(par, kind) {
              switch(kind,
                     integrable=TRUE,
                     stabilising=FALSE)
            },
            explainvalid=list(integrable="TRUE", stabilising="FALSE"),
            reach = function(par, ...) {
              r <- par[["r"]]
              eta <- par[["eta"]]
              return(if(eta == 1) 0 else (2 * r))
            },
            hardcore = function(par, ..., epsilon=0) {
              r <- par[["r"]]
              eta <- par[["eta"]]
              if(eta > epsilon) return(0)
              if(eta == 0) return(2 * r)
              # linear approximation
              return(2 * r * eta/epsilon)
            }
            ),
#
# 11. The ``badgey'' (Baddeley-Geyer) model.
#
       'badgey' =
       list(
            C.id="badgey",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the badgey cif"
              par <- check.named.list(par, c("beta","gamma","r","sat"), ctxt)
              par <- within(par, sat <- pmin(sat, .Machine$integer.max-100))
              par <- within(par, gamma[is.na(gamma) | is.na(r)] <- 1)
              par <- within(par, r[is.na(r)] <- 0)
              with(par, check.finite(beta, ctxt))
              with(par, check.finite(gamma, ctxt))
              with(par, check.finite(r, ctxt))
              with(par, check.finite(sat, ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              with(par, explain.ifnot(all(gamma >= 0), ctxt))
              with(par, explain.ifnot(all(r >= 0), ctxt))
              with(par, explain.ifnot(all(sat >= 0), ctxt))
              with(par, explain.ifnot(length(gamma) == length(r), ctxt)) 
              gamma <- par[["gamma"]]
              r     <- par[["r"]]
              sat   <- par[["sat"]]
              if(length(sat)==1) sat <- rep.int(sat,length(gamma))
              else explain.ifnot(length(sat) == length(gamma), ctxt)
              mmm <- cbind(gamma,r,sat)
              mmm <- mmm[fave.order(r),]
              ndisc <- length(r)
              par <- list(beta=par$beta,ndisc=ndisc,parms=as.vector(t(mmm)))
              return(par)
            },
            validity=function(par, kind) {
              switch(kind,
                     integrable=TRUE,
                     stabilising=FALSE)
            },
            explainvalid=list(integrable="TRUE", stabilising="FALSE"),
            reach = function(par, ...) {
              r <- par[["r"]]
              gamma <- par[["gamma"]]
              operative <- (gamma != 1)
              return(if(!any(operative)) 0 else (2 * max(r[operative])))
            },
            hardcore = function(par, ..., epsilon=0) {
              r <- par[["r"]]
              gamma <- par[["gamma"]]
              return(max(0, r[gamma <= epsilon]))
            }
            ),
#
# 12. The hard core process
       'hardcore' =
       list(
            C.id="hardcore",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the hardcore cif"
              par <- check.named.list(par, c("beta", "hc"), ctxt)
              par <- within(par, if(is.na(hc)) { hc <- 0 })
              with(par, check.finite(beta, ctxt))
              with(par, check.finite(hc, ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              with(par, check.1.real(hc, ctxt))
              return(par)
            },
            validity=function(par, kind) {
              hc <- par$hc
              switch(kind,
                     integrable=TRUE,
                     stabilising=(hc > 0))
            },
            explainvalid=list(integrable="TRUE", stabilising="hc > 0"),
            reach = function(par, ...) {
              hc <- par[["hc"]]
              return(hc)
            },
            hardcore = function(par, ...) {
              hc <- par[["hc"]]
              return(hc)
            }
            ),
#
# Lucky 13. Fiksel process
       'fiksel' =
       list(
            C.id="fiksel",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the Fiksel cif"
              par <- check.named.list(par,
                                      c("beta", "r", "hc", "kappa", "a"),
                                      ctxt)
              with(par, check.finite(beta, ctxt))
              with(par, check.finite(r, ctxt))
              with(par, check.finite(hc, ctxt))
              with(par, check.finite(kappa, ctxt))
              with(par, check.finite(a, ctxt))
              with(par, check.1.real(r, ctxt))
              with(par, check.1.real(hc, ctxt))
              with(par, check.1.real(kappa, ctxt))
              with(par, check.1.real(a, ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              with(par, explain.ifnot(hc >= 0, ctxt))
              with(par, explain.ifnot(r > hc, ctxt))
              return(par)
            },
            validity=function(par, kind) {
              hc <- par$hc
              a  <- par$a
              switch(kind,
                     integrable=(hc > 0 || a <= 0),
                     stabilising=(hc > 0))
            },
            explainvalid=list(
              integrable="hc > 0 or a <= 0",
              stabilising="hc > 0"),
            reach = function(par, ...) {
              r <- par[["r"]]
              hc <- par[["hc"]]              
              a <- par[["a"]]
              return(if(a != 0) r else hc)
            },
            hardcore = function(par, ...) {
              return(par[["hc"]])
            }
            ),
#
# 14. Lennard-Jones
       'lennard' =
       list(
            C.id="lennard",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the Lennard-Jones cif"
              par <- check.named.list(par,
                                      c("beta", "sigma", "epsilon"),
                                      ctxt)
              with(par, check.finite(beta, ctxt))
              with(par, check.finite(sigma, ctxt))
              with(par, check.finite(epsilon, ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              with(par, check.1.real(sigma, ctxt))
              with(par, check.1.real(epsilon, ctxt))
              with(par, explain.ifnot(sigma > 0, ctxt))
              with(par, explain.ifnot(epsilon > 0, ctxt))
              return(par)
            },
            validity=function(par, kind) {
              switch(kind,
                     integrable=(par$sigma > 0),
                     stabilising=FALSE)
            },
            explainvalid=list(
              integrable="sigma > 0",
              stabilising="FALSE"),
            reach = function(par, ...) {
              sigma <- par[["sigma"]]
              return(2.5 * sigma)
            },
            hardcore = function(par, ...) {
              sigma <- par[["sigma"]]
              return(sigma/2.5)
            }
            ),
#       
# 15. Multitype hardcore.
#       
       'multihard' = 
       list(
            C.id="multihard",
            multitype=TRUE,
            parhandler=function(par, types) {
              ctxt="For the multihard cif"
              par <- check.named.list(par,
                                      c("beta","hradii"),
                                      ctxt)

              beta <- par$beta
              hradii <- par$hradii
              ntypes <- length(types)

              check.nvector(beta, ntypes, TRUE, "types")
              check.finite(beta, ctxt)
              
              MultiPair.checkmatrix(hradii, ntypes, "par$hradii")
              hradii[is.na(hradii)] <- 0
              check.finite(hradii, ctxt)

              explain.ifnot(all(beta >= 0), ctxt)
              explain.ifnot(all(hradii >= 0), ctxt)

              par <- list(beta=beta,hradii=hradii)
              return(par)
            },
            validity=function(par, kind) {
              switch(kind,
                     integrable=return(TRUE),
                     stabilising={
                       hself <- diag(par$hradii)
                       repel <- !is.na(hself) & (hself > 0)
                       return(all(repel))
                     })
            },
            explainvalid=list(
              integrable="TRUE",
              stabilising="hradii[i,i] > 0 for all i"),
            reach=function(par, ...) {
              return(max(0, par$hradii, na.rm=TRUE))
            },
            hardcore=function(par, ..., epsilon=0) {
              return(max(0, par$hradii, na.rm=TRUE))
            }
            ),
#       
# 16. Triplets.
#       
       'triplets'=
       list(
            C.id="triplets",
            multitype=FALSE,
            parhandler=function(par, ...) {
              ctxt <- "For the triplets cif"
              par <- check.named.list(par, c("beta","gamma","r"), ctxt)
              # treat r=NA as absence of interaction
              par <- within(par, if(is.na(r)) { r <- 0; gamma <- 1 })
              with(par, check.finite(beta, ctxt))
              with(par, check.finite(gamma, ctxt))
              with(par, check.finite(r, ctxt))
              with(par, check.1.real(gamma, ctxt))
              with(par, check.1.real(r,     ctxt))
              with(par, explain.ifnot(all(beta >= 0), ctxt))
              with(par, explain.ifnot(gamma >= 0, ctxt))
              with(par, explain.ifnot(r >= 0, ctxt))
              return(par)
            },
            validity=function(par, kind) {
              gamma <- par$gamma
              switch(kind,
                     integrable=(gamma <= 1),
                     stabilising=(gamma == 0)
                     )
            },
            explainvalid=list(
              integrable="gamma <= 1",
              stabilising="gamma == 0"),
            reach = function(par, ...) {
              r <- par[["r"]]
              g <- par[["gamma"]]
              return(if(g == 1) 0 else r)
            },
            hardcore = function(par, ...) {
              return(0)
            }
            )
       # end of list '.Spatstat.RmhTable'
       )


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rmhmodel.ppm.R"
#
#  rmhmodel.ppm.R
#
#   convert ppm object into format palatable to rmh.default
#
#  $Revision: 2.59 $   $Date: 2014/12/09 08:49:17 $
#
#   .Spatstat.rmhinfo
#   rmhmodel.ppm()
#

.Spatstat.Rmhinfo <-
list(
     "Multitype Hardcore process" =
     function(coeffs, inte) {
       # hard core radii r[i,j]
       hradii <- inte$par$hradii
       return(list(cif='multihard',
                   par=list(hradii=hradii),
                   ntypes=ncol(hradii)))
     },
     "Lennard-Jones process" =
     function(coeffs, inte) {
       sigma   <- inte$par$sigma
       epsilon <- inte$par$epsilon
       return(list(cif='lennard',
                   par=list(sigma=sigma, epsilon=epsilon),
                   ntypes=1))
     },
     "Fiksel process" =
     function(coeffs, inte) {
       hc <- inte$par$hc
       r  <- inte$par$r
       kappa <- inte$par$kappa
       a <- inte$interpret(coeffs,inte)$param$a
       return(list(cif='fiksel',
                   par=list(r=r,hc=hc,kappa=kappa,a=a),
                   ntypes=1))
     },
     "Diggle-Gates-Stibbard process" =
     function(coeffs, inte) {
       rho   <- inte$par$rho
       return(list(cif='dgs',
                   par=list(rho=rho),
                   ntypes=1))
     },
     "Diggle-Gratton process" =
     function(coeffs, inte) {
       kappa <- inte$interpret(coeffs,inte)$param$kappa
       delta <- inte$par$delta
       rho   <- inte$par$rho
       return(list(cif='diggra',
                   par=list(kappa=kappa,delta=delta,rho=rho),
                   ntypes=1))
     },
     "Hard core process" =
     function(coeffs, inte) {
       hc <- inte$par$hc
       return(list(cif='hardcore',
                   par=list(hc=hc),
                   ntypes=1))
     },
     "Geyer saturation process" =
     function(coeffs, inte) {
       gamma <- inte$interpret(coeffs,inte)$param$gamma
       r <- inte$par$r
       sat <- inte$par$sat
       return(list(cif='geyer',
                   par=list(gamma=gamma,r=r,sat=sat),
                   ntypes=1))
     },
     "Soft core process" =
     function(coeffs, inte) {
       kappa <- inte$par$kappa
       sigma <- inte$interpret(coeffs,inte)$param$sigma
       return(list(cif="sftcr",
                   par=list(sigma=sigma,kappa=kappa),
                   ntypes=1))
     },
     "Strauss process" =
     function(coeffs, inte) {
       gamma <- inte$interpret(coeffs,inte)$param$gamma
       r <- inte$par$r
       return(list(cif = "strauss",
                   par = list(gamma = gamma, r = r),
                   ntypes=1))
     },
     "Strauss - hard core process" =
     function(coeffs, inte) {
       gamma <- inte$interpret(coeffs,inte)$param$gamma
       r <- inte$par$r
       hc <- inte$par$hc
       return(list(cif='straush',
                   par=list(gamma=gamma,r=r,hc=hc),
                   ntypes=1))
     },
     "Triplets process" =
     function(coeffs, inte) {
       gamma <- inte$interpret(coeffs,inte)$param$gamma
       r <- inte$par$r
       return(list(cif = "triplets",
                   par = list(gamma = gamma, r = r),
                   ntypes=1))
     },
     "Multitype Strauss process" =
     function(coeffs, inte) {
       # interaction radii r[i,j]
       radii <- inte$par$radii
       # interaction parameters gamma[i,j]
       gamma <- (inte$interpret)(coeffs, inte)$param$gammas
       return(list(cif='straussm',
                   par=list(gamma=gamma,radii=radii),
                   ntypes=ncol(radii)))
     },
     "Multitype Strauss Hardcore process" =
     function(coeffs, inte) {
       # interaction radii r[i,j]
       iradii <- inte$par$iradii
       # hard core radii r[i,j]
       hradii <- inte$par$hradii
       # interaction parameters gamma[i,j]
       gamma <- (inte$interpret)(coeffs, inte)$param$gammas
       return(list(cif='straushm',
                   par=list(gamma=gamma,iradii=iradii,hradii=hradii),
                   ntypes=ncol(iradii)))
     },
     "Piecewise constant pairwise interaction process" =
     function(coeffs, inte) {
       r <- inte$par$r
       gamma <- (inte$interpret)(coeffs, inte)$param$gammas
       h <- stepfun(r, c(gamma, 1))
       return(list(cif='lookup', par=list(h=h),
                   ntypes=1))
     },
     "Area-interaction process" =
     function(coeffs, inte) {
       r <- inte$par$r
       eta <- (inte$interpret)(coeffs, inte)$param$eta
       return(list(cif='areaint', par=list(eta=eta,r=r), ntypes=1))
     },
     "hybrid Geyer process" =
     function(coeffs, inte) {
       r <- inte$par$r
       sat <- inte$par$sat
       gamma <- (inte$interpret)(coeffs,inte)$param$gammas
       return(list(cif='badgey',par=list(gamma=gamma,r=r,sat=sat), ntypes=1))
     },
     "Hybrid interaction"=
     function(coeffs, inte){
       # for hybrids, $par is a list of the component interactions
       interlist <- inte$par
       # check for Poisson components
       ispois <- unlist(lapply(interlist, is.poisson))
       if(all(ispois)) {
         # reduces to Poisson
         Z <- list(cif='poisson', par=list())
         return(Z)
       } else if(any(ispois)) {
         # remove Poisson components
         interlist <- interlist[!ispois]
       }
       # 
       N <- length(interlist)
       cifs <- character(N)
       pars <- vector(mode="list", length=N)
       ntyp <- integer(N)
       for(i in 1:N) {
         interI <- interlist[[i]]
         # forbid hybrids-of-hybrids - these should not occur anyway
         if(interI$name == "Hybrid interaction")
           stop("Simulation of a hybrid-of-hybrid interaction is not implemented")
         # get RMH mapping for I-th component
         siminfoI <- .Spatstat.Rmhinfo[[interI$name]]
         if(is.null(siminfoI))
           stop(paste("Simulation of a fitted", sQuote(interI$name),
                      "has not yet been implemented"),
                call.=FALSE)
         # nameI is the tag that identifies I-th component in hybrid
         nameI  <- names(interlist)[[i]]
         nameI. <- paste(nameI, ".", sep="")
         # find coefficients with prefix that exactly matches nameI.
         Cname  <- names(coeffs)
         prefixlength <- nchar(nameI.)
         Cprefix <- substr(Cname, 1, prefixlength)
         relevant <- (Cprefix == nameI.)
         # extract coefficients
         #   (there may be none, if this interaction is an 'offset')
         coeffsI <- coeffs[relevant]
         # remove the prefix so the coefficients are recognisable to 'siminfoI'
         if(any(relevant)) 
           names(coeffsI) <-
             substr(Cname[relevant], prefixlength+1, max(nchar(Cname)))
         # compute RMH info
         ZI <- siminfoI(coeffsI, interI)
         cifs[i] <- ZI$cif
         pars[[i]] <- ZI$par
         ntyp[i] <- ZI$ntypes
       }
       nt <- unique(ntyp[ntyp != 1])
       if(length(nt) > 1)
         stop(paste("Hybrid components have different numbers of types:",
                    commasep(nt)))
       if(N == 1) {
         # single cif: revert to original format: par is a list of parameters
         Z <- list(cif=cifs[1], par=pars[[1]], ntypes=ntyp)
       } else {
         # hybrid cif: par is a list of lists of parameters
         Z <- list(cif=cifs,    par=pars,      ntypes=ntyp)
       }
       return(Z)
     }
)


# OTHER MODELS not yet implemented:
#
#
#      interaction object           rmh.default 
#      ------------------           -----------
#
#           OrdThresh                <none>
#


rmhmodel.ppm <- function(model, w, ...,
                         verbose=TRUE, project=TRUE,
                         control=rmhcontrol(),
                         new.coef=NULL) {
  ## converts ppm object `model' into format palatable to rmh.default
  
  verifyclass(model, "ppm")
  argh <- list(...)

  if(!is.null(new.coef)) {
    ## hack the coefficients
    co <- coef(model)
    check.nvector(new.coef, length(co), things="coefficients")
    model$coef.orig <- co
    model$coef <- new.coef
  }

  ## Ensure the fitted model is valid
  ## (i.e. exists mathematically as a point process)
  if(!valid.ppm(model)) {
    if(project) {
      if(verbose)
        cat("Model is invalid - projecting it\n")
      model <- project.ppm(model, fatal=TRUE)
    } else stop("The fitted model is not a valid point process")
  }
    
  if(verbose)
    cat("Extracting model information...")
    
  ## Extract essential information
  Y <- summary(model, quick="no variances")

  if(Y$marked && !Y$multitype)
    stop("Not implemented for marked point processes other than multitype")

  if(Y$uses.covars && is.data.frame(model$covariates))
    stop(paste("This model cannot be simulated, because the",
               "covariate values were given as a data frame."))
    
  ## enforce defaults for `control'

  control <- rmhcontrol(control)

  ## adjust to peculiarities of model
    
  control <- rmhResolveControl(control, model)
    
  ########  Interpoint interaction
  if(Y$poisson) {
    Z <- list(cif="poisson",
              par=list())  # par is filled in later
  } else {
    ## First check version number of ppm object
    if(Y$antiquated) 
      stop(paste("This model was fitted by a very old version",
                 "of the package: spatstat", Y$version,
                 "; simulation is not possible.",
                 "Re-fit the model using your original code"))
    else if(Y$old)
      warning(paste("This model was fitted by an old version",
                    "of the package: spatstat", Y$version,
                    ". Re-fit the model using update.ppm",
                    "or your original code"))
    ## Extract the interpoint interaction object
    inte <- Y$entries$interaction
    ## Determine whether the model can be simulated using rmh
    siminfo <- .Spatstat.Rmhinfo[[inte$name]]
    if(is.null(siminfo))
      stop(paste("Simulation of a fitted", sQuote(inte$name),
                 "has not yet been implemented"))
      
    ## Get fitted model's canonical coefficients
    coeffs <- Y$entries$coef
    if(newstyle.coeff.handling(inte)) {
      ## extract only the interaction coefficients
      Vnames <- Y$entries$Vnames
      IsOffset <- Y$entries$IsOffset
      coeffs <- coeffs[Vnames[!IsOffset]]
    }
    ## Translate the model to the format required by rmh.default
    Z <- siminfo(coeffs, inte)
    if(is.null(Z))
      stop("The model cannot be simulated")
    else if(is.null(Z$cif))
      stop(paste("Internal error: no cif returned from .Spatstat.Rmhinfo"))
  }

  ## Don't forget the types
  if(Y$multitype && is.null(Z$types))
    Z$types <- levels(Y$entries$marks)
       
  ######## Window for result 
    
  if(missing(w) || is.null(w)) {
    ## check for outdated argument name 'win'
    if(!is.na(m <- match("win", names(argh)))) {
      warning("Argument 'win' to rmhmodel.ppm is deprecated; use 'w'")
      w <- argh[[m]]
      argh <- argh[-m]
    } else w <- Y$entries$data$window
  }

  Z$w <- w

  ######## Expanded window for simulation?

  covims <- if(Y$uses.covars) model$covariates[Y$covars.used] else NULL
    
  wsim <- rmhResolveExpansion(w, control, covims, "covariate")$wsim
      
  ###### Trend or Intensity ############

  if(verbose)
    cat("Evaluating trend...")
    
  if(Y$stationary) {
    ## first order terms (beta or beta[i]) are carried in Z$par
    beta <- as.numeric(Y$trend$value)
    Z$trend <- NULL
  } else {
    ## trend terms present
    ## all first order effects are subsumed in Z$trend
    beta <- if(!Y$marked) 1 else rep.int(1, length(Z$types))
    ## predict on window possibly larger than original data window
    Z$trend <- 
      if(wsim$type == "mask")
        predict(model, window=wsim, type="trend", locations=wsim)
      else 
        predict(model, window=wsim, type="trend")
  }
    
  Ncif <- length(Z$cif)
  if(Ncif == 1) {
    ## single interaction
    Z$par[["beta"]] <- beta
  } else {
    ## hybrid interaction
    if(all(Z$ntypes == 1)) {
      ## unmarked model: scalar 'beta' is absorbed in first cif
      absorb <- 1
    } else {
      ## multitype model: vector 'beta' is absorbed in a multitype cif
      absorb <- min(which(Z$ntypes > 1))
    }
    Z$par[[absorb]]$beta <- beta
    ## other cifs have par$beta = 1 
    for(i in (1:Ncif)[-absorb])
      Z$par[[i]]$beta <- rep.int(1, Z$ntypes[i])
  }
  if(verbose)
    cat("done.\n")
  Z <- do.call(rmhmodel, append(list(Z), argh))
  return(Z)
}

rmhResolveExpansion <- function(win, control, imagelist, itype="covariate") {
  # Determine expansion window for simulation
  ex <- control$expand
  
# The following is redundant because it is implied by !will.expand(ex)  
#  if(ex$force.noexp) {
#    # Expansion prohibited
#    return(list(wsim=win, expanded=FALSE))
#  }
  
  # Is expansion contemplated?
  if(!will.expand(ex))
    return(list(wsim=win, expanded=FALSE))

  # Proposed expansion window
  wexp <- expand.owin(win, ex)

  # Check feasibility
  isim <- unlist(lapply(imagelist, is.im))
  imagelist <- imagelist[isim]

  if(length(imagelist) == 0) {
    # Unlimited expansion is feasible
    return(list(wsim=wexp, expanded=TRUE))
  }

  # Expansion is limited to domain of image data
  # Determine maximum possible expansion window
  wins <- lapply(imagelist, as.owin)
  cwin <- do.call("intersect.owin", unname(wins))
  
  if(!is.subset.owin(wexp, cwin)) {
    # Cannot expand to proposed window
    if(ex$force.exp)
      stop(paste("Cannot expand the simulation window,",
                 "because the", itype, "images do not cover",
                 "the expanded window"), call.=FALSE)
      # Take largest possible window
    wexp <- intersect.owin(wexp, cwin)
  }
  return(list(wsim=wexp, expanded=TRUE))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rmhsnoop.R"
#
# rmhsnoop.R
#
#   visual debug mechanism for rmh
#
#   $Revision: 1.26 $  $Date: 2014/10/24 00:22:30 $
#
#   When rmh is called in visual debug mode (snooping = TRUE),
#   it calls e <- rmhSnoopEnv(...) to create an R environment 'e'
#   containing variables that will represent the current state
#   of the M-H algorithm with initial state X and model reach R.
#
#   The environment 'e' is passed to the C routine xmethas.
#   This makes it possible for data to be exchanged between
#   the C and R code.
#
#   When xmethas reaches the debugger's stopping time,
#   the current state of the simulation and the proposal
#   are copied from C into the R environment 'e'.
#
#   Then to execute the visual display, the C code calls
#   'eval' to execute the R function rmhsnoop().
#
#   The function rmhsnoop uses the 'simplepanel' class
#   to generate a plot showing the state of the simulation
#   and the proposal, and then wait for point-and-click input using
#   locator(). 
#  
#   When rmhsnoop() exits, it returns an integer giving the
#   (user-specified) next stoppping time. This is read back into
#   the C code. Then xmethas resumes simulations.
#
#   I said it was simple! %^]

rmhSnoopEnv <- function(Xinit, Wclip, R) {
  stopifnot(is.ppp(Xinit))
  # Create an environment that will be accessible to R and C code
  e <- new.env()
  # initial state (point pattern)
  X <- Xinit
  assign("Wsim",     as.owin(X),      envir=e)
  assign("xcoords",  coords(X)[,1],   envir=e)
  assign("ycoords",  coords(X)[,2],   envir=e)
  if(is.multitype(X)) {
    mcodes <- as.integer(marks(X)) - 1
    mlevels <- levels(marks(X))
    assign("mcodes",  mcodes,  envir=e)
    assign("mlevels", mlevels, envir=e)
  } else {
    assign("mcodes",  NULL, envir=e)
    assign("mlevels", NULL, envir=e)
  }
  # clipping window
  assign("Wclip",    Wclip,           envir=e)
  # reach of model (could be infinite)
  assign("R",        R,               envir=e)
  # current iteration number 
  assign("irep", 0L,             envir=e)
  # next iteration to be inspected
  assign("inxt",  1L,             envir=e)
  # next transition to be inspected
  assign("tnxt",  1L,             envir=e)
  # proposal type
  assign("proptype", NULL,     envir=e)
  # outcome of proposal
  assign("itype",    NULL,     envir=e)
  # proposal location
  assign("proplocn", NULL,     envir=e)
  # proposal mark 
  assign("propmark", NULL,     envir=e)
  # index of proposal point in existing pattern
  assign("propindx", NULL,     envir=e)
  # Hastings ratio
  assign("numerator",   NULL,  envir=e)
  assign("denominator", NULL,  envir=e)
  # Expression actually evaluated to execute visual debug
  # Expression is evaluated in the environment 'e'
  snoopexpr <-
    expression({
      rslt <- rmhsnoop(Wsim=Wsim, Wclip=Wclip, R=R,
                       xcoords=xcoords,
                       ycoords=ycoords,
                       mlevels=mlevels,
                       mcodes=mcodes,
                       irep=irep,
                       itype=itype,
                       proptype=proptype,
                       proplocn=proplocn,
                       propmark=propmark,
                       propindx=propindx,
                       numerator=numerator,
                       denominator=denominator)
      inxt <- rslt$inxt
      tnxt <- rslt$tnxt
      itype <- if(rslt$accepted) rslt$itype else 0
      storage.mode(tnxt) <-
        storage.mode(inxt) <- storage.mode(itype) <- "integer"
})
  assign("snoopexpr", snoopexpr,  envir=e)
  # callback expression
  assign("callbackexpr", quote(eval(snoopexpr)), envir=e)
  return(e)
}

# visual debug display using base graphics

rmhsnoop <- local({

  rmhsnoop <- function(..., Wsim, Wclip, R,
                       xcoords, ycoords,
                       mlevels, mcodes,
                       irep, itype, 
                       proptype, proplocn, propmark, propindx,
                       numerator, denominator) {
    trap.extra.arguments(..., .Context="In rmhsnoop")
    X <- ppp(xcoords, ycoords, window=Wsim)
    if(!missing(mlevels) && length(mlevels) > 0)
      marks(X) <- factor(mlevels[mcodes+1], levels=mlevels)
    Wclip.orig <- Wclip
    # determine plot arguments
    if(is.mask(Wclip)) {
      parg.Wclip <- list(invert=TRUE, col="grey")
    } else {
      Wclip <- edges(Wclip) 
      parg.Wclip <- list(lty=3, lwd=2, col="grey")
    }
    parg.birth <- list(pch=16, cols="green")
    parg.death <- list(pch=4, cols="red", lwd=2)
    parg.birthcircle <- list(col="green", lty=3)
    parg.deathcircle <- list(col="red", lty=3)

    # assemble a layered object representing the state and the proposal
    if(is.null(proptype)) {
      # initial state
      L <- layered(Wsim,
                   Wclip,
                   X)
      layerplotargs(L)$Wclip <- parg.Wclip
      accepted <- TRUE
    } else {
      accepted <- (itype == proptype)
      # add proposal info
      switch(decode.proptype(proptype),
             Reject=
             {
               propname <- "rejected"
               L <- layered(Wsim=Wsim,
                            Wclip=Wclip,
                            X=X)
               layerplotargs(L)$Wclip <- parg.Wclip
             },
             Birth = 
             {
               propname <- "birth proposal"
               U <- ppp(proplocn[1], proplocn[2], window=Wsim)
               D <- if(is.finite(R) && R > 0) {
                 edges(disc(R, proplocn))[Wsim]
               } else NULL
               L <- layered(Wsim=Wsim,
                            Wclip=Wclip,
                            PrevState=X,
                            Reach=D,
                            NewPoint=U)
               layerplotargs(L)$Wclip <- parg.Wclip
               layerplotargs(L)$NewPoint <- parg.birth
             },
             Death = 
             {
               propname <- "death proposal"
               # convert from C to R indexing
               propindx <- propindx + 1
               XminI <- X[-propindx]
               XI <- X[propindx]
               D <- if(is.finite(R) && R > 0) {
                 edges(disc(R, c(XI$x, XI$y)))[Wsim]
               } else NULL
               L <- layered(Wsim=Wsim,
                            Wclip=Wclip,
                            RetainedPoints=XminI,
                            Reach=D,
                            Deletion=XI)
               layerplotargs(L)$Wclip    <- parg.Wclip
               layerplotargs(L)$Reach    <-  parg.deathcircle
               layerplotargs(L)$Deletion <- parg.death
             },
             Shift = 
             {
               propname <- "shift proposal"
               # convert from C to R indexing
               propindx <- propindx + 1
               # make objects
               XminI <- X[-propindx]
               XI <- X[propindx]
               U <- ppp(proplocn[1], proplocn[2], window=Wsim)
               if(is.finite(R) && R > 0) {
                 DU <- edges(disc(R, proplocn))[Wsim]
                 DXI <- edges(disc(R, c(XI$x, XI$y)))[Wsim]
               } else { DU <- DXI <- NULL }
               # make layers
               L <- layered(Wsim=Wsim,
                            Wclip=Wclip,
                            OtherPoints=XminI,
                            ReachAfter=DU,
                            AfterShift=U,
                            ReachBefore=DXI,
                            BeforeShift=XI)
               layerplotargs(L)$Wclip       <- parg.Wclip
               layerplotargs(L)$ReachAfter  <- parg.birthcircle
               layerplotargs(L)$AfterShift  <- parg.birth
               layerplotargs(L)$ReachBefore <- parg.deathcircle
               layerplotargs(L)$BeforeShift <- parg.death
             },
             stop("Unrecognised proposal type")
             )
    }
    header <- c(paste("Iteration", irep),
                propname,
                paste("Hastings ratio =",
                      signif(numerator, 4), "/", signif(denominator, 4)))
    info <- list(irep=irep,
                 Wsim=Wsim,
                 Wclip=Wclip.orig,
                 X=X,
                 proptype=proptype,
                 proplocn=proplocn,
                 propindx=propindx,
                 propmark=propmark,
                 accepted=accepted,
                 numerator=numerator,
                 denominator=denominator)
    inspectProposal(L, info, title=header)
  }

  decode.proptype <- function(n) {
    if(n < 0 || n > 3) stop(paste("Unrecognised proposal type:", n))
    switch(n+1, "Reject", "Birth", "Death", "Shift")
  }
  encode.proptype <- function(s) {
    switch(s, Reject=0, Birth=1, Death=2, Shift=3)
  }
  
  inspectProposal <- function(X, info, ..., title) {
    if(missing(title)) title <- short.deparse(substitute(X))
    if(!inherits(X, "layered"))
      X <- layered(X)
    lnames <- names(X)
    if(sum(nzchar(lnames)) != length(X))
      lnames <- paste("Layer", seq_len(length(X)))
    # Find window and bounding box (validates X)
    W <- as.owin(X)
    BX <- as.rectangle(W)
    # Initialise environment for state variables etc
    # This environment is accessible to the panel button functions
    en <- new.env()
    assign("X", X, envir=en)
    assign("W", W, envir=en)
    assign("BX", BX, envir=en)
    assign("zoomfactor", 1L, envir=en)
    midX <- unlist(centroid.owin(BX))
    assign("midX", midX, envir=en)
    assign("zoomcentre", midX, envir=en)
    assign("irep", info$irep, envir=en)
    assign("inxt", info$irep+1, envir=en) 
    assign("tnxt", -1, envir=en)
    assign("accepted", info$accepted, envir=en)
    assign("proplocn", info$proplocn, envir=en)
    assign("info", info, envir=en)
    # Build interactive panel
    # Start with data panel
    P <- simplepanel(title,
                     BX,
                     list(Data=BX),
                     list(Data=dataclickfun),
                     list(Data=dataredrawfun),
                     snoopexit,
                     en)
    # Add pan buttons
    margin <- max(sidelengths(BX))/4
    panelwidth <- sidelengths(BX)[1]/2
    P <- grow.simplepanel(P, "top", margin, navfuns["Up"], aspect=1)
    P <- grow.simplepanel(P, "bottom", margin, navfuns["Down"], aspect=1)
    P <- grow.simplepanel(P, "left", margin, navfuns["Left"], aspect=1)
    P <- grow.simplepanel(P, "right", margin, navfuns["Right"], aspect=1)
    # Zoom/Pan buttons at right
    P <- grow.simplepanel(P, "right", panelwidth, zoomfuns)
    # Accept/reject buttons at top
    P <- grow.simplepanel(P, "top", margin, accept.clicks, accept.redraws)
    # Dump/print buttons at bottom 
    P <- grow.simplepanel(P, "bottom", margin, dumpfuns)
    # Jump controls at left
    maxchars <- max(4, nchar(names(jump.clicks)))
    P <- grow.simplepanel(P, "left", panelwidth * maxchars/6, jump.clicks)
    # go
    rslt <- run.simplepanel(P, popup=FALSE)
    clear.simplepanel(P)
    rm(en)
    return(rslt)
  }


# button control functions
  zoomfuns <- 
    rev(list(
             "Zoom In"=function(env, xy) {
               z <- get("zoomfactor", envir=env)
               assign("zoomfactor", z * 2, envir=env)
               return(TRUE)
             },
             "Zoom Out"=function(env, xy) {
               z <- get("zoomfactor", envir=env)
               assign("zoomfactor", z / 2, envir=env)
               return(TRUE)
             },
             "At Proposal"=function(env, xy) {
               proplocn <- get("proplocn", envir=env)
               assign("zoomcentre", proplocn, envir=env)
               return(TRUE)
             },
             Reset=function(env, xy) {
               assign("zoomfactor", 1L, envir=env)
               midX <- get("midX", envir=env)
               assign("zoomcentre", midX, envir=env)
               return(TRUE)
             }))
                           
  navfuns <-
    list(
         Left = function(env, xy) {
           zoom <- get("zoomfactor", envir=env)
           ce <- get("zoomcentre", envir=env)
           BX <- get("BX", envir=env)
           width <- sidelengths(BX)[1]
           stepsize <- (width/4)/zoom
           ce <- ce - c(stepsize, 0)
           assign("zoomcentre", ce, envir=env)
           return(TRUE)
         },
         Right = function(env, xy) {
           zoom <- get("zoomfactor", envir=env)
           ce <- get("zoomcentre", envir=env)
           BX <- get("BX", envir=env)
           width <- sidelengths(BX)[1]
           stepsize <- (width/4)/zoom
           ce <- ce + c(stepsize, 0)
           assign("zoomcentre", ce, envir=env)
           return(TRUE)
         },
         Up = function(env, xy) {
           zoom <- get("zoomfactor", envir=env)
           ce <- get("zoomcentre", envir=env)
           BX <- get("BX", envir=env)
           height <- sidelengths(BX)[2]
           stepsize <- (height/4)/zoom
           ce <- ce + c(0, stepsize)
           assign("zoomcentre", ce, envir=env)
           return(TRUE)
         },
         Down = function(env, xy) {
           zoom <- get("zoomfactor", envir=env)
           ce <- get("zoomcentre", envir=env)
           BX <- get("BX", envir=env)
           height <- sidelengths(BX)[2]
           stepsize <- (height/4)/zoom
           ce <- ce - c(0, stepsize)
           assign("zoomcentre", ce, envir=env)
           return(TRUE)
         })

  accept.clicks <-
    rev(list(
             Accept=function(env, xy) {
               assign("accepted", TRUE, envir=env)
               return(TRUE)
             },
             Reject=function(env, xy) {
               assign("accepted", FALSE, envir=env)
               return(TRUE)
             }))

  accept.redraws <-
    rev(list(
             Accept=function(button, name, env) {
               accepted <- get("accepted", envir=env)
               if(accepted) {
                 plot(button, add=TRUE, col="green")
               } else {
                 plot(button, add=TRUE)
               }
               text(centroid.owin(button), labels=name)
             },
             Reject=function(button, name, env) {
               accepted <- get("accepted", envir=env)
               if(accepted) {
                 plot(button, add=TRUE)
               } else {
                 plot(button, add=TRUE, col="pink")
               }
               text(centroid.owin(button), labels=name)
             }))
             
  jump.clicks <-
    rev(list(
             "Next Iteration"=function(env, xy) {
               irep <- get("irep", envir=env)
               assign("inxt", irep+1, envir=env)
               return(FALSE)
             },
             "Skip 10"=function(env, xy) {
               irep <- get("irep", envir=env)
               assign("inxt", irep+10, envir=env)
               return(FALSE)
             },
             "Skip 100"=function(env, xy) {
               irep <- get("irep", envir=env)
               assign("inxt", irep+100, envir=env)
               return(FALSE)
             },
             "Skip 1000"=function(env, xy) {
               irep <- get("irep", envir=env)
               assign("inxt", irep+1000, envir=env)
               return(FALSE)
             },
             "Skip 10,000"=function(env, xy) {
               irep <- get("irep", envir=env)
               assign("inxt", irep+10000, envir=env)
               return(FALSE)
             },
             "Skip 100,000"=function(env, xy) {
               irep <- get("irep", envir=env)
               assign("inxt", irep+100000, envir=env)
               return(FALSE)
             },
             "Next Birth"=function(env, xy) {
               assign("inxt", -1, envir=env)
               assign("tnxt", encode.proptype("Birth"), envir=env)
               return(FALSE)
             },
             "Next Death"=function(env, xy) {
               assign("inxt", -1, envir=env)
               assign("tnxt", encode.proptype("Death"), envir=env)
               return(FALSE)
             },
             "Next Shift"=function(env, xy) {
               assign("inxt", -1, envir=env)
               assign("tnxt", encode.proptype("Shift"), envir=env)
               return(FALSE)
             },
             "Exit Debugger"=function(env, xy) {
               assign("inxt", -1L, envir=env)
               return(FALSE)
             }))

  dataclickfun <- function(env, xy) {
    # function for handling clicks in the data window
    z <- get("zoomfactor", envir=env)
    ce <- get("zoomcentre", envir=env)
    midX <- get("midX", envir=env)
    ce <- ce + (unlist(xy) - midX)/z
    assign("zoomcentre", ce, envir=env)
    return(TRUE)
  }

  dataredrawfun <- function(button, name, env) {                             
    # redraw data window
    X <- get("X", envir=env)
    BX <- get("BX", envir=env)
    W <- get("W", envir=env)
    midX <- get("midX", envir=env)
    z <- get("zoomfactor", envir=env)
    ce <- get("zoomcentre", envir=env)
    scaleX <- shift(affine(shift(X, -ce), diag(c(z,z))), unlist(midX))
    scaleW <- shift(affine(shift(W, -ce), diag(c(z,z))), unlist(midX))
    scaleX <- scaleX[, BX]
    scaleW <- intersect.owin(scaleW, BX, fatal=FALSE)
    # redraw data in 'BX' 
    if(!is.null(scaleW)) {
      if(z == 1 && is.rectangle(scaleW)) {
        plot(scaleW, add=TRUE, lwd=2)
      } else {
        plot(BX, add=TRUE, lty=3, border="red")
        if(!identical(BX, scaleW))
          plot(scaleW, add=TRUE, invert=TRUE)
      }
    }
    if(!is.null(scaleX))
      plot(scaleX, add=TRUE)
    invisible(NULL)
  }

# functions to dump the current state, etc
  dumpfuns <- list(
                   "Dump to file"=function(env, xy) {
                     irep <- get("irep", envir=env)
                     X <- get("X", envir=env)
                     xname <- paste("dump", irep, sep="")
                     assign(xname, X)
                     fname <- paste(xname, ".rda", sep="")
                     eval(substitute(save(x, file=y, compress=TRUE), 
                                     list(x=xname, y=fname)))
                     cat(paste("Saved to", sQuote(fname), "\n"))
                     return(TRUE)
                   },
                   "Print Info"=function(env, xy) {
                     info <- get("info", envir=env)
                     will.accept <- get("accepted", envir=env)
                     with(info, {
                       cat(paste("Iteration", irep, "\n"))
                       cat("Simulation window:\n")
                       print(Wsim)
                       cat("Clipping window:\n")
                       print(Wclip)
                       cat("Current state:\n")
                       print(X)
                       propname <- decode.proptype(proptype)
                       cat(paste("Proposal type:", propname, "\n"))
                       prxy <- function(z) paren(paste(z, collapse=", "))
                       switch(propname,
                              Reject = { },
                              Birth = {
                                cat(paste("Birth of new point at location",
                                          prxy(proplocn), "\n"))
                              },
                              Death = {
                                Xi <- X[propindx]
                                cat(paste("Death of data point", propindx,
                                          "located at",  
                                          prxy(as.numeric(coords(Xi))),
                                          "\n"))
                              },
                              Shift = {
                                Xi <- X[propindx]
                                cat(paste("Shift data point",
                                          propindx,
                                          "from current location",
                                          prxy(as.numeric(coords(Xi))),
                                          "to new location",
                                          prxy(proplocn),
                                          "\n"))
                              })
                       cat(paste("Hastings ratio = ",
                                 numerator, "/", denominator,
                                 "=", numerator/denominator, "\n"))
                       cat(paste("Fate of proposal:",
                                 if(will.accept) "Accepted" else "Rejected",
                                 "\n"))
                       return(TRUE)
                     })
                   })
  
# function to determine return value
                             
  snoopexit <- function(env) {
    ans <- eval(quote(list(inxt=inxt,
                           tnxt=tnxt,
                           accepted=accepted)),
                envir=env)
    return(ans)
  }
                             
  testit <- function() {
    rmhsnoop(Wsim=owin(), Wclip=square(0.7), R=0.1,
             xcoords=runif(40),
             ycoords=runif(40),
             mlevels=NULL, mcodes=NULL,
             irep=3, itype=1,
             proptype=1, proplocn=c(0.5, 0.5), propmark=0, propindx=0,
             numerator=42, denominator=24)
  }
                             
  rmhsnoop
})


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rmhstart.R"
#
#
#   rmhstart.R
#
#   $Revision: 1.11 $  $Date: 2014/06/06 09:37:45 $
#
#

rmhstart <- function(start, ...) {
  UseMethod("rmhstart")
}

rmhstart.rmhstart <- function(start, ...) {
  return(start)
}

rmhstart.list <- function(start, ...) {
  st <- do.call.matched("rmhstart.default", start)
  return(st)
}

rmhstart.default <- function(start=NULL, ..., n.start=NULL, x.start=NULL)
{
 if(!is.null(start) || length(list(...)) > 0)
    stop("Syntax should be rmhstart(n.start) or rmhstart(x.start)")
 
  ngiven <- !is.null(n.start)
  xgiven <- !is.null(x.start)
  
  # n.start and x.start are incompatible
  if(ngiven && xgiven)
    stop("Give only one of the arguments n.start and x.start")

  given <- if(ngiven) "n" else if(xgiven) "x" else "none"

  # Validate arguments
  if(ngiven && !is.numeric(n.start))
      stop("n.start should be numeric")
  if(xgiven) {
    # We can't check x.start properly because we don't have the relevant window
    # Just check that it is INTERPRETABLE as a point pattern  
    xx <- as.ppp(x.start, W=ripras, fatal=FALSE)
    if(is.null(xx))
      stop(paste("x.start should be a point pattern object,",
                 "or coordinate data in a format recognised by as.ppp"))
  } else
     xx <- NULL

###################################################################
# return augmented list  
  out <- list(n.start=n.start,
              x.start=x.start,
              given=given,
              xx=xx)
  class(out) <- c("rmhstart", class(out))
  return(out)
}

print.rmhstart <- function(x, ...) {
  verifyclass(x, "rmhstart")

  cat("Metropolis-Hastings algorithm starting parameters\n")
  cat("Initial state: ")
  switch(x$given,
         none={ cat("not given\n") },
         x = {
               cat("given as x.start\n")
               if(is.ppp(x$x.start)) 
                 print(x$x.start)
               else
                 cat(paste("(x,y) coordinates of", x$xx$n,
                           "points (window unspecified)\n"))
               cat("\n")
             },
         n = {
           n.start <- x$n.start
           nstring <-
             if(length(n.start) == 1)
               paste(n.start)
             else 
               paste("(", paste(n.start, collapse=","), ")", sep="")
           cat(paste("number fixed at n.start =", nstring, "\n")) }
         )
}

update.rmhstart <- function(object, ...) {
  do.call.matched("rmhstart.default",
                  resolve.defaults(list(...), as.list(object),
                                   .StripNull=TRUE))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rose.R"
#'
#'    rose.R
#'
#'   Rose diagrams
#'
#'   $Revision: 1.3 $  $Date: 2014/12/04 05:12:44 $
#'

rose <- function(x, ...) UseMethod("rose")

rose.default <- local({

  rose.default <- function(x, breaks = NULL, ...,
                           nclass=NULL,
                           unit=c("degree", "radian"), main) {
    if(missing(main) || is.null(main))
      main <- short.deparse(substitute(x))
    stopifnot(is.numeric(x))
    #' determine units
    missu <- missing(unit)
    unit <- match.arg(unit)
    unit <- validate.angles(x, unit, missu)
    FullCircle <- switch(unit, degree = 360, radian = 2*pi)
    #' reduce to [0, 2pi]
    x <- x %% FullCircle
    #' determine breakpoints strictly inside full circle
    breaks <- makebreaks(x, c(0, FullCircle), breaks, nclass)
    #'
    h <- do.call.matched(hist.default,
                         list(x=x, breaks=breaks, ..., plot=FALSE),
                         skipargs=graphicsAargh,
                         sieve=TRUE)
    do.call(rose.histogram, c(list(x=h$result, main=main), h$otherargs))
  }

  graphicsAargh <- c("density", "angle", "col", "border",
                     "xlim", "ylim", "xlab", "ylab", "axes")

  makebreaks <- function(x, r, breaks=NULL, nclass=NULL) {
    use.br <- !is.null(breaks)
    if (use.br) {
      if (!is.null(nclass)) 
        warning("'nclass' not used when 'breaks' is specified")
    } else if (!is.null(nclass) && length(nclass) == 1L) {
      breaks <- nclass
    } else breaks <- "Sturges"
    use.br <- use.br && (nB <- length(breaks)) > 1L
    if (use.br) 
      breaks <- sort(breaks)
    else {
      if (is.character(breaks)) {
        breaks <- match.arg(tolower(breaks),
                            c("sturges", 
                              "fd",
                              "freedman-diaconis",
                              "scott"))
        breaks <- switch(breaks,
                         sturges = nclass.Sturges(x), 
                         `freedman-diaconis` = ,
                         fd = nclass.FD(x),
                         scott = nclass.scott(x), 
                         stop("unknown 'breaks' algorithm"))
      }
      else if (is.function(breaks)) {
        breaks <- breaks(x)
      }
      if (length(breaks) == 1) {
        if (!is.numeric(breaks) || !is.finite(breaks) || 
            breaks < 1L) 
          stop("invalid number of 'breaks'")
        breaks <- seq(r[1], r[2], length.out=breaks)
      }
      else {
        if (!is.numeric(breaks) || length(breaks) <= 1) 
          stop(gettextf("Invalid breakpoints produced by 'breaks(x)': %s", 
                        format(breaks)), domain = NA)
        breaks <- sort(breaks)
      }
    }
    return(breaks)
  }
  
  rose.default
})


rose.histogram <- function(x, ...,
                           unit=c("degree", "radian"),
                           main, do.plot=TRUE) {
  if(missing(main) || is.null(main))
    main <- short.deparse(substitute(x))
  #' determine units
  missu <- missing(unit)
  unit <- match.arg(unit)
  #' validate
  bks <- x$breaks
  unit <- validate.angles(bks, unit, missu)
  FullCircle <- switch(unit, degree = 360, radian = 2*pi)
  #' get sector sizes
  y <- x$density
  ymax <- max(y)
  #' draw disc
  R <- 1.1 * ymax
  DD <- disc(R)
  result <- do.call.matched(plot.owin,
                            resolve.defaults(list(x=disc(R * 1.1),
                                                  main=main,
                                                  type="n"), 
                                             list(...)))
  do.call.matched(plot.owin,
                  resolve.defaults(list(x=DD,
                                        hatch=FALSE,
                                        add=TRUE),
                                   list(...)),
                  extrargs=graphicsPars("owin"),
                  skipargs="col")
  if(do.plot) {
    #' draw sectors
    ang <- switch(unit, degree = pi * (bks/180), radian=bks)
    eps <- min(diff(ang), pi/128)/2
    for(i in seq_along(y)) {
      aa <- seq(ang[i], ang[i+1], by=eps)
      aa[length(aa)] <- ang[i+1]
      yi <- y[i]
      xx <- c(0, yi * cos(aa), 0)
      yy <- c(0, yi * sin(aa), 0)
      do.call.matched(polygon, list(x=xx, y=yy, ...))
    }
    #' add tick marks
    circticks(R)
  }
  #'
  return(invisible(result))
}

rose.density <- function(x, ..., unit=c("degree", "radian"),
                         main, do.plot=TRUE) {
  if(missing(main) || is.null(main))
    main <- short.deparse(substitute(x))
  ang <- x$x
  rad <- x$y
  missu <- missing(unit)
  unit <- match.arg(unit)
  unit <- validate.angles(ang, unit, missu)
  #'
  result <- roseContinuous(ang, rad, unit, ..., main=main, do.plot=do.plot)
  return(invisible(result))
}

rose.fv <- function(x, ..., unit=c("degree", "radian"),
                            main, do.plot=TRUE) {
  if(missing(main) || is.null(main))
    main <- short.deparse(substitute(x))
  ang <- with(x, .x)
  rad <- with(x, .y)
  missu <- missing(unit)
  unit <- match.arg(unit)
  unit <- validate.angles(ang, unit, missu)
  #'
  result <- roseContinuous(ang, rad, unit, ..., main=main, do.plot=do.plot)
  return(invisible(result))
}

roseContinuous <- function(ang, rad, unit, ..., main, do.plot=TRUE) {
  rmax <- max(rad)
  #' draw disc
  R <- 1.1 * rmax
  DD <- disc(R)
  result <- do.call.matched(plot.owin,
                            resolve.defaults(list(x=disc(R * 1.1),
                                                  main=main,
                                                  type="n"), 
                                             list(...)))
  do.call.matched(plot.owin,
                  resolve.defaults(list(x=DD,
                                        add=TRUE,
                                        hatch=FALSE),
                                   list(...)),
                  extrargs=graphicsPars("owin"),
                  skipargs="col")
  #' draw plot
  if(do.plot) {
    if(unit == "degree") ang <- pi * (ang/180)
    xx <- rad * cos(ang)
    yy <- rad * sin(ang)
    do.call.matched(polygon, list(x=xx, y=yy, ...), extrargs="lwd")
    circticks(R)
  }
  return(result)
}

circticks <- function(R, at) {
  if(missing(at)) {
    at <- 2 * pi * (0:23)/24
    major <- ((0:23) %% 6 == 0)
  } else {
    nat <- at * 2/pi
    major <- abs(nat - round(nat)) < 0.01
  }
  tx <- R * cos(at)
  ty <- R * sin(at)
  expan <- ifelse(major, 1.1, 1.05)
  segments(tx, ty, expan * tx, expan * ty, lwd=major+1)
  invisible(NULL)
}

validate.angles <- function(angles, unit, guess=TRUE) {
  #' validate
  width <- diff(range(angles))
  if(guess && width <= 6.2832) {
    warning("Very small range of angles: treating them as radian")
    unit <- "radian"
  }
  FullCircle <- switch(unit, degree = 360, radian = 2*pi)
  if(width > 1.002 * FullCircle)
    stop("Range of angles exceeds a full circle")
  return(unit)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rotate.R"
#
#	rotate.S
#
#	$Revision: 1.21 $	$Date: 2014/10/24 00:22:30 $
#

rotxy <- function(X, angle=pi/2) {
  co <- cos(angle)
  si <- sin(angle)
  list(x = co * X$x - si * X$y,
       y = si * X$x + co * X$y)
}

rotxypolygon <- function(p, angle=pi/2) {
  p[c("x","y")] <- rotxy(p, angle=angle)
  # area and hole status are invariant under rotation
  return(p)
}

rotate <- function(X, ...) {
  UseMethod("rotate")
}

rotate.owin <- function(X, angle=pi/2, ..., rescue=TRUE, centre=NULL) {
  verifyclass(X, "owin")
  if(!is.null(centre)) {
    ## rotation about designated centre
    X <- shift(X, origin=centre)
    negorig <- getlastshift(X)
  } else negorig <- NULL
  switch(X$type,
         rectangle={
           # convert rectangle to polygon
           P <- owin(X$xrange, X$yrange, poly=
                     list(x=X$xrange[c(1,2,2,1)],
                          y=X$yrange[c(1,1,2,2)]),
                     unitname=unitname(X))
           # call polygonal case
           Y <- rotate.owin(P, angle, rescue=rescue)
         },
         polygonal={
           # First rotate the polygonal boundaries
           bdry <- lapply(X$bdry, rotxypolygon, angle=angle)
           # wrap up
           Y <- owin(poly=bdry, check=FALSE, unitname=unitname(X))
           if(rescue)
             Y <- rescue.rectangle(Y)
         },
         mask={
           newframe <- boundingbox(rotxy(corners(X), angle))
           Y <- if(length(list(...)) > 0) as.mask(newframe, ...) else 
                   as.mask(newframe, eps=with(X, min(xstep, ystep)))
           pixelxy <- rasterxy.mask(Y)
           xybefore <- rotxy(pixelxy, -angle)
           Y$m[] <- with(xybefore, inside.owin(x, y, X))
           Y <- intersect.owin(Y, boundingbox(Y))
           if(rescue)
             Y <- rescue.rectangle(Y)
           unitname(Y) <- unitname(X)
         },
         stop("Unrecognised window type")
         )
  if(!is.null(negorig))
    Y <- shift(Y, -negorig)
  return(Y)
}

rotate.ppp <- function(X, angle=pi/2, ..., centre=NULL) {
  verifyclass(X, "ppp")
  if(!is.null(centre)) {
    X <- shift(X, origin=centre)
    negorigin <- getlastshift(X)
  } else negorigin <- NULL
  r <- rotxy(X, angle)
  w <- rotate.owin(X$window, angle, ...)
  Y <- ppp(r$x, r$y, window=w, marks=marks(X, dfok=TRUE), check=FALSE)
  if(!is.null(negorigin))
    Y <- shift(Y, -negorigin)
  return(Y)
}

rotate.im <- function(X, angle=pi/2, ..., centre=NULL) {
  if(!is.null(centre)) {
    X <- shift(X, origin=centre)
    negorigin <- getlastshift(X)
  } else negorigin <- NULL
  co <- cos(angle)
  si <- sin(angle)
  m <- matrix(c(co,si,-si,co), nrow=2, ncol=2)
  Y <- affine(X, mat=m)
  if(!is.null(negorigin))
    Y <- shift(Y, -negorigin)
  return(Y)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rotmean.R"
##
## rotmean.R
##
## rotational average of pixel values
##
##  $Revision: 1.6 $ $Date: 2014/09/11 07:23:43 $

rotmean <- function(X, ..., origin, Xname, result=c("fv", "im")) {
  if(missing(Xname))
    Xname <- sensiblevarname(short.deparse(substitute(X)), "X")
  trap.extra.arguments(..., .Context="rotmean")
  stopifnot(is.im(X))
  if(!missing(origin))
    X <- shift(X, origin=origin)
  result <- match.arg(result)
  values <- X[drop=TRUE]
  radii <- with(as.data.frame(rasterxy.im(X, drop=TRUE)), sqrt(x^2+y^2))
  ra <- range(radii)
  eps <- sqrt(X$xstep^2 + X$ystep^2)
  a <- unnormdensity(radii,                 from=ra[1], to=ra[2], bw=eps)
  b <- unnormdensity(radii, weights=values, from=ra[1], to=ra[2], bw=eps)
  df <- data.frame(r=a$x, f=b$y/a$y)
  FUN <- fv(df,
            argu="r",
            ylab=substitute(bar(X)(r), list(X=as.name(Xname))),
            valu="f",
            fmla=(. ~ r),
            alim=ra,
            labl=c("r", "%s(r)"),
            desc=c("distance argument r",
                "rotational average"),
            unitname=unitname(X),
            fname=paste0("bar", paren(Xname)))
  attr(FUN, "dotnames") <- "f"
  if(result == "fv") return(FUN)
  ## compute image
  FUN <- as.function(FUN)
  XX <- as.im(X, na.replace=1)
  IM <- as.im(function(x,y,FUN){ FUN(sqrt(x^2+y^2)) }, XX, FUN=FUN)
  return(IM)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/round.R"
#
#   round.R
#
#   discretisation of coordinates
#
#   $Revision: 1.5 $  $Date: 2013/01/09 03:13:10 $

round.ppp <- round.pp3 <- round.ppx <- function(x, digits=0) {
  coords(x) <- round(as.matrix(coords(x)), digits=digits)
  return(x)
}

rounding <- function(x) {
  UseMethod("rounding")
}

rounding.ppp <- rounding.pp3 <- rounding.ppx <- function(x) {
  rounding(as.matrix(coords(x)))
}

rounding.default <- function(x) {
  # works for numeric, complex, matrix etc
  if(all(x == 0))
    return(NULL)
  if(identical(all.equal(x, round(x)), TRUE)) { 
    # integers: go up
    k <- 0
    smallk <- -log10(.Machine$double.xmax)
    repeat {
      if(k < smallk || !identical(all.equal(x, round(x, k-1)), TRUE))
        return(k)
      k <- k-1
    }
  } else {
    # not integers: go down
    k <- 1
    bigk <- -log10(.Machine$double.eps)
    repeat {
      if(k > bigk || identical(all.equal(x, round(x, k)), TRUE))
        return(k)
      k <- k+1
    }
  }
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rshift.R"
#
#   rshift.R
#
#   random shift with optional toroidal boundary
#
#   $Revision: 1.16 $   $Date: 2013/05/01 08:00:33 $
#
#
rshift <- function(X, ...) {
  UseMethod("rshift")
}

rshift.splitppp <- function(X, ..., which=seq_along(X))
{
  verifyclass(X, "splitppp")
  if("group" %in% names(list(...)))
    stop(paste("argument", sQuote("group"),
               "not implemented for splitppp objects"))

  if(is.null(which)) {
    iwhich <- which <- seq_along(X)
  } else {
    id <- seq_along(X)
    names(id) <- names(X)
    iwhich <- id[which]
    if(length(iwhich) == 0)
      stop(paste("Argument", sQuote("which"), "did not match any marks"))
  }
  
  # validate arguments and determine common clipping window
  arglist <- handle.rshift.args(X[[1]]$window, ..., edgedefault="torus")

  if(!is.null(clip <- arglist$clip)) {
    # clip the patterns that are not to be shifted
    if(length(iwhich) < length(X)) 
      X[-iwhich] <- lapply(X[-iwhich], "[.ppp", i=clip)
  }
  # perform shift on selected patterns
  # (setting group = NULL ensures each pattern is not split further)
  shiftXsub <- do.call("lapply", append(list(X[iwhich], rshift.ppp, group=NULL),
                                        arglist))
  # put back
  X[iwhich] <- shiftXsub

  return(X)
}

rshift.ppp <- function(X, ..., which=NULL, group)
{
  verifyclass(X, "ppp")
  
  # validate arguments and determine common clipping window
  arglist <- handle.rshift.args(X$window, ..., edgedefault="torus")

  # default grouping
  #   (NULL is not the default)
  #   (NULL means all points shifted in parallel)
  if(missing(group))
    group <- if(is.multitype(X)) marks(X) else NULL

  # if no grouping, use of `which' is undefined
  if(is.null(group) && !is.null(which))
    stop(paste("Cannot apply argument", sQuote("which"),
               "; no grouping defined"))

  # if grouping, use split
  if(!is.null(group)) {
    Y <- split(X, group)
    split(X, group) <- do.call("rshift.splitppp",
                               append(list(Y, which=which),
                                      arglist))
    return(X)
  } 
    
  # ungrouped point pattern
  # shift all points in parallel

  # recover arguments
  radius <- arglist$radius
  width  <- arglist$width
  height <- arglist$height
  edge   <- arglist$edge
  clip   <- arglist$clip
 
  W <- X$window
  W <- rescue.rectangle(W)
  if(W$type != "rectangle" && edge=="torus")
    stop("Torus (periodic) boundary is only meaningful for rectangular windows")

  # generate random translation vector
  
  if(!is.null(radius)) 
    jump <- runifdisc(1, radius=radius)
  else {
    jump <- list(x=runif(1, min=0, max=width),
                 y=runif(1, min=0, max=height))
  }

  # translate points
  x <- X$x + jump$x
  y <- X$y + jump$y

  # wrap points
  if(edge == "torus") {
    xr <- W$xrange
    yr <- W$yrange
    Wide <- diff(xr)
    High <- diff(yr)
    x <- xr[1] + (x - xr[1]) %% Wide
    y <- yr[1] + (y - yr[1]) %% High
  }

  # put back into point pattern
  X$x <- x
  X$y <- y

  # clip to window
  if(!is.null(clip))
    X <- X[clip]

  return(X)
}


handle.rshift.args <- function(W, ...,
                               radius=NULL, width=NULL, height=NULL,
                               edge=NULL, clip=NULL, edgedefault)
{
  verifyclass(W, "owin")
  W <- rescue.rectangle(W)
  
  if(length(aargh <- list(...)) > 0)
    stop(paste("Unrecognised arguments:",
               paste(names(aargh), collapse=",")))
  
  if(!is.null(radius)) {
    # radial generator
    if(!(is.null(width) && is.null(height)))
    stop(paste(sQuote("radius"), "is incompatible with",
               sQuote("width"), "and", sQuote("height")))
  } else {
    # rectangular generator
    if(is.null(width) != is.null(height))
      stop("Must specify both width and height, if one is specified")
    if(is.null(width)) width <- diff(W$xrange)
    if(is.null(height)) height <- diff(W$yrange)
  }
  
  if(is.null(edge))
    edge <- edgedefault
  else if(!(edge %in% c("torus", "erode", "none")))
    stop(paste("Unrecognised option erode=", sQuote(edge)))

  # determine whether clipping window is needed
  if(is.null(clip))
    clip <- switch(edge,
                   torus= NULL,
                   none= W,
                   erode={
                     if(!is.null(radius))
                       erosion.owin(W, radius)
                     else if(W$type == "rectangle")
                       trim.rectangle(W, width, height)
                     else
                       erosion.owin(W, max(width, height))
                   })

  return(list(radius=radius, width=width, height=height,
              edge=edge, clip=clip))
}

rtoro <- function(X, which=NULL, radius=NULL, width=NULL, height=NULL) {
  .Deprecated("rshift", package="spatstat")
  rshift(X, which=which, radius=radius, width=width, height=height)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/rshift.psp.R"
#
# rshift.psp.R
#
#  $Revision: 1.6 $  $Date: 2011/05/18 09:10:12 $
#


rshift.psp <- function(X, ..., group=NULL, which=NULL) {
  verifyclass(X, "psp")
  
  # process arguments
  W <- rescue.rectangle(X$window)
  arglist <- handle.rshift.args(W, ..., edgedefault="erode")
  radius <- arglist$radius
  width  <- arglist$width
  height <- arglist$height
  edge   <- arglist$edge
  clip   <- arglist$clip
  if(W$type != "rectangle")
    stop("Not yet implemented for non-rectangular windows")
  if(edge != "erode")
    stop(paste("Only implemented for edge=", dQuote("erode")))

  # split into groups
  if(is.null(group))
    Y <- list(X)
  else {
    stopifnot(is.factor(group))
    stopifnot(length(group) == X$n)
    Y <- lapply(levels(group),
                function(l, X, group) {X[group == l]},
                X=X, group=group)
  }

  ############ loop ################
  result <- psp(numeric(0), numeric(0), numeric(0), numeric(0),
                X$window)
  
  for(i in seq_along(Y)) {
    
    Z <- Y[[i]]
    
    # generate random translation vector
    if(!is.null(radius)) 
      jump <- runifdisc(1, radius=radius)
    else {
      jump <- list(x=runif(1, min=0, max=width),
                   y=runif(1, min=0, max=height))
    }
    # translate segments
    Zsh <- shift(Z, c(jump$x, jump$y))
    Zsh$window <- W

    # append to result
    result <- append.psp(result, Zsh)
  }

  # clip 
  if(!is.null(clip))
   result <- result[clip]

  return(result)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/satpiece.R"
#
#
#    satpiece.S
#
#    $Revision: 1.14 $	$Date: 2012/01/18 11:04:54 $
#
#    Saturated pairwise interaction process with piecewise constant potential
#
#    SatPiece()   create an instance of the process
#                 [an object of class 'interact']
#	
#
# -------------------------------------------------------------------
#	

SatPiece <- local({

  # ..... auxiliary functions ......

  delSP <- function(i, r, sat) {
    r   <- r[-i]
    sat <- sat[-i]
    nr <- length(r)
    if(nr == 0) return(Poisson())
    if(nr == 1) return(Geyer(r, sat))
    return(SatPiece(r, sat))
  }

  # ....... template object ..........
  
  BlankSatPiece <- 
    list(
         name     = "piecewise constant Saturated pairwise interaction process",
         creator  = "SatPiece",
         family   = "pairsat.family", # evaluated later
         pot      = function(d, par) {
                       r <- par$r
                       nr <- length(r)
                       out <- array(FALSE, dim=c(dim(d), nr))
                       out[,,1] <- (d < r[1])
                       if(nr > 1) {
                         for(i in 2:nr) 
                           out[,,i] <- (d >= r[i-1]) & (d < r[i])
                       }
                       out
                    },
         par      = list(r = NULL, sat=NULL), # filled in later
         parnames = c("interaction thresholds", "saturation parameters"),
         init     = function(self) {
                      r <- self$par$r
                      sat <- self$par$sat
                      if(!is.numeric(r) || !all(r > 0))
                        stop("interaction thresholds r must be positive numbers")
                      if(length(r) > 1 && !all(diff(r) > 0))
                        stop("interaction thresholds r must be strictly increasing")
                      if(!is.numeric(sat) || any(sat < 0))
                        stop("saturation parameters must be nonnegative numbers")
                      if(any(ceiling(sat) != floor(sat)))
                        warning("saturation parameter has a non-integer value")
                      if(length(sat) != length(r) && length(sat) != 1)
                        stop("vectors r and sat must have equal length")
                    },
         update = NULL,  # default OK
         print = NULL,    # default OK
         interpret =  function(coeffs, self) {
           r <- self$par$r
           npiece <- length(r)
           # extract coefficients
           gammas <- exp(as.numeric(coeffs))
           # name them
           gn <- gammas
           names(gn) <- paste("[", c(0,r[-npiece]),",", r, ")", sep="")
           #
           return(list(param=list(gammas=gammas),
                       inames="interaction parameters gamma_i",
                       printable=dround(gn)))
         },
        valid = function(coeffs, self) {
           # interaction parameters gamma must be
           #   non-NA 
           #   finite, if sat > 0
           #   less than 1, if sat = Inf
           gamma <- (self$interpret)(coeffs, self)$param$gammas
           sat <- self$par$sat
           if(any(is.na(gamma)))
             return(FALSE)
           return(all((is.finite(gamma) | sat == 0)
                      & (gamma <= 1 | sat != Inf)))
        },
        project = function(coeffs, self){
          loggammas <- as.numeric(coeffs)
          sat <- self$par$sat
          r   <- self$par$r
          ok <- is.finite(loggammas) & (is.finite(sat) | loggammas <= 0)
          if(all(ok))
            return(NULL)
          if(!any(ok))
            return(Poisson())
          bad <- !ok
          if(spatstat.options("project.fast") || sum(bad) == 1) {
            # remove smallest threshold with an unidentifiable parameter
            firstbad <- min(which(bad))
            return(delSP(firstbad, r, sat))
          } else {
            # consider all candidate submodels
            subs <- lapply(which(bad), delSP, r=r, sat=sat)
            return(subs)
          }
        },
        irange = function(self, coeffs=NA, epsilon=0, ...) {
          r <- self$par$r
          sat <- self$par$sat
          if(all(is.na(coeffs)))
            return(2 * max(r))
          gamma <- (self$interpret)(coeffs, self)$param$gammas
          gamma[is.na(gamma)] <- 1
          active <- (abs(log(gamma)) > epsilon) & (sat > 0)
          if(!any(active))
            return(0)
          else return(2 * max(r[active]))
        },
       version=NULL # added later
  )
  class(BlankSatPiece) <- "interact"

  SatPiece <- function(r, sat) {
    instantiate.interact(BlankSatPiece, list(r=r, sat=sat))
  }

  SatPiece <- intermaker(SatPiece, BlankSatPiece)
  
  SatPiece
})


                  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/saturated.R"
#
#
#    saturated.S
#
#    $Revision: 1.7 $	$Date: 2014/10/24 00:22:30 $
#
#    Saturated pairwise process with user-supplied potential
#
#    Saturated()  create a saturated pairwise process
#                 [an object of class 'interact']
#                 with user-supplied potential
#	
#
# -------------------------------------------------------------------
#	

Saturated <- function(pot, name) {
  if(missing(name))
    name <- "Saturated process with user-defined potential"
  
  fop <- names(formals(pot))
  if(!identical(all.equal(fop, c("d", "par")), TRUE)
     && !identical(all.equal(fop, c("d", "tx", "tu", "par")), TRUE))
    stop(paste("Formal arguments of pair potential function",
               sQuote("pot"),
               "must be either (d, par) or (d, tx, tu, par)"))

  out <- 
  list(
         name     = name,
         creator  = "Saturated",
         family    = pairsat.family,
         pot      = pot,
         par      = NULL,
         parnames = NULL,
         init     = NULL,
         update   = function(self, ...){
           do.call(Saturated,
                   resolve.defaults(list(...),
                                    list(pot=self$pot, name=self$name)))
         } , 
         print = function(self) {
           cat("Potential function:\n")
           print(self$pot)
           invisible()
         },
       version=versionstring.spatstat()
  )
  class(out) <- "interact"
  return(out)
}

Saturated <-
    intermaker(Saturated,
               list(creator="Saturated",
                    name="saturated process with user-defined potential",
                    par=formals(Saturated),
                    parnames=list("the potential",
                        "the name of the interaction")))
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/scanstat.R"
##
##  scanstat.R
##
##  Spatial scan statistics
##
##  $Revision: 1.13 $  $Date: 2014/10/24 00:22:30 $
##

scanmeasure <- function(X, ...){
  UseMethod("scanmeasure")
}


scanmeasure.ppp <- function(X, r, ..., method=c("counts", "fft")) {
  method <- match.arg(method)
  check.1.real(r)
  ## enclosing window
  R <- as.rectangle(as.owin(X))
  ## determine pixel resolution  
  M <- as.mask(R, ...)
  ## expand domain to include centres of all circles intersecting R
  W <- grow.mask(M, r)
  ## 
  switch(method,
         counts = {
           ## direct calculation using C code
           ## get new dimensions
           dimyx <- W$dim
           xr <- W$xrange
           yr <- W$yrange
           nr <- dimyx[1]
           nc <- dimyx[2]
           ##
           n <- npoints(X)
           zz <- .C("scantrans",
                    x=as.double(X$x),
                    y=as.double(X$y),
                    n=as.integer(n),
                    xmin=as.double(xr[1]),
                    ymin=as.double(yr[1]),
                    xmax=as.double(xr[2]),
                    ymax=as.double(yr[2]),
                    nr=as.integer(nr),
                    nc=as.integer(nc),
                    R=as.double(r),
                    counts=as.integer(numeric(prod(dimyx))))
           zzz <- matrix(zz$counts, nrow=dimyx[1], ncol=dimyx[2], byrow=TRUE)
           Z <- im(zzz, xrange=xr, yrange=yr, unitname=unitname(X))
         },
         fft = {
           ## Previous version of scanmeasure.ppp had
           ##    Y <- pixellate(X, ..., padzero=TRUE)
           ## but this is liable to Gibbs phenomena.
           ## Instead, convolve with small Gaussian (sd = 1 pixel width)
           sigma <- with(W, unique(c(xstep, ystep)))
           Y <- density(X, ..., sigma=sigma)
           ## invoke scanmeasure.im
           Z <- scanmeasure(Y, r)
           Z <- eval.im(as.integer(round(Z)))
         })
  return(Z)
}

scanmeasure.im <- function(X, r, ...) {
  D <- disc(radius=r)
  eps <- with(X, c(xstep,ystep))
  if(any(eps >= 2 * r)) return(eval.im(X * pi * r^2))
  D <- as.im(as.mask(D, eps=eps))
  Z <- imcov(X, D)
  return(Z)
}

scanPoisLRTS <- function(nZ, nG, muZ, muG, alternative) {
  nZco <- nG - nZ
  muZco <- muG - muZ
  nlogn <- function(n, a) ifelse(n == 0, 0, n * log(n/a))
  ll <- nlogn(nZ, muZ) + nlogn(nZco, muZco) - nlogn(nG, muG)
  criterion <- (nZ * muZco - muZ * nZco)
  switch(alternative,
         less={
           ll[criterion > 0] <- 0
         },
         greater={
           ll[criterion < 0] <- 0
         },
         two.sided={})
  return(2 * ll)
}

scanBinomLRTS <- function(nZ, nG, muZ, muG, alternative) {
  nZco <- nG - nZ
  muZco <- muG - muZ
  nlogn <- function(n, a) ifelse(n == 0, 0, n * log(n/a))
  logbin <- function(k, n) { nlogn(k, n) + nlogn(n-k, n) }
  ll <- logbin(nZ, muZ) + logbin(nZco, muZco) - logbin(nG, muG)
  criterion <- (nZ * muZco - muZ * nZco)
  switch(alternative,
         less={
           ll[criterion > 0] <- 0
         },
         greater={
           ll[criterion < 0] <- 0
         },
         two.sided={})
  return(2 * ll)
}

scanLRTS <- function(X, r, ...,
                       method=c("poisson", "binomial"),
                       baseline=NULL,
                       case=2,
                       alternative=c("greater", "less", "two.sided"),
                       saveopt = FALSE,
                       Xmask=NULL) {
  stopifnot(is.ppp(X))
  stopifnot(check.nvector(r))
  method <- match.arg(method)
  alternative <- match.arg(alternative)
  if(is.null(Xmask)) Xmask <- as.mask(as.owin(X), ...)
  switch(method,
         poisson={
           Y <- X
           if(is.null(baseline)) {
             mu <- as.im(Xmask, value=1)
           } else if(is.ppm(baseline)) {
             if(is.marked(baseline))
               stop("baseline is a marked point process: not supported")
             mu <- predict(baseline, locations=Xmask)
           } else if(is.im(baseline) || is.function(baseline)) {
             mu <- as.im(baseline, W=Xmask)
           } else stop(paste("baseline should be",
                             "a pixel image, a function, or a fitted model"))
           nG <- npoints(Y)
         },
         binomial={
           stopifnot(is.multitype(X))
           lev <- levels(marks(X))
           if(length(lev) != 2)
             warning("X should usually be a bivariate (2-type) point pattern")
           if(!is.null(baseline))
             stop("baseline is not supported in the binomial case")
           if(is.character(case) && !(case %in% lev))
             stop(paste("Unrecognised label for cases:", sQuote(case)))
           if(is.numeric(case) && !(case %in% seq_along(lev)))
             stop(paste("Undefined level:", case))
           Y <- split(X)[[case]]
           nG <- npoints(Y)
           mu <- unmark(X)
         })
  ## The following line ensures that the same pixel resolution information
  ## is passed to the two calls to 'scanmeasure' below
  Y$window <- Xmask
  ## 
  nr <- length(r)
  lrts <- vector(mode="list", length=nr)
  for(i in 1:nr) {
    ri <- r[i]
    nZ <- scanmeasure(Y, ri)
    muZ <- scanmeasure(mu, ri)
    if(!compatible.im(nZ, muZ)) {
      ha <- harmonise.im(nZ, muZ)
      nZ <- ha[[1]]
      muZ <- ha[[2]]
    }
    switch(method,
           poisson = {
             muG <- integral.im(mu)
             lrts[[i]] <- eval.im(scanPoisLRTS(nZ, nG, muZ, muG, alternative))
           },
           binomial = {
             muG <- npoints(mu)
             lrts[[i]] <- eval.im(scanBinomLRTS(nZ, nG, muZ, muG, alternative))
           })
  }
  if(length(lrts) == 1) {
    result <- lrts[[1]]
  } else {
    result <- im.apply(lrts, max)
    if(saveopt)
      attr(result, "iopt") <- im.apply(lrts, which.max)
  }
  return(result)
}

scan.test <- function(X, r, ...,
                      method=c("poisson", "binomial"),
                      nsim = 19,
                      baseline=NULL,
                      case = 2,
                      alternative=c("greater", "less", "two.sided"),
                      verbose=TRUE) {
  dataname <- short.deparse(substitute(X))
  stopifnot(is.ppp(X))
  method <- match.arg(method)
  alternative <- match.arg(alternative)
  stopifnot(is.numeric(r))
  check.1.real(nsim)
  if(!(round(nsim) == nsim && nsim > 1))
    stop("nsim should be an integer > 1")
  regionname <-
    paste("circles of radius",
          if(length(r) == 1) r else paste("between", min(r), "and", max(r)))
  ##
  ## compute observed loglikelihood function
  ## This also validates the arguments.
  obsLRTS <- scanLRTS(X=X, r=r,
                          method=method,
                          alternative=alternative, baseline=baseline,
                          case=case, ..., saveopt=TRUE)
  obs <- max(obsLRTS)
  sim <- numeric(nsim)
  ## determine how to simulate
  switch(method,
         binomial={
           methodname <- c("Spatial scan test",
                           "Null hypothesis: constant relative risk",
                           paste("Candidate cluster regions:", regionname),
                           "Likelihood: binomial",
                           paste("Monte Carlo p-value based on",
                                 nsim, "simulations"))

           lev <- levels(marks(X))
           names(lev) <- lev
           casename <- lev[case]
           counted <- paste("points with mark", sQuote(casename), 
                            "inside cluster region")
           simexpr <- expression(rlabel(X))
         },
         poisson={
           counted <- paste("points inside cluster region")
           X <- unmark(X)
           Xwin <- as.owin(X)
           Xmask <- as.mask(Xwin, ...)
           if(is.null(baseline)) {
             nullname <- "Complete Spatial Randomness (CSR)"
             lambda <- intensity(X)
             simexpr <- expression(runifpoispp(lambda, Xwin))
           } else if(is.ppm(baseline)) {
             nullname <- baseline$callstring
             rmhstuff <- rmh(baseline, preponly=TRUE, verbose=FALSE)
             simexpr <- expression(rmhEngine(rmhstuff))
           } else if(is.im(baseline) || is.function(baseline)) {
             nullname <- "Poisson process with intensity proportional to baseline"
             base <- as.im(baseline, W=Xmask)
             alpha <- npoints(X)/integral.im(base)
             lambda <- eval.im(alpha * base)
             simexpr <- expression(rpoispp(lambda))
           } else stop(paste("baseline should be",
                             "a pixel image, a function, or a fitted model"))
           methodname <- c("Spatial scan test",
                           paste("Null hypothesis:", nullname),
                           paste("Candidate cluster regions:", regionname),
                           "Likelihood: Poisson",
                           paste("Monte Carlo p-value based on",
                                 nsim, "simulations"))
         })
  if(verbose) cat("Simulating...")
  for(i in 1:nsim) {
    if(verbose) progressreport(i, nsim)
    Xsim <- eval(simexpr)
    simLRTS <- scanLRTS(X=Xsim, r=r,
                         method=method, alternative=alternative,
                         baseline=baseline,
                         case=case,
                         ...)
    sim[i] <- max(simLRTS)
  }
  pval <- mean(c(sim,obs) >= obs, na.rm=TRUE)
  names(obs) <- "maxLRTS"
  nm.alternative <- switch(alternative,
                           greater="Excess of",
                           less="Deficit of",
                           two.sided="Two-sided: excess or deficit of",
                           stop("Unknown alternative"))
  nm.alternative <- paste(nm.alternative, counted)
  result <- list(statistic = obs,
                 p.value = pval,
                 alternative = nm.alternative, 
                 method = methodname,
                 data.name = dataname)
  class(result) <- c("scan.test", "htest")
  attr(result, "obsLRTS") <- obsLRTS
  attr(result, "X") <- X
  attr(result, "r") <- r
  return(result)
}

plot.scan.test <- function(x, ..., what=c("statistic", "radius"),
                           do.window=TRUE) {
  xname <- short.deparse(substitute(x))
  what <- match.arg(what)
  Z <- as.im(x, what=what)
  do.call("plot", resolve.defaults(list(x=Z), list(...), list(main=xname)))
  if(do.window) {
    X <- attr(x, "X")
    plot(as.owin(X), add=TRUE, invert=TRUE)
  }
  invisible(NULL)
}

as.im.scan.test <- function(X, ..., what=c("statistic", "radius")) {
  Y <- attr(X, "obsLRTS")
  what <- match.arg(what)
  if(what == "radius") {
    iopt <- attr(Y, "iopt")
    r <- attr(X, "r")
    Y <- eval.im(r[iopt])
  }
  return(as.im(Y, ...))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/scriptUtils.R"
## scriptUtils.R
##       $Revision: 1.4 $ $Date: 2014/02/07 06:58:43 $

## slick way to use precomputed data
##    If the named file exists, it is loaded, giving access to the data.
##    Otherwise, 'expr' is evaluated, and all objects created
##    are saved in the designated file, for loading next time.

reload.or.compute <- function(filename, expr, 
                              objects=NULL,
                              destination=parent.frame()) {
  stopifnot(is.character(filename) && length(filename) == 1)
  if(!file.exists(filename)) {
    ## evaluate 'expr' in a fresh environment
    ee <- as.expression(substitute(expr))
    en <- new.env()
    local(eval(ee), envir=en)
    ## default is to save all objects that were created
    if(is.null(objects))
      objects <- ls(envir=en)
    ## save them in the designated file
    evalq(save(list=objects, file=filename, compress=TRUE), envir=en)
    ## assign them into the parent frame 
    for(i in seq_along(objects))
      assign(objects[i], get(objects[i], envir=en), envir=destination)
    result <- objects
  } else {
    result <- load(filename, envir=destination)
    if(!all(ok <- (objects %in% result))) {
      nbad <- sum(!ok)
      warning(paste(ngettext(nbad, "object", "objects"),
                    commasep(sQuote(objects[!ok])),
                    ngettext(nbad, "was", "were"),
                    "not present in data file", dQuote(filename)),
              call.=FALSE)
    }
  }
  return(invisible(result))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/setcov.R"
#
#
#     setcov.R
#
#     $Revision: 1.11 $ $Date: 2012/10/10 06:48:16 $
#
#    Compute the set covariance function of a window
#    or the (noncentred) spatial covariance function of an image
#

setcov <- function(W, V=W, ...) {
  W <- as.owin(W)
  # pixel approximation
  mW <- as.mask(W, ...)
  Z <- as.im(mW, na.replace=0)
  if(missing(V)) 
    return(imcov(Z))
  # cross-covariance
  V <- as.owin(V)
  mV <- as.mask(V, ...)
  Z2 <- as.im(mV, na.replace=0)
  imcov(Z, Z2)
}

imcov <- function(X, Y=X) {
  if(missing(Y)) Y <- NULL
  convolve.im(X, Y, reflectX = FALSE, reflectY=TRUE)
}

convolve.im <- function(X, Y=X, ..., reflectX=FALSE, reflectY=FALSE) {
  stopifnot(is.im(X))
  have.Y <- !missing(Y) && !is.null(Y)
  crosscov <- have.Y || reflectX || reflectY
  trap.extra.arguments(..., .Context="In convolve.im")
  #
  if(have.Y) {
    # cross-covariance 
    stopifnot(is.im(Y))
    Xbox <- as.rectangle(X)
    Ybox <- as.rectangle(Y)
    # first shift images to common midpoint, to reduce storage
    Xmid <- centroid.owin(Xbox)
    Ymid <- centroid.owin(Ybox)
    svec <- as.numeric(Xmid) - as.numeric(Ymid)
    Y <- shift(Y, svec)
    # ensure images are compatible
    XY <- harmonise.im(X=X, Y=Y)
    X <- XY$X
    Y <- XY$Y
  } else {
    # Y is missing or NULL
    Y <- X
    Xbox <- Ybox <- as.rectangle(X)
  }
  M <- X$v
  M[is.na(M)] <- 0
  xstep <- X$xstep
  ystep <- X$ystep
  # pad with zeroes
  nr <- nrow(M)
  nc <- ncol(M)
  Mpad <- matrix(0, ncol=2*nc, nrow=2*nr)
  Mpad[1:nr, 1:nc] <- M
  lengthMpad <- 4 * nc * nr
  fM <- fft(Mpad)
  if(!crosscov) {
    # compute convolution square
    G <- fft(fM^2, inverse=TRUE)/lengthMpad
  } else {
    # compute set cross-covariance or convolution by fft
    N <- Y$v
    N[is.na(N)] <- 0
    Npad <- matrix(0, ncol=2*nc, nrow=2*nr)
    Npad[1:nr, 1:nc] <- N
    fN <- fft(Npad)
    if(reflectY) fN <- Conj(fN)
    if(reflectX) fM <- Conj(fM)
    G <- fft(fM * fN, inverse=TRUE)/lengthMpad
  }
#  cat(paste("maximum imaginary part=", max(Im(G)), "\n"))
  G <- Mod(G) * xstep * ystep
  if(reflectX != reflectY) {
    # Currently G[i,j] corresponds to a vector shift of
    #     dy = (i-1) mod nr, dx = (j-1) mod nc.
    # Rearrange this periodic function so that 
    # the origin of translations (0,0) is at matrix position (nr,nc)
    # NB this introduces an extra row and column
    G <- G[ ((-nr):nr) %% (2 * nr) + 1, (-nc):nc %% (2*nc) + 1]
  }
  # Determine spatial domain of full raster image
  XB <- as.rectangle(X)
  YB <- as.rectangle(Y)
  # undo shift
  if(have.Y) YB <- shift(YB, -svec)
  # reflect
  if(reflectX) XB <- reflect(XB)
  if(reflectY) YB <- reflect(YB)
  # Minkowski sum of covering boxes
  xran <- XB$xrange + YB$xrange
  yran <- XB$yrange + YB$yrange
  # Declare spatial domain
  out <- im(G, xrange = xran, yrange=yran)
  if(crosscov) {
    # restrict to actual spatial domain of function
    if(reflectX) Xbox <- reflect(Xbox)
    if(reflectY) Ybox <- reflect(Ybox)
   # Minkowski sum 
    xran <- Xbox$xrange + Ybox$xrange
    yran <- Xbox$yrange + Ybox$yrange   
    XYbox <- owin(xran, yran)
    out <- out[XYbox, rescue=TRUE]
  }
  return(out)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/sharpen.R"
#
#      sharpen.R
#
#      $Revision: 1.6 $  $Date: 2013/08/29 03:52:17 $
#

sharpen <- function(X, ...) {
  UseMethod("sharpen")
}

sharpen.ppp <- function(X, sigma=NULL, ..., varcov=NULL,
                        edgecorrect=FALSE) {
  stopifnot(is.ppp(X))
  Yx <- Smooth(X %mark% X$x,
               at="points", sigma=sigma, varcov=varcov, edge=TRUE)
  Yy <- Smooth(X %mark% X$y,
               at="points", sigma=sigma, varcov=varcov, edge=TRUE)
  # trap NaN etc
  nbad <- sum(!(is.finite(Yx) & is.finite(Yy)))
  if(nbad > 0)
    stop(paste(nbad,
               ngettext(nbad, "point is", "points are"),
               "undefined due to numerical problems;",
               "smoothing parameter is probably too small"))
  #
  W <- as.owin(X)
  if(edgecorrect) {
    # convolve x and y coordinate functions with kernel
    xim <- as.im(function(x,y){x}, W)
    yim <- as.im(function(x,y){y}, W)
    xblur <- blur(xim, sigma=sigma, varcov=varcov, normalise=TRUE, ...)
    yblur <- blur(yim, sigma=sigma, varcov=varcov, normalise=TRUE, ...)
    # evaluate at data locations 
    xx <- safelookup(xblur, X, warn=FALSE)
    yy <- safelookup(yblur, X, warn=FALSE)
    # estimated vector bias of sharpening procedure
    xbias <- xx - X$x
    ybias <- yy - X$y
    # adjust
    Yx <- Yx - xbias
    Yy <- Yy - ybias
    # check this does not place points outside window
    if(any(uhoh <- !inside.owin(Yx, Yy, W))) {
      # determine mass of edge effect
      edgeim <- blur(as.im(W), sigma=sigma, varcov=varcov, normalise=FALSE, ...)
      edg <- safelookup(edgeim, X[uhoh], warn=FALSE)
      # contract bias correction
      Yx[uhoh] <- (1 - edg) * X$x[uhoh] + edg * Yx[uhoh]
      Yy[uhoh] <- (1 - edg) * X$y[uhoh] + edg * Yy[uhoh]
    }
    # check again
    if(any(nbg <- !inside.owin(Yx, Yy, W))) {
      # give up
      Yx[nbg] <- X$x[nbg]
      Yy[nbg] <- X$y[nbg]
    }
  }
  # make point pattern
  Y <- ppp(Yx, Yy, marks=marks(X), window=W)
  # tack on smoothing information
  attr(Y, "sigma") <- sigma
  attr(Y, "varcov") <- varcov
  attr(Y, "edgecorrected") <- edgecorrect
  return(Y)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/simplepanel.R"
#
# simplepanel.R
#
#  A simple, robust point & click interface
#     used in rmh visual debugger.
#
#  $Revision: 1.13 $  $Date: 2014/11/11 02:37:44 $
#

simplepanel <- function(title, B, boxes, clicks, redraws=NULL, exit=NULL, env) {
  stopifnot(is.rectangle(B))
  stopifnot(is.list(boxes))
  if(!all(unlist(lapply(boxes, is.rectangle))))
    stop("some of the boxes are not rectangles")
  if(!all(unlist(lapply(boxes, is.subset.owin, B=B))))
    stop("Some boxes do not lie inside the bounding box B")
  stopifnot(is.list(clicks) && length(clicks) == length(boxes))
  if(!all(unlist(lapply(clicks, is.function))))
    stop("clicks must be a list of functions")
  if(is.null(redraws)) {
    redraws <- rep.int(list(dflt.redraw), length(boxes))
  } else {
    stopifnot(is.list(redraws) && length(redraws) == length(boxes))
    if(any(isnul <- unlist(lapply(redraws, is.null))))
      redraws[isnul] <- rep.int(list(dflt.redraw), sum(isnul))
    if(!all(unlist(lapply(redraws, is.function))))
      stop("redraws must be a list of functions")
  }
  if(is.null(exit)) {
    exit <- function(...) { NULL}
  } else stopifnot(is.function(exit))
  stopifnot(is.environment(env))
  n <- length(boxes)
  got.boxnames <- (sum(nzchar(names(boxes))) == n)
  got.clicknames <- (sum(nzchar(names(clicks))) == n)
  nama <- if(got.boxnames && !got.clicknames) names(boxes) else
          if(got.clicknames && !got.boxnames) names(clicks) else
          paste("Button", seq_len(n))
  out <- list(title=title, B=B,
              nama=nama, boxes=boxes, clicks=clicks, redraws=redraws,
              exit=exit, env=env)
  class(out) <- c("simplepanel", class(out))
  return(out)
}

grow.simplepanel <- function(P, side=c("right","left","top","bottom"),
                             len=NULL,
                             new.clicks, new.redraws=NULL, ..., aspect) {
  verifyclass(P, "simplepanel")
  side <- match.arg(side)
  stopifnot(is.list(new.clicks))
  if(!all(unlist(lapply(new.clicks, is.function))))
    stop("new.clicks must be a list of functions")
  if(is.null(new.redraws)) {
    new.redraws <- rep.int(list(dflt.redraw), length(new.clicks))
  } else {
    stopifnot(is.list(new.redraws) && length(new.redraws) == length(new.clicks))
    if(!all(unlist(lapply(new.redraws, is.function))))
      stop("new.redraws must be a list of functions")
  }
  if(missing(aspect) || is.null(aspect)) {
    # determine aspect ratio from length of longest text string
    n <- length(new.clicks)
    nama <- names(new.clicks)
    if(sum(nzchar(nama)) != n)
      nama <- names(new.redraws)
    if(sum(nzchar(nama)) != n)
      nama <- paste("Box", seq_len(n))
    aspect <- 3/max(4, nchar(nama))
  }
  B <- P$B
  n <- length(new.clicks)
  switch(side,
         right={
           new.width <- if(!is.null(len)) len else sidelengths(B)[1]/2
           extraspace <- owin(B$xrange[2] + c(0, new.width), B$yrange)
           new.boxes <- layout.boxes(extraspace, n, ..., aspect=aspect)
         },
         left={
           new.width <- if(!is.null(len)) len else sidelengths(B)[1]/2
           extraspace <- owin(B$xrange[1] - c(new.width, 0), B$yrange)
           new.boxes <- layout.boxes(extraspace, n, ..., aspect=aspect)
         },
         top={
           new.height <- if(!is.null(len)) len else sidelengths(B)[2]/2
           extraspace <- owin(B$xrange, B$yrange[2] + c(0, new.height))
           new.boxes <- layout.boxes(extraspace, n, ..., aspect=aspect,
                                     horizontal=TRUE)
         },
         bottom={
           new.height <- if(!is.null(len)) len else sidelengths(B)[2]/2
           extraspace <- owin(B$xrange, B$yrange[1] - c(new.height, 0))
           new.boxes <- layout.boxes(extraspace, n, ..., aspect=aspect,
                                     horizontal=TRUE)
         })
  with(P, simplepanel(title,
                      boundingbox(B, extraspace),
                      append(boxes, new.boxes),
                      append(clicks, new.clicks),
                      append(redraws, new.redraws),
                      exit, env))
}

                             
redraw.simplepanel <- function(P, verbose=FALSE) {
  verifyclass(P, "simplepanel")
  if(verbose)
    cat("Redrawing entire panel\n")
  with(P, {
#    ntitle <- sum(nzchar(title))
    plot(B, type="n", main=title)
    for(j in seq_along(nama)) 
      (redraws[[j]])(boxes[[j]], nama[j], env)
  })
  invisible(NULL)
}

clear.simplepanel <- function(P) {
  verifyclass(P, "simplepanel")
  plot(P$B, main="")
  invisible(NULL)
}
                             
run.simplepanel <- function(P, popup=TRUE, verbose=FALSE) {
  verifyclass(P, "simplepanel")
  if(popup) dev.new()
  ntitle <- sum(nzchar(P$title))
  opa <- par(mar=c(0,0,ntitle+0.2,0),ask=FALSE)
  with(P, {
    # interaction loop
    more <- TRUE
    while(more) {
      redraw.simplepanel(P, verbose=verbose)
      xy <- locator(1)
      if(is.null(xy)) {
        if(verbose) cat("No (x,y) coordinates\n")
        break
      }
      found <- FALSE
      for(j in seq_along(boxes)) {
        if(inside.owin(xy$x, xy$y, boxes[[j]])) {
          found <- TRUE
          if(verbose) cat(paste("Caught click on", sQuote(nama[j]), "\n"))
          more <- (clicks[[j]])(env, xy)
          if(!is.logical(more) || length(more) != 1) {
            warning(paste("Click function for",
                          sQuote(nama[j]),
                          "did not return TRUE/FALSE"))
            more <- FALSE
          }
          if(verbose) cat(if(more) "Continuing\n" else "Terminating\n")
          break
        }
      }
      if(verbose && !found)
        cat(paste("Coordinates", paren(paste(xy, collapse=",")),
                  "not matched to any box\n"))
    }
  })
  if(verbose)
    cat("Calling exit function\n")

  rslt <- with(P, exit(env))
  
  # revert to original graphics parameters
  par(opa)
  # close popup window?
  if(popup) dev.off()
  
  # return value of 'exit' function
  return(rslt)
}

layout.boxes <- function(B, n, horizontal=FALSE, aspect=0.5, usefrac=0.9){
  # make n boxes in B
  stopifnot(is.rectangle(B))
  stopifnot(n > 0)
  width <- sidelengths(B)[1]
  height <- sidelengths(B)[2]
  if(!horizontal) {
    heightshare <- height/n
    useheight <- min(width * aspect, heightshare * usefrac)
    usewidth <-  min(useheight /aspect, width * usefrac)
    lostwidth <- width - usewidth
    lostheightshare <- heightshare - useheight
    template <- owin(c(0, usewidth), c(0, useheight))
    boxes <- list()
    boxes[[1]] <- shift(template,
                        c(B$xrange[1]+lostwidth/2,
                          B$yrange[1] + lostheightshare/2))
    if(n > 1) 
      for(j in 2:n) 
        boxes[[j]] <- shift(boxes[[j-1]], c(0, heightshare))
  } else {
    boxes <- layout.boxes(flipxy(B), n,
                            horizontal=FALSE, aspect=1/aspect, usefrac=usefrac)
    boxes <-  lapply(boxes, flipxy)
  }
  return(boxes)
}

# default redraw function for control buttons

dflt.redraw <- function(button, name, env) {
  plot(button, add=TRUE, border="pink")
  text(centroid.owin(button), labels=name)
}

print.simplepanel <- function(x, ...) {
  nama <- x$nama
  cat("simplepanel object\n")
  cat(paste("\tTitle:", sQuote(x$title), "\n"))
  cat("\tPanel names:")
  for(i in seq_along(nama)) {
    if(i %% 6 == 1) cat("\n\t")
    cat(paste0(sQuote(nama[i]), "  "))
  }
  cat("\n")
  return(invisible(NULL))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/simulatelppm.R"
##
## simulatelppm.R
##
##  Simulation of lppm objects
##
##  $Revision: 1.5 $  $Date: 2014/06/06 03:10:41 $
##

simulate.lppm <- function(object, nsim=1, ...,
                          new.coef=NULL,
                          progress=(nsim > 1)) {
  starttime <- proc.time()
  if(!is.poisson(object$fit))
    stop("Simulation of non-Poisson models is not yet implemented")
  lambda <- predict(object, ..., new.coef=new.coef)
  lmax <- if(is.im(lambda)) max(lambda) else unlist(lapply(lambda, max))
  L <- as.linnet(object)
  result <- vector(mode="list", length=nsim)
  for(i in seq_len(nsim)) {
    if(progress) progressreport(i, nsim)
    result[[i]] <- rpoislpp(lambda, L, lmax=lmax)
  }
  result <- as.listof(result)
  result <- timed(result, starttime=starttime)
  return(result)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/slrm.R"
#
#  slrm.R
#
#  Spatial Logistic Regression
#
#  $Revision: 1.24 $   $Date: 2013/09/05 07:44:08 $
#

slrm <- function(formula, ..., data=NULL, offset=TRUE, link="logit",
                 dataAtPoints=NULL, splitby=NULL) {
  
  # remember call
  CallInfo <- list(callstring = short.deparse(sys.call()),
                   cl = match.call(),
                   formula = formula,
                   offset=offset,
                   link=link,
                   splitby=splitby,
                   dotargs=list(...))
  if(!(link %in% c("logit", "cloglog")))
    stop(paste("Unrecognised link", dQuote(link)))

  ########### INTERPRET FORMULA ##############################
  
  if(!inherits(formula, "formula"))
    stop(paste("Argument", dQuote("formula"), "should be a formula"))

  # check formula has LHS and RHS. Extract them
  if(length(formula) < 3)
    stop(paste("Argument", sQuote("formula"),
               "must have a left hand side"))
  Yname <- formula[[2]]
  trend <- rhs <- formula[c(1,3)]
  if(!is.name(Yname))
    stop("Left hand side of formula should be a single name")
  Yname <- paste(Yname)
  if(!inherits(trend, "formula"))
    stop("Internal error: failed to extract RHS of formula")

  varnames <- unique(variablesinformula(trend))
  specials <- c("x", "y", "logpixelarea")
  covnames <- varnames[!(varnames %in% specials)]

  # add 'splitby' to covariate names
  if(!is.null(splitby)) {
    if(!is.character(splitby) || length(splitby) != 1)
      stop("splitby should be a single character string")
    covnames <- unique(c(covnames, splitby))
  }

  CallInfo$responsename <- Yname
  CallInfo$varnames     <- varnames
  CallInfo$covnames     <- covnames
  
  # Parent environment
  parenv <- environment(formula)

  ########  FIND DATA AND RESHAPE #######################

  Data <- slr.prepare(CallInfo, parenv, data, dataAtPoints, splitby)

#  W  <- Data$W
  df <- Data$df
  
  ########  FIT MODEL ###############################

  dformula <- formula
  if(offset) {
    # insert offset term in formula
    rhs <- paste(as.character(rhs), collapse=" ")
    rhs <- paste(c(rhs, "offset(logpixelarea)"), collapse="+")
    dformula <- as.formula(paste(Yname, rhs))
  }

  linkname <- link
  FIT  <- glm(dformula, family=binomial(link=linkname),
              data=df, na.action=na.exclude)

  result <- list(call     = CallInfo$cl,
                 CallInfo = CallInfo,
                 Data     = Data,
                 Fit      = list(FIT=FIT, dformula=dformula),
                 terms    = terms(formula))

  class(result) <- c("slrm", class(result))
  return(result)
}

################ UTILITY TO FIND AND RESHAPE DATA #################

slr.prepare <- function(CallInfo, envir, data,
                        dataAtPoints=NULL, splitby=NULL,
                        clip=TRUE) {
  # CallInfo is produced by slrm()
  # envir is parent environment of model formula
  # data  is 'data' argument that takes precedence over 'envir'
  # 'clip' is TRUE if the data should be clipped to the domain of Y
  Yname    <- CallInfo$responsename
#  varnames <- CallInfo$varnames
  covnames <- CallInfo$covnames
  dotargs  <- CallInfo$dotargs
  #
  getobj <- function(nama, env, dat) {
    if(!is.null(dat) && !is.null(x <- dat[[nama]]))
      return(x)
    else return(get(nama, envir=env))
  }
  # Get the response point pattern Y 
  Y <- getobj(Yname, envir, data)
  if(!is.ppp(Y))
    stop(paste("The response", sQuote(Yname), "must be a point pattern"))
  #
  if(!is.null(dataAtPoints)) {
    dataAtPoints <- as.data.frame(dataAtPoints)
    if(nrow(dataAtPoints) != npoints(Y))
      stop(paste("dataAtPoints should have one row for each point in",
                 dQuote(Yname)))
  }
  # Find the covariates
  ncov <- length(covnames)
  covlist <- lapply(as.list(covnames), getobj, env = envir, dat=data)
  names(covlist) <- covnames
  # Each covariate should be an image, a window, a function, or a single number
  if(ncov == 0) {
    isim <- isowin <- ismask <- isfun <- isnum <- isspatial <- israster <- logical(0)
  } else {
    isim  <- unlist(lapply(covlist, is.im))
    isowin  <- unlist(lapply(covlist, is.owin))
    ismask  <- unlist(lapply(covlist, is.mask))
    isfun  <- unlist(lapply(covlist, is.function))
    isspatial <- isim | isowin | isfun
    israster <- isim | ismask
    isnum <- unlist(lapply(covlist,
                           function(x) { is.numeric(x) && length(x) == 1} ))
  }
  if(!all(ok <- (isspatial | isnum))) {
    n <- sum(!ok)
    stop(paste(ngettext(n, "The argument", "Each of the arguments"),
               commasep(sQuote(covnames[!ok])),
               "should be either an image, a window, or a single number"))
  }
  # 'splitby' 
  if(!is.null(splitby)) {
    splitwin <- covlist[[splitby]]
    if(!is.owin(splitwin))
      stop("The splitting covariate must be a window")
    # ensure it is a polygonal window
    covlist[[splitby]] <- splitwin <- as.polygonal(splitwin)
    # delete splitting covariate from lists to be processed
    issplit <- (covnames == splitby)
    isspatial[issplit] <- FALSE
    israster[issplit] <- FALSE
  }
  # 
#  nnum <- sum(isnum)
#  nspatial <- sum(isspatial)
  nraster <- sum(israster)
  #
  numlist <- covlist[isnum]
  spatiallist <- covlist[isspatial]
  rasterlist <- covlist[israster]
  #
  numnames <- names(numlist)
  spatialnames <- names(spatiallist)
#  rasternames <- names(rasterlist)
  #
  
  ########  CONVERT TO RASTER DATA  ###############################

  convert <- function(x,W) {
    if(is.im(x) || is.function(x)) return(as.im(x,W))
    if(is.owin(x)) return(as.im(x, W, value=TRUE, na.replace=FALSE))
    return(NULL)
  }

  # determine spatial domain & common resolution: convert all data to it
  if(length(dotargs) > 0 || nraster == 0) {
    # Pixel resolution is determined by explicit arguments
    if(clip) {
      # Window extent is determined by response point pattern
      D <- as.owin(Y)
    } else {
      # Window extent is union of domains of data
      domains <- lapply(append(spatiallist, list(Y)), as.owin)
      D <- do.call("union.owin", domains)
    }
    # Create template mask
    W <- do.call("as.mask", append(list(D), dotargs))
    # Convert all spatial objects to this resolution
    spatiallist <- lapply(spatiallist, convert, W=W)
  } else {
    # Pixel resolution is determined implicitly by covariate data
    W <- do.call("commonGrid", rasterlist)
    if(clip) {
      # Restrict data to spatial extent of response point pattern
      W <- intersect.owin(W, as.owin(Y))
    }
    # Adjust spatial objects to this resolution
    spatiallist <- lapply(spatiallist, convert, W=W)
  }
  # images containing coordinate values
  xcoordim <- as.im(function(x,y){x}, W=W)
  ycoordim <- as.im(function(x,y){y}, W=W)
  #
  # create a list of covariate images, with names as in formula
  covimages <- append(list(x=xcoordim, y=ycoordim), spatiallist)

  basepixelarea <- W$xstep * W$ystep

  ########  ASSEMBLE DATA FRAME  ###############################

  if(is.null(splitby)) {
    df <- slrAssemblePixelData(Y, Yname, W,
                               covimages, dataAtPoints, basepixelarea)
    sumYloga <- Y$n * log(basepixelarea)
    serial <- attr(df, "serial")
  } else {
    # fractional pixel areas
    pixsplit <- pixellate(splitwin, W)
    splitpixelarea <- as.vector(as.matrix(pixsplit))
    # determine which points of Y are inside/outside window
    ins <- inside.owin(Y$x, Y$y, splitwin)
    # split processing
    dfIN <- slrAssemblePixelData(Y[ins], Yname, W, covimages,
                                 dataAtPoints[ins, ], splitpixelarea)
    serialIN <- attr(dfIN, "serial")
    dfIN[[splitby]] <- TRUE
    dfOUT <- slrAssemblePixelData(Y[!ins], Yname, W, covimages,
                                  dataAtPoints[!ins, ],
                                  basepixelarea - splitpixelarea)
    serialOUT <- attr(dfOUT, "serial")
    dfOUT[[splitby]] <- FALSE
    df <- rbind(dfIN, dfOUT)
    serial <- c(serialIN, serialOUT)
    # sum of log pixel areas associated with points
    Ysplit <- pixsplit[Y]
    sumYloga <- sum(log(ifelseXY(ins, Ysplit, basepixelarea - Ysplit)))
  }
  
  # tack on any numeric values
  df <- do.call("cbind", append(list(df), numlist))
  
  ### RETURN ALL 
  Data <- list(response=Y,
               covariates=covlist,
               spatialnames=spatialnames,
               numnames=numnames,
               W=W,
               df=df,
               serial=serial,
               sumYloga=sumYloga,
               dataAtPoints=dataAtPoints)
  return(Data)
}

#  
slrAssemblePixelData <- function(Y, Yname, W,
                                 covimages, dataAtPoints, pixelarea) {
  # pixellate point pattern
  Z <- pixellate(Y, W=W)
  Z <- eval.im(as.integer(Z>0))
  # overwrite pixel entries for data points using exact values
  # coordinates
  xcoordim <- covimages[["x"]]
  ycoordim <- covimages[["y"]]
  xcoordim[Y] <- Y$x
  ycoordim[Y] <- Y$y
  covimages[["x"]] <- xcoordim
  covimages[["y"]] <- ycoordim
  # overwrite pixel entries
  if(!is.null(dataAtPoints)) {
    enames <- colnames(dataAtPoints)
    relevant <- enames %in% names(covimages)
    for(v in enames[relevant]) {
      cova <- covimages[[v]]
      cova[Y] <- dataAtPoints[, v, drop=TRUE]
      covimages[[v]] <- cova
    }
  }
  # assemble list of all images
  Ylist <- list(Z)
  names(Ylist) <- Yname
  allimages <- append(Ylist, covimages)
  # extract pixel values of each image
  pixelvalues <-
    function(z) {
      v <- as.vector(as.matrix(z))
      if(z$type != "factor") return(v)
      lev <- levels(z)
      return(factor(v, levels=seq_along(lev), labels=lev))
    }
  pixdata <- lapply(allimages, pixelvalues)
  df <- as.data.frame(pixdata)
  serial <- seq_len(nrow(df))
  # add log(pixel area) column
  if(length(pixelarea) == 1) {
    df <- cbind(df, logpixelarea=log(pixelarea))
  } else {
    ok <- (pixelarea > 0)
    df <- cbind(df[ok, ], logpixelarea=log(pixelarea[ok]))
    serial <- serial[ok]
  }
  attr(df, "serial") <- serial
  return(df)
}

is.slrm <- function(x) {
  inherits(x, "slrm")
}

coef.slrm <- function(object, ...) {
  coef(object$Fit$FIT)
}

print.slrm <- function(x, ...) {
  lk <- x$CallInfo$link
  switch(lk,
         logit= {
           splat("Fitted spatial logistic regression model")
         },
         cloglog= {
           splat("Fitted spatial regression model (complementary log-log)")
         },
         {
           splat("Fitted spatial regression model")
           splat("Link =", dQuote(lk))
         })
  cat("Formula:\t")
  print(x$CallInfo$formula)
  splat("Fitted coefficients:")
  print(coef(x))
  return(invisible(NULL))
}

logLik.slrm <- function(object, ..., adjust=TRUE) {
  FIT  <- object$Fit$FIT
  ll <- -deviance(FIT)/2
  if(adjust) {
    sumYloga <- object$Data$sumYloga
    ll <- ll - sumYloga
  }
  attr(ll, "df") <- length(coef(object))
  class(ll) <- "logLik"
  return(ll)
}

fitted.slrm <- function(object, ...) {
  if(length(list(...)) > 0)
    warning("second argument (and any subsequent arguments) ignored")
  predict(object, type="probabilities")
}

predict.slrm <- function(object, ..., type="intensity",
                         newdata=NULL, window=NULL) {
  type <- pickoption("type", type,
                     c(probabilities="probabilities",
                       link="link",
                       intensity="intensity",
                       lambda="intensity"))
  
  FIT  <- object$Fit$FIT
  link <- object$CallInfo$link
  W    <- object$Data$W
  df   <- object$Data$df
  loga <- df$logpixelarea

  if(is.null(newdata) && is.null(window)) {
    # fitted values from existing fit
    switch(type,
           probabilities={
             values <- fitted(FIT)
           },
           link={
             values <- predict(FIT, type="link")
           },
           intensity={
             # this calculation applies whether an offset was included or not
             if(link == "cloglog") {
               linkvalues <- predict(FIT, type="link")
               values <- exp(linkvalues - loga)
             } else {
               probs <- fitted(FIT)
               values <- -log(1-probs)/exp(loga)
             }
           }
           )
    out <- im(values, xcol=W$xcol, yrow=W$yrow, unitname=unitname(W))
    return(out)
  } else {
    # prediction using new values
    # update arguments that may affect pixel resolution
    CallInfo <- object$CallInfo
    CallInfo$dotargs <- resolve.defaults(list(...), CallInfo$dotargs)
    #
    if(!is.null(window)) {
      # insert fake response in new window
      if(is.null(newdata)) newdata <- list()
      window <- as.owin(window)
      newdata[[CallInfo$responsename]] <- ppp(numeric(0), numeric(0),
                                            window=window)
    }
    # process new data
    newData <- slr.prepare(CallInfo, environment(CallInfo$formula), newdata,
                           clip=!is.null(window))
    newdf   <- newData$df
    newW    <- newData$W
    newloga <- newdf$logpixelarea
    # avoid NA etc
    npixel <- nrow(newdf)
    ok <- complete.cases(newdf)
    if(!all(ok)) {
      newdf   <- newdf[ok, , drop=FALSE]
      newloga <- newloga[ok]
    }
    # compute link values
    linkvalues <- predict(FIT, newdata=newdf, type="link")
    # transform to desired scale
    linkinv <- family(FIT)$linkinv
    switch(type,
           probabilities={
             values <- linkinv(linkvalues)
           },
           link={
             values <- linkvalues
           },
           intensity={
             # this calculation applies whether an offset was included or not
             if(link == "cloglog") {
               values <- exp(linkvalues - newloga)
             } else {
               probs <- linkinv(linkvalues)
               values <- -log(1-probs)/exp(newloga)
             }
           }
           )
    # form image
    v <- rep.int(NA_real_, npixel)
    v[ok] <- values
    out <- im(v, xcol=newW$xcol, yrow=newW$yrow, unitname=unitname(W))
    return(out)
  }
}

plot.slrm <- function(x, ..., type="intensity") {
  xname <- short.deparse(substitute(x))
  y <- predict(x, type=type)
  do.call("plot.im", resolve.defaults(list(x=y), list(...), list(main=xname)))
}

formula.slrm <- function(x, ...) {
  f <- x$CallInfo$formula
  return(f)
}

terms.slrm <- function(x, ...) {
  terms(formula(x), ...)
}

labels.slrm <- function(object, ...) {
  # extract fitted trend coefficients
  co <- coef(object)
  # model terms
  tt <- terms(object)
  lab <- attr(tt, "term.labels")
  if(length(lab) == 0)
    return(character(0))
  # model matrix
  mm <- model.matrix(object)
  ass <- attr(mm, "assign")
  # 'ass' associates coefficients with model terms
  # except ass == 0 for the Intercept
  coef.ok <- is.finite(co)
  relevant <- (ass > 0) 
  okterms <- unique(ass[coef.ok & relevant])
  return(lab[okterms])
}

extractAIC.slrm <- function (fit, scale = 0, k = 2, ...)
{
    edf <- length(coef(fit))
    aic <- AIC(fit)
    c(edf, aic + (k - 2) * edf)
}

model.matrix.slrm <- function(object,..., keepNA=TRUE) {
  FIT <- object$Fit$FIT
  mm <- model.matrix(FIT, ...)
  if(!keepNA)
    return(mm)
  df <- object$Data$df
  comp <- complete.cases(df)
  if(all(comp))
    return(mm)
  if(sum(comp) != nrow(mm))
      stop("Internal error in patching NA's")
  mmplus <- matrix(NA, nrow(df), ncol(mm))
  mmplus[comp, ] <- mm
  return(mmplus)
}

model.images.slrm <- function(object, ...) {
  mm <- model.matrix(object, ...)
  mm <- as.data.frame(mm)
  Data <- object$Data
  W      <- Data$W
  serial <- Data$serial
  splitby <- object$CallInfo$splitby
  blank   <- as.im(NA_real_, W)
  assignbyserial <- function(values, serial, template) {
    Z <- template
    Z$v[serial] <- values
    return(Z)
  }
  if(is.null(splitby)) {
    result <- lapply(as.list(mm), assignbyserial, serial=serial, template=blank)
  } else {
    df <- Data$df
    IN <- as.logical(df[[splitby]])
    OUT <- !IN
    mmIN <- mm[IN, , drop=FALSE]
    mmOUT <- mm[OUT, , drop=FALSE]
    resultIN <- lapply(as.list(mmIN), assignbyserial,
                       serial=serial[IN], template=blank)
    resultOUT <- lapply(as.list(mmOUT), assignbyserial,
                       serial=serial[OUT], template=blank)
    names(resultIN) <- paste(names(resultIN), splitby, "TRUE", sep="")
    names(resultOUT) <- paste(names(resultOUT), splitby, "FALSE", sep="")
    result <- c(resultIN, resultOUT)
  }
  return(as.listof(result))
}

update.slrm <- function(object, ..., evaluate=TRUE, env=parent.frame()) {
  e <- update.default(object, ..., evaluate=FALSE)
  if(evaluate)
    e <- eval(e, envir=env)
  return(e)
}

anova.slrm <- function(object, ..., test=NULL) {
  objex <- append(list(object), list(...))
  if(!all(unlist(lapply(objex, is.slrm))))
    stop("Some arguments are not of class slrm")
  fitz <- lapply(objex, function(z){z$Fit$FIT})
  do.call("anova", append(fitz, list(test=test)))
}

vcov.slrm <- function(object, ..., what=c("vcov", "corr", "fisher", "Fisher")) {
  stopifnot(is.slrm(object))
  what <- match.arg(what)
  vc <- vcov(object$Fit$FIT)
  result <- switch(what,
                   vcov = vc,
                   corr = {
                     sd <- sqrt(diag(vc))
                     vc / outer(sd, sd, "*")
                   },
                   fisher=,
                   Fisher={
                     solve(vc)
                   })
  return(result)
}

unitname.slrm <- function(x) {
  return(unitname(x$Data$response))
}

"unitname<-.slrm" <- function(x, value) {
  unitname(x$Data$response) <- value
  return(x)
}

is.stationary.slrm <- function(x) {
  fo <- formula(x)
  trend <- fo[c(1,3)]
  return(identical.formulae(trend, ~1))
}

is.poisson.slrm <- function(x) { TRUE }


simulate.slrm <- function(object, nsim=1, seed=NULL, ...,
                          window=NULL, covariates=NULL, 
                          verbose=TRUE) {
  # .... copied from simulate.lm ....
  if (!exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE))
    runif(1)
  if (is.null(seed))
    RNGstate <- get(".Random.seed", envir = .GlobalEnv)
  else {
    R.seed <- get(".Random.seed", envir = .GlobalEnv)
    set.seed(seed)
    RNGstate <- structure(seed, kind = as.list(RNGkind()))
    on.exit(assign(".Random.seed", R.seed, envir = .GlobalEnv))
  }
  
  # determine simulation window and compute intensity
  if(!is.null(window))
    stopifnot(is.owin(window))
  lambda <- predict(object, type="intensity", newdata=covariates, window=window)

  # max lambda (for efficiency)
  summ <- summary(lambda)
  lmax <- summ$max + 0.05 * diff(summ$range)

  # run
  out <- list()
  if(verbose && (nsim > 1))
    cat(paste("Generating", nsim, "simulations... "))
  for(i in 1:nsim) {
    out[[i]] <- rpoispp(lambda, lmax=lmax)
    if(verbose) progressreport(i, nsim)
  }
  # pack up
  out <- as.listof(out)
  names(out) <- paste("Simulation", 1:nsim)
  attr(out, "seed") <- RNGstate
  return(out)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/smooth.ppp.R"
#
#  smooth.ppp.R
#
#  Smooth the marks of a point pattern
# 
#  $Revision: 1.22 $  $Date: 2014/10/24 00:22:30 $
#

smooth.ppp <- function(X, ..., weights=rep(1, npoints(X)), at="pixels") {
  .Deprecated("Smooth.ppp", package="spatstat",
    msg="smooth.ppp is deprecated: use the generic Smooth with a capital S")
  Smooth(X, ..., weights=weights, at=at)
}

Smooth <- function(X, ...) {
  UseMethod("Smooth")
}

Smooth.ppp <- function(X, sigma=NULL, ...,
                       weights=rep(1, npoints(X)), at="pixels",
                       edge=TRUE, diggle=FALSE) {
  verifyclass(X, "ppp")
  if(!is.marked(X, dfok=TRUE))
    stop("X should be a marked point pattern")
  X <- coerce.marks.numeric(X)
  at <- pickoption("output location type", at,
                   c(pixels="pixels",
                     points="points"))
  ## determine smoothing parameters
  ker <- resolve.2D.kernel(sigma=sigma, ...,
                           x=X, bwfun=bw.smoothppp, allow.zero=TRUE)
  sigma <- ker$sigma
  varcov <- ker$varcov
  ## Diggle's edge correction?
  if(diggle && !edge) warning("Option diggle=TRUE overridden by edge=FALSE")
  diggle <- diggle && edge
  ## 
  if(ker$cutoff < minnndist(X)) {
    # very small bandwidth
    leaveoneout <- resolve.1.default("leaveoneout",
                                     list(...), list(leaveoneout=TRUE))
    if(!leaveoneout && at=="points") {
      warning(paste("Bandwidth is close to zero:",
                    "original values returned"))
      Y <- marks(X)
    } else {
      warning(paste("Bandwidth is close to zero:",
                    "nearest-neighbour interpolation performed"))
      Y <- nnmark(X, ..., k=1, at=at)
    }
    return(Y)
  }
  ## weights
  weightsgiven <- !missing(weights) && !is.null(weights) && (length(weights)>0)
  if(weightsgiven) {
    check.nvector(weights, npoints(X))
  } else weights <- NULL
  if(diggle) {
    ## absorb Diggle edge correction into weights vector
    edg <- second.moment.calc(X, sigma, what="edge", ..., varcov=varcov)
    ei <- safelookup(edg, X, warn=FALSE)
    weights <- if(weightsgiven) weights/ei else 1/ei
    weights[!is.finite(weights)] <- 0
    weightsgiven <- TRUE
  }
  ## rescale weights to avoid numerical gremlins
  if(weightsgiven && ((mw <- median(abs(weights))) > 0))
    weights <- weights/mw

  ## calculate...
  marx <- marks(X)
  if(!is.data.frame(marx)) {
    # ........ vector of marks ...................
    values <- marx
    if(is.factor(values)) {
      warning("Factor valued marks were converted to integers")
      values <- as.numeric(values)
    }
    ## detect constant values
    ra <- range(values, na.rm=TRUE)
    if(diff(ra) == 0) {
      switch(at,
             points = {
               result <- values
             },
             pixels = {
               M <- do.call.matched(as.mask, list(w=as.owin(X), ...))
               result <- as.im(ra[1], M)
             })
    } else {
      switch(at,
             points={
               result <-
                 do.call("smoothpointsEngine",
                         resolve.defaults(list(x=X,
                                               values=values, weights=weights,
                                               sigma=sigma, varcov=varcov,
                                               edge=FALSE),
                                          list(...)))
             },
             pixels={
               values.weights <- if(weightsgiven) values * weights else values
               numerator <-
                 do.call("density.ppp",
                         resolve.defaults(list(x=X,
                                               at="pixels",
                                               weights = values.weights,
                                               sigma=sigma, varcov=varcov,
                                               edge=FALSE),
                                          list(...)))
               denominator <-
                 do.call("density.ppp",
                         resolve.defaults(list(x=X,
                                               at="pixels",
                                               weights = weights,
                                               sigma=sigma,
                                               varcov=varcov,
                                               edge=FALSE),
                                          list(...)))
               result <- eval.im(numerator/denominator)
               ## trap small values of denominator
               ## trap NaN and +/- Inf values of result, but not NA
               eps <- .Machine$double.eps
               nbg <- eval.im(is.infinite(result)
                              | is.nan(result)
                              | (denominator < eps))
               if(any(as.matrix(nbg), na.rm=TRUE)) {
                 warning(paste("Numerical underflow detected:",
                               "sigma is probably too small"))
                 ## l'Hopital's rule
                 distX <- distmap(X, xy=numerator)
                 whichnn <- attr(distX, "index")
                 nnvalues <- eval.im(values[whichnn])
                 result[nbg] <- nnvalues[nbg]
               }
               attr(result, "warnings") <- attr(numerator, "warnings")
             })
    }
  } else {
    ## ......... data frame of marks ..................
    ## detect constant columns
    ra <- apply(marx, 2, range, na.rm=TRUE)
    isconst <- (apply(ra, 2, diff) == 0)
    if(anyisconst <- any(isconst)) {
      oldmarx <- marx
#      oldX <- X
      marx <- marx[, !isconst]
      X <- X %mark% marx
    }
    if(any(!isconst)) {
      ## compute denominator
      denominator <-
        do.call("density.ppp",
                resolve.defaults(list(x=X,
                                      at=at,
                                      weights = weights,
                                      sigma=sigma, varcov=varcov,
                                      edge=FALSE),
                                 list(...)))
      ## compute numerator for each column of marks
      marx.weights <- if(weightsgiven) marx * weights else marx
      numerators <-
        do.call("density.ppp",
                resolve.defaults(list(x=X,
                                      at=at,
                                      weights = marx.weights,
                                      sigma=sigma, varcov=varcov,
                                      edge=FALSE),
                                 list(...)))
      uhoh <- attr(numerators, "warnings")
      ## calculate ratios
      switch(at,
             points={
               if(is.null(uhoh)) {
                 ## numerators is a matrix
                 ratio <- numerators/denominator
                 if(any(badpoints <- apply(!is.finite(ratio), 1, any))) {
                   whichnnX <- nnwhich(X)
                   ratio[badpoints,] <- marx[whichnnX[badpoints], ]
                 }
               } else {
                 warning("returning original values")
                 ratio <- marx
               }
               result <- as.data.frame(ratio)
               colnames(result) <- colnames(marx)
             },
             pixels={
               ratio <- lapply(numerators,
                               function(a,b) eval.im(a/b),
                               b=denominator)
               if(!is.null(uhoh)) {
                 ## compute nearest neighbour map on same raster
                 distX <- distmap(X, xy=denominator)
                 whichnnX <- attr(distX, "index")
                 ## fix images
                 for(j in 1:length(ratio)) {
                   ratj <- ratio[[j]]
                   valj <- marx[,j]
                   ratio[[j]] <-
                     eval.im(ifelseXY(is.finite(ratj), ratj, valj[whichnnX]))
                 }
                 attr(ratio, "warnings") <- uhoh
               }
               result <- as.listof(ratio)
               names(result) <- colnames(marx)
             })
    } else result <- NULL 
    if(anyisconst) {
      partresult <- result
      switch(at,
             points = {
               nX <- npoints(X)
               result <- matrix(, nX, ncol(oldmarx))
               if(length(partresult) > 0)
                 result[,!isconst] <- partresult
               result[,isconst] <- rep(ra[1,isconst], each=nX)
               colnames(result) <- colnames(oldmarx)
             },
             pixels = {
               result <- vector(mode="list", length=ncol(oldmarx))
               if(length(partresult) > 0) {
                 result[!isconst] <- partresult
                 M <- as.owin(partresult[[1]])
               } else {
                 M <- do.call.matched(as.mask, list(w=as.owin(X), ...))
               }
               result[isconst] <- lapply(ra[1, isconst], as.im, W=M)
               result <- as.listof(result)
               names(result) <- colnames(oldmarx)
             })
    }
  }
  ## wrap up
  attr(result, "warnings") <-
    unlist(lapply(result, function(x){ attr(x, "warnings") }))
  attr(result, "sigma") <- sigma
  attr(result, "varcov") <- varcov
  return(result)
}


smoothpointsEngine <- function(x, values, sigma, ...,
                               weights=NULL, varcov=NULL,
                               leaveoneout=TRUE,
                               sorted=FALSE) {
  stopifnot(is.logical(leaveoneout))
#  if(is.null(varcov)) {
#    const <- 1/(2 * pi * sigma^2)
#  } else {
#    detSigma <- det(varcov)
#    Sinv <- solve(varcov)
#    const <- 1/(2 * pi * sqrt(detSigma))
#  }
  # detect constant values
  if(diff(range(values, na.rm=TRUE)) == 0) { 
    result <- values
    attr(result, "sigma") <- sigma
    attr(result, "varcov") <- varcov
    return(result)
  }
  # Contributions from pairs of distinct points
  # closer than 8 standard deviations
  sd <- if(is.null(varcov)) sigma else sqrt(sum(diag(varcov)))
  cutoff <- 8 * sd

  ## Handle weights that are meant to be null
  if(length(weights) == 0 || (!is.null(dim(weights)) && nrow(weights) == 0))
     weights <- NULL
     
  # detect very small bandwidth
  nnd <- nndist(x)
  nnrange <- range(nnd)
  if(cutoff < nnrange[1]) {
    if(leaveoneout && (npoints(x) > 1)) {
      warning("Very small bandwidth; values of nearest neighbours returned")
      result <- values[nnwhich(x)]
    } else {
      warning("Very small bandwidth; original values returned")
      result <- values
    }
    attr(result, "sigma") <- sigma
    attr(result, "varcov") <- varcov
    attr(result, "warnings") <- "underflow"
    return(result)
  }
  if(leaveoneout) {
    # ensure cutoff includes at least one point
    cutoff <- max(1.1 * nnrange[2], cutoff)
  }
  if(spatstat.options("densityC")) {
    # .................. new C code ...........................
    npts <- npoints(x)
    result <- numeric(npts)
    # sort into increasing order of x coordinate (required by C code)
    if(sorted) {
      xx <- x$x
      yy <- x$y
      vv <- values
    } else {
      oo <- fave.order(x$x)
      xx <- x$x[oo]
      yy <- x$y[oo]
      vv <- values[oo]
    }
    if(is.null(varcov)) {
      # isotropic kernel
      if(is.null(weights)) {
        zz <- .C("smoopt",
                 nxy     = as.integer(npts),
                 x       = as.double(xx),
                 y       = as.double(yy),
                 v       = as.double(vv),
                 self    = as.integer(!leaveoneout),
                 rmaxi   = as.double(cutoff),
                 sig     = as.double(sd),
                 result  = as.double(double(npts)))
        if(sorted) result <- zz$result else result[oo] <- zz$result
      } else {
        wtsort <- weights[oo]
        zz <- .C("wtsmoopt",
                 nxy     = as.integer(npts),
                 x       = as.double(xx),
                 y       = as.double(yy),
                 v       = as.double(vv),
                 self    = as.integer(!leaveoneout),
                 rmaxi   = as.double(cutoff),
                 sig     = as.double(sd),
                 weight  = as.double(wtsort),
                 result  = as.double(double(npts)))
        if(sorted) result <- zz$result else result[oo] <- zz$result
      }
    } else {
      # anisotropic kernel
      Sinv <- solve(varcov)
      flatSinv <- as.vector(t(Sinv))
      if(is.null(weights)) {
        zz <- .C("asmoopt",
                 nxy     = as.integer(npts),
                 x       = as.double(xx),
                 y       = as.double(yy),
                 v       = as.double(vv),
                 self    = as.integer(!leaveoneout),
                 rmaxi   = as.double(cutoff),
                 sinv    = as.double(flatSinv),
                 result  = as.double(double(npts)))
        if(sorted) result <- zz$result else result[oo] <- zz$result
      } else {
        wtsort <- weights[oo]
        zz <- .C("awtsmoopt",
                 nxy     = as.integer(npts),
                 x       = as.double(xx),
                 y       = as.double(yy),
                 v       = as.double(vv),
                 self    = as.integer(!leaveoneout),
                 rmaxi   = as.double(cutoff),
                 sinv    = as.double(flatSinv),
                 weight  = as.double(wtsort),
                 result  = as.double(double(npts)))
        if(sorted) result <- zz$result else result[oo] <- zz$result
      }
    }
    if(any(nbg <- (is.infinite(result) | is.nan(result)))) {
      # NaN or +/-Inf can occur if bandwidth is small
      # Use mark of nearest neighbour (by l'Hopital's rule)
      result[nbg] <- values[nnwhich(x)[nbg]]
    }
  } else {
    # previous, partly interpreted code
    # compute weighted densities
    if(is.null(weights)) {
      # weights are implicitly equal to 1
      numerator <- do.call("density.ppp",
                         resolve.defaults(list(x=x, at="points"),
                                          list(weights = values),
                                          list(sigma=sigma, varcov=varcov),
                                          list(leaveoneout=leaveoneout),
                                          list(sorted=sorted),
                                          list(...),
                                          list(edge=FALSE)))
      denominator <- do.call("density.ppp",
                             resolve.defaults(list(x=x, at="points"),
                                              list(sigma=sigma, varcov=varcov),
                                              list(leaveoneout=leaveoneout),
                                              list(sorted=sorted),
                                              list(...),
                                              list(edge=FALSE)))
    } else {
      numerator <- do.call("density.ppp",
                           resolve.defaults(list(x=x, at="points"),
                                            list(weights = values * weights),
                                            list(sigma=sigma, varcov=varcov),
                                            list(leaveoneout=leaveoneout),
                                            list(sorted=sorted),
                                            list(...),
                                            list(edge=FALSE)))
      denominator <- do.call("density.ppp",
                             resolve.defaults(list(x=x, at="points"),
                                              list(weights = weights),
                                              list(sigma=sigma, varcov=varcov),
                                              list(leaveoneout=leaveoneout),
                                              list(sorted=sorted),
                                              list(...),
                                              list(edge=FALSE)))
    }
    if(is.null(uhoh <- attr(numerator, "warnings"))) {
      result <- numerator/denominator
      result <- ifelseXB(is.finite(result), result, NA)
    } else {
      warning("returning original values")
      result <- values
      attr(result, "warnings") <- uhoh
    }
  }
  # pack up and return
  attr(result, "sigma") <- sigma
  attr(result, "varcov") <- varcov
  return(result)
}


markmean <- function(X, ...) {
  stopifnot(is.marked(X))
  Y <- Smooth(X, ...)
  return(Y)
}

markvar  <- function(X, sigma=NULL, ..., weights=NULL, varcov=NULL) {
  stopifnot(is.marked(X))
  if(is.expression(weights)) 
    weights <- eval(weights, envir=as.data.frame(X), enclos=parent.frame())
  E1 <- Smooth(X, sigma=sigma, varcov=varcov, weights=weights, ...)
  X2 <- X %mark% marks(X)^2
  ## ensure smoothing bandwidth is the same!
  sigma <- attr(E1, "sigma")
  varcov <- attr(E1, "varcov")
  E2 <- Smooth(X2, sigma=sigma, varcov=varcov, weights=weights, ...)
  V <- eval.im(E2 - E1^2)
  return(V)
}

bw.smoothppp <- function(X, nh=spatstat.options("n.bandwidth"),
                       hmin=NULL, hmax=NULL, warn=TRUE) {
  stopifnot(is.ppp(X))
  stopifnot(is.marked(X))
  # rearrange in ascending order of x-coordinate (for C code)
  X <- X[fave.order(X$x)]
  #
  marx <- marks(X)
  # determine a range of bandwidth values
#  n <- npoints(X)
  if(is.null(hmin) || is.null(hmax)) {
    W <- Window(X)
#    a <- area(W)
    d <- diameter(as.rectangle(W))
    # Stoyan's rule of thumb 
    stoyan <- bw.stoyan(X)
    # rule of thumb based on nearest-neighbour distances
    nnd <- nndist(X)
    nnd <- nnd[nnd > 0]
    if(is.null(hmin)) {
      hmin <- max(1.1 * min(nnd), stoyan/5)
      hmin <- min(d/8, hmin)
    }
    if(is.null(hmax)) {
      hmax <- max(stoyan * 20, 3 * mean(nnd), hmin * 2)
      hmax <- min(d/2, hmax)
    }
  } else stopifnot(hmin < hmax)
  #
  h <- exp(seq(from=log(hmin), to=log(hmax), length.out=nh))
  cv <- numeric(nh)
  # 
  # compute cross-validation criterion
  for(i in seq_len(nh)) {
    yhat <- Smooth(X, sigma=h[i], at="points", leaveoneout=TRUE,
                       sorted=TRUE)
    cv[i] <- mean((marx - yhat)^2)
  }

  # optimize
  iopt <- which.min(cv)
#  hopt <- h[iopt]
  #
  if(warn && (iopt == nh || iopt == 1)) 
    warning(paste("Cross-validation criterion was minimised at",
                  if(iopt == 1) "left-hand" else "right-hand",
                  "end of interval",
                  paste(prange(signif(c(hmin, hmax), 3)), ";", sep=""),
                  "use arguments hmin, hmax to specify a wider interval"),
            call.=FALSE)
  #
  result <- bw.optim(cv, h, iopt,
                     hname="sigma",
                     creator="bw.smoothppp",
                     criterion="Least Squares Cross-Validation")
  return(result)
}

smoothcrossEngine <- function(Xdata, Xquery, values, sigma, ...,
                              weights=NULL, varcov=NULL,
                              sorted=FALSE) {
#  if(is.null(varcov)) {
#    const <- 1/(2 * pi * sigma^2)
#  } else {
#    detSigma <- det(varcov)
#    Sinv <- solve(varcov)
#    const <- 1/(2 * pi * sqrt(detSigma))
#  }
  if(!is.null(dim(weights)))
    stop("weights must be a vector")

  if(npoints(Xquery) == 0 || npoints(Xdata) == 0) {
    if(is.null(dim(values))) return(rep(NA, npoints(Xquery)))
    nuttin <- matrix(NA, nrow=npoints(Xquery), ncol=ncol(values))
    colnames(nuttin) <- colnames(values)
    return(nuttin)
  }
  
  ## Contributions from pairs of distinct points
  ## closer than 8 standard deviations
  sd <- if(is.null(varcov)) sigma else sqrt(sum(diag(varcov)))
  cutoff <- 8 * sd

  ## detect very small bandwidth
  nnc <- nncross(Xquery, Xdata)
  if(cutoff < min(nnc$dist)) {
    if(npoints(Xdata) > 1) {
      warning("Very small bandwidth; values of nearest neighbours returned")
      nw <- nnc$which
      result <- if(is.null(dim(values))) values[nw] else values[nw,,drop=FALSE]
    } else {
      warning("Very small bandwidth; original values returned")
      result <- values
    }
    attr(result, "sigma") <- sigma
    attr(result, "varcov") <- varcov
    attr(result, "warnings") <- "underflow"
    return(result)
  }
  
  ## Handle weights that are meant to be null
  if(length(weights) == 0)
     weights <- NULL
     
  ## handle multiple columns of values
  if(is.matrix(values) || is.data.frame(values)) {
    k <- ncol(values)
    stopifnot(nrow(values) == npoints(Xdata))
    values <- as.data.frame(values)
    result <- matrix(, npoints(Xdata), k)
    colnames(result) <- colnames(values)
    if(!sorted) {
      ood <- fave.order(Xdata$x)
      Xdata <- Xdata[ood]
      values <- values[ood, ]
      ooq <- fave.order(Xquery$x)
      Xquery <- Xquery[ooq]
    }
    for(j in 1:k) 
      result[,j] <- smoothcrossEngine(Xdata, Xquery, values[,j],
                                      sigma=sigma, varcov=varcov,
                                      weights=weights, sorted=TRUE,
                                      ...)
    if(!sorted) {
      sortresult <- result
      result[ooq,] <- sortresult
    }
    attr(result, "sigma") <- sigma
    attr(result, "varcov") <- varcov
    return(result)
  }

  ## values must be a vector
  stopifnot(length(values) == npoints(Xdata) || length(values) == 1)
  if(length(values) == 1) values <- rep(values, npoints(Xdata))

  ndata <- npoints(Xdata)
  nquery <- npoints(Xquery)
  result <- numeric(nquery) 
  ## coordinates and values
  xq <- Xquery$x
  yq <- Xquery$y
  xd <- Xdata$x
  yd <- Xdata$y
  vd <- values
  if(!sorted) {
    ## sort into increasing order of x coordinate (required by C code)
    ooq <- fave.order(Xquery$x)
    xq <- xq[ooq]
    yq <- yq[ooq]
    ood <- fave.order(Xdata$x)
    xd <- xd[ood]
    yd <- yd[ood]
    vd <- vd[ood] 
  }
  if(is.null(varcov)) {
    ## isotropic kernel
    if(is.null(weights)) {
      zz <- .C("crsmoopt",
               nquery      = as.integer(nquery),
               xq      = as.double(xq),
               yq      = as.double(yq),
               ndata   = as.integer(ndata),
               xd      = as.double(xd),
               yd      = as.double(yd),
               vd      = as.double(vd),
               rmaxi   = as.double(cutoff),
               sig     = as.double(sd),
               result  = as.double(double(nquery)))
      if(sorted) result <- zz$result else result[ooq] <- zz$result
    } else {
      wtsort <- weights[ood]
      zz <- .C("wtcrsmoopt",
               nquery      = as.integer(nquery),
               xq      = as.double(xq),
               yq      = as.double(yq),
               ndata   = as.integer(ndata),
               xd      = as.double(xd),
               yd      = as.double(yd),
               vd      = as.double(vd),
               wd      = as.double(wtsort),
               rmaxi   = as.double(cutoff),
               sig     = as.double(sd),
               result  = as.double(double(nquery)))
        if(sorted) result <- zz$result else result[ooq] <- zz$result
      }
    } else {
      # anisotropic kernel
      Sinv <- solve(varcov)
      flatSinv <- as.vector(t(Sinv))
      if(is.null(weights)) {
        zz <- .C("acrsmoopt",
                 nquery      = as.integer(nquery),
                 xq      = as.double(xq),
                 yq      = as.double(yq),
                 ndata   = as.integer(ndata),
                 xd      = as.double(xd),
                 yd      = as.double(yd),
                 vd      = as.double(vd),
                 rmaxi   = as.double(cutoff),
                 sinv    = as.double(flatSinv),
                 result  = as.double(double(nquery)))
        if(sorted) result <- zz$result else result[ooq] <- zz$result
      } else {
        wtsort <- weights[ood]
        zz <- .C("awtcrsmoopt",
                 nquery      = as.integer(nquery),
                 xq      = as.double(xq),
                 yq      = as.double(yq),
                 ndata   = as.integer(ndata),
                 xd      = as.double(xd),
                 yd      = as.double(yd),
                 vd      = as.double(vd),
                 wd      = as.double(wtsort),
                 rmaxi   = as.double(cutoff),
                 sinv    = as.double(flatSinv),
                 result  = as.double(double(nquery)))
        if(sorted) result <- zz$result else result[ooq] <- zz$result
      }
    }
    if(any(nbg <- (is.infinite(result) | is.nan(result)))) {
      # NaN or +/-Inf can occur if bandwidth is small
      # Use mark of nearest neighbour (by l'Hopital's rule)
      result[nbg] <- values[nnc$which[nbg]]
    }
  # pack up and return
  attr(result, "sigma") <- sigma
  attr(result, "varcov") <- varcov
  return(result)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/smoothfun.R"
##
## smoothfun.R
##
## Exact 'funxy' counterpart of Smooth.ppp
##
##  $Revision: 1.1 $ $Date: 2014/04/04 03:04:08 $


Smoothfun <- function(X, ...) {
  UseMethod("Smoothfun")
}

Smoothfun.ppp <- function(X, sigma=NULL, ...,
                          weights=NULL, edge=TRUE, diggle=FALSE) {
  verifyclass(X, "ppp")
  if(!is.marked(X, dfok=TRUE))
    stop("X should be a marked point pattern")
  stuff <- list(X=X, weights=weights, edge=edge, diggle=diggle)
  X <- coerce.marks.numeric(X)
  ## determine smoothing parameters
  ker <- resolve.2D.kernel(sigma=sigma, ...,
                           x=X, bwfun=bw.smoothppp, allow.zero=TRUE)
  stuff <- append(stuff, ker[c("sigma", "varcov")])
  ##
  g <- function(x, y=NULL) {
    Y <- xy.coords(x, y)[c("x", "y")]
    with(stuff,
         smoothcrossEngine(Xdata=X,
                           Xquery=as.ppp(Y, X$window),
                           values=marks(X),
                           sigma=sigma,
                           varcov=varcov, 
                           weights=weights,
                           edge=edge, diggle=diggle))
  }
  g <- funxy(g, as.rectangle(as.owin(X)))
  class(g) <- c("Smoothfun", class(g))
  return(g)
}

print.Smoothfun <- function(x, ...) {
  cat("function(x,y)", "which returns",
      "values", "interpolated from", fill=TRUE)
  X <- get("X", envir=environment(x))
  print(X, ...)
  return(invisible(NULL))
}

## Method for as.im
## (enables plot.funxy, persp.funxy, contour.funxy to work for this class)

as.im.Smoothfun <- function(X, W=NULL, ...) {
  stuff <- get("stuff", envir=environment(X))
  if(!is.null(W)) stuff$X <- stuff$X[W]
  do.call("Smooth", resolve.defaults(list(...), stuff))
}


  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/smoothfv.R"
#
#  smoothfv.R
#
#   $Revision: 1.13 $   $Date: 2014/01/15 10:03:35 $
#
  
smooth.fv <- function(x, which="*", ..., 
                      method=c("smooth.spline", "loess"),
                      xinterval=NULL) {
  .Deprecated("Smooth.fv", package="spatstat",
     msg="smooth.fv is deprecated: use the generic Smooth with a capital S")
  Smooth(x, which=which, ..., method=method, xinterval=xinterval)
}
  
Smooth.fv <- function(X, which="*", ..., 
                      method=c("smooth.spline", "loess"),
                      xinterval=NULL) {
  x <- X
  stopifnot(is.character(which))
  method <- match.arg(method)
  if(!is.null(xinterval))
    check.range(xinterval) 
  if(length(which) == 1 && which %in% .Spatstat.FvAbbrev) {
    if(which == ".x")
      stop("Cannot smooth the function argument")
    which <- fvnames(x, which)
  }
  if(any(nbg <- !(which %in% names(x)))) 
    stop(paste("Unrecognised column",
               ngettext(sum(nbg), "name", "names"),
               commasep(sQuote(which[nbg])), 
               "in argument", sQuote("which")))
  xx <- x[[fvnames(x, ".x")]]
  # process each column of function values
  for(ynam in which) {
    yy <- x[[ynam]]
    ok <- is.finite(yy)
    if(!is.null(xinterval))
      ok <- ok & inside.range(xx, xinterval)
    switch(method,
           smooth.spline = {
             ss <- smooth.spline(xx[ok], yy[ok], ...)
             yhat <- predict(ss, xx[ok])$y
           },
           loess = {
             df <- data.frame(x=xx[ok], y=yy[ok])
             lo <- loess(y ~ x, df, ...)
             yhat <- predict(lo, df[,"x", drop=FALSE])
           })
    yy[ok] <- yhat
    x[[ynam]] <- yy
  }
  return(x)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/softcore.R"
#
#
#    softcore.S
#
#    $Revision: 2.13 $   $Date: 2014/04/14 03:53:40 $
#
#    Soft core processes.
#
#    Softcore()    create an instance of a soft core process
#                 [an object of class 'interact']
#
#
# -------------------------------------------------------------------
#

Softcore <- local({

  BlankSoftcore <- 
  list(
       name     = "Soft core process",
       creator  = "Softcore",
       family   = "pairwise.family",  # evaluated later
       pot      = function(d, par) {
         sig0 <- par$sigma0
         if(is.na(sig0)) {
           p <- -d^(-2/par$kappa)
         } else {
           # expand around sigma0 and set large negative numbers to -Inf
           drat <- d/sig0
           p <- -drat^(-2/par$kappa)
           p[p < -25] <- -Inf
         }
         return(p)
       },
       par      = list(kappa = NULL, sigma0=NA),  # filled in later
       parnames = c("Exponent kappa", "Initial approximation to sigma"),
       selfstart = function(X, self) {
         # self starter for Softcore
         if(npoints(X) < 2) {
           # not enough points to make any decisions
           return(self)
         }
         md <- minnndist(X)
         if(md == 0) {
           warning(paste("Pattern contains duplicated points:",
                         "impossible under Softcore model"))
           return(self)
         }
         kappa <- self$par$kappa
         if(!is.na(sigma0 <- self$par$sigma0)) {
           # value fixed by user or previous invocation
           # check it
           if((md/sigma0)^(-2/kappa) > 25)
             warning(paste("Initial approximation sigma0 is too large;",
                           "some data points will have zero probability"))
           return(self)
         }
         # take sigma0 = minimum interpoint distance
         Softcore(kappa=kappa, sigma0=md)
       },
       init     = function(self) {
         kappa <- self$par$kappa
         if(!is.numeric(kappa) || length(kappa) != 1 ||
            kappa <= 0 || kappa >= 1)
           stop(paste("Exponent kappa must be a",
                      "positive number less than 1"))
       },
       update = NULL,  # default OK
       print = NULL,    # default OK
       interpret =  function(coeffs, self) {
         theta <- as.numeric(coeffs[1])
         sigma <- theta^(self$par$kappa/2)
         if(!is.na(sig0 <- self$par$sigma0))
           sigma <- sigma * sig0
         return(list(param=list(sigma=sigma),
                     inames="interaction parameter sigma",
                     printable=signif(sigma)))
       },
       valid = function(coeffs, self) {
         theta <- coeffs[1]
         return(is.finite(theta) && (theta >= 0))
       },
       project = function(coeffs, self) {
         if((self$valid)(coeffs, self)) return(NULL) else return(Poisson())
       },
       irange = function(self, coeffs=NA, epsilon=0, ...) {
         # distance d beyond which log(interaction factor) <= epsilon
         if(any(is.na(coeffs)) || epsilon == 0)
           return(Inf)
         theta <- as.numeric(coeffs[1])
         kappa <- self$par$kappa
         sig0  <- self$par$sigma0
         if(is.na(sig0)) sig0 <- 1
         return(sig0 * (theta/epsilon)^(kappa/2))
       },
       Mayer=function(coeffs, self) {
         # second Mayer cluster integral
         kappa <- self$par$kappa
         sigma <- (self$interpret)(coeffs, self)$param$sigma
         return(pi * (sigma^2) * gamma(1 - kappa))
       },
       version=NULL # filled in later
  )
  class(BlankSoftcore) <- "interact"

  Softcore <- function(kappa, sigma0=NA) {
    instantiate.interact(BlankSoftcore, list(kappa=kappa, sigma0=sigma0))
  }

  Softcore <- intermaker(Softcore, BlankSoftcore)
  
  Softcore
})

                  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/solist.R"
##
## solist.R
##
## Methods for class `solist' (spatial object list)
##
##      and related classes 'anylist', 'ppplist', 'imlist'
##
## plot.solist is defined in plot.solist.R
##
## $Revision: 1.5 $ $Date: 2014/10/18 01:43:45 $

anylist <- function(...) {
  x <- list(...)
  class(x) <- c("anylist", "listof", class(x))
  return(x)
}

print.anylist <- function (x, ...) {
  nn <- names(x)
  ll <- length(x)
  if (length(nn) != ll) 
    nn <- paste("Component", seq.int(ll))
  for (i in seq_len(ll)) {
    splat(paste0(nn[i], ":"))
    print(x[[i]], ...)
    cat("\n")
  }
  return(invisible(x))
}

as.anylist <- function(x) {
  if(inherits(x, "anylist")) return(x)
  if(!is.list(x))
    x <- list(x)
  class(x) <- c("anylist", "listof", class(x))
  return(x)
}
  
"[.anylist" <- function(x, i, ...) {
  cl <- oldClass(x)
  ## invoke list method
  y <- NextMethod("[")
  if(length(y) == 0) return(list())
  class(y) <- cl
  return(y)
}

"[<-.anylist" <- function(x, i, value) {
  as.anylist(NextMethod("[<-"))
}

summary.anylist <- function(object, ...) {
  as.anylist(lapply(object, summary, ...))
}

## .................... solist .............................

solist <- local({

  checkspatial <-
    function(z) !inherits(try(Frame(z), silent=TRUE), "try-error")

  solist <- function(..., check=TRUE, promote=TRUE) {
    stuff <- list(...)
    if(check && !all(unlist(lapply(stuff, checkspatial))))
      stop("Some arguments of solist() are not 2D spatial objects")
    class(stuff) <- c("solist", "anylist", "listof", class(stuff))
    if(promote) {
      if(all(unlist(lapply(stuff, is.ppp)))) {
        class(stuff) <- c("ppplist", class(stuff))
      } else if(all(unlist(lapply(stuff, is.im)))) {
        class(stuff) <- c("imlist", class(stuff))
      }
    }
    return(stuff)
  }

  solist
})

as.solist <- function(x, ...) {
  if(inherits(x, "solist") && length(list(...)) == 0)
    return(x)
  if(!is.list(x))
    x <- list(x)
  return(do.call(solist, append(x, list(...))))
}

print.solist <- function (x, ...) {
  what <- if(inherits(x, "ppplist")) "point patterns" else
          if(inherits(x, "imlist")) "pixel images" else "spatial objects"
  splat(paste("List of", what))
  parbreak()
  NextMethod("print")
}


"[.solist" <- function(x, i, ...) {
  cl <- oldClass(x)
  ## invoke list method
  y <- NextMethod("[")
  if(length(y) == 0) return(list())
  class(y) <- cl
  return(y)
}
  
"[<-.solist" <- function(x, i, value) {
  ## invoke list method
  y <- NextMethod("[<-")
  ## check again
  return(do.call(solist, y))
}
  
summary.solist <- function(object, ...) {
  x <- lapply(object, summary, ...)
  attr(x, "otype") <-
    if(inherits(object, "ppplist")) "ppp" else
    if(inherits(object, "imlist")) "im" else ""
  class(x) <- c("summary.solist", "anylist")
  x
}

print.summary.solist <- function(x, ...) {
  what <- switch(attr(x, "otype"),
                 ppp="point patterns",
                 im="pixel images",
                 "spatial objects")
  splat("Summary of", length(x), what)
  parbreak()
  NextMethod("print")
}

as.layered.solist <- function(X) {
  layered(LayerList=X)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/spatialcdf.R"
##
## spatialcdf.R
##
##  $Revision: 1.2 $ $Date: 2014/10/24 00:22:30 $
##

spatialcdf <- function(Z, weights=NULL, normalise=FALSE, ...,
                       W=NULL, Zname=NULL) {
  Zdefaultname <- singlestring(short.deparse(substitute(Z)))
  if(is.character(Z) && length(Z) == 1) {
    if(is.null(Zname)) Zname <- Z
    switch(Zname,
           x={
             Z <- function(x,y) { x }
           }, 
           y={
             Z <- function(x,y) { y }
           },
           stop("Unrecognised covariate name")
         )
  }
  if(is.null(Zname)) Zname <- Zdefaultname
  ##
  if(is.ppm(weights) || is.kppm(weights) || is.dppm(weights)) {
    Q <- quad.ppm(as.ppm(weights))
    loc <- as.ppp(Q)
    df <- mpl.get.covariates(list(Z=Z), loc, covfunargs=list(...))
    df$wt <- fitted(weights) * w.quad(Q)
    wtname <- if(normalise) "fraction of points" else "number of points"
  } else {
    if(is.null(W)) W <- as.owin(weights, fatal=FALSE)
    if(is.null(W)) W <- as.owin(Z, fatal=FALSE)
    if(is.null(W)) stop("No information specifying the spatial window")
    if(is.null(weights)) weights <- 1
    M <- as.mask(W, ...)
    loc <- rasterxy.mask(M, drop=TRUE)
    df <- mpl.get.covariates(list(Z=Z, weights=weights), loc,
                             covfunargs=list(...))
    pixelarea <- with(unclass(M), xstep * ystep)
    df$wt <- rep(pixelarea, nrow(df))
    wtname <- if(normalise) "fraction of weight" else "weight"
  }
  if(normalise) 
    df$wt <- with(df, wt/sum(wt))
  G <- with(df, ewcdf(Z, wt))
  class(G) <- c("spatialcdf", class(G))
  attr(G, "call") <- sys.call()
  attr(G, "Zname") <- Zname
  attr(G, "ylab") <- paste("Cumulative", wtname)
  return(G)
}

plot.spatialcdf <- function(x, ..., xlab, ylab) {
  if(missing(xlab) || is.null(xlab))
    xlab <- attr(x, "Zname")
  if(missing(ylab) || is.null(ylab))
    ylab <- attr(x, "ylab")
  plot.ecdf(x, ..., xlab=xlab, ylab=ylab)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/split.ppp.R"
#
# split.ppp.R
#
# $Revision: 1.24 $ $Date: 2014/10/24 00:22:30 $
#
# split.ppp and "split<-.ppp"
#
#########################################

split.ppp <- function(x, f = marks(x), drop=FALSE, un=NULL, ...) {
  verifyclass(x, "ppp")
  mf <- markformat(x)
  
  if(is.null(un))
    un <- missing(f) && (mf != "dataframe")

  if(missing(f)) {
    # f defaults to marks of x
    switch(mf,
           none={
             stop("f is missing and there are no marks")
           },
           vector={
             if(!is.multitype(x)) 
               stop("f is missing and the pattern is not multitype")
             f <- fsplit <- marks(x)
           },
           dataframe={
             f <- fsplit <- firstfactor(marks(x))
             if(is.null(f))
               stop("Data frame of marks contains no factors")
           })
    splittype <- "factor"
  } else{
    # f was given
    fsplit <- f
    if(is.factor(f)) {
      splittype <- "factor"
    } else if(is.tess(f)) {
      # f is a tessellation: determine the grouping
      f <- marks(cut(x, fsplit))
      splittype <- "tess"
    } else if(is.owin(f)) {
      # f is a window: coerce to a tessellation
      W <- as.owin(x)
      fsplit <- tess(tiles=list(fsplit, setminus.owin(W, fsplit)),
                     window=W)
      f <- marks(cut(x, fsplit))
      splittype <- "tess"
    } else if(is.im(f)) {
      # f is an image: coerce to a tessellation
      fsplit <- tess(image=f)
      f <- marks(cut(x, fsplit))
      splittype <- "tess"
    } else if(is.character(f) && length(f) == 1) {
      # f is the name of a column of marks
      marx <- marks(x)
      if(is.data.frame(marx) && (f %in% names(marx))) 
        fsplit <- f <- marx[[f]]
      else
        stop(paste("The name", sQuote(f), "does not match any column of marks"))
      splittype <- "factor"
    } else 
      stop(paste("f must be",
                 "a factor, a tessellation, an image,",
                 "or the name of a column of marks"))
    if(length(f) != npoints(x))
      stop("length(f) must equal the number of points in x")
  }

  # At this point
  # 'f' is a factor that can be used to separate the points
  # 'fsplit' is the object (either a factor or a tessellation)
  # that determines the split (and can be "un-split")

  lev <- levels(f)
  if(drop) {
    # remove components that don't contain points
    retain <- (table(f) > 0)
    lev <- lev[retain]
    switch(splittype,
           tess = {
             # remove tiles that don't contain points
             fsplit <- fsplit[retain]
           },
           factor = {
             # delete levels that don't occur
             fsplit <- factor(fsplit, levels=lev)
           },
           stop("Internal error: wrong format for fsplit"))
  }

  # split the data
  out <- list()
  for(l in lev) 
    out[[paste(l)]] <- x[!is.na(f) & (f == l)]
  
  if(un)
     out <- lapply(out, unmark)
  if(splittype == "tess") {
    til <- tiles(fsplit)
    for(i in seq_along(out))
      out[[i]]$window <- til[[i]]
  }
  class(out) <- c("splitppp", class(out))
  attr(out, "fsplit") <- fsplit
  return(out)
}

"split<-.ppp" <- function(x, f=marks(x), drop=FALSE, un=missing(f), 
                          ..., value) {
  verifyclass(x, "ppp")
  W <- x$window
  mf <- markformat(x)
  # evaluate `un' before assigning value of 'f'
  force(un)

  # validate assignment value
  stopifnot(is.list(value))
  if(!all(unlist(lapply(value, is.ppp))))
    stop(paste("Each entry of", sQuote("value"),
               "must be a point pattern"))

  ismark <- unlist(lapply(value, is.marked))
  if(any(ismark) && !all(ismark))
    stop(paste("Some entries of",
               sQuote("value"),
               "are marked, and others are unmarked"))
  vmarked <- all(ismark)

  # determine type of splitting
  if(missing(f)) {
    # f defaults to marks of x
    switch(mf,
           none={
             stop("f is missing and there are no marks")
           },
           vector={
             if(!is.multitype(x)) 
               stop("f is missing and the pattern is not multitype")
             f <- fsplit <- marks(x)
           },
           dataframe={
             f <- fsplit <- firstfactor(marks(x))
             if(is.null(f))
               stop("Data frame of marks contains no factors")
           })
  } else {
    # f given
    fsplit <- f
    if(is.tess(f)) {
      # f is a tessellation: determine the grouping
      f <- marks(cut(x, fsplit))
    } else if(is.im(f)) {
      # f is an image: determine the grouping
      fsplit <- tess(image=f)
      f <- marks(cut(x, fsplit))
    } else if(is.character(f) && length(f) == 1) {
      # f is the name of a column of marks
      marx <- marks(x)
      if(is.data.frame(marx) && (f %in% names(marx))) 
        fsplit <- f <- marx[[f]]
      else
        stop(paste("The name", sQuote(f), "does not match any column of marks"))
    } else if(!is.factor(f))
      stop(paste("f must be",
                 "a factor, a tessellation, an image,",
                 "or the name of a column of marks"))
    if(length(f) != x$n)
      stop("length(f) must equal the number of points in x")
  } 
  #
  all.levels <- lev <- levels(f)
  if(!drop) 
    levtype <- "levels of f"
  else {
    levtype <- "levels which f actually takes"
    # remove components that don't contain points
    lev <- lev[table(f) > 0]
  }
  if(length(value) != length(lev))
      stop(paste("length of", sQuote("value"),
                 "should equal the number of",
                 levtype))

  # ensure value[[i]] is associated with lev[i]
  if(!is.null(names(value))) {
    if(!all(names(value) %in% as.character(lev)))
      stop(paste("names of", sQuote("value"), "should be levels of f"))
    value <- value[lev]
  }
  names(value) <- NULL

  # restore the marks, if they were discarded
  if(un && is.marked(x)) {
    if(vmarked)
      warning(paste(sQuote("value"), "contains marked point patterns:",
                    "this is inconsistent with un=TRUE; marks ignored."))
    for(i in seq_along(value)) 
      value[[i]] <- value[[i]] %mark% factor(lev[i], levels=all.levels)
  }

  # handle NA's in splitting factor
  if(any(isNA <- is.na(f))) {
    xNA <- x[isNA]
    if(un && is.marked(x)) 
      xNA <- xNA %mark% factor(NA, levels=all.levels)
    value <- append(value, list(xNA))
  }

  # put Humpty together again
  out <- do.call(superimpose,c(value,list(W=W)))
  return(out)
}


print.splitppp <- function(x, ...) {
  f <- attr(x, "fsplit")
  what <- if(is.tess(f)) "tessellation" else
          if(is.factor(f)) "factor" else "unknown data"
  cat(paste("Point pattern split by", what, "\n"))
  nam <- names(x)
  for(i in seq_along(x)) {
    cat(paste("\n", nam[i], ":\n", sep=""))
    print(x[[i]])
  }
  return(invisible(NULL))
}

summary.splitppp <- function(object, ...) {
  x <- lapply(object, summary, ...)
  class(x) <- "summary.splitppp"
  x
}

print.summary.splitppp <- function(x, ...) {
  class(x) <- "listof"
  print(x)
  invisible(NULL)
}

"[.splitppp" <- function(x, ...) {
  f <- attr(x, "fsplit")
  # invoke list method on x
  class(x) <- "list"
  y <- x[...]
  # then make it a 'splitppp' object too
  class(y) <- c("splitppp", class(y))
  if(is.tess(f)) {
    fsplit <- f[...]
  } else if(is.factor(f)) {
    lev <- levels(f)
    sublev <- lev[...]
    subf <- f[f %in% sublev]
    fsplit <- factor(subf, levels=lev)
  } else stop("Unknown splitting type")
  attr(y, "fsplit") <- fsplit
  y
}

"[<-.splitppp" <- function(x, ..., value) {
  if(!all(unlist(lapply(value, is.ppp))))
    stop("replacement value must be a list of point patterns")
  f <- attr(x, "fsplit")
  # invoke list method
  class(x) <- "list"
  x[...] <- value
  # then make it a 'splitppp' object too
  class(x) <- c("splitppp", class(x))
  if(is.tess(f)) {
    fsplit <- f
  } else if(is.factor(f)) {
    lev <- levels(f)
    fsplit <- factor(rep.int(lev, unlist(lapply(x, npoints))), levels=lev)
  }
  attr(x, "fsplit") <- fsplit
  x
}
  
density.splitppp <- function(x, ...) {
  as.listof(lapply(x, density, ...))
}

plot.splitppp <- function(x, ..., main) {
  if(missing(main)) main <- short.deparse(substitute(x))
  do.call("plot.listof",
          resolve.defaults(list(x=x, main=main),
                           list(...),
                           list(equal.scales=TRUE)))
}

as.layered.splitppp <- function(X) { do.call("layered", X) }

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/split.ppx.R"
#
# split.ppx.R
#
# $Revision: 1.3 $ $Date: 2013/04/25 06:37:43 $
#
# split.ppx etc
#
#########################################

split.ppx <- function(x, f = marks(x), drop=FALSE, un=NULL, ...) {
  stopifnot(inherits(x, "ppx"))
  mf <- markformat(x)
  if(is.null(un))
    un <- missing(f) && !(mf %in% c("dataframe", "hyperframe"))

  if(missing(f)) {
    # f defaults to marks of x
    switch(mf,
           none={
             stop("f is missing and there are no marks")
           },
           vector={
             if(!is.multitype(x)) 
               stop("f is missing and the pattern is not multitype")
             f <- fsplit <- marks(x)
           },
           hyperframe=,
           dataframe={
             f <- fsplit <- firstfactor(marks(x))
             if(is.null(f))
               stop("Marks do not include a factor")
           })
    splittype <- "factor"
  } else{
    # f was given
    fsplit <- f
    if(is.factor(f)) {
      splittype <- "factor"
    } else if(is.character(f) && length(f) == 1) {
      # f is the name of a column of marks
      marx <- marks(x)
      if((is.data.frame(marx) || is.hyperframe(marx))
         && (f %in% names(marx))) {
        fsplit <- f <- marx[[f]]
      } else
        stop(paste("The name", sQuote(f), "does not match any column of marks"))
      splittype <- "factor"
    } else 
      stop(paste("f must be",
                 "a factor,",
                 "or the name of a column of marks"))
    if(length(f) != npoints(x))
      stop("length(f) must equal the number of points in x")
  }

  # At this point
  # 'f' is a factor that can be used to separate the points
  # 'fsplit' is the object (either a factor or a tessellation)
  # that determines the split (and can be "un-split")

  lev <- levels(f)
  if(drop) {
    # remove components that don't contain points
    retain <- (table(f) > 0)
    lev <- lev[retain]
    switch(splittype,
           factor = {
             # delete levels that don't occur
             fsplit <- factor(fsplit, levels=lev)
           },
           stop("Internal error: wrong format for fsplit"))
  }

  # split the data
  out <- list()
  for(l in lev) 
    out[[paste(l)]] <- x[!is.na(f) & (f == l)]
  
  if(un)
     out <- lapply(out, unmark)
  class(out) <- c("splitppx", "listof", class(out))
  attr(out, "fsplit") <- fsplit
  return(out)
}

print.splitppx <- function(x, ...) {
  f <- attr(x, "fsplit")
  what <- if(is.factor(f)) "factor" else "unknown data"
  cat(paste("Multidimensional point pattern split by", what, "\n"))
  nam <- names(x)
  for(i in seq_along(x)) {
    cat(paste("\n", nam[i], ":\n", sep=""))
    print(x[[i]])
  }
  return(invisible(NULL))
}

summary.splitppx <- function(object, ...) {
  x <- lapply(object, summary, ...)
  class(x) <- "summary.splitppx"
  x
}

print.summary.splitppx <- function(x, ...) {
  class(x) <- "listof"
  print(x)
  invisible(NULL)
}

"[.splitppx" <- function(x, ...) {
  f <- attr(x, "fsplit")
  # invoke list method on x
  class(x) <- "list"
  y <- x[...]
  # then make it a 'splitppx' object too
  class(y) <- c("splitppx", class(y))
  if(is.factor(f)) {
    lev <- levels(f)
    sublev <- lev[...]
    subf <- f[f %in% sublev]
    fsplit <- factor(subf, levels=lev)
  } else stop("Unknown splitting type")
  attr(y, "fsplit") <- fsplit
  y
}

"[<-.splitppx" <- function(x, ..., value) {
  if(!all(unlist(lapply(value, is.ppx))))
    stop("replacement value must be a list of point patterns (ppx)")
  f <- attr(x, "fsplit")
  # invoke list method
  class(x) <- "list"
  x[...] <- value
  # then make it a 'splitppx' object too
  class(x) <- c("splitppx", class(x))
  if(is.factor(f)) {
    lev <- levels(f)
    fsplit <- factor(rep.int(lev, unlist(lapply(x, npoints))), levels=lev)
  }
  attr(x, "fsplit") <- fsplit
  x
}
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/stienen.R"
## stienen.R
##
##  Stienen diagram with border correction
##
##  $Revision: 1.7 $ $Date: 2014/12/06 02:29:14 $

stienen <- function(X, ..., bg="grey", border=list(bg=NULL)) {
  Xname <- short.deparse(substitute(X))
  stopifnot(is.ppp(X))
  if(npoints(X) <= 1) {
    do.call(plot,
            resolve.defaults(list(x=Window(X)),
                             list(...),
                             list(main=Xname)))
    return(invisible(NULL))
  }
  d <- nndist(X)
  b <- bdist.points(X)
  Y <- X %mark% d
  gp <- union(graphicsPars("symbols"), "lwd")
  do.call.plotfun(plot.ppp,
                  resolve.defaults(list(x=Y[b >= d],
                                        markscale=1),
                                   list(...),
                                   list(bg=bg),
                                   list(main=Xname)),
                  extrargs=gp)
  if(!identical(border, FALSE)) {
    if(!is.list(border)) border <- list()
    do.call.plotfun(plot.ppp,
                    resolve.defaults(list(x=Y[b < d],
                                          markscale=1,
                                          add=TRUE),
                                     border,
                                     list(...),
                                     list(bg=bg),
                                     list(cols=grey(0.75), lwd=2)),
                  extrargs=gp)
  }
  return(invisible(NULL))
}

stienenSet <- function(X, edge=TRUE) {
  stopifnot(is.ppp(X))
  nnd <- nndist(X)
  if(!edge) {
    ok <- bdist.points(X) >= nnd
    X <- X[ok]
    nnd <- nnd[ok]
  }
  n <- npoints(X)
  if(n == 0) return(emptywindow(Window(X)))
  if(n == 1) return(Window(X))
  d <- nnd/2
  delta <- 2 * pi * max(d)/128
  Z <- disc(d[1], X[1], delta=delta)
  for(i in 2:n) Z <- union.owin(Z, disc(d[i], X[i], delta=delta))
  return(Z)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/strauss.R"
#
#
#    strauss.R
#
#    $Revision: 2.32 $	$Date: 2014/12/07 09:01:47 $
#
#    The Strauss process
#
#    Strauss()    create an instance of the Strauss process
#                 [an object of class 'interact']
#	
#
# -------------------------------------------------------------------
#	

Strauss <- local({

  # create blank template object without family and pars

  BlankStrauss <-
  list(
       name     = "Strauss process",
       creator  = "Strauss",
       family    = "pairwise.family", # evaluated later
       pot      = function(d, par) {
         d <= par$r
       },
       par      = list(r = NULL), # to be filled in
       parnames = "interaction distance",
       init     = function(self) {
         r <- self$par$r
         if(!is.numeric(r) || length(r) != 1 || r <= 0)
           stop("interaction distance r must be a positive number")
       },
       update = NULL,  # default OK
       print = NULL,    # default OK
       interpret =  function(coeffs, self) {
         loggamma <- as.numeric(coeffs[1])
         gamma <- exp(loggamma)
         return(list(param=list(gamma=gamma),
                     inames="interaction parameter gamma",
                     printable=dround(gamma)))
       },
       valid = function(coeffs, self) {
         loggamma <- as.numeric(coeffs[1])
         return(is.finite(loggamma) && (loggamma <= 0))
       },
       project = function(coeffs, self) {
         if((self$valid)(coeffs, self)) return(NULL) else return(Poisson())
       },
       irange = function(self, coeffs=NA, epsilon=0, ...) {
         r <- self$par$r
         if(any(is.na(coeffs)))
           return(r)
         loggamma <- coeffs[1]
         if(abs(loggamma) <= epsilon)
           return(0)
         else
           return(r)
       },
       version=NULL, # to be filled in 
       # fast evaluation is available for the border correction only
       can.do.fast=function(X,correction,par) {
         return(all(correction %in% c("border", "none")))
       },
       fasteval=function(X,U,EqualPairs,pairpot,potpars,correction, ...) {
         # fast evaluator for Strauss interaction
         if(!all(correction %in% c("border", "none")))
           return(NULL)
         if(spatstat.options("fasteval") == "test")
           message("Using fast eval for Strauss")
         r <- potpars$r
         answer <- strausscounts(U, X, r, EqualPairs)
         return(matrix(answer, ncol=1))
       },
       Mayer=function(coeffs, self) {
         # second Mayer cluster integral
         gamma <- exp(as.numeric(coeffs[1]))
         r <- self$par$r
         return((1-gamma) * pi * r^2)
       },
       Percy=function(d, coeffs, par, ...) {
         ## term used in Percus-Yevick type approximation
         gamma <- exp(as.numeric(coeffs[1]))
         R <- par$r
         t <- abs(d/(2*R))
         t <- pmin.int(t, 1)
         y <- 2 * R^2 * (pi * (1-gamma)
                         - (1-gamma)^2 * (acos(t) - t * sqrt(1 - t^2)))
         return(y)
       },
       delta2 = function(X, inte, correction, ...) {
         if(!(correction %in% c("border", "none")))
           return(NULL)
         r <- inte$par$r
         X <- as.ppp(X) # algorithm is the same for data and dummy points
         nX <- npoints(X)
         cl <- closepairs(X, r, what="indices")
         I <- factor(cl$i, levels=1:nX)
         J <- factor(cl$j, levels=1:nX)
         v <- table(I, J)
         return(v)
       }
       )
  class(BlankStrauss) <- "interact"


  # Finally define main function
  
  Strauss <- function(r) {
    instantiate.interact(BlankStrauss, list(r=r))
  }

  Strauss <- intermaker(Strauss, BlankStrauss)
  
  Strauss
})

# generally accessible functions
      
strausscounts <- function(U, X, r, EqualPairs=NULL) {
  answer <- crosspaircounts(U,X,r)
  # subtract counts of identical pairs
  if(length(EqualPairs) > 0) {
    nU <- npoints(U)
    idcount <- as.integer(table(factor(EqualPairs[,2], levels=1:nU)))
    answer <- answer - idcount
  }
  return(answer)
}

crosspaircounts <- function(X, Y, r) {
  stopifnot(is.ppp(X))
  stopifnot(is.numeric(r) && length(r) == 1)
  stopifnot(is.finite(r))
  stopifnot(r >= 0)
  # sort in increasing order of x coordinate
  oX <- fave.order(X$x)
  oY <- fave.order(Y$x)
  Xsort <- X[oX]
  Ysort <- Y[oY]
  nX <- npoints(X)
  nY <- npoints(Y)
  # call C routine
  out <- .C("Ccrosspaircounts",
            nnsource = as.integer(nX),
            xsource  = as.double(Xsort$x),
            ysource  = as.double(Xsort$y),
            nntarget = as.integer(nY),
            xtarget  = as.double(Ysort$x),
            ytarget  = as.double(Ysort$y),
            rrmax    = as.double(r),
            counts   = as.integer(integer(nX)))
  answer <- integer(nX)
  answer[oX] <- out$counts
  return(answer)
}

closepaircounts <- function(X, r) {
  stopifnot(is.ppp(X))
  stopifnot(is.numeric(r) && length(r) == 1)
  stopifnot(is.finite(r))
  stopifnot(r >= 0)
  # sort in increasing order of x coordinate
  oX <- fave.order(X$x)
  Xsort <- X[oX]
  nX <- npoints(X)
  # call C routine
  out <- .C("Cclosepaircounts",
            nxy    = as.integer(nX),
            x      = as.double(Xsort$x),
            y      = as.double(Xsort$y),
            rmaxi  = as.double(r),
            counts = as.integer(integer(nX)))
  answer <- integer(nX)
  answer[oX] <- out$counts
  return(answer)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/strausshard.R"
#
#
#    strausshard.S
#
#    $Revision: 2.20 $	$Date: 2014/10/24 00:22:30 $
#
#    The Strauss/hard core process
#
#    StraussHard()     create an instance of the Strauss-hardcore process
#                      [an object of class 'interact']
#	
#
# -------------------------------------------------------------------
#	

StraussHard <- local({

  BlankStraussHard <- 
    list(
         name   = "Strauss - hard core process",
         creator = "StraussHard",
         family  = "pairwise.family",  # evaluated later
         pot    = function(d, par) {
           v <- 1 * (d <= par$r)
           v[ d <= par$hc ] <-  (-Inf)
           v
         },
         par    = list(r = NULL, hc = NULL), # filled in later
         parnames = c("interaction distance",
                      "hard core distance"), 
         selfstart = function(X, self) {
           # self starter for StraussHard
           nX <- npoints(X)
           if(nX < 2) {
             # not enough points to make any decisions
             return(self)
           }
           r <- self$par$r
           md <- minnndist(X)
           if(md == 0) {
             warning(paste("Pattern contains duplicated points:",
                           "hard core must be zero"))
             return(StraussHard(r=r, hc=0))
           }
           if(!is.na(hc <- self$par$hc)) {
             # value fixed by user or previous invocation
             # check it
             if(md < hc)
               warning(paste("Hard core distance is too large;",
                             "some data points will have zero probability"))
             return(self)
           }
           # take hc = minimum interpoint distance * n/(n+1)
           hcX <- md * nX/(nX+1)
           StraussHard(r=r, hc = hcX)
         },
         init   = function(self) {
           r <- self$par$r
           hc <- self$par$hc
           if(length(hc) != 1)
             stop("hard core distance must be a single value")
           if(!is.na(hc)) {
             if(!is.numeric(hc) || hc <= 0)
               stop("hard core distance hc must be a positive number, or NA")
             if(!is.numeric(r) || length(r) != 1 || r <= hc)
               stop("interaction distance r must be a number greater than hc")
           }
         },
         update = NULL,       # default OK
         print = NULL,         # default OK
         interpret =  function(coeffs, self) {
           loggamma <- as.numeric(coeffs[1])
           gamma <- exp(loggamma)
           return(list(param=list(gamma=gamma),
                       inames="interaction parameter gamma",
                       printable=dround(gamma)))
         },
         valid = function(coeffs, self) {
           loggamma <- as.numeric(coeffs[1])
           return(is.finite(loggamma))
         },
         project = function(coeffs, self) {
           loggamma <- as.numeric(coeffs[1])
           if(is.finite(loggamma))
             return(NULL)
           hc <- self$par$hc
           if(hc > 0) return(Hardcore(hc)) else return(Poisson()) 
         },
         irange = function(self, coeffs=NA, epsilon=0, ...) {
           r <- self$par$r
           hc <- self$par$hc
           if(any(is.na(coeffs)))
             return(r)
           loggamma <- coeffs[1]
           if(abs(loggamma) <= epsilon)
             return(hc)
           else
             return(r)
         },
       version=NULL, # evaluated later
       # fast evaluation is available for the border correction only
       can.do.fast=function(X,correction,par) {
         return(all(correction %in% c("border", "none")))
       },
       fasteval=function(X,U,EqualPairs,pairpot,potpars,correction, ...) {
         # fast evaluator for StraussHard interaction
         if(!all(correction %in% c("border", "none")))
           return(NULL)
         if(spatstat.options("fasteval") == "test")
           message("Using fast eval for StraussHard")
         r <- potpars$r
         hc <- potpars$hc
         hclose <- strausscounts(U, X, hc, EqualPairs)
         rclose <- strausscounts(U, X, r,  EqualPairs)
         answer <- ifelseXB(hclose == 0, rclose, -Inf)
         return(matrix(answer, ncol=1))
       },
       Mayer=function(coeffs, self) {
         # second Mayer cluster integral
         gamma <- exp(as.numeric(coeffs[1]))
         r <- self$par$r
         hc <- self$par$hc
         return(pi * (hc^2 + (1-gamma) * (r^2 - hc^2)))
       }
         )
  class(BlankStraussHard) <- "interact"
  
  StraussHard <- function(r, hc=NA) {
    instantiate.interact(BlankStraussHard, list(r=r, hc=hc))
  }

  StraussHard <- intermaker(StraussHard, BlankStraussHard)
  
  StraussHard
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/subfits.R"
#
#
#  $Revision: 1.31 $   $Date: 2014/11/11 03:06:52 $
#
#
subfits.new <- function(object, what="models", verbose=FALSE) {
  stopifnot(inherits(object, "mppm"))

  if(!(what %in% c("models","interactions")))
    stop(paste("Unrecognised option: what=", dQuote(what)))

  if(what == "interactions")
    return(subfits.old(object, what, verbose))
  
  # extract stuff
  announce <- if(verbose) function(x) { cat(x) } else function(x) {} 
    
  announce("Extracting stuff...")
  fitter   <- object$Fit$fitter
  FIT      <- object$Fit$FIT
  coef.FIT <- coef(FIT)
  trend    <- object$trend
#  iformula <- object$iformula
#  use.gam  <- object$Fit$use.gam
  info     <- object$Info
  npat     <- object$npat
  Inter    <- object$Inter
  interaction <- Inter$interaction
  itags    <- Inter$itags
  Vnamelist <- object$Fit$Vnamelist
  announce("done.\n")

  # determine which interaction(s) are active on each row
  announce("Determining active interactions...")
  active <- active.interactions(object)
  announce("done.\n")

  # exceptions
  if(any(rowSums(active) > 1))
    stop(paste("subfits() is not implemented for models",
               "in which several interpoint interactions",
               "are active on the same point pattern"))
  
  # implied coefficients for each active interaction
  announce("Computing implied coefficients...")
  implcoef <- list()
  for(tag in itags) {
    announce(tag)
    implcoef[[tag]] <- impliedcoefficients(object, tag)
    announce(", ")
  }
  announce("done.\n")

  # Fisher information, if possible
  if(what == "models") {
    announce("Fisher information...")
    fisher   <- vcov(object, what="fisher", err="null")
    varcov   <- try(solve(fisher), silent=TRUE)
    if(inherits(varcov, "try-error"))
      varcov <- NULL
    announce("done.\n")
  }
  
  # Extract data frame 
  announce("Extracting data...")
  datadf   <- object$datadf
  has.design <- info$has.design
  rownames <- object$Info$rownames
  announce("done.\n")

  # set up lists for results 
  models <- rep(list(NULL), npat)
  interactions <- rep(list(NULL), npat)

  # interactions
  announce("Determining interactions...")
  for(i in 1:npat) {
    if(verbose) progressreport(i, npat)
      # Find relevant interaction
    acti <- active[i,]
    nactive <- sum(acti)
    interi <- if(nactive == 0) Poisson else interaction[i, acti, drop=TRUE]
    tagi <- names(interaction)[acti]
      # Find relevant coefficients
    coef.avail  <- coef.FIT
    if(nactive == 1) {
      ic <- implcoef[[tagi]]
      coef.implied <- ic[i, ,drop=TRUE]
      names(coef.implied) <- colnames(ic)
    }
    # overwrite any existing values of coefficients; add new ones.
    coef.avail[names(coef.implied)] <- coef.implied
      # create fitted interaction with these coefficients
    interactions[[i]] <- fii(interi, coef.avail, Vnamelist[[tagi]])
    }
  announce("Done!\n")
  names(interactions) <- rownames

  #
  if(what=="interactions") 
    return(interactions)
  
  # Extract data required to reconstruct complete model fits
  announce("Extracting more data...")
  data  <- object$data
  Y     <- object$Y
  Yname <- info$Yname
  moadf <- object$Fit$moadf
  fmla  <- object$Fit$fmla
  # deal with older formats of mppm
  if(is.null(Yname)) Yname <- info$Xname
  if(is.null(Y)) Y <- data[ , Yname, drop=TRUE]
  # 
  used.cov.names <- info$used.cov.names
  has.covar <- info$has.covar
  if(has.covar) {
    covariates.hf <- data[, used.cov.names, drop=FALSE]
    dfvar <- used.cov.names %in% names(datadf)
  }
  announce("done.\n")

  # Construct template for fake ppm object
  spv <- package_version(versionstring.spatstat())
  fake.version <- list(major=spv$major,
                      minor=spv$minor,
                      release=spv$patchlevel,
                      date="$Date: 2014/11/11 03:06:52 $")
  fake.call <- call("cannot.update", Q=NULL, trend=trend,
                           interaction=NULL, covariates=NULL,
                           correction=object$Info$correction,
                           rbord     = object$Info$rbord)
  fakemodel <- list(
                    method       = "mpl",
                    fitter       = fitter,
                    coef         = coef(object),
                    trend        = object$trend,
                    interaction  = NULL,
                    fitin        = NULL,
                    Q            = NULL,
                    maxlogpl     = NA,
                    internal     = list(glmfit = FIT,
                                        glmdata  = NULL,
                                        Vnames   = NULL,
                                        fmla     = fmla,
                                        computed = list()),
                    covariates   = NULL,
                    correction   = object$Info$correction,
                    rbord        = object$Info$rbord,
                    version      = fake.version,
                    problems     = list(),
                    fisher       = fisher,
                    varcov       = varcov,
                    call         = fake.call,
                    callstring   = "cannot.update()",
                    fake         = TRUE)
  class(fakemodel) <- "ppm"

  ## Loop through point patterns
  announce("Generating models for each row...")
  for(i in 1:npat) {
    if(verbose) progressreport(i, npat)
    Yi <- Y[[i]]
    Wi <- if(is.ppp(Yi)) Yi$window else Yi$data$window
    # assemble relevant covariate images
    covariates <-
      if(has.covar) covariates.hf[i, , drop=TRUE, strip=FALSE] else NULL
    if(has.covar && has.design) 
      ## Convert each data frame covariate value to an image
      covariates[dfvar] <- lapply(covariates[dfvar], as.im, W=Wi)

    # Extract relevant interaction
    finte <- interactions[[i]]
    inte  <- finte$interaction
    if(is.poisson.interact(inte)) inte <- NULL
    Vnames <- finte$Vnames
    if(length(Vnames) == 0) Vnames <- NULL
    
    # Construct fake ppm object
    fakemodel$interaction <- inte
    fakemodel$fitin       <- finte
    fakemodel$Q           <- Yi
    fakemodel$covariates  <- covariates
    fakemodel$internal$glmdata <- moadf[moadf$id == i, ]
    fakemodel$internal$Vnames  <- Vnames

    fake.call$Q <- Yi
    fake.call$covariates <- covariates
    fakemodel$call <- fake.call
    fakemodel$callstring <- short.deparse(fake.call)

    # store in list
    models[[i]] <- fakemodel
  }
  announce("done.\n")
  names(models) <- rownames
  class(models) <- c("listof", class(models))
  return(models)
}

subfits <-
subfits.old <-
  function(object, what="models", verbose=FALSE) {
  stopifnot(inherits(object, "mppm"))

  if(!(what %in% c("models","interactions")))
    stop(paste("Unrecognised option: what=", dQuote(what)))
  
  # extract stuff
  announce <- if(verbose) function(x) { cat(x) } else function(x) {} 
    
  announce("Extracting stuff...")
  FIT      <- object$Fit$FIT
  coef.FIT <- coef(FIT)
  trend    <- object$trend
#  iformula <- object$iformula
  use.gam  <- object$Fit$use.gam
  info     <- object$Info
  npat     <- object$npat
  Inter    <- object$Inter
  interaction <- Inter$interaction
  itags    <- Inter$itags
  Vnamelist <- object$Fit$Vnamelist
  announce("done.\n")

  # determine which interaction(s) are active on each row
  announce("Determining active interactions...")
  active <- active.interactions(object)
  announce("done.\n")

  # exceptions
  if(any(rowSums(active) > 1))
    stop(paste("subfits() is not implemented for models",
               "in which several interpoint interactions",
               "are active on the same point pattern"))
  
  # implied coefficients for each active interaction
  announce("Computing implied coefficients...")
  implcoef <- list()
  for(tag in itags) {
    announce(tag)
    implcoef[[tag]] <- impliedcoefficients(object, tag)
    announce(", ")
  }
  announce("done.\n")

  # Fisher information, if possible
  if(what == "models") {
    announce("Fisher information...")
    fisher   <- vcov(object, what="fisher", err="null")
    varcov   <- try(solve(fisher), silent=TRUE)
    if(inherits(varcov, "try-error"))
      varcov <- NULL
    announce("done.\n")
  }
  
  # Extract data frame 
  announce("Extracting data...")
  datadf   <- object$datadf
  has.design <- info$has.design
  rownames <- object$Info$rownames
  announce("done.\n")

  # set up list for results 
  results <- rep(list(NULL), npat)
  
  if(what == "interactions") {
    announce("Determining interactions...")
    for(i in 1:npat) {
      if(verbose) progressreport(i, npat)
      # Find relevant interaction
      acti <- active[i,]
      nactive <- sum(acti)
      interi <- if(nactive == 0) Poisson else interaction[i, acti, drop=TRUE]
      tagi <- names(interaction)[acti]
      # Find relevant coefficients
      coef.avail  <- coef.FIT
      if(nactive == 1) {
        ic <- implcoef[[tagi]]
        coef.implied <- ic[i, ,drop=TRUE]
        names(coef.implied) <- colnames(ic)
      }
      # overwrite any existing values of coefficients; add new ones.
      coef.avail[names(coef.implied)] <- coef.implied
      # create fitted interaction with these coefficients
      results[[i]] <- fii(interi, coef.avail, Vnamelist[[tagi]])
    }
    announce("Done!\n")
    names(results) <- rownames
    return(results)
  }
  
  # Extract data required to reconstruct complete model fits
  announce("Extracting more data...")
  data  <- object$data
  Y     <- object$Y
  Yname <- info$Yname
  # deal with older formats of mppm
  if(is.null(Yname)) Yname <- info$Xname
  if(is.null(Y)) Y <- data[ , Yname, drop=TRUE]
  # 
  used.cov.names <- info$used.cov.names
  has.covar <- info$has.covar
  if(has.covar) {
    covariates.hf <- data[, used.cov.names, drop=FALSE]
    dfvar <- used.cov.names %in% names(datadf)
  }
  announce("done.\n")
  
  ## Loop through point patterns
  announce("Looping through rows...")
  for(i in 1:npat) {
    if(verbose) progressreport(i, npat)
    Yi <- Y[[i]]
    Wi <- if(is.ppp(Yi)) Yi$window else Yi$data$window
    # assemble relevant covariate images
    covariates <-
      if(has.covar) covariates.hf[i, , drop=TRUE, strip=FALSE] else NULL
    if(has.covar && has.design) {
      ## Convert each data frame covariate value to an image
      imrowi <- lapply(covariates[dfvar], as.im, W=Wi)
      
      # Problem: constant covariate leads to singular fit
      # --------------- Hack: ---------------------------
      #  Construct fake data by resampling from possible values
      possible <- function(z) {
        if(is.factor(z))
          factor(levels(z), levels=levels(z))
        else
          unique(z)
      }
      covar.vals <- lapply(as.list(covariates[dfvar, drop=FALSE]), possible)
      scramble <- function(vals, W, Y) {
        W <- as.mask(W)
        npixels <- prod(W$dim)
        nvalues <- length(vals)
        npoints <- Y$n
        # sample the possible values randomly at the non-data pixels
        sampled <- sample(vals, npixels, replace=TRUE)
        Z <- im(sampled, xcol=W$xcol, yrow=W$yrow)
        # repeat the possible values cyclically at the data points
        if(npoints >= 1)
          Z[Y] <- vals[1 + ((1:npoints) %% nvalues)]
        return(Z)
      }
      fake.imrowi <- lapply(covar.vals, scramble, W=Wi, Y=Yi$data)
      # insert fake data into covariates 
      covariates[dfvar] <- fake.imrowi
      # ------------------ end hack ----------------------------
    }

    # Fit ppm to data for case i only
    # using relevant interaction
    acti <- active[i,]
    nactive <- sum(acti)
    if(nactive == 1){
      interi <- interaction[i, acti, drop=TRUE] 
      tagi <- names(interaction)[acti]
      fit <- ppm(Yi, trend, interi, covariates=covariates,
                 use.gam=use.gam,
                 forcefit=TRUE, vnamebase=tagi, vnameprefix=tagi)
    } else {
      fit <- ppm(Yi, trend, Poisson(), covariates=covariates,
                 use.gam=use.gam,
                 forcefit=TRUE)
    }
    
    # now reset the coefficients to those obtained from the full fit
    coefnames.wanted <- names(fit$coef)
    coef.avail  <- coef.FIT
    if(nactive == 1) {
      ic <- implcoef[[tagi]]
      coef.implied <- ic[i, ,drop=TRUE]
      names(coef.implied) <- colnames(ic)
      # overwrite any existing values of coefficients; add new ones.
      coef.avail[names(coef.implied)] <- coef.implied
    }
    if(!all(coefnames.wanted %in% names(coef.avail))) 
      stop("Internal error: some fitted coefficients not accessible")
    fit$theta <- fit$coef <- coef.avail[coefnames.wanted]
    # ... make sure these coefficients will be used in getglmfit, etc ...
    fit$method <- "mppm"
    # ... and replace fake data by true data
    if(has.design) {
      for(nam in names(imrowi)) {
        fit$covariates[[nam]] <- imrowi[[nam]]
        fit$internal$glmdata[[nam]] <- data[i, nam, drop=TRUE]
      }
      # ... and tell glm fit object that it has full rank
      fit$internal$glmfit$rank <- FIT$rank
    }
    # Fisher information and variance-covariance if known
    # Extract submatrices for relevant parameters
    if(!is.null(fisher)) 
      fit$fisher <- fisher[coefnames.wanted, coefnames.wanted, drop=FALSE]
    if(!is.null(varcov))
      fit$varcov <- varcov[coefnames.wanted, coefnames.wanted, drop=FALSE]
    # store in list
    results[[i]] <- fit
  }
  announce("done.\n")
  names(results) <- rownames
  class(results) <- c("listof", class(results))
  return(results)
}

cannot.update <- function(...) {
  stop("This model cannot be updated")
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/subset.R"
##
## subset.R
##
## Methods for 'subset'
##
##   $Revision: 1.1 $  $Date: 2014/07/19 02:58:23 $

subset.ppp <- function(x, subset, select, ...) {
  stopifnot(is.ppp(x))
  w <- as.owin(x)
  y <- as.data.frame(x)
  r <- if (missing(subset)) 
    rep_len(TRUE, nrow(y))
  else {
    e <- substitute(subset)
    r <- eval(e, y, parent.frame())
    if (!is.logical(r)) 
      stop("'subset' must be logical")
    r & !is.na(r)
  }
  vars <- if (missing(select)) 
    TRUE
  else {
    ## create an environment in which column names are mapped to their positions
    nl <- as.list(seq_along(y))
    names(nl) <- names(y)
    if(length(nl) > 3) {
      ## multiple columns of marks: add the name 'marks'
      nl <- append(nl, list(marks=3:length(nl)))
    }
    eval(substitute(select), nl, parent.frame())
  }
  ## ensure columns include coordinates
  nama <- names(y)
  names(nama) <- nama
  vars <- union(c("x", "y"), nama[vars])
  ## take subset
  z <- y[r, vars, drop = FALSE]
  ## reinstate as point pattern
  out <- as.ppp(z, W=w, check=FALSE)
  return(out)
}

subset.pp3 <- subset.lpp <- subset.ppx <- function(x, subset, select, ...) {
  y <- as.data.frame(x)
  r <- if (missing(subset)) 
    rep_len(TRUE, nrow(y))
  else {
    e <- substitute(subset)
    r <- eval(e, y, parent.frame())
    if (!is.logical(r)) 
      stop("'subset' must be logical")
    r & !is.na(r)
  }
  vars <- if (missing(select)) 
    TRUE
  else {
    ## create an environment in which column names are mapped to their positions
    nl <- as.list(seq_along(y))
    names(nl) <- names(y)
    if(!("marks" %in% names(y)) && any(ismark <- (x$ctype == "mark"))) {
      ## add the symbol 'marks' 
      nl <- append(nl, list(marks=which(ismark)))
    }
    eval(substitute(select), nl, parent.frame())
  }
  ## ensure columns include coordinates 
  nama <- names(y)
  names(nama) <- nama
  vars <- union(names(coords(x)), nama[vars])
  ## take subset
  z <- y[r, vars, drop = FALSE]
  ## reinstate as point pattern
  ctype <- as.character(x$ctype)[match(vars, nama)]
  out <- ppx(z, domain=x$domain, coord.type=ctype)
  ## reinstate class
  class(out) <- class(x)
  return(out)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/suffstat.R"
#
#   suffstat.R
#
# calculate sufficient statistic
#
#  $Revision: 1.17 $  $Date: 2013/04/25 06:37:43 $
#
#

suffstat <- function(model, X=data.ppm(model)) {
  cl <- sys.call()
  callstring <- short.deparse(cl)

  verifyclass(model, "ppm")
  if(!missing(X))
    verifyclass(X, "ppp")
  else
    X <- NULL

  inter    <- model$interaction

  func <- if(is.null(inter) || is.poisson(inter)) suffstat.poisson else 
          if(!is.null(ssinter  <- inter$suffstat)) ssinter else
          if(!is.null(ssfamily <- inter$family$suffstat)) ssfamily else
          suffstat.generic

  return(func(model, X, callstring))
}

suffstat.generic <- function(model, X=NULL, callstring="suffstat.generic") {
  # This should work for an arbitrary ppm
  # since it uses the fundamental relation between
  # conditional intensity and likelihood.
  # But it is computationally intensive.

  verifyclass(model, "ppm")
  coefnames <- names(coef(model))

  if(is.null(X)) {
    X <- data.ppm(model)
    modelX <- model
  } else {
    verifyclass(X, "ppp")
    # refit the model to determine which points are used in pseudolikelihood
    modelX <- update(model, X, method="mpl")
  }
  
  # find data points which do not contribute to pseudolikelihood
  mplsubset <- getglmdata(modelX)$.mpl.SUBSET
  mpldata   <- is.data(quad.ppm(modelX))
  contribute <- mplsubset[mpldata]

  if(!any(contribute)) 
    # result is zero vector
    return(0 * coef(model))

  # Add points one-by-one
  # If there are points which don't contribute, condition on them
  use <- which(contribute)   
  dontuse <- which(!contribute)
  for(i in seq_along(use)) {
    prior <- if(i == 1) c() else use[1:(i-1)]
    prior <- c(dontuse, prior)
    Xprior <- X[prior]
    Xcurrent <- X[use[i]]
    mom <- partialModelMatrix(Xprior, Xcurrent, model, "suffstat")
    lastrow <- length(prior) + 1
    momrow <- mom[lastrow, ]
    if(i == 1)
      result <- momrow
    else
      result <- momrow + result
  }
  names(result) <- coefnames
  attr(result, "mplsubset") <- NULL
  return(result)
}

killinteraction <- function(model) {
  verifyclass(model, "ppm")
  ispoisson <- summary(model, quick=TRUE)$poisson
  if(ispoisson)
    return(model)
  # surgery required
  newmodel <- model
  newmodel$interaction <- NULL
  if(!is.null(Vnames <- model$internal$Vnames)) {
    matches <- names(model$coef) %in% Vnames
    newmodel$coef <- model$coef[!matches]
    newmodel$internal$Vnames <- NULL
  }
  # the other 'internal' stuff may still be wrong (or `preserved')
  return(newmodel)
}

suffstat.poisson <- function(model, X, callstring="suffstat.poisson") {
  verifyclass(model, "ppm")
  if(is.null(X))
    X <- data.ppm(model)
  else 
    verifyclass(X, "ppp")
  
  if(!is.poisson(model))
    stop("Model is not a Poisson process")

  Empty <- X[numeric(0)]
  mom <- partialModelMatrix(X, Empty, model, "suffstat")

  nmom <- ncol(mom)
  ncoef <- length(coef(model))
  if(nmom != ncoef)
    stop("Internal error: number of columns of model matrix does not match number of coefficients in fitted model")
  
  if(nmom > 1 && any(colnames(mom) != names(coef(model))))
    warning("Internal error: mismatch between column names of model matrix and names of coefficient vector in fitted model")
     
  o1sum   <- apply(mom, 2, sum)
  return(o1sum)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/summary.im.R"
#
#    summary.im.R
#
#    summary() method for class "im"
#
#    $Revision: 1.18 $   $Date: 2014/11/11 03:07:22 $
#
#    summary.im()
#    print.summary.im()
#    print.im()
#
summary.im <- function(object, ...) {
  verifyclass(object, "im")

  x <- object

  y <- unclass(x)[c("dim", "xstep", "ystep")]
  pixelarea <- y$xstep * y$ystep

  # extract image values
  v <- x$v
  inside <- !is.na(v)
  v <- v[inside]

  # type of values?
  y$type <- x$type
  
  # factor-valued?
  lev <- levels(x)
  if(!is.null(lev) && !is.factor(v))
    v <- factor(v, levels=seq_along(lev), labels=lev)

  switch(x$type,
         integer=,
         real={
           y$integral <- sum(v) * pixelarea
           y$mean <- mean(v)
           y$range <- range(v)
           y$min <- y$range[1]  
           y$max <- y$range[2]
         },
         factor={
           y$levels <- lev
           y$table <- table(v, dnn="")
         },
         complex={
           y$integral <- sum(v) * pixelarea
           y$mean <- mean(v)
           rr <- range(Re(v))
           y$Re <- list(range=rr, min=rr[1], max=rr[2])
           ri <- range(Im(v))
           y$Im <- list(range=ri, min=ri[1], max=ri[2])
         },
         {
           # another unknown type
           pixelvalues <- v
           y$summary <- summary(pixelvalues)
         })
    
  # summarise pixel raster
  win <- as.owin(x)
  y$window <- summary.owin(win)

  y$fullgrid <- (rescue.rectangle(win)$type == "rectangle")

  y$units <- unitname(x)
  
  class(y) <- "summary.im"
  return(y)
}

print.summary.im <- function(x, ...) {
  verifyclass(x, "summary.im")
  cat(paste0(x$type, "-valued"), "pixel image", fill=TRUE)
  unitinfo <- summary(x$units)
  pluralunits <- unitinfo$plural
  sigdig <- 5
  di <- x$dim
  win <- x$window
  cat(di[1], "x", di[2], "pixel array (ny, nx)", fill=TRUE)
  cat("enclosing rectangle:",
      prange(signif(x$window$xrange, sigdig)),
      "x",
      prange(signif(x$window$yrange, sigdig)),
      unitinfo$plural,
      unitinfo$explain,
      fill=TRUE)
  cat("dimensions of each pixel:",
      signif(x$xstep, 3), "x", signif(x$ystep, 3),
      pluralunits,
      fill=TRUE)
  if(!is.null(explain <- unitinfo$explain))
    cat(paste(explain, "\n"))
  if(x$fullgrid) {
    cat("Image is", "defined on the",  "full rectangular", "grid", fill=TRUE)
    whatpart <- "Frame"
  } else {
    cat("Image is", "defined on", "a subset of", "the rectangular", "grid",
        fill=TRUE)
    whatpart <- "Subset"
  }
  cat(whatpart, "area =", win$area, "square", pluralunits, fill=TRUE)
  if(x$fullgrid) cat("Pixel values:\n") else
                 cat("Pixel values", "(inside window):", fill=TRUE)
  switch(x$type,
         integer=,
         real={
           cat("\trange =", prange(signif(x$range, sigdig)), fill=TRUE)
           cat("\tintegral =", signif(x$integral, sigdig), fill=TRUE)
           cat("\tmean =", signif(x$mean, sigdig), fill=TRUE)
         },
         factor={
           print(x$table)
         },
         complex={
           cat("\trange: Real",
               prange(signif(x$Re$range, sigdig)),
               "Imaginary",
               prange(signif(x$Im$range, sigdig)),
               fill=TRUE)
           cat("\tintegral =", signif(x$integral, sigdig), fill=TRUE)
           cat("\tmean =", signif(x$mean, sigdig), fill=TRUE)
         },
         {
           print(x$summary)
         })

  return(invisible(NULL))
}

print.im <- function(x, ...) {
  cat(paste0(x$type, "-valued"), "pixel image", fill=TRUE)
  if(x$type == "factor") {
    cat("factor levels:\n")
    print(levels(x))
  }
  unitinfo <- summary(unitname(x))
  di <- x$dim
  cat(di[1], "x", di[2], "pixel array (ny, nx)", fill=TRUE)
  cat("enclosing rectangle:",
      prange(signif(x$xrange, 5)),
      "x",
      prange(signif(x$yrange, 5)),
      unitinfo$plural,
      unitinfo$explain,
      fill=TRUE)
  return(invisible(NULL))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/summary.mppm.R"
#
# summary.mppm.R
#
# $Revision: 1.8 $  $Date: 2013/11/13 18:02:37 $
#


summary.mppm <- function(object, ..., brief=FALSE) {
  # y will be the summary 
  y <- object[c("Call", "Info", "Inter", "trend", "iformula",
                "npat", "maxlogpl")]
  y$brief <- brief

  Info  <- object$Info
  Inter <- object$Inter
  FIT   <- object$Fit$FIT
  moadf <- object$Fit$moadf

  y$Fit <- object$Fit[c("fitter", "use.gam", "fmla", "Vnamelist")]
  y$Fit$FIT <- summary(FIT)
  y$Fit$moadf <- list(nrow=nrow(moadf), colnames=colnames(moadf))
  
  ninteract    <- Inter$ninteract
  interaction  <- Inter$interaction
  iused        <- Inter$iused
  itags        <- Inter$itags
  processnames <- Inter$processes
  constant     <- Inter$constant
  trivial      <- Inter$trivial

  npat      <- y$npat
  iformula  <- y$iformula
  Vnamelist <- y$Fit$Vnamelist
  allVnames <- unlist(Vnamelist)
  poistags  <- itags[trivial]

#  rownames  <- y$Info$rownames
  
  switch(y$Fit$fitter,
         gam=,
         glm={
           y$coef <- co <- coef(FIT)
           systematic <- !(names(co) %in% c(allVnames, poistags))
           y$coef.syst <- co[systematic]
         })

  # model depends on covariates
  y$depends.covar <- Info$has.covar && (length(Info$used.cov.names) > 0)


  ### Interactions 
  # model is Poisson 
  y$poisson <- all(trivial[iused])
  # Determine how complicated the interactions are:
  # (1) is the interaction formula of the form ~ tag + tag + ... + tag
  isimple  <- identical(sort(variablesinformula(iformula)),
                        sort(termsinformula(iformula)))
  # (2) is it of the form ~tag 
  trivialformula <- (isimple && ninteract == 1)
  # (3) is it of the form ~tag where the interaction is the same in each row
  fixedinteraction <- trivialformula && constant
  
  ### Determine printing of interactions, accordingly ###
  iprint <- list()
  if(fixedinteraction) {    
    # exactly the same interaction for all patterns
    interaction <- interaction[1,1,drop=TRUE]
    fi.all <- fii(interaction, co, Vnamelist[[1]]) 
    iprint <- list("Interaction for all patterns"=fi.all)
    printeachrow <- FALSE
    toohard      <- FALSE
  } else if(trivialformula) {
    # same type of process for all patterns
    pname <-  unlist(processnames)[iused]
    iprint <- list("Interaction for each pattern" = pname)
    printeachrow <- TRUE
    toohard      <- FALSE
  } else if(isimple && all(constant)) {
    # several interactions involved, each of which is the same for all patterns
    iprint <- list("Interaction formula"=iformula,
                   "Interactions defined for each pattern"=NULL)
    for(j in (1:ninteract)[iused]) {
      name.j <- paste("Interaction", sQuote(itags[j]))
      int.j <- Inter$interaction[1,j,drop=TRUE]
      Vnames.j <- Vnamelist[[j]]
      fii.j <- fii(int.j, co, Vnames.j)
      extra.j <- list(fii.j)
      names(extra.j) <- name.j
      iprint <- append(iprint, extra.j)
    }
    printeachrow <- FALSE
    toohard      <- FALSE
  } else {
    # general case
    # determine which interaction(s) are active on each row
    active <- active.interactions(object)
    if(ninteract > 1 || !all(active)) 
      iprint <- list("Active interactions"=active)
    printeachrow <- TRUE
    toohard <- any(rowSums(active) > 1)
  }

  y$ikind <- list(
                  isimple           =isimple,
                  trivialformula    =trivialformula,
                  fixedinteraction  =fixedinteraction,
                  toohard           =toohard,
                  printeachrow      =printeachrow)

  if(toohard)
    iprint <- append(iprint,
                     list("(Sorry, cannot interpret fitted interactions)"))
  else if(printeachrow) {
    subs <- subfits(object, what="interactions")
    names(subs) <- paste("Interaction", 1:npat)
    iprint <- append(iprint, subs)
  }

  y$iprint <- iprint

  class(y) <- c("summary.mppm", class(list))
  return(y)
}


print.summary.mppm <- function(x, ..., brief=x$brief) {
  # NB: x is an object of class "summary.mppm"
  npat <- x$npat
  Inter <- x$Inter
  ninteract   <- Inter$ninteract
  interaction   <- Inter$interaction
  iused     <- Inter$iused
  itags   <- Inter$itags
  processnames   <- Inter$processes
  constant <- Inter$constant
  trivial  <- Inter$trivial
  iformula <- x$iformula

  FIT <- x$Fit$FIT
  Vnamelist <- x$Fit$Vnamelist
  allVnames <- unlist(Vnamelist)
  poistags <- itags[trivial]

#  rownames <- x$Info$rownames

  cat(paste("Point process model fitted to", x$npat, "point patterns\n"))
  cat(paste("Call:\n", x$Call$callstring, "\n"))
  cat(paste("Trend formula:", paste(x$trend, collapse=""), "\n"))
  switch(x$Fit$fitter,
         gam=,
         glm={
           cat("Fitted trend coefficients:\n")
           print(x$coef.syst)
           co <- coef(FIT)
         })

  if(!brief) {
    cat("All fitted coefficients:\n")
    print(co)
  }
    
  cat("\n")

  
  ### Print interaction information ###
  iprint <- x$iprint
  nama <- names(iprint)
  for(i in seq(length(iprint))) {
    nami <- nama[i]
    vali <- iprint[[i]]
    newlin <- !(inherits(vali, "formula") || is.character(vali))
    if(nami != "")
      cat(paste(nami, ":", if(newlin) "\n" else "\t", sep=""))
    if(!is.null(vali)) {
      if(inherits(vali, "fii")) {
        print(vali, tiny=brief)
      } else if(is.character(vali)) {
        cat(vali)
      } else print(vali)
    }
    cat("\n")
  }

  if(!brief) {
    cat("--- Gory details: ---\n")
    cat(paste("Combined data frame has", x$Fit$moadf$nrow, "rows\n"))
    print(FIT)
  }
  invisible(NULL)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/summary.ppm.R"
#
#    summary.ppm.R
#
#    summary() method for class "ppm"
#
#    $Revision: 1.72 $   $Date: 2014/11/11 03:09:00 $
#
#    summary.ppm()
#    print.summary.ppm()
#

summary.ppm <- local({
  
  covtype <- function(x) {
    if(is.im(x)) "im" else
    if(is.function(x)) "function" else
    if(is.owin(x)) "owin" else
    if(is.numeric(x) && length(x) == 1) "number" else
    if(is.factor(x)) "factor" else
    if(is.integer(x)) "integer" else
    if(is.numeric(x)) "numeric" else storage.mode(x)
  }
  
  xargs <- function(f) {
    ar <- names(formals(f))[-(1:2)]
    return(ar[ar != "..."])
  }

  summary.ppm <- function(object, ..., quick=FALSE) {
    verifyclass(object, "ppm")

    x <- object
    y <- list()
  
    #######  Extract main data components #########################

    QUAD <- object$Q
    DATA <- QUAD$data
    TREND <- x$trend

    INTERACT <- x$interaction
    if(is.null(INTERACT)) INTERACT <- Poisson()
  
    #######  Check version #########################
    
    mpl.ver <- versionstring.ppm(object)
    int.ver <- versionstring.interact(INTERACT)
    current <- versionstring.spatstat()

    virgin <- min(package_version(c(mpl.ver, int.ver)))
    
    y$antiquated <- antiquated <- (virgin <= package_version("1.5"))
    y$old        <- (virgin < majorminorversion(current))

    y$version    <- as.character(virgin)
    
    ####### Determine type of model ############################
  
    y$entries <- list()
    y$no.trend <- identical.formulae(TREND, NULL) ||
                  identical.formulae(TREND, ~1)
    y$trendvar <- trendvar <- variablesinformula(TREND)
    y$stationary <- y$no.trend || all(trendvar == "marks")

    y$poisson <- is.poisson.interact(INTERACT)

    y$marked <- is.marked.ppp(DATA)
    y$multitype <- is.multitype.ppp(DATA)
    y$marktype <- if(y$multitype) "multitype" else
                  if(y$marked) "marked" else "unmarked"

    if(y$marked) y$entries$marks <- marks(DATA)

    y$name <- paste(if(y$stationary) "Stationary " else "Nonstationary ",
                    if(y$poisson) {
                      if(y$multitype) "multitype "
                      else if(y$marked) "marked "
                      else ""
                    },
                    INTERACT$name,
                    sep="")

    ######  Fitting algorithm ########################################

    y$method <- x$method
  
    y$problems <- x$problems

    y$fitter <- if(!is.null(x$fitter)) x$fitter else "unknown"
    if(y$fitter %in% c("glm", "gam"))
      y$converged <- x$internal$glmfit$converged

    ######  Coefficients were changed after fit? #####################
  
    y$projected <- yproj <- identical(x$projected, TRUE)
    y$changedcoef <- y$projected || !is.null(x$coef.orig)

    y$valid <- valid.ppm(x, warn=FALSE)
      
    ######  Extract fitted model coefficients #########################

    y$entries$coef <- COEFS <- x$coef
    y$coef.orig <- x$coef.orig

    y$entries$Vnames <- Vnames <- x$internal$Vnames
    y$entries$IsOffset <- x$internal$IsOffset

    ###### Extract fitted interaction and summarise  #################
  
    FITIN <- fitin(x)
    y$interaction <- summary(FITIN)

    # Exit here if quick=TRUE
    
    if(identical(quick, TRUE)) {
      class(y) <- "summary.ppm"
      return(y)
    }

    ######  Does it have external covariates?  ####################

    # defaults
    y <- append(y,
                list(has.covars    = FALSE,
                     covnames      = character(0),
                     covars.used   = character(0),
                     uses.covars   = FALSE,
                     covars.are.df = FALSE,
                     expandable    = TRUE,
                     covar.type    = character(0),
                     covar.descrip = character(0),
                     has.funcs     = FALSE,
                     covfunargs    = NULL,
                     has.xargs     = FALSE,
                     xargmap       = NULL))

    if(!antiquated) {
      covars <- x$covariates
      y$has.covars <- hc <- !is.null(covars) && (length(covars) > 0)
      if(hc) {
        y$covnames <- names(covars)
        used <- (y$trendvar %in% names(covars))
        y$covars.used <- y$trendvar[used]
        y$uses.covars <- any(used)
        y$covars.are.df <- is.data.frame(covars)
        # describe covariates
        ctype <- unlist(lapply(covars, covtype))
        y$expandable <- all(ctype[used] %in%c("function", "number"))
        names(ctype) <- names(covars)
        y$covar.type <- ctype
        y$covar.descrip <- ctype
        # are there any functions?
        y$has.funcs <- any(isfun <- (ctype == "function"))
        # do covariates depend on additional arguments?
        if(y$has.funcs) {
          y$covfunargs <- x$covfunargs
          y$cfafitter <- attr(x$covfunargs, "fitter")
          funs <- covars[isfun]
          fdescrip <- function(f) {
            if(inherits(f, "distfun")) return("distfun")
            alist <- paste(names(formals(f)), collapse=", ")
            paste("function(", alist, ")", sep="")
          }
          y$covar.descrip[isfun] <- unlist(lapply(funs, fdescrip))
          # find any extra arguments (after args 1 & 2) explicitly named
          fargs <- lapply(funs, xargs)
          nxargs <- unlist(lapply(fargs, length))
          y$has.xargs <- any(nxargs > 0)
          if(y$has.xargs) {
            # identify which function arguments are fixed in the call
            fmap <- data.frame(Covariate=rep.int(names(funs), nxargs),
                               Argument=unlist(fargs))
            fmap$Given <- (fmap$Argument %in% names(y$covfunargs))
            y$xargmap <- fmap
          }
        }
      } 
    } else {
      # Antiquated format
      # Interpret the function call instead
      callexpr <- parse(text=x$call)
      callargs <- names(as.list(callexpr[[1]]))
      # Data frame of covariates was called 'data' in versions up to 1.4-x
      y$has.covars <- !is.null(callargs) && !is.na(pmatch("data", callargs))
      # conservative guess
      y$uses.covars <- y$has.covars
      y$covfunargs <- NULL
    }
    
    ######  Arguments in call ####################################
  
    y$args <- x[c("call", "correction", "rbord")]
  
    #######  Main data components #########################

    y$entries <- append(list(quad=QUAD,
                             data=DATA,
                             interaction=INTERACT),
                        y$entries)

    if(is.character(quick) && (quick == "entries"))
      return(y)
  
    ####### Summarise data ############################

    y$data <- summary(DATA, checkdup=FALSE)
    y$quad <- summary(QUAD, checkdup=FALSE)

    if(is.character(quick) && (quick == "no prediction"))
      return(y)
  
    ######  Trend component #########################

    y$trend <- list()

    y$trend$name <- if(y$poisson) "Intensity" else "Trend"

    y$trend$formula <- if(y$no.trend) NULL else TREND

    if(y$poisson && y$no.trend) {
      # uniform Poisson process
      y$trend$value <- exp(COEFS[[1]])
      y$trend$label <- switch(y$marktype,
                              unmarked="Uniform intensity",
                              multitype="Uniform intensity for each mark level",
                              marked="Uniform intensity in product space",
                              "")
    } else if(y$stationary) {
      # stationary
      switch(y$marktype,
             unmarked={
               # stationary non-poisson non-marked
               y$trend$label <- "First order term"
               y$trend$value <- c(beta=exp(COEFS[[1]]))
             },
             multitype={
               # stationary, multitype
               mrk <- marks(DATA)
               y$trend$label <-
                 if(y$poisson) "Intensities" else "First order terms"
               # Use predict.ppm to evaluate the fitted intensities
               lev <- factor(levels(mrk), levels=levels(mrk))
               nlev <- length(lev)
               marx <- list(x=rep.int(0, nlev), y=rep.int(0, nlev), marks=lev)
               betas <- predict(x, locations=marx, type="trend")
               names(betas) <- paste("beta_", as.character(lev), sep="")
               y$trend$value <- betas
             },
             marked={
               # stationary, marked
               y$trend$label <- "Fitted intensity coefficients"
               y$trend$value <- blankcoefnames(COEFS)
             })
    } else {
      # not stationary 
      # extract trend terms without trying to understand them much
      if(is.null(Vnames)) 
        trendbits <- COEFS
      else {
        agree <- outer(names(COEFS), Vnames, "==")
        whichbits <- apply(!agree, 1, all)
        trendbits <- COEFS[whichbits]
      }
      y$trend$label <- ngettext(length(trendbits),
                                "Fitted trend coefficient",
                                "Fitted trend coefficients")
      y$trend$value <- blankcoefnames(trendbits)
    }
  
    # ----- parameters with SE --------------------------

    if(is.character(quick) && (quick == "no variances"))
      return(y)

    if(length(COEFS) > 0) {
      # compute standard errors
      se <- x$internal$se
      if(is.null(se)) {
        vc <- vcov(x, matrix.action="warn")
        if(!is.null(vc)) {
          se <- if(is.matrix(vc)) sqrt(diag(vc)) else
                if(length(vc) == 1) sqrt(vc) else NULL
        }
      }
      if(!is.null(se)) {
        two <- qnorm(0.975)
        lo <- COEFS - two * se
        hi <- COEFS + two * se
        zval <- COEFS/se
        pval <- 2 * pnorm(abs(zval), lower.tail=FALSE)
        psig <- cut(pval, c(0,0.001, 0.01, 0.05, 1),
                    labels=c("***", "**", "*", "  "),
                    include.lowest=TRUE)
        # table of coefficient estimates with SE and 95% CI
        y$coefs.SE.CI <- data.frame(Estimate=COEFS, S.E.=se,
                                    CI95.lo=lo, CI95.hi=hi,
                                    Ztest=psig,
                                    Zval=zval)
      }
    }
  
    class(y) <- "summary.ppm"
    return(y)
  }
  
  summary.ppm
})


coef.summary.ppm <- function(object, ...) {
  object$coefs.SE.CI
}

print.summary.ppm <- function(x, ...) {

  if(x$old)
    warning("Model was fitted by an older version of spatstat")
  
  if(is.null(x$args)) {
    # this is the quick version
    splat(x$name)
    return(invisible(NULL))
  }

  # otherwise - full details
  splat("Point process model")
  fitter <- if(!is.null(x$fitter)) x$fitter else "unknown"
  methodchosen <-
    if(is.null(x$method))
      "unspecified method"
    else if(fitter == "exact") "maximum likelihood" else 
      switch(x$method,
             mpl={
               if(x$poisson) {
                 # Poisson process
                 "maximum likelihood (Berman-Turner approximation)"
               } else {
                 "maximum pseudolikelihood (Berman-Turner approximation)"
               } 
             },
             logi={
               if(!x$poisson) {
                 "maximum pseudolikelihood (logistic regression approximation)"
               } else {
                 # Poisson process
                 "maximum likelihood (logistic regression approximation)"
               } 
             },
             ho="Huang-Ogata method (approximate maximum likelihood)",
             paste("unrecognised method", sQuote(x$method)))
  splat("Fitting method:", methodchosen)
  howfitted <- switch(fitter,
                      exact= "analytically",
                      gam  = "using gam()",
                      glm  = "using glm()",
                      ho   = NULL,
                      paste("using unrecognised fitter", sQuote(fitter)))
  if(!is.null(howfitted)) splat("Model was fitted", howfitted)
  if(fitter %in% c("glm", "gam")) {
    if(x$converged) splat("Algorithm converged")
    else splat("*** Algorithm did not converge ***")
  }
  if(x$projected)
    splat("Fit was projected to obtain a valid point process model")

  cat("Call:\n")
  print(x$args$call)

  if(x$old) 
    splat("** Executed by old spatstat version", x$version, " **")
  
  splat("Edge correction:", dQuote(x$args$correction))
  if(x$args$correction == "border")
    splat("\t[border correction distance r =", x$args$rbord,"]")

  ruletextline()

  # print summary of quadrature scheme
  print(x$quad)
  
  ruletextline()
  splat("FITTED MODEL:")
  parbreak()

  # This bit is currently identical to print.ppm()
  # except for a bit more fanfare
  # and the inclusion of the 'gory details' bit
  
  notrend <-    x$no.trend
#  stationary <- x$stationary
  poisson <-    x$poisson
  markeddata <- x$marked
  multitype  <- x$multitype
        
#  markedpoisson <- poisson && markeddata

  # ----------- Print model type -------------------
        
  cat(x$name)
  cat("\n")

  if(markeddata) mrk <- x$entries$marks
  if(multitype) {
    splat("Possible marks:")
    cat(paste(levels(mrk)))
  }

  # ----- trend --------------------------

  parbreak()
  splat(paste0("---- ", x$trend$name, ": ----"))
  parbreak()

  if(!notrend) {
    splat("Log",
          if(poisson) "intensity:" else "trend:",
          pasteFormula(x$trend$formula))
    if(x$uses.covars) 
      splat("Model depends on external",
            ngettext(length(x$covars.used), "covariate", "covariates"),
            commasep(sQuote(x$covars.used)))
  }
  if(x$has.covars) {
    if(notrend || !x$uses.covars)
      splat("Model object contains external covariates")
    isdf <- identical(x$covars.are.df, TRUE)
    if(!is.null(cd <- x$covar.descrip)) {
      # print description of each covariate
      splat(paste0("Covariates provided",
                   if(isdf) " (in data frame)" else NULL,
                   ":"))
      namescd <- names(cd)
      for(i in seq_along(cd))
        splat(paste0("\t", namescd[i], ": ", cd[i]))
    }
    if(!is.null(cfa <- x$covfunargs) && length(cfa) > 0) {
      splat("Covariate function arguments (covfunargs) provided:")
      namescfa <- names(cfa)
      for(i in seq_along(cfa)) {
        cat(paste(namescfa[i], "= "))
        cfai <- cfa[[i]]
        if(is.numeric(cfai) && length(cfai) == 1) {
          cat(paste(cfai, "\n"))
        } else print(cfa[[i]])
      }
    }
  }

  parbreak()
  splat(paste0(x$trend$label, ":"))
  
  tv <- x$trend$value
  if(!is.list(tv))
    print(tv)
  else 
    for(i in seq_along(tv))
      print(tv[[i]])

  # table of coefficient estimates with SE and 95% CI
  if(!is.null(cose <- x$coefs.SE.CI)) {
    cat("\n")
    print(cose)
  }
  
  # ---- Interaction ----------------------------

  
  if(!poisson) {
    parbreak()
    splat(" ---- Interaction: -----")
    parbreak()
    print(x$interaction)
  }

  ####### Gory details ###################################
  parbreak()
  splat("----------- gory details -----")
  parbreak()
  COEFS <- x$entries$coef
  
  splat("Fitted regular parameters (theta):")
  print(COEFS)

  parbreak()
  splat("Fitted exp(theta):")
  print(exp(unlist(COEFS)))

  ##### Warnings issued #######

  probs <- x$problems
  if(!is.null(probs) && is.list(probs) && (length(probs) > 0)) 
    lapply(probs,
           function(a) {
             if(is.list(a) && !is.null(p <- a$print))
               cat(paste("Problem:\n", p, "\n\n"))
           })

  vali <- x$valid
  if(identical(vali, FALSE) && waxlyrical("errors")) {
    parbreak()
    splat("***",
          "Model is not valid",
          "***\n***",
          "Interaction parameters are outside valid range",
          "***")
  } else if(is.na(vali) && waxlyrical("extras")) {
    parbreak()
    splat("[Validity of model could not be checked]")
  }
  
  return(invisible(NULL))
}

no.trend.ppm <- function(x) {
  summary.ppm(x, quick=TRUE)$no.trend
}

is.stationary <- function(x) {
  UseMethod("is.stationary")
}

is.poisson <- function(x) {
  UseMethod("is.poisson")
}

is.stationary.ppm <- function(x) {
  TREND <- x$trend
  if(is.null(TREND) || identical.formulae(TREND, ~1))
    return(TRUE)
  if(all(variablesinformula(TREND) == "marks"))
    return(TRUE)
  return(FALSE)
}

is.poisson.ppm <- function(x) {
  stopifnot(is.ppm(x))
  y <- x$interaction
  if(is.null(y)) y <- Poisson()
  is.poisson.interact(y)
}

is.marked.ppm <- function(X, ...) {
  summary.ppm(X, quick=TRUE)$marked
}

is.multitype.ppm <- function(X, ...) {
  summary.ppm(X, quick=TRUE)$multitype
}

is.expandable.ppm <- function(x) {
  return(identical(summary(x, quick="entries")$expandable, TRUE))
}

blankcoefnames <- function(x) {
  # remove name labels from ppm coefficients
  # First decide whether there are 'labels within labels'
  unlabelled <- unlist(lapply(x,
                              function(z) { is.null(names(z)) } ))
  if(all(unlabelled))
    value <- unlist(x)
  else {
    value <- list()
    for(i in seq_along(x))
      value[[i]] <- if(unlabelled[i]) unlist(x[i]) else x[[i]]
  }
  return(value)
} 
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/summary.quad.R"
#
# summary.quad.R
#
#  summary() method for class "quad"
#
#  $Revision: 1.7 $ $Date: 2014/05/08 10:29:25 $
#
summary.quad <- function(object, ..., checkdup=FALSE) {
  verifyclass(object, "quad")
  s <- list(
       data  = summary.ppp(object$data, checkdup=checkdup),
       dummy = summary.ppp(object$dummy, checkdup=checkdup),
       param = object$param)
  doit <- function(ww) {
    if(length(ww) > 0) 
      return(list(range=range(ww), sum=sum(ww)))
    else
      return(NULL)
  }
  w <- object$w
  Z <- is.data(object)
  s$w <- list(all=doit(w), data=doit(w[Z]), dummy=doit(w[!Z]))
  class(s) <- "summary.quad"
  return(s)
}

print.summary.quad <- local({

  summariseweights <- function(ww, blah, dp=3) {
    cat(paste(blah, ":\n\t", sep=""))
    if(is.null(ww)) {
      cat("(None)\n")
      return()
    }
    splat(paste0("range: ",
              "[",
              paste(signif(ww$range, digits=dp), collapse=", "),
              "]\t",
              "total: ",
              signif(ww$sum, digits=dp)))
  }

  print.summary.quad <- function(x, ..., dp=3) {
    cat("Quadrature scheme = data + dummy + weights\n")
    pa <- x$param
    if(is.null(pa))
      cat("created by an unknown function.\n")
    cat("Data pattern:\n")
    print(x$data, dp=dp)
    
    cat("\nDummy quadrature points:\n")
    ## How they were computed
    if(!is.null(pa)) {
      dumpar <- pa$dummy
      if(is.null(dumpar))
        cat("(provided manually)\n")
      else if(!is.null(nd <- dumpar$nd)) {
        splat(paste0("(",
                     if(dumpar$random) "stratified random points in " else NULL,
                     nd[1], " x ", nd[2], " ",
                     if(!dumpar$quasi) "grid" else
                     paste(" =", prod(nd), "quasirandom points"),
                     ", plus 4 corner points)"))
      } else
      cat("(rule for creating dummy points not understood)")
    }
    ## Description of them
    print(x$dummy, dp=dp)

    cat("\nQuadrature weights:\n")
    ## How they were computed
    if(!is.null(pa)) {
      wpar <- pa$weight
      if(is.null(wpar))
        cat("(values provided manually)\n")
      else if(!is.null(wpar$method)) {
        if(wpar$method=="grid") {
          cat(paste("(counting weights based on",
                    wpar$ntile[1], "x", wpar$ntile[2],
                    "array of rectangular tiles)\n"))
        } else if(wpar$method=="dirichlet") {
          cat(paste("(Dirichlet tile areas, computed",
                    if(wpar$exact) "exactly" else "by pixel approximation",
                    ")\n"))
        } else
        cat("(rule for creating dummy points not understood)\n")
      }
    }
    summariseweights(x$w$all, "All weights", dp)
    summariseweights(x$w$data, "Weights on data points", dp)
    summariseweights(x$w$dummy, "Weights on dummy points", dp)

    return(invisible(NULL))
  }

  print.summary.quad
})

    
print.quad <- function(x, ...) {
  cat("Quadrature scheme\n")
  splat(paste(x$data$n, "data points, ", x$dummy$n, "dummy points"))
  cat(paste("Total weight ", sum(x$w), "\n"))
  return(invisible(NULL))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/superimpose.R"
# superimpose.R
#
# $Revision: 1.28 $ $Date: 2014/07/21 06:40:11 $
#
#
############################# 

superimpose <- function(...) {
  # remove any NULL arguments
  arglist <- list(...)
  if(any(isnull <- sapply(arglist, is.null)))
    return(do.call("superimpose", arglist[!isnull]))
  UseMethod("superimpose")
}

superimpose.default <- function(...) {
  argh <- list(...)
  if(any(sapply(argh, is.lpp)) || any(sapply(argh, inherits, what="linnet")))
    return(superimpose.lpp(...))
  return(superimpose.ppp(...))
}

superimpose.ppp <- function(..., W=NULL, check=TRUE) {
  arglist <- list(...)
  # Check that all "..." arguments have x, y coordinates
  hasxy <- unlist(lapply(arglist, checkfields, L=c("x", "y")))
  if(!all(hasxy)) {
    nbad <- sum(bad <- !hasxy)
    stop(paste(ngettext(nbad, "Argument", "Arguments"),
               commasep(which(bad)),
               ngettext(nbad, "does not", "do not"),
               "have components x and y"))
  }
  
  # concatenate lists of (x,y) coordinates
  XY <- do.call("concatxy", arglist)
  needcheck <- TRUE

  # determine whether there is any window information
  if(!is.owin(W)) {
    # we have to compute the final window
    WXY <- NULL
    Wppp <- NULL
    if(any(isppp <- unlist(lapply(arglist, is.ppp)))) {
      # extract windows from ppp objects
      wins <- unname(lapply(arglist[isppp], as.owin))
      # take union
      Wppp <- if(length(wins) == 1) wins[[1]] else do.call(union.owin, wins)
    } 
    if(is.function(W)) {
      # W is a function like bounding.box.xy or ripras
      # Apply function to the x,y coordinates; it should return an owin
      WXY <- W(XY)
      if(!is.owin(WXY))
        stop("Function W did not return an owin object")
    }
    if(is.character(W)) {
      # character string identifies a function
      pW <- pmatch(W, c("convex", "rectangle", "bbox", "none"))
      if(is.na(pW))
        stop(paste("Unrecognised option W=", sQuote(W)))
      WXY <- switch(pW,
                    convex=ripras(XY),
                    rectangle=ripras(XY, shape="rectangle"),
                    bbox=boundingbox(XY),
                    none=NULL)
      # in these cases we don't need to verify that the points are inside.
      needcheck <- !is.null(WXY)
    }
    if(is.null(WXY) && is.null(Wppp)) {
      # no window information
      return(XY)
    }
    W <- union.owin(WXY, Wppp)
  }
  # extract the marks if any
  nobj <- sapply(arglist, function(x) { length(x$x) })
  marx  <- superimposeMarks(arglist, nobj)
  #
  ppp(XY$x, XY$y, window=W, marks=marx, check=check & needcheck)
}

superimpose.psp <- function(..., W=NULL, check=TRUE) {
  # superimpose any number of line segment patterns
  arglist <- list(...)
  misscheck <- missing(check)

  if(!all(sapply(arglist, is.psp)))
    stop("Patterns to be superimposed must all be psp objects")

  # extract segment coordinates
  matlist <- lapply(lapply(arglist, getElement, name="ends"),
                    asNumericMatrix)
  
  # tack them together
  mat <- do.call("rbind", matlist)

  # determine whether there is any window information
  needcheck <- FALSE
  if(!is.owin(W)) {
    # we have to compute the final window
    WXY <- NULL
#    Wpsp <- NULL
    if(any(ispsp <- unlist(lapply(arglist, is.psp)))) {
      # extract windows from psp objects
      wins <- unname(lapply(arglist[ispsp], as.owin))
      # take union
      Wppp <- if(length(wins) == 1) wins[[1]] else do.call(union.owin, wins)
    }
    if(is.function(W) || is.character(W)) {
      # guess window from x, y coordinates
      XY <- list(x=cbind(mat[,1], mat[,3]),
                 y=cbind(mat[,2], mat[,4]))
      if(is.function(W)) {
        # W is a function like bounding.box.xy or ripras
        # Apply function to the x,y coordinates; it should return an owin
        WXY <- W(XY)
        if(!is.owin(WXY))
          stop("Function W did not return an owin object")
      }
      if(is.character(W)) {
        # character string identifies a function
        pW <- pmatch(W, c("convex", "rectangle", "bbox", "none"))
        if(is.na(pW))
          stop(paste("Unrecognised option W=", sQuote(W)))
        WXY <- switch(pW,
                      convex=ripras(XY),
                      rectangle=ripras(XY, shape="rectangle"),
                      bbox=boundingbox(XY),
                      none=NULL)
      # in these cases we don't need to verify that the points are inside.
        needcheck <- !is.null(WXY)
      }
    }
    W <- union.owin(WXY, Wppp)
  }
  
  # extract marks, if any
  nobj <- sapply(arglist, nsegments)
  marx <- superimposeMarks(arglist, nobj)

  if(misscheck && !needcheck) check <- FALSE
  return(as.psp(mat, window=W, marks=marx, check=check))
}

superimposeMarks <- function(arglist, nobj) {
  # combine marks from the objects in the argument list
  marxlist <- lapply(arglist, marks)
  marx <- do.call(markappend, unname(marxlist))
  nama <- names(arglist)
  if(length(nama) == length(arglist) && all(nzchar(nama))) {
    # arguments are named: use names as (extra) marks
    newmarx <- factor(rep.int(nama, nobj))
    marx <- markcbind(marx, newmarx)
    if(ncol(marx) == 2) {
      ## component marks were not named: call them 'origMarks'
      colnames(marx) <- c("origMarks", "pattern")
    } else colnames(marx)[ncol(marx)] <- "pattern"
  }
  return(marx)
}

#==+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

  # This function is now deprecated.
superimposePSP <-
  function(..., W=NULL, check=TRUE)
{
  .Deprecated("superimpose","spatstat")
  
  # superimpose any number of line segment patterns
  arglist <- list(...)

  nargue <- length(arglist)
  if(nargue == 0)
    stop("No line segment patterns given")
  
  # catch possible abuses
  if(is.null(W) && any(suspicious <- (names(arglist) == "window"))) {
    id <- min(which(suspicious))
    Win <- arglist[[id]]
    if(is.owin(Win) || is.null(Win)) {
      W <- Win
      arglist <- arglist[-id]
      nargue <- length(arglist)
    }
  }

  # unpack a list
  if(nargue == 1) {
    X <- arglist[[1]]
    if(!inherits(X, "psp") && inherits(X, "list"))
      arglist <- X
  }

  isnull <- unlist(lapply(arglist, is.null))
  arglist <- arglist[!isnull]
  
  if(!all(unlist(lapply(arglist, is.psp))))
    stop("Some of the arguments are not psp objects")
  
  # extract segment coordinates
  matlist <- lapply(arglist, function(x) { as.matrix(x$ends) })
  # tack them together
  mat <- do.call("rbind", matlist)

  # extract marks if any
  marxlist <- lapply(arglist, marks)

  # check on compatibility of marks
  mkfmt <- sapply(marxlist,markformat)
  if(length(unique(mkfmt))>1)
	stop(paste("Marks of some patterns are of different format\n",
                   "  from those of other patterns.\n",sep=""))
  mkfmt <- mkfmt[1]
  if(mkfmt=="dataframe") {
	mcnms <- lapply(marxlist,names)
	cdim  <- sapply(mcnms,length)
	OK    <- length(unique(cdim)) == 1
	if(OK) {
		allInOne <- sapply(mcnms,paste,collapse="")
		OK <- length(unique(allInOne)) == 1
		if(!OK) stop("Data frames of marks have different names.\n")
	} else stop("Data frames of marks have different column dimensions.\n")
  }
 
  # combine the marks
  marx <- switch(mkfmt,
                 none = NULL,
                 vector = {
                   marxlist <- lapply(marxlist,
                                      function(x){as.data.frame.vector(x,nm="v1")})
                   do.call("rbind", marxlist)[,1]
                 },
                 dataframe = do.call("rbind", marxlist))

  # determine window
  if(!is.null(W))
    W <- as.owin(W)
  else {
    # extract windows from psp objects
    Wlist <- lapply(arglist, as.owin)
    # take the union of all the windows
    W <- NULL
    for(i in seq_along(Wlist))
      W <- union.owin(W, Wlist[[i]])
  }

  return(as.psp(mat, window=W, marks=marx, check=check))
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/symbolmap.R"
##
## symbolmap.R
##
##   $Revision: 1.21 $  $Date: 2014/11/10 11:18:52 $
##

symbolmap <- local({

  known.unknowns <- c("shape", "pch", "chars",
                      "size", "cex",
                      "col", "cols", "fg", "bg",
                      "lty", "lwd", "border", "fill",
                      "etch")
  
  symbolmap <- function(..., range=NULL, inputs=NULL) {
    if(!is.null(range) && !is.null(inputs))
      stop("Arguments range and inputs are incompatible")
    ## graphics parameters
    parlist <- list(...)
    ## remove unrecognised parameters and NULL values 
    if(length(parlist) > 0) {
      ok <- names(parlist) %in% known.unknowns
      ok <- ok & !unlist(lapply(parlist, is.null))
      parlist <- parlist[ok]
    }
    got.pars <- (length(parlist) > 0)
    parnames <- names(parlist)
    type <- if(is.null(inputs) && is.null(range)) "constant" else
            if(!is.null(inputs)) "discrete" else "continuous"
    if(got.pars) {
      ## validate parameters
      if(is.null(parnames) || !all(nzchar(parnames)))
        stop("All graphics parameters must have names")
          atomic <- unlist(lapply(parlist, is.atomic))
      functions <- unlist(lapply(parlist, is.function))
      lengths <- unlist(lapply(parlist, length))
      constants <- atomic & (lengths == 1)
      if(any(bad <- !(constants | functions))) {
        if(type == "discrete" && any(repairable <- atomic[bad])) {
          ## recycle data to desired length
          parlist[repairable] <- lapply(parlist[repairable],
                                        function(z, n) rep.int(z, n)[1:n],
                                        n=length(inputs))
          bad[repairable] <- FALSE
        }
        nbad <- sum(bad)
        if(nbad > 0) 
          stop(paste(ngettext(nbad, "Argument", "Arguments"),
                     commasep(sQuote(parnames[bad])),
                     ngettext(nbad, "is neither a function nor a constant",
                              "are neither functions nor constants")))
      }
      if(type == "constant" && any(functions))
        type <- "continuous"
    } 
    switch(type,
           constant ={
             ## set of constant graphics parameters defining a single symbol
             stuff <- list(type=type, parlist=parlist)
             ConstantValue <- as.data.frame(parlist, stringsAsFactors=FALSE)
             f <- function(x) ConstantValue
           },
           discrete = {
             ## finite set of inputs mapped to symbols
             stuff <- list(type=type, inputs=inputs, parlist=parlist)
             f <- function(x) ApplyDiscreteSymbolMap(x, stuff)
           },
           continuous = {
             got.shape <- "shape" %in% parnames
             got.size <- "size" %in% parnames
             got.cha <- any(c("pch", "chars") %in% parnames)
             ## interval of real line (etc) mapped to symbols or characters
             if(!got.cha) {
               ## mapped to symbols
               if(!got.shape)
                 parlist$shape <- "circles"
               if(!got.size)
                 stop("Parameter 'size' is missing")
             }
             rangetype <- if(is.null(range)) "numeric" else
                          if(inherits(range, "POSIXt")) "datetime" else
                          if(inherits(range, "Date")) "date" else
                          if(is.numeric(range)) "numeric" else "unknown"
             stuff <- list(type=type, range=range, rangetype=rangetype,
                           parlist=parlist)
             f <- function(x) ApplyContinuousSymbolMap(x, stuff)
           })
    attr(f, "stuff") <- stuff
    class(f) <- c("symbolmap", class(f))
    f
  }

  MapDiscrete <- function(f, x, i) {
    if(is.function(f)) f(x) else f[i]
  }
  
  MapContinuous <- function(f, x) {
    if(is.function(f)) f(x) else rep.int(f, length(x))
  }

  ApplyContinuousSymbolMap <- function(x, stuff) {
    with(stuff, {
      y <- as.data.frame(lapply(parlist, MapContinuous, x=x),
                         stringsAsFactors=FALSE)
      return(y)
    })
  }
  
  ApplyDiscreteSymbolMap <- function(x, stuff) {
    with(stuff, {
      ii <- match(x, inputs)
      if(any(is.na(ii)))
        stop("Some values do not belong to the domain of the symbol map")
      y <- as.data.frame(lapply(parlist, MapDiscrete, x=x, i=ii),
                         stringsAsFactors=FALSE)
      return(y)
    })
  }
  symbolmap
})

symbolmaptype <- function(x) { attr(x, "stuff")$type }

update.symbolmap <- function(object, ...) {
  y <- attr(object, "stuff")
  oldargs <- append(y[["parlist"]], y[c("inputs", "range")])
  do.call("symbolmap", resolve.defaults(list(...), oldargs))
}

print.symbolmap <- function(x, ...) {
  with(attr(x, "stuff"), {
    switch(type,
           constant = {
             if(length(parlist) == 0) {
               cat("Symbol map", "with no parameters", fill=TRUE)
             } else {
               cat("Symbol map", "with constant values", fill=TRUE)
             }
           },
           discrete = {
             cat("Symbol map", "for discrete inputs:", fill=TRUE)
             print(inputs)
           },
           continuous = {
             cat("Symbol map", "for",
                 switch(rangetype,
                        numeric="real numbers",
                        date = "dates",
                        datetime = "date/time values",
                        unknown = "unrecognised data"),
                 if(!is.null(range)) paste("in", prange(range)) else NULL,
                 fill=TRUE)
           })
    if(length(parlist) > 0) {
      for(i in seq_along(parlist)) {
        cat(paste0(names(parlist)[i], ": "))
        pari <- parlist[[i]]
        if(!is.function(pari) && length(pari) == 1)
          cat(pari, fill=TRUE) else print(pari)
      }
    }
    return(invisible(NULL))
  })
}

## Function which actually plots the symbols.
## Called by plot.ppp and plot.symbolmap
## Returns maximum size of symbols

invoke.symbolmap <- local({

  ## plot points, handling various arguments
  do.points <- function(x, y, ...,
                        cex=size, size=NULL, 
                        col=cols, pch=chars, cols=NULL, chars=NULL,
                        lwd=1, etch=FALSE, 
                        do.plot=TRUE) {
    if(do.plot) {
      if(length(cex) == 0) cex <- 1
      if(length(col) == 0) col <- par("col")
      if(length(pch) == 0) pch <- 1
      if(length(lwd) == 0) lwd <- 1
      n <- length(x)
      if(length(cex) == 1) cex <- rep(cex, n)
      if(length(col) == 1) col <- rep(col, n)
      if(length(pch) == 1) pch <- rep(pch, 1)
      if(length(lwd) == 1) lwd <- rep(lwd, n)
      if(length(etch) == 1) etch <- rep(etch, n)
      ## infer which arguments are parallelised
      other <- append(list(...), list(cex=cex, pch=pch))
      isvec <- (unlist(lapply(other, length)) == n)
      other.fixed <- other[!isvec]
      other.vec   <- other[isvec]
      ##
      if(any(i <- as.logical(etch))) {
        anti.col <- complementarycolour(col)
        anti.lwd <- if(is.numeric(etch)) etch else 2 * lwd
        do.call.matched("points.default",
                        resolve.defaults(list(x=x[i], y=y[i]),
                                         other.fixed,
                                         lapply(other.vec, "[", i=i),
                                         list(col=anti.col[i],
                                              lwd=anti.lwd[i])),
                        extrargs=c("col", "pch", "type", "bg",
                                   "cex", "lwd", "lty"))
      }
      do.call.matched("points.default",
                    resolve.defaults(list(x=x, y=y),
                                     other,
                                     list(col=col, lwd=lwd)),
                    extrargs=c("col", "pch", "type", "bg", "cex", "lwd", "lty"))
    }
    return(max(cex %orifnull% 1))
  }
  ## plot symbols likewise
  do.symbols <- function(x, y, ..., 
                         shape,
                         size=cex, cex=NULL,
                         fg=col, col=cols, cols=NULL,
                         lwd=1, etch=FALSE, do.plot=TRUE) {
    if(do.plot) {
      ## zap tiny sizes
      tiny <- (size < (max(size)/1000))
      size[tiny] <- 0
      ## collect arguments
      n <- length(x)
      if(length(lwd) == 1) lwd <- rep(lwd, n)
      if(length(etch) == 1) etch <- rep(etch, n)
      if(length(fg) == 0) fg <- rep(par("col"), n) else
      if(length(fg) == 1) fg <- rep(fg, n)
      other <- resolve.defaults(list(...),
                                list(add=TRUE, inches=FALSE))
      ## infer which arguments are parallelised
      isvec <- (unlist(lapply(other, length)) == n)
      other.fixed <- other[!isvec]
      other.vec   <- other[isvec]
      ##
      if(any(as.logical(etch))) {
        anti.fg <- complementarycolour(fg)
        anti.lwd <- if(is.numeric(etch)) etch else 2 * lwd
      }
      ## plot
      if(any(i <- (shape == "circles") & as.logical(etch))) 
        do.call.matched("symbols",
                        c(list(x=x[i], y=y[i], circles=size[i]),
                          other.fixed,
                          lapply(other.vec, "[", i=i),
                          list(lwd=anti.lwd[i], fg=anti.fg[i])),
                        extrargs=c("lwd", "lty"))
      if(any(i <- (shape == "circles")))
        do.call.matched("symbols",
                        c(list(x=x[i], y=y[i], circles=size[i]),
                          other.fixed,
                          lapply(other.vec, "[", i=i),
                          list(lwd=lwd[i], fg=fg[i])),
                        extrargs=c("lwd", "lty"))
      if(any(i <- (shape == "squares") & as.logical(etch)))
        do.call.matched("symbols",
                        c(list(x=x[i], y=y[i], squares=size[i]),
                          other.fixed,
                          lapply(other.vec, "[", i=i),
                          list(lwd=anti.lwd[i], fg=anti.fg[i])),
                        extrargs=c("lwd", "lty"))
      if(any(i <- (shape == "squares"))) 
        do.call.matched("symbols",
                        c(list(x=x[i], y=y[i], squares=size[i]),
                          other.fixed,
                          lapply(other.vec, "[", i=i),
                          list(lwd=lwd[i], fg=fg[i])),
                        extrargs=c("lwd", "lty"))
    }
    return(max(size * ifelse(shape == "circles", 2, 1)))
  }

  ## main function
  invoke.symbolmap <- function(map, values, x, y=NULL, ...,
                                 add=FALSE, do.plot=TRUE,
                                 started = add && do.plot) {
    if(!inherits(map, "symbolmap"))
      stop("map should be an object of class 'symbolmap'")
    ## function will return maximum size of symbols plotted.
    maxsize <- 0
    if(do.plot) {
      xy <- xy.coords(x, y)
      x <- xy$x
      y <- xy$y
      if(!add) plot(x, y, type="n", ...)
    }
    force(values)
    g <- map(values)
    parnames <- colnames(g)
    if(do.plot) {
      xydf <- data.frame(x=x, y=y)
      if(nrow(xydf) == 0)
        return(invisible(maxsize))
      g <- if(prod(dim(g)) == 0) xydf else 
           do.call("data.frame",
                   c(as.list(g), as.list(xydf), list(stringsAsFactors=FALSE)))
    }
    n <- nrow(g)
    ## figure out which function does the graphics job
    need.points <- any(c("pch", "chars") %in% parnames)
    need.symbols <- "shape" %in% parnames
    if(need.symbols && need.points) {
      worker <- with(g, ifelse(!is.na(shape), "symbols", "points"))
    } else if(need.symbols) {
      worker <- rep.int("symbols", n)
    } else {
      worker <- rep.int("points", n)
    } 
    ## split data according to graphics function involved
    z <- split(g, factor(worker))
    ## display using 'pch'
    zpoints <- z[["points"]]
    if(!is.null(zpoints) && nrow(zpoints) > 0) {
      ms <- do.call("do.points",
                    resolve.defaults(as.list(zpoints),
                                     list(...),
                                     list(do.plot=do.plot)))
      ## value is max(cex)
      ## guess size of one character
      charsize <- if(started) max(par('cxy')) else
                    max(sidelengths(boundingbox(x,y))/40)
      maxsize <- max(maxsize, charsize * ms)
    }
    ## display using 'symbols'
    zsymbols <- z[["symbols"]]
    if(!is.null(zsymbols) && nrow(zsymbols) > 0) {
      ms <- do.call("do.symbols",
                    resolve.defaults(as.list(zsymbols),
                                     list(...),
                                     list(do.plot=do.plot)))
      ## ms value is max physical size.
      maxsize <- max(maxsize, ms)
    }
    return(invisible(maxsize))
  }

  invoke.symbolmap
})


## Display the symbol map itself (`legend' style)

plot.symbolmap <- local({

  # recognised additional arguments to axis()
  
  axisparams <- c("cex", 
                  "cex.axis", "cex.lab",
                  "col.axis", "col.lab",
                  "font.axis", "font.lab",
                  "las", "mgp", "xaxp", "yaxp",
                  "tck", "tcl", "xpd")

  plot.symbolmap <- function(x, ..., main,
                               xlim=NULL, ylim=NULL,
                               vertical=FALSE,
                               side=c("bottom", "left", "top", "right"),
                               annotate=TRUE, labelmap=NULL, add=FALSE) {
    if(missing(main))
      main <- short.deparse(substitute(x))
    miss.side <- missing(side)
    side <- match.arg(side)

    type <- symbolmaptype(x)
    map <- x
    stuff <- attr(map, "stuff")

    if(type == "constant" && length(stuff$parlist) == 0)
      return(invisible(NULL))

    if(is.null(labelmap)) {
      labelmap <- function(x) x
    } else if(type == "continuous" &&
              is.numeric(labelmap) && length(labelmap) == 1) {
      labscal <- labelmap
      labelmap <- function(x) { x * labscal }
    } else stopifnot(is.function(labelmap))

    ## determine the 'example' input values and their graphical representations
    switch(type,
           constant = {
             vv <- NULL
           },
           continuous = {
             ra <- stuff$range
             if(is.null(ra))
               stop("Cannot plot symbolmap with an infinite range")
             vv <- prettyinside(ra)
             if(is.numeric(vv))
               vv <- signif(vv, 4)
           },
           discrete = {
             vv <- prettydiscrete(stuff$inputs)
             if(vertical) vv <- rev(vv)
           })
    nn <- length(vv)
##    gg <- map(vv)
    ll <- paste(labelmap(vv))
    
    ## determine position of plot and symbols
    if(add) {
      ## x and y limits must respect existing plot space
      usr <- par('usr')
      if(is.null(xlim)) xlim <- usr[1:2]
      if(is.null(ylim)) ylim <- usr[3:4]
    } else {
      ## create new plot
      zz <- c(0, 1)
      if(is.null(xlim) && is.null(ylim)) {
        if(vertical) {
          xlim <- zz
          ylim <- length(vv) * zz
        } else {
          xlim <- length(vv) * zz
          ylim <- zz
        }
      } else if(is.null(ylim)) {
        ylim <- zz
      } else if(is.null(xlim)) {
        xlim <- zz
      }
    }

    ## .......... initialise plot ...............................
    if(!add)
      do.call.matched("plot.default",
                      resolve.defaults(list(x=xlim, y=ylim,
                                            type="n", main=main,
                                            axes=FALSE, xlab="", ylab="",
                                            asp=1.0),
                                       list(...)))
    ## maximum symbol diameter
    maxdiam <- invoke.symbolmap(map, vv, do.plot=FALSE, started=TRUE)

    ## .......... plot symbols ....................
    if(type == "constant") {
      xp <- mean(xlim)
      yp <- mean(ylim)
    } else if(vertical) {
      ## vertical arrangement
      xp <- rep(mean(xlim), nn)
      vskip <- 1.1 * max(maxdiam, 3 * max(strheight(labelmap(vv))))
      if(diff(ylim) > nn * vskip) {
        yp <- (1:nn) * vskip
        yp <- yp - mean(yp) + mean(ylim)
      } else {
        z <- seq(ylim[1], ylim[2], length=nn+1)
        yp <- z[-1] - diff(z)/2
      }
    } else {
      ## horizontal arrangement
      yp <- rep(mean(ylim), nn)
      hskip <- 1.1 * max(maxdiam, max(strwidth(labelmap(vv))))
      if(diff(xlim) > nn * hskip) {
        xp <- (1:nn) * hskip
        xp <- xp - mean(xp) + mean(xlim)
      } else {
        z <- seq(xlim[1], xlim[2], length=nn+1)
        xp <- z[-1] - diff(z)/2
      }
    }
    invoke.symbolmap(map, vv, xp, yp, ..., add=TRUE)

    ## ................. draw annotation ..................
    if(annotate && length(ll) > 0) {
      if(vertical) {
        ## default axis position is to the right 
        if(miss.side) side <- "right"
        sidecode <- match(side, c("bottom", "left", "top", "right"))
        if(!(sidecode %in% c(2,4)))
          warning(paste("side =", sQuote(side),
                        "is not consistent with vertical orientation"))
        pos <- c(ylim[1], xlim[1], ylim[2], xlim[2])[sidecode]
        ## draw axis
        do.call.matched("axis",
                        resolve.defaults(list(...),
                                         list(side=sidecode, pos=pos, at=yp,
                                              labels=ll, tick=FALSE, las=1)),
                        extrargs=axisparams)
      } else {
        ## default axis position is below 
        if(miss.side) side <- "bottom"
        sidecode <- match(side, c("bottom", "left", "top", "right"))
        if(!(sidecode %in% c(1,3)))
          warning(paste("side =", sQuote(side),
                        "is not consistent with horizontal orientation"))
        pos <- c(ylim[1], xlim[1], ylim[2], xlim[2])[sidecode]
        ## draw axis
        do.call.matched("axis",
                        resolve.defaults(list(...),
                                         list(side = sidecode, pos = pos,
                                              at = xp, labels=ll, tick=FALSE)),
                        extrargs=axisparams)
      } 
    }
    return(invisible(NULL))
  }

  plot.symbolmap
})

plan.legend.layout <- function(B, 
                               ..., 
                               side=c("bottom", "left", "top", "right"),
                               sep=NULL,
                               size=NULL,
                               sep.frac=0.05,
                               size.frac=0.05,
                               started=FALSE,
                               map=NULL) {
  ## Determine size and position of a box containing legend or symbolmap
  ## attached to a plot in region 'B'.
  ##   sep, size are absolute distances;
  ##   sep.frac, size.frac are fractions of the maximum sidelength of B.
  side <- match.arg(side)
  B <- as.rectangle(B)
  Bsize <- max(sidelengths(B))
  if(is.null(size)) {
    size <- size.frac * Bsize
  } else {
    check.1.real(size)
    stopifnot(size > 0)
  }
  if(is.null(sep)) {
    sep <- sep.frac * Bsize
  } else {
    check.1.real(sep)
    stopifnot(sep > 0)
  }
  if(is.null(map) || !inherits(map, "symbolmap")) {
    textlength <- 8
  } else {
    vv <- with(attr(map, "stuff"),
               if(type == "discrete") inputs else prettyinside(range))
    textlength <- max(nchar(paste(vv)))
  }
  if(started) {
    textwidth <- max(strwidth(vv))
    textheight <- max(strheight(vv))
  } else {
    ## the plot has not been initialised: guess character size
    charsize <- diff(if(side %in% c("left", "right")) B$yrange else B$xrange)/40
    textwidth <- charsize * textlength
    textheight <- charsize
  }
  switch(side,
         right={
           ## symbols to right of image
           b <- owin(B$xrange[2] + sep + c(0, size),
                     B$yrange)
           ## text to right of symbols
           tt <- owin(b$xrange[2] + sep + c(0, textwidth),
                      b$yrange)
           iside <- 4
         },
         left={
           ## symbols to left of image
           b <- owin(B$xrange[1] - sep - c(size, 0),
                     B$yrange)
           ## text to left of symbols
           tt <- owin(b$xrange[1] - sep - c(textwidth, 0),
                      b$yrange)
           iside <- 2
         },
         top={
           ## symbols above image
           b <- owin(B$xrange,
                     B$yrange[2] + sep + c(0, size))
           ## text above symbols
           tt <- owin(b$xrange,
                      b$yrange[2] + 3* charsize + c(0, textheight))
           iside <- 3
         },
         bottom={
           ## symbols below image
           b <- owin(B$xrange,
                     B$yrange[1] - sep - c(size, 0))
           ## text below symbols
           tt <- owin(b$xrange,
                      b$yrange[1] - 3 * charsize - c(textheight, 0))
           iside <- 1
         })
  A <- boundingbox(B, b, tt)
  return(list(A=A, B=B, b=b, tt=tt,
              iside=iside, side=side, size=size, charsize=charsize, sep=sep))
}

         
  
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/terse.R"
##  terse.R
##
##  code to control terseness and layout of printed output
##
##  $Revision: 1.6 $  $Date: 2014/12/10 06:43:37 $
##

## 'split cat'
## Replacement for 'cat(paste(...))' ensuring a multi-word output string
## doesn't extend over text margin

splat <- function(...) {
  s <- paste(...)
  ## split at newline characters, if present
  ss <- unlist(strsplit(s, "\n"))
  for(ssi in ss) 
    cat(unlist(strsplit(ssi, " ")), fill=TRUE)
  return(invisible(NULL))
}

pasteFormula <- function(f) {
  ## convert formula to a single string
  sf <- paste(format(f), collapse=" ")
  ## remove excessive blanks
  sf <- gsub("   ", " ", sf)
  sf <- gsub("  ", " ", sf)
  return(sf)
}

## paragraph break in long output e.g. ppm
parbreak <- function(terse = spatstat.options("terse")) {
  if(waxlyrical('space', terse)) cat("\n")
  return(invisible(NULL))
}

waxlyrical <- local({

  ##  Values of spatstat.options('terse'):
  ##        0    default
  ##        1    suppress obvious wastage e.g. 'gory details'
  ##        2    contract space between paragraphs in long output
  ##        3    suppress extras e.g. standard errors and CI 
  ##        4    suppress error messages eg failed to converge

  TerseCutoff <- list(gory=1,
                      space=2,
                      extras=3,
                      errors=4)

  waxlyrical <- function(type, terse = spatstat.options("terse")) {
    if(!(type %in% names(TerseCutoff)))
      stop(paste("Internal error: unrecognised permission request",
                 sQuote(type)),
           call.=TRUE)
    return(terse < TerseCutoff[[type]])
  }
  
  waxlyrical
  
})

ruletextline <- function(ch="-", n=getOption('width'),
                         terse=spatstat.options('terse')) {
  if(waxlyrical('space', terse)) {
    chn <- paste(rep(ch, n), collapse="")
    chn <- substr(chn, 1, n)
    cat(chn, fill=TRUE)
  }
  return(invisible(NULL))
}
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/tess.R"
#
# tess.R
#
# support for tessellations
#
#   $Revision: 1.58 $ $Date: 2014/10/24 00:22:30 $
#
tess <- function(..., xgrid=NULL, ygrid=NULL, tiles=NULL, image=NULL,
                 window=NULL, keepempty=FALSE) {
  if(!is.null(window))
    win <- as.owin(window)
  else win <- NULL
  isrect <- !is.null(xgrid) && !is.null(ygrid)
  istiled <- !is.null(tiles)
  isimage <- !is.null(image)
  if(isrect + istiled + isimage != 1)
    stop("Must specify either (xgrid, ygrid) or tiles or img")
  if(isrect) {
    stopifnot(is.numeric(xgrid) && all(diff(xgrid) > 0))
    stopifnot(is.numeric(ygrid) && all(diff(ygrid) > 0))
    if(is.null(win)) win <- owin(range(xgrid), range(ygrid))
    ntiles <- (length(xgrid)-1) * (length(ygrid)-1)
    out <- list(type="rect", window=win, xgrid=xgrid, ygrid=ygrid, n=ntiles)
  } else if(istiled) {
    stopifnot(is.list(tiles))
    if(!all(unlist(lapply(tiles, is.owin))))
      stop("tiles must be a list of owin objects")
    if(!keepempty) {
      # remove empty tiles
      isempty <- unlist(lapply(tiles, is.empty))
      if(all(isempty))
        stop("All tiles are empty")
      if(any(isempty))
        tiles <- tiles[!isempty]
    }
    ntiles <- length(tiles)
    nam <- names(tiles)
    lev <- if(!is.null(nam) && all(nzchar(nam))) nam else 1:ntiles
    if(is.null(win)) {
      for(i in 1:ntiles) {
        if(i == 1)
          win <- tiles[[1]]
        else
          win <- union.owin(win, tiles[[i]])
      }
    }
    ismask <- function(x) {x$type == "mask"}
    if(ismask(win) || any(unlist(lapply(tiles, ismask)))) {
      # convert to pixel image tessellation
      win <- as.mask(win)
      ima <- as.im(win)
      ima$v[] <- NA
      for(i in 1:ntiles)
        ima[tiles[[i]]] <- i
      ima <- ima[win, drop=FALSE]
      ima <- eval.im(factor(ima, levels=1:ntiles))
      levels(ima) <- lev
      out <- list(type="image",
                  window=win, image=ima, n=length(lev))
    } else {
      # tile list
      win <- rescue.rectangle(win)
      out <- list(type="tiled", window=win, tiles=tiles, n=length(tiles))
    }
  } else if(isimage) {
    # convert to factor valued image
    image <- as.im(image)
    switch(image$type,
           logical={
             # convert to factor
             if(keepempty) 
               image <- eval.im(factor(image, levels=c(FALSE,TRUE)))
             else
               image <- eval.im(factor(image))
           },
           factor={
             # eradicate unused levels
             if(!keepempty) 
               image <- eval.im(factor(image))
           },
           {
             # convert to factor
             image <- eval.im(factor(image))
           })
               
    if(is.null(win)) win <- as.owin(image)
    out <- list(type="image", window=win, image=image, n=length(levels(image)))
  } else stop("Internal error: unrecognised format")
  class(out) <- c("tess", class(out))
  return(out)
}

is.tess <- function(x) { inherits(x, "tess") }

print.tess <- function(x, ..., brief=FALSE) {
  full <- !brief
  if(full) cat("Tessellation\n")
  win <- x$window
  switch(x$type,
         rect={
           if(full) {
             unitinfo <- summary(unitname(win))
             equispaced <- function(z) {
               dz <- diff(z)
               diff(range(dz))/mean(dz) < 0.01
             }
             if(equispaced(x$xgrid) && equispaced(x$ygrid)) 
               cat(paste("Tiles are equal rectangles, of dimension",
                         signif(mean(diff(x$xgrid)), 5),
                         "x",
                         signif(mean(diff(x$ygrid)), 5),
                         unitinfo$plural, " ", unitinfo$explain,
                         "\n"))
             else
               cat(paste("Tiles are unequal rectangles\n"))
           }
           cat(paste(length(x$xgrid)-1, "by", length(x$ygrid)-1,
                     "grid of tiles", "\n"))
         },
         tiled={
           if(full) {
             if(win$type == "polygonal")
               cat("Tiles are irregular polygons\n")
             else
               cat("Tiles are windows of general type\n")
           }
           cat(paste(length(x$tiles), "tiles (irregular windows)\n"))
         },
         image={
           nlev <- length(levels(x$image))
           if(full) {
             cat(paste("Tessellation is determined by",
                       "a factor-valued image",
                       "with", nlev, "levels\n"))
           } else cat(paste(nlev, "tiles (levels of a pixel image)\n"))
         })
  if(full) print(win)
  invisible(NULL)
}

plot.tess <- local({

  plotem <- function(z, ..., col=NULL) {
    if(is.null(col))
      plot(z, ..., add=TRUE)
    else if(z$type != "mask")
      plot(z, ..., border=col, add=TRUE)
    else plot(z, ..., col=col, add=TRUE)
  }

  plotpars <- c("sub", "lty", "lwd",
                "cex.main", "col.main", "font.main",
                "cex.sub", "col.sub", "font.sub", "border")

  plot.tess <- function(x, ..., main, add=FALSE, show.all=!add, col=NULL) {
    if(missing(main) || is.null(main))
      main <- short.deparse(substitute(x))
    switch(x$type,
           rect={
             win <- x$window
             do.call.matched("plot.owin",
                             resolve.defaults(list(x=win, main=main,
                                                   add=add, show.all=show.all),
                                              list(...)),
                             extrargs=plotpars)
             xg <- x$xgrid
             yg <- x$ygrid
             do.call.matched("segments",
                             resolve.defaults(list(x0=xg, y0=win$yrange[1],
                                                   x1=xg, y1=win$yrange[2]),
                                              list(col=col),
                                              list(...),
                                              .StripNull=TRUE))
             do.call.matched("segments",
                             resolve.defaults(list(x0=win$xrange[1], y0=yg,
                                                   x1=win$xrange[2], y1=yg),
                                              list(col=col),
                                              list(...),
                                              .StripNull=TRUE))
           },
           tiled={
             do.call.matched("plot.owin",
                             resolve.defaults(list(x=x$window, main=main,
                                                   add=add, show.all=show.all),
                                              list(...)),
                             extrargs=plotpars)
             til <- tiles(x)
             lapply(til, plotem, ..., col=col)
           },
           image={
             do.call("plot",
                     resolve.defaults(list(x$image, add=add, main=main,
                                           show.all=show.all),
                                      list(...),
                                      list(valuesAreColours=FALSE)))
           })
    return(invisible(NULL))
  }

  plot.tess
})


"[<-.tess" <- function(x, ..., value) {
  switch(x$type,
         rect=,
         tiled={
           til <- tiles(x)
           til[...] <- value
           ok <- !unlist(lapply(til, is.null))
           x <- tess(tiles=til[ok])
         },
         image={
           stop("Cannot assign new values to subsets of a pixel image")
         })
  return(x)
}
  
"[.tess" <- function(x, ...) {
  switch(x$type,
         rect=,
         tiled={
           til <- tiles(x)[...]
           return(tess(tiles=til))
         },
         image={
           img <- x$image
           oldlev <- levels(img)
           newlev <- unique(oldlev[...])
           img <- eval.im(factor(img, levels=newlev))
           return(tess(image=img))
         })
}

tiles <- function(x) {
  switch(x$type,
         rect={
           out <- list()
           xg <- x$xgrid
           yg <- x$ygrid
           nx <- length(xg) - 1
           ny <- length(yg) - 1
           for(j in rev(seq_len(ny)))
             for(i in seq_len(nx)) {
               winij <- owin(xg[c(i,i+1)], yg[c(j,j+1)])
               dout <- list(winij)
               names(dout) <- paste("Tile row ", ny-j+1, ", col ", i,
                                    sep="")
               out <- append(out, dout)
             }
         },
         tiled={
           out <- x$tiles
           if(is.null(names(out)))
             names(out) <- paste("Tile", seq_along(out))
         },
         image={
           out <- list()
           ima <- x$image
           lev <- levels(ima)
           for(i in seq_along(lev))
             out[[i]] <- solutionset(ima == lev[i])
           names(out) <- paste(lev)
         })
  out <- as.listof(out)
  return(out)
}

tilenames <- function(x) {
  stopifnot(is.tess(x))
  switch(x$type,
         rect={
           nx <- length(x$xgrid) - 1
           ny <- length(x$ygrid) - 1
           nam <- outer(rev(seq_len(ny)),
                        seq_len(nx),
                        function(j,i,ny) {
                          paste("Tile row ", ny-j+1, ", col ", i,
                                sep="")},
                        ny=ny)
           return(nam)
         },
         tiled={
           til <- x$tiles
           if(!is.null(names(til)))
             nam <- names(til)
           else 
             nam <- paste("Tile", seq_along(til))
         },
         image={
           ima <- x$image
           lev <- levels(ima)
           nam <- paste(lev)
         })
  return(nam)
}

"tilenames<-" <- function(x, value) {
  stopifnot(is.tess(x))
  switch(x$type,
         rect = {
           warning("Cannot change names of the tiles in a rectangular grid")
         },
         tiled = {
           names(x$tiles) <- value
         },
         image = {
           levels(x$image) <- value
         })
  return(x)
}

tile.areas <- function(x) {
  stopifnot(is.tess(x))
  switch(x$type,
         rect={
           xg <- x$xgrid
           yg <- x$ygrid
#           nx <- length(xg) - 1 
#           ny <- length(yg) - 1
           a <- outer(rev(diff(yg)), diff(xg), "*")
           a <- as.vector(t(a))
           names(a) <- as.vector(t(tilenames(x)))
         },
         tiled={
           a <- unlist(lapply(x$tiles, area))
         },
         image={
           z <- x$image
           a <- table(z$v) * z$xstep * z$ystep
         })
  return(a)
}

         
as.im.tess <- function(X, W=NULL, ...,
                       eps=NULL, dimyx=NULL, xy=NULL,
                       na.replace=NULL) {
  # if W is present, it may have to be converted
  if(!is.null(W)) {
    stopifnot(is.owin(W))
    if(W$type != "mask")
      W <- as.mask(W, eps=eps, dimyx=dimyx, xy=xy)
  } 
  switch(X$type,
         image={
           out <- as.im(X$image, W=W, eps=eps, dimyx=dimyx, xy=xy,
                        na.replace=na.replace)
         },
         tiled={
           if(is.null(W))
             W <- as.mask(as.owin(X), eps=eps, dimyx=dimyx, xy=xy)
           til <- X$tiles
           ntil <- length(til)
           nama <- names(til)
           if(is.null(nama) || !all(nzchar(nama)))
             nama <- paste(seq_len(ntil))
           xy <- list(x=W$xcol, y=W$yrow)
           for(i in seq_len(ntil)) {
             indic <- as.mask(til[[i]], xy=xy)
             tag <- as.im(indic, value=i)
             if(i == 1) {
               out <- tag
               outv <- out$v
             } else {
               outv <- pmin.int(outv, tag$v, na.rm=TRUE)
             }
           }
           out <- im(factor(outv, levels=seq_len(ntil), labels=nama),
                     out$xcol, out$yrow)
           unitname(out) <- unitname(W)
         },
         rect={
           if(is.null(W))
             out <- as.im(as.rectangle(X), eps=eps, dimyx=dimyx, xy=xy)
           else
             out <- as.im(W)
           xg <- X$xgrid
           yg <- X$ygrid
           nrows <- length(yg) - 1
           ncols <- length(xg) - 1
           jx <- findInterval(out$xcol, xg, rightmost.closed=TRUE)
           iy <- findInterval(out$yrow, yg, rightmost.closed=TRUE)
           M <- as.matrix(out)
           Jcol <- jx[col(M)]
           Irow <- nrows - iy[row(M)] + 1
           Ktile <- Jcol + ncols * (Irow - 1)
           Ktile <- factor(Ktile, levels=seq_len(nrows * ncols))
           out <- im(Ktile, xcol=out$xcol, yrow=out$yrow,
                     unitname=unitname(W))
         }
         )
  return(out)
}

tileindex <- function(x, y, Z) {
  stopifnot(is.tess(Z))
  stopifnot(length(x) == length(y))
  switch(Z$type,
         rect={
           jx <- findInterval(x, Z$xgrid, rightmost.closed=TRUE)
           iy <- findInterval(y, Z$ygrid, rightmost.closed=TRUE)
           nrows <- length(Z$ygrid) - 1
           ncols <- length(Z$xgrid) - 1
           iy[iy < 1 | iy > nrows] <- NA
           jx[jx < 1 | jx > ncols] <- NA
           jcol <- jx
           irow <- nrows - iy + 1
           ktile <- jcol + ncols * (irow - 1)
           m <- factor(ktile, levels=seq_len(nrows*ncols))
           ij <- expand.grid(j=seq_len(ncols),i=seq_len(nrows))
           levels(m) <- paste("Tile row ", ij$i, ", col ", ij$j, sep="")
         },
         tiled={
           n <- length(x)
           todo <- seq_len(n)
           nt <- length(Z$tiles)
           m <- integer(n)
           for(i in 1:nt) {
             ti <- Z$tiles[[i]]
             hit <- inside.owin(x[todo], y[todo], ti)
             if(any(hit)) {
               m[todo[hit]] <- i
               todo <- todo[!hit]
             }
             if(length(todo) == 0)
               break
           }
           m[m == 0] <- NA
           nama <- names(Z$tiles)
           lev <- seq_len(nt)
           lab <- if(!is.null(nama) && all(nzchar(nama))) nama else paste("Tile", lev)
           m <- factor(m, levels=lev, labels=lab)
         },
         image={
           Zim <- Z$image
           m <- factor(Zim[list(x=x, y=y), drop=FALSE], levels=levels(Zim))
         }
         )
  return(m)
}
  
as.tess <- function(X) {
  UseMethod("as.tess")
}

as.tess.tess <- function(X) {
  fields <- 
    switch(X$type,
           rect={ c("xgrid", "ygrid") },
           tiled={ "tiles" },
           image={ "image" },
           stop(paste("Unrecognised tessellation type", sQuote(X$type))))
  fields <- c(c("type", "window"), fields)
  X <- unclass(X)[fields]
  class(X) <- c("tess", class(X))
  return(X)
}

as.tess.im <- function(X) {
  return(tess(image = X))
}

as.tess.list <- function(X) {
  W <- lapply(X, as.owin)
  return(tess(tiles=W))
}

as.tess.owin <- function(X) {
  return(tess(tiles=list(X)))
}

domain.tess <- Window.tess <- function(X, ...) { as.owin(X) } 

intersect.tess <- function(X, Y, ...) {
  X <- as.tess(X)
  if(is.owin(Y) && Y$type == "mask") {
    # special case
    # convert to pixel image 
    result <- as.im(Y)
    Xtiles <- tiles(X)
    for(i in seq_along(Xtiles)) {
      tilei <- Xtiles[[i]]
      result[tilei] <- i
    }
    result <- result[Y, drop=FALSE]
    return(tess(image=result, window=Y))
  }
  if(is.owin(Y)) {
    # efficient code when Y is a window, retaining names of tiles of X
    Ztiles <- lapply(tiles(X), intersect.owin, B=Y, ..., fatal=FALSE)
    isempty <- unlist(lapply(Ztiles, function(x) { is.null(x) || is.empty(x)}))
    Ztiles <- Ztiles[!isempty]
    Xwin <- as.owin(X)
    Ywin <- Y
  } else {
    # general case
    Y <- as.tess(Y)
    Xtiles <- tiles(X)
    Ytiles <- tiles(Y)
    Ztiles <- list()
    namesX <- names(Xtiles)
    for(i in seq_along(Xtiles)) {
      Xi <- Xtiles[[i]]
      Ti <- lapply(Ytiles, intersect.owin, B=Xi, ..., fatal=FALSE)
      isempty <- unlist(lapply(Ti, function(x) { is.null(x) || is.empty(x)}))
      Ti <- Ti[!isempty]
      names(Ti) <- paste(namesX[i], names(Ti), sep="x")
      Ztiles <- append(Ztiles, Ti)
    }
    Xwin <- as.owin(X)
    Ywin <- as.owin(Y)
  }
  Zwin <- intersect.owin(Xwin, Ywin)
  return(tess(tiles=Ztiles, window=Zwin))
}


bdist.tiles <- local({

  vdist <- function(x,w) {
    z <- as.ppp(vertices(x), W=w, check=FALSE)
    min(bdist.points(z))
  }
  edist <- function(x,b) {
    xd <- crossdist(edges(x, check=FALSE), b, type="separation")
    min(xd)
  }

  bdist.tiles <-  function(X) {
    if(!is.tess(X))
      stop("X must be a tessellation")
    W <- as.owin(X)
    switch(X$type,
           rect=,
           tiled={
             tt <- tiles(X)
             if(is.convex(W)) {
               # distance is minimised at a tile vertex
               d <- sapply(tt, vdist, w=W)
             } else {
               # coerce everything to polygons
               W  <- as.polygonal(W)
               tt <- lapply(tt, as.polygonal)
               # compute min dist from tile edges to window edges
               d <- sapply(tt, edist, b=edges(W))
             }
           },
           image={
             Xim <- X$image
             # compute boundary distance for each pixel
             bd <- bdist.pixels(as.owin(Xim), style="image")
             bd <- bd[W, drop=FALSE]
             # split over tiles
             bX <- split(bd, X)
             # compute minimum distance over each level of factor
             d <- sapply(bX, function(z) { summary(z)$min })
           }
           )
    return(d)
  }
  bdist.tiles
})


## ......... geometrical transformations ..................

shift.tess <- function(X, ...) {
  Y <- X
  Y$window <- wY <- shift(X$window, ...)
  vec <- getlastshift(wY)
  switch(X$type,
         rect={
           Y$xgrid <- Y$xgrid + vec[1]
           Y$ygrid <- Y$ygrid + vec[2]
         },
         tiled={
           Y$tiles <- lapply(Y$tiles, shift, vec=vec)
         },
         image = {
           Y$image <- shift(Y$image, vec)
         })
  attr(Y, "lastshift") <- vec
  return(Y)
}

affine.tess <- function(X, mat=diag(c(1,1)), vec=c(0,0), ...) {
  Y <- X
  Y$window <- affine(X$window, mat=mat, vec=vec, ...)
  switch(Y$type,
         rect = {
           if(all(mat == diag(diag(mat)))) {
             ## result is rectangular
             Y$xgrid <- sort(mat[1,1] * X$xgrid + vec[1])
             Y$ygrid <- sort(mat[2,2] * X$ygrid + vec[2])
           } else {
             ## shear transformation; treat rectangles as general tiles
             Y <- tess(tiles=tiles(X), window=Y$window)
             Y$tiles <- lapply(Y$tiles, affine, mat=mat, vec=vec, ...)
           }
         },
         tiled={
           Y$tiles <- lapply(Y$tiles, affine, mat=mat, vec=vec, ...)
         },
         image = {
           Y$image <- affine(Y$image, mat=mat, vec=vec, ...)
         })
  return(Y)
}

reflect.tess <- function(X) {
  Y <- X
  Y$window <- reflect(Y$window)
  switch(X$type,
         rect = {
           Y$xgrid <- rev(- Y$xgrid)
           Y$ygrid <- rev(- Y$ygrid)
         },
         tiled = {
           Y$tiles <- lapply(Y$tiles, reflect)
         },
         image = {
           Y$image <- reflect(Y$image)
         })
  return(Y)
}

scalardilate.tess <- function(X, f, ...) {
  Y <- X
  Y$window <- scalardilate(X$window, f, ...)
  switch(X$type,
         rect = {
           Y$xgrid <- f * Y$xgrid
           Y$ygrid <- f * Y$ygrid
         },
         tiled = {
           Y$tiles <- lapply(Y$tiles, scalardilate, f=f, ...)
         },
         image = {
           Y$image <- scalardilate(Y$image, f=f, ...)
         })
  return(Y)
}

rotate.tess <- function(X, angle=pi/2, ..., centre=NULL) {
  if(angle %% (2 * pi) == 0) return(X)
  if(!is.null(centre)) {
    X <- shift(X, origin=centre)
    negorigin <- getlastshift(X)
  } else negorigin <- NULL
  Y <- X
  Y$window <- rotate(X$window, angle=angle, ...)
  switch(X$type,
         rect = {
           if(angle %% (pi/2) == 0) {
             ## result is rectangular
             co <- round(cos(angle))
             si <- round(sin(angle))
             Y$xgrid <- sort((if(co == 0) 0 else (co * X$xgrid)) -
                             (if(si == 0) 0 else (si * X$ygrid)))
             Y$ygrid <- sort((if(si == 0) 0 else (si * X$xgrid)) +
                             (if(co == 0) 0 else (co * X$ygrid)))
           } else {
             ## general tessellation
             Y <- tess(tiles=lapply(tiles(X), rotate, angle=angle, ...),
                       window=Y$window)
           }
         },
         tiled = {
           Y$tiles <- lapply(X$tiles, rotate, angle=angle, ...)
         },
         image = {
           Y$image <- rotate(X$image, angle=angle, ...)
         })
  if(!is.null(negorigin))
    Y <- shift(Y, -negorigin)
  return(Y)
}
  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/texture.R"
##
##     texture.R
##
##     Texture plots and texture maps
##
##  $Revision: 1.5 $ $Date: 2014/11/10 11:20:15 $

### .................. basic graphics .............................

## put hatching in a window
add.texture <- function(W, texture=4, spacing=NULL, ...) {
  if(is.data.frame(texture)) {
    ## texture = f(x) where f is a texturemap
    out <- do.call("add.texture",
                   resolve.defaults(list(W=W, spacing=spacing),
                                    list(...),
                                    as.list(texture)))
    return(out)
  }
  ## texture should be an integer
  stopifnot(is.owin(W))
  stopifnot(texture %in% 1:8)
  if(is.null(spacing)) {
    spacing <- diameter(as.rectangle(W))/50
  } else {
    check.1.real(spacing)
    stopifnot(spacing > 0)
  }
  P <- L <- NULL
  switch(texture,
         {
           ## texture 1: graveyard
           P <- rsyst(W, dx=3*spacing)
         },
         {
           ## texture 2: vertical lines
           L <- rlinegrid(90, spacing, W)[W]
         },
         {
           ## texture 3: horizontal lines
           L <- rlinegrid(0, spacing, W)[W]
         },
         {
           ## texture 4: forward slashes
           L <- rlinegrid(45, spacing, W)[W]
         },
         {
           ## texture 5: back slashes
           L <- rlinegrid(135, spacing, W)[W]
         },
         {
           ## texture 6: horiz/vert grid
           L0 <- rlinegrid(0, spacing, W)[W]
           L90 <- rlinegrid(90, spacing, W)[W]
           L <- superimpose(L0, L90, W=W, check=FALSE)
         },
         {
           ## texture 7: diagonal grid
           L45 <- rlinegrid(45, spacing, W)[W]
           L135 <- rlinegrid(135, spacing, W)[W]
           L <- superimpose(L45, L135, W=W, check=FALSE)
         },
         {
           ## texture 8: hexagons
           H <- hextess(W, spacing, offset=runifpoint(1, W))
           H <- intersect.tess(H, W)
           do.call.matched("plot.tess",
                           resolve.defaults(list(x=H, add=TRUE),
                                            list(...)))
         })
  if(!is.null(P))
    do.call.matched("plot.ppp",
                    resolve.defaults(list(x=P, add=TRUE),
                                     list(...),
                                     list(chars=3, cex=0.2)),
                    extrargs=c("lwd", "col", "cols", "pch"))
  if(!is.null(L))
    do.call.matched("plot.psp",
                    resolve.defaults(list(x=L, add=TRUE),
                                     list(...)),
                    extrargs=c("lwd","lty","col"))
  return(invisible(NULL))
}

## .................. texture maps ................................

## create a texture map

texturemap <- function(inputs, textures, ...) {
  argh <- list(...)
  isnul <- unlist(lapply(argh, is.null))
  argh <- argh[!isnul]
  df <- do.call("data.frame",
                append(list(input=inputs, texture=textures), argh))
  f <- function(x) {
    df[match(x, df$input), -1, drop=FALSE]
  }
  class(f) <- c("texturemap", class(f))
  attr(f, "df") <- df
  return(f)
}

print.texturemap <- function(x, ...) {
  cat("Texture map\n")
  print(attr(x, "df"))
  return(invisible(NULL))
}

## plot a texture map

plot.texturemap <- local({

  ## recognised additional arguments to and axis()
  axisparams <- c("cex", 
                  "cex.axis", "cex.lab",
                  "col.axis", "col.lab",
                  "font.axis", "font.lab",
                  "las", "mgp", "xaxp", "yaxp",
                  "tck", "tcl", "xpd")

  # rules to determine the map dimensions when one dimension is given
  widthrule <- function(heightrange, separate, n, gap) {
    if(separate) 1 else diff(heightrange)/10
  }
  heightrule <- function(widthrange, separate, n, gap) {
    (if(separate) (n + (n-1)*gap) else 10) * diff(widthrange) 
  }

  plot.texturemap <- function(x, ..., main,
                             xlim=NULL, ylim=NULL, vertical=FALSE, axis=TRUE,
                             labelmap=NULL, gap=0.25, add=FALSE) {
    if(missing(main))
      main <- short.deparse(substitute(x))
    df <- attr(x, "df")
#    textures <- df$textures
    n   <- nrow(df)
    check.1.real(gap, "In plot.texturemap")
    explain.ifnot(gap >= 0, "In plot.texturemap")
    separate <- (gap > 0)
    if(is.null(labelmap)) {
      labelmap <- function(x) x
    } else stopifnot(is.function(labelmap))
    ## determine rectangular window for display
    rr <- c(0, n + (n-1)*gap)
    if(is.null(xlim) && is.null(ylim)) {
      u <- widthrule(rr, separate, n, gap)
      if(!vertical) {
        xlim <- rr
        ylim <- c(0,u)
      } else {
        xlim <- c(0,u)
        ylim <- rr
      }
    } else if(is.null(ylim)) {
      if(!vertical) 
        ylim <- c(0, widthrule(xlim, separate, n, gap))
      else 
        ylim <- c(0, heightrule(xlim, separate, n, gap))
    } else if(is.null(xlim)) {
      if(!vertical) 
        xlim <- c(0, heightrule(ylim, separate, n, gap))
      else 
        xlim <- c(0, widthrule(ylim, separate, n, gap))
    } 
    width <- diff(xlim)
    height <- diff(ylim)
    ## determine boxes to be filled with textures,
    if(vertical) {
      boxheight <- min(width, height/(n + (n-1) * gap))
      vgap   <- (height - n * boxheight)/(n-1)
      boxes <- list()
      for(i in 1:n) boxes[[i]] <-
        owin(xlim, ylim[1] + c(i-1, i) * boxheight + (i-1) * vgap)
    } else {
      boxwidth <- min(height, width/(n + (n-1) * gap))
      hgap   <- (width - n * boxwidth)/(n-1)
      boxes <- list()
      for(i in 1:n) boxes[[i]] <-
        owin(xlim[1] + c(i-1, i) * boxwidth + (i-1) * hgap, ylim)
    }
    boxsize <- shortside(boxes[[1]])
    # .......... initialise plot ...............................
    if(!add)
      do.call.matched("plot.default",
                      resolve.defaults(list(x=xlim, y=ylim,
                                            type="n", main=main,
                                            axes=FALSE, xlab="", ylab="",
                                            asp=1.0),
                                       list(...)))
    
    ## ................ plot texture blocks .................
    for(i in 1:n) {
      dfi <- df[i,,drop=FALSE]
      add.texture(W=boxes[[i]], texture=dfi, ..., spacing=0.1 * boxsize)
      plot(boxes[[i]], add=TRUE)
    }

    if(axis) {
      # ................. draw annotation ..................
      la <- paste(labelmap(df$input))
      if(!vertical) {
        ## add horizontal axis/annotation
        at <- lapply(lapply(boxes, centroid.owin), "getElement", name="x")
        # default axis position is below the ribbon (side=1)
        sidecode <- resolve.1.default("side", list(...), list(side=1))
        if(!(sidecode %in% c(1,3)))
          warning(paste("side =", sidecode,
                        "is not consistent with horizontal orientation"))
        pos <- c(ylim[1], xlim[1], ylim[2], xlim[2])[sidecode]
        # don't draw axis lines if plotting separate blocks
        lwd0 <- if(separate) 0 else 1
        # draw axis
        do.call.matched("axis",
                        resolve.defaults(list(...),
                                         list(side = 1, pos = pos, at = at),
                                         list(labels=la, lwd=lwd0)),
                        extrargs=axisparams)
      } else {
        ## add vertical axis
        at <- lapply(lapply(boxes, centroid.owin), "getElement", name="y")
        # default axis position is to the right of ribbon (side=4)
        sidecode <- resolve.1.default("side", list(...), list(side=4))
        if(!(sidecode %in% c(2,4)))
          warning(paste("side =", sidecode,
                        "is not consistent with vertical orientation"))
        pos <- c(ylim[1], xlim[1], ylim[2], xlim[2])[sidecode]
        # don't draw axis lines if plotting separate blocks
        lwd0 <- if(separate) 0 else 1
        # draw labels horizontally if plotting separate blocks
        las0 <- if(separate) 1 else 0
        # draw axis
        do.call.matched("axis",
                        resolve.defaults(list(...),
                                         list(side=4, pos=pos, at=at),
                                         list(labels=la, lwd=lwd0, las=las0)),
                        extrargs=axisparams)
      }
    }
    invisible(NULL)
  }

  plot.texturemap
})

## plot a pixel image using textures

textureplot <- local({

  textureplot <- function(x, ..., main, add=FALSE, clipwin=NULL, do.plot=TRUE,
                          border=NULL, col=NULL, lwd=NULL, lty=NULL,
                          spacing=NULL, textures=1:8,
                          legend=TRUE,
                          leg.side=c("right", "left", "bottom", "top"),
                          legsep=0.1, legwid=0.2) {
    if(missing(main))
      main <- short.deparse(substitute(x))
    stopifnot(is.im(x))
    leg.side <- match.arg(leg.side)
    if(!is.null(clipwin))
      x <- x[clipwin, drop=FALSE]
    if(x$type != "factor")
      x <- eval.im(factor(x))
    levX <- levels(x)
    n <- length(levX)
    if(n > 8)
      stop("Too many factor levels for texture plot: maximum is 8")
    ## determine texture map
    if(inherits(textures, "texturemap")) {
      tmap <- textures
    } else {
      stopifnot(all(textures %in% 1:8))
      stopifnot(length(textures) >= n)
      mono <- spatstat.options("monochrome")
      col <- enforcelength(col, n, if(mono) 1 else 1:8)
      lwd <- if(is.null(lwd)) NULL else enforcelength(lwd, n, 1)
      lty <- if(is.null(lty)) NULL else enforcelength(lwd, n, 1)
      tmap <- texturemap(inputs=levX, textures=textures[1:n],
                         col=col, lwd=lwd, lty=lty)
    }
    ## determine plot region
    bb <- as.rectangle(x)
    if(!legend) {
      bb.all <- bb
    } else {
      Size <- max(sidelengths(bb))
      bb.leg <-
        switch(leg.side,
               right={
                 ## legend to right of image
                 owin(bb$xrange[2] + c(legsep, legsep+legwid) * Size,
                      bb$yrange)
               },
               left={
                 ## legend to left of image
                 owin(bb$xrange[1] - c(legsep+legwid, legsep) * Size,
                      bb$yrange)
               },
               top={
                 ## legend above image
                 owin(bb$xrange,
                      bb$yrange[2] + c(legsep, legsep+legwid) * Size)
               },
               bottom={
                 ## legend below image
                 owin(bb$xrange,
                      bb$yrange[1] - c(legsep+legwid, legsep) * Size)
           })
      iside <- match(leg.side, c("bottom", "left", "top", "right"))
      bb.all <- boundingbox(bb.leg, bb)
    }
    ## 
    result <- tmap
    attr(result, "bbox") <- bb
    ##
    if(do.plot) {
      ## Plot textures
      if(!add) {
        plot(bb.all, type="n", main="")
        fakemaintitle(bb, main, ...)
      }
      if(is.null(spacing)) spacing <- diameter(as.rectangle(x))/50
      ok <- (table(x$v) > 0)
      for(i in which(ok)) {
        Zi <- as.polygonal(levelset(x, levX[i], "=="))
        if(is.null(border) || !is.na(border))
          plot(Zi, add=TRUE, border=border)
        add.texture(Zi, texture=tmap(levX[i]), spacing=spacing, ...)
      }
      vertical <- leg.side %in% c("left", "right")
      if(legend)
        do.call("plot.texturemap",
                resolve.defaults(list(x=tmap, add=TRUE,
                                      vertical=vertical,
                                      side=iside,
                                      xlim=bb.leg$xrange,
                                      ylim=bb.leg$yrange),
                                 list(...)))
    }
    return(invisible(result))
  }

  enforcelength <- function(x, n, x0) {
    if(is.null(x)) x <- x0
    if(length(x) < n) x <- rep(x, n)
    return(x[1:n])
  }

  textureplot
})



  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/transect.R"
#
#  transect.R
#
# Line transects of pixel images
#
#  $Revision: 1.6 $  $Date: 2013/03/15 01:28:06 $
#

transect.im <- local({

  specify.location <- function(loc, rect) {
    lname <- short.deparse(substitute(loc))
    if(is.numeric(loc) && length(loc) == 2)
      return(list(x=loc[1], y=loc[2]))
    if(is.list(loc))
      return(xy.coords(loc))
    if(!(is.character(loc) && length(loc) == 1))
      stop(paste("Unrecognised format for", sQuote(lname)), call.=FALSE)
    xr <- rect$xrange
    yr <- rect$yrange
    switch(loc,
           bottomleft  = list(x=xr[1],    y=yr[1]),
           bottom      = list(x=mean(xr), y=yr[1]),
           bottomright = list(x=xr[2],    y=yr[1]),
           right       = list(x=xr[2],    y=mean(yr)),
           topright    = list(x=xr[2],    y=yr[2]),
           top         = list(x=mean(xr), y=yr[2]),
           topleft     = list(x=xr[1],    y=yr[2]),
           left        = list(x=xr[1],    y=mean(yr)),
           centre=,
           center      = list(x=mean(xr), y=mean(yr)),
           stop(paste("Unrecognised location",
                      sQuote(lname), "=", dQuote(loc)),
                call.=FALSE)
           )
  }

  transect.im <- 
    function(X, ..., from="bottomleft", to="topright",
             click=FALSE, add=FALSE) {
      Xname <- short.deparse(substitute(X))
      Xname <- sensiblevarname(Xname, "X")
      stopifnot(is.im(X))
      # determine transect position
      if(click) {
        # interactive
        if(!add) plot(X)
        from <- locator(1)
        points(from)
        to <- locator(1)
        points(to)
        segments(from$x, from$y, to$x, to$y)
      } else {
        # data defining a line segment
        R <- as.rectangle(X)
        from <- specify.location(from, R)
        to   <- specify.location(to,   R)
      }
      # create sample points along transect
      if(identical(from,to))
        stop(paste(sQuote("from"), "and", sQuote("to"),
                   "must be distinct points"), call.=FALSE)
      u <- seq(0,1,length=512)
      x <- from$x + u * (to$x - from$x)
      y <- from$y + u * (to$y - from$y)
      leng <- sqrt( (to$x - from$x)^2 +  (to$y - from$y)^2)
      t <- u * leng
      # look up pixel values (may be NA)
      v <- X[list(x=x, y=y), drop=FALSE]
      # package into fv object
      df <- data.frame(t=t, v=v)
      colnames(df)[2] <- Xname
      fv(df, argu = "t",
         ylab = substitute(Xname(t), list(Xname=as.name(Xname))),
         valu=Xname,
         labl = c("t", "%s(t)"),
         desc = c("distance along transect",
           "pixel value of %s"),
         unitname = unitname(X), fname = Xname)
    }

  transect.im
})
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/triplet.family.R"
#
#
#    triplet.family.R
#
#    $Revision: 1.1 $	$Date: 2011/11/05 07:18:51 $
#
#    Family of `third-order' point process models
#
#    triplet.family:      object of class 'isf' 
#	
#
# -------------------------------------------------------------------
#	

triplet.family <-
  list(
       name  = "triplet",
       print = function(self) {
         cat("Family of third-order interactions\n")
       },
       plot = NULL,
       # ----------------------------------------------------
       eval  = function(X,U,EqualPairs,pot,pars,correction, ...) {
  #
  # This is the eval function for the `triplet' family.
  # 
  # This internal function is not meant to be called by the user.
  # It is called by mpl.prepare() during execution of ppm().
  #         
  # The eval functions perform all the manipulations that are common to
  # a given class of interactions. 
  #
  # This function is currently modelled on 'inforder.family'.
  # It simply invokes the potential 'pot' directly
  # and expects 'pot' to return the values of the sufficient statistic S(u,X).
  #
  # ARGUMENTS:
  #   All 'eval' functions have the following arguments 
  #   which are called in sequence (without formal names)
  #   by mpl.prepare():
  #       
  #   X           data point pattern                      'ppp' object
  #   U           points at which to evaluate potential   list(x,y) suffices
  #   EqualPairs  two-column matrix of indices i, j such that X[i] == U[j]
  #               (or NULL, meaning all comparisons are FALSE)
  #   pot         potential function 
  #   potpars     auxiliary parameters for pairpot        list(......)
  #   correction  edge correction type                    (string)
  #
  # VALUE:
  #    All `eval' functions must return a        
  #    matrix of values of the total potential
  #    induced by the pattern X at each location given in U.
  #    The rows of this matrix correspond to the rows of U (the sample points);
  #    the k columns are the coordinates of the k-dimensional potential.
  #
  ##########################################################################

  # POTENTIAL:
  # In this case the potential function 'pot' should have arguments
  #    pot(X, U, EqualPairs, pars, correction, ...)
  #         
  # It must return a vector with length equal to the number of points in U,
  # or a matrix with as many rows as there are points in U.

         if(!is.ppp(U))
           U <- ppp(U$x, U$y, window=X$window)
         
         POT <- pot(X, U, EqualPairs, pars, correction, ...)

         if(is.matrix(POT)) {
           if(nrow(POT) != U$n)
             stop("Internal error: the potential returned a matrix with the wrong number of rows")
         } else if(is.array(POT) && length(dim(POT)) > 2)
           stop("Internal error: the potential returned an array with more than 2 dimensions")
         else if(is.vector(POT)) {
           if(length(POT) != U$n)
             stop("Internal error: the potential returned a vector with the wrong length")
           POT <- matrix(POT, ncol=1)
         } else
         stop("Internal error: the return value from the potential is not understood")

         return(POT)
       },
######### end of function $eval
       suffstat = NULL
######### end of function $suffstat
)
######### end of list

class(triplet.family) <- "isf"


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/triplets.R"
#
#
#    triplets.R
#
#    $Revision: 1.14 $	$Date: 2014/10/24 00:22:30 $
#
#    The triplets interaction
#
#    Triplets()    create an instance of the triplets process
#                 [an object of class 'interact']
#	
# -------------------------------------------------------------------
#

Triplets <- local({

  DebugTriplets <- FALSE
  
  # define triplet potential
  TripletPotential <- function(X,U,EqualPairs,pars,correction, ...) {
    if(!all(ok <- correction %in% c("border", "none"))) {
      nbad <- sum(bad <- !ok)
      warning(paste(ngettext(nbad, "Correction", "Corrections"),
                    commasep(sQuote(correction[bad])),
                    ngettext(nbad,
                             "is unavailable and was ignored",
                             "are unavailable and were ignored")))
    }
    # check that all points of X are included in U
    nX <- npoints(X)
    nU <- npoints(U)
    XinU <- if(length(EqualPairs) == 0) integer(0) else EqualPairs[,1]
    missX <- which(table(factor(XinU, levels=1:nX)) == 0)
    if((nmiss <- length(missX)) > 0) {
      # add missing points to (the end of) U
      U <- superimpose(U, X[missX], W=as.owin(X), check=FALSE)
      EqualPairs <- rbind(EqualPairs, cbind(missX, nU + 1:nmiss))
      nU <- nU + nmiss
    }
    iXX <- EqualPairs[,1]
    iXU <- EqualPairs[,2]
    # construct map from X index to U index 
    mapXU <- integer(nX)
    mapXU[iXX] <- iXU
    # construct map from U index to X index 
    mapUX <- rep.int(NA_integer_, nU)
    mapUX[iXU] <- iXX
    # logical vector identifying which quadrature points are in X
    isdata <- rep.int(FALSE, nU)
    isdata[iXU] <- TRUE
    # identify all close pairs u, x
    r <- pars$r
    cp <- crosspairs(U, X, r, what="indices")
    if(DebugTriplets)
      cat(paste("crosspairs at distance", r, "yields", length(cp$i), "pairs\n"))
    IU <- cp$i
    J <- cp$j
    # map X index to U index
    JU <- mapXU[J]
    # Each (Xi, Xj) pair will appear twice - eliminate duplicates
    dupX <- isdata[IU] & isdata[JU] & (IU > JU)
    retain <- !dupX
    IU <- IU[retain]
    JU <- JU[retain]
    if(DebugTriplets)
      cat(paste(sum(dupX), "duplicate pairs removed\n"))
    # find all triangles
    tri <- edges2triangles(IU, JU, nU, friendly=isdata)
    if(DebugTriplets)
      cat(paste(nrow(tri), "triangles identified\n"))
    if(nrow(tri) == 0) {
      # there are no triangles; return vector of zeroes
      return(rep.int(0, nU-nmiss))
    }
    # count triangles containing a given quadrature point
    tcount <- apply(tri, 2,
                    function(x, n) { table(factor(x, levels=1:n)) }, n=nU)
    tcount <- .rowSums(tcount, nrow(tcount), ncol(tcount))
    # select triangles consisting only of data points
    triX <- matrix(mapUX[tri], nrow=nrow(tri))
    isX <- apply(!is.na(triX), 1, all)
    triX <- triX[isX, , drop=FALSE]
    #
    if(nrow(triX) > 0) {
      # count triangles of data points containing each given data point
      tXcount <- apply(triX, 2,
                       function(x, n) { table(factor(x, levels=1:n)) }, n=nX)
      tXcount <- .rowSums(tXcount, nrow(tXcount), ncol(tXcount))
    } else {
      # there are no triangles of data points
      tXcount <- rep.int(0, nX)
    }
    #
    answer <- tcount
    answer[iXU] <- tXcount[iXX]
    if(DebugTriplets)
      cat(paste("Max suff stat: data ", max(tXcount),
                ", dummy ", max(tcount[isdata]), "\n", sep=""))
    # truncate to original size
    if(nmiss > 0)
      answer <- answer[-((nU-nmiss+1):nU)]
    return(answer)
  }
  # set up basic 'triplets' object except for family and parameters
  BlankTripletsObject <- 
    list(
         name     = "Triplets process",
         creator  = "Triplets",
         family   = "triplet.family", # evaluated later
         pot      = TripletPotential,
         par      = list(r=NULL), # filled in later
         parnames = "interaction distance",
         init     = function(self) {
                      r <- self$par$r
                      if(!is.numeric(r) || length(r) != 1 || r <= 0)
                       stop("interaction distance r must be a positive number")
                    },
         update = NULL,  # default OK
         print = NULL,    # default OK
         interpret =  function(coeffs, self) {
           loggamma <- as.numeric(coeffs[1])
           gamma <- exp(loggamma)
           return(list(param=list(gamma=gamma),
                       inames="interaction parameter gamma",
                       printable=dround(gamma)))
         },
         valid = function(coeffs, self) {
           gamma <- ((self$interpret)(coeffs, self))$param$gamma
           return(is.finite(gamma) && (gamma <= 1))
         },
         project = function(coeffs, self) {
           if((self$valid)(coeffs, self)) return(NULL) else return(Poisson())
         },
         irange = function(self, coeffs=NA, epsilon=0, ...) {
           r <- self$par$r
           if(any(is.na(coeffs)))
             return(r)
           loggamma <- coeffs[1]
           if(abs(loggamma) <= epsilon)
             return(0)
           else
             return(r)
         },
         version=NULL # to be added
         )
  class(BlankTripletsObject) <- "interact"
  # define Triplets function
  Triplets <- function(r) {
    instantiate.interact(BlankTripletsObject, list(r=r))
  }
  Triplets <- intermaker(Triplets, BlankTripletsObject)
  
  Triplets
})

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/unique.ppp.R"
#
#   unique.ppp.R
#
# $Revision: 1.30 $  $Date: 2014/11/11 01:25:17 $
#
# Methods for 'multiplicity' co-authored by Sebastian Meyer
# Copyright 2013 Adrian Baddeley and Sebastian Meyer 

unique.ppp <- function(x, ..., warn=FALSE) {
  verifyclass(x, "ppp")
  dupe <- duplicated.ppp(x, ...) 
  if(!any(dupe)) return(x)
  if(warn) warning(paste(sum(dupe), "duplicated points were removed"),
                   call.=FALSE)
  return(x[!dupe])
}

duplicated.ppp <- function(x, ...,
                           rule=c("spatstat", "deldir", "unmark")) {
  verifyclass(x, "ppp")
  rule <- match.arg(rule)
  if(rule == "deldir")
    return(deldir::duplicatedxy(x))
  if(rule == "unmark")
    x <- unmark(x)
  n <- npoints(x)
  switch(markformat(x),
         none = {
           # unmarked points
           # check for duplication of x and y separately (a necessary condition)
           xx <- x$x
           yy <- x$y
           possible <- duplicated(xx) & duplicated(yy)
           if(!any(possible))
             return(possible)
           # split by x coordinate of duplicated x values
           result <- possible
           xvals <- unique(xx[possible])
           for(xvalue in xvals) {
             sub <- (xx == xvalue)
           # compare y values
             result[sub] <- duplicated(yy[sub])
           }
         },
         vector = {
           # marked points - split by mark value
           m <- marks(x)
           um <- if(is.factor(m)) levels(m) else unique(m)
           xx <- unmark(x)
           result <- logical(n)
           for(i in seq_along(um)) {
             sub <- (m == um[i])
             result[sub] <- duplicated.ppp(xx[sub])
           }
         },
         dataframe = {
           result <- duplicated(as.data.frame(x))
         },
         # the following are currently not supported
         hyperframe = {
           result <- duplicated(as.data.frame(x))
         }, 
         listof = {
           result <- duplicated(as.data.frame(as.hyperframe(x)))
         },
         stop(paste("Unknown mark type", sQuote(markformat(x))))
         )
  return(result)
}

anyDuplicated.ppp <- function(x, ...) {
  anyDuplicated(as.data.frame(x), ...)
}

## utility to check whether two rows are identical

IdenticalRows <- local({
  id <- function(i,j, a, b=a) {
    ai <- a[i,]
    bj <- b[j,]
    row.names(ai) <- row.names(bj) <- NULL
    identical(ai, bj)
  }
  Vectorize(id, c("i", "j"))
})
    

multiplicity <- function(x) {
  UseMethod("multiplicity")
}
  
multiplicity.ppp <- function(x) {
  verifyclass(x, "ppp")
  np <- npoints(x)
  if(np == 0) return(integer(0))
  cl <- closepairs(x, 0, what="indices")
  I <- cl$i
  J <- cl$j
  if(length(I) == 0)
    return(rep.int(1L, np))
  switch(markformat(x),
         none = { },
         vector = {
           marx <- as.data.frame(marks(x))
           agree <- IdenticalRows(I, J, marx)
           I <- I[agree]
           J <- J[agree]
         },
         dataframe = {
           marx <- marks(x)
           agree <- IdenticalRows(I, J, marx)
           I <- I[agree]
           J <- J[agree]
         },
         hyperframe = {
           marx <- as.data.frame(marks(x)) # possibly discards columns
           agree <- IdenticalRows(I, J, marx)
           I <- I[agree]
           J <- J[agree]
         }, 
         listof = stop("Not implemented for lists of marks")
         )
  if(length(I) == 0)
    return(rep.int(1L, np))
  JbyI <- split(J, factor(I, levels=1:np))
  result <- 1 + sapply(JbyI, length)
  return(result)
}
  
multiplicity.data.frame <- function (x) {
  if(all(unlist(lapply(x, is.numeric))))
    return(multiplicityNumeric(as.matrix(x)))
  ## result template (vector of 1's)
  result <- setNames(rep.int(1L, nrow(x)), rownames(x))
  ## check for duplicates (works for data frames, arrays and vectors)
  ## CAVE: comparisons are based on a character representation of x
  if (!any(dup <- duplicated(x)))
    return(result)
  ux <- x[!dup, , drop=FALSE]
  dx <- x[dup,  , drop=FALSE]
  nu <- nrow(ux)
  nd <- nrow(dx)
  hit <- outer(seq_len(nu), seq_len(nd), IdenticalRows, a=ux, b=dx)
  counts <- as.integer(1 + .rowSums(hit, nu, nd))
  result[!dup] <- counts
  dumap <- apply(hit, 2, function(z) min(which(z)))
  result[dup] <- counts[dumap]
  return(result)
}

### multiplicity method for NUMERIC arrays, data frames, and vectors
### This implementation is simply based on checking for dist(x)==0

multiplicityNumeric <- function(x)
{
  if (anyDuplicated(x)) {
    distmat <- as.matrix(dist(x, method="manhattan"))  # faster than euclid.
    as.integer(rowSums(distmat == 0))                  # labels are kept
  } else {                                             # -> vector of 1's
    nx <- NROW(x)
    labels <- if (length(dim(x))) rownames(x) else names(x)
    if (is.null(labels)) labels <- seq_len(nx)
    setNames(rep.int(1L, nx), labels)
  }
}

### multiplicity method for arrays, data frames, and vectors (including lists)
### It also works for non-numeric data, since it is based on duplicated().

multiplicity.default <- function (x) {
  if(is.numeric(x))
    return(multiplicityNumeric(x))
  nx <- NROW(x)                   # also works for a vector x
  ## result template (vector of 1's)
  labels <- if (length(dim(x))) rownames(x) else names(x)
  if (is.null(labels)) labels <- seq_len(nx)
  result <- setNames(rep.int(1L, nx), labels)
  ## check for duplicates (works for data frames, arrays and vectors)
  ## CAVE: comparisons are based on a character representation of x
  if (!any(dup <- duplicated(x)))
    return(result)

  ## convert x to a matrix for IdenticalRows()
  x <- as.matrix(x)
  dimnames(x) <- NULL             # discard any names!
  ux <- x[!dup, , drop=FALSE]
  dx <- x[dup,  , drop=FALSE]
  nu <- nrow(ux)
  nd <- nrow(dx)
  hit <- outer(seq_len(nu), seq_len(nd), IdenticalRows, a=ux, b=dx)
  counts <- as.integer(1 + .rowSums(hit, nu, nd))
  dumap <- apply(hit, 2, function(z) min(which(z)))
  result[dup] <- counts[dumap]
  return(result)
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/units.R"
#
# Functions for extracting and setting the name of the unit of length
#
#   $Revision: 1.19 $   $Date: 2014/03/04 10:25:19 $
#
#

unitname <- function(x) {
  UseMethod("unitname")
}

unitname.owin <- function(x) {
  u <- as.units(x$units)
  return(u)
}

unitname.ppp <- function(x) {
  u <- as.units(x$window$units)
  return(u)
}

unitname.im <- function(x) {
  u <- as.units(x$units)
  return(u)
}

unitname.default <- function(x) {
  return(as.units(attr(x, "units")))
}

"unitname<-" <- function(x, value) {
  UseMethod("unitname<-")
}

"unitname<-.owin" <- function(x, value) {
  x$units <- as.units(value)
  return(x)
}

"unitname<-.ppp" <- function(x, value) {
  w <- x$window
  unitname(w) <- value
  x$window <- w
  return(x)
}

"unitname<-.im" <- function(x, value) {
  x$units <- as.units(value)
  return(x)
}

"unitname<-.default" <- function(x, value) {
  attr(x, "units") <- as.units(value)
  return(x)
}


###  class 'units'

makeunits <- function(sing="unit", plur="units", mul = 1) {
  if(!is.character(sing))
    stop("In unit name, first entry should be a character string")
  if(!is.character(plur))
    stop("In unit name, second entry should be a character string")
  if(!is.numeric(mul)) {
    mul <- try(as.numeric(mul), silent=TRUE)
    if(inherits(mul, "try-error"))
      stop("In unit name, third entry should be a number")
  }
  if(length(mul) != 1 || mul <= 0)
    stop("In unit name, third entry should be a single positive number")
  u <- list(singular=sing, plural=plur, multiplier=mul)
  if(mul != 1 && (sing=="unit" || plur=="units"))
    stop(paste("A multiplier is not allowed",
               "if the unit does not have a specific name"))
  class(u) <- "units"
  return(u)
}
  
as.units <- function(s) {
  s <- as.list(s)
  n <- length(s)
  if(n > 3)
    stop(paste("Unit name should be a character string,",
               "or a vector/list of 2 character strings,",
               "or a list(character, character, numeric)"))
  
  out <- switch(n+1,
                makeunits(),
                makeunits(s[[1]], s[[1]]),
                makeunits(s[[1]], s[[2]]),
                makeunits(s[[1]], s[[2]], s[[3]]))
  return(out)
}

print.units <- function(x, ...) {
  mul <- x$multiplier
  if(mul == 1)
    cat(paste(x$singular, "/", x$plural, "\n"))
  else 
    cat(paste(mul, x$plural, "\n"))
  return(invisible(NULL))
}

as.character.units <- function(x, ...) {
  mul <- x$multiplier
  return(if(mul == 1) x$plural else paste(mul, x$plural))
}

summary.units <- function(object, ...) {
  x <- object
  scaled <- (x$multiplier != 1)
  named  <- (x$singular != "unit")
  vanilla <- !named && !scaled
  out <-
    if(vanilla) {
      list(legend = NULL,
           axis   = NULL, 
           explain = NULL,
           singular = "unit",
           plural   = "units")
    } else if(named & !scaled) {
      list(legend = paste("Unit of length: 1", x$singular),
           axis   = paste("(", x$plural, ")", sep=""),
           explain = NULL,
           singular = x$singular,
           plural   = x$plural)
    } else {
      expanded <- paste(x$multiplier, x$plural)
      list(legend = paste("Unit of length:", expanded),
           axis   = paste("(one unit = ", expanded, ")", sep=""),
           explain  = paste("(one unit = ", expanded, ")", sep=""),
           singular = "unit",
           plural   = "units")
    }
  out <- append(out, list(scaled  = scaled,
                          named   = named,
                          vanilla = vanilla))
  class(out) <- "summary.units"
  return(out)
}

print.summary.units <- function(x, ...) {
  if(x$vanilla)
    cat("Unit of length (unnamed)\n")
  else
    cat(paste(x$legend, "\n"))
  invisible(NULL)
}

compatible.units <- function(A, B, ..., coerce=TRUE) {
  stopifnot(inherits(A, "units"))
  if(missing(B)) return(TRUE)
  stopifnot(inherits(B, "units"))
  # check for null units
  Anull <- summary(A)$vanilla
  Bnull <- summary(B)$vanilla
  # `coerce' determines whether `vanilla' units are compatible with other units
  coerce <- as.logical(coerce)
  # 
  agree <- if(!Anull && !Bnull) identical(all.equal(A,B), TRUE) else
           if(Anull && Bnull) TRUE else coerce 
  #
  if(!agree) return(FALSE)
  # A and B agree
  if(length(list(...)) == 0) return(TRUE)
  # recursion
  return(compatible.units(B, ...))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/unnormdensity.R"
#
#  unnormdensity.R
#
#  $Revision: 1.4 $  $Date: 2014/05/15 10:09:09 $
#

unnormdensity <- function(x, ..., weights=NULL) {
  if(any(!nzchar(names(list(...)))))
    stop("All arguments must be named (tag=value)")
  if(is.null(weights)) {
    out <- do.call.matched("density.default", c(list(x=x), list(...)))
    out$y <- length(x) * out$y
  } else if(all(weights == 0)) {
    # result is zero
    out <- do.call.matched("density.default", c(list(x=x), list(...)))
    out$y <- 0 * out$y
  } else if(all(weights >= 0)) {
    # all masses are nonnegative
    w <- weights
    totmass <- sum(w)
    out <- do.call.matched("density.default",
                           c(list(x=x),
                             list(...),
                             list(weights=w/totmass)))
    out$y <- out$y * totmass
  } else if(all(weights <= 0)) {
    # all masses are nonpositive
    w <- (- weights)
    totmass <- sum(w)
    out <- do.call.matched("density.default",
                           c(list(x=x),
                             list(...),
                             list(weights=w/totmass)))
    out$y <- out$y * (- totmass)
  } else {
    # mixture of positive and negative masses
    w <- weights
    wabs <- abs(w)
    wpos <- pmax.int(0, w)
    wneg <- - pmin.int(0, w)
    # determine bandwidth using absolute masses
    dabs <- do.call.matched("density.default",
                            c(list(x=x),
                              list(...),
                              list(weights=wabs/sum(wabs))))
    bw <- dabs$bw
    # compute densities for positive and negative masses separately
    outpos <- do.call.matched("density.default",
                      resolve.defaults(list(x=x),
                                       list(bw=bw, adjust=1),
                                       list(weights=wpos/sum(wpos)),
                                       list(...),
                                       .StripNull=TRUE))
    outneg <- do.call.matched("density.default",
                      resolve.defaults(list(x=x),
                                       list(bw=bw, adjust=1),
                                       list(weights=wneg/sum(wneg)),
                                       list(...),
                                       .StripNull=TRUE))
    # combine
    out <- outpos
    out$y <- sum(wpos) * outpos$y - sum(wneg) * outneg$y
  }
  out$call <- match.call()
  return(out)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/update.ppm.R"
#
#  update.ppm.R
#
#
#  $Revision: 1.55 $    $Date: 2014/10/24 00:22:30 $
#
#
#

update.ppm <- local({

  ## update formula and expand polynomial
  newformula <- function(old, change, eold, enew) {
    old <- if(is.null(old)) ~1 else eval(old, eold)
    change <- if(is.null(change)) ~1 else eval(change, enew)
    old <- as.formula(old, env=eold)
    change <- as.formula(change, env=enew)
    answer <- update.formula(old, change)
    if(spatstat.options("expand.polynom")) 
      answer <- expand.polynom(answer)
    return(answer)
  }

  ## update point pattern dataset using either data or formula
  newpattern <- function(oldpattern, lhs, callframe, envir) {
    eval(eval(substitute(substitute(l, list("."=Q)),
                         list(l=lhs,
                              Q=oldpattern)),
              envir=as.list(envir), enclos=callframe),
         envir=as.list(envir), enclos=callframe)
  }
  
  update.ppm <- function(object, ...,
                         fixdummy=TRUE, use.internal=NULL,
                         envir=environment(terms(object))) {
    verifyclass(object, "ppm")
    new.callstring <- short.deparse(sys.call())
    aargh <- list(...)
    
    if(inherits(object, "ippm")) {
      call <- object$dispatched$call
      callframe <- object$dispatched$callframe
    } else {
      call <- getCall(object)
      if(!is.call(call))
        stop(paste("Internal error - getCall(object) is not of class",
                   sQuote("call")))
      callframe <- object$callframe
    }
    
    callfun <- as.character(call[[1]])
    newstyle <- (callfun == "ppm.formula")
    oldstyle <- !newstyle
    
    ## Special cases 
    ## (1) no new information given
    if(length(aargh) == 0 && !identical(use.internal, TRUE)) {
      result <- eval(call, as.list(envir), enclos=callframe)
      result$callframe <- callframe
      return(result)
    }

    ## (2) model can be updated using existing covariate data frame
    if(!identical(use.internal, FALSE) &&
       ## single argument which is a formula
       (length(aargh) == 1) &&
       inherits(fmla <- aargh[[1]], "formula") &&
       is.null(lhs.of.formula(fmla)) &&
       ## not a ppm.formula call
       oldstyle &&
       ## fitted by mpl using glm/gam
       with(object,
            method == "mpl" &&
            !is.null(fitter) &&
            fitter %in% c("gam", "glm"))) {
      ## This is a dangerous hack! 
      glmdata <- object$internal$glmdata
      ## check whether data for new variables are available
      ## (this doesn't work with things like 'pi')
      vars.available <- c(colnames(glmdata), names(object$covfunargs))
      if(all(variablesinformula(fmla) %in% c(".", vars.available))) {
        ## we can update using internal data
        FIT <- object$internal$glmfit
        orig.env <- environment(FIT$terms)
        ## update formulae using "." rules
        trend <- newformula(object$trend, fmla, callframe, envir)
        fmla  <- newformula(formula(FIT), fmla, callframe, envir)
        ## expand polynom() in formula
        if(spatstat.options("expand.polynom")) {
          fmla <- expand.polynom(fmla)
          trend <- expand.polynom(trend)
        }
        ## update GLM/GAM fit 
        upd.glm.call <- update(FIT, fmla, evaluate=FALSE)
        FIT <- eval(upd.glm.call, envir=orig.env)
        environment(FIT$terms) <- orig.env
        object$internal$glmfit <- FIT
        ## update entries of object
        object$trend <- trend
        object$terms <- terms(fmla)
        object$coef <- co <- FIT$coef
        object$callstring <- new.callstring
        object$internal$fmla <- fmla
        ##
        if(is.finite(object$maxlogpl)) {
          ## Update maxlogpl provided it is finite
          ## (If the likelihood is infinite, this is due to the interaction;
          ## if we update the trend, the likelihood will remain infinite.)
          W <- glmdata$.mpl.W
          SUBSET <- glmdata$.mpl.SUBSET        
          Z <- is.data(object$Q)
          object$maxlogpl <- -(deviance(FIT)/2 +
                               sum(log(W[Z & SUBSET])) + sum(Z & SUBSET))
        }
        ## update the model call
        upd.call <- call
        upd.call$trend <- trend
        object$call <- upd.call
        ## update fitted interaction (depends on coefficients, if not Poisson)
        if(!is.null(inter <- object$interaction) && !is.poisson(inter)) 
          object$fitin <-
            fii(inter, co, object$internal$Vnames, object$internal$IsOffset)
        ##
        if(is.stationary(object) && !is.marked(object)) {
          ## uniform Poisson
          if(eval(call$rename.intercept) %orifnull% TRUE) {
             names(object$coef) <- "log(lambda)"
          }
        }
        return(object)
      }
    }

    ## (3) Need to use internal data   
    if(oldstyle) {
      ## decide whether to use internal data
      undecided <- is.null(use.internal) || !is.logical(use.internal)
      force.int   <- !undecided && use.internal
      force.ext   <- !undecided && !use.internal
      if(!force.int) {
        ## check for validity of format
        badformat <- damaged.ppm(object)
      }
      if(undecided) {
        use.internal <- badformat
        if(badformat)
          message("object format corrupted; repairing it")
      } else if(force.ext && badformat)
        warning("object format corrupted; try update(object, use.internal=TRUE)")
      if(use.internal) {
        ## reset the main arguments in the call using the internal data
        call$Q <- quad.ppm(object)
        namobj <- names(call)
        if("trend" %in% namobj)
          call$trend <- newformula(call$trend, object$trend, callframe, envir)
        if("interaction" %in% namobj) call$interaction <- object$interaction
        if("covariates" %in% namobj) call$covariates <- object$covariates
      }
    }

    ## General case.
    X.is.new <- FALSE
    
    ## First split named and unnamed arguments
    nama <- names(aargh)
    named <- if(is.null(nama)) rep.int(FALSE, length(aargh)) else nzchar(nama)
    namedargs <- aargh[named]
    unnamedargs <- aargh[!named]
    nama <- names(namedargs)

    ## Find the argument 'Q' by name or implicitly by class
    ##   (including detection of conflicts)
    argQ <- NULL
    if(n <- sp.foundclasses(c("ppp", "quad"), unnamedargs, "Q", nama)) {
      argQ <- unnamedargs[[n]]
      unnamedargs <- unnamedargs[-n]
    }
    if("Q" %in% nama) {
      argQ <- namedargs$Q
      nama <- setdiff(nama, "Q")
      namedargs <- namedargs[nama]
    }
    ## Deal with argument 'Q' which has several possible forms
    if(!is.null(argQ)) {
      X.is.new <- TRUE
      if(inherits(argQ, "formula")) {
        ## Q = X ~ trend
        if(newstyle) {
          ## update the formula
          call$Q <- newformula(call$Q, argQ, callframe, envir)
        } else {
          ## split into Q = X and trend = ~trend
          if(!is.null(lhs <- lhs.of.formula(argQ)))
            call$Q <- newpattern(call$Q, lhs, callframe, envir)
          call$trend <- newformula(call$trend,
                                   rhs.of.formula(eval(argQ)),
                                   callframe, envir)
        }
      } else {
        ## Q = X
        if(newstyle) {
          ## convert old call to old style
          fo <- as.formula(call$Q)
          Yexpr <- lhs.of.formula(fo)
          trend <- rhs.of.formula(fo)
          newcall <- call("ppm", Q=Yexpr, trend=trend)
          if(length(call) > 2) {
            whichQ <- which(names(call) == "Q")
            morecall <- call[-c(1, whichQ)]
            if((mc <- length(morecall)) > 0) {
              newcall[3 + 1:mc] <- morecall
              names(newcall)[3 + 1:mc] <- names(call)[-c(1, whichQ)]
            }
          }
          call <- newcall
          newstyle <- FALSE
          oldstyle <- TRUE
        }
        ## Now update the dataset
        call$Q <- argQ
      }
    }

    ## Find any formula arguments 
    ##   (including detection of conflicts)
    argfmla <- NULL
    if(n <- sp.foundclass("formula", unnamedargs, "trend", nama)) {
      argfmla <- unnamedargs[[n]]
      unnamedargs <- unnamedargs[-n]
    } else if(n <- sp.foundclass("character", unnamedargs, "trend", nama)) {
      ## string that might be interpreted as a formula
      strg <- unnamedargs[[n]]
      if(!is.na(charmatch("~", strg))) {
        argfmla <- as.formula(strg)
        unnamedargs <- unnamedargs[-n]
      }
    }
    if("trend" %in% nama) {
      argfmla <- namedargs$trend
      nama <- setdiff(nama, "trend")
      namedargs <- namedargs[nama]
    }
    ## Handle new formula
    if(!is.null(argfmla)) {
      lhs <- lhs.of.formula(argfmla)
      if(newstyle) {
        ## ppm.formula: update the formula
        if(is.null(lhs)) {
          argfmla <- as.formula(paste(".", deparse(argfmla)))
        } else X.is.new <- TRUE
        call$Q <- newformula(call$Q, argfmla, callframe, envir)
      } else {
        ## ppm.ppp: update the trend and possibly the data
        if(is.null(lhs)) {
          ## assign new trend
          call$trend <- newformula(call$trend, argfmla, callframe, envir)
        } else {
          ## split into Q = X and trend = ~trend
          X.is.new <- TRUE
          call$Q <- newpattern(call$Q, lhs, callframe, envir)
          call$trend <- newformula(call$trend,
                                   rhs.of.formula(argfmla),
                                   callframe, envir)
        }
      } 
    }
    
    if(length(namedargs) > 0) {
      ## any other named arguments that were also present in the original call
      ## override their original values.
      existing <- !is.na(match(nama, names(call)))
      for (a in nama[existing]) call[[a]] <- aargh[[a]]

      ## add any named arguments not present in the original call
      if (any(!existing)) {
        call <- c(as.list(call), namedargs[!existing])
        call <- as.call(call)
      }
    }
    if(length(unnamedargs) > 0) {
      ## some further objects identified by their class
      if(n<- sp.foundclass("interact", unnamedargs, "interaction", nama)) {
        call$interaction <- unnamedargs[[n]]
        unnamedargs <- unnamedargs[-n]
      }
      if(n <- sp.foundclasses(c("data.frame", "im"),
                              unnamedargs, "covariates", nama)) {
        call$covariates <- unnamedargs[[n]]
        unnamedargs <- unnamedargs[-n]
      }
    }
  
    ## *************************************************************
    ## ****** Special action when Q is a point pattern *************
    ## *************************************************************
    if(X.is.new && fixdummy && oldstyle &&
       inherits((X <- eval(call$Q, as.list(envir), enclos=callframe)), "ppp")) {
      ## Instead of allowing default.dummy(X) to occur,
      ## explicitly create a quadrature scheme from X,
      ## using the same dummy points and weight parameters
      ## as were used in the fitted model 
      Qold <- quad.ppm(object)
      if(is.marked(Qold)) {
        dpar <- Qold$param$dummy
        wpar <- Qold$param$weight
        Qnew <- do.call("quadscheme", append(list(X), append(dpar, wpar)))
      } else {
        Dum <- Qold$dummy
        wpar <- Qold$param$weight
        Qnew <- do.call("quadscheme", append(list(X, Dum), wpar))
      }
      ## replace X by new Q
      call$Q <- Qnew
    }

    ## finally call ppm
    call[[1]] <- as.name('ppm')
    return(eval(call, as.list(envir), enclos=callframe))
  }

  update.ppm
})

sp.foundclass <- function(cname, inlist, formalname, argsgiven) {
  ok <- unlist(lapply(inlist, inherits, what=cname))
  nok <- sum(ok)
  if(nok > 1)
    stop(paste("I am confused: there are two unnamed arguments",
               "of class", sQuote(cname)))
  if(nok == 0) return(0)
  absent <- !(formalname %in% argsgiven)
  if(!absent)
    stop(paste("I am confused: there is an unnamed argument",
               "of class", sQuote(cname), "which conflicts with the",
               "named argument", sQuote(formalname)))
  theposition <- seq_along(ok)[ok]
  return(theposition)
}

sp.foundclasses <- function(cnames, inlist, formalname, argsgiven) {
  ncn <- length(cnames)
  pozzie <- logical(ncn)
  for(i in seq_len(ncn))
    pozzie[i] <- sp.foundclass(cnames[i],  inlist, formalname, argsgiven)
  found <- (pozzie > 0)
  nfound <- sum(found)
  if(nfound == 0)
    return(0)
  else if(nfound == 1)
    return(pozzie[found])
  else
    stop(paste("I am confused: there are", nfound,
               "unnamed arguments of different classes (",
               paste(sQuote(cnames(pozzie[found])), collapse=", "),
               ") which could be interpreted as",
               sQuote(formalname)))
}
    

damaged.ppm <- function(object) {
  ## guess whether the object format has been damaged
  ## e.g. by dump/restore
  gf <- getglmfit(object)
  badfit <- !is.null(gf) && !inherits(gf$terms, "terms")
  if(badfit)
    return(TRUE)
  ## escape clause for fake models
  if(identical(object$fake, TRUE))
    return(FALSE)
  ## otherwise it was made by ppm 
  Qcall <- object$call$Q
  cf <- object$callframe
  if(is.null(cf)) {
    ## Old format of ppm objects
    if(is.name(Qcall) && !exists(paste(Qcall)))
      return(TRUE)
    Q <- eval(Qcall)
  } else {
    ## New format of ppm objects
    if(is.name(Qcall) && !exists(paste(Qcall), cf))
      return(TRUE)
    Q <- eval(Qcall, cf)
  }
  badQ <- is.null(Q) || !(inherits(Q, c("ppp", "quad", "formula")))
  return(badQ)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/util.R"
#
#    util.S    miscellaneous utilities
#
#    $Revision: 1.165 $    $Date: 2014/10/14 05:44:08 $
#
#
matrowsum <- function(x) {
  x %*% rep.int(1, ncol(x))
}

matcolsum <- function(x) {
  rep.int(1, nrow(x)) %*% x
}
  
matrowany <- function(x) {
  (matrowsum(x) > 0)
}

matrowall <- function(x) {
  (matrowsum(x) == ncol(x))
}

matcolany <- function(x) {
  (matcolsum(x) > 0)
}

matcolall <- function(x) {
  (matcolsum(x) == nrow(x))
}

########
    # hm, this is SLOWER

apply23sum <- function(x) {
  dimx <- dim(x)
  if(length(dimx) != 3)
    stop("x is not a 3D array")
  result <- array(0, dimx[-1])

  nz <- dimx[3]
  for(k in 1:nz) {
    result[,k] <- matcolsum(x[,,k])
  }
  result
}
    
#######################
#
#    whist      weighted histogram
#

whist <- function(x, breaks, weights=NULL) {
    N <- length(breaks)
    if(length(x) == 0) 
      h <- numeric(N+1)
    else {
      # classify data into histogram cells (breaks need not span range of data)
      cell <- findInterval(x, breaks, rightmost.closed=TRUE)
      # values of 'cell' range from 0 to N.
      nb <- N + 1L
      if(is.null(weights)) {
        ## histogram
        h <- tabulate(cell+1L, nbins=nb)
      } else {
        ##  weighted histogram
        if(!spatstat.options("Cwhist")) {
          cell <- factor(cell, levels=0:N)
          h <- unlist(lapply(split(weights, cell), sum, na.rm=TRUE))
        } else {
          h <- .Call("Cwhist",
                     as.integer(cell), as.double(weights), as.integer(nb))
        }
      }
    }
    h <- as.numeric(h)
    y <- h[2:N]
    attr(y, "low") <- h[1]
    attr(y, "high") <- h[N+1]
    return(y)
}

######################
#
#   matrixsample         subsample or supersample a matrix
#

matrixsample <- function(mat, newdim, phase=c(0,0), scale, na.value=NA) {
  # 'phase+1' is the position of the [1,1] corner of the new matrix
  #  expressed in the coordinates of the old matrix.
  # 'scale' is the size of one step in the new matrix,
  #  expressed in the coordinates of the old matrix.
  # Both 'phase' and 'scale' can take any real value.
  olddim <- dim(mat)
  if(missing(scale)) scale <- (olddim - 1)/(newdim - 1)
  scale <- ensure2vector(scale)
  newdim  <- ensure2vector(newdim)
  newmat <- matrix(na.value, newdim[1], newdim[2])
  newrow <- 1:newdim[1]
  newcol <- 1:newdim[2]
  oldrow <- round(1 + phase[1] + (newrow-1) * scale[1])
  oldcol <- round(1 + phase[2] + (newcol-1) * scale[2])
  oldrow.ok <- (oldrow >= 1) & (oldrow <= olddim[1])
  oldcol.ok <- (oldcol >= 1) & (oldcol <= olddim[2])
  newmat[oldrow.ok, oldcol.ok] <- mat[oldrow[oldrow.ok],
                                      oldcol[oldcol.ok]]
  return(newmat)
}

# common invocation of matrixsample

rastersample <- function(X, Y) {
  stopifnot(is.im(X) || is.mask(X))
  stopifnot(is.im(Y) || is.mask(Y))
  phase <- c((Y$yrow[1] - X$yrow[1])/X$ystep,
             (Y$xcol[1] - X$xcol[1])/X$xstep)
  scale <- c(Y$ystep/X$ystep,
             Y$xstep/X$xstep)
  if(is.im(X)) {
    # resample an image
    if(!is.im(Y))
      Y <- as.im(Y)
    Xtype <- X$type
    Xv    <- X$v
    # handle factor-valued image as integer
    if(Xtype == "factor") 
      Xv <- array(as.integer(Xv), dim=X$dim)
    # resample
    naval <- switch(Xtype,
                 factor=,
                 integer= NA_integer_, 
                 logical = as.logical(NA_integer_), 
                 real = NA_real_, 
                 complex = NA_complex_, 
                 character = NA_character_,
                 NA)
    Y$v <- matrixsample(Xv, Y$dim, phase=phase, scale=scale, na.value=naval)
    # inherit pixel data type from X
    Y$type <- Xtype
    if(Xtype == "factor") {
      Y$v <- factor(Y$v, labels=levels(X))
      dim(Y$v) <- Y$dim
    }
  } else {
    # resample a mask
    if(!is.mask(Y)) Y <- as.mask(Y)
    Y$m <- matrixsample(X$m, Y$dim, phase=phase, scale=scale, na.value=FALSE)
  }
  return(Y)
}

pointgrid <- function(W, ngrid) {
  W <- as.owin(W)
  masque <- as.mask(W, dimyx=ngrid)
  rxy <- rasterxy.mask(masque, drop=TRUE)
  xx <- rxy$x
  yy <- rxy$y
  return(ppp(xx, yy, W))
}

# text magic

commasep <- function(x, join=" and ", flatten=TRUE) {
  px <- paste(x)
  nx <- length(px)
  if(nx <= 1) return(px)
  commas <- c(rep(", ", length(px)-2),
              join,
              "")
  out <- paste0(px, commas, collapse=if(flatten) "" else NULL)
  return(out)
}

paren <- function(x, type="(") {
  switch(type,
         "(" = {
           out <- paste("(", x, ")", sep="")
         },
         "[" = {
           out <- paste("[", x, "]", sep="")
         },
         "{" = {
           out <- paste("{", x, "}", sep="")
         },
         stop(paste("Unrecognised parenthesis type:", sQuote(type)))
         )
  out
}

unparen <- function(x) {
  x <- as.character(x)
  firstchar <- substr(x, 1, 1)
  n <- nchar(x)
  lastchar <- substr(x, n, n)
  enclosed <- n > 2 & (
                       (firstchar == "(" & lastchar == ")") |
                       (firstchar == "[" & lastchar == "]") |
                       (firstchar == "{" & lastchar == "}") )
  if(any(enclosed))
    x[enclosed] <- substr(x[enclosed], 2, n-1)
  return(x)
}

strsplitretain <- local({
  strsplitretain <- function(x, split=",") {
    ## split strings after occurrence of character b, but retain b
    y <- strsplit(x, split)
    lapply(y, addback, b=split)
  }
  addback <- function(x, b=",") {
    n <- length(x)
    if(n <= 1) x else c(paste0(x[-n], b), x[n])
  }    
  strsplitretain
})

truncline <- function(x, nc) {
  if(length(x) > 1)
    return(unlist(lapply(as.list(x), truncline, nc=nc)))
  ## split string into words
  y <- strsplit(x, " ", fixed=TRUE)[[1]]
  ## find max number of whole words that take up nc characters
  maxwords <- max(0, which(cumsum(nchar(y) + 1) <= nc+1))
  if(maxwords == length(y))
    return(x)
  ## truncation will occur.
  pad <- " [..]"
  nc <- nc - nchar(pad)
  maxwords <- max(0, which(cumsum(nchar(y) + 1) <= nc+1))
  z <- paste(y[seq_len(maxwords)], collapse=" ")
  d <- nc - nchar(z)
  if(d < 0)
    z <- substr(z, 1, nc)
  z <- paste0(z, pad)
  return(z)
}

fakecallstring <- function(fname, parlist) {
  cl <- do.call("call", append(list(name = fname), parlist))
  return(format(cl))
}

prange <- function(x) {
  stopifnot(length(x) == 2)
  paren(paste(x, collapse=", "), "[")
}

  
ordinal <- function(k) {
  last <- abs(k) %% 10
  lasttwo <- abs(k) %% 100
  isteen <- (lasttwo > 10 & lasttwo < 20)
  ending <- ifelse(isteen, "th",
                   ifelse(last == 1, "st",
                          ifelse(last == 2, "nd",
                                 ifelse(last == 3, "rd",
                                        "th"))))
  return(paste(k, ending, sep=""))
}

# equivalent to rev(cumsum(rev(x)))

revcumsum <- function(x) {
  n <- length(x)
  if(identical(storage.mode(x), "integer")) {
    z <- .C("irevcumsum",
            x=as.integer(x),
            as.integer(n))
#            PACKAGE="spatstat")
    return(z$x)
  } else {
    z <- .C("drevcumsum",
            x=as.double(x),
            as.integer(n))
#            PACKAGE="spatstat")
    return(z$x)
  }
}

prolongseq <- function(x, newrange, step=NULL) {
  ## Extend a sequence x so that it covers the new range.
  stopifnot(length(newrange) == 2 && newrange[1] < newrange[2])
  ## Check 'x' is an evenly-spaced sequence
  if(length(x) > 1) {
    dx <- diff(x)
    if(any(dx <= 0))
      stop("x must be an increasing sequence")
    if(diff(range(dx)) > 0.01 * abs(mean(dx)))
      stop("x must be evenly spaced")
  }
  ## Infer step length
  if(!is.null(step)) {
    check.1.real(step)
    stopifnot(step > 0)
  } else if(length(x) > 1) {
    step <- mean(dx)
  } else stop("step is needed when x is a single value")

  ## 
  if(max(x) < newrange[1] || min(x) > newrange[2])
    stop("x lies entirely outside the desired range")
    
  ## add or trim data to left
  if(x[1] > newrange[1]) {
    leftbit <- seq(from=x[1], to=newrange[1], by= -step)[-1]
    x <- c(rev(leftbit), x)
    nleft <- length(leftbit)
  } else {
    nx <- length(x)
    x <- x[x >= newrange[1]]
    nleft <- length(x) - nx
  }

  # add or trim data to right
  nx <- length(x)
  if(newrange[2] > x[nx]) {
    rightbit <- seq(from=x[nx], to=newrange[2], by= step)[-1]
    x <- c(x, rightbit)
    nright <- length(rightbit)
  } else {
    x <- x[x <= newrange[2]]
    nright <- length(x) - nx
  }
  attr(x, "nleft") <- nleft
  attr(x, "nright") <- nright
  return(x)
}

intersect.ranges <- function(a, b, fatal=TRUE) {
  if(!is.null(a) && !is.null(b)) {
    lo <- max(a[1],b[1])
    hi <- min(a[2],b[2])
    if(lo <= hi)
      return(c(lo, hi))
  }
  if(fatal) stop("Intersection is empty")
  return(NULL)
}

inside.range <- function(x, r) {
  stopifnot(length(r) == 2 && r[1] <= r[2])
  return(x >= r[1] & x <= r[2])
}

check.in.range <- function(x, r, fatal=TRUE) {
  xname <- deparse(substitute(x))
  if(inside.range(x, r))
    return(TRUE)
  if(fatal) 
    stop(paste(xname, "should be a number between",
               r[1], "and", r[2]),
         call.=FALSE)
  return(FALSE)
}

startinrange <- function(x0, dx, r) {
  ## find y = x0 + n * dx such that y \in r
  if(all(inside.range(x0, r))) return(x0)
  stopifnot(is.numeric(dx) && length(dx) == 1)
  y <- x0 + dx * round((mean(r) - x0)/dx)
  y[!inside.range(y, r)] <- NA
  return(y)
}

prettyinside <- function(x, ...) {
  r <- range(x, na.rm=TRUE)
  if(diff(r) == 0) return(r[1])
  p <- pretty(x, ...)
  ok <- inside.range(p, r)
  return(p[ok])
}

prettydiscrete <- function(x, n=10) {
  nx <- length(x)
  dx <- nx %/% n
  if(dx < 1) return(x)
  i <- 1 + (0:(n-1)) * dx
  return(x[i])
}


check.range <- function(x, fatal=TRUE) {
  xname <- deparse(substitute(x))
  if(is.numeric(x) && identical(x, range(x, na.rm=TRUE)))
    return(TRUE)
  if(fatal) 
    stop(paste(xname, "should be a vector of length 2 giving (min, max)"))
  return(FALSE)
}
                        
niceround <- function(x, m=c(1,2,5,10)) {
  expo <- 10^as.integer(floor(log10(x)))
  y <- m * expo
  z <- y[which.min(abs(y - x))]
  return(z)
}

progressreport <- function(i, n, every=min(100,max(1, ceiling(n/100))),
                           nperline=min(charsperline,
                             every * ceiling(charsperline /(every+3))),
                           charsperline=60,
                           style=spatstat.options("progress")) {
  missevery <- missing(every)
  if(i > n) {
    warning(paste("progressreport called with i =", i, "> n =", n))
    return(invisible(NULL))
  }
  switch(style,
         txtbar={
           if(i == 1) {
             # initialise text bar
             putSpatstatVariable("Spatstat.ProgressBar",
                                 txtProgressBar(1, n, 1, style=3))
           } else {
             # get text bar
             pbar <- getSpatstatVariable("Spatstat.ProgressBar")
             # update 
             setTxtProgressBar(pbar, i)
             if(i == n) {
               close(pbar)
               putSpatstatVariable("Spatstat.ProgressBar", NULL)
             } 
           }
         },
         tty={
           now <- proc.time()
           if(i == 1) {
             # Initialise stuff
             if(missevery && every > 1 && n > 10) {
               every <- niceround(every)
               nperline <- min(charsperline,
                               every * ceiling(charsperline /(every+3)))
             }
             showtime <- FALSE
             showevery <- n
             putSpatstatVariable("Spatstat.ProgressData",
                                 list(every=every, nperline=nperline,
                                      starttime=now,
                                      showtime=FALSE, showevery=n))
           } else {
             pd <- getSpatstatVariable("Spatstat.ProgressData")
             if(is.null(pd))
               stop(paste("progressreport called with i =", i, "before i = 1"))
             every     <- pd$every
             nperline  <- pd$nperline
             showtime  <- pd$showtime
             showevery <- pd$showevery
             if(i < n) {
               # estimate time remaining
               starttime <- pd$starttime
               elapsed <- now - starttime
               elapsed <- unname(elapsed[3])
               rate <- elapsed/(i-1)
               remaining <- rate * (n-i)
               if(!showtime) {
                 # show time remaining if..
                 if(rate > 20) {
                   # .. rate is very slow
                   showtime <- TRUE
                   showevery <- 1
                 } else if(remaining > 180) {
                   # ... more than 3 minutes remaining
                   showtime <- TRUE
                   showevery <- every
                   aminute <- ceiling(60/rate)
                   if(aminute < showevery) 
                     showevery <- min(niceround(aminute), showevery)
                 }
               }
               putSpatstatVariable("Spatstat.ProgressData",
                                   list(every=every, nperline=nperline,
                                        starttime=starttime,
                                        showtime=showtime, showevery=showevery))
             }
           }
           if(i == n) 
             cat(paste(" ", n, ".\n", sep=""))
           else if(every == 1 || i <= 3)
             cat(paste(i, ",", if(i %% nperline == 0) "\n" else " ", sep=""))
           else {
             if(i %% every == 0) 
               cat(i)
             else
               cat(".")
             if(i %% nperline == 0)
               cat("\n")
           }
           if(i < n && showtime && (i %% showevery == 0)) {
             st <- paste("etd", codetime(round(remaining)))
             st <- paren(st, "[")
             cat(paste("", st, ""))
           }
           flush.console()
         },
         stop(paste("Unrecognised option for style:", dQuote(style)))
         )
  return(invisible(NULL))
}
  
numalign <- function(i, nmax, zero="0") {
  stopifnot(i <= nmax)
  nplaces <- as.integer(ceiling(log10(nmax+1)))
  out <- paste(rep(zero, nplaces), collapse="")
  istring <- paste(i)
  ilen <- nchar(istring)
  substr(out, nplaces-ilen+1, nplaces) <- istring
  return(out)
}

as2vector <- function(x) {
  ## convert various wacky formats to numeric vector of length 2
  ## for use as coordinates of a single point.
  xname <- deparse(substitute(x))
  if(is.numeric(x)) {
    if(length(x) != 2)
      stop(paste(xname, "should have length 2"))
    return(x)
  }
  if(is.ppp(x)) {
    if(npoints(x) != 1)
      stop(paste(xname, "should consist of exactly one point"))
    return(c(x$x, x$y))
  }
  if(is.list(x) && all(c("x", "y") %in% names(x))) {
    if(length(x$x) != 1) stop(paste0(xname, "$x should have length 1"))
    if(length(x$y) != 1) stop(paste0(xname, "$y should have length 1"))
    return(c(x$x, x$y))
  }
  stop(paste("Format of", sQuote(xname), "not understood"))
}

ensure2vector <- function(x) {
  xname <- deparse(substitute(x))
  if(!is.numeric(x))
    stop(paste(xname, "is not numeric"))
  n <- length(x)
  if(n == 0 || n > 2)
    stop(paste(xname, "should be of length 1 or 2"))
  if(n == 1)
    return(rep(x,2))
  return(x)
}

ensure3Darray <- function(x) {
  nd <- length(dim(x))
  if(nd == 0) {
    x <- array(x, dim=c(length(x), 1, 1))
  } else if(nd == 2) {
    x <- array(x, dim=c(dim(x), 1))
  } else if(nd > 3) {
    laterdims <- dim(x)[-(1:3)]
    if(any(laterdims != 1))
      stop("Higher-dimensional array cannot be reduced to 3 dimensions")
    x <- array(x, dim=dim(x)[1:3])
  }
  return(x)
}

check.nvector <- function(v, npoints=NULL, fatal=TRUE, things="data points",
                          naok=FALSE, warn=FALSE) {
  # vector of numeric values for each point/thing
  vname <- sQuote(deparse(substitute(v)))
  whinge <- NULL
  if(!is.numeric(v))
    whinge <- paste(vname, "is not numeric")
  else if(!is.atomic(v) || !is.null(dim(v)))  # vector with attributes
    whinge <- paste(vname, "is not a vector")
  else if(!is.null(npoints) && (length(v) != npoints))
    whinge <- paste("The length of", vname,
                    paren(paste0("=", length(v))), 
                    "should equal the number of", things,
                    paren(paste0("=", npoints)))
  else if(!naok && any(is.na(v)))
    whinge <- paste("Some values of", vname, "are NA or NaN")
  #
  if(!is.null(whinge)) {
    if(fatal) stop(whinge)
    if(warn) warning(whinge)
    return(FALSE)
  }
  return(TRUE)
}

check.nmatrix <- function(m, npoints=NULL, fatal=TRUE, things="data points",
                          naok=FALSE, squarematrix=TRUE, matchto="nrow",
                          warn=FALSE) {
  ## matrix of values for each thing or each pair of things
  mname <- sQuote(deparse(substitute(m)))
  whinge <- NULL
  if(!is.matrix(m))
    whinge <- paste(mname, "should be a matrix")
  else if(squarematrix && (nrow(m) != ncol(m)))
    whinge <- paste(mname, "should be a square matrix")
  else if(!naok && any(is.na(m)))
    whinge <- paste("Some values of", mname, "are NA or NaN")
  else if(!is.null(npoints)) {
    if(matchto=="nrow" && nrow(m) != npoints)
      whinge <- paste("Number of rows in", mname,
                      paren(paste0("=", nrow(m))),
                      "does not match number of", things,
                      paren(paste0("=", npoints)))
    else if(matchto=="ncol" && ncol(m) != npoints)
      whinge <- paste("Number of columns in", mname,
                      paren(paste0("=", ncol(m))),
                      "does not match number of", things,
                      paren(paste0("=", npoints)))
  }
  ##
  if(!is.null(whinge)) {
    if(fatal) stop(whinge)
    if(warn) warning(whinge)
    return(FALSE)
  }
  return(TRUE)
}

check.named.vector <- function(x, nam, context="", namopt=character(0)) {
  xtitle <- deparse(substitute(x))
  check.named.thing(x, nam, namopt, sQuote(xtitle),
                    is.numeric(x), "vector", context)
  opt <- namopt %in% names(x)
  return(x[c(nam, namopt[opt])])
}

check.named.list <- function(x, nam, context="", namopt=character(0)) {
  xtitle <- deparse(substitute(x))
  check.named.thing(x, nam, namopt, sQuote(xtitle),
                    is.list(x), "list", context)  
  opt <- namopt %in% names(x)
  return(x[c(nam, namopt[opt])])
}

check.named.thing <- function(x, nam, namopt=character(0), xtitle=NULL,
                              valid=TRUE, type="object", context="",
                              fatal=TRUE) {
  if(is.null(xtitle))
    xtitle <- sQuote(deparse(substitute(x)))
  # check whether names(x) contains all obligatory names 'nam'
  # and possibly some of the optional names 'namopt'
  namesx <- names(x)
  omitted <- !(nam %in% namesx)
  foreign <- !(namesx %in% c(nam, namopt))
  if(valid && !any(omitted) && !any(foreign))
    return(character(0))
  # some condition violated
  if(nzchar(context))
    xtitle <- paste(context, xtitle)
  whinge <- paste(xtitle,
                  "must be a named", paste(type, ",", sep=""),
                  "with components", commasep(nam))
  if(length(namopt) > 0)
    whinge <- paste(whinge, paren(paste("and optionally", commasep(namopt))))
  if(any(omitted)) {
    grizzle <- paste(ngettext(sum(omitted), "parameter", "parameters"),
                     commasep(nam[omitted]),
                     "omitted")
    whinge <- paste(whinge, grizzle, sep="; ")
  }
  if(any(foreign)) {
    grizzle <- paste(ngettext(sum(foreign), "component", "components"),
                     commasep(namesx[foreign]),
                     "not recognised")
    whinge <- paste(whinge, grizzle, sep="; ")
  }
  if(fatal)
    stop(whinge, call.=FALSE)
  return(whinge)
}


forbidNA <- function(x, context="", xname, fatal=TRUE, usergiven=TRUE) {
  if(missing(xname)) xname <- sQuote(deparse(substitute(x)))
  if(any(is.na(x))) {
    if(usergiven) {
      # argument came from user
      offence <- ngettext(length(x), "be NA", "contain NA values")
      whinge <- paste(context, xname, "must not", offence)
    } else {
      # argument was computed internally
      violates <- ngettext(length(x), "is NA", "contains NA values")
      whinge <- paste(context, xname, violates)
    }
    if(fatal) stop(whinge, call.=FALSE)
    warning(whinge, call.=FALSE)
    return(FALSE)
  }
  return(TRUE)
}

check.finite <- function(x, context="", xname, fatal=TRUE, usergiven=TRUE) {
  if(missing(xname)) xname <- sQuote(deparse(substitute(x)))
  forbidNA(x, context, xname, fatal=fatal, usergiven=usergiven)
  if(any(!is.finite(x))) {
    if(usergiven) {
      # argument came from user
      oblige <- ngettext(length(x),
                         "be a finite value", "contain finite values")
      whinge <- paste(context, xname, "must", oblige)
    } else {
      # argument was computed internally
      violates <- ngettext(length(x),
                           "is not finite", "contains non-finite values")
      whinge <- paste(context, xname, violates)
    }
    if(fatal) stop(whinge, call.=FALSE)
    warning(whinge, call.=FALSE)
    return(FALSE)
  }
  return(TRUE)
}

evenly.spaced <- function(x, tol=1e-07) {
  # test whether x is evenly spaced and increasing
  dx <- diff(x)
  if(any(dx <= .Machine$double.eps))
    return(FALSE)
  # The following test for equal spacing is used in hist.default
  if(diff(range(dx)) > tol * mean(dx))
    return(FALSE)
  return(TRUE)
}

adjustthinrange <- function(ur,vstep,vr) {
  if(diff(ur) >= vstep) return(ur)
  ur <- mean(ur) + c(-1,1) * vstep/2
  if(ur[1] < vr[1]) ur <- vr[1] + c(0,1)*vstep
  if(ur[2] > vr[2]) ur <- vr[2] - c(1,0)*vstep
  return(ur)
}

validposint <- function(n, caller, fatal=TRUE) {
  nname <- deparse(substitute(n))
  if(length(n) != 1 || n != round(n) || n <=0) {
    if(!fatal)
      return(FALSE)
    prefix <- if(!missing(caller)) paste("In ", caller, ",", sep="") else NULL
    stop(paste(prefix, nname, "should be a single positive integer"),
         call.=FALSE)
  }
  return(TRUE)
}

# wrangle data.frames

firstfactor <- function(x) {
  stopifnot(is.data.frame(x) || is.hyperframe(x))
  isfac <- unlist(lapply(as.list(x), is.factor))
  if(!any(isfac)) 
    return(NULL)
  return(x[, min(which(isfac)), drop=TRUE])
}

onecolumn <- function(m) {
  switch(markformat(m),
         none=stop("No marks provided"),
         vector=m,
         dataframe=m[,1, drop=TRUE],
         NA)
}

# errors and checks

complaining <- function(whinge, fatal=FALSE, value=NULL) {
  if(fatal) stop(whinge, call.=FALSE)
  warning(whinge, call.=FALSE)
  return(value)
}

check.1.real <- function(x, context="", fatal=TRUE) {
  xname <- deparse(substitute(x))
  if(!is.numeric(x) || length(x) != 1) {
    whinge <-  paste(sQuote(xname), "should be a single number")
    if(nzchar(context)) whinge <- paste(context, whinge)
    return(complaining(whinge, fatal=fatal, value=FALSE))
  }
  return(TRUE)
}

check.1.integer <- function(x, context="", fatal=TRUE) {
  xname <- deparse(substitute(x))
  if(!is.numeric(x) || length(x) != 1 || !is.finite(x) || x %% 1 != 0) {
    whinge <-  paste(sQuote(xname), "should be a single finite integer")
    if(nzchar(context)) whinge <- paste(context, whinge)
    return(complaining(whinge, fatal=fatal, value=FALSE))
  }
  return(TRUE)
}

explain.ifnot <- function(expr, context="") {
  ex <- deparse(substitute(expr))
  ans <- expr
  if(!(is.logical(ans) && length(ans) == 1 && ans))
    stop(paste(context, "it must be TRUE that", sQuote(ex)), call.=FALSE)
}

warn.ignored.args <- function(..., context=NULL) {
  if((narg <- length(list(...))) > 0) {
    whinge <- paste(narg, "unrecognised",
                    ngettext(narg, "argument was", "arguments were"),
                    "ignored")
    if(!is.null(context)) whinge <- paste(context, whinge)
    warning(context)
  }
}

multiply.only.finite.entries <- function(x, a) {
  # In ppm a potential value that is -Inf must remain -Inf
  # and a potential value that is 0 multiplied by NA remains 0
  y <- x
  ok <- is.finite(x) & (x != 0)
  y[ok] <- a * x[ok]
  return(y)
}

singlestring <- function(s, coll="") {
  s <- as.character(s)
  if(length(s) > 1)
    s <- paste(s, collapse=coll)
  return(s)
}

verbalogic <- function(x, op="and") {
  stopifnot(is.character(x))
  istrue <- (x == "TRUE")
  isfalse <- (x == "FALSE")
  isvariable <- !istrue & !isfalse
  y <- x[isvariable]
  switch(op,
         and={
           if(any(isfalse))
             return("FALSE")
           if(all(istrue))
             return("TRUE")
           return(paste(y, collapse=" and "))
         },
         or={
           if(all(isfalse))
             return("FALSE")
           if(any(istrue))
             return("TRUE")
           return(paste(y, collapse=" or "))
         },
         not={
           x[isfalse] <- "TRUE"
           x[istrue] <- "FALSE"
           x[isvariable] <- paste("not {", y, "}")
         },
         stop(paste("Unrecognised operation", sQuote(op))))
}

sensiblevarname <- function(guess, fallback, maxlen=12) {
  out <- if(is.character(guess) &&
            length(guess) == 1  &&
            make.names(guess) == guess) guess else fallback
  out <- substr(out, 1, maxlen)
  return(out)
}

## deparse() can sometimes be equivalent to dumping the whole object
short.deparse <- function(x, maxlen=60) {
  deparse(x,
          nlines=1,
          width.cutoff=maxlen,
          control="delayPromises")
}

## deparse() can produce multiple lines of text
flat.deparse <- function(x) {
  y <- paste(deparse(x), collapse=" ")
  y <- gsub("\n", " ", y)
  y <- gsub(" ", "", y)
  return(y)
}

good.names <- function(nama, defaults, suffices) {
  # ensure sensible, unique names 
  stopifnot(is.character(defaults))
  if(!missing(suffices))
    defaults <- paste(defaults, suffices, sep="")
  result <- nama
  if(is.null(result))
    result <- defaults
  else if(any(blank <- !nzchar(result)))
    result[blank] <- defaults[blank]
  if(anyDuplicated(result))
    result <- make.names(result, unique=TRUE)
  return(result)
}

cat.factor <- function (..., recursive=FALSE) {
  lll <- list(...)
  chk <- sapply(lll,is.factor)
  if(!all(chk))
    stop("First argument is a factor and at least one other argument is not.\n")
  lll <- lapply(lll,as.data.frame,nm="v1")
  return(do.call(rbind,lll)[,1])
}

nzpaste <- function(..., sep=" ", collapse=NULL) {
  # Paste only the non-empty strings
  v <- list(...)
  ok <- unlist(lapply(v, function(z) {any(nzchar(z))}))
  do.call("paste", append(v[ok], list(sep=sep, collapse=collapse)))
}

substringcount <- function(x, y) {
  ## count occurrences of 'x' in 'y'
  yy <- paste0("a", y, "a")
  splot <- strsplit(yy, split=x, fixed=TRUE)
  nhits <- unlist(lapply(splot, length)) - 1
  return(nhits)
}

is.parseable <- function(x) {
  unlist(lapply(x, function(z) {
    !inherits(try(parse(text=z), silent=TRUE), "try-error")
  }))
}

make.parseable <- function(x) {
  if(all(is.parseable(x))) x else make.names(x)
}

# paste(expression(..)) seems to be broken

paste.expr <- function(x) {
  unlist(lapply(x, function(z) { paste(deparse(z), collapse="") }))
}

#   gsub(".", replacement, x) but only when "." appears as a variable

gsubdot <- function(replacement, x) {
  x <- as.character(x)
  stopifnot(length(x) == 1)
  # find all positions of "." in x
  dotpos <- gregexpr("\\.", x)[[1]]
  if(all(dotpos == -1)) return(x)
  # find all positions of "." preceded or followed by alphanumeric
  dotbefore <- gregexpr("\\.[0-9A-Za-z]", x)[[1]]
  dotafter <- gregexpr("[0-9A-Za-z]\\.", x)[[1]] - 1
  # exclude them
  dotpos <- setdiff(dotpos, union(dotbefore, dotafter))
  #
  if(length(dotpos) == 0) return(x)
  lenrep <-length(replacement)
  while(length(dotpos) > 0) {
    dp <- dotpos[1]
    x <- paste0(substr(x, 0, dp-1), replacement, substr(x, dp+1, nchar(x)))
    dotpos <- dotpos[-1] + lenrep-1
  }
  return(x)
}

badprobability <- function(x, NAvalue=NA) {
  ifelse(is.na(x), NAvalue, !is.finite(x) | x < 0 | x > 1)
}

# test for equivalence of two functions 
samefunction <- function(f, g) {
  identical(deparse(f), deparse(g))
}

codetime <- local({
  uname <- c("min", "hours", "days", "years",
             "thousand years", "million years", "billion years")
  u1name <- c("min", "hour", "day", "year",
             "thousand years", "million years", "billion years")
  multiple <- c(60, 60, 24, 365, 1e3, 1e3, 1e3)
  codehms <- function(x) {
    sgn <- if(x < 0) "-" else ""
    x <- round(abs(x))
    hours <- x %/% 3600
    mins  <- (x %/% 60) %% 60
    secs  <- x %% 60
    h <- if(hours > 0) paste(hours, ":", sep="") else ""
    started <- (hours > 0)
    m <- if(mins > 0) {
      paste(if(mins < 10 && started) "0" else "", mins, ":", sep="")
    } else if(started) "00:" else ""
    started <- started | (mins > 0)
    s <- if(secs > 0) {
      paste(if(secs < 10 && started) "0" else "", secs, sep="")
    } else if(started) "00" else "0"
    if(!started) s <- paste(s, "sec")
    paste(sgn, h, m, s, sep="")
  }
  codetime <- function(x, hms=TRUE, what=c("elapsed","user","system")) {
    if(inherits(x, "proc_time")) x <- summary(x)[[match.arg(what)]] 
    if(!is.numeric(x) || length(x) != 1)
      stop("codetime: x must be a proc_time object or a single number")
    sgn <- if(x < 0) "-" else ""
    x <- abs(x)
    if(x < 60)
      return(paste(sgn, signif(x, 3), " sec", sep=""))
    # more than 1 minute: round to whole number of seconds
    x <- round(x)
    if(hms && (x < 60 * 60 * 24))
      return(paste(sgn, codehms(x), sep=""))
    u <- u1 <- "sec"
    for(k in seq_along(multiple)) {
      if(x >= multiple[k]) {
        x <- x/multiple[k]
        u <- uname[k]
        u1 <- u1name[k]
      } else break
    }
    xx <- round(x, 1)
    ux <- if(xx == 1) u1 else u
    paste(sgn, xx, " ", ux, sep="")
  }
  codetime
})

# defines the current favorite algorithm for 'order' 
fave.order <- function(x) { sort.list(x, method="quick", na.last=NA) }

# convert any appropriate subset index for a point pattern
# to a logical vector

ppsubset <- function(X, I) {
  Iname <- deparse(substitute(I))
  # I could be a function to be applied to X
  if(is.function(I)) {
    I <- I(X)
    if(!is.vector(I)) {
      warning(paste("Function", sQuote(Iname), "did not return a vector"),
              call.=FALSE)
      return(NULL)
    }
  }      
  # I is now an index vector
  n <- npoints(X)
  i <- try(seq_len(n)[I])
  if(inherits(i, "try-error") || any(is.na(i))) {
    warning(paste("Invalid subset index", sQuote(Iname)),
            call.=FALSE)
    return(NULL)
  }
  if(is.logical(I))
    return(I)
  # convert to logical
  Z <- rep.int(FALSE, n)
  Z[I] <- TRUE
  return(Z)
}


trap.extra.arguments <- function(..., .Context="", .Fatal=FALSE) {
  z <- list(...)
  if((narg <- length(z)) == 0) return(FALSE)
  nama <- names(z)
  named <- nzchar(nama)
  whinge <- paste(.Context, ":", sep="")
  if(any(named)) {
    # some arguments are named: ensure all are named
    nama <- sQuote(nama)
    if(!all(named)) 
      nama[!named] <- paste("[Arg", 1:length(nama), ,"]", sep="")[!named]
    whinge <- paste(whinge,
                    "unrecognised",
                    ngettext(narg, "argument", "arguments"),
                    commasep(nama),
                    ngettext(narg, "was", "were"), "ignored")
  } else {
    # all arguments unnamed
    whinge <- paste(whinge, 
                    narg, "unrecognised",
                    ngettext(narg, "argument was", "arguments were"),
                    "ignored")   
  }
  if(.Fatal) stop(whinge, call.=FALSE) else warning(whinge, call.=FALSE)
  return(TRUE)
}

dotexpr.to.call <- function(expr, dot="funX", evaluator="eval.fv") {
  # convert an expression into a function call
  # replacing "." by the specified variable 
  stopifnot(is.expression(expr))
  aa <- substitute(substitute(ee, list(.=as.name(d))),
                   list(ee=expr, d=dot))
  bb <- eval(parse(text=deparse(aa)))
  cc <- as.call(bb)
  cc[[1]] <- as.name("eval.fv")
  return(cc)
}

inject.expr <- function(base, expr) {
  ## insert an expression inside a call and parse it
  txt <- sub(".", as.character(expr), as.character(base), fixed=TRUE)
  parse(text=txt)
}

  
## Match variable names to objects in 'data' list or environment
getdataobjects <- function(nama, envir, datalist=NULL, fatal=FALSE) {
  if(is.null(nama)) return(NULL)
  stopifnot(is.character(nama))
  n <- length(nama)
  y <- vector(mode="list", length=n)
  names(y) <- nama
  if(!is.null(datalist)) {
    hit <- nama %in% names(datalist)
    if(any(hit))
      y[hit] <- as.list(datalist)[nama[hit]]
    external <- unlist(lapply(y, is.null))
  } else external <- rep(TRUE, n)
  y[external] <- mget(nama[external], envir=envir,
                    ifnotfound=list(NULL), inherits=TRUE)
  if(fatal && any(bad <- unlist(lapply(y, is.null)))) {
    nbad <- sum(bad)
    stop(paste(ngettext(nbad, "Covariate", "Covariates"),
               commasep(sQuote(nama[bad])),
               ngettext(nbad, "was not found", "were not found")),
         call.=FALSE)
  }
  names(y) <- nama
  attr(y, "external") <- external
  return(y)
}
 
## print names and version numbers of libraries loaded

sessionLibs <- function() {
  a <- sessionInfo()
  b <- unlist(lapply(a$otherPkgs, getElement, name="Version"))
  g <- rbind(names(b), unname(b))
  d <- apply(g, 2, paste, collapse=" ")
  if(length(d) > 0) {
    cat("Libraries loaded:\n")
    for(di in d) cat(paste("\t", di, "\n"))
  } else cat("Libraries loaded: None\n")
  return(invisible(d))
}

dropifsingle <- function(x) if(length(x) == 1) x[[1]] else x

# timed objects

timed <- function(x, ..., starttime=NULL, timetaken=NULL) {
  if(is.null(starttime)) # time starts now.
    starttime <- proc.time()
  # evaluate expression if any
  object <- x
  timetaken <- proc.time() - starttime
  class(object) <- c("timed", class(object))
  attr(object, "timetaken") <- timetaken
  return(object)
}

print.timed <- function(x, ...) {
  # strip the timing information and print the rest.
  taken <- attr(x, "timetaken")
  cx <- class(x)
  attr(x, "timetaken") <- NULL
  class(x) <- cx[cx != "timed"]
  NextMethod("print")
  # Now print the timing info
  cat(paste("\nTime taken:", codetime(taken), "\n"))
  return(invisible(NULL))
}

# wrapper for computing weighted variance of a vector
# Note: this includes a factor 1 - sum(v^2) in the denominator
# where v = w/sum(w). See help(cov.wt)

weighted.var <- function(x, w, na.rm=FALSE) {
  bad <- is.na(w) | is.na(x)
  if(any(bad)) {
    if(!na.rm) return(NA_real_)
    ok <- !bad
    x <- x[ok]
    w <- w[ok]
  }
  cov.wt(matrix(x, ncol=1),w)$cov[]
}

# efficient replacements for ifelse()
# 'a' and 'b' are single values
# 'x' and 'y' are vectors of the same length as 'test'

# ifelse(test, a, b)
ifelseAB <- function(test,  a, b) {
  y <- rep.int(b, length(test))
  y[test] <- a
  return(y)
}

# ifelse(test, a, x)
ifelseAX <- function(test, a, x) {
  y <- x
  y[test] <- a
  return(y)
}

# ifelse(test, x, b)
ifelseXB <- function(test, x, b) {
  y <- rep.int(b, length(test))
  y[test] <- x[test]
  return(y)
}
  
# ifelse(test, x, y)
ifelseXY <- function(test, x, y) {
  z <- y
  z[test] <- x[test]
  return(z)
}

#.... very special cases ......

# ifelse(test, 1, NA)
ifelse1NA <- function(test) {
  y <- as.integer(test)
  y[!test] <- NA
  return(y)
}

# ifelse(test, 0, NA)
ifelse0NA <- function(test) {
  nyet <- !test
  y <- as.integer(nyet)
  y[nyet] <- NA
  return(y)
}

# ifelse(test, -x, x)
ifelseNegPos <- function(test, x) {
  y <- x
  y[test] <- -x[test]
  return(y)
}

# ..................

"%orifnull%" <- function(a, b) {
  if(!is.null(a)) return(a)
  # b is evaluated only now
  return(b)
}

blockdiagmatrix <- function(...) {
  x <- list(...)
  if(!all(unlist(lapply(x, is.matrix))))
    stop("Some of the arguments are not matrices", call.=FALSE)
  nr <- unlist(lapply(x, nrow))
  nc <- unlist(lapply(x, ncol))
  result <- matrix(0, sum(nr), sum(nc))
  rownames(result) <- unlist(lapply(x, rownames))
  colnames(result) <- unlist(lapply(x, colnames))
  rowend <- cumsum(nr)
  rowstart <- c(0, rowend) + 1
  colend <- cumsum(nc)
  colstart <- c(0, colend) + 1
  for(i in seq_along(x))
    result[ (rowstart[i]):(rowend[i]) , (colstart[i]):(colend[i])] <- x[[i]]
  return(result)
}

blockdiagarray <- function(...) {
  x <- list(...)
  if(!all(unlist(lapply(x, is.array))))
    stop("Some of the arguments are not arrays", call.=FALSE)
  dims <- lapply(x, dim)
  dims1 <- unlist(lapply(dims, "[", i=1))
  if(length(dim1 <- unique(dims1)) > 1)
    stop("Arrays have different extents in first dimension")
  dims2 <- unlist(lapply(dims, "[", i=2))
  dims3 <- unlist(lapply(dims, "[", i=3))
  result <- array(0, dim=c(dim1, sum(dims2), sum(dims3)))
  dn <- lapply(x, dimnames)
  dimnames(result)[[2]] <- unlist(lapply(dn, "[[", 2))
  dimnames(result)[[3]] <- unlist(lapply(dn, "[[", 3))
  rowend <- cumsum(dims2)
  rowstart <- c(0, rowend) + 1
  colend <- cumsum(dims3)
  colstart <- c(0, colend) + 1
  for(i in seq_along(x))
    result[ , (rowstart[i]):(rowend[i]) , (colstart[i]):(colend[i])] <- x[[i]]
  return(result)
}

lty2char <- function(i) {
  if(is.numeric(i)) c("blank", "solid", "dashed", "dotted",
                      "dotdash", "longdash", "twodash")[(i %% 7) + 1] else i
}

## convert numeric matrix to character, and blank out lower sub-diagonal.
uptrimat <- function(x) {
  stopifnot(is.matrix(x))
  x[] <- as.character(x)
  x[row(x) > col(x)] <- ""
  return(noquote(x))
}

asNumericMatrix <- function(x) {
  ## workaround for strange artefact of as.matrix.data.frame
  x <- as.matrix(x)
  storage.mode(x) <- "double"
  x
}

prepareTitle <- function(main) {
  ## Count the number of lines in a main title
  ## Convert title to a form usable by plot.owin
  if(is.expression(main)) {
    nlines <- 1
  } else {
    main <- paste(main)
    ## break at newline 
    main <- unlist(strsplit(main, "\n"))
    nlines <- if(sum(nchar(main)) == 0) 0 else length(main)
  }
  return(list(main=main,
              nlines=nlines,
              blank=rep('  ', nlines)))
}

simplenumber <- function(x, unit = "", multiply="*") {
  ## Try to express x as a simple multiple or fraction
  stopifnot(length(x) == 1)
  s <- if(x < 0) "-" else ""
  x <- abs(x)
  if(unit == "") {
    if(x %% 1 == 0) return(paste0(s, round(x)))
    for(i in 1:12) 
      if((i/x) %% 1 == 0) return(paste0(s, i, "/", round(i/x)))
  } else {
    if(x == 0) return("0")
    if(x == 1) return(paste0(s,unit))
    if(x %% 1 == 0) return(paste0(s, round(x), multiply, unit))
    if((1/x) %% 1 == 0) return(paste0(s, unit, "/", round(i/x)))
    for(i in 2:12) 
      if((i/x) %% 1 == 0) return(paste0(s, i, multiply, unit, "/", round(i/x)))
  }
  return(NULL)
}

fontify <- function(x, font="italic") {
  if(!nzchar(font) || font == "plain")
    return(x)
  if(is.character(x))
    return(paste0(font, "(", x, ")"))
  if(is.expression(x)) {
    if((n <- length(x)) > 0) {
      for(i in 1:n) 
        x[[i]] <- fontify(x[[i]], font)
    }
    return(x)
  }
  if(is.language(x) || is.numeric(x)) 
    return(substitute(f(X), list(f=as.name(font), X=x)))
  if(all(sapply(x, is.language)))
    return(lapply(x, fontify))
  return(NULL)
}

dround <- function(x) {
  round(x, getOption('digits'))
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/varblock.R"
#
#   varblock.R
#
#   Variance estimation using block subdivision
#
#   $Revision: 1.14 $  $Date: 2014/09/26 10:04:41 $
#

varblock <- local({

  rvalues <- function(z) { with(z, .x) }

  dofun <- function(domain, fun, Xpp, ...) { fun(Xpp, ..., domain=domain) }

  varblock <- function(X, fun=Kest,
                       blocks=quadrats(X, nx=nx, ny=ny), ..., 
                       nx=3, ny=nx,
                       confidence=0.95) {
    stopifnot(is.ppp(X))
    stopifnot(is.tess(blocks))
    stopifnot(is.function(fun) || is.character(fun))
    if(is.character(fun)) 
      fun <- get(fun, mode="function")
    ## validate confidence level
    stopifnot(confidence > 0.5 && confidence < 1)
    alpha <- 1 - confidence
    probs <- c(alpha/2, 1-alpha/2)
    ## determine whether 'fun' has an argument called 'domain'
    canrestrict <- ("domain" %in% names(formals(fun))) ||
                   samefunction(fun, pcf) ||
                   samefunction(fun, Lest)
    ## check there's at least one point in each block
    Y <- split(X, blocks)
    nums <- sapply(Y, npoints)
    blockok <- (nums > 0)
    if(some.zeroes <- any(!blockok)) 
      warning("Some tiles contain no data: they are discarded")
    if(!canrestrict) {
      ## divide data into disjoint blocks
      if(some.zeroes)
        Y <- Y[blockok]
      n <- length(Y)
      if(n <= 1) stop("Need at least 2 blocks")
      ## apply 'fun' to each block
      if(any(c("r", "breaks") %in% names(list(...)))) {
        ## r vector specified
        fX <- fun(X, ...)
        z <- lapply(Y, fun, ...)
      } else {
        ## need to ensure compatible fv objects
        z <- lapply(Y, fun, ...)
        rmaxes <- unlist(lapply(z, function(x){ max(rvalues(x)) }))
        smallest <- which.min(rmaxes)
        r <- rvalues(z[[smallest]])
        z <- lapply(Y, fun, ..., r=r)
        fX <- fun(X, ..., r=r)
      }
    } else {
      ## use 'domain' argument of 'fun' to compute contributions from each tile
      B <- tiles(blocks)
      if(some.zeroes)
        B <- B[blockok]
      n <- length(B)
      if(any(c("r", "breaks") %in% names(list(...)))) {
        ## r vector specified
        fX <- fun(X, ...)
        z <- lapply(B, dofun, ..., fun=fun, Xpp=X)
      } else {
        ## need to ensure compatible fv objects
        z <- lapply(B, dofun, ..., fun=fun, Xpp=X)
        rmaxes <- unlist(lapply(z, function(x){ max(rvalues(x)) }))
        smallest <- which.min(rmaxes)
        r <- rvalues(z[[smallest]])
        z <- lapply(B, dofun, ..., fun=fun, Xpp=X, r=r)
        fX <- fun(X, ..., r=r)
      }
    }
    ## find columns that are common to all estimates
    zzz <- reconcile.fv(append(list(fX), z))
    fX <- zzz[[1]]
    z <- zzz[-1]
    ## sample mean
    m <- meanlistfv(z)
    ## sample variance
    sqdev <- lapply(z, function(x,m){ eval.fv((x-m)^2, dotonly=FALSE) }, m=m)
    v <- meanlistfv(sqdev)
    v <- eval.fv(v * n/(n-1), dotonly=FALSE)
    ## sample standard deviation
    sd <- eval.fv(sqrt(v), dotonly=FALSE)
    ## upper and lower limits
    sem <- eval.fv(sd/sqrt(n), dotonly=FALSE)
    zcrit <- qnorm(probs)
    lower <- eval.fv(m + zcrit[1] * sem, dotonly=FALSE)
    upper <- eval.fv(m + zcrit[2] * sem, dotonly=FALSE)
    ## rebadge
    fva <- .Spatstat.FvAttrib
    fva <- fva[fva %in% names(attributes(fX))]
    attributes(m)[fva] <- attributes(v)[fva] <- attributes(sd)[fva] <- 
        attributes(upper)[fva] <- attributes(lower)[fva] <- attributes(fX)[fva]
    m <- prefixfv(m, "mean", "sample mean of", "bold(mean)~")
    v <- prefixfv(v, "var", "estimated variance of", "bold(var)~")
    sd <- prefixfv(sd, "sd", "estimated standard deviation of", "bold(sd)~")
    CItext <- paste(c("lower", "upper"),
                    paste0(100 * confidence, "%%"),
                    "CI limit for")
    lower <- prefixfv(lower, "lo", CItext[1], "bold(lo)~")
    upper <- prefixfv(upper, "hi", CItext[2], "bold(hi)~")
    ## tack together 
    out <- cbind(fX,m,v,sd,upper,lower)
    ## restrict r domain
    bad <- apply(!is.finite(as.matrix(as.data.frame(out))), 1, all)
    rmax <- max(rvalues(out)[!bad])
    alim <- c(0, rmax)
    if(!canrestrict) alim <- intersect.ranges(attr(out, "alim"), alim)
    attr(out, "alim") <- alim
    ## sensible default plot formula
    ybase <- fvnames(fX, ".y")
    xname <- fvnames(fX, ".x")
    tname <- intersect("theo", fvnames(fX, "."))
    fvnames(out, ".y") <- yname <- paste0("mean", ybase)
    fvnames(out, ".s") <- snames <- paste0(c("lo", "hi"), ybase)
    fvnames(out, ".") <- c(yname, snames, tname)
    attr(out, "fmla") <- paste(". ~ ", xname)
    return(out)
  }

  varblock
})


meanlistfv <- local({

  getYmatrix <- function(x, yn=ynames) { as.matrix(as.data.frame(x)[,yn]) }

  meanlistfv <- function(z, ...) {
    ## compute sample mean of a list of fv objects
    if(!is.list(z) || !all(unlist(lapply(z, is.fv))))
      stop("z should be a list of fv objects")
    if(!do.call("compatible", unname(z)))
      stop("Objects are not compatible")
    result <- template <- z[[1]]
    ## extract each object's function values as a matrix
    ynames <- fvnames(template, "*")
    matlist <- unname(lapply(z, getYmatrix, yn=ynames))
    ## stack matrices into an array
    y <- do.call("abind", append(matlist, list(along=3)))
    ## take mean 
    ymean <- apply(y, 1:2, mean, ...)
    result[,ynames] <- ymean
    return(result)
  }

  meanlistfv
})


  
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/vblogistic.R"
#' Variational Bayesian Logistic regression
#' 
#' author: Tuomas Rajala < tuomas.rajala a iki.fi >
#'
#' Copyright (C) Tuomas Rajala 2014
#' GNU Public License GPL 2.0 | 3.0
#' 
#' Special version for 'spatstat'
#'
#'    $Revision: 1.4 $ $Date: 2014/12/17 00:53:11 $
#' 
####################################################
#' Used inside ppm
vblogit.fmla <- function(formula, offset, data, subset, weights,
                            verbose=FALSE, epsilon=0.01, ...) {
  mf <- match.call(expand.dots = FALSE)
  m <- match(c("formula", "data", "subset", "offset"), names(mf), 0L)
  mf <- mf[c(1L, m)]
  mf$drop.unused.levels <- TRUE
  mf[[1L]] <- quote(stats::model.frame)
  mf <- eval(mf, parent.frame())
  mt <- attr(mf, "terms")
  offset <- model.offset(mf)
  y <- model.response(mf, "any")
  X <- model.matrix(mt, mf) 
  colnames(X)[1] <- "(Intercept)"
  Vnames <- colnames(X)
  #' then we fit:
  fit <- vblogit(y=y, X=X, offset=offset, verb=verbose, eps=epsilon, ...)
  #'
  names(fit$coefficients) <- names(fit$coef) <- Vnames
  #' add some variables to conform to summary.ppm
  fit$se <- sqrt(diag(as.matrix(fit$S)))
  fit$call <- match.call(expand.dots=FALSE)
  fit$formula <- formula
  fit$method <- "vblogit"
  fit$model <- mf
  fit$terms <- mt
  fit$offset <- offset
  fit$data <- data
  fit$xlevels <- .getXlevels(mt, mf)
  fit
}
###################################################
# the fitting function:
vblogit <- local({

  ## helper functions needed:
  lambda <- function(x) { -tanh(x/2)/(4*x) }
  mygamma <- function(x) { x/2 - log(1+exp(x)) + x*tanh(x/2)/4 }
  
  vblogit <- function(y, X, offset, eps=1e-2, m0, S0, S0i, xi0,
                      verb=FALSE, maxiter=1000, ...) {
    ## Logistic regression using JJ96 idea. Ormeron00 notation.
    ## p(y, w, t) = p(y | w) p(w | t) p(t) 
    ##
    ## Y ~ Bern(logit(Xw + offset))
    ## w  ~ N(m0, S0) iid
    ##
    ## "*0" are fixed priors.
    ##
    cat2 <- if(verb) cat else function(...) NULL
    varnames <- colnames(data.frame(as.matrix(X[1:2,])))
  
    ## Write 
    N <- length(y)
    K <- ncol(X)
    #'
    #'
    #' offset
    if(missing('offset')) offset <- 0
    if(length(offset)<N) offset <- rep(offset, N)[1:N]
    #'
    #'
    #' Priors and initial estimates.
    if(missing(S0))  S0  <- diag(1e5, K, K)
    if(missing(S0i)) S0i <- solve(S0)
    if(missing(m0))  m0  <- rep(0, K)
    #' Constants:
    oo2 <- offset^2
    LE_CONST <- as.numeric( -0.5*t(m0)%*%S0i%*%m0
                           - 0.5*determinant(S0)$mod
                           + sum((y-0.5)*offset) ) 
    Sm0 <- S0i%*%m0
    #' start values for xi:
    if(missing(xi0))   xi0 <- rep(4, N) # something positive
    if(length(xi0)!=N) xi0 <- rep(xi0, N)[1:N]
  
    est <- list(m=m0, S=S0, Si=S0i, xi=xi0)
    #'
    #'
    #'
    ## loop
    le <- -Inf
    le_hist <- le
    loop <- TRUE
    iter <- 0
    #' initials:
    la <- lambda(xi0)
    Si <- S0i - 2 * t(X*la)%*%X
    S <- solve(Si)
    m <- S%*%( t(X)%*%( (y-0.5) + 2*la*offset ) + Sm0  )
    #'
    #' Main loop:
    while(loop){
      old <- le
      #' update variational parameters
      M <- S+m%*%t(m)
      #' Make sure M is symmetric in case of numerical errors:
      M <- (M+t(M))/2
      L <- t(chol(M))
      V <- X%*%L
      dR <- rowSums(V^2)
      dO <- 2*offset*c(X%*%m)
      xi2 <- dR + dO + oo2
      xi <- sqrt(xi2)
      la <- lambda(xi)
      #' update post covariance
      Si <- S0i - 2 * t(X*la)%*%X
      S <- solve(Si)
      #' update post mean
      m <- S%*%( t(X)%*%( (y-0.5) + 2*la*offset ) + Sm0  )
      #' compute the log evidence
      le <-  as.numeric( 0.5*determinant(S)$mod
                        + sum( mygamma(xi) )
                        + sum(oo2*la)
                        + 0.5*t(m)%*%Si%*%m
                        + LE_CONST)
      #' check convergence 
      devi <- le - old
      if(devi < 0)
        warning("Log-evidence decreasing; try different starting values for xi.")
      loop <- abs(devi) > eps & (iter<-iter+1) <= maxiter
      le_hist <- c(le_hist, le)
      cat2("diff:", devi, "             \r")
    }
    if(iter == maxiter) warning("Maximum iteration limit reached.")
    cat2("\n")
    ## done. Compile:
    est <- list(m=m, S=S, Si=Si, xi=xi, lambda_xi=la)
    #' Marginal evidence
    est$logLik <- le
    #' Compute max logLik with the Bernoulli model;
    #' this should be what glm gives:
    est$logLik_ML <- as.numeric( t(y)%*%(X%*%m+offset)
                                - sum( log( 1 + exp(X%*%m+offset)) ) )
    #' Max loglik with the approximation
    est$logLik_ML2 <- as.numeric(  t(y)%*%(X%*%m + offset)
                                 + t(m)%*%t(X*la)%*%X%*%m
                                 - 0.5*sum(X%*%m)
                                 + sum(mygamma(xi))
                                 + 2*t(offset*la)%*%X%*%m
                                 + t(offset*la)%*%offset
                                 - 0.5 * sum(offset)  )
    #' some additional parts, like in glm output
    est$coefficients <- est$m[,1]
    names(est$coefficients) <- varnames
    est$call <- sys.call()
    est$converged <- !(maxiter==iter)
    #' more additional stuff
    est$logp_hist <- le_hist
    est$parameters <- list(eps=eps, maxiter=maxiter)
    est$priors <- list(m=m0, S=S0)
    est$iterations <- iter
    class(est) <- "vblogit"
    ## return
    est
  }

  vblogit
})


###################################################
#' Predict method
predict.vblogit <- local({

  sigmoid <- function(e) 1/(1+exp(-e))

  predict.vblogit <- function(object, newdata = NULL,
                              type = c("link", "response", "terms"),
                              se.fit = FALSE,
                              dispersion = NULL,
                              terms = NULL,
                              na.action = na.pass, 
                              ...) {
    type <- match.arg(type)
    if(type != "response") stop("type not supported.")
    if(missing(newdata)) {
      stop("not implemented.")
    }
    else{  # newdata
      #' build the new covariate matrix, inspired by predict.lm
      tt <- terms(object)
      Terms <- delete.response(tt)
      m <- model.frame(Terms, newdata, na.action = na.action, 
                       xlev = object$xlevels)
      X <- model.matrix(Terms, m, contrasts.arg = object$contrasts)
      offset <- rep(0, nrow(X))
      if (!is.null(off.num <- attr(tt, "offset"))) 
        for (i in off.num)
          offset <- offset + eval(attr(tt, "variables")[[i + 1]], newdata)
      if (!is.null(object$call$offset)) 
        offset <- offset + eval(object$call$offset, newdata)
      #' predict using probit approximation to logit-function
      mu <- object$m
      S <- object$S
      mua <- as.numeric(X%*%mu)+offset
      s2a <- diag(X%*%S%*%t(X) )
      predictor <- sigmoid( as.numeric( mua/sqrt(1+pi*s2a/8) ) ) 
      names(predictor) <- rownames(X)
    }
    predictor
  }

  predict.vblogit
})



# ###################################################
# print method
print.vblogit <- function(x, ...) {
  splat("Variational Bayes logistic regression fit")
  cat("\nCall: ")
  print(x$call)
  cat("\nCoefficients:\n")
  print(x$coefficients)
  cat("\n")
  splat("Log-likelihood:", x$logLik)
  splat("Converged:", x$converged)
  splat("Convergence threshold:", x$parameters$eps)
  splat("Iterations / max:", x$iterations, "/", x$parameters$maxiter)
  splat("* Caution: the estimates are conditional on convergence.")
  invisible(NULL)
}
####################################################
# vblogit family method
family.vblogit <- function(object, ...) binomial()

####################################################
#' vblogit fit summary method
summary.vblogit <- function(object, ...) {
  splat("Variational Bayes logistic regression fit")
  cat("\nCall: ")
  print(object$call)
  splat("\nCoefficients and posterior 95% central regions:")
  vna <- names(object$coefficients)
  s <- sqrt(diag(object$S))
  q0 <- qnorm(c(0.025, 0.975))
  m <- as.numeric(object$m)
  df <- data.frame(estimate=m,
                   "low 0.05"=m+s*q0[1],
                   "high 97.5"=m+s*q0[2],
                   "prior mean"=object$priors$m,
                   "prior var"=diag(object$priors$S))
  rownames(df) <- vna
  print(df)
  cat("\n")
  splat("Lower bound for log-likelihood:", object$logLik)
  invisible(NULL)
}

####################################################
# Coef
coef.vblogit <- function(object, ...) object$coefficients

####################################################
# Log-evidence
logLik.vblogit <- function(object, ...) {
  object$logLik
}


#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/vcov.kppm.R"
#
# vcov.kppm
#
#  vcov method for kppm objects
#
#   Original code: Abdollah Jalilian
#
#   $Revision: 1.4 $  $Date: 2014/08/27 09:51:02 $
#

vcov.kppm <- function(object, ...,
                      what=c("vcov", "corr", "fisher", "internals"),
                      fast = NULL, rmax = NULL, eps.rmax = 0.01)
{
  what <- match.arg(what)
  verifyclass(object, "kppm")
  if(is.null(object$improve)){#Normal composite likelihood (poisson) case
  # extract composite likelihood results
  po <- object$po
  # ensure it was fitted with quadscheme
  if(is.null(getglmfit(po))) {
    warning("Re-fitting model with forcefit=TRUE")
    po <- update(po, forcefit=TRUE)
  }
  # extract quadrature scheme information
  Q <- quad.ppm(po)
  U <- union.quad(Q)
  nU <- npoints(U)
  wt <- w.quad(Q)
  # compute fitted intensity values
  lambda <- fitted(po, type="lambda")
  # extract covariate values
  Z <- model.matrix(po)
  # extract pcf
  g <- pcfmodel(object)
  # resolve fast option
  if(is.null(fast)){
    fast <- (nU > sqrt(spatstat.options("maxmatrix")))
  }
  if(!is.logical(fast))
      stop("Argument fast must be NULL or logical.")
  # compute pair correlation function minus 1
  if(fast){
    if(!require(Matrix))
      stop(paste("Package Matrix must be installed in order for",
                 "the fast option to work."),
           call.=FALSE)
    if(is.null(rmax)){
        diamwin <- diameter(as.owin(U))
        fnc <- get("fnc", envir = environment(improve.kppm))
        rmax <- if(fnc(diamwin, eps.rmax, g) >= 0) diamwin else
                  uniroot(fnc, lower = 0, upper = diamwin,
                          eps=eps.rmax, g=g)$root
    }
    cp <- crosspairs(U,U,rmax)
    gminus1 <- Matrix::sparseMatrix(i=cp$i, j=cp$j,
                                    x=g(cp$d) - 1, dims=c(nU, nU))
  } else{
    gminus1 <- matrix(g(c(pairdist(U))) - 1, nU, nU)
  }
  # evaluate integral
  ff <- Z * lambda * wt
  J <- t(Z) %*% ff
  E <- t(ff) %*% gminus1 %*% ff
  # asymptotic covariance matrix in the Poisson case
  J.inv <- try(solve(J))
  # could be singular 
  if(inherits(J.inv, "try-error")) {
    if(what == "internals") {
      return(list(ff=ff, J=J, E=E, J.inv=NULL))
    } else {
      return(NULL)
    }
  }
  # asymptotic covariance matrix in the clustered case
  vc <- J.inv + J.inv %*% E %*% J.inv
  #
  } else{#Case of quasi-likelihood (or other things from improve.kppm)
      run <- is.null(object$vcov) || (!is.null(fast) && (fast!=object$improve$fast.vcov))
      if(run){#Calculate vcov if it hasn't already been so or option fast differs from fast.vcov
          args <- object$improve
          internal <- what=="internals"
          if(!is.null(fast))
              args$fast.vcov <- fast
          object <- with(args, improve.kppm(object, type = type,
                                            rmax = rmax, dimyx = dimyx,
                                            fast = fast, vcov = TRUE, fast.vcov = fast.vcov,
                                            maxIter = 0, save.internals = internal))
      }
      vc <- object$vcov
  }
  
  switch(what,
         vcov={ return(vc) },
         corr={
           sd <- sqrt(diag(vc))
           co <- vc/outer(sd, sd, "*")
           return(co)
         },
         fisher={
           fish <- try(solve(vc))
           if(inherits(fish, "try-error")) fish <- NULL 
           return(fish)
         },
         internals={
           return(list(ff=ff, J=J, E=E, J.inv=J.inv, vc=vc))
         })
  stop(paste("Unrecognised option: what=", what))
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/vcov.mppm.R"
#  Variance-covariance matrix for mppm objects
#
# $Revision: 1.9 $ $Date: 2013/11/09 16:55:46 $
#
#
vcov.mppm <- function(object, ..., what="vcov", err="fatal") {

  errhandler <- function(whinge, err) {
    switch(err,
           fatal=stop(whinge),
           warn={
             warning(whinge)
             return(NA)
           },
           null= return(NULL),
           stop(paste("Unrecognised option: err=", dQuote(err))))
  }
    
  whinge <- NULL
  if(object$Fit$fitter != "glm")
    whinge <- "vcov.mppm only implemented for glm fits"
  else if(!is.poisson.mppm(object))
    whinge <- "vcov.mppm only implemented for Poisson processes"

  if(!is.null(whinge))
    return(errhandler(whinge, err))
  
  gf <- object$Fit$FIT
  gd <- object$Fit$moadf
  wt <- gd$.mpl.W
  fi <- fitted(gf)

  fo <- object$trend
  if(is.null(fo)) fo <- (~1)

  mof <- model.frame(fo, gd)
  mom <- model.matrix(fo, mof)
  momnames <- dimnames(mom)[[2]]

  fisher <- sumouter(mom, fi * wt)
  dimnames(fisher) <- list(momnames, momnames)

  switch(what,
         fisher = { return(fisher) },
         vcov   = {
           vc <- try(solve(fisher), silent=(err == "null"))
           if(inherits(vc, "try-error"))
             return(errhandler("Fisher information is singular", err))
           else
             return(vc)
         },
         corr={
           co <- try(solve(fisher), silent=(err == "null"))
           if(inherits(co, "try-error"))
             return(errhandler("Fisher information is singular", err))
           sd <- sqrt(diag(co))
           return(co / outer(sd, sd, "*"))
         })
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/vcov.ppm.R"
##
## Asymptotic covariance & correlation matrices
## and Fisher information matrix
## for ppm objects
##
##  $Revision: 1.112 $  $Date: 2014/12/21 11:31:45 $
##

vcov.ppm <- local({

vcov.ppm <- function(object, ..., what="vcov", verbose=TRUE,
                     fine=FALSE,
                     gam.action=c("warn", "fatal", "silent"),
                     matrix.action=c("warn", "fatal", "silent"),
                     logi.action=c("warn", "fatal", "silent"),
                     hessian=FALSE) {
  verifyclass(object, "ppm")
  argh <- list(...)

  gam.action <- match.arg(gam.action)
  matrix.action <- match.arg(matrix.action)
  logi.action <- match.arg(logi.action)

  if(missing(fine) && ("A1dummy" %in% names(argh))) {
    message("Argument 'A1dummy' has been replaced by 'fine'")
    fine <- as.logical(argh$A1dummy)
  } else fine <- as.logical(fine)
  
  stopifnot(length(what) == 1 && is.character(what))
  what.options <- c("vcov", "corr", "fisher", "Fisher", "internals", "all")
  what.map     <- c("vcov", "corr", "fisher", "fisher", "internals", "all")
  if(is.na(m <- pmatch(what, what.options)))
    stop(paste("Unrecognised option: what=", sQuote(what)))
  what <- what.map[m]

  ## no parameters, no variance
  if(length(coef(object)) == 0) {
    result <- switch(what,
                     vcov=, corr=, fisher= {
                       matrix(, 0, 0)
                     },
                     internals=, all={
                       list()
                     })
    return(result)
  }
  
  ## nonstandard calculations (hack) 
  generic.triggers <- c("A1", "new.coef", "matwt", "saveterms")
  nonstandard <- any(generic.triggers %in% names(argh)) || fine
#  saveterms <- identical(resolve.1.default("saveterms", argh), TRUE)
  
  ## Fisher information *may* be contained in object
  fisher <- object$fisher
  varcov <- object$varcov
  
  ## Do we need to go into the guts?
  needguts <- nonstandard ||
    (is.null(fisher) && what=="fisher") ||
    (is.null(varcov) && what %in% c("vcov", "corr")) ||
    (what %in% c("internals", "all")) 

  ## In general it is not true that varcov = solve(fisher)
  ## because we might use different estimators,
  ## or the parameters might be a subset of the canonical parameter

  if(needguts) {
    ## warn if fitted model was obtained using GAM
    if(identical(object$fitter, "gam")) {
      switch(gam.action,
             fatal={
               stop(paste("model was fitted by gam();",
                          "execution halted because fatal=TRUE"),
                    call.=FALSE)
             },
             warn={
               warning(paste("model was fitted by gam();",
                             "asymptotic variance calculation ignores this"),
                       call.=FALSE)
             },
             silent={})
    }
    ## ++++ perform main calculation ++++
    if((is.poisson(object) || hessian) && object$method != "logi") {
      ## Poisson model, or Hessian of Gibbs model
      results <- vcalcPois(object, ..., what=what,
                           matrix.action=matrix.action,
                           verbose=verbose, fisher=fisher)
    } else {
      ## Gibbs model 
      results <- vcalcGibbs(object, ..., what=what,
                            fine=fine,
                            matrix.action=matrix.action)
    }
    varcov <- results$varcov
    fisher <- results$fisher
    internals  <- results$internals
  }
  
  if(what %in% c("vcov", "corr") && is.null(varcov)) {
    ## Need variance-covariance matrix.
    if(!is.null(fisher) && is.poisson(object)) 
      ## Derive from Fisher information
      varcov <- checksolve(fisher, matrix.action,
                           "Fisher information matrix",
                           "variance")
  }

  out <- switch(what,
                fisher = fisher,
                vcov   = varcov,
                corr   = {
                  if(is.null(varcov)) return(NULL)
                  sd <- sqrt(diag(varcov))
                  varcov / outer(sd, sd, "*")
                },
                internals = internals,
                all = results
                )
  return(out)
}

## ................  variance calculation for Poisson models  .............

vcalcPois <- function(object, ...,
                      what = c("vcov", "corr", "fisher", "internals", "all"),
                      matrix.action=c("warn", "fatal", "silent"),
                      method=c("C", "interpreted"),
                      verbose=TRUE,
                      fisher=NULL, 
                      matwt=NULL, new.coef=NULL,
                      saveterms=FALSE) {
  ## variance-covariance matrix of Poisson model,
  ## or Hessian of Gibbs model
  what <- match.arg(what)
  method <- match.arg(method)
  matrix.action <- match.arg(matrix.action)
  if(reweighting <- !is.null(matwt)) 
    stopifnot(is.numeric(matwt) && is.vector(matwt))
  internals <- NULL
  nonstandard <- reweighting || !is.null(new.coef) || saveterms
  ## compute Fisher information if not known
  if(is.null(fisher) || nonstandard) {
    gf <- getglmfit(object)
    ## we need a glm or gam
    if(is.null(gf)) {
      if(verbose) 
        warning("Refitting the model using GLM/GAM")
      object <- update(object, forcefit=TRUE)
      gf <- getglmfit(object)
      if(is.null(gf))
        stop("Internal error - refitting did not yield a glm object")
    }
    ## compute fitted intensity and sufficient statistic
    ltype <- if(is.poisson(object)) "trend" else "lambda"
    lambda <- fitted(object, type=ltype, new.coef=new.coef, check=FALSE)
    mom <- model.matrix(object)
    nmom <- nrow(mom)
    Q <- quad.ppm(object)
    wt <- w.quad(Q)
    ok <- getglmsubset(object)
    Z  <- is.data(Q)
    ## save them
    if(what == "internals") {
      internals <-
        if(!saveterms) list(suff=mom) else
      list(suff=mom, mom=mom, lambda=lambda, Z=Z, ok=ok)
    }
    ## Now restrict all terms to the domain of the pseudolikelihood
    lambda <- lambda[ok]
    mom <- mom[ok, , drop=FALSE]
    wt <- wt[ok]
    Z <- Z[ok]
    ## apply weights to rows of model matrix - temporary hack
    if(reweighting) {
      nwt <- length(matwt)
      if(nwt == nmom) {
        ## matwt matches original quadrature scheme - trim it
        matwt <- matwt[ok]
      } else if(nwt != sum(ok))
        stop("Hack argument matwt has incompatible length")
      mom.orig <- mom
      mom <- matwt * mom
    }
    ## compute Fisher information
    switch(method,
           C = {
             fisher <- sumouter(mom, lambda * wt)
             if(reweighting) {
               gradient <- sumouter(mom.orig, matwt * lambda * wt)
             }
           },
           interpreted = {
             if(!reweighting) {
               fisher <- 0
               for(i in 1:nrow(mom)) {
                 ro <- mom[i, ]
                 v <- outer(ro, ro, "*") * lambda[i] * wt[i]
                 if(!any(is.na(v)))
                   fisher <- fisher + v
               }
               momnames <- dimnames(mom)[[2]]
               dimnames(fisher) <- list(momnames, momnames)
             } else {
               fisher <- gradient <- 0
               for(i in 1:nrow(mom)) {
                 ro <- mom[i, ]
                 ro0 <- mom.orig[i,]
                 ldu <- lambda[i] * wt[i]
                 v <- outer(ro, ro, "*") * ldu
                 v0 <- outer(ro0, ro0, "*") * matwt[i] * ldu
                 if(!any(is.na(v)))
                   fisher <- fisher + v
                 if(!any(is.na(v0)))
                   gradient <- gradient + v0
               }
               momnames <- dimnames(mom)[[2]]
               dn <- list(momnames, momnames)
               dimnames(fisher) <- dimnames(gradient) <- dn
             }
           })
  } 

  if(what %in% c("all", "internals")) {
    ## Internals needed
    if(is.null(internals))
      internals <- list(suff = model.matrix(object))
    internals$fisher <- fisher
    if(reweighting)
      internals$gradient <- gradient
    ilist <- list(internals=internals)
  }

  if(what %in% c("all", "vcov", "corr")) {
    ## Variance-covariance matrix needed
    if(!reweighting) {
      ## Derive variance-covariance from Fisher info
      varcov <- checksolve(fisher, matrix.action,
                           "Fisher information matrix",
                           "variance")
      vcovlist <- list(fisher=fisher, varcov=varcov)
    } else {
      invgrad <- checksolve(gradient, matrix.action,
                            "gradient matrix", "variance")
      varcov <- if(is.null(invgrad)) NULL else
      invgrad %*% fisher %*% invgrad
      vcovlist <- list(fisher=fisher, varcov=varcov, invgrad=invgrad)
    }
  }
  result <- switch(what,
                   fisher    = list(fisher=fisher),
                   vcov      = vcovlist,
                   corr      = vcovlist,
                   internals = ilist,
                   all       = append(ilist, vcovlist))
  return(result)
}


## ...................... vcov calculation for Gibbs models ....................

vcalcGibbs <- function(fit, ...,
                       fine=FALSE,
                       what = c("vcov", "corr", "fisher", "internals", "all"),
                       generic=FALSE) {
  what <- match.arg(what)

  if(missing(generic)) {
    ## Change default to TRUE in certain cases
    ## For logistic fits, use generic method by default
    if(fit$method == "logi")
      generic <- TRUE
    ## For 'difficult' interactions, use generic method by default
    fasterbygeneric <- c("Areainter")
    if(as.interact(fit)$creator %in% fasterbygeneric)
      generic <- TRUE
  }
  
  ## decide whether to use the generic algorithm
  generic.triggers <- c("A1", "hessian",
                        "new.coef", "matwt", "saveterms")
  
  use.generic <-
    generic || fine ||
  !is.stationary(fit) ||
  (fit$method == "logi" && ("marks" %in% variablesinformula(fit$trend))) ||
  (fit$method != "logi" && has.offset(fit)) ||
  (fit$method == "logi" && has.offset.term(fit)) ||
  !(fit$correction == "border" && fit$rbord == reach(fit)) ||
  any(generic.triggers %in% names(list(...))) ||
  !identical(options("contrasts")[[1]],
             c(unordered="contr.treatment",
               ordered="contr.poly"))
  
  ## compute
  spill <- (what %in% c("all", "internals", "fisher"))
  spill.vc <- (what == "all")
  out <- if(use.generic)
    vcalcGibbsGeneral(fit, ..., fine=fine, spill=spill, spill.vc=spill.vc) else
    vcalcGibbsSpecial(fit, ..., spill=spill, spill.vc=spill.vc)

  switch(what,
         vcov = ,
         corr = {
           ## out is the variance-covariance matrix; return it
           return(list(varcov=out))
         },
         fisher = {
           ## out is a list of internal data: extract the Fisher info
           Fmat <- with(out,
                        if(fit$method != "logi") Sigma else Sigma1log+Sigma2log)
           return(list(fisher=Fmat))
         },
         internals = {
           ## out is a list of internal data: return it
           ## (ensure model matrix is included)
           if(is.null(out$mom))
             out$mom <- model.matrix(fit)
           return(list(internals=out))
         },
         all = {
           ## out is a list(internals, vc): return it
           ## (ensure model matrix is included)
           if(is.null(out$internals$mom))
             out$internals$mom <- model.matrix(fit)
           ## ensure Fisher info is included
           if(is.null(out$internals$fisher)) {
             Fmat <- with(out$internals,
                     if(fit$method != "logi") Sigma else Sigma1log+Sigma2log)
             out$internals$fisher <- Fmat
           }
           return(out)
         },
         )
  return(NULL)
}

## ...................... general algorithm ...........................

vcalcGibbsGeneral <- function(model,
                         ...,
                         spill = FALSE,
                         spill.vc = FALSE,
                         matrix.action=c("warn", "fatal", "silent"),
                         logi.action=c("warn", "fatal", "silent"),
                         algorithm=c("vectorclip", "vector", "basic"),
                         A1 = NULL,
                         fine = FALSE,
                         hessian = FALSE,
                         matwt = NULL, new.coef = NULL,
                         saveterms = FALSE,
                         parallel = TRUE
                         ) {
  matrix.action <- match.arg(matrix.action)
  logi.action <- match.arg(logi.action)
  algorithm <- match.arg(algorithm)
  if(reweighting <- !is.null(matwt)) 
    stopifnot(is.numeric(matwt) && is.vector(matwt))
  spill <- spill || spill.vc
  saveterms <- spill && saveterms
  logi <- model$method=="logi"
  asked.parallel <- !missing(parallel)
  
  old.coef <- coef(model)
  use.coef <- if(!is.null(new.coef)) new.coef else old.coef
  p <- length(old.coef)
  if(p == 0) {
    ## this probably can't happen
    if(!spill) return(matrix(, 0, 0)) else return(list())
  }
  pnames <- names(old.coef)
  dnames <- list(pnames, pnames)
  
  internals <- list()
  ##
  sumobj <- summary(model, quick="entries")
  correction <- model$correction
  rbord      <- model$rbord
  R <- reach(model, epsilon=1e-2)
  Q <- quad.ppm(model)
  D <- dummy.ppm(model)
  rho <- model$internal$logistic$rho
  #### If dummy intensity rho is unknown we estimate it
  if(is.null(rho))
     rho <- npoints(D)/(area(D)*markspace.integral(D))
  X <- data.ppm(model)
  Z <- is.data(Q)
  W <- as.owin(model)
  areaW <- if(correction == "border") eroded.areas(W, rbord) else area(W)
  ##
  ## determine which quadrature points contributed to the
  ## sum/integral in the pseudolikelihood
  ## (e.g. some points may be excluded by the border correction)
  okall <- getglmsubset(model)
  ## data only:
  ok <- okall[Z]
  nX <- npoints(X)
  ## conditional intensity lambda(X[i] | X) = lambda(X[i] | X[-i])
  ## data and dummy:
  lamall <- fitted(model, check = FALSE, new.coef = new.coef)
  ## data only:
  lam <- lamall[Z]
  ## sufficient statistic h(X[i] | X) = h(X[i] | X[-i])
  ## data and dummy:
  mall <- model.matrix(model)
  ## save
  if(saveterms) 
    internals <- append(internals,
                        list(mom=mall, lambda=lamall, Z=Z, ok=okall,
                             matwt=matwt))
  if(reweighting) {
    ## each column of the model matrix is multiplied by 'matwt'
    check.nvector(matwt, nrow(mall), things="quadrature points")
    mall.orig <- mall
    mall      <- mall * matwt
  }
  ## subsets of model matrix
  mokall <- mall[okall, , drop=FALSE]
  ## data only:
  m <- mall[Z, , drop=FALSE]
  mok <- m[ok, , drop=FALSE]
  ##
  if(reweighting) {
    ## save unweighted versions
    mokall.orig <- mall.orig[okall, , drop=FALSE]
    m.orig      <- mall.orig[Z, , drop=FALSE]
    mok.orig    <- m.orig[ok, , drop=FALSE]
    ##
    matwtX <- matwt[Z]
  }

  ## ^^^^^^^^^^^^^^^^ First order (sensitivity) matrices A1, S
  
  ## logistic 
  if(logi){
    ## Sensitivity matrix S for logistic case
    Slog <- sumouter(mokall, w = lamall[okall]*rho/(lamall[okall]+rho)^2)
    dimnames(Slog) <- dnames
    ## A1 matrix for logistic case
    A1log <- sumouter(mokall, w = lamall[okall]*rho*rho/(lamall[okall]+rho)^3)
    dimnames(A1log) <- dnames
  }
  ## Sensitivity matrix for MPLE case (= A1)
  if(is.null(A1) || reweighting) {
    if(fine){
      A1 <- sumouter(mokall, w = (lamall * w.quad(Q))[okall])
      if(reweighting)
        gradient <- sumouter(mokall.orig, w=(matwt * lamall * w.quad(Q))[okall])
    } else{
      A1 <- sumouter(mok)
      if(reweighting)
        gradient <- sumouter(mok.orig, w=matwtX)
    }
  } else {
    stopifnot(is.matrix(A1))
    if(!all(dim(A1) == p))
      stop(paste("Matrix A1 has wrong dimensions:",
                 prange(dim(A1)), "!=", prange(c(p, p))))
  }
  dimnames(A1) <- dnames

  ## ^^^^^^^^^^ Second order interaction effects A2, A3

  if(hessian) {
    ## interaction terms suppressed
    A2 <- A3 <- matrix(0, p, p, dimnames=dnames)
    if(logi)
      A2log <- A3log <- matrix(0, p, p, dimnames=dnames)
  } else {
    ## ^^^^^^^^^^^^^^^^^^^^ `parallel' evaluation
    need.loop <- TRUE
    if(parallel) {
      ## compute second order difference
      ##  ddS[i,j,] = h(X[i] | X) - h(X[i] | X[-j])
      ddS <- deltasuffstat(model, restrict=TRUE, force=FALSE)
      if(is.null(ddS)) {
        if(asked.parallel)
          warning("parallel option not available - reverting to loop")
      } else {
        need.loop <- FALSE
        ## rearrange so that
        ##  ddS[ ,i,j] = h(X[i] | X) - h(X[i] | X[-j])
        ddS <- aperm(ddS, c(3,2,1))
        ## now compute sum_{i,j} for i != j
        ## outer(ddS[,i,j], ddS[,j,i])
        ddSok <- ddS[ , ok, ok, drop=FALSE]
        A3 <- sumsymouter(ddSok)
        ## mom.array[ ,i,j] = h(X[i] | X)
        mom.array <- array(t(m), dim=c(p, nX, nX))
        ## momdel[ ,i,j] = h(X[i] | X[-j])
        momdel <- mom.array - ddS
        ## lamdel[i,j] = lambda(X[i] | X[-j])
        lamdel <-
          matrix(lam, nX, nX) * exp(tensor::tensor(-use.coef, ddS, 1, 1))
        ##  pairweight[i,j] = lamdel[i,j]/lambda[i] - 1 
        pairweight <- lamdel / lam - 1
        ## now compute sum_{i,j} for i != j
        ## pairweight[i,j] * outer(momdel[,i,j], momdel[,j,i])
        ## for data points that contributed to the pseudolikelihood
        momdelok <- momdel[ , ok, ok, drop=FALSE]
        A2 <- sumsymouter(momdelok, w=pairweight[ok, ok])
        if(logi){
          ## lam.array[ ,i,j] = lambda(X[i] | X)
          lam.array <- array(lam, c(nX,nX,p))
          lam.array <- aperm(lam.array, c(3,1,2))
          ## lamdel.array[,i,j] = lambda(X[i] | X[-j])
          lamdel.array <- array(lamdel, c(nX,nX,p))
          lamdel.array <- aperm(lamdel.array, c(3,1,2))
          momdellogi <- rho/(lamdel.array+rho)*momdel
          momdellogiok <- momdellogi[ , ok, ok, drop=FALSE]
          A2log <- sumsymouter(momdellogiok, w=pairweight[ok, ok])
          ddSlogi <- rho/(lam.array+rho)*mom.array - momdellogi
          ddSlogiok <- ddSlogi[ , ok, ok, drop=FALSE]
          A3log <- sumsymouter(ddSlogiok)
        }
      }
    }
  
    ## ^^^^^^^^^^^^^^^^^^^^ loop evaluation
    if(need.loop) {
    
      A2 <- A3 <- matrix(0, p, p, dimnames=dnames)
      if(logi)
        A2log <- A3log <- matrix(0, p, p, dimnames=dnames)
    
      if(saveterms) {
        ## *initialise* matrices 
        ##  lamdel[i,j] = lambda(X[i] | X[-j]) = lambda(X[i] | X[-c(i,j)])
        lamdel <- matrix(lam, nX, nX)
        ##  momdel[ ,i,j] = h(X[i] | X[-j]) = h(X[i] | X[-c(i,j)])
        momdel <- array(t(m), dim=c(p, nX, nX))
      }
  
      ## identify close pairs
      if(is.finite(R)) {
        cl <- closepairs(X, R, what="indices")
        I <- cl$i
        J <- cl$j
        if(algorithm == "vectorclip") {
          cl2 <- closepairs(X, 2*R, what="indices")
          I2 <- cl2$i
          J2 <- cl2$j
        }
      } else {
        ## either infinite reach, or something wrong
        IJ <- expand.grid(I=1:nX, J=1:nX)
        IJ <- subset(IJ, I != J)
        I2 <- I <- IJ$I
        J2 <- J <- IJ$J
      }
      ## filter:  I and J must both belong to the nominated subset 
      okIJ <- ok[I] & ok[J]
      I <- I[okIJ]
      J <- J[okIJ]
      ##
      if(length(I) > 0 && length(J) > 0) {
        ## .............. loop over pairs ........................
        ## The following ensures that 'empty' and 'X' have compatible marks 
        empty <- X[integer(0)]
        ## make an empty 'equalpairs' matrix
        nonE <- matrix(, nrow=0, ncol=2)
        ## Run through pairs
        switch(algorithm,
               basic={
                 for(i in unique(I)) {
                   Xi <- X[i]
                   Ji <- unique(J[I==i])
                   if((nJi <- length(Ji)) > 0) {
                     for(k in 1:nJi) {
                       j <- Ji[k]
                       X.ij <- X[-c(i,j)]
                       ## compute conditional intensity
                       ##    lambda(X[j] | X[-i]) = lambda(X[j] | X[-c(i,j)]
                       plamj.i <- predict(model, type="cif",
                                          locations=X[j], X=X.ij,
                                          check = FALSE,
                                          new.coef = new.coef,
                                          sumobj = sumobj, E=nonE)
                       ## corresponding values of sufficient statistic 
                       ##    h(X[j] | X[-i]) = h(X[j] | X[-c(i,j)]
                       pmj.i <- partialModelMatrix(X.ij, X[j], model)[nX-1, ]
                       ## conditional intensity and sufficient statistic
                       ## in reverse order
                       ##    lambda(X[i] | X[-j]) = lambda(X[i] | X[-c(i,j)]
                       plami.j <- predict(model, type="cif",
                                          locations=X[i], X=X.ij,
                                          check = FALSE,
                                          new.coef = new.coef,
                                          sumobj = sumobj, E=nonE)
                       pmi.j <- partialModelMatrix(X.ij, Xi, model)[nX-1, ]
                       ## 
                       if(reweighting) {
                         pmj.i <- pmj.i * matwtX[j]
                         pmi.j <- pmi.j * matwtX[i]
                       }
                       if(saveterms) {
                         lamdel[i,j] <- plami.j
                         momdel[ , i, j] <- pmi.j
                         lamdel[j,i] <- plamj.i
                         momdel[ , j, i] <- pmj.i
                       }
                       ## increment A2, A3
                       wt <- plami.j / lam[i] - 1
                       A2 <- A2 + wt * outer(pmi.j, pmj.i)
                       if(logi)
                         A2log <- A2log +
                           wt * rho/(plami.j+rho) *
                             rho/(plamj.i+rho) * outer(pmi.j, pmj.i)
                       ## delta sufficient statistic
                       ## delta_i h(X[j] | X[-c(i,j)])
                       ## = h(X[j] | X[-j]) - h(X[j] | X[-c(i,j)])
                       ## = h(X[j] | X) - h(X[j] | X[-i])
                       ## delta_j h(X[i] | X[-c(i,j)])
                       ## = h(X[i] | X[-i]) - h(X[i] | X[-c(i,j)])
                       ## = h(X[i] | X) - h(X[i] | X[-j])
                       deltaiSj <- m[j, ] - pmj.i
                       deltajSi <- m[i, ] - pmi.j
                       A3 <- A3 + outer(deltaiSj, deltajSi)
                       if(logi){
                         deltaiSjlog <- rho*(m[j, ]/
                                             (lam[j]+rho) - pmj.i/(plamj.i+rho))
                         deltajSilog <- rho*(m[i, ]/
                                             (lam[i]+rho) - pmi.j/(plami.j+rho))
                         A3log <- A3log + outer(deltaiSjlog, deltajSilog)
                       }
                     }
                   }
                 }
               },
               vector={
                 ## --------- faster algorithm using vector functions --------
                 for(i in unique(I)) {
                   Ji <- unique(J[I==i])
                   nJi <- length(Ji)
                   if(nJi > 0) {
                     Xi <- X[i]
                     ## neighbours of X[i]
                     XJi <- X[Ji]
                     ## all points other than X[i]
                     X.i <- X[-i]
                     ## index of XJi in X.i
                     J.i <- Ji - (Ji > i)
                     ## equalpairs matrix
                     E.i <- cbind(J.i, seq_len(nJi))
                     ## compute conditional intensity
                     ##   lambda(X[j] | X[-i]) = lambda(X[j] | X[-c(i,j)]
                     ## for all j
                     plamj <- predict(model, type="cif",
                                      locations=XJi, X=X.i,
                                      check = FALSE,
                                      new.coef = new.coef,
                                      sumobj=sumobj, E=E.i)
                     ## corresponding values of sufficient statistic 
                     ##    h(X[j] | X[-i]) = h(X[j] | X[-c(i,j)]
                     ## for all j
                     pmj <-
                       partialModelMatrix(X.i, empty, model)[J.i, , drop=FALSE]
                     ##
                     ## conditional intensity & sufficient statistic
                     ## in reverse order
                     ##    lambda(X[i] | X[-j]) = lambda(X[i] | X[-c(i,j)]
                     ## for all j
                     plami <- numeric(nJi)
                     pmi <- matrix(, nJi, p)
                     for(k in 1:nJi) {
                       j <- Ji[k]
                       X.ij <- X[-c(i,j)]
                       plami[k] <- predict(model, type="cif",
                                           locations=Xi, X=X.ij,
                                           check = FALSE,
                                           new.coef = new.coef,
                                           sumobj = sumobj, E=nonE)
                       pmi[k, ] <- partialModelMatrix(X.ij, Xi, model)[nX-1, ]
                     }
                     ##
                     if(reweighting) {
                       pmj <- pmj * matwtX[Ji]
                       pmi <- pmi * matwtX[i]
                     }
                     if(saveterms) {
                       lamdel[Ji, i] <- plamj
                       momdel[ , Ji, i] <- t(pmj)
                       lamdel[i,Ji] <- plami
                       momdel[ , i, Ji] <- t(pmi)
                     }
                     ## increment A2, A3
                     wt <- plami / lam[i] - 1
                     for(k in 1:nJi) {
                       j <- Ji[k]
                       A2 <- A2 + wt[k] * outer(pmi[k,], pmj[k,])
                       if(logi)
                         A2log <- A2log + wt[k] * rho/(plami[k]+rho) *
                           rho/(plamj[k]+rho) * outer(pmi[k,], pmj[k,])
                       ## delta sufficient statistic
                       ## delta_i h(X[j] | X[-c(i,j)])
                       ## = h(X[j] | X[-j]) - h(X[j] | X[-c(i,j)])
                       ## = h(X[j] | X) - h(X[j] | X[-i])
                       ## delta_j h(X[i] | X[-c(i,j)])
                       ## = h(X[i] | X[-i]) - h(X[i] | X[-c(i,j)])
                       ## = h(X[i] | X) - h(X[i] | X[-j])
                       deltaiSj <- m[j, ] - pmj[k,]
                       deltajSi <- m[i, ] - pmi[k,]
                       A3 <- A3 + outer(deltaiSj, deltajSi)
                       if(logi){
                         deltaiSjlog <- rho*(m[j, ]/(lam[j]+rho) -
                                             pmj[k,]/(plamj[k]+rho))
                         deltajSilog <- rho*(m[i, ]/(lam[i]+rho) -
                                             pmi[k,]/(plami[k]+rho))
                         A3log <- A3log + outer(deltaiSjlog, deltajSilog)
                       }
                     }
                   }
                 }
               },
               vectorclip={
                 ## --------- faster version of 'vector' algorithm
                 ## --------  by removing non-interacting points of X
                 for(i in unique(I)) {
                   ## all points within 2R
                   J2i <- unique(J2[I2==i])
                   ## all points within R
                   Ji  <- unique(J[I==i])
                   nJi <- length(Ji)
                   if(nJi > 0) {
                     Xi <- X[i]
                     ## neighbours of X[i]
                     XJi <- X[Ji]
                     ## replace X[-i] by X[-i] \cap b(0, 2R)
                     X.i <- X[J2i]
                     nX.i <- length(J2i)
                     ## index of XJi in X.i
                     J.i <- match(Ji, J2i)
                     if(any(is.na(J.i)))
                       stop("Internal error: Ji not a subset of J2i")
                     ## equalpairs matrix
                     E.i <- cbind(J.i, seq_len(nJi))
                     ## compute conditional intensity
                     ##   lambda(X[j] | X[-i]) = lambda(X[j] | X[-c(i,j)]
                     ## for all j
                     plamj <- predict(model, type="cif",
                                      locations=XJi, X=X.i,
                                      check = FALSE,
                                      new.coef = new.coef,
                                      sumobj = sumobj, E=E.i)
                     ## corresponding values of sufficient statistic 
                     ##    h(X[j] | X[-i]) = h(X[j] | X[-c(i,j)]
                     ## for all j
                     pmj <-
                       partialModelMatrix(X.i, empty, model)[J.i, , drop=FALSE]
                     ##
                     ## conditional intensity & sufficient statistic
                     ##  in reverse order
                     ##    lambda(X[i] | X[-j]) = lambda(X[i] | X[-c(i,j)]
                     ## for all j
                     plami <- numeric(nJi)
                     pmi <- matrix(, nJi, p)
                     for(k in 1:nJi) {
                       j <- Ji[k]
                       ## X.ij <- X[-c(i,j)]
                       X.ij <- X.i[-J.i[k]]
                       plami[k] <- predict(model, type="cif",
                                           locations=Xi, X=X.ij,
                                           check = FALSE,
                                           new.coef = new.coef,
                                           sumobj = sumobj, E=nonE)
                       pmi[k, ] <- partialModelMatrix(X.ij, Xi, model)[nX.i, ]
                     }
                     ##
                     if(reweighting) {
                       pmj <- pmj * matwtX[Ji]
                       pmi <- pmi * matwtX[i]
                     }
                     if(saveterms) {
                       lamdel[Ji, i] <- plamj
                       momdel[ , Ji, i] <- t(pmj)
                       lamdel[i,Ji] <- plami
                       momdel[ , i, Ji] <- t(pmi)
                     }
                     ## increment A2, A3
                     wt <- plami / lam[i] - 1
                     for(k in 1:nJi) {
                       j <- Ji[k]
                       A2 <- A2 + wt[k] * outer(pmi[k,], pmj[k,])
                       if(logi)
                         A2log <- A2log + wt[k] * rho/(plami[k]+rho) *
                           rho/(plamj[k]+rho) * outer(pmi[k,], pmj[k,])
                       ## delta sufficient statistic
                       ## delta_i h(X[j] | X[-c(i,j)])
                       ## = h(X[j] | X[-j]) - h(X[j] | X[-c(i,j)])
                       ## = h(X[j] | X) - h(X[j] | X[-i])
                       ## delta_j h(X[i] | X[-c(i,j)])
                       ## = h(X[i] | X[-i]) - h(X[i] | X[-c(i,j)])
                       ## = h(X[i] | X) - h(X[i] | X[-j])
                       deltaiSj <- m[j, ] - pmj[k,]
                       deltajSi <- m[i, ] - pmi[k,]
                       A3 <- A3 + outer(deltaiSj, deltajSi)
                       if(logi){
                         deltaiSjlog <- rho*(m[j, ]/(lam[j]+rho) -
                                             pmj[k,]/(plamj[k]+rho))
                         deltajSilog <- rho*(m[i, ]/(lam[i]+rho) -
                                             pmi[k,]/(plami[k]+rho))
                         A3log <- A3log + outer(deltaiSjlog, deltajSilog)
                       }
                     }
                   }
                 }
               })
      }
    }
    ## ......... end of loop computation ...............
  }

  #### Matrix Sigma 
  Sigma <- A1+A2+A3
  
  if(spill) {
    ## save internal data (with matrices unnormalised) 
    internals <-
      c(internals,
        list(A1=A1, A2=A2, A3=A3, Sigma=Sigma, areaW=areaW),
        if(logi)
           list(A1log=A1log, A2log=A2log, A3log=A3log, Slog=Slog) else NULL,
        if(reweighting) list(gradient=gradient) else NULL,
        if(saveterms) list(lamdel=lamdel, momdel=momdel) else NULL)
    ## return internal data if no further calculation needed
    if(!spill.vc && !logi)
      return(internals)
  }
    
  ## ........... calculate variance/covariance matrix for MPL .........

  if(!reweighting) {
    ## Normalise
    A1 <- A1/areaW
    Sigma <- Sigma/areaW
    ## Enforce exact symmetry 
    A1 <- (A1 + t(A1))/2
    Sigma <- (Sigma + t(Sigma))/2
    ## calculate inverse negative Hessian
    U <- checksolve(A1, matrix.action, , "variance")
  } else {
    ## Normalise
    gradient <- gradient/areaW
    Sigma <- Sigma/areaW
    ## Enforce exact symmetry
    gradient <- (gradient + t(gradient))/2
    Sigma <- (Sigma + t(Sigma))/2
    ## calculate inverse negative Hessian
    U <- checksolve(gradient, matrix.action, , "variance")
  }
  
  ## compute variance-covariance
  vc.mpl <- if(is.null(U)) matrix(NA, p, p) else 
              U %*% Sigma %*% U / areaW
  dimnames(vc.mpl) <- dnames

  ## return variance-covariance matrix, if model was fitted by MPL
  if(!logi) {
    if(spill.vc) return(list(varcov=vc.mpl, internals=internals))
    return(vc.mpl)
  }
  
  ###### Everything below is only computed for logistic fits #######

  ## Matrix Sigma1log (A1log+A2log+A3log):
  Sigma1log <- A1log+A2log+A3log
  ## Resolving the dummy process type
  how <- model$internal$logistic$how
  if(how %in% c("given", "grid", "transgrid")){
    whinge <- paste("vcov is not implemented for dummy type", sQuote(how))
    if(logi.action=="fatal")
      stop(whinge)
    how <- if(how=="given") "poisson" else "stratrand"
    if(logi.action=="warn")
      warning(paste(whinge,"- using", sQuote(how), "formula"), call.=FALSE)
  }
  ## Matrix Sigma2log (depends on dummy process type)
  switch(how,
         poisson={
           Sigma2log <- sumouter(mokall, w = lamall[okall]*lamall[okall]*rho/(lamall[okall]+rho)^3)
         },
         binomial={
           Sigma2log <- sumouter(mokall, w = lamall[okall]*lamall[okall]*rho/(lamall[okall]+rho)^3)
           A1vec <- t(mokall) %*% (rho*lamall[okall]/(lamall[okall]+rho)^2)
           Sigma2log <- Sigma2log - A1vec%*%t(A1vec)/rho*1/sum(1/(lamall[okall]+rho))
         },
         stratrand={
           ## Dirty way of refitting model with new dummy pattern (should probably be done using call, eval, envir, etc.):
           ## Changed by ER 2013/06/14 to use the new quadscheme.logi
           ## D2 <- logi.dummy(X = X, type = "stratrand", nd = model$internal$logistic$args)
           ## Q2 <- quad(data=X, dummy=D2)
           ## Q2$dummy$Dinfo <- D2$Dinfo
           Q2 <- quadscheme.logi(data=X, dummytype = "stratrand",
                                 nd = model$internal$logistic$nd)
           D2 <- Q2$dummy
           Q2$dummy$Dinfo <- D2$Dinfo
           Z2 <- is.data(Q2)
           arglist <- list(Q=Q2, trend=model$trend, interaction = model$interaction, method = model$method,
                           correction = model$correction, rbord = model$rbord, covariates = model$covariates)
           arglist <- append(arglist, model$internal$logistic$extraargs)
           model2 <- do.call(ppm, args = arglist)

           ## New cif
           lamall2 <- fitted(model2, check = FALSE, new.coef = new.coef)
           ## New model matrix
           mall2 <- model.matrix(model2)
           okall2 <- getglmsubset(model2)

           ## index vectors of stratrand cell indices of dummy points 
           inD <- model$internal$logistic$inD
           inD2 <- model2$internal$logistic$inD

           ## Dummy points inside eroded window (for border correction)
           if(is.finite(R) && (correction == "border")){
             ii <- (bdist.points(D) >= R)
             ii2 <- (bdist.points(D2) >= R)
           } else{
             ii <- rep.int(TRUE, npoints(D))
             ii2 <- rep.int(TRUE, npoints(D2))
           }
           ## OK points of dummy pattern 1 with a valid point of dummy pattern 2 in same stratrand cell (and vice versa)
           okdum <- okall[!Z]
           okdum2 <- okall2[!Z2]
           ok1 <- okdum & ii & is.element(inD, inD2[okdum2 & ii2])
           ok2 <- okdum2 & ii2 & is.element(inD2, inD[okdum & ii])
           ## ok1 <- okdum & okdum2 & ii & is.element(inD, inD2[ii2])
           ## ok2 <- okdum2 & okdum1 & ii2 & is.element(inD2, inD[ii])
           ## ok1 <- ii & is.element(inD, inD2[ii2])
           ## ok2 <- ii2 & is.element(inD2, inD[ii])

           ## cif and suff. stat. for valid points in dummy patterns 1 and 2
           lamdum <- lamall[!Z][ok1]
           lamdum2 <- lamall2[!Z2][ok2]
           mdum <- mall[!Z,,drop=FALSE][ok1,]
           mdum2 <- mall2[!Z2,,drop=FALSE][ok2,]

           ## finally calculation of Sigma2
           wlam <- mdum * rho*lamdum/(lamdum+rho)
           wlam2 <- mdum2 * rho*lamdum2/(lamdum2+rho)
           Sigma2log <- t(wlam-wlam2)%*%(wlam-wlam2)/(2*rho*rho)
         },
         stop("sorry - unrecognized dummy process in logistic fit")
         )
  ## Attaching to Sigma2log calculated above
  dimnames(Sigma2log) <- dnames

  
  if(spill) {
    ## return internal data only (with matrices unnormalised)
    internals <- c(internals, 
                   list(Sigma1log=Sigma1log, Sigma2log=Sigma2log, mple=vc.mpl))
    if(!spill.vc)
      return(internals)
  }

  ## .. Calculate variance-covariance matrix for logistic fit ...........
  ## normalise
  Slog <- Slog/areaW
  Sigma1log <- Sigma1log/areaW
  Sigma2log <- Sigma2log/areaW
  ## evaluate
  Ulog <- checksolve(Slog, matrix.action, , "variance")
  vc.logi <- if(is.null(Ulog)) matrix(NA, p, p) else 
             Ulog %*% (Sigma1log+Sigma2log) %*% Ulog / areaW
  dimnames(vc.logi) <- dnames
  ##
  if(spill.vc) return(list(varcov=vc.logi, internals=internals))
  return(vc.logi)
}

## vcalcGibbs from Ege Rubak and J-F Coeurjolly
## 2013/06/14, modified by Ege to handle logistic case as well

vcalcGibbsSpecial <- function(fit, ...,
                              spill=FALSE,
                              spill.vc=FALSE,
                              special.alg = TRUE,
                              matrix.action=c("warn", "fatal", "silent"),
                              logi.action=c("warn", "fatal", "silent")) {
  matrix.action <- match.arg(matrix.action)
  logi.action <- match.arg(logi.action)
  spill <- spill || spill.vc
  
  ## Interaction name:
  iname <- fit$interaction$name
  
  ## Does the model have marks which are in the trend?
  marx <- is.marked(fit) && ("marks" %in% variablesinformula(fit$trend))

  ## The full data and window:
  Xplus <- data.ppm(fit)
  Wplus <- as.owin(Xplus)

  ## Fitted parameters and the parameter dimension p (later consiting of p1 trend param. and p2 interaction param.):
  theta <- coef(fit)
  p <- length(theta)

  ## Number of points:
  n <- npoints(Xplus)

  ## Using the faster algorithms for special cases
  if(special.alg && fit$method != "logi"){
    param <- coef(fit)
    switch(iname,
      "Strauss process"={
        ## Only implemented for non-marked case:
        if(!marx)
	  return(vcovPairPiece(Xplus,
                               reach(fit$interaction),
                               exp(coef(fit)[2]),
                               matrix.action,
                               spill=spill,
                               spill.vc=spill.vc))
      },
           
      "Piecewise constant pairwise interaction process"={
        ## Only implemented for non-marked case:
        if(!marx)
          return(vcovPairPiece(Xplus,
                               fit$interaction$par$r,
                               exp(coef(fit)[-1]),
                               matrix.action,
                               spill=spill,
                               spill.vc=spill.vc))
      },

      "Multitype Strauss process"={
	matR <- fit$interaction$par$radii
        R <- c(matR[1,1], matR[1,2], matR[2,2])
        ## Only implemented for 2 types with equal interaction range:
        if(ncol(matR)==2 && marx){
          n <- length(theta)
          res <- vcovMultiStrauss(Xplus, R, exp(theta[c(n-2,n-1,n)]),
                                  matrix.action,spill=spill,spill.vc=spill.vc)
          if(!spill) {
            res <- contrastmatrix(res, 2)
            dimnames(res) <- list(names(theta), names(theta))
          }
          return(res)
        }
      }
    )
  }
  
  ## Matrix specifying equal points in the two patterns in the call to eval below:
  E <- matrix(rep.int(1:n, 2), ncol = 2)

  ## Eval. the interaction potential difference at all points (internal spatstat function):
#  V1 <- fit$interaction$family$eval(Xplus, Xplus, E, fit$interaction$pot, fit$interaction$par, fit$correction)
  oldopt <- NULL
  if(fit$interaction$family$name=="pairwise"){
      oldopt <- spatstat.options(fasteval = "off")
  }
  V1 <- evalInteraction(Xplus, Xplus, E, as.interact(fit), fit$correction)
  spatstat.options(oldopt)

  ## Calculate parameter dimensions and correct the contrast type parameters:
  p2 <- ncol(V1)
  p1 <- p-p2
  if(p1>1)
    theta[2:p1] <- theta[2:p1] + theta[1]
  ## V1 <- evalInteraction(Q, Xplus, union.quad(Q), fit$interaction, fit$correction)
  POT <- attr(V1, "POT")
  attr(V1, "POT") <- NULL
  ## Adding the constant potential as first column (one column per type for multitype):
  if(!marx){
    V1 <- cbind(1, V1)
    colnames(V1) <- names(theta)
  }
  else{
    lev <- levels(marks(Xplus))
    ## Indicator matrix for mark type attached to V1:
    tmp <- matrix(marks(Xplus), nrow(V1), p1)==matrix(lev, nrow(V1), p-ncol(V1), byrow=TRUE)
    colnames(tmp) <- lev
    V1 <- cbind(tmp,V1)
  }

  ## Matrices for differences of potentials:
  E <- matrix(rep.int(1:(n-1), 2), ncol = 2)
  dV <- V2 <- array(0,dim=c(n,n,p))

  for(k in 1:p1){
    V2[,,k] <- matrix(V1[,k], n, n, byrow = FALSE)
  }
  for(k in (p1+1):p){
    diag(V2[,,k]) <- V1[,k]
  }
  for(j in 1:n){
    ## Fast evaluation for pairwise interaction processes:
    if(fit$interaction$family$name=="pairwise" && !is.null(POT)){
      V2[-j,j,-(1:p1)] <- V1[-j,-(1:p1)]-POT[-j,j,]
    }
    else{
      V2[-j,j,-(1:p1)] <- fit$interaction$family$eval(Xplus[-j], Xplus[-j], E, fit$interaction$pot, fit$interaction$par, fit$correction)
      ## Q <- quadscheme(Xplus[-j],emptyppp)
      ## V2[-j,j,-1] <- evalInteraction(Q, Xplus[-j], Xplus[-j], fit$interaction, fit$correction)
    }
    for(k in 1:p){
      dV[,j,k] <- V1[,k] - V2[,j,k]
    }
  }
  ## Ratio of first and second order Papangelou - 1:
  frac <- 0*dV[,,1]
  for(k in (p1+1):p){
    frac <- frac + dV[,,k]*theta[k]
  }
  frac <- exp(-frac)-1

  ## In the rest we restrict attention to points in the interior:
  
  ## The interaction range:
  R <- reach(fit$interaction)

  ## The reduced window, area and point pattern:
  W<-erosion.owin(Wplus,R)
  areaW <- area(W)

  ## Interior points determined by bdist.points:
  IntPoints <- bdist.points(Xplus)>=R  
  X <- Xplus[IntPoints]
  
  ## Making a logical matrix, I, indicating R-close pairs which are in the interior:
  D <- pairdist(Xplus)
  diag(D) <- Inf
  I <- (D<=R) & outer(IntPoints,IntPoints, "&")
  
  ## Matrix A1:
  A1 <- t(V1[IntPoints,])%*%V1[IntPoints,]

  ## Matrix A2:
  A2 <- matrix(0,p,p)
  for(k in 1:p){
    for(l in k:p){
      A2[k,l] <- A2[l,k] <- sum(I*V2[,,k]*frac*t(V2[,,l]))
    }
  }
  
  ## Matrix A3:
  A3 <- matrix(0,p,p)
  for(k in 1:p){
    for(l in k:p){
      A3[k,l] <- A3[l,k] <- sum(I*dV[,,k]*t(dV[,,l]))
    }
  }

  ## Matrix Sigma (A1+A2+A3):
  Sigma<-A1+A2+A3

  if(spill) {
    # save internal data (with matrices unnormalised)
    dimnames(A1) <- dimnames(A2) <-
      dimnames(A3) <- list(names(theta), names(theta))
    internals <- list(A1=A1, A2=A2, A3=A3, Sigma=Sigma, areaW=areaW)
    # return internal data, if model fitted by MPL
    if(!spill.vc && fit$method != "logi")
      return(internals)
  }

  # ......... Calculate variance-covariance matrix for MPL ........
  
  # normalise
  A1 <- A1/areaW
  Sigma <- Sigma/areaW
  # evaluate
  U <- checksolve(A1, matrix.action, , "variance")
  vc.mpl <- if(is.null(U)) matrix(NA, p, p) else U %*% Sigma %*% U / areaW
  ## Convert to treatment contrasts
  if(marx)
    vc.mpl <- contrastmatrix(vc.mpl, p1)
  dimnames(vc.mpl) <- list(names(theta), names(theta))
  
  # Return result for standard ppm method:
  if(fit$method!="logi") {
    if(spill.vc) return(list(varcov=vc.mpl, internals=internals))
    return(vc.mpl)
  }
  
  ########################################################################
  ###### The remainder is only executed when the method is logistic ######
  ########################################################################

  ### Most of this is copy/pasted from vcalcGibbsGeneral
  correction <- fit$correction
  Q <- quad.ppm(fit)
  D <- dummy.ppm(fit)
  rho <- fit$internal$logistic$rho
  ## If dummy intensity rho is unknown we estimate it
  if(is.null(rho))
     rho <- npoints(D)/(area(D)*markspace.integral(D))
  X <- data.ppm(fit)
  Z <- is.data(Q)

  # determine which data points entered into the sum in the pseudolikelihood
  # (border correction, nonzero cif)
  # data and dummy:
  okall <- getglmsubset(fit)
  ## # data only:
  ## ok <- okall[Z]

  # conditional intensity lambda(X[i] | X) = lambda(X[i] | X[-i])
  # data and dummy:
  lamall <- fitted(fit, check = FALSE)
  ## # data only:
  ## lam <- lamall[Z]

  # sufficient statistic h(X[i] | X) = h(X[i] | X[-i])
  # data and dummy:
  mall <- model.matrix(fit)
  mokall <- mall[okall, , drop=FALSE]
  ## # data only:
  ## m <- mall[Z, , drop=FALSE]
  ## mok <- m[ok, , drop=FALSE]

  # Sensitivity matrix S and A1 matrix for logistic case
  Slog <- sumouter(mokall, w = lamall[okall]*rho/(lamall[okall]+rho)^2)
  A1log <- sumouter(mokall, w = lamall[okall]*rho*rho/(lamall[okall]+rho)^3)

  ## Define W1, W2 and dW for the logistic method based on V1, V2 and dV (frac is unchanged)
  lambda1 <- exp(.rowSums(matrix(theta,n,p,byrow=TRUE)*V1, n, p))
  W1 <- V1*rho/(lambda1+rho)
  lambda2 <- exp(apply(array(rep(theta,each=n*n),dim=c(n,n,p))*V2, c(1,2), sum))
  W2 <- V2
  dW <- dV
  for(k in 1:p){
    W2[,,k] <- V2[,,k] * rho/(lambda2+rho)
    for(j in 1:n){
      dW[,j,k] <- W1[,k] - W2[,j,k]
    }
  }
  ## Matrices A2log and A3log for the first component Sigma1log of the variance:
  A2log <- A3log <- matrix(0,p,p)
  for(k in 1:p){
    for(l in k:p){
      A2log[k,l] <- A2log[l,k] <- sum(I*W2[,,k]*frac*t(W2[,,l]))
      A3log[k,l] <- A3log[l,k] <- sum(I*dW[,,k]*t(dW[,,l]))
    }
  }
  A2log <- A2log
  A3log <- A3log
  
  ## First variance component Sigma1log (A1log+A2log+A3log):
  Sigma1log <- A1log+A2log+A3log

  ## Resolving the dummy process type
  how <- fit$internal$logistic$how
  if(how %in% c("given", "grid", "transgrid")){
    whinge <- paste("vcov is not implemented for dummy type", sQuote(how))
    if(logi.action=="fatal")
      stop(whinge)
    how <- if(how=="given") "poisson" else "stratrand"
    if(logi.action=="warn")
      warning(paste(whinge,"- using", sQuote(how), "formula"), call.=FALSE)
  }

  ## Matrix Sigma2log (depends on dummy process type)
  switch(how,
         poisson={
           Sigma2log <- sumouter(mokall, w = lamall[okall]*lamall[okall]*rho/(lamall[okall]+rho)^3)
         },
         binomial={
           Sigma2log <- sumouter(mokall, w = lamall[okall]*lamall[okall]*rho/(lamall[okall]+rho)^3)
           A1vec <- t(mokall) %*% (rho*lamall[okall]/(lamall[okall]+rho)^2)
           Sigma2log <- Sigma2log - A1vec%*%t(A1vec)/rho*1/sum(1/(lamall[okall]+rho))
         },
         stratrand={
           ### Dirty way of refitting model with new dummy pattern (should probably be done using call, eval, envir, etc.):
           ## D2 <- logi.dummy(X = X, type = "stratrand", nd = model$internal$logistic$args)
           ## Q2 <- quad(data=X, dummy=D2)
           ## Q2$dummy$Dinfo <- D2$Dinfo
           Q2 <- quadscheme.logi(data=X, dummytype = "stratrand", nd = fit$internal$logistic$nd)
           D2 <- Q2$dummy
           Z2 <- is.data(Q2)
           arglist <- list(Q=Q2, trend=fit$trend, interaction = fit$interaction, method = fit$method,
                           correction = fit$correction, rbord = fit$rbord, covariates = fit$covariates)
           arglist <- append(arglist, fit$internal$logistic$extraargs)
           fit2 <- do.call(ppm, args = arglist)

           ## New cif
           lamall2 <- fitted(fit2, check=FALSE)
           ## New model matrix
           mall2 <- model.matrix(fit2)
           okall2 <- getglmsubset(fit2)

           # index vectors of stratrand cell indices of dummy points 
           inD <- fit$internal$logistic$inD
           inD2 <- fit2$internal$logistic$inD

           # Dummy points inside eroded window (for border correction)
           if(is.finite(R) && (correction == "border")){
             ii <- inside.owin(D, w = W)
             ii2 <- inside.owin(D2, w = W)
           } else{
             ii <- rep.int(TRUE, npoints(D))
             ii2 <- rep.int(TRUE, npoints(D2))
           }
           # OK points of dummy pattern 1 with a valid point of dummy pattern 2 in same stratrand cell (and vice versa)
           okdum <- okall[!Z]
           okdum2 <- okall2[!Z2]
           ok1 <- okdum & ii & is.element(inD, inD2[okdum2 & ii2])
           ok2 <- okdum2 & ii2 & is.element(inD2, inD[okdum & ii])
           ## ok1 <- okdum & okdum2 & ii & is.element(inD, inD2[ii2])
           ## ok2 <- okdum2 & okdum1 & ii2 & is.element(inD2, inD[ii])
           ## ok1 <- ii & is.element(inD, inD2[ii2])
           ## ok2 <- ii2 & is.element(inD2, inD[ii])

           # cif and suff. stat. for valid points in dummy patterns 1 and 2
           lamdum <- lamall[!Z][ok1]
           lamdum2 <- lamall2[!Z2][ok2]
           mdum <- mall[!Z,][ok1,]
           mdum2 <- mall2[!Z2,][ok2,]

           # finally calculation of Sigma2
           wlam <- mdum * rho*lamdum/(lamdum+rho)
           wlam2 <- mdum2 * rho*lamdum2/(lamdum2+rho)
           Sigma2log <- t(wlam-wlam2)%*%(wlam-wlam2)/(2*rho*rho)
         },
         stop("sorry - unrecognized dummy process in logistic fit")
         )


  if(spill) {
    ## Attach dimnames to all matrices
    dimnames(Sigma2log) <- dimnames(Slog) <-
      dimnames(Sigma1log) <- dimnames(A1log) <-
        dimnames(A2log) <- dimnames(A3log) <-
          list(names(theta),names(theta))
    # return internal data (with matrices unnormalised)
    internals <- c(internals,
                   list(A1log=A1log, A2log=A2log, A3log=A3log, Slog=Slog,
                        Sigma1log=Sigma1log, Sigma2log=Sigma2log, mple=vc.mpl))
    if(!spill.vc)
      return(internals)
  }

  # ....... Compute variance-covariance for logistic fit .............
  # Normalise
  Slog <- Slog/areaW
  Sigma1log <- Sigma1log/areaW
  Sigma2log <- Sigma2log/areaW
  ## Finally the result is calculated:
  Ulog <- checksolve(Slog, matrix.action, , "variance")
  vc.logi <- if(is.null(Ulog)) matrix(NA, p, p) else 
             Ulog %*% (Sigma1log+Sigma2log) %*% Ulog / areaW
  #
  dimnames(vc.logi) <- list(names(theta), names(theta))
  if(spill.vc) return(list(varcov=vc.logi, internals=internals))
  return(vc.logi)
}

vcovPairPiece <- function(Xplus, R, Gam, matrix.action,
                          spill=FALSE, spill.vc=FALSE){
  ## R is  the  vector of breaks (R[length(R)]= range of the pp.
  ## Gam is the vector of weights
  Rmax <- R[length(R)]
  
  ## Xplus : point process observed in W+R
  ## Extracting the window and calculating area:
  Wplus<-as.owin(Xplus)
  W<-erosion.owin(Wplus,Rmax)
  areaW <- area(W)

  ## Interior points determined by bdist.points:
  IntPoints <- bdist.points(Xplus)>=Rmax
  X <- Xplus[IntPoints]

  nX <- npoints(X)
  nXplus <- npoints(Xplus)
  ## Matrix D with pairwise distances between points and infinite distance
  ## between a point and itself:
  
  Dplus<-pairdist(Xplus)
  D <- pairdist(X)
  diag(D) <- diag(Dplus) <- Inf
  ## logical matrix, I, indicating R-close pairs:
  p<-length(R)
  Tplus<-T<-matrix(0,X$n,p)
  I<-Iplus<-list()
  for (i in 1:p){
     if (i==1){
	Iplus[[1]]<- Dplus <=R[1]
	I[[1]] <- D<=R[1]
     } else {
	Iplus[[i]]<- ((Dplus>R[i-1]) & (Dplus <=R[i]))
	I[[i]] <- ((D>R[i-1]) & (D <=R[i]))
     }
     ## Vector T with the number of $R$-close neighbours to each point:
     Tplus[,i]<-  .colSums(Iplus[[i]], nXplus, nXplus)[IntPoints]
     T[,i] <-  .colSums(I[[i]], nX, nX)
  }
  ## Matrices A1, A2 and A3 are initialized to zero:
  A1 <- A2 <- A3 <- matrix(0,p+1,p+1)
  ## A1 and A3:
  A1[1,1] <- npoints(X)
  
  for (j in (2:(p+1))){
    A1[1,j]<-A1[j,1]<-sum(Tplus[,j-1])
    A3[j,j]<-sum(T[,j-1])
    for (k in (2:(p+1))){
      A1[j,k]<-sum(Tplus[,j-1] * Tplus[,k-1])
    }
  }
  ## A2:
  for (j in (2:(p+1))){
    A2[1,1]<-A2[1,1]+(Gam[j-1]^(-1)-1)*sum(T[,j-1])
    for (l in (2:(p+1))){
      if (l==j) vj<-Tplus[,j-1]-1 else vj<-Tplus[,j-1]
	A2[1,j]<-A2[1,j]+(Gam[l-1]^(-1)-1)*sum(T[,l-1]*(vj) )
    }
    A2[j,1]<-A2[1,j]
    for (k in (2:(p+1))){
      for (l in (2:(p+1))){
	if (l==j) vj<-Tplus[,j-1]-1 else vj<-Tplus[,j-1]
	if (l==k) vk<-Tplus[,k-1]-1 else vk<-Tplus[,k-1]

	A2[j,k]<-A2[j,k]+ (Gam[l-1]^(-1)-1)*sum(I[[l-1]]*outer(vj,vk))
      }
    }

  }

  Sigma<-A1+A2+A3

  nam <- c("(Intercept)", names(Gam))
  dnam <- list(nam, nam)
  
  if(spill) {
    # return internal data (with matrices unnormalised)
    dimnames(A1) <- dimnames(A2) <- dimnames(A3) <- dimnames(Sigma) <- dnam
    internals <- list(A1=A1, A2=A2, A3=A3, Sigma=Sigma)
    if(!spill.vc) return(internals)
  }
           
  ## Calculate variance-covariance
  # Normalise:
  A1    <- A1/areaW
  Sigma <- Sigma/areaW
  U <- checksolve(A1, matrix.action, , "variance")
  mat <- if(is.null(U)) matrix(NA, length(nam), length(nam)) else U%*%Sigma%*%U / areaW
  dimnames(mat) <- dnam

  if(spill.vc) return(list(varcov=mat, internals=internals))
  return(mat)
}

vcovMultiStrauss <- function(Xplus, vecR, vecg, matrix.action,
                             spill=FALSE, spill.vc=FALSE){
  ## Xplus : marked Strauss point process 
  ## with two types 
  ## observed in W+R (R=max(R11,R12,R22))

  ## vecg =  estimated parameters of interaction parameters
  ##	    ordered as the output of ppm, i.e. vecg=(g11,g12,g22)	
  ## vecR = range for the diff. strauss ordered a vecg(R11,R12,R22)

  R <- max(vecR)
  R11<-vecR[1];R12<-vecR[2];R22<-vecR[3]
  ## Extracting the window and calculating area:
  Wplus<-as.owin(Xplus)
  W<-erosion.owin(Wplus,R)
  areaW <- area(W)
  X1plus<-Xplus[Xplus$marks==levels(Xplus$marks)[1]]
  X2plus<-Xplus[Xplus$marks==levels(Xplus$marks)[2]]

  ## Interior points determined by bdist.points:
  IntPoints1 <- bdist.points(X1plus)>=R
  IntPoints2 <- bdist.points(X2plus)>=R
  X1 <- X1plus[IntPoints1]
  X2 <- X2plus[IntPoints2]

  nX1 <- npoints(X1)
  nX2 <- npoints(X2)
  nX1plus <- npoints(X1plus)
  nX2plus <- npoints(X2plus)
  
  ## Matrix D with pairwise distances between points and infinite distance
  ## between a point and itself:

  D1plus<-pairdist(X1plus)
  D1 <- pairdist(X1)
  diag(D1) <- diag(D1plus) <- Inf
  
  D2plus<-pairdist(X2plus)
  D2 <- pairdist(X2)
  diag(D2) <- diag(D2plus) <- Inf
  
  D12plus<-crossdist(X1,X2plus)  
  T12plus<-  .rowSums(D12plus<=R12, nX1, nX2plus)
  D21plus<-crossdist(X2,X1plus) 
  T21plus<-  .rowSums(D21plus<=R12, nX2, nX1plus)
  
  I12<-crossdist(X1,X2)<=R12
  I21<-crossdist(X2,X1)<=R12
  T12<-   .rowSums(I12, nX1, nX2)
  T21<-   .rowSums(I21, nX2, nX1)
  ## logical matrix, I, indicating R-close pairs:
  I1plus<- D1plus <=R11
  I1 <- D1<=R11
  I2plus<- D2plus <=R22
  I2 <- D2<=R22
  ## Vector T with the number of $R$-close neighbours to each point:
  T1plus<-  .colSums(I1plus, nX1plus, nX1plus)[IntPoints1]
  T1 <-     .colSums(I1,     nX1,     nX1)
  T2plus<-  .colSums(I2plus, nX2plus, nX2plus)[IntPoints2]
  T2 <-     .colSums(I2,     nX2,     nX2)

  ## Matrices A1, A2 and A3 are initialized to zero:
  A1 <- A2 <- A3 <- matrix(0,5,5)
  ## A1 is filled:
  A1[1,1]<-npoints(X1)
  A1[1,3]<-A1[3,1]<-sum(T1plus)
  A1[1,4]<-A1[4,1]<-sum(T12plus)
  A1[2,2]<-npoints(X2)
  A1[2,5]<-A1[5,2]<-sum(T2plus)
  A1[2,4]<-A1[4,2]<-sum(T21plus)
  A1[3,3]<-sum(T1plus*T1plus)
  A1[3,4]<-A1[4,3]<-sum(T1plus*T12plus)
  A1[5,5]<-sum(T2plus*T2plus)
  A1[4,5]<-A1[5,4]<-sum(T2plus*T21plus)
  A1[4,4]<-sum(T12plus*T12plus)+sum(T21plus*T21plus)

  ## A3 is filled:
  A3[3,3]<-sum(T1)
  A3[5,5]<-sum(T2)
  A3[4,4]<-sum(T12)+sum(T21)
   

  ## A2 is filled:
  gamInv<-vecg^(-1)-1
  gi1<-gamInv[1];gi12<-gamInv[2];gi2<-gamInv[3]
  A2[1,1]<-sum(T1)*gi1
  A2[1,2]<-A2[2,1]<-sum(T12)*gi12
  A2[1,3]<-A2[3,1]<-sum(T1*(T1plus-1))*gi1
  A2[1,5]<-A2[5,1]<-sum(T21*T2plus)*gi12
  A2[1,4]<-A2[4,1]<-gi1*sum(T1*(T12plus))+gi12*sum(T21*(T21plus-1))
  A2[2,2]<-sum(T2)*gi2
  A2[2,3]<-A2[3,2]<-sum(T12*T1plus)*gi12
  A2[2,5]<-A2[5,2]<-sum(T2*(T2plus-1))*gi2
  A2[2,4]<-A2[4,2]<-gi2*sum(T2*(T21plus))+gi12*sum(T12*(T12plus-1))

  A2[3,3]<-gi1*sum(I1*outer(T1plus-1,T1plus-1))
  
  A2[3,5]<-A2[5,3]<- gi12*sum(I12*outer(T1plus,T2plus))
  A2[3,4]<-A2[4,3]<-gi1*sum(I1*outer(T1plus-1,T12plus))+gi12*sum(I12*outer(T1plus,T21plus-1))
  
  A2[5,5]<-gi2*sum(I2*outer(T2plus-1,T2plus-1))
  A2[4,5]<-A2[5,4]<-gi2*sum(I2*outer(T2plus-1,T21plus))+gi12*sum(I21*outer(T2plus,T12plus-1))
  
  A2[4,4]<-gi1*sum(I1*outer(T12plus,T12plus))+gi2*sum(I2*outer(T21plus,T21plus))+ gi12*sum(I12*outer(T12plus-1,T21plus-1))+gi12*sum(I21*outer(T21plus-1,T12plus-1))
  
  Sigma<-A1+A2+A3
  nam <- c(levels(marks(Xplus)), names(vecg))
  dnam <- list(nam, nam)
  
  if(spill) {
    # return internal data (with matrices unnormalised)
    dimnames(A1) <- dimnames(A2) <- dimnames(A3) <- dimnames(Sigma) <- dnam
    internals <- list(A1=A1, A2=A2, A3=A3, Sigma=Sigma)
    if(!spill.vc) return(internals)
  }
           
  ## Calculate variance-covariance
  # Normalise:
  A1    <- A1/areaW
  Sigma <- Sigma/areaW
  U <- checksolve(A1, matrix.action, , "variance")
  mat <- if(is.null(U)) matrix(NA, length(nam), length(nam)) else U%*%Sigma%*%U / areaW
  dimnames(mat) <- dnam

  if(spill.vc) return(list(varcov=mat, internals=internals))
  return(mat)
}

# Convert the first p rows & columns of variance matrix x
# to variances of treatment contrasts
contrastmatrix <- function(x,p){
  mat <- x
  ## Correct column and row 1:
  for(i in 2:p){
    mat[1,i] <- mat[i,1] <- x[1,i]-x[1,1]
  }
  ## Correct columns and rows 2,...,p:
  for(i in 2:p){
    for(j in 2:p){
      mat[i,j] <- x[1,1]-x[1,i]-x[1,j]+x[i,j]
    }
    for(j in (p+1):ncol(x)){
      mat[i,j] <- mat[j,i] <- x[i,j]-x[1,j]
    }
  }
  mat
}


checksolve <- function(M, action, descrip, target="") {
  Mname <- short.deparse(substitute(M))
  Minv <- try(solve(M), silent=(action=="silent"))
  if(!inherits(Minv, "try-error"))
    return(Minv)
  if(missing(descrip))
    descrip <- paste("the matrix", sQuote(Mname))
  whinge <- paste0("Cannot compute ", target, ": ", descrip, " is singular")
  switch(action,
         fatal=stop(whinge, call.=FALSE),
         warn= warning(whinge, call.=FALSE),
         silent={})
  return(NULL)
}

vcov.ppm
}
)

suffloc <- function(object) {
  verifyclass(object, "ppm")
  if(!is.poisson(object))
    stop("Internals not available for Gibbs models")
  return(vcov(object, what="internals")$suff)
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/versions.R"
#
# versions.R
#
# version numbers
#
# $Revision: 1.10 $  $Date: 2014/10/24 00:22:30 $
#
#####################


# Extract version string from ppm object

versionstring.ppm <- function(object) {
  verifyclass(object, "ppm")
  v <- object$version
  if(is.null(v) || !is.list(v))
    v <- list(major=1, minor=3, release=4)
  vs <- paste(v$major, ".", v$minor, "-", v$release, sep="")
  return(vs)
}

# Extract version string from interact object

versionstring.interact <- function(object) {
  verifyclass(object, "interact")
  v <- object$version
  return(v)  # NULL before 1.11-0
}

# Get version number of current spatstat installation
# This is now saved in the spatstat cache environment rather than read from file every time

versionstring.spatstat <- function() {
  getSpatstatVariable("SpatstatVersion")
}

store.versionstring.spatstat <- function() {
  vs <- read.dcf(file=system.file("DESCRIPTION", package="spatstat"),
                 fields="Version")
  vs <- as.character(vs)
  putSpatstatVariable("SpatstatVersion", vs)
}


# Extract major and minor versions only.

majorminorversion <- function(v) {
  vp <- package_version(v)
  return(package_version(paste(vp$major, vp$minor, sep=".")))
}

# legacy function

RandomFieldsSafe <- function() { TRUE }
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/weights.R"
#
#	weights.S
#
#	Utilities for computing quadrature weights
#
#	$Revision: 4.33 $	$Date: 2014/12/19 14:08:19 $
#
#
# Main functions:
		
#	gridweights()	    Divide the window frame into a regular nx * ny
#			    grid of rectangular tiles. Given an arbitrary
#			    pattern of (data + dummy) points derive the
#			    'counting weights'.
#
#	dirichlet.weights() Compute the areas of the tiles of the
#			    Dirichlet tessellation generated by the 
#			    given pattern of (data+dummy) points,
#			    restricted to the window.
#	
# Auxiliary functions:	
#			
#       countingweights()   compute the counting weights
#                           for a GENERIC tiling scheme and an arbitrary
#			    pattern of (data + dummy) points,
#			    given the tile areas and the information
#			    that point number k belongs to tile number id[k]. 
#
#
#	gridindex()	    Divide the window frame into a regular nx * ny
#			    grid of rectangular tiles. 
#			    Compute tile membership for arbitrary x,y.
#				    
#       grid1index()        1-dimensional analogue of gridindex()
#
#
#-------------------------------------------------------------------
	
countingweights <- function(id, areas, check=TRUE) {
	#
	# id:        cell indices of n points
	#                     (length n, values in 1:k)
	#
	# areas:     areas of k cells 
	#                     (length k)
	#
  id <- as.integer(id)
  fid <- factor(id, levels=seq_along(areas))
  counts <- table(fid)
  w <- areas[id] / counts[id]     # ensures denominator > 0
  w <- as.vector(w)
#	
# that's it; but check for funny business
#
  if(check) {
    zerocount <- (counts == 0)
    zeroarea <- (areas == 0)
    if(any(uhoh <- !zeroarea & zerocount)) {
      lostfrac <- sum(areas[uhoh])/sum(areas)
      warning(paste("some tiles with positive area do not contain any points:",
                    "relative error =", signif(lostfrac, 4)))
    }
    if(any(!zerocount & zeroarea)) {
	warning("Some tiles with zero area contain points")
	warning("Some weights are zero")
	attr(w, "zeroes") <- zeroarea[id]
    }
  }
#
  names(w) <- NULL
  return(w)
}

gridindex <- function(x, y, xrange, yrange, nx, ny) {
	#
	# The box with dimensions xrange, yrange is divided
	# into nx * ny cells.
	#
	# For each point (x[i], y[i]) compute the index (ix, iy)
	# of the cell containing the point.
	# 
	ix <- grid1index(x, xrange, nx)
	iy <- grid1index(y, yrange, ny)
	#
	return(list(ix=ix, iy=iy, index=as.integer((iy-1) * nx + ix)))
}

grid1index <- function(x, xrange, nx) {
	i <- ceiling( nx * (x - xrange[1])/diff(xrange))
	i <- pmax.int(1, i)
	i <- pmin.int(i, nx)
	i
}

gridweights <- function(X, ntile=NULL, ..., window=NULL, verbose=FALSE,
                        npix=NULL, areas=NULL) {
	#
	# Compute counting weights based on a regular tessellation of the
	# window frame into ntile[1] * ntile[2] rectangular tiles.
	#
	# Arguments X and (optionally) 'window' are interpreted as a
	# point pattern.
	#
	# The window frame is divided into a regular ntile[1] * ntile[2] grid
	# of rectangular tiles. The counting weights based on this tessellation
	# are computed for the points (x, y) of the pattern.
	#
        # 'npix' determines the dimensions of the pixel raster used to
        # approximate tile areas.
	
	X <- as.ppp(X, window)
	x <- X$x
	y <- X$y
        win <- X$window

        # determine number of tiles
        if(is.null(ntile))
          ntile <- default.ntile(X)
        if(length(ntile) == 1)
          ntile <- rep.int(ntile, 2)
        nx <- ntile[1]
        ny <- ntile[2]

        if(verbose) 
          cat(paste("grid weights for a", nx, "x", ny, "grid of tiles\n"))
        
        if(is.null(npix)) npix <- rev(spatstat.options("npixel"))
        npix <- ensure2vector(npix)
        
        if(is.null(areas)) {
  	  # compute tile areas
          if(win$type == "rectangle") {

            tilearea <- area(win)/(nx * ny)
            areas <- rep.int(tilearea, nx * ny)

          } else {
            # convert window to mask
            win <- as.mask(win, dimyx=rev(npix))

            if(verbose) 
              splat(paste0("Approximating window by mask (",
                           npix[1], " x ", npix[2], " pixels)"))
                
            # extract pixel coordinates inside window
            rxy <- rasterxy.mask(win, drop=TRUE)
            xx <- rxy$x
            yy <- rxy$y
                                
	    # classify all pixels into tiles
            pixelid <- gridindex(xx, yy, 
                                 win$xrange, win$yrange, nx, ny)$index
            pixelid <- factor(pixelid, levels=seq_len(nx * ny))
                                
	    # compute digital areas of tiles
            tilepixels <- as.vector(table(pixelid))
            pixelarea <- win$xstep * win$ystep
            areas <- tilepixels * pixelarea
            zeroareas <- (tilepixels == 0)
          } 
        } else zeroareas <- (areas == 0)
        
        id <- gridindex(x, y, win$xrange, win$yrange, nx, ny)$index

        if(win$type != "rectangle" && any(uhoh <- zeroareas[id])) {
          # this can happen: the tile has digital area zero
          # but contains a data/dummy point 
          if(win$type != "mask") 
            pixelarea <- area(Frame(win))/prod(npix)
          slivers <- unique(id[uhoh])
          areas[slivers] <- pixelarea/2
        }
        
	# compute counting weights 
	w <- countingweights(id, areas)

        # attach information about weight construction parameters
        attr(w, "weight.parameters") <-
          list(method="grid", ntile=ntile, npix=npix, areas=areas)
        
	return(w)
}


dirichlet.weights <- function(X, window = NULL, exact=TRUE, ...) {
	#
	# Compute weights based on Dirichlet tessellation of the window 
	# induced by the point pattern X. 
	# The weights are just the tile areas.
	#
	# NOTE:	X should contain both data and dummy points,
	# if you need these weights for the B-T-B method.
	#
	# Arguments X and (optionally) 'window' are interpreted as a
	# point pattern.
	#
	# If the window is a rectangle, we invoke Rolf Turner's "deldir"
	# package to compute the areas of the tiles of the Dirichlet
	# tessellation of the window frame induced by the points.
	# [NOTE: the functionality of deldir to create dummy points
	# is NOT used. ]
	#	if exact=TRUE	compute the exact areas, using "deldir"
	#	if exact=FALSE      compute the digital areas using exactdt()
	# 
	# If the window is a mask, we compute the digital area of
	# each tile of the Dirichlet tessellation by counting pixels.
	#
	#
	# 
	#
	
	X <- as.ppp(X, window)
	x <- X$x
	y <- X$y
	win <- X$window

	if(exact && (win$type == "rectangle")) {
		rw <- c(win$xrange, win$yrange)
	        # invoke deldir() with NO DUMMY POINTS
		tessellation <- deldir(x, y, dpl=NULL, rw=rw)
	        # extract tile areas
	        w <- tessellation$summary[, 'dir.area']
	} else {
		# Compute digital areas of Dirichlet tiles.
                win <- as.mask(win)
                X$window <- win
		#
                # Nearest data point to each pixel:
                tileid <- exactdt(X)$i
                # 
		if(win$type == "mask") 
			# Restrict to window (result is a vector - OK)
			tileid <- tileid[win$m]
		# Count pixels in each tile
		id <- factor(tileid, levels=seq_len(X$n))
		counts <- table(id)
                # turn off the christmas lights
                class(counts) <- NULL
                names(counts) <- NULL
                dimnames(counts) <- NULL
		# Convert to digital area
		pixelarea <- win$xstep * win$ystep
		w <- pixelarea * counts
		# Check for zero pixel counts
		zeroes <- (counts == 0)
		if(any(zeroes)) {
			warning("some Dirichlet tiles have zero digital area")
			attr(w, "zeroes") <- zeroes
		}
	} 
        # attach information about weight construction parameters
        attr(w, "weight.parameters") <- list(method="dirichlet", exact=exact)

        return(w)
}

default.ntile <- function(X) { 
	# default number of tiles (n x n) for tile weights
        # when data and dummy points are X
  X <- as.ppp(X)
  guess.ngrid <- 10 * floor(sqrt(X$n)/10)
  max(5, guess.ngrid/2)
}

#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/window.R"
#
#	window.S
#
#	A class 'owin' to define the "observation window"
#
#	$Revision: 4.156 $	$Date: 2014/11/10 05:38:43 $
#
#
#	A window may be either
#
#		- rectangular:
#                       a rectangle in R^2
#                       (with sides parallel to the coordinate axes)
#
#		- polygonal:
#			delineated by 0, 1 or more non-self-intersecting
#                       polygons, possibly including polygonal holes.
#	
#		- digital mask:
#			defined by a binary image
#			whose pixel values are TRUE wherever the pixel
#                       is inside the window
#
#	Any window is an object of class 'owin', 
#       containing at least the following entries:	
#
#		$type:	a string ("rectangle", "polygonal" or "mask")
#
#		$xrange   
#		$yrange
#			vectors of length 2 giving the real dimensions 
#			of the enclosing box
#               $units
#                       name of the unit of length
#
#	The 'rectangle' type has only these entries.
#
#       The 'polygonal' type has an additional entry
#
#               $bdry
#                       a list of polygons.
#                       Each entry bdry[[i]] determines a closed polygon.
#
#                       bdry[[i]] has components $x and $y which are
#                       the cartesian coordinates of the vertices of
#                       the i-th boundary polygon (without repetition of
#                       the first vertex, i.e. same convention as in the
#                       plotting function polygon().)
#
#
#	The 'mask' type has entries
#
#		$m		logical matrix
#		$dim		its dimension array
#		$xstep,ystep	x and y dimensions of a pixel
#		$xcol	        vector of x values for each column
#               $yrow           vector of y values for each row
#	
#	(the row index corresponds to increasing y coordinate; 
#	 the column index "   "     "   "  "  "  x "   "    ".)
#
#
#-----------------------------------------------------------------------------
#

.Spatstat.Image.Warning <-
  c("Row index corresponds to increasing y coordinate; column to increasing x",
    "Transpose matrices to get the standard presentation in R",
    "Example: image(result$xcol,result$yrow,t(result$d))")

owin <- function(xrange=c(0,1), yrange=c(0,1),
                 ..., poly=NULL, mask=NULL, unitname=NULL, xy=NULL) {

  unitname <- as.units(unitname)

  ## Exterminate ambiguities
  poly.given <- !is.null(poly)
  mask.given <- !is.null(mask)
  if(poly.given  && mask.given)
     stop("Ambiguous -- both polygonal boundary and digital mask supplied")

  if(!is.null(xy) && !mask.given)
    warning("Argument xy ignored: it is only applicable when a mask is given")
     
  if(missing(xrange) != missing(yrange))
    stop("If one of xrange, yrange is specified then both must be.")

  # convert data frames to vanilla lists
  if(poly.given) {
    if(is.data.frame(poly))
      poly <- as.list(poly)
    else if(is.list(poly) && any(unlist(lapply(poly, is.data.frame))))
      poly <- lapply(poly, as.list)
  }
  
  ## Hidden options controlling how much checking is performed
  check <- resolve.1.default(list(check=TRUE), list(...))
  calculate <- resolve.1.default(list(calculate=check), list(...))
  strict <- resolve.1.default(list(strict=spatstat.options("checkpolygons")),
                              list(...))
  fix <- resolve.1.default(list(fix=spatstat.options("fixpolygons")),
                           list(...))

  if(!poly.given && !mask.given) {
    ######### rectangle #################
    if(check) {
      if(!is.vector(xrange) || length(xrange) != 2 || xrange[2] < xrange[1])
        stop("xrange should be a vector of length 2 giving (xmin, xmax)")
      if(!is.vector(yrange) || length(yrange) != 2 || yrange[2] < yrange[1])
        stop("yrange should be a vector of length 2 giving (ymin, ymax)")
    }
    w <- list(type="rectangle", xrange=xrange, yrange=yrange, units=unitname)
    class(w) <- "owin"
    return(w)
  } else if(poly.given) {
    ######### polygonal boundary ########
    #
    if(length(poly) == 0) {
      # empty polygon
      if(check) {
        if(!is.vector(xrange) || length(xrange) != 2 || xrange[2] < xrange[1])
          stop("xrange should be a vector of length 2 giving (xmin, xmax)")
        if(!is.vector(yrange) || length(yrange) != 2 || yrange[2] < yrange[1])
          stop("yrange should be a vector of length 2 giving (ymin, ymax)")
      }
      w <- list(type="polygonal", xrange=xrange, yrange=yrange,
                bdry=list(), units=unitname)
      class(w) <- "owin"
      return(w)
    }
    # convert matrix or data frame to list(x,y)
    isxy <- function(x) { (is.matrix(x) || is.data.frame(x)) && ncol(x) == 2 }
    asxy <- function(xy) { list(x=xy[,1], y=xy[,2]) }
    if(isxy(poly)) {
      poly <- asxy(poly)
    } else if(is.list(poly) && all(unlist(lapply(poly, isxy)))) {
      poly <- lapply(poly, asxy)
    }
    # nonempty polygon  
    # test whether it's a single polygon or multiple polygons
    if(verify.xypolygon(poly, fatal=FALSE))
      psingle <- TRUE
    else if(all(unlist(lapply(poly, verify.xypolygon, fatal=FALSE))))
      psingle <- FALSE
    else
      stop("poly must be either a list(x,y) or a list of list(x,y)")

    w.area <- NULL
    
    if(psingle) {
      # single boundary polygon
      bdry <- list(poly)
      if(check || calculate) {
        w.area <- Area.xypolygon(poly)
        if(w.area < 0)
          stop(paste("Area of polygon is negative -",
                     "maybe traversed in wrong direction?"))
      }
    } else {
      # multiple boundary polygons
      bdry <- poly
      if(check || calculate) {
        w.area <- unlist(lapply(poly, Area.xypolygon))
        if(sum(w.area) < 0)
          stop(paste("Area of window is negative;\n",
                     "check that all polygons were traversed",
                     "in the right direction"))
      }
    }

    actual.xrange <- range(unlist(lapply(bdry, function(a) a$x)))
    if(missing(xrange))
      xrange <- actual.xrange
    else if(check) {
      if(!is.vector(xrange) || length(xrange) != 2 || xrange[2] <= xrange[1])
        stop("xrange should be a vector of length 2 giving (xmin, xmax)")
      if(!all(xrange == range(c(xrange, actual.xrange))))
        stop("polygon's x coordinates outside xrange")
    }
    
    actual.yrange <- range(unlist(lapply(bdry, function(a) a$y)))
    if(missing(yrange))
      yrange <- actual.yrange
    else if(check) {
      if(!is.vector(yrange) || length(yrange) != 2 || yrange[2] <= yrange[1])
        stop("yrange should be a vector of length 2 giving (ymin, ymax)")
      if(!all(yrange == range(c(yrange, actual.yrange))))
      stop("polygon's y coordinates outside yrange")
    }

    if(!is.null(w.area)) {
      # tack on area and hole data
      holes <- (w.area < 0)
      for(i in seq_along(bdry)) 
        bdry[[i]] <- append(bdry[[i]], list(area=w.area[i], hole=holes[i]))
    }
    
    w <- list(type="polygonal",
              xrange=xrange, yrange=yrange, bdry=bdry, units=unitname)
    class(w) <- "owin"

    if(check && strict) { 
      ## strict checks on geometry (self-intersection etc)
      ok <- owinpolycheck(w)
      if(!ok) {
        errors <- attr(ok, "err")
        stop(paste("Polygon data contain", commasep(errors)))
      }
    }
    if(check && fix) {
      if(length(bdry) == 1 &&
         length(bx <- bdry[[1]]$x) == 4 &&
         length(unique(bx)) == 2 &&
         length(unique(bdry[[1]]$y)) == 2) {
        ## it's really a rectangle
        if(Area.xypolygon(bdry[[1]]) < 0)
          w$bdry <- lapply(bdry, reverse.xypolygon)
      } else {
        ## repair polygon data by invoking polyclip
        ##        to intersect polygon with larger-than-bounding rectangle
        ##        (Streamlined version of intersect.owin)
        ww <- lapply(bdry, reverse.xypolygon)
        xrplus <- mean(xrange) + c(-1,1) * diff(xrange)
        yrplus <- mean(yrange) + c(-1,1) * diff(yrange)
        bignum <- (.Machine$integer.max^2)/2
        epsclip <- max(diff(xrange), diff(yrange))/bignum
        rr <- list(list(x=xrplus[c(1,2,2,1)], y=yrplus[c(2,2,1,1)]))
        bb <- polyclip::polyclip(ww, rr, "intersection",
                                 fillA="nonzero", fillB="nonzero", eps=epsclip)
        ## ensure correct polarity
        totarea <- sum(unlist(lapply(bb, Area.xypolygon)))
        if(totarea < 0)
          bb <- lapply(bb, reverse.xypolygon)
        w$bdry <- bb
      }
    }
    return(w)
  } else if(mask.given) {
    ######### digital mask #####################
    
    if(!is.matrix(mask))
      stop(paste(sQuote("mask"), "must be a matrix"))
    if(!is.logical(mask))
      stop(paste("The entries of", sQuote("mask"), "must be logical"))
    
    nc <- ncol(mask)
    nr <- nrow(mask)

    if(!is.null(xy)) {
      # pixel coordinates given explicitly
      # validate dimensions
      if(!is.list(xy) || !checkfields(xy, c("x","y")))
        stop("xy should be a list with entries x and y")
      xcol <- xy$x
      yrow <- xy$y
      if(length(xcol) != nc)
        stop(paste("length of xy$x =", length(xcol),
                   "!=", nc, "= number of columns of mask"))
      if(length(yrow) != nr)
        stop(paste("length of xy$y =", length(yrow),
                   "!=", nr, "= number of rows of mask"))
      # x and y should be evenly spaced
      if(!evenly.spaced(xcol))
        stop("xy$x is not evenly spaced")
      if(!evenly.spaced(yrow))
        stop("xy$y is not evenly spaced")
      # determine other parameters
      xstep <- diff(xcol)[1]
      ystep <- diff(yrow)[1]
      if(missing(xrange) && missing(yrange)) {
        xrange <- range(xcol) + c(-1,1) * xstep/2
        yrange <- range(yrow) + c(-1,1) * ystep/2
      }
    } else {
      # determine pixel coordinates from xrange, yrange
      if(missing(xrange) && missing(yrange)) {
        # take pixels to be 1 x 1 unit
        xrange <- c(0,nc)
        yrange <- c(0,nr)
      } else if(check) {
        if(!is.vector(xrange) || length(xrange) != 2 || xrange[2] <= xrange[1])
          stop("xrange should be a vector of length 2 giving (xmin, xmax)")
        if(!is.vector(yrange) || length(yrange) != 2 || yrange[2] <= yrange[1])
          stop("yrange should be a vector of length 2 giving (ymin, ymax)")
      }
      xstep <- diff(xrange)/nc
      ystep <- diff(yrange)/nr
      xcol  <- seq(from=xrange[1]+xstep/2, to=xrange[2]-xstep/2, length.out=nc)
      yrow  <- seq(from=yrange[1]+ystep/2, to=yrange[2]-ystep/2, length.out=nr)
    }

    out <- list(type     = "mask",
                xrange   = xrange,
                yrange   = yrange,
                dim      = c(nr, nc),
                xstep    = xstep,
                ystep    = ystep,
                warnings = .Spatstat.Image.Warning,
                xcol    = xcol, 
                yrow    = yrow,
                m       = mask,
                units   = unitname)
    class(out) <- "owin"
    return(out)
  }
  # never reached
  NULL
}

#
#-----------------------------------------------------------------------------
#

is.owin <- function(x) { inherits(x, "owin") }

#
#-----------------------------------------------------------------------------
#

as.owin <- function(W, ..., fatal=TRUE) {
  UseMethod("as.owin")
}

as.owin.owin <- function(W, ..., fatal=TRUE) {
  if(verifyclass(W, "owin", fatal=fatal)) 
    return(owin(W$xrange, W$yrange, poly=W$bdry, mask=W$m, unitname=unitname(W), check=FALSE))
  else
    return(NULL)
}

as.owin.ppp <- function(W, ..., fatal=TRUE) {
  if(verifyclass(W, "ppp", fatal=fatal))
    return(W$window)
  else
    return(NULL)
}

as.owin.quad <- function(W, ..., fatal=TRUE) {
  if(verifyclass(W, "quad", fatal=fatal))
    return(W$data$window)
  else
    return(NULL)
}

as.owin.im <- function(W, ..., fatal=TRUE) {
  if(!verifyclass(W, "im", fatal=fatal))
    return(NULL)
  out <- list(type     = "mask",
              xrange   = W$xrange,
              yrange   = W$yrange,
              dim      = W$dim,
              xstep    = W$xstep,
              ystep    = W$ystep,
              warnings = .Spatstat.Image.Warning,
              xcol    = W$xcol,
              yrow    = W$yrow,
              m       = !is.na(W$v),
              units   = unitname(W))
  class(out) <- "owin"
  return(out)
}

as.owin.psp <- function(W, ..., fatal=TRUE) {
  if(!verifyclass(W, "psp", fatal=fatal))
    return(NULL)
  return(W$window)
}

as.owin.tess <- function(W, ..., fatal=TRUE) {
  if(!verifyclass(W, "tess", fatal=fatal))
    return(NULL)
  return(W$window)
}

as.owin.data.frame <- function(W, ..., fatal=TRUE) {
  if(!verifyclass(W, "data.frame", fatal=fatal))
    return(NULL)
  if(ncol(W) != 3) {
    whinge <- "need exactly 3 columns of data"
    if(fatal) stop(whinge)
    warning(whinge)
    return(NULL)
  }
  mch <- match(c("x", "y"), names(W))
  if(!any(is.na(mch))) {
    ix <- mch[1]
    iy <- mch[2]
    iz <- (1:3)[-mch]
  } else {
    ix <- 1
    iy <- 2
    iz <- 3
  }
  df <- data.frame(x=W[,ix], y=W[,iy], z=as.logical(W[,iz]))
  # convert data frame (x,y,z) to logical matrix
  m <- with(df, tapply(z, list(y, x), any))
  # extract pixel coordinates
  xy <- with(df, list(x=sort(unique(x)), y=sort(unique(y))))
  # make binary mask
  out <- owin(mask=m, xy=xy)
  return(out)
}

as.owin.default <- function(W, ..., fatal=TRUE) {
  ## Tries to interpret data as an object of class 'owin'
  ## W may be
  ##	a structure with entries xrange, yrange
  ##	a four-element vector (interpreted xmin, xmax, ymin, ymax)
  ##	a structure with entries xl, xu, yl, yu
  ##	an object with attribute "bbox"

  if(checkfields(W, c("xrange", "yrange"))) {
    Z <- owin(W$xrange, W$yrange)
    return(Z)
  } else if(is.vector(W) && is.numeric(W) && length(W) == 4) {
    Z <- owin(W[1:2], W[3:4])
    return(Z)
  } else if(checkfields(W, c("xl", "xu", "yl", "yu"))) {
    W <- as.list(W)
    Z <- owin(c(W$xl, W$xu),c(W$yl, W$yu))
    return(Z)
  } else if(checkfields(W, c("x", "y", "area"))
            && checkfields(W$area, c("xl", "xu", "yl", "yu"))) {
    V <- as.list(W$area)
    Z <- owin(c(V$xl, V$xu),c(V$yl, V$yu))
    return(Z)
  } else if(!is.null(Z <- attr(W, "bbox"))) {
    return(as.owin(Z, ..., fatal=fatal))
  } else if(fatal)
    stop("Can't interpret W as a window")
  else return(NULL)
}		

#
#-----------------------------------------------------------------------------
#
#
Frame <- function(X) { UseMethod("Frame") }

"Frame<-" <- function(X, value) { UseMethod("Frame<-") }

Frame.default <- function(X) { as.rectangle(X) }

## .........................................................

as.rectangle <- function(w, ...) {
  if(inherits(w, "owin"))
    return(owin(w$xrange, w$yrange, unitname=unitname(w)))
  else if(inherits(w, "im"))
    return(owin(w$xrange, w$yrange, unitname=unitname(w)))
  else if(inherits(w, "layered")) 
    return(do.call(boundingbox, unname(lapply(w, as.rectangle))))
  else {
    w <- as.owin(w, ...)
    return(owin(w$xrange, w$yrange, unitname=unitname(w)))
  }
}

#
#-----------------------------------------------------------------------------
#
as.mask <- function(w, eps=NULL, dimyx=NULL, xy=NULL) {
#	eps:		   grid mesh (pixel) size
#	dimyx:		   dimensions of pixel raster
#       xy:                coordinates of pixel raster  
  if(!missing(w) && !is.null(w)) {
    if(is.matrix(w))
      return(owin(mask=w, xy=xy))
    w <- as.owin(w)
    uname <- unitname(w)
  } else {
    uname <- as.units(NULL)
    if(is.null(xy)) 
      stop("If w is missing, xy is required")
  }
  # If it's already a mask, and no other arguments specified,
  # just return it.
  if(!missing(w) && w$type == "mask" &&
     is.null(eps) && is.null(dimyx) && is.null(xy))
    return(w)
  
##########################
#  First determine pixel coordinates
##########################
  if(is.null(xy)) {
# Pixel coordinates to be computed from other dimensions
# First determine row & column dimensions
    if(!is.null(dimyx)) {
      dimyx <- ensure2vector(dimyx)
      nr <- dimyx[1]
      nc <- dimyx[2]
    } else {
    # use pixel size 'eps'
      if(!is.null(eps)) {
        eps <- ensure2vector(eps)
        nc <- diff(w$xrange)/eps[1]
        nr <- diff(w$yrange)/eps[2]
        if(nr < 1 || nc < 1)
          warning("pixel size parameter eps > size of window")
        nr <- ceiling(nr)
        nc <- ceiling(nc)
      } else {
    # use spatstat defaults
        np <- spatstat.options("npixel")
        if(length(np) == 1)
          nr <- nc <- np[1]
        else {
          nr <- np[2]  
          nc <- np[1]
        }
      }
    }
    # Initialise mask with all entries TRUE
    rasta <- owin(w$xrange, w$yrange, mask=matrix(TRUE, nr, nc))
  } else {
# 
# Pixel coordinates given explicitly:
#    xy is an image, a mask, or a list(x,y)
#
    if(is.im(xy)) {
      rasta <- as.owin(xy)
      rasta$m[] <- TRUE
    } else if(is.owin(xy)) {
      if(xy$type != "mask")
        stop("argument xy does not contain raster coordinates.")
      rasta <- xy
      rasta$m[] <- TRUE
    } else {
      if(!checkfields(xy, c("x", "y")))
        stop(paste(sQuote("xy"),
                   "should be a list containing two vectors x and y"))
      x <- sort(unique(xy$x))
      y <- sort(unique(xy$y))
      # derive other parameters
      nr <- length(y)
      nc <- length(x)
      # x and y pixel sizes
      dx <- diff(x)
      if(diff(range(dx)) > 0.01 * mean(dx))
        stop("x coordinates must be evenly spaced")
      xstep <- mean(dx)
      dy <- diff(y)
      if(diff(range(dy)) > 0.01 * mean(dy))
        stop("y coordinates must be evenly spaced")
      ystep <- mean(dy)
      xr <- range(x)
      yr <- range(y)
      xrange <-  xr + xstep * c(-1,1)/2
      yrange <-  yr + ystep * c(-1,1)/2
      # initialise mask with all entries TRUE
      rasta <- list(type     = "mask",
                    xrange   = xrange,
                    yrange   = yrange,
                    dim      = c(nr, nc),
                    xstep    = xstep,
                    ystep    = ystep,
                    warnings = .Spatstat.Image.Warning,
                    xcol    = seq(from=xr[1], to=xr[2], length.out=nc),
                    yrow    = seq(from=yr[1], to=yr[2], length.out=nr),
                    m       = matrix(TRUE, nr, nc),
                    units   = uname)
      class(rasta) <- "owin"
    }
    # window may be implicit in this case.
    if(missing(w))
      w <- owin(xrange, yrange)
  }

################################  
# Second, mask pixel raster with existing window
################################  
  switch(w$type,
         rectangle = {
           out <- rasta
           if(!all(w$xrange == rasta$xrange)
              || !all(w$yrange == rasta$yrange)) {
             xcol <- rasta$xcol
             yrow <- rasta$yrow
             wx <- w$xrange
             wy <- w$yrange
             badrow <- which(yrow > wy[2] | yrow < wy[1])
             badcol <- which(xcol > wx[2] | xcol < wx[1])
             out$m[badrow , ] <- FALSE
             out$m[ , badcol] <- FALSE
           }
         },
         mask = {
           # resample existing mask on new raster
           out <- rastersample(w, rasta)
         },
         polygonal = {
           # use C code
           out <- owinpoly2mask(w, rasta, FALSE)
         })

  unitname(out) <- uname
  return(out)
}

as.matrix.owin <- function(x, ...) {
  m <- as.mask(x, ...)
  return(m$m)
}

#
#
#-----------------------------------------------------------------------------
#
as.polygonal <- function(W) {
  verifyclass(W, "owin")
  switch(W$type,
         rectangle = {
           xr <- W$xrange
           yr <- W$yrange
           return(owin(xr, yr, poly=list(x=xr[c(1,2,2,1)],y=yr[c(1,1,2,2)]),
                       unitname=unitname(W),
                       check=FALSE))
         },
         polygonal = {
           return(W)
         },
         mask = {
           # This could take a while
           M <- W$m
           nr <- nrow(M)
           notM <- !M
           out <- NULL
           xcol <- W$xcol
           yrow <- W$yrow
           xbracket <- 1.1 * c(-1,1) * W$xstep/2
           ybracket <- 1.1 * c(-1,1) * W$ystep/2
           # identify runs of TRUE entries in each column
           start <- M & rbind(TRUE, notM[-nr, ])
           finish <- M & rbind(notM[-1, ], TRUE)
           for(j in 1:ncol(M)) {
             xj <- xcol[j]
             # identify start and end positions in column j
             starts <- which(start[,j])
             finishes <- which(finish[,j])
             ns <- length(starts)
             nf <- length(finishes)
             if(ns != nf)
               stop(paste("Internal error: length(starts)=", ns,
                          ", length(finishes)=", nf))
             if(ns > 0) {
               for(k in 1:ns) {
                 yfrom <- yrow[starts[k]]
                 yto   <- yrow[finishes[k]]
                 yk <- sort(c(yfrom,yto))
                 # make rectangle
                 recto <- owin(xj+xbracket,yk+ybracket)
                 # add to result
                 out <- union.owin(out, recto)
               }
               unitname(out) <- unitname(W)
             }
           }
           return(out)
         }
         )
}

#
# ----------------------------------------------------------------------

is.polygonal <- function(w) {
  return(inherits(w, "owin") && (w$type == "polygonal"))
}

is.rectangle <- function(w) {
  return(inherits(w, "owin") && (w$type == "rectangle"))
}

is.mask <- function(w) {
  return(inherits(w, "owin") && (w$type == "mask"))
}

validate.mask <- function(w, fatal=TRUE) {
  verifyclass(w, "owin", fatal=fatal)
  if(w$type == "mask")
    return(TRUE)
  if(fatal)
      stop(paste(short.deparse(substitute(w)), "is not a binary mask"))
  else {
      warning(paste(short.deparse(substitute(w)), "is not a binary mask"))
      return(FALSE)
  }
}

dim.owin <- function(x) { return(x$dim) } ## NULL unless it's a mask

## internal use only:

rasterx.mask <- function(w, drop=FALSE) {
  validate.mask(w)
  x <- w$xcol[col(w)]
  x <- if(drop) x[w$m, drop=TRUE] else array(x, dim=w$dim)
  return(x)
}

rastery.mask <- function(w, drop=FALSE) {
  validate.mask(w)
  y <- w$yrow[row(w)]
  y <- if(drop) y[w$m, drop=TRUE] else array(y, dim=w$dim)
  return(y)
}

rasterxy.mask <- function(w, drop=FALSE) {
  validate.mask(w)
  x <- w$xcol[col(w)]
  y <- w$yrow[row(w)]
  if(drop) {
    m <- w$m
    x <- x[m, drop=TRUE] 
    y <- y[m, drop=TRUE]
  }
  return(list(x=as.numeric(x),
              y=as.numeric(y)))
}
  
nearest.raster.point <- function(x,y,w, indices=TRUE) {
  stopifnot(is.mask(w) || is.im(w))
  nr <- w$dim[1]
  nc <- w$dim[2]
  if(length(x) == 0) {
    cc <- rr <- integer(0)
  } else {
    cc <- 1 + round((x - w$xcol[1])/w$xstep)
    rr <- 1 + round((y - w$yrow[1])/w$ystep)
    cc <- pmax.int(1,pmin.int(cc, nc))
    rr <- pmax.int(1,pmin.int(rr, nr))
  }
  if(indices) 
    return(list(row=rr, col=cc))
  else
    return(list(x=w$xcol[cc], y=w$yrow[rr]))
}

mask2df <- function(w) {
  stopifnot(is.owin(w) && w$type == "mask")
  xx <- raster.x(w)
  yy <- raster.y(w)
  ok <- w$m
  xx <- as.vector(xx[ok])
  yy <- as.vector(yy[ok])
  return(data.frame(x=xx, y=yy))
}

#------------------------------------------------------------------
		
complement.owin <- function(w, frame=as.rectangle(w)) {
  w <- as.owin(w)

  if(reframe <- !missing(frame)) {
    verifyclass(frame, "owin")
    w <- rebound.owin(w, frame)
    # if w was a rectangle, it's now polygonal
  }

  switch(w$type,
         mask = {
           w$m <- !(w$m)
         },
         rectangle = {
           # return empty window
           return(emptywindow(w))
         },
         polygonal = {
           bdry <- w$bdry
           if(length(bdry) == 0) {
             # w is empty
             return(frame)
           }
           # bounding box, in anticlockwise order
           box <- list(x=w$xrange[c(1,2,2,1)],
                       y=w$yrange[c(1,1,2,2)])
           boxarea <- Area.xypolygon(box)
                 
           # first check whether one of the current boundary polygons
           # is the bounding box itself (with + sign)
           if(reframe)
             is.box <- rep.int(FALSE, length(bdry))
           else {
             nvert <- unlist(lapply(bdry, function(a) { length(a$x) }))
             areas <- unlist(lapply(bdry, Area.xypolygon))
             boxarea.mineps <- boxarea * (0.99999)
             is.box <- (nvert == 4 & areas >= boxarea.mineps)
             if(sum(is.box) > 1)
               stop("Internal error: multiple copies of bounding box")
             if(all(is.box)) {
               return(emptywindow(box))
             }
           }
                 
           # if box is present (with + sign), remove it
           if(any(is.box))
             bdry <- bdry[!is.box]
                 
           # now reverse the direction of each polygon
           bdry <- lapply(bdry, reverse.xypolygon, adjust=TRUE)

           # if box was absent, add it
           if(!any(is.box))
             bdry <- c(bdry, list(box))   # sic

           # put back into w
           w$bdry <- bdry
         },
         stop("unrecognised window type", w$type)
         )
  return(w)
}

#-----------------------------------------------------------

inside.owin <- function(x, y, w) {
  # test whether (x,y) is inside window w
  # x, y may be vectors 

  if(missing(y) && all(c("x", "y") %in% names(x)))
    return(inside.owin(x$x, x$y, w))

  w <- as.owin(w)

  if(length(x)==0)
    return(logical(0))
  
  # test whether inside bounding rectangle
  xr <- w$xrange
  yr <- w$yrange
  eps <- sqrt(.Machine$double.eps)
  frameok <- (x >= xr[1] - eps) & (x <= xr[2] + eps) & 
             (y >= yr[1] - eps) & (y <= yr[2] + eps)
 
  if(!any(frameok))  # all points OUTSIDE window - no further work needed
    return(frameok)

  ok <- frameok
  switch(w$type,
         rectangle = {
           return(ok)
         },
         polygonal = {
           xy <- list(x=x,y=y)
           bdry <- w$bdry
           total <- numeric(length(x))
           on.bdry <- rep.int(FALSE, length(x))
           for(i in seq_along(bdry)) {
             score <- inside.xypolygon(xy, bdry[[i]], test01=FALSE)
             total <- total + score
             on.bdry <- on.bdry | attr(score, "on.boundary")
           }
           # any points identified as belonging to the boundary get score 1
           total[on.bdry] <- 1
           # check for sanity now..
           uhoh <- (total * (1-total) != 0)
           if(any(uhoh)) {
             nuh <- sum(uhoh)
             warning(paste("point-in-polygon test had difficulty with",
                           nuh,
                           ngettext(nuh, "point", "points"),
                           "(total score not 0 or 1)"),
                     call.=FALSE)
             total[uhoh] <- 0
           }
           return(ok & (total != 0))
         },
         mask = {
           # consider only those points which are inside the frame
           xf <- x[frameok]
           yf <- y[frameok]
           # map locations to raster (row,col) coordinates
           loc <- nearest.raster.point(xf,yf,w)
           # look up mask values
           okf <- (w$m)[cbind(loc$row, loc$col)]
           # insert into 'ok' vector
           ok[frameok] <- okf
           return(ok)
         },
         stop("unrecognised window type", w$type)
         )
}

#-------------------------------------------------------------------------
  
print.owin <- function(x, ...) {
  verifyclass(x, "owin")
  unitinfo <- summary(unitname(x))
  switch(x$type,
         rectangle={
           rectname <- "window: rectangle ="
         },
         polygonal={
           cat("window:", "polygonal", "boundary", fill=TRUE)
           if(length(x$bdry) == 0)
             cat("window is empty\n")
           rectname <- "enclosing rectangle:"
         },
         mask={
           cat("window: binary", "image mask", fill=TRUE)
           di <- x$dim
           cat(di[1], "x", di[2], "pixel array (ny, nx)", fill=TRUE)
           rectname <- "enclosing rectangle:"
         }
         )
  cat(rectname,
      prange(zapsmall(x$xrange)),
      "x",
      prange(zapsmall(x$yrange)),
      unitinfo$plural,
      unitinfo$explain,
      fill=TRUE)
  invisible(NULL)
}

summary.owin <- function(object, ...) {
  verifyclass(object, "owin")
  result <- list(xrange=object$xrange,
                 yrange=object$yrange,
                 type=object$type,
                 area=area(object),
                 units=unitname(object))
  switch(object$type,
         rectangle={
         },
         polygonal={
           poly <- object$bdry
           result$npoly <- npoly <- length(poly)
           if(npoly == 0) {
             result$areas <- result$nvertices <- numeric(0)
           } else if(npoly == 1) {
             result$areas <- Area.xypolygon(poly[[1]])
             result$nvertices <- length(poly[[1]]$x)
           } else {
             result$areas <- unlist(lapply(poly, Area.xypolygon))
             result$nvertices <- unlist(lapply(poly,
                                               function(a) {length(a$x)}))
           }
           result$nhole <- sum(result$areas < 0)
         },
         mask={
           result$npixels <- object$dim
           result$xstep <- object$xstep
           result$ystep <- object$ystep
         }
         )
  class(result) <- "summary.owin"
  result
}

print.summary.owin <- function(x, ...) {
  verifyclass(x, "summary.owin")
  unitinfo <- summary(x$units)
  pluralunits <- unitinfo$plural
  singularunits <- unitinfo$singular
  switch(x$type,
         rectangle={
           rectname <- "Window: rectangle ="
         },
         polygonal={
           np <- x$npoly
           cat("Window:", "polygonal", "boundary", fill=TRUE)
           if(np == 0) {
             cat("window is empty\n")
           } else if(np == 1) {
             cat("single connected", "closed polygon",
                 "with",
                 x$nvertices, 
                 "vertices", fill=TRUE)
           } else {
             nh <- x$nhole
             holy <- if(nh == 0) "(no holes)" else
                     if(nh == 1) "(1 hole)" else
                     paren(paste(nh, "holes"))
             cat(np, "separate polygons", holy, fill=TRUE)
             if(np > 0)
               print(data.frame(vertices=x$nvertices,
                                area=signif(x$areas, 6),
                                relative.area=signif(x$areas/x$area,3),
                                row.names=paste("polygon",
                                  1:np,
                                  ifelse(x$areas < 0, "(hole)", "")
                                  )))
           }
           rectname <- "enclosing rectangle:"
         },
         mask={
           cat("binary image mask\n")
           di <- x$npixels
           cat(paste(di[1], "x", di[2], "pixel array (ny, nx)\n"))
           cat(paste("pixel size:",
                     signif(x$xstep,3), "by", signif(x$ystep,3),
                     pluralunits, "\n"))
           rectname <- "enclosing rectangle:"
         }
         )
  cat(rectname,
      prange(zapsmall(x$xrange)),
      "x",
      prange(zapsmall(x$yrange)),
      pluralunits, 
      fill=TRUE)
  Area <- signif(x$area, 6)
  cat("Window area =", Area, "square",
      if(Area == 1) singularunits else pluralunits,
      fill=TRUE)
  if(!is.null(ledge <- unitinfo$legend))
    cat(ledge, "\n")
  return(invisible(x))
}

discretise <- function(X,eps=NULL,dimyx=NULL,xy=NULL) {
  verifyclass(X,"ppp")
  W <- X$window
  ok <- inside.owin(X$x,X$y,W)
  if(!all(ok))
    stop("There are points of X outside the window of X")
  all.null <- is.null(eps) & is.null(dimyx) & is.null(xy)
  if(W$type=="mask" & all.null) return(X)
  WM  <- as.mask(W,eps=eps,dimyx=dimyx,xy=xy)
  nok <- !inside.owin(X$x,X$y,WM)
  if(any(nok)) {
    ifix <- nearest.raster.point(X$x[nok],X$y[nok], WM)
    ifix <- cbind(ifix$row,ifix$col)
    WM$m[ifix] <- TRUE
  }
  X$window <- WM
  X
}

pixelcentres <- function (X, W=NULL,...) {
  X <- as.mask(as.owin(X), ...)
  if(is.null(W)) W <- as.rectangle(X)
  Y <- as.ppp(raster.xy(X,drop=TRUE),W=W)
  return(Y)
}

## generics which extract and assign the window of some object

Window <- function(X, ...) { UseMethod("Window") }

"Window<-" <- function(X, ..., value) { UseMethod("Window<-") }
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/wingeom.R"
#
#	wingeom.S	Various geometrical computations in windows
#
#
#	$Revision: 4.95 $	$Date: 2014/12/14 08:16:37 $
#
#
#
#
#-------------------------------------

volume.owin <- function(x) { area.owin(x) }

area <- function(w) UseMethod("area")

area.default <- function(w) area.owin(as.owin(w))

area.owin <- function(w) {
    stopifnot(is.owin(w))
        switch(w$type,
               rectangle = {
		width <- abs(diff(w$xrange))
		height <- abs(diff(w$yrange))
		area <- width * height
               },
               polygonal = {
                 area <- sum(unlist(lapply(w$bdry, Area.xypolygon)))
               },
               mask = {
                 pixelarea <- abs(w$xstep * w$ystep)
                 npixels <- sum(w$m)
                 area <- pixelarea * npixels
               },
               stop("Unrecognised window type")
        )
        return(area)
}

perimeter <- function(w) {
  w <- as.owin(w)
  switch(w$type,
         rectangle = {
           return(2*(diff(w$xrange)+diff(w$yrange)))
         },
         polygonal={
           return(sum(lengths.psp(edges(w))))
         },
         mask={
           p <- as.polygonal(w)
           if(is.null(p)) return(NA)
           delta <- sqrt(w$xstep^2 + w$ystep^2)
           p <- simplify.owin(p, delta * 1.15)
           return(sum(lengths.psp(edges(p))))
         })
  return(NA)
}

sidelengths.owin <- function(x) {
  if(x$type != "rectangle")
    warning("Computing the side lengths of a non-rectangular window")
  with(x, c(diff(xrange), diff(yrange)))
}

shortside.owin <- function(x) { min(sidelengths(x)) }

eroded.areas <- function(w, r, subset=NULL) {
  w <- as.owin(w)
  if(!is.null(subset) && !is.mask(w))
    w <- as.mask(w)
  switch(w$type,
         rectangle = {
           width <- abs(diff(w$xrange))
           height <- abs(diff(w$yrange))
           areas <- pmax(width - 2 * r, 0) * pmax(height - 2 * r, 0)
         },
         polygonal = {
           ## warning("Approximating polygonal window by digital image")
           w <- as.mask(w)
           areas <- eroded.areas(w, r)
         },
         mask = {
           ## distances from each pixel to window boundary
           b <- if(is.null(subset)) bdist.pixels(w, style="matrix") else 
                bdist.pixels(w)[subset, drop=TRUE, rescue=FALSE]
           ## histogram breaks to satisfy hist()
           Bmax <- max(b, r)
           breaks <- c(-1,r,Bmax+1)
           ## histogram of boundary distances
           h <- hist(b, breaks=breaks, plot=FALSE)$counts
           ## reverse cumulative histogram
           H <- revcumsum(h)
           ## drop first entry corresponding to r=-1
           H <- H[-1]
           ## convert count to area
           pixarea <- w$xstep * w$ystep
           areas <- pixarea * H
         },
         stop("unrecognised window type")
         )
  areas
}	

even.breaks.owin <- function(w) {
	verifyclass(w, "owin")
        Rmax <- diameter(w)
        make.even.breaks(Rmax, Rmax/(100 * sqrt(2)))
}

unit.square <- function() { owin(c(0,1),c(0,1)) }

square <- function(r=1) {
  stopifnot(is.numeric(r))
  if(any(is.na(r) | !is.finite(r)))
    stop("argument r is NA or infinite")
  if(length(r) == 1) {
    stopifnot(r > 0)
    r <- c(0,r)
  } else if(length(r) == 2) {
    stopifnot(r[1] < r[2])
  } else stop("argument r must be a single number, or a vector of length 2")
  owin(r,r)
}

overlap.owin <- function(A, B) {
  # compute the area of overlap between two windows
  
  # check units
  if(!compatible.units(unitname(A), unitname(B)))
    warning("The two windows have incompatible units of length")
  
  At <- A$type
  Bt <- B$type
  if(At=="rectangle" && Bt=="rectangle") {
    xmin <- max(A$xrange[1],B$xrange[1])
    xmax <- min(A$xrange[2],B$xrange[2])
    if(xmax <= xmin) return(0)
    ymin <- max(A$yrange[1],B$yrange[1])
    ymax <- min(A$yrange[2],B$yrange[2])
    if(ymax <= ymin) return(0)
    return((xmax-xmin) * (ymax-ymin))
  }
  if((At=="rectangle" && Bt=="polygonal")
     || (At=="polygonal" && Bt=="rectangle")
     || (At=="polygonal" && Bt=="polygonal"))
  {
    AA <- as.polygonal(A)$bdry
    BB <- as.polygonal(B)$bdry
    area <- 0
    for(i in seq_along(AA))
      for(j in seq_along(BB))
        area <- area + overlap.xypolygon(AA[[i]], BB[[j]])
    return(area)
  }
  if(At=="mask") {
    # count pixels in A that belong to B
    pixelarea <- abs(A$xstep * A$ystep)
    rxy <- rasterxy.mask(A, drop=TRUE)
    x <- rxy$x
    y <- rxy$y
    ok <- inside.owin(x, y, B) 
    return(pixelarea * sum(ok))
  }
  if(Bt== "mask") {
    # count pixels in B that belong to A
    pixelarea <- abs(B$xstep * B$ystep)
    rxy <- rasterxy.mask(B, drop=TRUE)
    x <- rxy$x
    y <- rxy$y
    ok <- inside.owin(x, y, A)
    return(pixelarea * sum(ok))
  }
  stop("Internal error")
}

#
#  subset operator for window
#

"[.owin" <- 
function(x, i, ...) {
  if(!missing(i) && !is.null(i)) {
    if(is.im(i) && i$type == "logical") {
      # convert to window
      i <- as.owin(eval.im(ifelse1NA(i)))
    } else stopifnot(is.owin(i))
    x <- intersect.owin(x, i, fatal=FALSE)
  }
  return(x)
}
    
#
#
#  Intersection and union of windows
#
#

intersect.owin <- function(A, B, ..., fatal=TRUE) {
  liszt <- list(...)
  rasterinfo <- list()
  if(length(liszt) > 0) {
    # explicit arguments controlling raster info
    israster <- names(liszt) %in% names(formals(as.mask))
    rasterinfo <- liszt[israster]
    # handle intersection of more than two windows
    isowin <- unlist(lapply(liszt, is.owin))
    nextra <- sum(isowin)
    if(nextra > 0) {
      windows <- liszt[isowin]
      for(i in 1:nextra)
        B <- do.call("intersect.owin",
                     append(list(B, windows[[i]]), rasterinfo))
    }
  }
  if(missing(A) || is.null(A)) return(B)
  if(missing(B) || is.null(B)) return(A)
  verifyclass(A, "owin")
  verifyclass(B, "owin")
  #
  if(identical(A, B))
    return(A)

  # check units
  if(!compatible(unitname(A), unitname(B)))
    warning("The two windows have incompatible units of length")

  # determine intersection of x and y ranges
  xr <- intersect.ranges(A$xrange, B$xrange, fatal=fatal)
  yr <- intersect.ranges(A$yrange, B$yrange, fatal=fatal)
  if(!fatal && (is.null(xr) || is.null(yr)))
    return(NULL)
  C <- owin(xr, yr, unitname=unitname(A))

  if(is.empty(A) || is.empty(B))
    return(emptywindow(C))
           
  # Determine type of intersection
  
  Arect <- is.rectangle(A)
  Brect <- is.rectangle(B)
#  Apoly <- is.polygonal(A)
#  Bpoly <- is.polygonal(B)
  Amask <- is.mask(A)
  Bmask <- is.mask(B)
  
  # Rectangular case
  if(Arect && Brect)
    return(C)

  if(!Amask && !Bmask) {
    ####### Result is polygonal ############
    a <- lapply(as.polygonal(A)$bdry, reverse.xypolygon)
    b <- lapply(as.polygonal(B)$bdry, reverse.xypolygon)
    ab <- polyclip::polyclip(a, b, "intersection",
                             fillA="nonzero", fillB="nonzero")
    if(length(ab)==0)
      return(emptywindow(C))
    # ensure correct polarity
    totarea <- sum(unlist(lapply(ab, Area.xypolygon)))
    if(totarea < 0)
      ab <- lapply(ab, reverse.xypolygon)
    AB <- owin(poly=ab, check=FALSE, unitname=unitname(A))
    AB <- rescue.rectangle(AB)
    return(AB)
  }

  ######### Result is a mask ##############
  
  # Restrict domain where possible 
  if(Arect)
    A <- C
  if(Brect)
    B <- C
  if(Amask)
    A <- trim.mask(A, C)
  if(Bmask)
    B <- trim.mask(B, C)

  # Did the user specify the pixel raster?
  if(length(rasterinfo) > 0) {
    # convert to masks with specified parameters, and intersect
    if(Amask) {
      A <- do.call("as.mask", append(list(A), rasterinfo))
      return(restrict.mask(A, B))
    } else {
      B <- do.call("as.mask", append(list(B), rasterinfo))
      return(restrict.mask(B, A))
    }
  } 
  
  # One mask and one rectangle?
  if(Arect && Bmask)
      return(B)
  if(Amask && Brect)
      return(A)

  # One mask and one polygon?
  if(Amask && !Bmask) 
    return(restrict.mask(A, B))
  if(!Amask && Bmask)
    return(restrict.mask(B, A))

  # Two existing masks?
  if(Amask && Bmask) {
    # choose the finer one
    if(A$xstep <= B$xstep)
      return(restrict.mask(A, B))
    else
      return(restrict.mask(B, A))
  }

  # No existing masks. No clipping applied so far.
  # Convert one window to a mask with default pixel raster, and intersect.
  if(Arect) {
    A <- as.mask(A)
    return(restrict.mask(A, B))
  } else {
    B <- as.mask(B)
    return(restrict.mask(B, A))
  }
}


union.owin <- function(A, B, ...) {
  liszt <- list(...)
  rasterinfo <- list()
  if(length(liszt) > 0) {
    # explicit arguments controlling raster info
    israster <- names(liszt) %in% names(formals(as.mask))
    rasterinfo <- liszt[israster]
    # handle union of more than two windows
    isowin <- unlist(lapply(liszt, is.owin))
    nextra <- sum(isowin)
    if(nextra > 0) {
      windows <- liszt[isowin]
      for(i in 1:nextra)
        B <- do.call("union.owin",
                     append(list(B, windows[[i]]), rasterinfo))
    }
  }
  #
  if(missing(A) || is.null(A) || is.empty(A)) return(B)
  if(missing(B) || is.null(B) || is.empty(B)) return(A)
  verifyclass(A, "owin")
  verifyclass(B, "owin")

  if(identical(A, B))
    return(A)

  # check units
  if(!compatible(unitname(A), unitname(B)))
    warning("The two windows have incompatible units of length")
  
  # Determine type of intersection
  
#  Arect <- is.rectangle(A)
#  Brect <- is.rectangle(B)
#  Apoly <- is.polygonal(A)
#  Bpoly <- is.polygonal(B)
  Amask <- is.mask(A)
  Bmask <- is.mask(B)

  # Create a rectangle to contain the result
  
  C <- owin(range(A$xrange, B$xrange),
            range(A$yrange, B$yrange),
            unitname=unitname(A))

  if(!Amask && !Bmask) {
    ####### Result is polygonal (or rectangular) ############
    a <- lapply(as.polygonal(A)$bdry, reverse.xypolygon)
    b <- lapply(as.polygonal(B)$bdry, reverse.xypolygon)
    ab <- polyclip::polyclip(a, b, "union", fillA="nonzero", fillB="nonzero")
    if(length(ab) == 0)
      return(emptywindow(C))
    # ensure correct polarity
    totarea <- sum(unlist(lapply(ab, Area.xypolygon)))
    if(totarea < 0)
      ab <- lapply(ab, reverse.xypolygon)
    AB <- owin(poly=ab, check=FALSE, unitname=unitname(A))
    AB <- rescue.rectangle(AB)
    return(AB)
  }

  ####### Result is a mask ############

  # Determine pixel raster parameters
  if(length(rasterinfo) == 0) {
    rasterinfo <-
      if(Amask)
        list(xy=list(x=as.numeric(prolongseq(A$xcol, C$xrange)),
               y=as.numeric(prolongseq(A$yrow, C$yrange))))
      else if(Bmask)
        list(xy=list(x=as.numeric(prolongseq(B$xcol, C$xrange)),
               y=as.numeric(prolongseq(B$yrow, C$yrange))))
      else
        list()
  }

  # Convert C to mask
  C <- do.call("as.mask", append(list(w=C), rasterinfo))

  rxy <- rasterxy.mask(C)
  x <- rxy$x
  y <- rxy$y
  ok <- inside.owin(x, y, A) | inside.owin(x, y, B)

  if(all(ok)) {
    # result is a rectangle
    C <- as.rectangle(C)
  } else {
    # result is a mask
    C$m[] <- ok
  }
  return(C)
}

setminus.owin <- function(A, B, ...) {
  if(is.null(A) || is.empty(A)) return(B)
  if(is.null(B) || is.empty(B)) return(A)
  verifyclass(A, "owin")
  verifyclass(B, "owin")

  if(identical(A, B))
    return(emptywindow(as.rectangle(A)))

  # check units
  if(!compatible(unitname(A), unitname(B)))
    warning("The two windows have incompatible units of length")
  
  # Determine type of arguments
  
  Arect <- is.rectangle(A)
  Brect <- is.rectangle(B)
#  Apoly <- is.polygonal(A)
#  Bpoly <- is.polygonal(B)
  Amask <- is.mask(A)
  Bmask <- is.mask(B)

  # Case where A and B are both rectangular
  if(Arect && Brect) {
    C <- intersect.owin(A, B, fatal=FALSE)
    if(is.null(C)) return(A)
    return(complement.owin(C, A))
  }
    
  # Polygonal case

  if(!Amask && !Bmask) {
    ####### Result is polygonal ############
    a <- lapply(as.polygonal(A)$bdry, reverse.xypolygon)
    b <- lapply(as.polygonal(B)$bdry, reverse.xypolygon)
    ab <- polyclip::polyclip(a, b, "minus", fillA="nonzero", fillB="nonzero")
    if(length(ab) == 0)
      return(emptywindow(A))
    # ensure correct polarity
    totarea <- sum(unlist(lapply(ab, Area.xypolygon)))
    if(totarea < 0)
      ab <- lapply(ab, reverse.xypolygon)
    AB <- owin(poly=ab, check=FALSE, unitname=unitname(A))
    AB <- rescue.rectangle(AB)
    return(AB)
  }

  ####### Result is a mask ############

  # Determine pixel raster parameters
  rasterinfo <- 
    if((length(list(...)) > 0))
      list(...)
    else if(Amask)
      list(xy=list(x=A$xcol,
                   y=A$yrow))
    else if(Bmask)
      list(xy=list(x=B$xcol,
                   y=B$yrow))
    else
      list()

  # Convert A to mask
  AB <- do.call("as.mask", append(list(w=A), rasterinfo))

  rxy <- rasterxy.mask(AB)
  x <- rxy$x
  y <- rxy$y
  ok <- inside.owin(x, y, A) & !inside.owin(x, y, B)

  if(!all(ok))
    AB$m[] <- ok
  else
    AB <- rescue.rectangle(AB)

  return(AB)
}

# auxiliary functions
  
trim.mask <- function(M, R, tolerant=TRUE) {
    # M is a mask,
    # R is a rectangle

    # Ensure R is a subset of bounding rectangle of M
    R <- owin(intersect.ranges(M$xrange, R$xrange),
              intersect.ranges(M$yrange, R$yrange))
    
    # Deal with very thin rectangles
    if(tolerant) {
      R$xrange <- adjustthinrange(R$xrange, M$xstep, M$xrange)
      R$yrange <- adjustthinrange(R$yrange, M$ystep, M$yrange)
    }

    # Extract subset of image grid
    within.range <- function(u, v) { (u >= v[1]) & (u <= v[2]) }
    yrowok <- within.range(M$yrow, R$yrange)
    xcolok <- within.range(M$xcol, R$xrange)
    if((ny <- sum(yrowok)) == 0 || (nx <- sum(xcolok)) == 0) 
      return(emptywindow(R))
    Z <- M
    Z$xrange <- R$xrange
    Z$yrange <- R$yrange
    Z$yrow <- M$yrow[yrowok]
    Z$xcol <- M$xcol[xcolok]
    Z$m <- M$m[yrowok, xcolok]
    if(ny < 2 || nx < 2)
      Z$m <- matrix(Z$m, nrow=ny, ncol=nx)
    Z$dim <- dim(Z$m)
    return(Z)
}

restrict.mask <- function(M, W) {
  ## M is a mask, W is any window
  stopifnot(is.mask(M))
  stopifnot(inherits(W, "owin"))
  if(is.rectangle(W))
    return(trim.mask(M, W))
  M <- trim.mask(M, as.rectangle(W))
  ## Determine which pixels of M are inside W
  rxy <- rasterxy.mask(M, drop=TRUE)
  x <- rxy$x
  y <- rxy$y
  ok <- inside.owin(x, y, W)
  Mm <- M$m
  Mm[Mm] <- ok
  M$m <- Mm
  return(M)
}

# SUBSUMED IN rmhexpand.R
# expand.owin <- function(W, f=1) {
#
#  # expand bounding box of 'win'
#  # by factor 'f' in **area**
#  if(f <= 0)
#    stop("f must be > 0")
#  if(f == 1)
#    return(W)
#  bb <- boundingbox(W)
#  xr <- bb$xrange
#  yr <- bb$yrange
#  fff <- (sqrt(f) - 1)/2
#  Wexp <- owin(xr + fff * c(-1,1) * diff(xr),
#               yr + fff * c(-1,1) * diff(yr),
#               unitname=unitname(W))
#  return(Wexp)
#}

trim.rectangle <- function(W, xmargin=0, ymargin=xmargin) {
  if(!is.rectangle(W))
    stop("Internal error: tried to trim margin off non-rectangular window")
  xmargin <- ensure2vector(xmargin)
  ymargin <- ensure2vector(ymargin)
  if(any(xmargin < 0) || any(ymargin < 0))
    stop("values of xmargin, ymargin must be nonnegative")
  if(sum(xmargin) > diff(W$xrange))
    stop("window is too small to cut off margins of the width specified")
  if(sum(ymargin) > diff(W$yrange))
    stop("window is too small to cut off margins of the height specified")
  owin(W$xrange + c(1,-1) * xmargin,
       W$yrange + c(1,-1) * ymargin,
       unitname=unitname(W))
}

grow.rectangle <- function(W, xmargin=0, ymargin=xmargin) {
  xmargin <- ensure2vector(xmargin)
  ymargin <- ensure2vector(ymargin)
  if(any(xmargin < 0) || any(ymargin < 0))
    stop("values of xmargin, ymargin must be nonnegative")
  owin(W$xrange + c(-1,1) * xmargin,
       W$yrange + c(-1,1) * ymargin,
       unitname=unitname(W))
}

grow.mask <- function(M, xmargin=0, ymargin=xmargin) {
  stopifnot(is.mask(M))
  m <- as.matrix(M)
  Rplus <- grow.rectangle(as.rectangle(M), xmargin, ymargin)
  ## extend the raster
  xcolplus <- prolongseq(M$xcol, Rplus$xrange)
  yrowplus <- prolongseq(M$yrow, Rplus$yrange)
  mplus <- matrix(FALSE, length(yrowplus), length(xcolplus))
  ## pad out the mask entries
  nleft <- attr(xcolplus, "nleft")
  nright <- attr(xcolplus, "nright")
  nbot <- attr(yrowplus, "nleft")
  ntop <- attr(yrowplus, "nright")
  mplus[ (nleft+1):(length(yrowplus)-nright),
         (nbot+1):(length(xcolplus)-ntop) ] <- m
  ## pack up
  result <- owin(xrange=Rplus$xrange,
                 yrange=Rplus$yrange,
                 xcol=as.numeric(xcolplus),
                 yrow=as.numeric(yrowplus),
                 mask=mplus,
                 unitname=unitname(M))
  return(result)
}
  
bdry.mask <- function(W) {
  verifyclass(W, "owin")
  W <- as.mask(W)
  m <- W$m
  nr <- nrow(m)
  nc <- ncol(m)
  if(!spatstat.options('Cbdrymask')) {
    ## old interpreted code
    b <-     (m != rbind(FALSE,       m[-nr, ]))
    b <- b | (m != rbind(m[-1, ], FALSE))
    b <- b | (m != cbind(FALSE,       m[, -nc]))
    b <- b | (m != cbind(m[, -1], FALSE))
  } else {
    b <- integer(nr * nc)
    z <- .C("bdrymask",
            nx = as.integer(nc),
            ny = as.integer(nr),
            m = as.integer(m),
            b = as.integer(b))
    b <- matrix(as.logical(z$b), nr, nc)
  }
  W$m <- b
  return(W)
}

vertices <- function(w) {
  verifyclass(w, "owin")
  if(is.empty(w))
    return(NULL)
  switch(w$type,
         rectangle={
           xr <- w$xrange
           yr <- w$yrange
           vert <- list(x=xr[c(1,2,2,1)], y=yr[c(1,1,2,2)])
         },
         polygonal={
           vert <- do.call("concatxy",w$bdry)
         },
         mask={
           bm <- bdry.mask(w)$m
           rxy <- rasterxy.mask(w)
           xx <- rxy$x
           yy <- rxy$y
           vert <- list(x=as.vector(xx[bm]),
                        y=as.vector(yy[bm]))
         })
  return(vert)
}

diameter <- function(x) { UseMethod("diameter") }

diameter.owin <- function(x) {
  w <- as.owin(x)
  if(is.empty(w))
    return(NULL)
  vert <- vertices(w)
  if(length(vert$x) > 3) {
    # extract convex hull
    h <- with(vert, chull(x, y))
    vert <- with(vert, list(x=x[h], y=y[h]))
  }
  d <- pairdist(vert, squared=TRUE)
  return(sqrt(max(d)))
}

incircle <- function(W) {
  # computes the largest circle contained in W
  verifyclass(W, "owin")
  if(is.empty(W))
    return(NULL)
  if(is.rectangle(W)) {
    xr <- W$xrange
    yr <- W$yrange
    x0 <- mean(xr)
    y0 <- mean(yr)
    radius <- min(diff(xr), diff(yr))/2
    return(list(x=x0, y=y0, r=radius))
  }
  # compute distance to boundary
  D <- distmap(W, invert=TRUE)
  D <- D[W, drop=FALSE]
  # find maximum distance
  v <- D$v
  ok <- !is.na(v)
  Dvalues <- as.vector(v[ok])
  Dmax <- max(Dvalues)
  # find location of maximum
  locn <- which.max(Dvalues)
  locrow <- as.vector(row(v)[ok])[locn]
  loccol <- as.vector(col(v)[ok])[locn]
  x0 <- D$xcol[loccol]
  y0 <- D$yrow[locrow]
  if(is.mask(W)) {
    # radius could be one pixel diameter shorter than Dmax
    Dpixel <- sqrt(D$xstep^2 + D$ystep^2)
    radius <- max(0, Dmax - Dpixel)
  } else radius <- Dmax
  return(list(x=x0, y=y0, r=radius))
}

inpoint <- function(W) {
  # selects a point that is always inside the window.
  verifyclass(W, "owin")
  if(is.empty(W))
    return(NULL)
  if(is.rectangle(W))
    return(c(mean(W$xrange), mean(W$yrange)))
  if(is.polygonal(W)) {
    xy <- centroid.owin(W)
    if(inside.owin(xy$x, xy$y, W))
      return(xy)
  }
  W <- as.mask(W)
  Mm <- W$m
  Mrow <- as.vector(row(Mm)[Mm])
  Mcol <- as.vector(col(Mm)[Mm])
  selectmiddle <- function(x) { x[ceiling(length(x)/2)] }
  midcol <- selectmiddle(Mcol)
  midrow <- selectmiddle(Mrow[Mcol==midcol])
  x <- W$xcol[midcol]
  y <- W$yrow[midrow]
  return(c(x,y))
}

simplify.owin <- function(W, dmin) {
  verifyclass(W, "owin")
  if(is.empty(W))
    return(W)
  W <- as.polygonal(W)
  W$bdry <- lapply(W$bdry, simplify.xypolygon, dmin=dmin)
  return(W)
}

  
is.convex <- function(x) {
  verifyclass(x, "owin")
  if(is.empty(x))
    return(TRUE)
  switch(x$type,
         rectangle={return(TRUE)},
         polygonal={
           b <- x$bdry
           if(length(b) > 1)
             return(FALSE)
           b <- b[[1]]
           xx <- b$x
           yy <- b$y
           ch <- chull(xx,yy)
           return(length(ch) == length(xx))
         },
         mask={
           v <- vertices(x)
           v <- as.ppp(v, W=as.rectangle(x))
           ch <- convexhull.xy(v)
           edg <- edges(ch)
           edgedist <- nncross(v, edg, what="dist")
           pixdiam <- sqrt(x$xstep^2 + x$ystep^2)
           return(all(edgedist <= pixdiam))
         })
  return(as.logical(NA))
}

convexhull <- function(x) {
  if(inherits(x, "owin")) 
    v <- vertices(x)
  else if(inherits(x, "psp"))
    v <- endpoints.psp
  else if(inherits(x, "ppp"))
    v <- x
  else {
    x <- as.owin(x)
    v <- vertices(x)
  }
  b <- as.rectangle(x)
  if(is.empty(x))
    return(emptywindow(b))
  ch <- convexhull.xy(v)
  out <- rebound.owin(ch, b)
  return(out)
}

  
is.empty <- function(x) { UseMethod("is.empty") }

is.empty.default <- function(x) { length(x) == 0 }

is.empty.owin <- function(x) {
  switch(x$type,
         rectangle=return(FALSE),
         polygonal=return(length(x$bdry) == 0),
         mask=return(!any(x$m)))
  return(NA)
}

emptywindow <- function(w) {
  w <- as.owin(w)
  out <- owin(w$xrange, w$yrange, poly=list(), unitname=unitname(w))
  return(out)
}

discs <- function(centres, radii=marks(centres)/2, ..., 
                  separate=FALSE, mask=FALSE, trim=TRUE, delta=NULL) {
  stopifnot(is.ppp(centres))
  n <- npoints(centres)
  if(n == 0) return(emptywindow(Frame(centres)))
  check.nvector(radii, npoints(centres))
  stopifnot(all(radii > 0))
  if(is.null(delta)) delta <- 2 * pi * min(radii)/16
  if(separate) {
    D <- list()
    W <- disc(centre=centres[1], radius=radii[1], delta=delta)
    D[[1]] <- W
    if(n == 1) return(D)
    for(i in 2:n) 
      D[[i]] <- disc(centre=centres[i], radius=radii[i], delta=delta)
    return(D)
  } else if(mask) {
    M <- as.mask(Window(centres), ...)
    z <- .C("discs2grid",
            nx    = as.integer(M$dim[2]),
            x0    = as.double(M$xcol[1]),
            xstep = as.double(M$xstep),  
            ny    = as.integer(M$dim[1]),
            y0    = as.double(M$yrow[1]),
            ystep = as.double(M$ystep), 
            nd    = as.integer(n),
            xd    = as.double(centres$x),
            yd    = as.double(centres$y),
            rd    = as.double(radii), 
            out   = as.integer(integer(prod(M$dim))))
    M$m[] <- as.logical(z$out)
    return(M)
  } else {
    W <- disc(centre=centres[1], radius=radii[1], delta=delta)
    if(n == 1) return(W)
    for(i in 2:n) {
      Di <- disc(centre=centres[i], radius=radii[i], delta=delta)
      W <- union.owin(W, Di)
    }
    if(trim) W <- intersect.owin(W, Window(centres))
    return(W)
  }
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/xypolygon.R"
#
#    xypolygon.S
#
#    $Revision: 1.63 $    $Date: 2014/11/11 12:24:55 $
#
#    low-level functions defined for polygons in list(x,y) format
#
verify.xypolygon <- function(p, fatal=TRUE) {
  whinge <- NULL
  if(!is.list(p) || !all(c("x","y") %in% names(p)))
    whinge <- "polygon must be a list with components x and y"
  else if(is.null(p$x) || is.null(p$y) || !is.numeric(p$x) || !is.numeric(p$y))
    whinge <- "components x and y must be numeric vectors"
  else if(any(is.na(p$x)) || any(is.na(p$y)))
    whinge <- "x and y coordinates must not contain NA values"
  else if(length(p$x) != length(p$y))
    whinge <- "lengths of x and y vectors unequal"
  else if(length(p$x) < 3)
    whinge <- "need at least 3 vertices for a polygon"
  ok <- is.null(whinge)
  if(!ok && fatal)
    stop(whinge)
  return(ok)
}

inside.xypolygon <- function(pts, polly, test01=TRUE, method="C") {
  # pts:  list(x,y) points to be tested
  # polly: list(x,y) vertices of a single polygon (n joins to 1)
  # test01: logical - if TRUE, test whether all values in output are 0 or 1
  pts <- xy.coords(pts, NULL)
  verify.xypolygon(polly)
  
  x <- pts$x
  y <- pts$y
  xp <- polly$x
  yp <- polly$y

  full.npts <- npts <- length(x)
  nedges <- length(xp)   # sic

  # Check for points (x,y) that coincide with vertices (xp, yp)
  # Handle them separately
  z <- .C("Cmatchxy",
          na=as.integer(npts),
          xa=as.double(x),
          ya=as.double(y),
          nb=as.integer(nedges),
          xb=as.double(xp),
          yb=as.double(yp),
          match=as.integer(integer(npts)))
  is.vertex <- (z$match != 0)
  retain <- !is.vertex
  # Remove vertices from subsequent consideration; replace them later
  if(vertices.present <- !all(retain)) {
    x <- x[retain]
    y <- y[retain]
    npts <- sum(retain)
  }

  #-------------   MAIN ALGORITHM -------------------------------
  score <- numeric(npts)
  on.boundary <- rep.int(FALSE, npts)

  if(anyretain<- any(retain)) {
    switch(method,
           C={
             #------------------ call C routine ------------------
             temp <- .C("inxyp",
                        x=as.double(x),
                        y=as.double(y),
                        xp=as.double(xp),
                        yp=as.double(yp),
                        npts=as.integer(npts),
                        nedges=as.integer(nedges),
                        score=as.integer(score),
                        onbndry=as.integer(on.boundary))
#                        PACKAGE="spatstat")
             score <- temp$score/2
             on.boundary <- as.logical(temp$onbndry)
           },
           Fortran={
             #------------------ call Fortran routine ------------------
             temp <- .Fortran("inxyp",
                              x=as.double(x),
                              y=as.double(y),
                              xp=as.double(xp),
                              yp=as.double(yp),
                              npts=as.integer(npts),
                              nedges=as.integer(nedges),
                              score=as.double(score),
                              onbndry=as.logical(on.boundary))
#                              PACKAGE="spatstat")
             score <- temp$score
             on.boundary <- temp$onbndry
           },
           interpreted={
             #----------------- original interpreted code --------------
             for(i in 1:nedges) {
               x0 <- xp[i]
               y0 <- yp[i]
               x1 <- if(i == nedges) xp[1] else xp[i+1]
               y1 <- if(i == nedges) yp[1] else yp[i+1]
               dx <- x1 - x0
               dy <- y1 - y0
               if(dx < 0) {
                 # upper edge
                 xcriterion <- (x - x0) * (x - x1)
                 consider <- (xcriterion <= 0)
                 if(any(consider)) {
                   ycriterion <-
                     y[consider] * dx - x[consider] * dy +  x0 * dy - y0 * dx
                   # closed inequality
                   contrib <- (ycriterion >= 0) *
                     ifelseAB(xcriterion[consider] == 0, 1/2, 1)
                   # positive edge sign
                   score[consider] <- score[consider] + contrib
                   # detect whether any point lies on this segment
                   on.boundary[consider] <-
                     on.boundary[consider] | (ycriterion == 0)
                 }
               } else if(dx > 0) {
                 # lower edge
                 xcriterion <- (x - x0) * (x - x1)
                 consider <- (xcriterion <= 0)
                 if(any(consider)) {
                   ycriterion <-
                     y[consider] * dx - x[consider] * dy + x0 * dy - y0 * dx
                   # open inequality
                   contrib <- (ycriterion < 0) *
                     ifelseAB(xcriterion[consider] == 0, 1/2, 1)
                   # negative edge sign
                   score[consider] <- score[consider] - contrib
                   # detect whether any point lies on this segment
                   on.boundary[consider] <-
                     on.boundary[consider] | (ycriterion == 0)
                 }
               } else {
                 # vertical edge
                 consider <- (x == x0)
                 if(any(consider)) {
                   # zero score
                   # detect whether any point lies on this segment
                   yconsider <- y[consider]
                   ycriterion <- (yconsider - y0) * (yconsider - y1)
                   on.boundary[consider] <-
                     on.boundary[consider] | (ycriterion <= 0)
                 }
               }
             }
           },
           stop(paste("Unrecognised choice for", sQuote("method")))
           )
  }
  
  #------------------- END SWITCH ------------------------------

  # replace any polygon vertices that were temporarily removed
  if(vertices.present) {
    full.score <- numeric(full.npts)
    full.on.boundary <- rep.int(FALSE, full.npts)
    if(anyretain) {
      full.score[retain] <- score
      full.on.boundary[retain] <- on.boundary
    }
    full.score[is.vertex] <- 1
    full.on.boundary[is.vertex] <- TRUE
    score       <- full.score
    on.boundary <- full.on.boundary
    npts        <- full.npts
    
  }
    
  #-------------------------------------------------
  
  # any point recognised as lying on the boundary gets score 1.
  score[on.boundary] <- 1

  if(test01) {
    # check sanity
    if(!all((score == 0) | (score == 1)))
      warning("internal error: some scores are not equal to 0 or 1")
  }

  attr(score, "on.boundary") <- on.boundary
  
  return(score)
}

owinpoly2mask <- function(w, rasta, check=TRUE) {
  if(check) {
    verifyclass(w, "owin")
    stopifnot(w$type == "polygonal")
    verifyclass(rasta, "owin")
    stopifnot(rasta$type == "mask")
  }
  
  bdry <- w$bdry

  x0    <- rasta$xcol[1]
  y0    <- rasta$yrow[1]
  xstep <- rasta$xstep
  ystep <- rasta$ystep
  dimyx <- rasta$dim
  nx    <- dimyx[2]
  ny    <- dimyx[1]

  epsilon <- with(.Machine, double.base^floor(double.ulp.digits/2))

  score <- numeric(nx*ny)
  
  for(i in seq_along(bdry)) {
    p <- bdry[[i]]
    xp <- p$x
    yp <- p$y
    np <- length(p$x)
    # repeat last vertex
    xp <- c(xp, xp[1])
    yp <- c(yp, yp[1])
    np <- np + 1
    # rescale coordinates so that pixels are at integer locations
    xp <- (xp - x0)/xstep
    yp <- (yp - y0)/ystep
    # avoid exact integer locations for vertices
    whole <- (ceiling(xp) == floor(xp))
    xp[whole] <-  xp[whole] + epsilon
    whole <- (ceiling(yp) == floor(yp))
    yp[whole] <-  yp[whole] + epsilon
    # call C
    z <- .C("poly2imI",
            xp=as.double(xp),
            yp=as.double(yp),
            np=as.integer(np),
            nx=as.integer(nx),
            ny=as.integer(ny),
            out=as.integer(integer(nx * ny)))
#            PACKAGE="spatstat")
    if(i == 1)
      score <- z$out
    else 
      score <- score + z$out
  }
  status <- (score != 0)
  out <- owin(rasta$xrange, rasta$yrange, mask=matrix(status, ny, nx))
  return(out)
}

is.hole.xypolygon <- function(polly) {
  h <- polly$hole
  if(is.null(h))
    h <- (Area.xypolygon(polly) < 0)
  return(h)
}
  
Area.xypolygon <- function(polly) {
  #
  # polly: list(x,y) vertices of a single polygon (n joins to 1)
  #

  # area could be pre-calculated
  if(!is.null(pa <- polly$area) && is.numeric(pa) && length(pa)==1)
    return(pa)

  # else calculate
  verify.xypolygon(polly)
  xp <- polly$x
  yp <- polly$y
  
  nedges <- length(xp)   # sic
  
  # place x axis below polygon
  yp <- yp - min(yp) 

  # join vertex n to vertex 1
  nxt <- c(2:nedges, 1)

  # x step, WITH sign
  dx <- xp[nxt] - xp

  # average height 
  ym <- (yp + yp[nxt])/2
  
  -sum(dx * ym)
}

bdrylength.xypolygon <- function(polly) {
  verify.xypolygon(polly)
  xp <- polly$x
  yp <- polly$y
  nedges <- length(xp)
  nxt <- c(2:nedges, 1)
  dx <- xp[nxt] - xp
  dy <- yp[nxt] - yp
  sum(sqrt(dx^2 + dy^2))
}

reverse.xypolygon <- function(p, adjust=FALSE) {
  # reverse the order of vertices
  # (=> change sign of polygon)
  verify.xypolygon(p)
  p$x <- rev(p$x)
  p$y <- rev(p$y)
  if(adjust) {
    if(!is.null(p$hole)) p$hole <- !p$hole
    if(!is.null(p$area)) p$area <- -p$area
  }
  return(p)
}

overlap.xypolygon <- function(P, Q) {
  # compute area of overlap of two simple closed polygons 
  verify.xypolygon(P)
  verify.xypolygon(Q)
  
  xp <- P$x
  yp <- P$y
  np <- length(xp)
  nextp <- c(2:np, 1)

  xq <- Q$x
  yq <- Q$y
  nq <- length(xq)
  nextq <- c(2:nq, 1)

  # adjust y coordinates so all are nonnegative
  ylow <- min(c(yp,yq))
  yp <- yp - ylow
  yq <- yq - ylow

  area <- 0
  for(i in 1:np) {
    ii <- c(i, nextp[i])
    xpii <- xp[ii]
    ypii <- yp[ii]
    for(j in 1:nq) {
      jj <- c(j, nextq[j])
      area <- area +
        overlap.trapezium(xpii, ypii, xq[jj], yq[jj])
    }
  }
  return(area)
}

overlap.trapezium <- function(xa, ya, xb, yb, verb=FALSE) {
  # compute area of overlap of two trapezia
  # which have same baseline y = 0
  #
  # first trapezium has vertices
  # (xa[1], 0), (xa[1], ya[1]), (xa[2], ya[2]), (xa[2], 0).
  # Similarly for second trapezium
  
  # Test for vertical edges
  dxa <- diff(xa)
  dxb <- diff(xb)
  if(dxa == 0 || dxb == 0)
    return(0)

  # Order x coordinates, x0 < x1
  if(dxa > 0) {
    signa <- 1
    lefta <- 1
    righta <- 2
    if(verb) cat("A is positive\n")
  } else {
    signa <- -1
    lefta <- 2
    righta <- 1
    if(verb) cat("A is negative\n")
  }
  if(dxb > 0) {
    signb <- 1
    leftb <- 1
    rightb <- 2
    if(verb) cat("B is positive\n")
  } else {
    signb <- -1
    leftb <- 2
    rightb <- 1
    if(verb) cat("B is negative\n")
  }
  signfactor <- signa * signb # actually (-signa) * (-signb)
  if(verb) cat(paste("sign factor =", signfactor, "\n"))

  # Intersect x ranges
  x0 <- max(xa[lefta], xb[leftb])
  x1 <- min(xa[righta], xb[rightb])
  if(x0 >= x1)
    return(0)
  if(verb) {
    cat(paste("Intersection of x ranges: [", x0, ",", x1, "]\n"))
    abline(v=x0, lty=3)
    abline(v=x1, lty=3)
  }

  # Compute associated y coordinates
  slopea <- diff(ya)/diff(xa)
  y0a <- ya[lefta] + slopea * (x0-xa[lefta])
  y1a <- ya[lefta] + slopea * (x1-xa[lefta])
  slopeb <- diff(yb)/diff(xb)
  y0b <- yb[leftb] + slopeb * (x0-xb[leftb])
  y1b <- yb[leftb] + slopeb * (x1-xb[leftb])
  
  # Determine whether upper edges intersect
  # if not, intersection is a single trapezium
  # if so, intersection is a union of two trapezia

  yd0 <- y0b - y0a
  yd1 <- y1b - y1a
  if(yd0 * yd1 >= 0) {
    # edges do not intersect
    areaT <- (x1 - x0) * (min(y1a,y1b) + min(y0a,y0b))/2
    if(verb) cat(paste("Edges do not intersect\n"))
  } else {
    # edges do intersect
    # find intersection
    xint <- x0 + (x1-x0) * abs(yd0/(yd1 - yd0))
    yint <- y0a + slopea * (xint - x0)
    if(verb) {
      cat(paste("Edges intersect at (", xint, ",", yint, ")\n"))
      points(xint, yint, cex=2, pch="O")
    }
    # evaluate left trapezium
    left <- (xint - x0) * (min(y0a, y0b) + yint)/2
    # evaluate right trapezium
    right <- (x1 - xint) * (min(y1a, y1b) + yint)/2
    areaT <- left + right
    if(verb)
      cat(paste("Left area = ", left, ", right=", right, "\n"))    
  }

  # return area of intersection multiplied by signs 
  return(signfactor * areaT)
}


xypolygon2psp <- function(p, w, check=spatstat.options("checksegments")) {
  verify.xypolygon(p)
  n <- length(p$x)
  nxt <- c(2:n, 1)
  return(psp(p$x, p$y, p$x[nxt], p$y[nxt], window=w, check=check))
}
         
    
xypolyselfint <- function(p, eps=.Machine$double.eps,
                          proper=FALSE, yesorno=FALSE, checkinternal=FALSE) {
  verify.xypolygon(p)
  n <- length(p$x)
  verbose <- (n > 1000)
  if(verbose)
    cat(paste("[Checking polygon with", n, "edges..."))
  x0 <- p$x
  y0 <- p$y
  dx <- diff(x0[c(1:n,1)])
  dy <- diff(y0[c(1:n,1)])
  if(yesorno) {
    # get a yes-or-no answer
    answer <- .C("xypsi",
                 n=as.integer(n),
                 x0=as.double(x0),
                 y0=as.double(y0),
                 dx=as.double(dx),
                 dy=as.double(dy),
                 xsep=as.double(2 * max(abs(dx))),
                 ysep=as.double(2 * max(abs(dy))),
                 eps=as.double(eps),
                 proper=as.integer(proper),
                 answer=as.integer(integer(1)))$answer
    if(verbose)
      cat("]\n")
    return(answer != 0)
  }
  out <- .C("Cxypolyselfint",
            n=as.integer(n),
            x0=as.double(x0),
            y0=as.double(y0),
            dx=as.double(dx),
            dy=as.double(dy), 
            eps=as.double(eps),
            xx=as.double(numeric(n^2)),
            yy=as.double(numeric(n^2)),
            ti=as.double(numeric(n^2)),
            tj=as.double(numeric(n^2)),
            ok=as.integer(integer(n^2)))

  uhoh <- (matrix(out$ok, n, n) != 0)
  if(proper) {
    # ignore cases where two vertices coincide 
    ti <- matrix(out$ti, n, n)[uhoh]
    tj <- matrix(out$tj, n, n)[uhoh]
    i.is.vertex <- (abs(ti) < eps) | (abs(ti - 1) < eps)
    j.is.vertex <- (abs(tj) < eps) | (abs(tj - 1) < eps)
    dup <- i.is.vertex & j.is.vertex
    uhoh[uhoh] <- !dup
  }
  if(checkinternal && any(uhoh != t(uhoh)))
    warning("Internal error: incidence matrix is not symmetric")
  xx <- matrix(out$xx, n, n)
  yy <- matrix(out$yy, n, n)
  uptri <- (row(uhoh) < col(uhoh))
  xx <- as.vector(xx[uhoh & uptri])
  yy <- as.vector(yy[uhoh & uptri])
  result <- list(x=xx, y=yy)
  if(verbose)
    cat("]\n")
  return(result)
}
  

owinpolycheck <- function(W, verbose=TRUE) {
  verifyclass(W, "owin")
  stopifnot(W$type == "polygonal")

  # extract stuff
  B <- W$bdry
  npoly <- length(B)
  outerframe <- owin(W$xrange, W$yrange)
  # can't use as.rectangle here; we're still checking validity
  boxarea.mineps <- area.owin(outerframe) * (1 - 0.00001)

  # detect very large datasets
  BS <- object.size(B)
  blowbyblow <- verbose & (BS > 1e4 || npoly > 20)
  #
  
  answer <- TRUE
  notes <- character(0)
  err <- character(0)
  
  # check for duplicated points, self-intersection, outer frame
  if(blowbyblow)
    cat(paste("Checking", npoly, ngettext(npoly, "polygon...", "polygons...")))

  dup <- self <- is.box <- logical(npoly)

  for(i in 1:npoly) {
    if(blowbyblow && npoly > 1)
      progressreport(i, npoly)
    Bi <- B[[i]]
    # check for duplicated vertices
    dup[i] <- as.logical(anyDuplicated(ppp(Bi$x, Bi$y,
                                           window=outerframe, check=FALSE)))
    if(dup[i] && blowbyblow)
      message(paste("Polygon", i, "contains duplicated vertices"))
    # check for self-intersection
    self[i] <- xypolyselfint(B[[i]], proper=TRUE, yesorno=TRUE)
    if(self[i] && blowbyblow)
      message(paste("Polygon", i, "is self-intersecting"))
    # check whether one of the current boundary polygons
    # is the bounding box itself (with + sign)
    is.box[i] <- (length(Bi$x) == 4) && (Area.xypolygon(Bi) >= boxarea.mineps)
  }
  if(blowbyblow)
    cat("done.\n")
  
  if((ndup <- sum(dup)) > 0) {
    whinge <- paste(ngettext(ndup, "Polygon", "Polygons"),
                    if(npoly == 1) NULL else
                    commasep(which(dup)), 
                    ngettext(ndup, "contains", "contain"),
                    "duplicated vertices")
    notes <- c(notes, whinge)
    err <- c(err, "duplicated vertices")
    if(verbose) 
      message(whinge)
    answer <- FALSE
  }
  
  if((nself <- sum(self)) > 0) {
    whinge <-  paste(ngettext(nself, "Polygon", "Polygons"),
                     if(npoly == 1) NULL else
                     commasep(which(self)),
                     ngettext(nself, "is", "are"),
                     "self-intersecting")
    notes <- c(notes, whinge)
    if(verbose) 
      message(whinge)
    err <- c(err, "self-intersection")
    answer <- FALSE
  }
  
  if(sum(is.box) > 1) {
    answer <- FALSE
    whinge <- paste("Polygons",
                    commasep(which(is.box)),
                    "coincide with the outer frame")
    notes <- c(notes, whinge)
    err <- c(err, "polygons duplicating the outer frame")
  }
  
  # check for crossings between different polygons
  cross <- matrix(FALSE, npoly, npoly)
  if(npoly > 1) {
    if(blowbyblow)
      cat(paste("Checking for cross-intersection between",
                npoly, "polygons..."))
    P <- lapply(B, xypolygon2psp, w=outerframe, check=FALSE)
    for(i in seq_len(npoly-1)) {
      if(blowbyblow)
        progressreport(i, npoly-1)
      Pi <- P[[i]]
      for(j in (i+1):npoly) {
        crosses <- if(is.box[i] || is.box[j]) FALSE else {
          anycrossing.psp(Pi, P[[j]])
        }
        cross[i,j] <- cross[j,i] <- crosses
        if(crosses) {
          answer <- FALSE
          whinge <- paste("Polygons", i, "and", j, "cross over")
          notes <- c(notes, whinge)
          if(verbose) 
            message(whinge)
          err <- c(err, "overlaps between polygons")
        }
      }
    }
    if(blowbyblow)
      cat("done.\n")
  }

  err <- unique(err)
  attr(answer, "notes") <- notes
  attr(answer, "err") <-  err
  return(answer)
}

simplify.xypolygon <- function(p, dmin) {
  verify.xypolygon(p)
  x <- p$x
  y <- p$y
  n <- length(x)
  if(n <= 3) return(p)
  dmin2 <- dmin^2
  # edge lengths: len2[i] is distance from i to i+1 
  len2 <- (x - c(x[-1], x[1]))^2 + (y - c(y[-1],y[1]))^2
  #
  while(n > 3 && any(len2 < dmin2)) {
    # delete the shortest edge
    kill <- which.min(len2)
    # edge from 'kill' to 'kill+1' will be removed 
    # Replacement vertex is midpoint of segment
    left <- if(kill == 1) n else (kill - 1)
    killplus1 <- if(kill == n) 1 else (kill + 1)
    right <- if(killplus1 == n) 1 else (killplus1 + 1)
    xmid <- (x[kill]+x[killplus1])/2
    ymid <- (y[kill]+y[killplus1])/2
    d2leftmid <- (xmid-x[left])^2+(ymid-y[left])^2
    d2midright <- (xmid-x[right])^2+(ymid-y[right])^2
    # adjust vectors: first replace segment endpoints without deleting
    x[kill] <- xmid
    y[kill] <- ymid
    x[killplus1] <- xmid
    y[killplus1] <- ymid
    len2[left] <- d2leftmid
    len2[kill] <- 0
    len2[killplus1] <- d2midright
    # now delete 
    x <- x[-kill]
    y <- y[-kill]
    len2 <- len2[-kill]
    n <- n-1
  }
  #
  p$x <- x
  p$y <- y
  p$area <- Area.xypolygon(p[c("x","y")])
  return(p)
}

inside.triangle <- function(x, y, xx, yy) {
  # test whether points x[i], y[i] lie in triangle xx[1:3], yy[1:3]
  # using barycentric coordinates
  # vector 0 is edge from A to C
  v0x <- xx[3] - xx[1]
  v0y <- yy[3] - yy[1]
  # vector 1 is edge from A to B
  v1x <- xx[2] - xx[1]
  v1y <- yy[2] - yy[1]
  # vector 2 is from vertex A to point P
  v2x <- x - xx[1]
  v2y <- y - yy[1]
  # inner products
  dot00 <- v0x^2 + v0y^2
  dot01 <- v0x * v1x + v0y * v1y
  dot02 <- v0x * v2x + v0y * v2y
  dot11 <- v1x^2 + v1y^2
  dot12 <- v1x * v2x + v1y * v2y
  # unnormalised barycentric coordinates
  Denom <- dot00 * dot11 - dot01 * dot01
  u <- dot11 * dot02 - dot01 * dot12
  v <- dot00 * dot12 - dot01 * dot02
  # test
  return((u > 0) & (v > 0) & (u + v < Denom))
  
  
}
#line 1 "/tmp/RtmpFuQrdV/R.INSTALL325217e700f5/spatstat/R/xysegment.R"
#
#      xysegment.S
#
#     $Revision: 1.16 $    $Date: 2014/10/24 00:22:30 $
#
# Low level utilities for analytic geometry for line segments
#
# author: Adrian Baddeley 2001
#         from an original by Rob Foxall 1997
#
# distpl(p, l) 
#       distance from a single point p  = (xp, yp)
#       to a single line segment l = (x1, y1, x2, y2)
#
# distppl(p, l) 
#       distances from each of a list of points p[i,]
#       to a single line segment l = (x1, y1, x2, y2)
#       [uses only vector parallel ops]
#
# distppll(p, l) 
#       distances from each of a list of points p[i,]
#       to each of a list of line segments l[i,] 
#       [interpreted code uses large matrices and 'outer()']
#       [Fortran implementation included!]

distpl <- function(p, l) {
  xp <- p[1]
  yp <- p[2]
  dx <- l[3]-l[1]
  dy <- l[4]-l[2]
  leng <- sqrt(dx^2 + dy^2)
  # vector from 1st endpoint to p
  xpl <- xp - l[1]
  ypl <- yp - l[2]
  # distance from p to 1st & 2nd endpoints
  d1 <- sqrt(xpl^2 + ypl^2)
  d2 <- sqrt((xp-l[3])^2 + (yp-l[4])^2)
  dmin <- min(d1,d2)
  # test for zero length
  if(leng < .Machine$double.eps)
    return(dmin)
  # rotation sine & cosine
  co <- dx/leng
  si <- dy/leng
  # back-rotated coords of p
  xpr <- co * xpl + si * ypl
  ypr <-  - si * xpl + co * ypl
  # test
  if(xpr >= 0 && xpr <= leng)
    dmin <- min(dmin, abs(ypr))
  return(dmin)
}

distppl <- function(p, l) {
  xp <- p[,1]
  yp <- p[,2]
  dx <- l[3]-l[1]
  dy <- l[4]-l[2]
  leng <- sqrt(dx^2 + dy^2)
  # vector from 1st endpoint to p
  xpl <- xp - l[1]
  ypl <- yp - l[2]
  # distance from p to 1st & 2nd endpoints
  d1 <- sqrt(xpl^2 + ypl^2)
  d2 <- sqrt((xp-l[3])^2 + (yp-l[4])^2)
  dmin <- pmin.int(d1,d2)
  # test for zero length
  if(leng < .Machine$double.eps)
    return(dmin)
  # rotation sine & cosine
  co <- dx/leng
  si <- dy/leng
  # back-rotated coords of p
  xpr <- co * xpl + si * ypl
  ypr <-  - si * xpl + co * ypl
  # ypr is perpendicular distance to infinite line
  # Applies only when xp, yp in the middle
  middle <- (xpr >= 0 & xpr <= leng)
  if(any(middle))
    dmin[middle] <- pmin.int(dmin[middle], abs(ypr[middle]))
  
  return(dmin)
}

distppll <- function(p, l, mintype=0,
                     method=c("Fortran", "C", "interpreted"), listit=FALSE) {
  np <- nrow(p)
  nl <- nrow(l)
  xp <- p[,1]
  yp <- p[,2]
  if(is.na(match(mintype,0:2)))
    stop(paste("Argument", sQuote("mintype"), "must be 0, 1 or 2.\n"))
  method <- match.arg(method)
  switch(method,
         interpreted={
           dx <- l[,3]-l[,1]
           dy <- l[,4]-l[,2]
           # segment lengths
           leng <- sqrt(dx^2 + dy^2)
           # rotation sines & cosines
           co <- dx/leng
           si <- dy/leng
           co <- matrix(co, nrow=np, ncol=nl, byrow=TRUE)
           si <- matrix(si, nrow=np, ncol=nl, byrow=TRUE)
           # matrix of squared distances from p[i] to 1st endpoint of segment j
           xp.x1 <- outer(xp, l[,1], "-")
           yp.y1 <- outer(yp, l[,2], "-")
           d1 <- xp.x1^2 + yp.y1^2
           # ditto for 2nd endpoint
           xp.x2 <- outer(xp, l[,3], "-")
           yp.y2 <- outer(yp, l[,4], "-")
           d2 <- xp.x2^2 + yp.y2^2
           # for each (i,j) rotate p[i] around 1st endpoint of segment j
           # so that line segment coincides with x axis
           xpr <- xp.x1 * co + yp.y1 * si
           ypr <-  - xp.x1 * si + yp.y1 * co
           d3 <- ypr^2
           # test
           lenf <- matrix(leng, nrow=np, ncol=nl, byrow=TRUE)
           zero <- (lenf < .Machine$double.eps) 
           outside <- (zero | xpr < 0 | xpr > lenf) 
           if(any(outside))
             d3[outside] <- Inf

           dsq <- matrix(pmin.int(d1, d2, d3),nrow=np, ncol=nl)
           d <- sqrt(dsq)
           if(mintype >= 1)
             min.d <- apply(d, 1, min)
           if(mintype == 2)
             min.which <- apply(d, 1, which.min)
         },
         Fortran={
           eps <- .Machine$double.eps
           if(mintype > 0) {
             big <- sqrt(2)*diff(range(c(p,l)))
             xmin <- rep.int(big,np)
           } else {
             xmin <- 1
           } 
           n2 <- if(mintype > 1) np else 1
           temp <- .Fortran("dppll",
                            x=as.double(xp),
                            y=as.double(yp),
                            l1=as.double(l[,1]),
                            l2=as.double(l[,2]),
                            l3=as.double(l[,3]),
                            l4=as.double(l[,4]),
                            np=as.integer(np),
                            nl=as.integer(nl),
                            eps=as.double(eps),
                            mint=as.integer(mintype),
                            rslt=double(np*nl),
                            xmin=as.double(xmin),
                            jmin=integer(n2))
#                            PACKAGE="spatstat")
           d <- matrix(temp$rslt, nrow=np, ncol=nl)
           if(mintype >= 1)
             min.d <- temp$xmin
           if(mintype == 2)
             min.which <- temp$jmin
         },
         C = {
           eps <- .Machine$double.eps
           temp <- .C("prdist2segs",
                      x=as.double(xp),
                      y=as.double(yp),
                      npoints =as.integer(np),
                      x0=as.double(l[,1]),
                      y0=as.double(l[,2]),
                      x1=as.double(l[,3]),
                      y1=as.double(l[,4]),
                      nsegments=as.integer(nl),
                      epsilon=as.double(eps),
                      dist2=as.double(numeric(np * nl)))
           d <- sqrt(matrix(temp$dist2, nrow=np, ncol=nl))
           if(mintype == 2) {
             min.which <- apply(d, 1, which.min)
             min.d <- d[cbind(1:np, min.which)]
           } else if (mintype == 1) {
             min.d <- apply(d, 1, min)
           }
         })
  ###### end switch #####
  if(mintype==0)
    return(if(listit) list(d=d) else d)
  else if(mintype==1)
    return(list(d=d, min.d=min.d))
  else if(mintype==2) 
    return(list(d=d, min.d=min.d, min.which=min.which))
}

# faster code if you don't want the n*m matrix 'd'

distppllmin <- function(p, l, big=NULL) {
  np <- nrow(p)
  nl <- nrow(l)
  # initialise squared distances to large value
  if(is.null(big)) {
    xdif <- diff(range(c(p[,1],l[, c(1,3)])))
    ydif <- diff(range(c(p[,2],l[, c(2,4)])))
    big <- 2 * (xdif^2 + ydif^2)
  }
  dist2 <- rep.int(big, np)
  #
  z <- .C("nndist2segs",
          xp=as.double(p[,1]),
          yp=as.double(p[,2]),
          npoints=as.integer(np),
          x0=as.double(l[,1]),
          y0=as.double(l[,2]),
          x1=as.double(l[,3]),
          y1=as.double(l[,4]),
          nsegments=as.integer(nl),
          epsilon=as.double(.Machine$double.eps),
          dist2=as.double(dist2),
          index=as.integer(integer(np)))
  min.d <- sqrt(z$dist2)
  min.which <- z$index+1L
  return(list(min.d=min.d, min.which=min.which))
}
